Directory structure:
└── dendibakh-perf-ninja/
    ├── README.md
    ├── Contributing.md
    ├── GetStarted.md
    ├── QuickstartLinux.md
    ├── QuickstartMacOS.md
    ├── QuickstartWindows.md
    ├── .editorconfig
    ├── buildbot/
    │   ├── runCI.py
    │   └── gbench/
    │       ├── __init__.py
    │       ├── report.py
    │       └── util.py
    ├── labs/
    │   ├── bad_speculation/
    │   │   ├── README.md
    │   │   ├── branches_to_cmov_1/
    │   │   │   ├── README.md
    │   │   │   ├── bench.cpp
    │   │   │   ├── CMakeLists.txt
    │   │   │   ├── init.cpp
    │   │   │   ├── solution.cpp
    │   │   │   ├── solution.hpp
    │   │   │   └── validate.cpp
    │   │   ├── conditional_store_1/
    │   │   │   ├── README.md
    │   │   │   ├── bench.cpp
    │   │   │   ├── CMakeLists.txt
    │   │   │   ├── init.cpp
    │   │   │   ├── solution.cpp
    │   │   │   ├── solution.h
    │   │   │   └── validate.cpp
    │   │   ├── lookup_tables_1/
    │   │   │   ├── README.md
    │   │   │   ├── bench.cpp
    │   │   │   ├── CMakeLists.txt
    │   │   │   ├── init.cpp
    │   │   │   ├── solution.cpp
    │   │   │   ├── solution.hpp
    │   │   │   └── validate.cpp
    │   │   └── virtual_call_mispredict/
    │   │       ├── README.md
    │   │       ├── bench.cpp
    │   │       ├── CMakeLists.txt
    │   │       ├── solution.cpp
    │   │       ├── solution.h
    │   │       └── validate.cpp
    │   ├── core_bound/
    │   │   ├── README.md
    │   │   ├── compiler_intrinsics_1/
    │   │   │   ├── README.md
    │   │   │   ├── bench.cpp
    │   │   │   ├── CMakeLists.txt
    │   │   │   ├── init.cpp
    │   │   │   ├── solution.cpp
    │   │   │   ├── solution.h
    │   │   │   └── validate.cpp
    │   │   ├── compiler_intrinsics_2/
    │   │   │   ├── README.md
    │   │   │   ├── bench.cpp
    │   │   │   ├── CMakeLists.txt
    │   │   │   ├── solution.cpp
    │   │   │   ├── solution.hpp
    │   │   │   ├── validate.cpp
    │   │   │   └── inputs/
    │   │   │       ├── counter-example.txt
    │   │   │       ├── MarkTwain-TomSawyer.txt
    │   │   │       ├── test1.txt
    │   │   │       ├── test2.txt
    │   │   │       └── test3.txt
    │   │   ├── compiler_intrinsics_3/
    │   │   │   ├── README.md
    │   │   │   ├── bench.cpp
    │   │   │   ├── CMakeLists.txt
    │   │   │   ├── solution.cpp
    │   │   │   ├── solution.hpp
    │   │   │   └── validate.cpp
    │   │   ├── compiler_intrinsics_4/
    │   │   │   ├── README.md
    │   │   │   ├── bench.cpp
    │   │   │   ├── CMakeLists.txt
    │   │   │   ├── const.h
    │   │   │   ├── data_paths.h.in
    │   │   │   ├── picture.cpp
    │   │   │   ├── picture.h
    │   │   │   ├── solution.cpp
    │   │   │   ├── solution.h
    │   │   │   └── validate.cpp
    │   │   ├── dep_chains_1/
    │   │   │   ├── README.md
    │   │   │   ├── arena.hpp
    │   │   │   ├── bench.cpp
    │   │   │   ├── CMakeLists.txt
    │   │   │   ├── init.cpp
    │   │   │   ├── solution.cpp
    │   │   │   ├── solution.hpp
    │   │   │   └── validate.cpp
    │   │   ├── dep_chains_2/
    │   │   │   ├── README.md
    │   │   │   ├── bench.cpp
    │   │   │   ├── CMakeLists.txt
    │   │   │   ├── init.cpp
    │   │   │   ├── solution.hpp
    │   │   │   └── validate.cpp
    │   │   ├── function_inlining_1/
    │   │   │   ├── README.md
    │   │   │   ├── bench.cpp
    │   │   │   ├── CMakeLists.txt
    │   │   │   ├── init.cpp
    │   │   │   ├── solution.cpp
    │   │   │   ├── solution.h
    │   │   │   └── validate.cpp
    │   │   ├── vectorization_1/
    │   │   │   ├── README.md
    │   │   │   ├── bench.cpp
    │   │   │   ├── CMakeLists.txt
    │   │   │   ├── init.cpp
    │   │   │   ├── solution.cpp
    │   │   │   ├── solution.hpp
    │   │   │   └── validate.cpp
    │   │   └── vectorization_2/
    │   │       ├── README.md
    │   │       ├── bench.cpp
    │   │       ├── CMakeLists.txt
    │   │       ├── init.cpp
    │   │       ├── solution.cpp
    │   │       ├── solution.hpp
    │   │       └── validate.cpp
    │   ├── data_driven/
    │   │   └── README.md
    │   ├── frontend_bound/
    │   │   └── README.md
    │   ├── memory_bound/
    │   │   ├── README.md
    │   │   ├── data_packing/
    │   │   │   ├── README.md
    │   │   │   ├── bench.cpp
    │   │   │   ├── CMakeLists.txt
    │   │   │   ├── init.cpp
    │   │   │   ├── solution.cpp
    │   │   │   ├── solution.h
    │   │   │   └── validate.cpp
    │   │   ├── false_sharing_1/
    │   │   │   ├── README.md
    │   │   │   ├── bench.cpp
    │   │   │   ├── CMakeLists.txt
    │   │   │   ├── solution.cpp
    │   │   │   ├── solution.hpp
    │   │   │   └── validate.cpp
    │   │   ├── huge_pages_1/
    │   │   │   ├── README.md
    │   │   │   ├── AllocateDoublesArray.hpp
    │   │   │   ├── bench.cpp
    │   │   │   ├── CMakeLists.txt
    │   │   │   ├── GenerateMesh.cpp
    │   │   │   ├── GenerateMesh.hpp
    │   │   │   ├── HugePagesSetupTips.md
    │   │   │   ├── solution.cpp
    │   │   │   ├── solution.hpp
    │   │   │   └── validate.cpp
    │   │   ├── loop_interchange_1/
    │   │   │   ├── README.md
    │   │   │   ├── bench.cpp
    │   │   │   ├── CMakeLists.txt
    │   │   │   ├── init.cpp
    │   │   │   ├── solution.cpp
    │   │   │   ├── solution.h
    │   │   │   └── validate.cpp
    │   │   ├── loop_interchange_2/
    │   │   │   ├── README.md
    │   │   │   ├── bench.cpp
    │   │   │   ├── CMakeLists.txt
    │   │   │   ├── solution.cpp
    │   │   │   ├── solution.h
    │   │   │   └── validate.cpp
    │   │   ├── loop_tiling_1/
    │   │   │   ├── README.md
    │   │   │   ├── bench.cpp
    │   │   │   ├── CMakeLists.txt
    │   │   │   ├── init.cpp
    │   │   │   ├── solution.cpp
    │   │   │   ├── solution.hpp
    │   │   │   └── validate.cpp
    │   │   ├── mem_alignment_1/
    │   │   │   ├── README.md
    │   │   │   ├── bench.cpp
    │   │   │   ├── CMakeLists.txt
    │   │   │   ├── solution.cpp
    │   │   │   ├── solution.h
    │   │   │   └── validate.cpp
    │   │   ├── mem_order_violation_1/
    │   │   │   ├── README.md
    │   │   │   ├── bench.cpp
    │   │   │   ├── CMakeLists.txt
    │   │   │   ├── DataPaths.h.in
    │   │   │   ├── solution.cpp
    │   │   │   ├── solution.h
    │   │   │   ├── validate.cpp
    │   │   │   └── data/
    │   │   │       ├── bird.pgm
    │   │   │       ├── coins.pgm
    │   │   │       ├── pepper-binary-ref.pgm
    │   │   │       └── pepper.pgm
    │   │   └── swmem_prefetch_1/
    │   │       ├── README.md
    │   │       ├── bench.cpp
    │   │       ├── CMakeLists.txt
    │   │       ├── init.cpp
    │   │       ├── solution.cpp
    │   │       ├── solution.hpp
    │   │       └── validate.cpp
    │   └── misc/
    │       ├── README.md
    │       ├── io_opt1/
    │       │   ├── README.md
    │       │   ├── bench.cpp
    │       │   ├── CMakeLists.txt
    │       │   ├── DataPaths.h.in
    │       │   ├── MappedFile.hpp
    │       │   ├── solution.cpp
    │       │   ├── solution.hpp
    │       │   └── validate.cpp
    │       ├── lto/
    │       │   ├── README.md
    │       │   ├── ao.cpp
    │       │   ├── ao.h
    │       │   ├── ao_helpers.cpp
    │       │   ├── ao_init.cpp
    │       │   ├── ao_intersect.cpp
    │       │   ├── ao_occlusion.cpp
    │       │   ├── ao_orthoBasis.cpp
    │       │   ├── ao_render.cpp
    │       │   ├── bench.cpp
    │       │   ├── CMakeLists.txt
    │       │   ├── golden.ppm
    │       │   └── validate.cpp
    │       ├── pgo/
    │       │   ├── README.md
    │       │   ├── bench.cpp
    │       │   ├── CMakeLists.txt
    │       │   ├── reference_output.txt
    │       │   ├── run_bench_tests.lua
    │       │   ├── validate.cpp
    │       │   ├── bench/
    │       │   │   ├── ackermann.lua
    │       │   │   ├── ary.lua
    │       │   │   ├── binarytrees.lua
    │       │   │   ├── chameneos.lua
    │       │   │   ├── fannkuch.lua
    │       │   │   ├── fibo.lua
    │       │   │   ├── harmonic.lua
    │       │   │   ├── hash2.lua
    │       │   │   ├── heapsort.lua
    │       │   │   ├── hello.lua
    │       │   │   ├── knucleotide.lua
    │       │   │   ├── license.txt
    │       │   │   ├── matrix.lua
    │       │   │   ├── meteor.lua
    │       │   │   ├── moments.lua
    │       │   │   ├── nbody.lua
    │       │   │   ├── nestedloop.lua
    │       │   │   ├── nsieve.lua
    │       │   │   ├── nsievebits.lua
    │       │   │   ├── partialsums.lua
    │       │   │   ├── process.lua
    │       │   │   ├── prodcons.lua
    │       │   │   ├── random.lua
    │       │   │   ├── recursive.lua
    │       │   │   ├── regexdna.lua
    │       │   │   ├── regexmatch.lua
    │       │   │   ├── revcomp.lua
    │       │   │   ├── reversefile.lua
    │       │   │   ├── sieve.lua
    │       │   │   ├── spectralnorm.lua
    │       │   │   ├── sumcol.lua
    │       │   │   ├── takfp.lua
    │       │   │   ├── wc.lua
    │       │   │   └── wordfreq.lua
    │       │   ├── input/
    │       │   │   ├── knucleotide-input20000.txt
    │       │   │   └── license.txt
    │       │   ├── lua/
    │       │   │   ├── README
    │       │   │   ├── COPYRIGHT
    │       │   │   ├── HISTORY
    │       │   │   ├── INSTALL
    │       │   │   ├── lapi.c
    │       │   │   ├── lapi.h
    │       │   │   ├── lauxlib.c
    │       │   │   ├── lauxlib.h
    │       │   │   ├── lbaselib.c
    │       │   │   ├── lcode.c
    │       │   │   ├── lcode.h
    │       │   │   ├── ldblib.c
    │       │   │   ├── ldebug.c
    │       │   │   ├── ldebug.h
    │       │   │   ├── ldo.c
    │       │   │   ├── ldo.h
    │       │   │   ├── ldump.c
    │       │   │   ├── lfunc.c
    │       │   │   ├── lfunc.h
    │       │   │   ├── lgc.c
    │       │   │   ├── lgc.h
    │       │   │   ├── linit.c
    │       │   │   ├── liolib.c
    │       │   │   ├── llex.c
    │       │   │   ├── llex.h
    │       │   │   ├── llimits.h
    │       │   │   ├── lmathlib.c
    │       │   │   ├── lmem.c
    │       │   │   ├── lmem.h
    │       │   │   ├── loadlib.c
    │       │   │   ├── lobject.c
    │       │   │   ├── lobject.h
    │       │   │   ├── lopcodes.c
    │       │   │   ├── lopcodes.h
    │       │   │   ├── loslib.c
    │       │   │   ├── lparser.c
    │       │   │   ├── lparser.h
    │       │   │   ├── lstate.c
    │       │   │   ├── lstate.h
    │       │   │   ├── lstring.c
    │       │   │   ├── lstring.h
    │       │   │   ├── lstrlib.c
    │       │   │   ├── ltable.c
    │       │   │   ├── ltable.h
    │       │   │   ├── ltablib.c
    │       │   │   ├── ltm.c
    │       │   │   ├── ltm.h
    │       │   │   ├── lua.c
    │       │   │   ├── lua.h
    │       │   │   ├── luaconf.h
    │       │   │   ├── lualib.h
    │       │   │   ├── lundump.c
    │       │   │   ├── lundump.h
    │       │   │   ├── lvm.c
    │       │   │   ├── lvm.h
    │       │   │   ├── lzio.c
    │       │   │   ├── lzio.h
    │       │   │   └── print.c
    │       │   └── md5/
    │       │       ├── check_md5.lua
    │       │       ├── md5.lua
    │       │       └── MIT-LICENSE.txt
    │       └── warmup/
    │           ├── README.md
    │           ├── bench.cpp
    │           ├── CMakeLists.txt
    │           ├── solution.cpp
    │           ├── solution.h
    │           └── validate.cpp
    ├── tools/
    │   ├── check_speedup.py
    │   ├── labs.cmake
    │   ├── make_benchmark_library.sh
    │   ├── make_benchmark_library_mingw.cmd
    │   ├── make_benchmark_library_vs.cmd
    │   ├── msvc_simd_isa.cmake
    │   └── gbench/
    │       ├── __init__.py
    │       ├── report.py
    │       └── util.py
    └── .github/
        ├── FUNDING.yml
        └── workflows/
            ├── CI_Linux_Alderlake.yml
            ├── CI_Linux_Coffeelake.yml
            ├── CI_Macos_M1.yml
            └── CI_Win_Zen3.yml


(Files content cropped to 300k characters, download full ingest to see more)
================================================
FILE: README.md
================================================
<p align="center"> <img src="/logo.jpg" width=200> </p>

![Linux](https://github.com/dendibakh/perf-ninja/actions/workflows/CI_Linux_Alderlake.yml/badge.svg) ![Windows](https://github.com/dendibakh/perf-ninja/actions/workflows/CI_Macos_M1.yml/badge.svg) ![Windows](https://github.com/dendibakh/perf-ninja/actions/workflows/CI_Win_Zen3.yml/badge.svg) ![Linux](https://github.com/dendibakh/perf-ninja/actions/workflows/CI_Linux_Coffeelake.yml/badge.svg) 

# Performance Ninja Class

[![YouTube](https://img.shields.io/youtube/channel/subscribers/UCGmEJdQ993cdCGdnLZDuOOQ)](https://youtube.com/@easyperf3992)
[![X (formerly Twitter) Follow](https://img.shields.io/twitter/follow/dendibakh)](https://twitter.com/dendibakh)
![GitHub Repo stars](https://img.shields.io/github/stars/dendibakh/perf-ninja)

This is an online course where you can learn to find and fix low-level performance issues, for example CPU cache misses and branch mispredictions. It's all about practice. So we offer you this course in a form of lab assignments and youtube videos. You will spend at least 90% of the time analyzing performance of the code and trying to improve it.

[<img src="img/WelcomeVideo.png">](https://www.youtube.com/watch?v=2tzdkC6IDbo&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d)

Each lab assignment focuses on a specific performance problem and can take anywhere from 30 mins up to 4 hours depending on your background and the complexity of the lab assignment itself. Once you're done improving the code, you can submit your solution to Github for automated benchmarking and verification.

Performance Ninja is supported on Linux, Windows, and Mac, and is run on all the recent HW including Intel's 12th-gen Alderlake, AMD's Zen3, and Apple's M1 CPUs. You can observe the effect of your optimizations on a variety of modern platforms.

Prerequisites: basic C++ skills are an absolute must-have for the course. Denis' [book](https://products.easyperf.net/perf-book-2) "Performance Analysis and Tuning on Modern CPUs" is recommended as an introduction to performance analysis basics. Knowledge of compilers, computer architecture, and the ability to read assembly code is a plus.

Before you start working on lab assignments, make sure you read [Get Started page](GetStarted.md) and watch the [warmup video](https://youtu.be/jFRwAcIoLgQ).

Lab assignments in this project are implemented in C++. Also, Performance Ninja was ported to:
* Rust ([perf-ninja-rs](https://github.com/grahamking/perf-ninja-rs)), thanks to @grahamking.
* Zig ([perf-ninja-zig](https://github.com/JonathanHallstrom/perf-ninja-zig)), thanks to @JonathanHallstrom.

## Lab assignments

* Core Bound:
  * [Vectorization 1](labs/core_bound/vectorization_1)
  * [Vectorization 2](labs/core_bound/vectorization_2)
  * [Function Inlining](labs/core_bound/function_inlining_1)
  * [Dependency Chains 1](labs/core_bound/dep_chains_1)
  * [Dependency Chains 2](labs/core_bound/dep_chains_2)
  * [Compiler Intrinsics 1](labs/core_bound/compiler_intrinsics_1)
  * [Compiler Intrinsics 2](labs/core_bound/compiler_intrinsics_2)
  * [Compiler Intrinsics 3](labs/core_bound/compiler_intrinsics_3)
  * [Compiler Intrinsics 4](labs/core_bound/compiler_intrinsics_4)
* Memory Bound:
  * [Data Packing](labs/memory_bound/data_packing)
  * [Loop Interchange 1](labs/memory_bound/loop_interchange_1)
  * [Loop Interchange 2](labs/memory_bound/loop_interchange_2)
  * [Loop Tiling](labs/memory_bound/loop_tiling_1)
  * [SW memory prefetching](labs/memory_bound/swmem_prefetch_1)
  * [False Sharing](labs/memory_bound/false_sharing_1)
  * [Huge Pages](labs/memory_bound/huge_pages_1)
  * [Memory Order Violation](labs/memory_bound/mem_order_violation_1)
  * [Memory Alignment](labs/memory_bound/mem_alignment_1)
* Bad Speculation:
  * [Branches To CMOVs](labs/bad_speculation/branches_to_cmov_1)
  * [Conditional Store](labs/bad_speculation/conditional_store_1)
  * [Replacing Branches With Lookup Tables](labs/bad_speculation/lookup_tables_1)
  * [C++ Virtual Calls](labs/bad_speculation/virtual_call_mispredict)
* CPU Frontend Bound:
* Data-Driven optimizations:
* Misc:
  * [Warmup](labs/misc/warmup)
  * [LTO](labs/misc/lto)
  * [PGO](labs/misc/pgo)
  * [Optimize IO](labs/misc/io_opt1)

## Support the project

Performance Ninja is in a very much work-in-progress state. We will be adding new lab assignments and videos! The course is free by default, but we ask you to support us on [Github Sponsors](https://github.com/sponsors/dendibakh), [Patreon](https://www.patreon.com/dendibakh) or [PayPal](https://www.paypal.com/cgi-bin/webscr?cmd=_donations&business=TBM3NW8TKTT34&currency_code=USD&source=url). Your sponsorship will speed up adding new lab assignments.

Current sponsors:
* Pavel Davydov (@pdavydov108)
* Matias Christensen
* Maya Lekova (@MayaLekova)
* Aaron St. George (@AaronStGeorge)

Thanks to Mansur Mavliutov (@Mansur) for providing an AMD-based machine for running CI jobs.

Lab authors:
* Andrew Evstyukhin (@andrewevstyukhin)
* Ivica Bogosavljevic (@ibogosavljevic)
* René Rahn (@rrahn)
* Adam Folwarczny (@adamf88)
* Jakub Beránek (@Kobzol)
* Jakub Gałecki (@kubagalecki)
* Jonathan Hallstrom (@JonathanHallstrom)
* Oleg Makovski (@0legmak)
* Denis Bakhvalov (@dendibakh)

## Contributing

We warmly welcome contributions! See [Contributing.md](Contributing.md) for the details.

Please write to dendibakh@gmail.com with suggestions.

Copyright © 2025 by Denis Bakhvalov under Creative Commons license (CC BY 4.0).



================================================
FILE: Contributing.md
================================================
# Contributing

We are looking for proposals and implementations of the new lab assignments similar to the ones we already have.

Some criterias:
- We prefer a small localized example over a big application (ideally within 1KLOC). But if something is hard to write on our own, we could reuse existing benchmark.
- We prefer real-world problems over synthesized ones. But synthesized benchmarks are welcome too.
- Performance issue in the lab assignment should be the top hotspot. I.e. the benchmark should be stressing the major performance bottleneck, not the secondary one.
- Deoptimize existing benchmarks/workloads and making a lab out of it is also fine. I.e. if you know of a case when a certain optimization *was* made in the codebase, we can use the version *before* that change was introduced.

Please *do not* submit new lab assignments as PR against this repo. Otherwise we will spoil the solution :) . I have internal repo, which we use for staging the code for new lab assignments. Write to me and I will give you access there.

We have created a template for streamlining the process of creating new lab assignments. You don't have to spend time on setting up an infrastructure and you can focus directly on the code of the assignment.

We are also looking to increase diversity of the platforms on which we test your submissions. For now, the CI runs on a dedicated Intel x86 Linux box (at Denis' home). We would gladly extend this list with ARM- and AMD-based machines. If you have one sitting idle in at your desk, consider using it to run CI jobs for this project. All you need is to install Github [runner client](https://docs.github.com/en/actions/hosting-your-own-runners/about-self-hosted-runners), which you can kill at any time.

Please write to dendibakh@gmail.com with any comments & suggestions.

## License

This project is licensed under the terms of the Creative Commons license ([CC BY 4.0](https://creativecommons.org/licenses/by/4.0/)). By contributing to this project, you agree to the copyright terms and release your contribution under these terms.


================================================
FILE: GetStarted.md
================================================
# Get started

## How to set up the environment

Here is the list of tools you *absolutely* have to install to build labs in this video course:
* CMake 3.13
* [Google benchmark](https://github.com/google/benchmark), you can also use the scripts in the [tools](tools) directory.

Others are optional depending on your platform of choice. So far we support native builds on Windows and Linux. Check out the instructions specific to each platform ([Windows](QuickstartWindows.md)) ([Linux](QuickstartLinux.md)) ([MacOS](QuickstartMacOS.md)).

## How to build lab assignments

Watch the warmup video:

[<img src="img/WarmupLabAssignment.png">](https://www.youtube.com/watch?v=jFRwAcIoLgQ&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d)

Every lab assignment has the following:
* Video that introduces a particular transformation.
* Baseline version of a workload that has a particular performance bottleneck in it. You need to find it and fix the source code accordingly.
* Summary video that explains the solution for the lab.

We encourage you to work on the lab assignment first, without watching the summary video.

Every lab can be built and run using the following commands:
```
cmake -E make_directory build
cd build
cmake -DCMAKE_BUILD_TYPE=Release ..
cmake --build . --config Release --parallel 8
cmake --build . --target validateLab
cmake --build . --target benchmarkLab
```
When you push changes to your private branch, it will automatically trigger a CI benchmarking job. More details about it are at the bottom of the page.

## Profiling

To match assembly code back to the source in the profile, build your binaries with the debug information:
```
cmake -DCMAKE_BUILD_TYPE=Release -DCMAKE_C_FLAGS="-g" -DCMAKE_CXX_FLAGS="-g" ..
```

Lab assignments are built on top of the Google Benchmark library, which by default performs a variable number of benchmark iterations. That makes it hard to compare the performance profiles of two runs since they will not do the same amount of work. You can see the same wall time even though the number of iterations is different. To fix the number of iterations, you can make the following changes:

```
  BENCHMARK(bench1)->Iterations(10);
```

This will instruct the Google Benchmark framework to execute exactly 10 iterations of the benchmark. Now when you improve your code you can also compare performance profiles since the wall time will be different.

## Target platforms

You are free to work on whatever platform you have at your disposal. However, we use the following CI machines to run your submissions:

**Machine 1 - (Linux + Alderlake)**

* 12th Gen Intel(R) Core(TM) i7-1260P CPU @ 2.10GHz (4.70GHz Turbo), 4P+8E cores, 18MB L3-cache
* 16 GB RAM, DDR4 @ 3200 MT/s
* 256GB NVMe PCIe M.2 SSD
* Ubuntu 24.04 LTS, kernel version 6.8
* Clang C++ compiler, version 17.0

**Machine 2 - (Mac OS + M1)**

* Mac mini (M1, 2020) @ 3.20GHz max frequency, 4P+4E cores, 8 MB LLC
* 16 GB RAM, LPDDR4
* 256GB NVME APPLE SSD AP0256Q
* macOS 13.5.1 Ventura (22G90)
* Clang C++ compiler, version 17.0

**Machine 3 - (Windows + Zen3)**

* AMD Ryzen 7 3700X 8-Core Processor @ 3.6GHz (4.40GHz Turbo), 32MB L3-cache
* 64 GB RAM
* ADATA XPG SX8200 Pro 1TB 3D NAND NVMe SSD
* Windows 11 Version 21H2, build 22000.282
* Clang C++ compiler, version 17.0

**Machine 4 - (Linux + CoffeeLake)**

* Intel(R) Core(TM) i5-8259U CPU @ 2.30GHz (3.80GHz Turbo), 6MB L3-cache
* 16 GB RAM, DDR4 @ 2400 MT/s
* 256GB NVME INTEL SSDPEKKW256G8
* Ubuntu 20.04, kernel version 5.13
* Clang C++ compiler, version 17.0

Keep in mind that sometimes you may see different speedups on different platforms.

## Local experiments:

Here are a few tips that will help you compare the results of your experiments against the baseline. You can run the baseline version and write down the results, which you will later use to compare with your experiments. But there is a better way to automate this process. You can choose between two options:

1) Use the `compare.py` script, which is a part of the Google benchmark library:

    ```
    # 1. Benchmark the baseline and save the score into a JSON file
    ./lab --benchmark_min_time=1 --benchmark_out_format=json --benchmark_out=baseline.json
    # 2. Change the code
    # 3. Benchmark your solution and save the score into a JSON file
    ./lab --benchmark_min_time=1 --benchmark_out_format=json --benchmark_out=solution.json
    # 4. Compare solution.json against baseline.json
    /path/to/benchmark/tools/compare.py benchmarks baseline.json solution.json
    ```

2) Use the `check_speedup.py` script, which is inside the Performance Ninja repo (uses the `compare.py` script under the hood):

    ```
    # 1. Put your solution under `#ifdef SOLUTION`:
      #ifdef SOLUTION
        // your solution
      #else
        // baseline version
      #endif
    # 2. Run the script, which will build and run your solution against the baseline N times
    cd build
    python3 ~/workspace/perf-ninja/tools/check_speedup.py -lab_path ../ -num_runs 3
    ```

## Submission guidelines:

**IMPORTANT:** Send a request to be added as a collaborator to this Github repo. Otherwise, you won't be able to push your private branch[es]. Send your github handle to dendibakh@gmail.com with the topic "[PerfNinjaAccessRequest]". Do not fork the repo and submit a pull request with your solution, the CI job won't be triggered.

Push your submissions into your own branch[es]. CI job will be triggered every time you push changes to your remote Github branch. For now, we use a self-hosted runner, which is configured specifically for benchmarking purposes.

By default, CI will detect which lab was modified in the last commit and will only benchmark affected assignment. If you make changes to more than one lab, the CI job will benchmark all the labs. You can also force benchmarking all the labs if you add `[CheckAll]` in the commit message.

In case all the labs were benchmarked, a summary will be provided at the end, e.g.:

```
Lab Assignments Summary:
  memory_bound:
    data_packing: Passed
    sequential_accesses: Failed: not fast enough
  core_bound:
    function_inlining: Failed: build error
  misc:
    warmup: Skipped
```



================================================
FILE: QuickstartLinux.md
================================================
## Set up environment on Linux

1. Run terminal.

2. Install clang-17 compiler using instructions from [here](https://apt.llvm.org/):

    ```
    wget https://apt.llvm.org/llvm.sh
    chmod +x llvm.sh
    sudo ./llvm.sh 17 all
    ```

3. Build release version of google [benchmark library](https://github.com/google/benchmark#installation). It doesn't matter which compiler you use to build it. Install google benchmark library with:
    ```
    cmake --build "build" --config Release --target install
    ```

4. Enable clang-17 compiler for building labs. If you want to make clang-17 to be the default on a system do the following:
    ```
    sudo update-alternatives --install /usr/bin/cc cc /usr/bin/clang-17 30
    sudo update-alternatives --install /usr/bin/c++ c++ /usr/bin/clang++-17 30
    ```

    If you don't want to make it a default, you can pass `-DCMAKE_C_COMPILER=clang-17 -DCMAKE_CXX_COMPILER=clang++-17` to the CMake.

5. Go to any lab and check if local lab builds are working. You can find the CMake commands [here](GetStarted.md#how-to-build-lab-assignments). 

6. Set the frequency scaling governor to `performance`.
    ```
    sudo cpupower frequency-set --governor performance
    ```

7. (Optional) Install [ninja](https://github.com/ninja-build).
    
    ```
    $ sudo apt install ninja-build
    ```
    
    You can use it to build labs by passing `-G Ninja` to the CMake invocation.



================================================
FILE: QuickstartMacOS.md
================================================
## Set up environment on Mac OS

**Mac support is still experimental. Submit bugs if you experience issues.**

1. Run terminal.

2. Install homebrew (if haven't already) following instructions from [here](https://brew.sh):

    ```
    /bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"
    echo 'eval "$(/opt/homebrew/bin/brew shellenv)"' >> ~/.zprofile\n
    ```

2. Install clang-17 compiler (make sure that the version is not older than 15, otherwise it will not compile):

    ```
    brew install llvm@17
    export PATH="/opt/homebrew/opt/llvm/bin:$PATH"
    export CC=clang
    export CXX=clang++
    ```

    Consider making environment changes permanent:

    ```
    echo 'export PATH="/opt/homebrew/opt/llvm/bin:$PATH"' >> ~/.zshrc
    echo 'export CC=clang' >> ~/.zshrc
    echo 'export CXX=clang++' >> ~/.zshrc
    ```

5. Build release version of google [benchmark library](https://github.com/google/benchmark#installation). It doesn't matter which compiler you use to build it. Install google benchmark library with:
    
    ```
    git clone https://github.com/google/benchmark.git
    cd benchmark
    git clone https://github.com/google/googletest.git
    mkdir build
    cd build
    cmake -DCMAKE_BUILD_TYPE=Release ..
    cmake --build . --config Release --target install
    ```

6. Go to any lab and check if local lab builds are working. You can find the CMake commands [here](GetStarted.md#how-to-build-lab-assignments). 

7. (Optional) Install [ninja](https://github.com/ninja-build).
    
    ```
    $ brew install ninja
    ```
    
    You can use it to build labs by passing `-G Ninja` to the CMake invocation.



================================================
FILE: QuickstartWindows.md
================================================
## Set up environment on Windows

1. Run powershell.

2. Install [ninja](https://github.com/ninja-build/ninja/releases). 
    
    Add it to the PATH. For example:
    ```
    $ENV:PATH="$ENV:PATH;C:\Program Files\ninja"
    ```
3. Download clang-17 compiler from [here](https://github.com/llvm/llvm-project/releases/tag/llvmorg-17.0.1) (LLVM-17.0.1-win64.exe) and install it. Select "add LLVM to the PATH" while installing.

4. Build release version of google [benchmark library](https://github.com/google/benchmark#installation). It doesn't matter which compiler you use to build it. Install google benchmark library with:
    ```
    cmake --build "build" --config Release --target install
    ```
    Add google benchmark library to PATH
    ```
    $ENV:PATH="$ENV:PATH;C:\Program Files (x86)\benchmark\lib"
    ```
5. Go to any lab and check if local lab builds are working. You can find the CMake commands [here](GetStarted.md#how-to-build-lab-assignments), but note that you need to add `-G Ninja` to the CMake invocation.

6. If everything works as expected, you can set environment variables permanently (run as Administrator):
    ```
    # be carefull, back up your PATH
    setx /M PATH "$($env:path);C:\Program Files\ninja"
    setx /M PATH "$($env:path);C:\Program Files (x86)\benchmark\lib"
    ```


================================================
FILE: .editorconfig
================================================
﻿root = true

[*]
charset = utf-8
tab_width = 2
indent_size = 2
indent_style = space
insert_final_newline = true

[.*]
insert_final_newline = false


================================================
FILE: buildbot/runCI.py
================================================
import sys
import subprocess
import os
import shutil
import argparse
import json
import re
from enum import Enum
from dataclasses import dataclass
import gbench
from gbench import util, report
from gbench.util import *
import statistics

class bcolors:
    HEADER = '\033[95m'
    OKBLUE = '\033[94m'
    OKCYAN = '\033[96m'
    OKGREEN = '\033[92m'
    WARNING = '\033[93m'
    FAIL = '\033[91m'
    ENDC = '\033[0m'
    BOLD = '\033[1m'
    UNDERLINE = '\033[4m'

class ScoreResult(Enum):
    SKIPPED = READY = 0
    BUILD_FAILED = 1
    BENCH_FAILED = 2
    PASSED = 3

@dataclass
class LabParams:
    threshold: float = 10.0
    result: ScoreResult = ScoreResult.SKIPPED

@dataclass
class LabPath:
    category: str
    name: str

parser = argparse.ArgumentParser(description='test results')
parser.add_argument("-workdir", type=str, help="working directory", default="")
parser.add_argument("-runner", type=str, help="CI runner machine", default="LinuxIntelAlderlake")
parser.add_argument("-v", help="verbose", action="store_true", default=False)

args = parser.parse_args()
workdir = args.workdir
runner = args.runner
verbose = args.v

Labs = dict()
Labs["memory_bound"] = dict()
Labs["core_bound"] = dict()
Labs["bad_speculation"] = dict()
Labs["frontend_bound"] = dict()
Labs["data_driven"] = dict()
Labs["misc"] = dict()

if runner == "LinuxIntelAlderlake":
  Labs["memory_bound"]["data_packing"] = LabParams(threshold=40.0)
  Labs["memory_bound"]["false_sharing_1"] = LabParams(threshold=70.0)
  Labs["memory_bound"]["huge_pages_1"] = LabParams(threshold=10.0)
  Labs["memory_bound"]["loop_interchange_1"] = LabParams(threshold=85.0)
  Labs["memory_bound"]["loop_interchange_2"] = LabParams(threshold=75.0)
  Labs["memory_bound"]["loop_tiling_1"] = LabParams(threshold=35.0)
  Labs["memory_bound"]["mem_alignment_1"] = LabParams(threshold=10.0)
  Labs["memory_bound"]["mem_order_violation_1"] = LabParams(threshold=10.0)
  Labs["memory_bound"]["swmem_prefetch_1"] = LabParams(threshold=60.0)
  Labs["misc"]["warmup"] = LabParams(threshold=50.0)
  Labs["misc"]["lto"] = LabParams(threshold=20.0)
  Labs["misc"]["pgo"] = LabParams(threshold=10.0)
  Labs["misc"]["io_opt1"] = LabParams(threshold=70.0)
  Labs["core_bound"]["function_inlining_1"] = LabParams(threshold=25.0)
  Labs["core_bound"]["compiler_intrinsics_1"] = LabParams(threshold=60.0)
  Labs["core_bound"]["compiler_intrinsics_2"] = LabParams(threshold=65.0)
  Labs["core_bound"]["compiler_intrinsics_3"] = LabParams(threshold=30.0)
  Labs["core_bound"]["compiler_intrinsics_4"] = LabParams(threshold=60.0)
  Labs["core_bound"]["dep_chains_1"] = LabParams(threshold=60.0)
  Labs["core_bound"]["dep_chains_2"] = LabParams(threshold=10.0)
  Labs["core_bound"]["vectorization_1"] = LabParams(threshold=80.0)
  Labs["core_bound"]["vectorization_2"] = LabParams(threshold=85.0)
  Labs["bad_speculation"]["branches_to_cmov_1"] = LabParams(threshold=60.0)
  Labs["bad_speculation"]["conditional_store_1"] = LabParams(threshold=70.0)
  Labs["bad_speculation"]["lookup_tables_1"] = LabParams(threshold=80.0)
  Labs["bad_speculation"]["virtual_call_mispredict"] = LabParams(threshold=60.0)
elif runner == "LinuxIntelCoffeelake":
  Labs["memory_bound"]["data_packing"] = LabParams(threshold=40.0)
  Labs["memory_bound"]["false_sharing_1"] = LabParams(threshold=70.0)
  Labs["memory_bound"]["huge_pages_1"] = LabParams(threshold=10.0)
  Labs["memory_bound"]["loop_interchange_1"] = LabParams(threshold=85.0)
  Labs["memory_bound"]["loop_interchange_2"] = LabParams(threshold=75.0)
  Labs["memory_bound"]["loop_tiling_1"] = LabParams(threshold=65.0)
  Labs["memory_bound"]["mem_alignment_1"] = LabParams(threshold=10.0)
  Labs["memory_bound"]["mem_order_violation_1"] = LabParams(threshold=5.0)
  Labs["memory_bound"]["swmem_prefetch_1"] = LabParams(threshold=40.0)
  Labs["misc"]["warmup"] = LabParams(threshold=50.0)
  Labs["misc"]["lto"] = LabParams(threshold=20.0)
  Labs["misc"]["pgo"] = LabParams(threshold=5.0)
  Labs["misc"]["io_opt1"] = LabParams(threshold=70.0)
  Labs["core_bound"]["function_inlining_1"] = LabParams(threshold=25.0)
  Labs["core_bound"]["compiler_intrinsics_1"] = LabParams(threshold=60.0)
  Labs["core_bound"]["compiler_intrinsics_2"] = LabParams(threshold=65.0)
  Labs["core_bound"]["compiler_intrinsics_3"] = LabParams(threshold=30.0)
  Labs["core_bound"]["compiler_intrinsics_4"] = LabParams(threshold=60.0)
  Labs["core_bound"]["dep_chains_1"] = LabParams(threshold=60.0)
  # (It seems it doesn't help Coffelake) Labs["core_bound"]["dep_chains_2"] = LabParams(threshold=10.0)
  Labs["core_bound"]["vectorization_1"] = LabParams(threshold=75.0)
  Labs["core_bound"]["vectorization_2"] = LabParams(threshold=85.0)
  Labs["bad_speculation"]["branches_to_cmov_1"] = LabParams(threshold=60.0)
  Labs["bad_speculation"]["conditional_store_1"] = LabParams(threshold=70.0)
  Labs["bad_speculation"]["lookup_tables_1"] = LabParams(threshold=80.0)
  Labs["bad_speculation"]["virtual_call_mispredict"] = LabParams(threshold=40.0)  
elif runner == "WinZen3":
  Labs["memory_bound"]["data_packing"] = LabParams(threshold=40.0)
  Labs["memory_bound"]["false_sharing_1"] = LabParams(threshold=60.0)
  Labs["memory_bound"]["huge_pages_1"] = LabParams(threshold=50.0)
  Labs["memory_bound"]["loop_interchange_1"] = LabParams(threshold=85.0)
  Labs["memory_bound"]["loop_interchange_2"] = LabParams(threshold=75.0)
  Labs["memory_bound"]["loop_tiling_1"] = LabParams(threshold=35.0)
  Labs["memory_bound"]["mem_alignment_1"] = LabParams(threshold=5.0)
  Labs["memory_bound"]["mem_order_violation_1"] = LabParams(threshold=25.0)
  Labs["memory_bound"]["swmem_prefetch_1"] = LabParams(threshold=40.0)
  Labs["misc"]["warmup"] = LabParams(threshold=50.0)
  Labs["misc"]["lto"] = LabParams(threshold=20.0)
  Labs["misc"]["pgo"] = LabParams(threshold=10.0)
  Labs["misc"]["io_opt1"] = LabParams(threshold=70.0)  
  Labs["core_bound"]["function_inlining_1"] = LabParams(threshold=25.0)
  Labs["core_bound"]["compiler_intrinsics_1"] = LabParams(threshold=60.0)
  Labs["core_bound"]["compiler_intrinsics_2"] = LabParams(threshold=60.0)
  Labs["core_bound"]["compiler_intrinsics_3"] = LabParams(threshold=40.0)
  Labs["core_bound"]["compiler_intrinsics_4"] = LabParams(threshold=60.0)
  Labs["core_bound"]["dep_chains_1"] = LabParams(threshold=60.0)  
  Labs["core_bound"]["dep_chains_2"] = LabParams(threshold=10.0)
  Labs["core_bound"]["vectorization_1"] = LabParams(threshold=70.0)
  Labs["core_bound"]["vectorization_2"] = LabParams(threshold=85.0)
  Labs["bad_speculation"]["branches_to_cmov_1"] = LabParams(threshold=60.0)
  Labs["bad_speculation"]["conditional_store_1"] = LabParams(threshold=70.0)
  Labs["bad_speculation"]["lookup_tables_1"] = LabParams(threshold=80.0)
  Labs["bad_speculation"]["virtual_call_mispredict"] = LabParams(threshold=40.0)
elif runner == "MacosM1":
  Labs["memory_bound"]["data_packing"] = LabParams(threshold=40.0)
  Labs["memory_bound"]["false_sharing_1"] = LabParams(threshold=70.0)
  # FIXME: Labs["memory_bound"]["huge_pages_1"] = LabParams(threshold=10.0)
  Labs["memory_bound"]["loop_interchange_1"] = LabParams(threshold=85.0)
  Labs["memory_bound"]["loop_interchange_2"] = LabParams(threshold=75.0)
  Labs["memory_bound"]["loop_tiling_1"] = LabParams(threshold=25.0)
  Labs["memory_bound"]["mem_alignment_1"] = LabParams(threshold=10.0)
  Labs["memory_bound"]["mem_order_violation_1"] = LabParams(threshold=40.0)
  Labs["memory_bound"]["swmem_prefetch_1"] = LabParams(threshold=50.0)
  Labs["misc"]["warmup"] = LabParams(threshold=50.0)
  Labs["misc"]["lto"] = LabParams(threshold=10.0)
  Labs["misc"]["pgo"] = LabParams(threshold=10.0)
  # FIXME: Labs["misc"]["io_opt1"] = LabParams(threshold=70.0)
  Labs["core_bound"]["function_inlining_1"] = LabParams(threshold=25.0)
  Labs["core_bound"]["compiler_intrinsics_1"] = LabParams(threshold=60.0)
  # FIXME: Labs["core_bound"]["compiler_intrinsics_2"] = LabParams(threshold=65.0)
  Labs["core_bound"]["compiler_intrinsics_3"] = LabParams(threshold=15.0)
  Labs["core_bound"]["compiler_intrinsics_4"] = LabParams(threshold=40.0)
  Labs["core_bound"]["dep_chains_1"] = LabParams(threshold=60.0)
  Labs["core_bound"]["dep_chains_2"] = LabParams(threshold=40.0)
  Labs["core_bound"]["vectorization_1"] = LabParams(threshold=80.0)
  Labs["core_bound"]["vectorization_2"] = LabParams(threshold=85.0)
  Labs["bad_speculation"]["branches_to_cmov_1"] = LabParams(threshold=60.0)
  Labs["bad_speculation"]["conditional_store_1"] = LabParams(threshold=70.0)
  Labs["bad_speculation"]["lookup_tables_1"] = LabParams(threshold=70.0)
  Labs["bad_speculation"]["virtual_call_mispredict"] = LabParams(threshold=60.0)

def getLabCurrentStatus(labPath):
  return Labs[labPath.category][labPath.name].result

def setLabCurrentStatus(labPath, status):
  Labs[labPath.category][labPath.name].result = status
  return True

def getLabThreshold(labPath):
  return Labs[labPath.category][labPath.name].threshold

def getLabNameStr(labPath):
  return labPath.category + ":" + labPath.name

def buildAndValidate(labBuildDir):
  try:
    subprocess.check_call("cmake -E make_directory " + labBuildDir, shell=True)
    print("Prepare build directory - OK")
  except:
    print(bcolors.FAIL + "Prepare build directory - Failed" + bcolors.ENDC)
    return False

  os.chdir(labBuildDir)

  try:
    if sys.platform != 'win32':
      subprocess.check_call("cmake -DCMAKE_BUILD_TYPE=Release -DCI=ON " + os.path.join(labBuildDir, ".."), shell=True)
    else:
      subprocess.check_call("cmake -G Ninja -DCMAKE_CXX_COMPILER=clang++ -DCMAKE_C_COMPILER=clang -DCMAKE_BUILD_TYPE=Release -DCI=ON " + os.path.join(labBuildDir, ".."), shell=True)
    print("CMake - OK")
  except:
    print(bcolors.FAIL + "CMake - Failed" + bcolors.ENDC)
    return False

  try:
    subprocess.check_call("cmake --build . --config Release --target clean", shell=True)
    subprocess.check_call("cmake --build . --config Release --parallel 8", shell=True)
    print("Build - OK")
  except:
    print(bcolors.FAIL + "Build - Failed" + bcolors.ENDC)
    return False

  try:
    subprocess.check_call("cmake --build . --config Release --target validateLab", shell=True)
    print("Validation - OK")
  except:
    print(bcolors.FAIL + "Validation - Failed" + bcolors.ENDC)
    return False

  return True

def buildLab(labDir, solutionOrBaseline):
  os.chdir(labDir)
  buildDir = os.path.join(labDir, "build_" + solutionOrBaseline)
  print("Build and Validate the " + solutionOrBaseline)
  if not buildAndValidate(buildDir):
    return False

  return True

def noChangesToTheBaseline(labDir):
  solutionDir = os.path.join(labDir, "build_solution")
  baselineDir = os.path.join(labDir, "build_baseline")
  if sys.platform != 'win32':
    solutionExe = os.path.join(solutionDir, "lab")
    baselineExe = os.path.join(baselineDir, "lab")
    exit_code = subprocess.call("cmp " + solutionExe + " " + baselineExe, shell=True)
  else:
    # This is the ugly way of comparing whether binaries are similar on Windows.
    # We disassemble both binaries and compare textual output.
    solutionExe = os.path.join(solutionDir, "lab.exe")
    solutionDisasm = os.path.join(solutionDir, "lab.disasm")
    baselineExe = os.path.join(baselineDir, "lab.exe")
    baselineDisasm = os.path.join(baselineDir, "lab.disasm")
    subprocess.call("llvm-objdump.exe -d " + solutionExe + " >" + solutionDisasm, shell=True)
    subprocess.call("llvm-objdump.exe -d " + baselineExe + " >" + baselineDisasm, shell=True)
    subprocess.call("powershell -Command \"((Get-Content -path " + baselineDisasm + " -Raw) -replace 'baseline','') | Set-Content -Path " + baselineDisasm + "\"", shell=True)
    subprocess.call("powershell -Command \"((Get-Content -path " + solutionDisasm + " -Raw) -replace 'solution','') | Set-Content -Path " + solutionDisasm + "\"", shell=True)
    exit_code = subprocess.call("fc >NUL " + solutionDisasm + " " + baselineDisasm, shell=True)
  return exit_code == 0

def checkoutBaseline(workdir):
  os.chdir(workdir)

  try:
    # Branch 'main' is always the baseline
    subprocess.check_call("git checkout main", shell=True)
    print("Checkout baseline - OK")
  except:
    print(bcolors.FAIL + "Checkout baseline - Failed" + bcolors.ENDC)
    return False

  return True

def getSpeedUp(jsonMeasurement):
  old = jsonMeasurement['real_time']
  new = jsonMeasurement['real_time_other']
  diff = old - new
  speedup = (diff / old ) * 100
  return speedup

# We can implement other aggregating function if average
# doesn't work for some scenarios.
# It can be customized depending on a lab.
def getAverageSpeedup(diff_report):
  speedups = []
  for benchmark in diff_report:
    speedups.append(getSpeedUp(benchmark['measurements'][0]))
  return statistics.mean(speedups)

def benchmarkSolutionOrBaseline(labBuildDir, solutionOrBaseline):
  #os.chdir(labBuildDir)
  try:
    subprocess.check_call("cmake --build " + labBuildDir + " --config Release --target benchmarkLab", shell=True)
    print("Benchmarking " + solutionOrBaseline + " - OK")
  except:
    print(bcolors.FAIL + "Benchmarking " + solutionOrBaseline + " - Failed" + bcolors.ENDC)
    return False

  return True

def benchmarkLab(labPath):

  print("Benchmark solution against the baseline")

  labDir = os.path.join(workdir, labPath.category, labPath.name)

  solutionDir = os.path.join(labDir, "build_solution")
  baselineDir = os.path.join(labDir, "build_baseline")

  benchmarkSolutionOrBaseline(solutionDir, "solution")
  benchmarkSolutionOrBaseline(baselineDir, "baseline")

  try:
    outJsonSolution = gbench.util.load_benchmark_results(os.path.join(solutionDir, "result.json"))
  except JSONDecodeError:
    print (bcolors.FAIL + "Error while loading solution's result.json file. Submission for the lab " + getLabNameStr(labPath) + " failed." + bcolors.ENDC)
    return False 
  try:
    outJsonBaseline = gbench.util.load_benchmark_results(os.path.join(baselineDir, "result.json"))
  except JSONDecodeError:
    print (bcolors.FAIL + "Error while loading baseline's result.json file. Submission for the lab " + getLabNameStr(labPath) + " failed." + bcolors.ENDC)
    return False 

  # Parse two report files and compare them
  diff_report = gbench.report.get_difference_report(
    outJsonBaseline, outJsonSolution, True)
  output_lines = gbench.report.print_difference_report(
    diff_report,
    False, True, 0.05, True)
  for ln in output_lines:
    print(ln)

  speedup = getAverageSpeedup(diff_report)
  if abs(speedup) < 2.0:
    print (bcolors.FAIL + "New version has performance similar to the baseline (<2% difference). Submission for the lab " + getLabNameStr(labPath) + " failed." + bcolors.ENDC)
    return False
  if speedup < 0:
    print (bcolors.FAIL + "New version is slower. Submission for the lab " + getLabNameStr(labPath) + " failed." + bcolors.ENDC)
    return False

  if (speedup < getLabThreshold(labPath)):
    print (bcolors.FAIL + "Submission for the lab " + getLabNameStr(labPath) + " failed. New version is not fast enough." + bcolors.ENDC)
    print ("Measured speedup:", "{:.2f}".format(speedup), "%")
    print ("Pass threshold:", "{:.2f}".format(getLabThreshold(labPath)), "%")
    return False

  print ("Measured speedup:", "{:.2f}".format(speedup), "%")
  print (bcolors.OKGREEN + "Submission for the lab " + getLabNameStr(labPath) + " succeded" + bcolors.ENDC)
  return True

def runActionForAllLabs(workdir, func):
  for labCategory in os.listdir(workdir):
    if labCategory in Labs:
      categoryDir = os.path.join(workdir, labCategory)
      for labName in os.listdir(categoryDir):
        if labName in Labs[labCategory]:
          labPath = LabPath(labCategory, labName)
          if (getLabCurrentStatus(labPath) == ScoreResult.READY):
            func(labPath)

def buildSolutionAction(labPath):
  labWorkDir = os.path.join(workdir, labPath.category, labPath.name)
  if not buildLab(labWorkDir, "solution"):
    setLabCurrentStatus(labPath, ScoreResult.BUILD_FAILED)

def buildBaselineAction(labPath):
  labWorkDir = os.path.join(workdir, labPath.category, labPath.name)
  if not buildLab(labWorkDir, "baseline"):
    setLabCurrentStatus(labPath, ScoreResult.BUILD_FAILED)

def benchmarkAction(labPath):
  labWorkDir = os.path.join(workdir, labPath.category, labPath.name)
  if noChangesToTheBaseline(labWorkDir):
    setLabCurrentStatus(labPath, ScoreResult.SKIPPED)
  elif not benchmarkLab(labPath):
    setLabCurrentStatus(labPath, ScoreResult.BENCH_FAILED)
  else:
    setLabCurrentStatus(labPath, ScoreResult.PASSED)

def checkAllLabs(workdir):
  runActionForAllLabs(workdir, buildSolutionAction)
  if not checkoutBaseline(workdir):
    return False
  runActionForAllLabs(workdir, buildBaselineAction)
  runActionForAllLabs(workdir, benchmarkAction)

  return True

def changedMultipleLabs(lines):
  percent1, path1 = lines[1].split(b'%')
  GitShowLabPath1 = DirLabPathRegex.search(str(path1))
  if (GitShowLabPath1):
    for i in range(2, len(lines)):
      if len(lines[i]) == 0:
        continue
      percent_i, path_i = lines[i].split(b'%')
      GitShowLabPath_i = DirLabPathRegex.search(str(path_i))
      if (GitShowLabPath_i):
        if GitShowLabPath1.group(1) != GitShowLabPath_i.group(1) or GitShowLabPath1.group(2) != GitShowLabPath_i.group(2):
          return True
  return False

if not workdir:
  print ("Error: working directory is not provided.")
  sys.exit(1)

os.chdir(workdir)

checkAll = False
benchLabPath = ""
DirLabPathRegex = re.compile(r'labs/([a-zA-Z0-9-_]+?)/([a-zA-Z0-9-_]+?)/(.*)')

try:
  outputGitLog = subprocess.check_output("git log -1 --oneline" , shell=True)
  # If the commit message has '[CheckAll]' substring, benchmark everything
  if b'[CheckAll]' in outputGitLog:
    checkAll = True
    print("Will benchmark all the labs")
  # Otherwise, analyze the changes made in the last commit and identify which lab to benchmark
  else:
    outputGitShow = subprocess.check_output("git show -1 --dirstat --oneline" , shell=True)
    lines = outputGitShow.split(b'\n')
    # Expect at least 2 lines in the output
    if (len(lines) < 2 or len(lines[1]) == 0):
      print("Can't figure out which lab was changed in the last commit. Will benchmark all the labs.")
      checkAll = True
    elif changedMultipleLabs(lines):
      print("Multiple labs changed. Will benchmark all the labs.")
      checkAll = True
    else:
      # Skip the first line that has the commit hash and message
      percent, path = lines[1].split(b'%')
      GitShowLabPath = DirLabPathRegex.search(str(path))
      if (GitShowLabPath):
        benchLabPath = LabPath(GitShowLabPath.group(1), GitShowLabPath.group(2))
        print("Will benchmark the lab: " + getLabNameStr(benchLabPath))
      else:
        print("Can't figure out which lab was changed in the last commit. Will benchmark all the labs.")
        checkAll = True
except:
  print("Error: can't fetch the last commit from git history")
  sys.exit(1)

result = False
if checkAll:
  if not checkAllLabs(workdir):
    sys.exit(1)
  print(bcolors.HEADER + "\nLab Assignments Summary:" + bcolors.ENDC)
  allSkipped = True
  for category in Labs:
    print(bcolors.HEADER + "  " + category + ":" + bcolors.ENDC)
    for lab in Labs[category]:
      if ScoreResult.SKIPPED == Labs[category][lab].result:
        print(bcolors.OKCYAN + "    " + lab + ": Skipped" + bcolors.ENDC)
      else:
        allSkipped = False
      if ScoreResult.PASSED == Labs[category][lab].result:
        print(bcolors.OKGREEN + "    " + lab + ": Passed" + bcolors.ENDC)
        # Return true if at least one lab succeeded
        result = True
      if ScoreResult.BENCH_FAILED == Labs[category][lab].result:
        print(bcolors.FAIL + "    " + lab + ": Failed: not fast enough" + bcolors.ENDC)
      if ScoreResult.BUILD_FAILED == Labs[category][lab].result:
        print(bcolors.FAIL + "    " + lab + ": Failed: build error" + bcolors.ENDC)
  if allSkipped:
    result = True
else:
  labdir = os.path.join(workdir, benchLabPath.category, benchLabPath.name)
  if not buildLab(labdir, "solution"):
    sys.exit(1)
  if not checkoutBaseline(workdir):
    sys.exit(1)
  if not buildLab(labdir, "baseline"):
    sys.exit(1)
  if noChangesToTheBaseline(labdir):
    print(bcolors.OKCYAN + "The solution and the baseline are identical. Skipped." + bcolors.ENDC)
    result = True
  else:
    result = benchmarkLab(benchLabPath)

if not result:
  sys.exit(1)
else:
  sys.exit(0)



================================================
FILE: buildbot/gbench/__init__.py
================================================
"""Google Benchmark tooling"""

__author__ = 'Eric Fiselier'
__email__ = 'eric@efcs.ca'
__versioninfo__ = (0, 5, 0)
__version__ = '.'.join(str(v) for v in __versioninfo__) + 'dev'

__all__ = []



================================================
FILE: buildbot/gbench/report.py
================================================
import unittest
"""report.py - Utilities for reporting statistics about benchmark results
"""
import os
import re
import copy

from scipy.stats import mannwhitneyu


class BenchmarkColor(object):
    def __init__(self, name, code):
        self.name = name
        self.code = code

    def __repr__(self):
        return '%s%r' % (self.__class__.__name__,
                         (self.name, self.code))

    def __format__(self, format):
        return self.code


# Benchmark Colors Enumeration
BC_NONE = BenchmarkColor('NONE', '')
BC_MAGENTA = BenchmarkColor('MAGENTA', '\033[95m')
BC_CYAN = BenchmarkColor('CYAN', '\033[96m')
BC_OKBLUE = BenchmarkColor('OKBLUE', '\033[94m')
BC_OKGREEN = BenchmarkColor('OKGREEN', '\033[32m')
BC_HEADER = BenchmarkColor('HEADER', '\033[92m')
BC_WARNING = BenchmarkColor('WARNING', '\033[93m')
BC_WHITE = BenchmarkColor('WHITE', '\033[97m')
BC_FAIL = BenchmarkColor('FAIL', '\033[91m')
BC_ENDC = BenchmarkColor('ENDC', '\033[0m')
BC_BOLD = BenchmarkColor('BOLD', '\033[1m')
BC_UNDERLINE = BenchmarkColor('UNDERLINE', '\033[4m')

UTEST_MIN_REPETITIONS = 2
UTEST_OPTIMAL_REPETITIONS = 9  # Lowest reasonable number, More is better.
UTEST_COL_NAME = "_pvalue"


def color_format(use_color, fmt_str, *args, **kwargs):
    """
    Return the result of 'fmt_str.format(*args, **kwargs)' after transforming
    'args' and 'kwargs' according to the value of 'use_color'. If 'use_color'
    is False then all color codes in 'args' and 'kwargs' are replaced with
    the empty string.
    """
    assert use_color is True or use_color is False
    if not use_color:
        args = [arg if not isinstance(arg, BenchmarkColor) else BC_NONE
                for arg in args]
        kwargs = {key: arg if not isinstance(arg, BenchmarkColor) else BC_NONE
                  for key, arg in kwargs.items()}
    return fmt_str.format(*args, **kwargs)


def find_longest_name(benchmark_list):
    """
    Return the length of the longest benchmark name in a given list of
    benchmark JSON objects
    """
    longest_name = 1
    for bc in benchmark_list:
        if len(bc['name']) > longest_name:
            longest_name = len(bc['name'])
    return longest_name


def calculate_change(old_val, new_val):
    """
    Return a float representing the decimal change between old_val and new_val.
    """
    if old_val == 0 and new_val == 0:
        return 0.0
    if old_val == 0:
        return float(new_val - old_val) / (float(old_val + new_val) / 2)
    return float(new_val - old_val) / abs(old_val)


def filter_benchmark(json_orig, family, replacement=""):
    """
    Apply a filter to the json, and only leave the 'family' of benchmarks.
    """
    regex = re.compile(family)
    filtered = {}
    filtered['benchmarks'] = []
    for be in json_orig['benchmarks']:
        if not regex.search(be['name']):
            continue
        filteredbench = copy.deepcopy(be)  # Do NOT modify the old name!
        filteredbench['name'] = regex.sub(replacement, filteredbench['name'])
        filtered['benchmarks'].append(filteredbench)
    return filtered


def get_unique_benchmark_names(json):
    """
    While *keeping* the order, give all the unique 'names' used for benchmarks.
    """
    seen = set()
    uniqued = [x['name'] for x in json['benchmarks']
               if x['name'] not in seen and
               (seen.add(x['name']) or True)]
    return uniqued


def intersect(list1, list2):
    """
    Given two lists, get a new list consisting of the elements only contained
    in *both of the input lists*, while preserving the ordering.
    """
    return [x for x in list1 if x in list2]


def is_potentially_comparable_benchmark(x):
    return ('time_unit' in x and 'real_time' in x and 'cpu_time' in x)


def partition_benchmarks(json1, json2):
    """
    While preserving the ordering, find benchmarks with the same names in
    both of the inputs, and group them.
    (i.e. partition/filter into groups with common name)
    """
    json1_unique_names = get_unique_benchmark_names(json1)
    json2_unique_names = get_unique_benchmark_names(json2)
    names = intersect(json1_unique_names, json2_unique_names)
    partitions = []
    for name in names:
        time_unit = None
        # Pick the time unit from the first entry of the lhs benchmark.
        # We should be careful not to crash with unexpected input.
        for x in json1['benchmarks']:
            if (x['name'] == name and is_potentially_comparable_benchmark(x)):
                time_unit = x['time_unit']
                break
        if time_unit is None:
            continue
        # Filter by name and time unit.
        # All the repetitions are assumed to be comparable.
        lhs = [x for x in json1['benchmarks'] if x['name'] == name and
               x['time_unit'] == time_unit]
        rhs = [x for x in json2['benchmarks'] if x['name'] == name and
               x['time_unit'] == time_unit]
        partitions.append([lhs, rhs])
    return partitions


def extract_field(partition, field_name):
    # The count of elements may be different. We want *all* of them.
    lhs = [x[field_name] for x in partition[0]]
    rhs = [x[field_name] for x in partition[1]]
    return [lhs, rhs]


def calc_utest(timings_cpu, timings_time):
    min_rep_cnt = min(len(timings_time[0]),
                      len(timings_time[1]),
                      len(timings_cpu[0]),
                      len(timings_cpu[1]))

    # Does *everything* has at least UTEST_MIN_REPETITIONS repetitions?
    if min_rep_cnt < UTEST_MIN_REPETITIONS:
        return False, None, None

    time_pvalue = mannwhitneyu(
        timings_time[0], timings_time[1], alternative='two-sided').pvalue
    cpu_pvalue = mannwhitneyu(
        timings_cpu[0], timings_cpu[1], alternative='two-sided').pvalue

    return (min_rep_cnt >= UTEST_OPTIMAL_REPETITIONS), cpu_pvalue, time_pvalue

def print_utest(bc_name, utest, utest_alpha, first_col_width, use_color=True):
    def get_utest_color(pval):
        return BC_FAIL if pval >= utest_alpha else BC_OKGREEN

    # Check if we failed miserably with minimum required repetitions for utest
    if not utest['have_optimal_repetitions'] and utest['cpu_pvalue'] is None and utest['time_pvalue'] is None:
        return []

    dsc = "U Test, Repetitions: {} vs {}".format(
        utest['nr_of_repetitions'], utest['nr_of_repetitions_other'])
    dsc_color = BC_OKGREEN

    # We still got some results to show but issue a warning about it.
    if not utest['have_optimal_repetitions']:
        dsc_color = BC_WARNING
        dsc += ". WARNING: Results unreliable! {}+ repetitions recommended.".format(
            UTEST_OPTIMAL_REPETITIONS)

    special_str = "{}{:<{}s}{endc}{}{:16.4f}{endc}{}{:16.4f}{endc}{}      {}"

    return [color_format(use_color,
                         special_str,
                         BC_HEADER,
                         "{}{}".format(bc_name, UTEST_COL_NAME),
                         first_col_width,
                         get_utest_color(
                             utest['time_pvalue']), utest['time_pvalue'],
                         get_utest_color(
                             utest['cpu_pvalue']), utest['cpu_pvalue'],
                         dsc_color, dsc,
                         endc=BC_ENDC)]


def get_difference_report(
        json1,
        json2,
        utest=False):
    """
    Calculate and report the difference between each test of two benchmarks
    runs specified as 'json1' and 'json2'. Output is another json containing
    relevant details for each test run.
    """
    assert utest is True or utest is False

    diff_report = []
    partitions = partition_benchmarks(json1, json2)
    for partition in partitions:
        benchmark_name = partition[0][0]['name']
        time_unit = partition[0][0]['time_unit']
        measurements = []
        utest_results = {}
        # Careful, we may have different repetition count.
        for i in range(min(len(partition[0]), len(partition[1]))):
            bn = partition[0][i]
            other_bench = partition[1][i]
            measurements.append({
                'real_time': bn['real_time'],
                'cpu_time': bn['cpu_time'],
                'real_time_other': other_bench['real_time'],
                'cpu_time_other': other_bench['cpu_time'],
                'time': calculate_change(bn['real_time'], other_bench['real_time']),
                'cpu': calculate_change(bn['cpu_time'], other_bench['cpu_time'])
            })

        # After processing the whole partition, if requested, do the U test.
        if utest:
            timings_cpu = extract_field(partition, 'cpu_time')
            timings_time = extract_field(partition, 'real_time')
            have_optimal_repetitions, cpu_pvalue, time_pvalue = calc_utest(timings_cpu, timings_time)
            if cpu_pvalue and time_pvalue:
                utest_results = {
                    'have_optimal_repetitions': have_optimal_repetitions,
                    'cpu_pvalue': cpu_pvalue,
                    'time_pvalue': time_pvalue,
                    'nr_of_repetitions': len(timings_cpu[0]),
                    'nr_of_repetitions_other': len(timings_cpu[1])
                }

        # Store only if we had any measurements for given benchmark.
        # E.g. partition_benchmarks will filter out the benchmarks having
        # time units which are not compatible with other time units in the
        # benchmark suite.
        if measurements:
            run_type = partition[0][0]['run_type'] if 'run_type' in partition[0][0] else ''
            aggregate_name = partition[0][0]['aggregate_name'] if run_type == 'aggregate' and 'aggregate_name' in partition[0][0] else ''
            diff_report.append({
                'name': benchmark_name,
                'measurements': measurements,
                'time_unit': time_unit,
                'run_type': run_type,
                'aggregate_name': aggregate_name,
                'utest': utest_results
            })

    return diff_report


def print_difference_report(
        json_diff_report,
        include_aggregates_only=False,
        utest=False,
        utest_alpha=0.05,
        use_color=True):
    """
    Calculate and report the difference between each test of two benchmarks
    runs specified as 'json1' and 'json2'.
    """
    assert utest is True or utest is False

    def get_color(res):
        if res > 0.05:
            return BC_FAIL
        elif res > -0.07:
            return BC_WHITE
        else:
            return BC_CYAN

    first_col_width = find_longest_name(json_diff_report)
    first_col_width = max(
        first_col_width,
        len('Benchmark'))
    first_col_width += len(UTEST_COL_NAME)
    first_line = "{:<{}s}Time             CPU      Time Old      Time New       CPU Old       CPU New".format(
        'Benchmark', 12 + first_col_width)
    output_strs = [first_line, '-' * len(first_line)]

    fmt_str = "{}{:<{}s}{endc}{}{:+16.4f}{endc}{}{:+16.4f}{endc}{:14.0f}{:14.0f}{endc}{:14.0f}{:14.0f}"
    for benchmark in json_diff_report:
        # *If* we were asked to only include aggregates,
        # and if it is non-aggregate, then skip it.
        if include_aggregates_only and 'run_type' in benchmark:
            if benchmark['run_type'] != 'aggregate':
                continue

        for measurement in benchmark['measurements']:
            output_strs += [color_format(use_color,
                                         fmt_str,
                                         BC_HEADER,
                                         benchmark['name'],
                                         first_col_width,
                                         get_color(measurement['time']),
                                         measurement['time'],
                                         get_color(measurement['cpu']),
                                         measurement['cpu'],
                                         measurement['real_time'],
                                         measurement['real_time_other'],
                                         measurement['cpu_time'],
                                         measurement['cpu_time_other'],
                                         endc=BC_ENDC)]

        # After processing the measurements, if requested and
        # if applicable (e.g. u-test exists for given benchmark),
        # print the U test.
        if utest and benchmark['utest']:
            output_strs += print_utest(benchmark['name'],
                                       benchmark['utest'],
                                       utest_alpha=utest_alpha,
                                       first_col_width=first_col_width,
                                       use_color=use_color)

    return output_strs


###############################################################################
# Unit tests


class TestGetUniqueBenchmarkNames(unittest.TestCase):
    def load_results(self):
        import json
        testInputs = os.path.join(
            os.path.dirname(
                os.path.realpath(__file__)),
            'Inputs')
        testOutput = os.path.join(testInputs, 'test3_run0.json')
        with open(testOutput, 'r') as f:
            json = json.load(f)
        return json

    def test_basic(self):
        expect_lines = [
            'BM_One',
            'BM_Two',
            'short',  # These two are not sorted
            'medium',  # These two are not sorted
        ]
        json = self.load_results()
        output_lines = get_unique_benchmark_names(json)
        print("\n")
        print("\n".join(output_lines))
        self.assertEqual(len(output_lines), len(expect_lines))
        for i in range(0, len(output_lines)):
            self.assertEqual(expect_lines[i], output_lines[i])


class TestReportDifference(unittest.TestCase):
    @classmethod
    def setUpClass(cls):
        def load_results():
            import json
            testInputs = os.path.join(
                os.path.dirname(
                    os.path.realpath(__file__)),
                'Inputs')
            testOutput1 = os.path.join(testInputs, 'test1_run1.json')
            testOutput2 = os.path.join(testInputs, 'test1_run2.json')
            with open(testOutput1, 'r') as f:
                json1 = json.load(f)
            with open(testOutput2, 'r') as f:
                json2 = json.load(f)
            return json1, json2

        json1, json2 = load_results()
        cls.json_diff_report = get_difference_report(json1, json2)

    def test_json_diff_report_pretty_printing(self):
        expect_lines = [
            ['BM_SameTimes', '+0.0000', '+0.0000', '10', '10', '10', '10'],
            ['BM_2xFaster', '-0.5000', '-0.5000', '50', '25', '50', '25'],
            ['BM_2xSlower', '+1.0000', '+1.0000', '50', '100', '50', '100'],
            ['BM_1PercentFaster', '-0.0100', '-0.0100', '100', '99', '100', '99'],
            ['BM_1PercentSlower', '+0.0100', '+0.0100', '100', '101', '100', '101'],
            ['BM_10PercentFaster', '-0.1000', '-0.1000', '100', '90', '100', '90'],
            ['BM_10PercentSlower', '+0.1000', '+0.1000', '100', '110', '100', '110'],
            ['BM_100xSlower', '+99.0000', '+99.0000',
                '100', '10000', '100', '10000'],
            ['BM_100xFaster', '-0.9900', '-0.9900',
                '10000', '100', '10000', '100'],
            ['BM_10PercentCPUToTime', '+0.1000',
                '-0.1000', '100', '110', '100', '90'],
            ['BM_ThirdFaster', '-0.3333', '-0.3334', '100', '67', '100', '67'],
            ['BM_NotBadTimeUnit', '-0.9000', '+0.2000', '0', '0', '0', '1'],
        ]
        output_lines_with_header = print_difference_report(
            self.json_diff_report, use_color=False)
        output_lines = output_lines_with_header[2:]
        print("\n")
        print("\n".join(output_lines_with_header))
        self.assertEqual(len(output_lines), len(expect_lines))
        for i in range(0, len(output_lines)):
            parts = [x for x in output_lines[i].split(' ') if x]
            self.assertEqual(len(parts), 7)
            self.assertEqual(expect_lines[i], parts)

    def test_json_diff_report_output(self):
        expected_output = [
            {
                'name': 'BM_SameTimes',
                'measurements': [{'time': 0.0000, 'cpu': 0.0000, 'real_time': 10, 'real_time_other': 10, 'cpu_time': 10, 'cpu_time_other': 10}],
                'time_unit': 'ns',
                'utest': {}
            },
            {
                'name': 'BM_2xFaster',
                'measurements': [{'time': -0.5000, 'cpu': -0.5000, 'real_time': 50, 'real_time_other': 25, 'cpu_time': 50, 'cpu_time_other': 25}],
                'time_unit': 'ns',
                'utest': {}
            },
            {
                'name': 'BM_2xSlower',
                'measurements': [{'time': 1.0000, 'cpu': 1.0000, 'real_time': 50, 'real_time_other': 100, 'cpu_time': 50, 'cpu_time_other': 100}],
                'time_unit': 'ns',
                'utest': {}
            },
            {
                'name': 'BM_1PercentFaster',
                'measurements': [{'time': -0.0100, 'cpu': -0.0100, 'real_time': 100, 'real_time_other': 98.9999999, 'cpu_time': 100, 'cpu_time_other': 98.9999999}],
                'time_unit': 'ns',
                'utest': {}
            },
            {
                'name': 'BM_1PercentSlower',
                'measurements': [{'time': 0.0100, 'cpu': 0.0100, 'real_time': 100, 'real_time_other': 101, 'cpu_time': 100, 'cpu_time_other': 101}],
                'time_unit': 'ns',
                'utest': {}
            },
            {
                'name': 'BM_10PercentFaster',
                'measurements': [{'time': -0.1000, 'cpu': -0.1000, 'real_time': 100, 'real_time_other': 90, 'cpu_time': 100, 'cpu_time_other': 90}],
                'time_unit': 'ns',
                'utest': {}
            },
            {
                'name': 'BM_10PercentSlower',
                'measurements': [{'time': 0.1000, 'cpu': 0.1000, 'real_time': 100, 'real_time_other': 110, 'cpu_time': 100, 'cpu_time_other': 110}],
                'time_unit': 'ns',
                'utest': {}
            },
            {
                'name': 'BM_100xSlower',
                'measurements': [{'time': 99.0000, 'cpu': 99.0000, 'real_time': 100, 'real_time_other': 10000, 'cpu_time': 100, 'cpu_time_other': 10000}],
                'time_unit': 'ns',
                'utest': {}
            },
            {
                'name': 'BM_100xFaster',
                'measurements': [{'time': -0.9900, 'cpu': -0.9900, 'real_time': 10000, 'real_time_other': 100, 'cpu_time': 10000, 'cpu_time_other': 100}],
                'time_unit': 'ns',
                'utest': {}
            },
            {
                'name': 'BM_10PercentCPUToTime',
                'measurements': [{'time': 0.1000, 'cpu': -0.1000, 'real_time': 100, 'real_time_other': 110, 'cpu_time': 100, 'cpu_time_other': 90}],
                'time_unit': 'ns',
                'utest': {}
            },
            {
                'name': 'BM_ThirdFaster',
                'measurements': [{'time': -0.3333, 'cpu': -0.3334, 'real_time': 100, 'real_time_other': 67, 'cpu_time': 100, 'cpu_time_other': 67}],
                'time_unit': 'ns',
                'utest': {}
            },
            {
                'name': 'BM_NotBadTimeUnit',
                'measurements': [{'time': -0.9000, 'cpu': 0.2000, 'real_time': 0.4, 'real_time_other': 0.04, 'cpu_time': 0.5, 'cpu_time_other': 0.6}],
                'time_unit': 's',
                'utest': {}
            },
        ]
        self.assertEqual(len(self.json_diff_report), len(expected_output))
        for out, expected in zip(
                self.json_diff_report, expected_output):
            self.assertEqual(out['name'], expected['name'])
            self.assertEqual(out['time_unit'], expected['time_unit'])
            assert_utest(self, out, expected)
            assert_measurements(self, out, expected)


class TestReportDifferenceBetweenFamilies(unittest.TestCase):
    @classmethod
    def setUpClass(cls):
        def load_result():
            import json
            testInputs = os.path.join(
                os.path.dirname(
                    os.path.realpath(__file__)),
                'Inputs')
            testOutput = os.path.join(testInputs, 'test2_run.json')
            with open(testOutput, 'r') as f:
                json = json.load(f)
            return json

        json = load_result()
        json1 = filter_benchmark(json, "BM_Z.ro", ".")
        json2 = filter_benchmark(json, "BM_O.e", ".")
        cls.json_diff_report = get_difference_report(json1, json2)

    def test_json_diff_report_pretty_printing(self):
        expect_lines = [
            ['.', '-0.5000', '-0.5000', '10', '5', '10', '5'],
            ['./4', '-0.5000', '-0.5000', '40', '20', '40', '20'],
            ['Prefix/.', '-0.5000', '-0.5000', '20', '10', '20', '10'],
            ['Prefix/./3', '-0.5000', '-0.5000', '30', '15', '30', '15'],
        ]
        output_lines_with_header = print_difference_report(
            self.json_diff_report, use_color=False)
        output_lines = output_lines_with_header[2:]
        print("\n")
        print("\n".join(output_lines_with_header))
        self.assertEqual(len(output_lines), len(expect_lines))
        for i in range(0, len(output_lines)):
            parts = [x for x in output_lines[i].split(' ') if x]
            self.assertEqual(len(parts), 7)
            self.assertEqual(expect_lines[i], parts)

    def test_json_diff_report(self):
        expected_output = [
            {
                'name': u'.',
                'measurements': [{'time': -0.5, 'cpu': -0.5, 'real_time': 10, 'real_time_other': 5, 'cpu_time': 10, 'cpu_time_other': 5}],
                'time_unit': 'ns',
                'utest': {}
            },
            {
                'name': u'./4',
                'measurements': [{'time': -0.5, 'cpu': -0.5, 'real_time': 40, 'real_time_other': 20, 'cpu_time': 40, 'cpu_time_other': 20}],
                'time_unit': 'ns',
                'utest': {},
            },
            {
                'name': u'Prefix/.',
                'measurements': [{'time': -0.5, 'cpu': -0.5, 'real_time': 20, 'real_time_other': 10, 'cpu_time': 20, 'cpu_time_other': 10}],
                'time_unit': 'ns',
                'utest': {}
            },
            {
                'name': u'Prefix/./3',
                'measurements': [{'time': -0.5, 'cpu': -0.5, 'real_time': 30, 'real_time_other': 15, 'cpu_time': 30, 'cpu_time_other': 15}],
                'time_unit': 'ns',
                'utest': {}
            }
        ]
        self.assertEqual(len(self.json_diff_report), len(expected_output))
        for out, expected in zip(
                self.json_diff_report, expected_output):
            self.assertEqual(out['name'], expected['name'])
            self.assertEqual(out['time_unit'], expected['time_unit'])
            assert_utest(self, out, expected)
            assert_measurements(self, out, expected)


class TestReportDifferenceWithUTest(unittest.TestCase):
    @classmethod
    def setUpClass(cls):
        def load_results():
            import json
            testInputs = os.path.join(
                os.path.dirname(
                    os.path.realpath(__file__)),
                'Inputs')
            testOutput1 = os.path.join(testInputs, 'test3_run0.json')
            testOutput2 = os.path.join(testInputs, 'test3_run1.json')
            with open(testOutput1, 'r') as f:
                json1 = json.load(f)
            with open(testOutput2, 'r') as f:
                json2 = json.load(f)
            return json1, json2

        json1, json2 = load_results()
        cls.json_diff_report = get_difference_report(
            json1, json2, utest=True)

    def test_json_diff_report_pretty_printing(self):
        expect_lines = [
            ['BM_One', '-0.1000', '+0.1000', '10', '9', '100', '110'],
            ['BM_Two', '+0.1111', '-0.0111', '9', '10', '90', '89'],
            ['BM_Two', '-0.1250', '-0.1628', '8', '7', '86', '72'],
            ['BM_Two_pvalue',
             '0.6985',
             '0.6985',
             'U',
             'Test,',
             'Repetitions:',
             '2',
             'vs',
             '2.',
             'WARNING:',
             'Results',
             'unreliable!',
             '9+',
             'repetitions',
             'recommended.'],
            ['short', '-0.1250', '-0.0625', '8', '7', '80', '75'],
            ['short', '-0.4325', '-0.1351', '8', '5', '77', '67'],
            ['short_pvalue',
             '0.7671',
             '0.1489',
             'U',
             'Test,',
             'Repetitions:',
             '2',
             'vs',
             '3.',
             'WARNING:',
             'Results',
             'unreliable!',
             '9+',
             'repetitions',
             'recommended.'],
            ['medium', '-0.3750', '-0.3375', '8', '5', '80', '53'],
        ]
        output_lines_with_header = print_difference_report(
            self.json_diff_report, utest=True, utest_alpha=0.05, use_color=False)
        output_lines = output_lines_with_header[2:]
        print("\n")
        print("\n".join(output_lines_with_header))
        self.assertEqual(len(output_lines), len(expect_lines))
        for i in range(0, len(output_lines)):
            parts = [x for x in output_lines[i].split(' ') if x]
            self.assertEqual(expect_lines[i], parts)

    def test_json_diff_report(self):
        expected_output = [
            {
                'name': u'BM_One',
                'measurements': [
                    {'time': -0.1,
                     'cpu': 0.1,
                     'real_time': 10,
                     'real_time_other': 9,
                     'cpu_time': 100,
                     'cpu_time_other': 110}
                ],
                'time_unit': 'ns',
                'utest': {}
            },
            {
                'name': u'BM_Two',
                'measurements': [
                    {'time': 0.1111111111111111,
                     'cpu': -0.011111111111111112,
                     'real_time': 9,
                     'real_time_other': 10,
                     'cpu_time': 90,
                     'cpu_time_other': 89},
                    {'time': -0.125, 'cpu': -0.16279069767441862, 'real_time': 8,
                        'real_time_other': 7, 'cpu_time': 86, 'cpu_time_other': 72}
                ],
                'time_unit': 'ns',
                'utest': {
                    'have_optimal_repetitions': False, 'cpu_pvalue': 0.6985353583033387, 'time_pvalue': 0.6985353583033387
                }
            },
            {
                'name': u'short',
                'measurements': [
                    {'time': -0.125,
                     'cpu': -0.0625,
                     'real_time': 8,
                     'real_time_other': 7,
                     'cpu_time': 80,
                     'cpu_time_other': 75},
                    {'time': -0.4325,
                     'cpu': -0.13506493506493514,
                     'real_time': 8,
                     'real_time_other': 4.54,
                     'cpu_time': 77,
                     'cpu_time_other': 66.6}
                ],
                'time_unit': 'ns',
                'utest': {
                    'have_optimal_repetitions': False, 'cpu_pvalue': 0.14891467317876572, 'time_pvalue': 0.7670968684102772
                }
            },
            {
                'name': u'medium',
                'measurements': [
                    {'time': -0.375,
                     'cpu': -0.3375,
                     'real_time': 8,
                     'real_time_other': 5,
                     'cpu_time': 80,
                     'cpu_time_other': 53}
                ],
                'time_unit': 'ns',
                'utest': {}
            }
        ]
        self.assertEqual(len(self.json_diff_report), len(expected_output))
        for out, expected in zip(
                self.json_diff_report, expected_output):
            self.assertEqual(out['name'], expected['name'])
            self.assertEqual(out['time_unit'], expected['time_unit'])
            assert_utest(self, out, expected)
            assert_measurements(self, out, expected)


class TestReportDifferenceWithUTestWhileDisplayingAggregatesOnly(
        unittest.TestCase):
    @classmethod
    def setUpClass(cls):
        def load_results():
            import json
            testInputs = os.path.join(
                os.path.dirname(
                    os.path.realpath(__file__)),
                'Inputs')
            testOutput1 = os.path.join(testInputs, 'test3_run0.json')
            testOutput2 = os.path.join(testInputs, 'test3_run1.json')
            with open(testOutput1, 'r') as f:
                json1 = json.load(f)
            with open(testOutput2, 'r') as f:
                json2 = json.load(f)
            return json1, json2

        json1, json2 = load_results()
        cls.json_diff_report = get_difference_report(
            json1, json2, utest=True)

    def test_json_diff_report_pretty_printing(self):
        expect_lines = [
            ['BM_One', '-0.1000', '+0.1000', '10', '9', '100', '110'],
            ['BM_Two', '+0.1111', '-0.0111', '9', '10', '90', '89'],
            ['BM_Two', '-0.1250', '-0.1628', '8', '7', '86', '72'],
            ['BM_Two_pvalue',
             '0.6985',
             '0.6985',
             'U',
             'Test,',
             'Repetitions:',
             '2',
             'vs',
             '2.',
             'WARNING:',
             'Results',
             'unreliable!',
             '9+',
             'repetitions',
             'recommended.'],
            ['short', '-0.1250', '-0.0625', '8', '7', '80', '75'],
            ['short', '-0.4325', '-0.1351', '8', '5', '77', '67'],
            ['short_pvalue',
             '0.7671',
             '0.1489',
             'U',
             'Test,',
             'Repetitions:',
             '2',
             'vs',
             '3.',
             'WARNING:',
             'Results',
             'unreliable!',
             '9+',
             'repetitions',
             'recommended.'],
             ['medium', '-0.3750', '-0.3375', '8', '5', '80', '53']
        ]
        output_lines_with_header = print_difference_report(
            self.json_diff_report,
            utest=True, utest_alpha=0.05, use_color=False)
        output_lines = output_lines_with_header[2:]
        print("\n")
        print("\n".join(output_lines_with_header))
        self.assertEqual(len(output_lines), len(expect_lines))
        for i in range(0, len(output_lines)):
            parts = [x for x in output_lines[i].split(' ') if x]
            self.assertEqual(expect_lines[i], parts)

    def test_json_diff_report(self):
        expected_output = [
            {
                'name': u'BM_One',
                'measurements': [
                    {'time': -0.1,
                     'cpu': 0.1,
                     'real_time': 10,
                     'real_time_other': 9,
                     'cpu_time': 100,
                     'cpu_time_other': 110}
                ],
                'time_unit': 'ns',
                'utest': {}
            },
            {
                'name': u'BM_Two',
                'measurements': [
                    {'time': 0.1111111111111111,
                     'cpu': -0.011111111111111112,
                     'real_time': 9,
                     'real_time_other': 10,
                     'cpu_time': 90,
                     'cpu_time_other': 89},
                    {'time': -0.125, 'cpu': -0.16279069767441862, 'real_time': 8,
                        'real_time_other': 7, 'cpu_time': 86, 'cpu_time_other': 72}
                ],
                'time_unit': 'ns',
                'utest': {
                    'have_optimal_repetitions': False, 'cpu_pvalue': 0.6985353583033387, 'time_pvalue': 0.6985353583033387
                }
            },
            {
                'name': u'short',
                'measurements': [
                    {'time': -0.125,
                     'cpu': -0.0625,
                     'real_time': 8,
                     'real_time_other': 7,
                     'cpu_time': 80,
                     'cpu_time_other': 75},
                    {'time': -0.4325,
                     'cpu': -0.13506493506493514,
                     'real_time': 8,
                     'real_time_other': 4.54,
                     'cpu_time': 77,
                     'cpu_time_other': 66.6}
                ],
                'time_unit': 'ns',
                'utest': {
                    'have_optimal_repetitions': False, 'cpu_pvalue': 0.14891467317876572, 'time_pvalue': 0.7670968684102772
                }
            },
            {
                'name': u'medium',
                'measurements': [
                    {'real_time_other': 5,
                     'cpu_time': 80,
                     'time': -0.375,
                     'real_time': 8,
                     'cpu_time_other': 53,
                     'cpu': -0.3375
                    }
                ],
                'utest': {},
                'time_unit': u'ns',
                'aggregate_name': ''
            }
        ]
        self.assertEqual(len(self.json_diff_report), len(expected_output))
        for out, expected in zip(
                self.json_diff_report, expected_output):
            self.assertEqual(out['name'], expected['name'])
            self.assertEqual(out['time_unit'], expected['time_unit'])
            assert_utest(self, out, expected)
            assert_measurements(self, out, expected)


def assert_utest(unittest_instance, lhs, rhs):
    if lhs['utest']:
        unittest_instance.assertAlmostEqual(
            lhs['utest']['cpu_pvalue'],
            rhs['utest']['cpu_pvalue'])
        unittest_instance.assertAlmostEqual(
            lhs['utest']['time_pvalue'],
            rhs['utest']['time_pvalue'])
        unittest_instance.assertEqual(
            lhs['utest']['have_optimal_repetitions'],
            rhs['utest']['have_optimal_repetitions'])
    else:
        # lhs is empty. assert if rhs is not.
        unittest_instance.assertEqual(lhs['utest'], rhs['utest'])


def assert_measurements(unittest_instance, lhs, rhs):
    for m1, m2 in zip(lhs['measurements'], rhs['measurements']):
        unittest_instance.assertEqual(m1['real_time'], m2['real_time'])
        unittest_instance.assertEqual(m1['cpu_time'], m2['cpu_time'])
        # m1['time'] and m1['cpu'] hold values which are being calculated,
        # and therefore we must use almost-equal pattern.
        unittest_instance.assertAlmostEqual(m1['time'], m2['time'], places=4)
        unittest_instance.assertAlmostEqual(m1['cpu'], m2['cpu'], places=4)


if __name__ == '__main__':
    unittest.main()

# vim: tabstop=4 expandtab shiftwidth=4 softtabstop=4
# kate: tab-width: 4; replace-tabs on; indent-width 4; tab-indents: off;
# kate: indent-mode python; remove-trailing-spaces modified;



================================================
FILE: buildbot/gbench/util.py
================================================
"""util.py - General utilities for running, loading, and processing benchmarks
"""
import json
import os
import tempfile
import subprocess
import sys

# Input file type enumeration
IT_Invalid = 0
IT_JSON = 1
IT_Executable = 2

_num_magic_bytes = 2 if sys.platform.startswith('win') else 4


def is_executable_file(filename):
    """
    Return 'True' if 'filename' names a valid file which is likely
    an executable. A file is considered an executable if it starts with the
    magic bytes for a EXE, Mach O, or ELF file.
    """
    if not os.path.isfile(filename):
        return False
    with open(filename, mode='rb') as f:
        magic_bytes = f.read(_num_magic_bytes)
    if sys.platform == 'darwin':
        return magic_bytes in [
            b'\xfe\xed\xfa\xce',  # MH_MAGIC
            b'\xce\xfa\xed\xfe',  # MH_CIGAM
            b'\xfe\xed\xfa\xcf',  # MH_MAGIC_64
            b'\xcf\xfa\xed\xfe',  # MH_CIGAM_64
            b'\xca\xfe\xba\xbe',  # FAT_MAGIC
            b'\xbe\xba\xfe\xca'   # FAT_CIGAM
        ]
    elif sys.platform.startswith('win'):
        return magic_bytes == b'MZ'
    else:
        return magic_bytes == b'\x7FELF'


def is_json_file(filename):
    """
    Returns 'True' if 'filename' names a valid JSON output file.
    'False' otherwise.
    """
    try:
        with open(filename, 'r') as f:
            json.load(f)
        return True
    except BaseException:
        pass
    return False


def classify_input_file(filename):
    """
    Return a tuple (type, msg) where 'type' specifies the classified type
    of 'filename'. If 'type' is 'IT_Invalid' then 'msg' is a human readable
    string represeting the error.
    """
    ftype = IT_Invalid
    err_msg = None
    if not os.path.exists(filename):
        err_msg = "'%s' does not exist" % filename
    elif not os.path.isfile(filename):
        err_msg = "'%s' does not name a file" % filename
    elif is_executable_file(filename):
        ftype = IT_Executable
    elif is_json_file(filename):
        ftype = IT_JSON
    else:
        err_msg = "'%s' does not name a valid benchmark executable or JSON file" % filename
    return ftype, err_msg


def check_input_file(filename):
    """
    Classify the file named by 'filename' and return the classification.
    If the file is classified as 'IT_Invalid' print an error message and exit
    the program.
    """
    ftype, msg = classify_input_file(filename)
    if ftype == IT_Invalid:
        print("Invalid input file: %s" % msg)
        sys.exit(1)
    return ftype


def find_benchmark_flag(prefix, benchmark_flags):
    """
    Search the specified list of flags for a flag matching `<prefix><arg>` and
    if it is found return the arg it specifies. If specified more than once the
    last value is returned. If the flag is not found None is returned.
    """
    assert prefix.startswith('--') and prefix.endswith('=')
    result = None
    for f in benchmark_flags:
        if f.startswith(prefix):
            result = f[len(prefix):]
    return result


def remove_benchmark_flags(prefix, benchmark_flags):
    """
    Return a new list containing the specified benchmark_flags except those
    with the specified prefix.
    """
    assert prefix.startswith('--') and prefix.endswith('=')
    return [f for f in benchmark_flags if not f.startswith(prefix)]


def load_benchmark_results(fname):
    """
    Read benchmark output from a file and return the JSON object.
    REQUIRES: 'fname' names a file containing JSON benchmark output.
    """
    with open(fname, 'r') as f:
        return json.load(f)


def run_benchmark(exe_name, benchmark_flags):
    """
    Run a benchmark specified by 'exe_name' with the specified
    'benchmark_flags'. The benchmark is run directly as a subprocess to preserve
    real time console output.
    RETURNS: A JSON object representing the benchmark output
    """
    output_name = find_benchmark_flag('--benchmark_out=',
                                      benchmark_flags)
    is_temp_output = False
    if output_name is None:
        is_temp_output = True
        thandle, output_name = tempfile.mkstemp()
        os.close(thandle)
        benchmark_flags = list(benchmark_flags) + \
            ['--benchmark_out=%s' % output_name]

    cmd = [exe_name] + benchmark_flags
    print("RUNNING: %s" % ' '.join(cmd))
    exitCode = subprocess.call(cmd)
    if exitCode != 0:
        print('TEST FAILED...')
        sys.exit(exitCode)
    json_res = load_benchmark_results(output_name)
    if is_temp_output:
        os.unlink(output_name)
    return json_res


def run_or_load_benchmark(filename, benchmark_flags):
    """
    Get the results for a specified benchmark. If 'filename' specifies
    an executable benchmark then the results are generated by running the
    benchmark. Otherwise 'filename' must name a valid JSON output file,
    which is loaded and the result returned.
    """
    ftype = check_input_file(filename)
    if ftype == IT_JSON:
        return load_benchmark_results(filename)
    if ftype == IT_Executable:
        return run_benchmark(filename, benchmark_flags)
    raise ValueError('Unknown file type %s' % ftype)



================================================
FILE: labs/bad_speculation/README.md
================================================
# Bad Speculation

[<img src="../../img/BadSpecIntro.png">](https://www.youtube.com/watch?v=B8AsUSN3Xa4&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d)

This is a collection of labs, which experience large amount of branch mispredictions. We will be covering branchless algorithms. Here are some of the topics we plan to cover:

* Replace branches with look-up tables
* Replace branches with arithmetics
* Replace branches with predication

**Work in progress...**

Let us know if you have any suggestion for a new lab assignment.



================================================
FILE: labs/bad_speculation/branches_to_cmov_1/README.md
================================================
**TODO**: add an introductory and a summary videos.

This is the good old game of life. The program takes 10 randomly generated 1024x1024 grids (boards) and simulates the next 10 game of life rounds. It first simulates 10 rounds for the first board, then goes off to the second board, and so on.

As written, the program experiences many branch mispredictions. Your job is to find where they happen and replace them with predicate instructions. On x86 you should see `cmov` instructions (hint: use `__builtin_unpredictable`, make sure you have Clang-17 or later version installed). On ARM you should see `csel` (conditional select) instructions. It is a good idea to experiment with the code in godbolt.org before you start modifying the actual code.

Bonus question: when you fix the main source of mispredictions, there are still many branches left in the hot loop nest. How can you get rid of them?



================================================
FILE: labs/bad_speculation/branches_to_cmov_1/bench.cpp
================================================

#include "benchmark/benchmark.h"
#include "solution.hpp"

static void bench1(benchmark::State &state) {
  // Init benchmark data
  std::vector<Life::Grid> grids;
  for (int i = 0; i < NumberOfGrids; i++)
    grids.emplace_back(initRandom());

  // Run the benchmark
  for (auto _ : state) {
    auto output = solution(grids);
    benchmark::DoNotOptimize(output);
  }
}

// Register the function as a benchmark and measure time in microseconds
BENCHMARK(bench1)->Unit(benchmark::kMillisecond);

// Run the benchmark
BENCHMARK_MAIN();



================================================
FILE: labs/bad_speculation/branches_to_cmov_1/CMakeLists.txt
================================================
cmake_minimum_required(VERSION 2.8.12)

project(lab)

string(REGEX MATCH "^(.*)[\\/]labs[\\/].*$" repo "${CMAKE_CURRENT_SOURCE_DIR}")
include(${CMAKE_MATCH_1}/tools/labs.cmake)



================================================
FILE: labs/bad_speculation/branches_to_cmov_1/init.cpp
================================================
#include "solution.hpp"
#include <algorithm>
#include <random>

// Init random starting grid of the game
Life::Grid initRandom() {
  std::random_device r;
  std::mt19937_64 random_engine(r());
  std::uniform_int_distribution<int> distrib(0, 9);

  Life::Grid retGrid;
  retGrid.resize(GridXDimension);

  for (auto &row : retGrid) {
    row.resize(GridYDimension);
    std::generate(row.begin(), row.end(),[&]() { 
      // 70% dead cells and 30% alive cells
      return distrib(random_engine) > 6; 
    });
  }

  return retGrid;
}


================================================
FILE: labs/bad_speculation/branches_to_cmov_1/solution.cpp
================================================
#include "solution.hpp"

// Simulates N steps of the game for each starting grid 
// and return population count
std::vector<int> solution(const std::vector<Life::Grid>& grids) {
  std::vector<int> popCounts;
  popCounts.reserve(grids.size());

  Life life;
  for (auto& grid : grids) {
    life.reset(grid);
    for (int i = 0; i < NumberOfSims; i++)
      life.simulateNext();
    popCounts.push_back(life.getPopulationCount());
  }

  return popCounts;
}


================================================
FILE: labs/bad_speculation/branches_to_cmov_1/solution.hpp
================================================
#include <vector>
#include <iostream>

constexpr int NumberOfGrids = 16;
constexpr int GridXDimension = 1024;
constexpr int GridYDimension = 1024;
constexpr int NumberOfSims = 10;

class Life {

public:
    using Grid = std::vector<std::vector<int>>;
private:    
    Grid current;
    Grid future;

public:

    void reset(const Grid& grid) {
        current = future = grid;
    }

    int getPopulationCount() {
        int populationCount = 0;
        for (auto& row: current)
            for (auto& item: row)
                populationCount += item;
        return populationCount;
    }

    void printCurrentGrid() {
        for (auto& row: current) {
            for (auto& item: row)
                item ? std::cout << "x " : std::cout << ". ";
            std::cout << "\n";
        }
        std::cout << "\n";
    }    

    // Simulate the next generation of life
    void simulateNext() {
        //printCurrentGrid();
        int M = current.size();
        int N = current[0].size();
        
        // Loop through every cell
        for(int i = 0; i < M; i++) {
            for(int j = 0; j < N; j++) {
                int aliveNeighbours = 0;      
                // finding the number of neighbours that are alive                  
                for(int p = -1; p <= 1; p++) {              // row-offet (-1,0,1)
                    for(int q = -1; q <= 1; q++) {          // col-offset (-1,0,1)
                        if((i + p < 0) ||                   // if row offset less than UPPER boundary
                           (i + p > M - 1) ||               // if row offset more than LOWER boundary
                           (j + q < 0) ||                   // if column offset less than LEFT boundary
                           (j + q > N - 1))                 // if column offset more than RIGHT boundary
                            continue;
                        aliveNeighbours += current[i + p][j + q];
                    }
                }
                // The cell needs to be subtracted from
                // its neighbours as it was counted before
                aliveNeighbours -= current[i][j];

                // Implementing the Rules of Life:
                switch(aliveNeighbours) {
                    // 1. Cell is lonely and dies
                    case 0:
                    case 1:
                        future[i][j] = 0;
                        break;                   
                    // 2. Remains the same
                    case 2:
                        future[i][j] = current[i][j];
                        break;
                    // 3. A new cell is born
                    case 3:
                        future[i][j] = 1;
                        break;
                    // 4. Cell dies due to over population
                    default:
                        future[i][j] = 0;
                }
            }
        }
        std::swap(current, future);
    }
};

// Init random starting grid of the game
Life::Grid initRandom();
// Simulates N steps of the game for each starting grid 
// and return population count
std::vector<int> solution(const std::vector<Life::Grid>& grids);



================================================
FILE: labs/bad_speculation/branches_to_cmov_1/validate.cpp
================================================

#include "solution.hpp"
#include <iostream>

class LifeOriginal {

public:
    using Grid = std::vector<std::vector<int>>;
private:    
    Grid current;
    Grid future;

public:

    void reset(const Grid& grid) {
        current = future = grid;
    }

    int getPopulationCount() {
        int populationCount = 0;
        for (auto& row: current)
            for (auto& item: row)
                populationCount += item;
        return populationCount;
    }

    void printCurrentGrid() {
        for (auto& row: current) {
            for (auto& item: row)
                item ? std::cout << "x " : std::cout << ". ";
            std::cout << "\n";
        }
        std::cout << "\n";
    }    

    // Simulate the next generation of life
    void simulateNext() {
        //printCurrentGrid();
        int M = current.size();
        int N = current[0].size();
        
        // Loop through every cell
        for(int i = 0; i < M; i++) {
            for(int j = 0; j < N; j++) {
                int aliveNeighbours = 0;      
                // finding the number of neighbours that are alive                  
                for(int p = -1; p <= 1; p++) {              // row-offet (-1,0,1)
                    for(int q = -1; q <= 1; q++) {          // col-offset (-1,0,1)
                        if((i + p < 0) ||                   // if row offset less than UPPER boundary
                           (i + p > M - 1) ||               // if row offset more than LOWER boundary
                           (j + q < 0) ||                   // if column offset less than LEFT boundary
                           (j + q > N - 1))                 // if column offset more than RIGHT boundary
                            continue;
                        aliveNeighbours += current[i + p][j + q];
                    }
                }
                // The cell needs to be subtracted from
                // its neighbours as it was counted before
                aliveNeighbours -= current[i][j];

                // Implementing the Rules of Life:
                switch(aliveNeighbours) {
                    // 1. Cell is lonely and dies
                    case 0:
                    case 1:
                        future[i][j] = 0;
                        break;                   
                    // 2. Remains the same
                    case 2:
                        future[i][j] = current[i][j];
                        break;
                    // 3. A new cell is born
                    case 3:
                        future[i][j] = 1;
                        break;
                    // 4. Cell dies due to over population
                    default:
                        future[i][j] = 0;
                }
            }
        }
        std::swap(current, future);
    }
};

std::vector<int> original_solution(const std::vector<LifeOriginal::Grid>& grids) {
  std::vector<int> popCounts;
  popCounts.reserve(grids.size());

  LifeOriginal life;
  for (auto& grid : grids) {
    life.reset(grid);
    for (int i = 0; i < NumberOfSims; i++)
      life.simulateNext();
    popCounts.push_back(life.getPopulationCount());
  }

  return popCounts;
}

int main() {
  // Init benchmark data
  std::vector<LifeOriginal::Grid> grids;
  for (int i = 0; i < NumberOfGrids; i++)
    grids.emplace_back(initRandom());

  auto original_result = original_solution(grids);
  auto result = solution(grids);
  
  if (original_result != result) {
    std::cerr << "Validation Failed. Population count doesn't match" << "\n";
    return 1;
  }

  std::cout << "Validation Successful" << std::endl;
  return 0;
}



================================================
FILE: labs/bad_speculation/conditional_store_1/README.md
================================================
**TODO**: add an introductory and a summary videos.

This lab assignment focuses on improving performance by reducing the number of branch mispredictions. In this lab, we have a large collection of key-value pairs from which we select only useful items. Such algorithms are widely used in many real-world applications, for example, texture compression. Input collection contains random key values which makes it hard for a modern CPU to predict whether they should be selected or not. Your task here is to reduce the number of branch mispredictions.



================================================
FILE: labs/bad_speculation/conditional_store_1/bench.cpp
================================================

#include "benchmark/benchmark.h"
#include "solution.h"
#include <limits>

static void bench1(benchmark::State &state) {
  std::array<S, N> arr;
  init(arr);

  std::array<S, N> temp;
  constexpr auto lower = (std::numeric_limits<std::uint32_t>::max() / 4) + 1;
  constexpr auto upper =
      (std::numeric_limits<std::uint32_t>::max() / 2) + lower;

  for (auto _ : state) {
    select(temp, arr, lower, upper);
    benchmark::DoNotOptimize(temp);
  }
}

// Register the function as a benchmark
BENCHMARK(bench1)->Iterations(10000)->Unit(benchmark::kMicrosecond);

// Run the benchmark
BENCHMARK_MAIN();



================================================
FILE: labs/bad_speculation/conditional_store_1/CMakeLists.txt
================================================
cmake_minimum_required(VERSION 3.3)

project(lab)

string(REGEX MATCH "^(.*)[\\/]labs[\\/].*$" repo "${CMAKE_CURRENT_SOURCE_DIR}")
include(${CMAKE_MATCH_1}/tools/labs.cmake)



================================================
FILE: labs/bad_speculation/conditional_store_1/init.cpp
================================================

#include "solution.h"
#include <limits>
#include <random>

void init(std::array<S, N> &arr) {
  std::default_random_engine generator;
  std::uniform_int_distribution<std::uint32_t> distribution(
      std::numeric_limits<std::uint32_t>::min(),
      std::numeric_limits<std::uint32_t>::max());

  for (std::size_t i = 0; i < N; i++) {
    arr[i].first = distribution(generator);
    arr[i].second = distribution(generator);
  }
}



================================================
FILE: labs/bad_speculation/conditional_store_1/solution.cpp
================================================

#include "solution.h"

// Select items which have S.first in range [lower..upper]
std::size_t select(std::array<S, N> &output, const std::array<S, N> &input,
                   const std::uint32_t lower, const std::uint32_t upper) {
  std::size_t count = 0;
  for (const auto item : input) {
    if ((lower <= item.first) && (item.first <= upper)) {
      output[count++] = item;
    }
  }
  return count;
}



================================================
FILE: labs/bad_speculation/conditional_store_1/solution.h
================================================

#include <array>
#include <cstdint>

// Assume this constant never changes
constexpr std::size_t N = 64 * 1024;

// "first" contains a metric
// "second" contains associated data
using S = std::pair<std::uint32_t, std::uint32_t>;

// Select items which have S.first in range [lower..upper]
std::size_t select(std::array<S, N> &output, const std::array<S, N> &input,
                   const std::uint32_t lower, const std::uint32_t upper);

void init(std::array<S, N> &arr);



================================================
FILE: labs/bad_speculation/conditional_store_1/validate.cpp
================================================

#include "solution.h"
#include <iostream>
#include <limits>

static std::size_t originalSelect(std::array<S, N> &output,
                                  const std::array<S, N> &input,
                                  const std::uint32_t lower,
                                  const std::uint32_t upper) {
  std::size_t count = 0;
  for (const auto item : input) {
    if ((lower <= item.first) && (item.first <= upper)) {
      output[count++] = item;
    }
  }
  return count;
}

static bool equals(const std::array<S, N> &a, const std::array<S, N> &b,
                   std::size_t size) {
  constexpr int maxErrors = 10;

  int errors = 0;
  for (std::size_t i = 0; i < size; i++) {
    auto va = a[i];
    auto vb = b[i];
    if (va != vb) {
      if (va.first != vb.first) {
        std::cerr << "Result[" << i << "].first = " << va.first << ". Expected["
                  << i << "].first = " << vb.first << std::endl;
      }
      if (va.second != vb.second) {
        std::cerr << "Result[" << i << "].second = " << va.second
                  << ". Expected[" << i << "].second = " << vb.second
                  << std::endl;
      }
      if (++errors >= maxErrors)
        return false;
    }
  }
  return 0 == errors;
}

int main() {
  std::array<S, N> arr;
  init(arr);

  constexpr auto lower = (std::numeric_limits<std::uint32_t>::max() / 4) + 1;
  constexpr auto upper =
      (std::numeric_limits<std::uint32_t>::max() / 2) + lower;

  std::array<S, N> expected, result;
  auto expectedSize = originalSelect(expected, arr, lower, upper);
  auto resultSize = select(result, arr, lower, upper);

  if (resultSize != expectedSize) {
    std::cerr << "Result size = " << resultSize
              << ". Expected size = " << expectedSize << std::endl;
    return 1;
  }

  if (!equals(result, expected, expectedSize)) {
    std::cerr << "Validation Failed" << std::endl;
    return 1;
  }

  std::cout << "Validation Successful" << std::endl;
  return 0;
}



================================================
FILE: labs/bad_speculation/lookup_tables_1/README.md
================================================
[<img src="../../../img/LookupTables1.png">](https://www.youtube.com/watch?v=bhz4t5QYApE&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d)

Welcome to the next lab assignment, where we will fight branch mispredictions by replacing them with lookup tables. The code in this lab assignment maps values from `[0;150]` into buckets, which involves a lot of comparisons, and so, branches. To solve this assignment you need to figure out a way how to replace *all* hard-to-predict branches.

Bonus question: how would you solve it if the range of possible values will be bigger, say `[0;10000]`?



================================================
FILE: labs/bad_speculation/lookup_tables_1/bench.cpp
================================================

#include "benchmark/benchmark.h"
#include "solution.hpp"

static void bench1(benchmark::State &state) {
  std::vector<int> values;
  values.reserve(NUM_VALUES);
  init(values);

  // Run the benchmark
  for (auto _ : state) {
    auto output = histogram(values);
    benchmark::DoNotOptimize(output);
  }
}

// Register the function as a benchmark and measure time in microseconds
BENCHMARK(bench1)->Unit(benchmark::kMicrosecond);

// Run the benchmark
BENCHMARK_MAIN();



================================================
FILE: labs/bad_speculation/lookup_tables_1/CMakeLists.txt
================================================
cmake_minimum_required(VERSION 3.3)

project(lab)

string(REGEX MATCH "^(.*)[\\/]labs[\\/].*$" repo "${CMAKE_CURRENT_SOURCE_DIR}")
include(${CMAKE_MATCH_1}/tools/labs.cmake)



================================================
FILE: labs/bad_speculation/lookup_tables_1/init.cpp
================================================
#include "solution.hpp"
#include <limits>
#include <random>

void init(std::vector<int> &values) {
  std::random_device r;
  std::default_random_engine generator(r());
  // generate random integer in the closed interval [0,150]
  // the chance of selecting the default bucket is ~33%
  std::uniform_int_distribution<int> distribution(0, 150);
  for (int i = 0; i < NUM_VALUES; i++) {
    values.push_back(distribution(generator));
  }
}


================================================
FILE: labs/bad_speculation/lookup_tables_1/solution.cpp
================================================
#include "solution.hpp"

static std::size_t mapToBucket(std::size_t v) {
                              //   size of a bucket
  if      (v < 13)  return 0; //   13
  else if (v < 29)  return 1; //   16
  else if (v < 41)  return 2; //   12
  else if (v < 53)  return 3; //   12
  else if (v < 71)  return 4; //   18
  else if (v < 83)  return 5; //   12
  else if (v < 100) return 6; //   17
  return DEFAULT_BUCKET;
}

std::array<std::size_t, NUM_BUCKETS> histogram(const std::vector<int> &values) {
  std::array<std::size_t, NUM_BUCKETS> retBuckets{0};
  for (auto v : values) {
    retBuckets[mapToBucket(v)]++;
  }
  return retBuckets;
}



================================================
FILE: labs/bad_speculation/lookup_tables_1/solution.hpp
================================================
#include <array>
#include <vector>

constexpr std::size_t NUM_BUCKETS = 8;
constexpr std::size_t DEFAULT_BUCKET = NUM_BUCKETS - 1;
constexpr std::size_t NUM_VALUES = 1024 * 1024;

void init(std::vector<int> &values);
std::array<std::size_t, NUM_BUCKETS> histogram(const std::vector<int> &values);



================================================
FILE: labs/bad_speculation/lookup_tables_1/validate.cpp
================================================

#include "solution.hpp"
#include <iostream>

static size_t mapToBucket(size_t v) {
                              //   size of a bucket
  if      (v < 13)  return 0; //   13
  else if (v < 29)  return 1; //   16
  else if (v < 41)  return 2; //   12
  else if (v < 53)  return 3; //   12
  else if (v < 71)  return 4; //   18
  else if (v < 83)  return 5; //   12
  else if (v < 100) return 6; //   17
  return DEFAULT_BUCKET;
}

std::array<size_t, NUM_BUCKETS>
original_histogram(const std::vector<int> &values) {
  std::array<size_t, NUM_BUCKETS> retBuckets{0};
  for (auto v : values) {
    retBuckets[mapToBucket(v)]++;
  }
  return retBuckets;
}

int main() {
  std::vector<int> values;
  values.reserve(NUM_VALUES);
  init(values);

  auto original_result = original_histogram(values);
  auto result = histogram(values);

  if (original_result != result) {
    std::cerr << "Validation Failed."
              << "\n";
    std::cerr << "Original result: ";
    for (auto v : original_result)
      std::cerr << v << " ";
    std::cerr << "\n";
    std::cerr << "Modified version returned: ";
    for (auto v : result)
      std::cerr << v << " ";
    return 1;
  }

  std::cout << "Validation Successful" << std::endl;
  return 0;
}



================================================
FILE: labs/bad_speculation/virtual_call_mispredict/README.md
================================================
**TODO**: add an introductory and a summary videos.

This lab assignment focuses on improving performance by reducing the number of branch target mispredictions. In this lab,
we have a collection of objects of three distinct classes that inherit from a shared base class. An array of objects is
created in some arbitrary order and then repeatedly iterated. During the iteration, a virtual method is called on each
object. The CPU does not know which exact method will be called beforehand (it does not know the *target* of the call),
which slows its execution down.

Your task here is to reduce the number of branch target mispredictions by making the virtual method calls more predictable.

Authored-by: Jakub Beránek (@Kobzol)


================================================
FILE: labs/bad_speculation/virtual_call_mispredict/bench.cpp
================================================
#include "benchmark/benchmark.h"
#include "solution.h"

static void bench1(benchmark::State& state) {
    InstanceArray arr;
    generateObjects(arr);

    for (auto _: state) {
        std::size_t data = 0;
        invoke(arr, data);
        benchmark::DoNotOptimize(data);
    }
}

// Register the function as a benchmark
BENCHMARK(bench1)->Unit(benchmark::kMicrosecond); // ->Iterations(10000)

// Run the benchmark
BENCHMARK_MAIN();



================================================
FILE: labs/bad_speculation/virtual_call_mispredict/CMakeLists.txt
================================================
cmake_minimum_required(VERSION 3.3)

project(lab)

string(REGEX MATCH "^(.*)[\\/]labs[\\/].*$" repo "${CMAKE_CURRENT_SOURCE_DIR}")
include(${CMAKE_MATCH_1}/tools/labs.cmake)



================================================
FILE: labs/bad_speculation/virtual_call_mispredict/solution.cpp
================================================
#include "solution.h"

#include <random>

void generateObjects(InstanceArray& array) {
    std::default_random_engine generator(0);
    std::uniform_int_distribution<std::uint32_t> distribution(0, 2);

    for (std::size_t i = 0; i < N; i++) {
        int value = distribution(generator);
        if (value == 0) {
            array.push_back(std::make_unique<ClassA>());
        } else if (value == 1) {
            array.push_back(std::make_unique<ClassB>());
        } else {
            array.push_back(std::make_unique<ClassC>());
        }
    }
}

// Invoke the `handle` method on all instances in `output`
void invoke(InstanceArray& array, std::size_t& data) {
    for (const auto& item: array) {
        item->handle(data);
    }
}



================================================
FILE: labs/bad_speculation/virtual_call_mispredict/solution.h
================================================
#include <cstdint>
#include <vector>
#include <memory>

// Assume this constant never changes
constexpr std::size_t N = 64 * 1024;

struct BaseClass {
    virtual ~BaseClass() = default;

    virtual void handle(std::size_t& data) const = 0;
};

struct ClassA : public BaseClass {
    void handle(std::size_t& data) const override {
        data += 1;
    }
};

struct ClassB : public BaseClass {
    void handle(std::size_t& data) const override {
        data += 2;
    }
};

struct ClassC : public BaseClass {
    void handle(std::size_t& data) const override {
        data += 3;
    }
};

using InstanceArray = std::vector<std::unique_ptr<BaseClass>>;

void generateObjects(InstanceArray& array);
void invoke(InstanceArray& array, std::size_t& data);



================================================
FILE: labs/bad_speculation/virtual_call_mispredict/validate.cpp
================================================
#include "solution.h"

#include <iostream>
#include <random>

void originalGenerateObjects(InstanceArray& array) {
    std::default_random_engine generator(0);
    std::uniform_int_distribution<std::uint32_t> distribution(0, 2);

    for (std::size_t i = 0; i < N; i++) {
        int value = distribution(generator);
        if (value == 0) {
            array.push_back(std::make_unique<ClassA>());
        } else if (value == 1) {
            array.push_back(std::make_unique<ClassB>());
        } else {
            array.push_back(std::make_unique<ClassC>());
        }
    }
}

void originalInvoke(InstanceArray& array, std::size_t& data) {
    for (const auto& item: array) {
        item->handle(data);
    }
}

int main() {
    InstanceArray arr;
    generateObjects(arr);

    std::size_t data = 0;
    invoke(arr, data);

    InstanceArray arrReference;
    originalGenerateObjects(arrReference);

    std::size_t reference = 0;
    originalInvoke(arrReference, reference);

    if (data != reference) {
        std::cerr << "Result = " << data
                  << ". Expected result = " << reference << std::endl;
        return 1;
    }

    std::cout << "Validation Successful" << std::endl;
    return 0;
}



================================================
FILE: labs/core_bound/README.md
================================================
# Core Bound

[<img src="../../img/CoreBoundIntro.png">](https://www.youtube.com/watch?v=CcGhMusQFXA&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d)

This is a collection of labs with performance bound by core execution unit. Here are some of the topics we plan to cover:

* Vectorization
* Function Inlining
* Loop Unrolling
* Loop multiversioning
* Compiler Intrinsics

**Work in progress...**

Let us know if you have any suggestion for a new lab assignment.



================================================
FILE: labs/core_bound/compiler_intrinsics_1/README.md
================================================
[<img src="../../../img/CompilerIntrinsics1-Intro.png">](https://www.youtube.com/watch?v=mlXw_qYRi78&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d&index=12)

This is a lab about using [compiler intrinsics](https://en.wikipedia.org/wiki/Intrinsic_function) to speed up parts of the code, where compilers fail to generate optimal code.

The kernel in this lab assignment is a part of the Average ImageSmoothing algorithm, which is reduced to 1 dimension and lacks division part. The algorithm uses sliding window approach to compute a sum in the subrange [-radius .. +radius]. It is a very fast approach compared to a classical Gaussian blur.

[<img src="../../../img/CompilerIntrinsics1-Summary.png">](https://www.youtube.com/watch?v=fP6Rhwf3rEs&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d&index=12)

Author: @adamf88.


================================================
FILE: labs/core_bound/compiler_intrinsics_1/bench.cpp
================================================

#include "benchmark/benchmark.h"
#include "solution.h"
#include <memory>

static void bench_partial_sum(benchmark::State &state) {
  InputVector inA;
  init(inA);

  OutputVector outB;
  zero(outB, (int)inA.size());

  for (auto _ : state) {
    imageSmoothing(inA, radius, outB);
    benchmark::DoNotOptimize(outB);
  }
}

// Register the function as a benchmark
BENCHMARK(bench_partial_sum)->Unit(benchmark::kMicrosecond);

// Run the benchmark
BENCHMARK_MAIN();



================================================
FILE: labs/core_bound/compiler_intrinsics_1/CMakeLists.txt
================================================
cmake_minimum_required(VERSION 3.3)

project(lab)

string(REGEX MATCH "^(.*)[\\/]labs[\\/].*$" repo "${CMAKE_CURRENT_SOURCE_DIR}")
include(${CMAKE_MATCH_1}/tools/labs.cmake)



================================================
FILE: labs/core_bound/compiler_intrinsics_1/init.cpp
================================================
#include "solution.h"
#include <cmath>
#include <limits>
#include <random>

constexpr int N = 40000;

void init(InputVector &data) {
  std::default_random_engine generator;
  std::uniform_int_distribution<int> distribution(0, 255);

  data.reserve(N);
  for (int i = 0; i < N; i++) {
    uint8_t value = static_cast<uint8_t>(distribution(generator));
    data.emplace_back(value);
  }
}

void zero(OutputVector &data, std::size_t size) {
  data.clear();
  data.resize(size);
}



================================================
FILE: labs/core_bound/compiler_intrinsics_1/solution.cpp
================================================

#include "solution.h"
#include <memory>

void imageSmoothing(const InputVector &input, uint8_t radius,
                    OutputVector &output) {
  int pos = 0;
  int currentSum = 0;
  int size = static_cast<int>(input.size());

  // 1. left border - time spend in this loop can be ignored, no need to
  // optimize it
  for (int i = 0; i < std::min<int>(size, radius); ++i) {
    currentSum += input[i];
  }

  int limit = std::min(radius + 1, size - radius);
  for (pos = 0; pos < limit; ++pos) {
    currentSum += input[pos + radius];
    output[pos] = currentSum;
  }

  // 2. main loop.
  limit = size - radius;
  for (; pos < limit; ++pos) {
    currentSum -= input[pos - radius - 1];
    currentSum += input[pos + radius];
    output[pos] = currentSum;
  }

  // 3. special case, executed only if size <= 2*radius + 1
  limit = std::min(radius + 1, size);
  for (; pos < limit; pos++) {
    output[pos] = currentSum;
  }

  // 4. right border - time spend in this loop can be ignored, no need to
  // optimize it
  for (; pos < size; ++pos) {
    currentSum -= input[pos - radius - 1];
    output[pos] = currentSum;
  }
}



================================================
FILE: labs/core_bound/compiler_intrinsics_1/solution.h
================================================

#include <cstdint>
#include <vector>

using InputVector = std::vector<uint8_t>;
using OutputVector = std::vector<uint16_t>;
constexpr uint8_t radius = 13; // assume diameter (2 * radius + 1) to be less
                               // than 256 so results fits in uint16_t

void init(InputVector &data);
void zero(OutputVector &data, std::size_t size);
void imageSmoothing(const InputVector &inA, uint8_t radius,
                    OutputVector &outResult);



================================================
FILE: labs/core_bound/compiler_intrinsics_1/validate.cpp
================================================

#include "solution.h"
#include <algorithm>
#include <cmath>
#include <iostream>
#include <limits>
#include <memory>

static void reference_solution(const InputVector &input, uint8_t radius,
                               OutputVector &output) {
  int pos = 0;
  int currentSum = 0;
  int size = (int)input.size();

  // 1. left border - time spend in this loop can be ignored, no need to
  // optimize it
  for (int i = 0; i < std::min<int>(size, radius); ++i) {
    currentSum += input[i];
  }

  int limit = std::min(radius + 1, size - radius);
  for (pos = 0; pos < limit; ++pos) {
    currentSum += input[pos + radius];
    output[pos] = currentSum;
  }

  // 2. main loop. During optimization, focus mainly on this part
  limit = size - radius;

  for (; pos < limit; ++pos) {
    currentSum -= input[pos - radius - 1];
    currentSum += input[pos + radius];
    output[pos] = currentSum;
  }

  // 3. special case, executed only if size <= 2*radius + 1
  limit = std::min(radius + 1, size);
  for (; pos < limit; pos++) {
    output[pos] = currentSum;
  }

  // 4. right border - time spend in this loop can be ignored, no need to
  // optimize it
  for (; pos < size; ++pos) {
    currentSum -= input[pos - radius - 1];
    output[pos] = currentSum;
  }
}

int main() {
  InputVector inA;
  init(inA);

  OutputVector expected, received;
  zero(expected, (int)inA.size());
  zero(received, (int)inA.size());

  reference_solution(inA, radius, expected);
  imageSmoothing(inA, radius, received);

  if (expected.size() != received.size()) {
    std::cerr << "Result has invalid size. Expected size: " << expected.size()
              << " received: " << received.size() << std::endl;
    return 1;
  }

  auto cmp_result =
      std::mismatch(expected.begin(), expected.end(), received.begin());
  if (cmp_result.first != expected.end()) {
    std::cerr << "Validation Failed at position: "
              << std::distance(expected.begin(), cmp_result.first)
              << ". Expected: " << *cmp_result.first
              << " received: " << *cmp_result.second << "." << std::endl;
    return 1;
  }

  std::cout << "Validation Successful" << std::endl;
  return 0;
}



================================================
FILE: labs/core_bound/compiler_intrinsics_2/README.md
================================================
[<img src="../../../img/CompIntrin2.png">](https://www.youtube.com/watch?v=0WUihFxjzSE&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d)

This is a second lab about using [compiler intrinsics](https://en.wikipedia.org/wiki/Intrinsic_function) to speed up parts of the code, where compilers fail to generate optimal code.

The task of this lab assignment is to find the longest line in a file. There is a way to find end-of-line characters in a parallel way if you utilize compiler intrinsics.

Bonus exercise: whether solution that uses intrinsics is faster than the baseline is heavily affected by the input data. Run your solution on different input files to determine the speedup/slowdown.

The idea for this lab was proposed by Yuriy Lyfenko (@obender12).

Co-authored-by: Andrew Evstyukhin (@andrewevstyukhin)

Co-authored-by: Jakub Beránek (@Kobzol)



================================================
FILE: labs/core_bound/compiler_intrinsics_2/bench.cpp
================================================

#include "benchmark/benchmark.h"
#include "solution.hpp"
#include <filesystem>
#include <fstream>
#include <iostream>

static std::string inputsDirName;

static void bench1(benchmark::State &state) {
  const std::vector<std::string> inputs = {
      "LoopVectorize.cpp",       // a large C++ file from the LLVM compiler.
      "MarkTwain-TomSawyer.txt", // a typical text file with long lines.
      /*"counter-example.txt" // input where sequential solution is faster*/
  };

  std::vector<std::string> inputContents;

  for (auto &input : inputs) {
    std::filesystem::path inputsDirPath = inputsDirName;
    inputsDirPath.append(input);
    std::ifstream inFile{inputsDirPath.string()};
    inputContents.emplace_back(std::istreambuf_iterator<char>(inFile),
                               std::istreambuf_iterator<char>());
  }

  // Run the benchmark
  for (auto _ : state) {
    for (auto &inputContent : inputContents) {
      auto output = solution(inputContent);
      benchmark::DoNotOptimize(output);
    }
  }
}

// Register the function as a benchmark and measure time in microseconds
BENCHMARK(bench1)->Unit(benchmark::kMicrosecond);

int main(int argc, char **argv) {
  constexpr int mandatoryArgumentsCount = 1;
  if (argc < 1 + mandatoryArgumentsCount) {
    std::cerr << "Usage: lab path/to/inputs [gbench args]" << std::endl;
    return 1;
  }
  inputsDirName = argv[1];

  ::benchmark::Initialize(&argc, argv);
  if (::benchmark::ReportUnrecognizedArguments(argc - mandatoryArgumentsCount,
                                               argv + mandatoryArgumentsCount))
    return 1;
  ::benchmark::RunSpecifiedBenchmarks();
  return 0;
}



================================================
FILE: labs/core_bound/compiler_intrinsics_2/CMakeLists.txt
================================================
cmake_minimum_required(VERSION 3.3)

project(lab)

set(VALIDATE_ARGS "${CMAKE_CURRENT_SOURCE_DIR}/inputs/")
set(LAB_ARGS "${CMAKE_CURRENT_SOURCE_DIR}/inputs/")

string(REGEX MATCH "^(.*)[\\/]labs[\\/].*$" repo "${CMAKE_CURRENT_SOURCE_DIR}")
include(${CMAKE_MATCH_1}/tools/labs.cmake)



================================================
FILE: labs/core_bound/compiler_intrinsics_2/solution.cpp
================================================
#include "solution.hpp"
#include <iostream>

// Find the longest line in a file.
// Implementation uses ternary operator with a hope that compiler will
// turn it into a CMOV instruction.
// The code inside the inner loop is equivalent to:
/*
if (s == '\n') {
  longestLine = std::max(curLineLength, longestLine);
  curLineLength = 0;
} else {
  curLineLength++;
}*/
unsigned solution(const std::string &inputContents) {
  unsigned longestLine = 0;
  unsigned curLineLength = 0;

  for (auto s : inputContents) {
    curLineLength = (s == '\n') ? 0 : curLineLength + 1;
    longestLine = std::max(curLineLength, longestLine);
  }

  return longestLine;
}



================================================
FILE: labs/core_bound/compiler_intrinsics_2/solution.hpp
================================================
#include <string>

unsigned solution(const std::string &inputContents);


================================================
FILE: labs/core_bound/compiler_intrinsics_2/validate.cpp
================================================

#include "solution.hpp"
#include <filesystem>
#include <fstream>
#include <iostream>
#include <vector>

unsigned original_solution(const std::string &inputContents) {
  unsigned longestLine = 0;
  unsigned curLineLength = 0;
  for (auto s : inputContents) {
    if (s == '\n') {
      longestLine = std::max(curLineLength, longestLine);
      curLineLength = 0;
    } else {
      curLineLength++;
    }
  }
  // if no end-of-line in the end
  longestLine = std::max(curLineLength, longestLine);
  return longestLine;
}

int main(int argc, char **argv) {
  constexpr int mandatoryArgumentsCount = 1;
  if (argc != 1 + mandatoryArgumentsCount) {
    std::cerr << "Usage: lab path/to/inputs" << std::endl;
    return 1;
  }
  const std::string inputsDirName = argv[1];
  // feel free to comment out tests for debugging
  const std::vector<std::string> inputs = {
      "test1.txt",               // basic test
      "test2.txt",               // no end-of-line in the end
      "test3.txt",               // small number of characters
      "LoopVectorize.cpp",       // a large C++ file from the LLVM compiler.
      "MarkTwain-TomSawyer.txt", // a typical text file with long lines.
      "counter-example.txt"      // input where sequential solution is faster
  };

  bool valid = true;
  for (auto &input : inputs) {
    std::filesystem::path inputsDirPath = inputsDirName;
    inputsDirPath.append(input);
    std::ifstream inFile{inputsDirPath.string()};
    if (!inFile) {
      std::cerr << "Validation Failed. No input file: "
                << inputsDirPath.string() << "\n";
      return 1;
    }
    std::string inputContents{std::istreambuf_iterator<char>(inFile),
                              std::istreambuf_iterator<char>()};
    auto original_result = original_solution(inputContents);
    auto result = solution(inputContents);
    if (original_result != result) {
      std::cerr << "Validation Failed on test input: " << input
                << ". Original result = " << original_result
                << "; Modified version returned = " << result << "\n";
      valid = false;
    }
  }

  if (!valid)
    return 1;

  std::cout << "Validation Successful" << std::endl;
  return 0;
}



================================================
FILE: labs/core_bound/compiler_intrinsics_2/inputs/counter-example.txt
================================================
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1
1


================================================
FILE: labs/core_bound/compiler_intrinsics_2/inputs/MarkTwain-TomSawyer.txt
================================================
Produced by David Widger. The previous edition was updated by Jose
Menendez.

                   THE ADVENTURES OF TOM SAWYER
                                BY
                            MARK TWAIN
                     (Samuel Langhorne Clemens)




                           P R E F A C E

MOST of the adventures recorded in this book really occurred; one or
two were experiences of my own, the rest those of boys who were
schoolmates of mine. Huck Finn is drawn from life; Tom Sawyer also, but
not from an individual--he is a combination of the characteristics of
three boys whom I knew, and therefore belongs to the composite order of
architecture.

The odd superstitions touched upon were all prevalent among children
and slaves in the West at the period of this story--that is to say,
thirty or forty years ago.

Although my book is intended mainly for the entertainment of boys and
girls, I hope it will not be shunned by men and women on that account,
for part of my plan has been to try to pleasantly remind adults of what
they once were themselves, and of how they felt and thought and talked,
and what queer enterprises they sometimes engaged in.

                                                            THE AUTHOR.

HARTFORD, 1876.



                          T O M   S A W Y E R

"TOM!"

No answer.

"TOM!"

No answer.

"What's gone with that boy, I wonder? You TOM!"

No answer.

The old lady pulled her spectacles down and looked over them about the room; then she put them up and looked out under them. She seldom or never looked THROUGH them for so small a thing as a boy; they were her state pair, the pride of her heart, and were built for "style," not service—she could have seen through a pair of stove–lids just as well. She looked perplexed for a moment, and then said, not fiercely, but still loud enough for the furniture to hear:

"Well, I lay if I get hold of you I'll—"

She did not finish, for by this time she was bending down and punching under the bed with the broom, and so she needed breath to punctuate the punches with. She resurrected nothing but the cat.

"I never did see the beat of that boy!"

She went to the open door and stood in it and looked out among the tomato vines and "jimpson" weeds that constituted the garden. No Tom. So she lifted up her voice at an angle calculated for distance and shouted:

"Y–o–u–u TOM!"

There was a slight noise behind her and she turned just in time to seize a small boy by the slack of his roundabout and arrest his flight.

"There! I might 'a' thought of that closet. What you been doing in there?"

"Nothing."

"Nothing! Look at your hands. And look at your mouth. What IS that truck?"

"I don't know, aunt."

"Well, I know. It's jam—that's what it is. Forty times I've said if you didn't let that jam alone I'd skin you. Hand me that switch."

The switch hovered in the air—the peril was desperate—

"My! Look behind you, aunt!"

The old lady whirled round, and snatched her skirts out of danger. The lad fled on the instant, scrambled up the high board–fence, and disappeared over it.

His aunt Polly stood surprised a moment, and then broke into a gentle laugh.

"Hang the boy, can't I never learn anything? Ain't he played me tricks enough like that for me to be looking out for him by this time? But old fools is the biggest fools there is. Can't learn an old dog new tricks, as the saying is. But my goodness, he never plays them alike, two days, and how is a body to know what's coming? He 'pears to know just how long he can torment me before I get my dander up, and he knows if he can make out to put me off for a minute or make me laugh, it's all down again and I can't hit him a lick. I ain't doing my duty by that boy, and that's the Lord's truth, goodness knows. Spare the rod and spile the child, as the Good Book says. I'm a laying up sin and suffering for us both, I know. He's full of the Old Scratch, but laws–a–me! he's my own dead sister's boy, poor thing, and I ain't got the heart to lash him, somehow. Every time I let him off, my conscience does hurt me so, and every time I hit him my old heart most breaks. Well–a–well, man that is born of woman is of few days and full of trouble, as the Scripture says, and I reckon it's so. He'll play hookey this evening, * and [* Southwestern for "afternoon"] I'll just be obleeged to make him work, to–morrow, to punish him. It's mighty hard to make him work Saturdays, when all the boys is having holiday, but he hates work more than he hates anything else, and I've GOT to do some of my duty by him, or I'll be the ruination of the child."

Tom did play hookey, and he had a very good time. He got back home barely in season to help Jim, the small colored boy, saw next–day's wood and split the kindlings before supper—at least he was there in time to tell his adventures to Jim while Jim did three–fourths of the work. Tom's younger brother (or rather half–brother) Sid was already through with his part of the work (picking up chips), for he was a quiet boy, and had no adventurous, troublesome ways.

While Tom was eating his supper, and stealing sugar as opportunity offered, Aunt Polly asked him questions that were full of guile, and very deep—for she wanted to trap him into damaging revealments. Like many other simple–hearted souls, it was her pet vanity to believe she was endowed with a talent for dark and mysterious diplomacy, and she loved to contemplate her most transparent devices as marvels of low cunning. Said she:

"Tom, it was middling warm in school, warn't it?"

"Yes'm."

"Powerful warm, warn't it?"

"Yes'm."

"Didn't you want to go in a–swimming, Tom?"

A bit of a scare shot through Tom—a touch of uncomfortable suspicion. He searched Aunt Polly's face, but it told him nothing. So he said:

"No'm—well, not very much."

The old lady reached out her hand and felt Tom's shirt, and said:

"But you ain't too warm now, though." And it flattered her to reflect that she had discovered that the shirt was dry without anybody knowing that that was what she had in her mind. But in spite of her, Tom knew where the wind lay, now. So he forestalled what might be the next move:

"Some of us pumped on our heads—mine's damp yet. See?"

Aunt Polly was vexed to think she had overlooked that bit of circumstantial evidence, and missed a trick. Then she had a new inspiration:

"Tom, you didn't have to undo your shirt collar where I sewed it, to pump on your head, did you? Unbutton your jacket!"

The trouble vanished out of Tom's face. He opened his jacket. His shirt collar was securely sewed.

"Bother! Well, go 'long with you. I'd made sure you'd played hookey and been a–swimming. But I forgive ye, Tom. I reckon you're a kind of a singed cat, as the saying is—better'n you look. THIS time."

She was half sorry her sagacity had miscarried, and half glad that Tom had stumbled into obedient conduct for once.

But Sidney said:

"Well, now, if I didn't think you sewed his collar with white thread, but it's black."

"Why, I did sew it with white! Tom!"

But Tom did not wait for the rest. As he went out at the door he said:

"Siddy, I'll lick you for that."

In a safe place Tom examined two large needles which were thrust into the lapels of his jacket, and had thread bound about them—one needle carried white thread and the other black. He said:

"She'd never noticed if it hadn't been for Sid. Confound it! sometimes she sews it with white, and sometimes she sews it with black. I wish to geeminy she'd stick to one or t'other—I can't keep the run of 'em. But I bet you I'll lam Sid for that. I'll learn him!"

He was not the Model Boy of the village. He knew the model boy very well though—and loathed him.

Within two minutes, or even less, he had forgotten all his troubles. Not because his troubles were one whit less heavy and bitter to him than a man's are to a man, but because a new and powerful interest bore them down and drove them out of his mind for the time—just as men's misfortunes are forgotten in the excitement of new enterprises. This new interest was a valued novelty in whistling, which he had just acquired from a negro, and he was suffering to practise it undisturbed. It consisted in a peculiar bird–like turn, a sort of liquid warble, produced by touching the tongue to the roof of the mouth at short intervals in the midst of the music—the reader probably remembers how to do it, if he has ever been a boy. Diligence and attention soon gave him the knack of it, and he strode down the street with his mouth full of harmony and his soul full of gratitude. He felt much as an astronomer feels who has discovered a new planet—no doubt, as far as strong, deep, unalloyed pleasure is concerned, the advantage was with the boy, not the astronomer.

The summer evenings were long. It was not dark, yet. Presently Tom checked his whistle. A stranger was before him—a boy a shade larger than himself. A new–comer of any age or either sex was an impressive curiosity in the poor little shabby village of St. Petersburg. This boy was well dressed, too—well dressed on a week–day. This was simply astounding. His cap was a dainty thing, his close–buttoned blue cloth roundabout was new and natty, and so were his pantaloons. He had shoes on—and it was only Friday. He even wore a necktie, a bright bit of ribbon. He had a citified air about him that ate into Tom's vitals. The more Tom stared at the splendid marvel, the higher he turned up his nose at his finery and the shabbier and shabbier his own outfit seemed to him to grow. Neither boy spoke. If one moved, the other moved—but only sidewise, in a circle; they kept face to face and eye to eye all the time. Finally Tom said:

"I can lick you!"

"I'd like to see you try it."

"Well, I can do it."

"No you can't, either."

"Yes I can."

"No you can't."

"I can."

"You can't."

"Can!"

"Can't!"

An uncomfortable pause. Then Tom said:

"What's your name?"

"'Tisn't any of your business, maybe."

"Well I 'low I'll MAKE it my business."

"Well why don't you?"

"If you say much, I will."

"Much—much—MUCH. There now."

"Oh, you think you're mighty smart, DON'T you? I could lick you with one hand tied behind me, if I wanted to."

"Well why don't you DO it? You SAY you can do it."

"Well I WILL, if you fool with me."

"Oh yes—I've seen whole families in the same fix."

"Smarty! You think you're SOME, now, DON'T you? Oh, what a hat!"

"You can lump that hat if you don't like it. I dare you to knock it off—and anybody that'll take a dare will suck eggs."

"You're a liar!"

"You're another."

"You're a fighting liar and dasn't take it up."

"Aw—take a walk!"

"Say—if you give me much more of your sass I'll take and bounce a rock off'n your head."

"Oh, of COURSE you will."

"Well I WILL."

"Well why don't you DO it then? What do you keep SAYING you will for? Why don't you DO it? It's because you're afraid."

"I AIN'T afraid."

"You are."

"I ain't."

"You are."

Another pause, and more eying and sidling around each other. Presently they were shoulder to shoulder. Tom said:

"Get away from here!"

"Go away yourself!"

"I won't."

"I won't either."

So they stood, each with a foot placed at an angle as a brace, and both shoving with might and main, and glowering at each other with hate. But neither could get an advantage. After struggling till both were hot and flushed, each relaxed his strain with watchful caution, and Tom said:

"You're a coward and a pup. I'll tell my big brother on you, and he can thrash you with his little finger, and I'll make him do it, too."

"What do I care for your big brother? I've got a brother that's bigger than he is—and what's more, he can throw him over that fence, too." [Both brothers were imaginary.]

"That's a lie."

"YOUR saying so don't make it so."

Tom drew a line in the dust with his big toe, and said:

"I dare you to step over that, and I'll lick you till you can't stand up. Anybody that'll take a dare will steal sheep."

The new boy stepped over promptly, and said:

"Now you said you'd do it, now let's see you do it."

"Don't you crowd me now; you better look out."

"Well, you SAID you'd do it—why don't you do it?"

"By jingo! for two cents I WILL do it."

The new boy took two broad coppers out of his pocket and held them out with derision. Tom struck them to the ground. In an instant both boys were rolling and tumbling in the dirt, gripped together like cats; and for the space of a minute they tugged and tore at each other's hair and clothes, punched and scratched each other's nose, and covered themselves with dust and glory. Presently the confusion took form, and through the fog of battle Tom appeared, seated astride the new boy, and pounding him with his fists. "Holler 'nuff!" said he.

The boy only struggled to free himself. He was crying—mainly from rage.

"Holler 'nuff!"—and the pounding went on.

At last the stranger got out a smothered "'Nuff!" and Tom let him up and said:

"Now that'll learn you. Better look out who you're fooling with next time."

The new boy went off brushing the dust from his clothes, sobbing, snuffling, and occasionally looking back and shaking his head and threatening what he would do to Tom the "next time he caught him out." To which Tom responded with jeers, and started off in high feather, and as soon as his back was turned the new boy snatched up a stone, threw it and hit him between the shoulders and then turned tail and ran like an antelope. Tom chased the traitor home, and thus found out where he lived. He then held a position at the gate for some time, daring the enemy to come outside, but the enemy only made faces at him through the window and declined. At last the enemy's mother appeared, and called Tom a bad, vicious, vulgar child, and ordered him away. So he went away; but he said he "'lowed" to "lay" for that boy.

He got home pretty late that night, and when he climbed cautiously in at the window, he uncovered an ambuscade, in the person of his aunt; and when she saw the state his clothes were in her resolution to turn his Saturday holiday into captivity at hard labor became adamantine in its firmness.


================================================
FILE: labs/core_bound/compiler_intrinsics_2/inputs/test1.txt
================================================
This line is 32 chracters long..
This line is 40 chracters long..........
This line is 30 chracters long
This line is 41 chracters long...........
This line is 39 chracters long.........

eof



================================================
FILE: labs/core_bound/compiler_intrinsics_2/inputs/test2.txt
================================================
.....
.....
.....
.....
.....
.....
..........


================================================
FILE: labs/core_bound/compiler_intrinsics_2/inputs/test3.txt
================================================
...
..
....
.


================================================
FILE: labs/core_bound/compiler_intrinsics_3/README.md
================================================
This is a third lab about using [compiler intrinsics](https://en.wikipedia.org/wiki/Intrinsic_function) to speed up parts of the code, where compilers fail to generate optimal code.

The task of this lab is to find the average position of a series of positions in 3d space:
```
struct Position {
    u32 x;
    u32 y;
    u32 z;
}
...
    u64 x = 0;
    u64 y = 0;
    u64 z = 0;

    for (Position pos: input) {
        x += pos.x; // extend 32 bit to 64 bit and accumulate
        y += pos.y;
        z += pos.z;
    }
```

Currently, compilers fail to vectorize it for x86. However, for ARM they generate clever code using their magic LDM instruction that deinterleaves the XYZ components. [^1] However, we can still vectorize it more efficiently.

To vectorize this loop manually, think about the memory layout and operations applied to the elements.

Caveat: current benchmark processes 16k positions, which takes 192KB of space (`12 bytes * 16K positions`). As the input size grows, the benchmarks becomes more memory bound which reduces the gains. 

**The lab is contributed by Jonathan Hallström (@JonathanHallstrom).**

[^1]: Here is an example of the ARM's LDM instruction.
    ```asm
    // Assume input points to an array of structures {u32 x, u32 y, u32 z}
    LD3 {V0.4S, V1.4S, V2.4S}, [input] // Load 4 positions at once (each containing xyz elements) 
    // After that:
    //  V0.4S will have four X coordinates,
    //  V1.4S will have four Y coordinates,
    //  V2.4S will have four Z coordinates,
    // Reducing vectors with such a friendly layout is much easier.
    ```


================================================
FILE: labs/core_bound/compiler_intrinsics_3/bench.cpp
================================================

#include "benchmark/benchmark.h"
#include "solution.hpp"
#include <cstdint>
#include <random>
#include <vector>

static std::string inputsDirName;

static void bench1(benchmark::State &state) {

  std::vector<Position<std::uint32_t>> input;
  std::default_random_engine eng{};
  std::uniform_int_distribution<std::uint32_t> distr;
  for (std::size_t i = 0; i < (64 << 8); ++i) {

    input.push_back(Position<std::uint32_t>{distr(eng), distr(eng), distr(eng)});
  }
  // Run the benchmark
  for (auto _: state) {
    auto output = solution(input);
    benchmark::DoNotOptimize(input);
    benchmark::DoNotOptimize(output);
  }
}

// Register the function as a benchmark and measure time in microseconds
BENCHMARK(bench1)->Unit(benchmark::kMicrosecond);

int main(int argc, char **argv) {
  ::benchmark::Initialize(&argc, argv);
  ::benchmark::RunSpecifiedBenchmarks();
  return 0;
}



================================================
FILE: labs/core_bound/compiler_intrinsics_3/CMakeLists.txt
================================================
cmake_minimum_required(VERSION 3.3)

project(lab)

string(REGEX MATCH "^(.*)[\\/]labs[\\/].*$" repo "${CMAKE_CURRENT_SOURCE_DIR}")
include(${CMAKE_MATCH_1}/tools/labs.cmake)



================================================
FILE: labs/core_bound/compiler_intrinsics_3/solution.cpp
================================================
#include "solution.hpp"
#include <algorithm>

Position<std::uint32_t> solution(std::vector<Position<std::uint32_t>> const &input) {
  std::uint64_t x = 0;
  std::uint64_t y = 0;
  std::uint64_t z = 0;

  for (auto pos: input) {
    x += pos.x;
    y += pos.y;
    z += pos.z;
  }

  return {
          static_cast<std::uint32_t>(x / std::max<std::uint64_t>(1, input.size())),
          static_cast<std::uint32_t>(y / std::max<std::uint64_t>(1, input.size())),
          static_cast<std::uint32_t>(z / std::max<std::uint64_t>(1, input.size())),
  };
}


================================================
FILE: labs/core_bound/compiler_intrinsics_3/solution.hpp
================================================
#include <cstdint>
#include <iostream>
#include <ostream>
#include <vector>

template<class T>
struct Position {
  T x;
  T y;
  T z;

  constexpr bool operator==(Position const &other) const {
    return x == other.x and y == other.y and z == other.z;
  }

  constexpr bool operator!=(Position const &other) const {
    return !(*this == other);
  }
};

template<class T>
constexpr std::ostream &operator<<(std::ostream &oss, Position<T> position) {
  return oss << '(' << position.x << ", " << position.y << ", " << position.z << ')';
}

Position<std::uint32_t> solution(std::vector<Position<std::uint32_t>> const &input);



================================================
FILE: labs/core_bound/compiler_intrinsics_3/validate.cpp
================================================

#include "solution.hpp"
#include <iostream>
#include <limits>
#include <random>
#include <sstream>
#include <vector>


Position<std::uint32_t> original_solution(std::vector<Position<std::uint32_t>> const &input) {
  std::uint64_t x = 0;
  std::uint64_t y = 0;
  std::uint64_t z = 0;

  for (auto pos: input) {
    x += pos.x;
    y += pos.y;
    z += pos.z;
  }

  return {
          static_cast<std::uint32_t>(x / std::max<std::uint64_t>(1, input.size())),
          static_cast<std::uint32_t>(y / std::max<std::uint64_t>(1, input.size())),
          static_cast<std::uint32_t>(z / std::max<std::uint64_t>(1, input.size())),
  };
}

// adds 1000 random inputs with lengths from 1 to 1000
void addSmallRandomInputs(std::vector<std::vector<Position<std::uint32_t>>> &inputs) {
  std::vector<Position<std::uint32_t>> input;
  std::default_random_engine eng{};
  std::uniform_int_distribution<std::uint32_t> distr;
  for (std::size_t i = 0; i < 1000; ++i) {
    input.push_back(Position<std::uint32_t>{distr(eng), distr(eng), distr(eng)});
    inputs.push_back(input);
  }
}

int main(int argc, char **argv) {
  // feel free to comment out tests for debugging
  const std::uint32_t biggest_coord = std::numeric_limits<std::uint32_t>::max();

  const Position<std::uint32_t> biggest_possible_position = {biggest_coord, biggest_coord, biggest_coord};

  std::vector<std::vector<Position<std::uint32_t>>> inputs = {
          {}, // empty vector
          {{0, 0, 0}},
          {{1, 1, 1}, {2, 2, 2}, {3, 3, 3}},
          {{1, 1, 1}, {2, 2, 2}, {3, 3, 3}, {4, 4, 4}, {5, 5, 5}, {6, 6, 6}, {7, 7, 7}, {8, 8, 8}, {9, 9, 9}, {10, 10, 10}, {11, 11, 11}, {12, 12, 12}, {13, 13, 13}, {14, 14, 14}, {15, 15, 15}, {16, 16, 16}},
          {biggest_possible_position, biggest_possible_position}, // make changing the accumulators to u32 overflow
          {biggest_possible_position, {1, 1, 1}},
  };

  addSmallRandomInputs(inputs);

  bool valid = true;
  for (auto &input: inputs) {
    auto original_result = original_solution(input);
    auto result = solution(input);

    if (original_result != result) {
      std::stringstream iss;
      iss << '{';
      bool first = true;
      for (auto pos: input) {
        if (!first) iss << ", ";
        iss << pos;
        first = false;
      }
      std::cerr << "Validation Failed on test input: " << iss.str()
                << ". Original result = " << original_result
                << "; Modified version returned = " << result << "\n";
      valid = false;
    }
  }

  if (!valid)
    return 1;

  std::cout << "Validation Successful" << std::endl;
  return 0;
}



================================================
FILE: labs/core_bound/compiler_intrinsics_4/README.md
================================================
This lab calculates an image of [Mandelbrot set](https://en.wikipedia.org/wiki/Mandelbrot_set). In this algorithm, you can process each pixel independently, however, the number of iterations for processing each pixel can be different. The issue you will face when you process two pixels in a SIMD fashion: what to do when the processing loop for one pixel finishes after 100 iterations while for the adjacent pixel it runs for 200 iterations?

The `-ffast-math` option is disabled for validation purposes. It doesn't help compiler to autovectorize the code.

Lab assignment developed by Oleg Makovski (@0legmak).



================================================
FILE: labs/core_bound/compiler_intrinsics_4/bench.cpp
================================================
#include "data_paths.h"
#include "picture.h"
#include "solution.h"

#include "benchmark/benchmark.h"

#include <iostream>
#include <fstream>

namespace {

constexpr auto kImageWidth = 1280;
constexpr auto kImageHeight = 720;

bool image_saved = false;

void bench1(benchmark::State& state) {
  std::vector<short> data;
  for (auto _ : state) {
    data = mandelbrot(kImageWidth, kImageHeight);
  }
  if (!image_saved) {
    image_saved = true;
    std::cout << "Saving image to " << benchmark_image_path << std::endl;
    std::ofstream(benchmark_image_path, std::ios::binary) << generate_ppm_image(data, kImageWidth, kImageHeight);
  }
}

}  // namespace

BENCHMARK(bench1)->Unit(benchmark::kMillisecond);

BENCHMARK_MAIN();



================================================
FILE: labs/core_bound/compiler_intrinsics_4/CMakeLists.txt
================================================
cmake_minimum_required(VERSION 3.3)

project(lab)

set(CMAKE_CXX_STANDARD 20)
# -ffast-math is disabled for validation purposes; it doesn't help compiler to autovectorize the code.
set(DISABLE_FAST_MATH 1)

set(LAB_DATA_PATH "${CMAKE_CURRENT_SOURCE_DIR}/data")
# Create the directory if it does not exist
file(MAKE_DIRECTORY ${LAB_DATA_PATH})
cmake_path(SET VALIDATION_IMAGE_PATH "${LAB_DATA_PATH}/validation_user.ppm")
cmake_path(SET REFERENCE_IMAGE_PATH "${LAB_DATA_PATH}/validation_reference.ppm")
cmake_path(SET BENCHMARK_IMAGE_PATH "${LAB_DATA_PATH}/benchmark_output.ppm")
configure_file(data_paths.h.in "${CMAKE_CURRENT_BINARY_DIR}/data_paths.h")

include_directories(${CMAKE_CURRENT_BINARY_DIR})

string(REGEX MATCH "^(.*)[\\/]labs[\\/].*$" repo "${CMAKE_CURRENT_SOURCE_DIR}")
include(${CMAKE_MATCH_1}/tools/labs.cmake)



================================================
FILE: labs/core_bound/compiler_intrinsics_4/const.h
================================================
constexpr auto kMaxIterations = 2000;
constexpr auto kSquareBound = 4.0;
constexpr auto kCenterX = -0.743643135;
constexpr auto kCenterY = 0.131825963;
constexpr auto kDiameterX = 0.000014628;



================================================
FILE: labs/core_bound/compiler_intrinsics_4/data_paths.h.in
================================================
constexpr auto validation_image_path = "@VALIDATION_IMAGE_PATH@";
constexpr auto reference_image_path = "@REFERENCE_IMAGE_PATH@";
constexpr auto benchmark_image_path = "@BENCHMARK_IMAGE_PATH@";



================================================
FILE: labs/core_bound/compiler_intrinsics_4/picture.cpp
================================================
#include "picture.h"
#include "const.h"

#include <array>
#include <cstdint>
#include <numeric>
#include <vector>

namespace {

constexpr auto kScale = 1.0;
constexpr auto kOffset = 0.0;
constexpr double kGaussKernel[3][3] = {
  { 1.0 / 16, 2.0 / 16, 1.0 / 16 },
  { 2.0 / 16, 4.0 / 16, 2.0 / 16 },
  { 1.0 / 16, 2.0 / 16, 1.0 / 16 }
};

struct Point {
  double x;
  double y;
};

constexpr size_t kColorCnt = 3;

using RGB = std::array<uint8_t, kColorCnt>;
using Gradient = std::array<std::vector<Point>, kColorCnt>;

constexpr auto kBackgroundColor = RGB{0, 0, 0};
const Gradient kGradient = {{
  { {0.0, 0.0}, {0.7, 1.0}, {1.0, 0.0} },
  { {0.0, 0.0}, {0.5, 1.0}, {1.0, 0.0} },
  { {0.0, 0.0}, {0.3, 1.0}, {1.0, 0.0} },
}};

class CubicBezier {
public:
  CubicBezier() = default;
  CubicBezier(const Point p0, const Point p1, const Point p2, const Point p3) noexcept
    : p0(p0), p1(p1), p2(p2), p3(p3) 
  {}
  Point calculate(double t) const noexcept {
    const double t_2 = t * t;
    const double t_3 = t_2 * t;
    const double u = 1 - t;
    const double u_2 = u * u;
    const double u_3 = u_2 * u;
    Point result;
    result.x = u_3 * p0.x + 3 * u_2 * t * p1.x + 3 * u * t_2 * p2.x + t_3 * p3.x;
    result.y = u_3 * p0.y + 3 * u_2 * t * p1.y + 3 * u * t_2 * p2.y + t_3 * p3.y;
    return result;
  }
private:
  Point p0;
  Point p1;
  Point p2;
  Point p3;
};

double lerp(const Point p1, const Point p2, double x) {
  const auto dx = p2.x - p1.x;
  const auto dy = p2.y - p1.y;
  return p1.y + dy * (x - p1.x) / dx;
}

std::vector<RGB> calc_color_map() {
  constexpr int size = kMaxIterations;
  std::array<std::vector<Point>, kColorCnt> interpolated;
  for (int c = 0; c < kColorCnt; ++c) {
    interpolated[c].resize(size);
    int c_idx = 0;
    double c_x1, c_x2;
    CubicBezier bezier;
    auto update_curve = [&]() {
      const auto p1 = kGradient[c][c_idx];
      const auto p2 = kGradient[c][c_idx + 1];
      const double mid_x = std::midpoint(p1.x, p2.x);
      bezier = CubicBezier(p1, {mid_x, p1.y}, {mid_x, p2.y}, p2);
      c_x1 = p1.x;
      c_x2 = p2.x;
    };
    update_curve();
    for (int idx = 0; idx < size; ++idx) {
      const double x = 1.0 * idx / (size - 1);
      if (x > kGradient[c][c_idx + 1].x) {
        do {
          ++c_idx;
        } while (x > kGradient[c][c_idx + 1].x);
        update_curve();
      }
      const double t = (x - c_x1) / (c_x2 - c_x1);
      interpolated[c][idx] = bezier.calculate(t);
    }
  }
  std::vector<RGB> colors(size);
  for (int c = 0; c < kColorCnt; ++c) {
    int in_idx = 0;
    for (int out_idx = 0; out_idx < size; ++out_idx) {
      const double x = 1.0 * out_idx / (size - 1);
      while (in_idx < size && interpolated[c][in_idx].x < x) {
        ++in_idx;
      }
      double res;
      if (in_idx + 1 < size) {
        res = lerp(interpolated[c][in_idx], interpolated[c][in_idx + 1], x);
      } else {
        res = interpolated[c].back().y;
      }
      colors[out_idx][c] = std::min(static_cast<int>(res * 256), 255);
    }
  }
  std::vector<RGB> result(size + 1);
  for (int i = 0; i < size; ++i) {
    result[i] = colors[static_cast<int>(i * kScale + kOffset * size) % size];
  }
  result[size] = kBackgroundColor;
  return result;
}

RGB gaussian_blur(const RGB input[3][3]) {
  std::array<double, 3> output{};
  for (int x = 0; x < 3; ++x) {
    for (int y = 0; y < 3; ++y) {
      for (int c = 0; c < 3; ++c) {
        output[c] += input[x][y][c] * kGaussKernel[x][y];
      }
    }
  }
  return {
    static_cast<uint8_t>(output[0]),
    static_cast<uint8_t>(output[1]),
    static_cast<uint8_t>(output[2]),
  };
}

}  // namespace

std::string generate_ppm_image(const std::vector<short>& data, int image_width, int image_height) {
  const auto data_width = image_width + 2;
  std::string out;
  out.append("P6\n");
  out.append(std::to_string(image_width));
  out.push_back(' ');
  out.append(std::to_string(image_height));
  out.push_back('\n');
  out.append("255\n");
  out.reserve(out.size() + image_width * image_height * sizeof(RGB));
  RGB color_matrix[3][3];
  const auto color_map = calc_color_map();
  for (int py = 0; py < image_height; ++py) {
    for (int x = 0; x < 2; ++x) {
      for (int y = 0; y < 3; ++y) {
        color_matrix[x + 1][y] = color_map[data[(py + y) * data_width + x]];
      }
    }
    for (int px = 0; px < image_width; ++px) {
      for (int y = 0; y < 3; ++y) {
        color_matrix[0][y] = color_matrix[1][y];
        color_matrix[1][y] = color_matrix[2][y];
        color_matrix[2][y] = color_map[data[(py + y) * data_width + px + 2]];
      }
      const auto color = gaussian_blur(color_matrix);
      out.append(color.begin(), color.end());
    }
  }
  return out;
}



================================================
FILE: labs/core_bound/compiler_intrinsics_4/picture.h
================================================
#include <string>
#include <vector>

std::string generate_ppm_image(const std::vector<short>& data, int image_width, int image_height);



================================================
FILE: labs/core_bound/compiler_intrinsics_4/solution.cpp
================================================
#include "const.h"
#include "solution.h"

std::vector<short> mandelbrot(int image_width, int image_height) {
  const auto data_width = image_width + 2;
  const auto data_height = image_height + 2;
  const auto diameter_y = kDiameterX / image_width * image_height;
  const auto min_x = kCenterX - kDiameterX / 2;
  const auto max_x = kCenterX + kDiameterX / 2;
  const auto min_y = kCenterY - diameter_y / 2;
  const auto max_y = kCenterY + diameter_y / 2;
  std::vector<short> result(data_width * data_height);
  auto result_idx = 0;
  for (auto py = 0; py < data_height; ++py) {
    for (auto px = 0; px < data_width; ++px) {
      const auto c_x = min_x + (max_x - min_x) * px / data_width;
      const auto c_y = min_y + (max_y - min_y) * py / data_height;
      auto z_x = 0.0;
      auto z_y = 0.0;
      auto iter_cnt = 0;
      for (; iter_cnt < kMaxIterations; ++iter_cnt) {
        const auto z_xx = z_x * z_x;
        const auto z_yy = z_y * z_y;
        if (z_xx + z_yy > kSquareBound) {
          break;
        }
        const auto z_xy = z_x * z_y;
        z_x = z_xx - z_yy + c_x;
        z_y = z_xy + z_xy + c_y;
      }
      result[result_idx++] = iter_cnt;
    }
  }
  return result;
}



================================================
FILE: labs/core_bound/compiler_intrinsics_4/solution.h
================================================
#include <vector>

std::vector<short> mandelbrot(int width, int height);



================================================
FILE: labs/core_bound/compiler_intrinsics_4/validate.cpp
================================================
#include "const.h"
#include "data_paths.h"
#include "picture.h"
#include "solution.h"

#include <algorithm>
#include <cmath>
#include <fstream>
#include <iostream>

namespace {

constexpr auto kImageWidth = 640;
constexpr auto kImageHeight = 360;

std::vector<short> reference_mandelbrot(int image_width, int image_height) {
  const auto data_width = image_width + 2;
  const auto data_height = image_height + 2;
  const auto diameter_y = kDiameterX / image_width * image_height;
  const auto min_x = kCenterX - kDiameterX / 2;
  const auto max_x = kCenterX + kDiameterX / 2;
  const auto min_y = kCenterY - diameter_y / 2;
  const auto max_y = kCenterY + diameter_y / 2;
  std::vector<short> result(data_width * data_height);
  auto result_idx = 0;
  for (auto py = 0; py < data_height; ++py) {
    for (auto px = 0; px < data_width; ++px) {
      const auto c_x = std::lerp(min_x, max_x, 1.0 * px / data_width);
      const auto c_y = std::lerp(min_y, max_y, 1.0 * py / data_height);
      auto z_x = 0.0;
      auto z_y = 0.0;
      auto iter_cnt = 0;
      for (; iter_cnt < kMaxIterations; ++iter_cnt) {
        const auto z_xx = z_x * z_x;
        const auto z_yy = z_y * z_y;
        if (z_xx + z_yy > kSquareBound) {
          break;
        }
        const auto z_xy = z_x * z_y;
        z_x = z_xx - z_yy + c_x;
        z_y = z_xy + z_xy + c_y;
      }
      result[result_idx++] = iter_cnt;
    }
  }
  return result;
}

} // namespace

int main() {
  const auto ref_data = reference_mandelbrot(kImageWidth, kImageHeight);
  const auto data = mandelbrot(kImageWidth, kImageHeight);

  if (data.size() != ref_data.size()) {
    std::cerr << "Result has invalid size. Expected size: " << ref_data.size()
              << " received: " << data.size() << std::endl;
    return EXIT_FAILURE;
  }

  std::cout << "Saving image to " << validation_image_path << std::endl;
  std::ofstream(validation_image_path, std::ios::binary) << generate_ppm_image(data, kImageWidth, kImageHeight);
  std::cout << "Saving reference image to " << reference_image_path << std::endl;
  std::ofstream(reference_image_path, std::ios::binary) << generate_ppm_image(ref_data, kImageWidth, kImageHeight);

  const auto cmp_result = std::mismatch(data.begin(), data.end(), ref_data.begin());
  if (cmp_result.first != data.end()) {
    std::cerr << "Validation Failed at position: "
              << std::distance(data.begin(), cmp_result.first)
              << ". Expected: " << *cmp_result.second
              << " received: " << *cmp_result.first
              << "." << std::endl;
    return EXIT_FAILURE;
  }

  std::cout << "Validation Successful" << std::endl;
  return EXIT_SUCCESS;
}



================================================
FILE: labs/core_bound/dep_chains_1/README.md
================================================
# Speed up data dependency chains #1.

[<img src="../../../img/DepChains1.png">](https://www.youtube.com/watch?v=nXf6MxNlXdg&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d)

Critical data dependency chains are increasingly becoming the [only thing that matters](https://easyperf.net/blog/2022/05/11/Visualizing-Performance-Critical-Dependency-Chains) for performance of a general-purpose application. That is why it is very important to identify those and know possible ways to make them run faster. On a SW level, you can sometimes occasionally introduce an artificial data dependency, which should not exist in the first place. Those cases are usually easy to find. In a contrast, some data dependency chains are inherent to a particular type of data structure.

Ahhhh, good old linked lists... Traversing a linked list is essentially a looooooooong data dependency chain. To get the node `N+1` you need to retrieve the node `N` first. Even if we set aside the problem with memory locality, a dependency chain will not go away. The data dependency effectively serializes the execution making your ILP (Instruction-Level Parallelism) be very low.

The task in this lab assignment is to look up all the values from linked list A in linked list B. This is an O(N^2) algorithm and involves a lot of pointer chasing. Both linked lists use an arena allocator to place individual nodes right next to each other, which improves memory locality. To improve performance of the benchmark in this lab assignment even further you need to overlap the execution of multiple dependency chains.

The idea for the lab was proposed by @ibogosavljevic.


================================================
FILE: labs/core_bound/dep_chains_1/arena.hpp
================================================
#include <cstddef>

// Simplest one-time arena allocator
// T - type of objects.
// N - size in bytes.
// Allocate objects of T consecutively.
template <class T, size_t N> class Arena {
public:
  Arena() : curPtr(arena) {}

  Arena(const Arena &) = delete;
  Arena &operator=(const Arena &) = delete;

  T *allocate() {
    auto endPtr = arena + N;
    if (endPtr - curPtr < sizeof(T))
      return nullptr;

    T *savePtr = (T *)curPtr;
    curPtr += sizeof(T);
    return savePtr;
  }
  // no dealloc method - rely on RAII to dealloc arena

private:
  alignas(128) std::byte arena[N];
  std::byte *curPtr = nullptr;
};



================================================
FILE: labs/core_bound/dep_chains_1/bench.cpp
================================================

#include "benchmark/benchmark.h"
#include "solution.hpp"
#include <memory>

static void bench1(benchmark::State &state) {
  // Init benchmark data
  auto arena1 = ArenaListAllocator{};
  auto l1 = getRandomList(arena1);
  auto arena2 = ArenaListAllocator{};
  auto l2 = getRandomList(arena2);

  // Run the benchmark
  for (auto _ : state) {
    auto output = solution(l1, l2);
    benchmark::DoNotOptimize(output);
  }
}

// Register the function as a benchmark and measure time in microseconds
BENCHMARK(bench1)->Unit(benchmark::kMillisecond);

// Run the benchmark
BENCHMARK_MAIN();



================================================
FILE: labs/core_bound/dep_chains_1/CMakeLists.txt
================================================
cmake_minimum_required(VERSION 3.3)

project(lab)

string(REGEX MATCH "^(.*)[\\/]labs[\\/].*$" repo "${CMAKE_CURRENT_SOURCE_DIR}")
include(${CMAKE_MATCH_1}/tools/labs.cmake)



================================================
FILE: labs/core_bound/dep_chains_1/init.cpp
================================================
#include "solution.hpp"
#include <algorithm>
#include <iostream>
#include <limits>
#include <random>

std::vector<unsigned> getRandomVector() {
  std::random_device r;
  std::default_random_engine generator(r());
  std::uniform_int_distribution<unsigned> distribution(
      0, std::numeric_limits<RandomRangeT>::max());

  std::vector<unsigned> retVector;
  retVector.reserve(N);
  // generate random values.
  for (int i = 0; i < N; i++) {
    retVector.push_back(distribution(generator));
  }
  // remove duplicates
  std::sort(retVector.begin(), retVector.end());
  retVector.erase(std::unique(retVector.begin(), retVector.end()),
                  retVector.end());

  // reshuffle
  std::shuffle(std::begin(retVector), std::end(retVector), generator);
  return retVector;
}

List *getRandomList(ArenaListAllocator &allocator) {
  auto createNode = [&](unsigned v) {
    List *n = allocator.allocate();
    if (!n)
      return n; // consider crash
    n->value = v;
    n->next = nullptr;
    return n;
  };

  List *head = createNode(0);
  if (!head)
    return nullptr;

  List *l = head;
  std::vector<unsigned> randoms = getRandomVector();
  for (auto v : randoms) {
    l->next = createNode(v);
    if (!l->next)
      return nullptr; // consider crash
    l = l->next;
  }
  return head;
}

// For debugging
void printList(List *l) {
  while (l) {
    std::cout << l->value << " ";
    l = l->next;
  }
  std::cout << '\n';
}



================================================
FILE: labs/core_bound/dep_chains_1/solution.cpp
================================================
#include "solution.hpp"
#include <array>
#include <iostream>

unsigned getSumOfDigits(unsigned n) {
  unsigned sum = 0;
  while (n != 0) {
    sum = sum + n % 10;
    n = n / 10;
  }
  return sum;
}

// Task: lookup all the values from l2 in l1.
// For every found value, find the sum of its digits.
// Return the sum of all digits in every found number.
// Both lists have no duplicates and elements placed in *random* order.
// Do NOT sort any of the lists. Do NOT store elements in a hash_map/sets.

// Hint: Traversing a linked list is a long data dependency chain:
//       to get the node N+1 you need to retrieve the node N first.
//       Think how you can execute multiple dependency chains in parallel.
unsigned solution(List *l1, List *l2) {
  unsigned retVal = 0;

  List *head2 = l2;
  // O(N^2) algorithm:
  while (l1) {
    unsigned v = l1->value;
    l2 = head2;
    while (l2) {
      if (l2->value == v) {
        retVal += getSumOfDigits(v);
        break;
      }
      l2 = l2->next;
    }
    l1 = l1->next;
  }

  return retVal;
}



================================================
FILE: labs/core_bound/dep_chains_1/solution.hpp
================================================
#include "arena.hpp"
#include <vector>

constexpr unsigned N = 10000;
using RandomRangeT = unsigned short;

struct List {
  List *next;
  unsigned value;
};

using ArenaListAllocator = Arena<List, sizeof(List) * N>;
List *getRandomList(ArenaListAllocator &allocator);
void printList(List *l);

unsigned getSumOfDigits(unsigned n);
unsigned solution(List *l1, List *l2);


================================================
FILE: labs/core_bound/dep_chains_1/validate.cpp
================================================

#include "solution.hpp"
#include <iostream>
#include <memory>

unsigned original_solution(List *l1, List *l2) {
  unsigned retVal = 0;

  List *head2 = l2;
  while (l1) {
    unsigned v = l1->value;
    l2 = head2;
    while (l2) {
      if (l2->value == v) {
        retVal += getSumOfDigits(v);
        break;
      }
      l2 = l2->next;
    }
    l1 = l1->next;
  }

  return retVal;
}

int main() {
  // Init benchmark data
  auto arena1 = ArenaListAllocator{};
  auto l1 = getRandomList(arena1);
  auto arena2 = ArenaListAllocator{};
  auto l2 = getRandomList(arena2);

  auto original_result = original_solution(l1, l2);
  auto result = solution(l1, l2);

  if (original_result != result) {
    std::cerr << "Validation Failed. Original result = " << original_result
              << "; Modified version returned = " << result << "\n";
    return 1;
  }

  std::cout << "Validation Successful" << std::endl;
  return 0;
}



================================================
FILE: labs/core_bound/dep_chains_2/README.md
================================================
**TODO**: add an introductory and a summary videos.

This small program simulates the random particle movement. We have 1000 particles moving on a 2D surface without constraints. It means that there are no bounds, they can move as far from their initial coordinates as they want. Each particle has initial x and y coordinates in the range [-1000,1000] and a constant speed in the range [0;1]. The program simulates 1000 steps of particle movement.

To validate the simulation (final positions of the particles), we use a deterministic random number generator (fake) that uses a global state and thus always generates the same sequence of numbers.

There is one very nasty performance problem that doesn't allow us to run the simulation fast. Can you find a dependency chain in the code and fix it?

Note: your solution is allowed to be not functionally equivalent to the original program if validation still passes. For example, if an RNG will generate a different sequence of random numbers than before - that's OK. Users would not be able to tell the difference since the motion of particles is random anyway.



================================================
FILE: labs/core_bound/dep_chains_2/bench.cpp
================================================

#include "benchmark/benchmark.h"
#include "solution.hpp"

static void bench1(benchmark::State &state) {
  // Init benchmark data
  auto particles = initParticles();

  // Run the benchmark
  for (auto _ : state) {
    randomParticleMotion<XorShift32>(particles, STEPS);
    benchmark::DoNotOptimize(particles);
  }
}

// Register the function as a benchmark and measure time in microseconds
BENCHMARK(bench1)->Unit(benchmark::kMillisecond);

// Run the benchmark
BENCHMARK_MAIN();



================================================
FILE: labs/core_bound/dep_chains_2/CMakeLists.txt
================================================
cmake_minimum_required(VERSION 2.8.12)

project(lab)

# Disable SLP vectorization to isolate the effect of breaking a dependency chain.
set(CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} -fno-slp-vectorize")

macro(remove_cxx_flag flag)
  string(REPLACE "${flag}" "" CMAKE_CXX_FLAGS_RELEASE "${CMAKE_CXX_FLAGS_RELEASE}")
endmacro()

# Clear the -O3 flag in the CMAKE_CXX_FLAGS_RELEASE, otherwise it will reenable SLP vectorization.
remove_cxx_flag("-O3")

string(REGEX MATCH "^(.*)[\\/]labs[\\/].*$" repo "${CMAKE_CURRENT_SOURCE_DIR}")
include(${CMAKE_MATCH_1}/tools/labs.cmake)



================================================
FILE: labs/core_bound/dep_chains_2/init.cpp
================================================
#include "solution.hpp"
#include <algorithm>
#include <random>

std::vector<Particle> initParticles() {
  std::random_device r;
  std::default_random_engine gen(r());
  // particles are moving with a constant speed in the range [0;1]
  std::uniform_real_distribution<float> distrib_velocity(0.0f, 1.0f);
  // particles have initial x and y coordinates in the range [-1000,1000]
  std::uniform_real_distribution<float> distrib_coord(-1000.0f, 1000.0f);
  std::vector<Particle> particles;
  particles.reserve(PARTICLES);
  for (int i = 0; i < PARTICLES; i++)
    particles.push_back({distrib_coord(gen), distrib_coord(gen), distrib_velocity(gen)});
  return particles;
}


================================================
FILE: labs/core_bound/dep_chains_2/solution.hpp
================================================
#include <vector>
#include <iostream>
#include <cstdint>
#include <array>

// The number of motion simulation steps.
constexpr uint32_t STEPS = 10000;
// The number of paticles to simulate.
constexpr uint32_t PARTICLES = 1000;

struct Particle {
  float x;
  float y;
  float velocity;
};

// Initialize the particles with random coordinates and velocities.
std::vector<Particle> initParticles();

// Medium-quality random number generator.
// https://www.javamex.com/tutorials/random_numbers/xorshift.shtml
struct XorShift32 {
  uint32_t val;
  XorShift32 (uint32_t seed) : val(seed) {}
public:
  uint32_t gen() {
    val ^= (val << 13);
    val ^= (val >> 17);
    val ^= (val << 5);
    return val;
  }
};

constexpr double PI_D = 3.141592653589793238463;
constexpr float PI_F = 3.14159265358979f;

// Approximate sine and cosine functions
// https://stackoverflow.com/questions/18662261/fastest-implementation-of-sine-cosine-and-square-root-in-c-doesnt-need-to-b
static float sine(float x) {
    const float B = 4 / PI_F;
    const float C = -4/( PI_F * PI_F);
    return B * x + C * x * std::abs(x);
}
static float cosine(float x) {
    return sine(x + (PI_F / 2));
}

// A constant to convert from degrees to radians.
// It maps the random number from [0;UINT32_MAX) to [0;2*pi).
// We do calculations in double precision then convert to float.
constexpr float DEGREE_TO_RADIAN = (2 * PI_D) / UINT32_MAX;

// Simulate the motion of the particles.
// For every particle, we generate a random angle and move the particle
// in the corresponding direction.
template <class RNG>
void randomParticleMotion(std::vector<Particle> &particles, uint32_t seed) {
  RNG rng(seed);  
  for (int i = 0; i < STEPS; i++)
    for (auto &p : particles) {
      uint32_t angle = rng.gen();
      float angle_rad = angle * DEGREE_TO_RADIAN;
      p.x += cosine(angle_rad) * p.velocity;
      p.y += sine(angle_rad) * p.velocity;
    }
}


================================================
FILE: labs/core_bound/dep_chains_2/validate.cpp
================================================
#include "solution.hpp"
#include <iostream>
#include <limits>
#include <cmath>
#include <random>

static bool equals(const std::vector<Particle> &p1, const std::vector<Particle> &p2) {
  constexpr int maxErrors = 10;
  const float epsilon = std::sqrt(std::numeric_limits<float>::epsilon());
  int errors = 0;

  for (int i = 0; i < p1.size(); i++) {
    float x1 = p1[i].x;
    float x2 = p2[i].x;
    float y1 = p1[i].y;
    float y2 = p2[i].y;
    float xerror = std::abs(x1 - x2);
    float yerror = std::abs(y1 - y2);
    if (xerror >= epsilon || yerror >= epsilon) {
      std::cerr << "Result: p1[" << i << "] = {" << x1 << "," << y1 << "}"
                << ". Expected : p1[" << i << "] = {" << x2 << "," << y2 << "}"
                << std::endl;
      if (++errors >= maxErrors)
        return false;
      }
  }
  return 0 == errors;
}

// For validation we use a deterministic random number generator
// that uses a global state and thus always generates the same sequence of numbers
struct rngForValidation {
  rngForValidation (uint32_t seed) {(void)seed;}
public:
  static uint32_t val;
  uint32_t gen() {
    return val++;
  }
};

uint32_t rngForValidation::val = 0;

void randomParticleMotionOriginal(std::vector<Particle> &particles, uint32_t seed) {
  rngForValidation rng(seed);  
  for (int i = 0; i < STEPS; i++)
    for (auto &p : particles) {
      uint32_t angle = rng.gen();
      float angle_rad = angle * DEGREE_TO_RADIAN;
      p.x += cosine(angle_rad) * p.velocity;
      p.y += sine(angle_rad) * p.velocity;
    }
}

int main() {
  // Init benchmark data
  auto particles = initParticles();
  auto particlesCopy = particles;

  std::random_device r;
  std::mt19937_64 random_engine(r());
  std::uniform_int_distribution<uint32_t> distrib(0, std::numeric_limits<uint32_t>::max());

  auto seed = distrib(random_engine);
  randomParticleMotionOriginal(particlesCopy, seed);
  rngForValidation::val = 0;
  randomParticleMotion<rngForValidation>(particles, seed);
  
  if (!equals(particlesCopy, particles)) {
    std::cerr << "Validation Failed." << "\n";
    return 1;
  }

  std::cout << "Validation Successful" << std::endl;
  return 0;
}



================================================
FILE: labs/core_bound/function_inlining_1/README.md
================================================
[<img src="../../../img/FunctionInlining1Intro.png">](https://www.youtube.com/watch?v=fp1_e3rjZQs&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d&index=12)

This is a lab about [function inlining](https://en.wikipedia.org/wiki/Inline_expansion) to speed up sorting.

Function inlining is a transformation that replaces a call to a function `F` with the body for `F` specialized with the actual arguments of the call. Inlining is one of the most important compiler optimizations, not only because it eliminates the overhead of calling a function (prologue and epilogue), but also it enables other optimizations.

Whenever you find in a performance profile a function with hot prologue and epilogue, consider such function as one of the potential candidates for being inlined. In this lab assignment you will practice fixing such performance issues.

[<img src="../../../img/FunctionInlining1Summary.png">](https://www.youtube.com/watch?v=qlFUV0FjpPQ&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d&index=12)


================================================
FILE: labs/core_bound/function_inlining_1/bench.cpp
================================================

#include "benchmark/benchmark.h"
#include "solution.h"

static void bench1(benchmark::State &state) {
  std::array<S, N> arr;
  init(arr);

  for (auto _ : state) {
    auto copy = arr;
    solution(copy);
    benchmark::DoNotOptimize(copy);
  }
}

// Register the function as a benchmark
BENCHMARK(bench1)->Unit(benchmark::kMicrosecond);

// Run the benchmark
BENCHMARK_MAIN();



================================================
FILE: labs/core_bound/function_inlining_1/CMakeLists.txt
================================================
cmake_minimum_required(VERSION 3.3)

project(lab)

string(REGEX MATCH "^(.*)[\\/]labs[\\/].*$" repo "${CMAKE_CURRENT_SOURCE_DIR}")
include(${CMAKE_MATCH_1}/tools/labs.cmake)



================================================
FILE: labs/core_bound/function_inlining_1/init.cpp
================================================

#include "solution.h"
#include <random>

void init(std::array<S, N> &arr) {
  std::default_random_engine generator;
  std::uniform_int_distribution<uint32_t> distribution(
      0, 9000u);

  for (size_t i = 0; i < N; i++) {
    uint32_t random_int1 = distribution(generator);
    uint32_t random_int2 = distribution(generator);

    arr[i].key1 = random_int1;
    arr[i].key2 = random_int2;
  }
}



================================================
FILE: labs/core_bound/function_inlining_1/solution.cpp
================================================

#include "solution.h"
#include <algorithm>
#include <stdlib.h>

static int compare(const void *lhs, const void *rhs) {
  auto &a = *reinterpret_cast<const S *>(lhs);
  auto &b = *reinterpret_cast<const S *>(rhs);

  if (a.key1 < b.key1)
    return -1;

  if (a.key1 > b.key1)
    return 1;

  if (a.key2 < b.key2)
    return -1;

  if (a.key2 > b.key2)
    return 1;

  return 0;
}

void solution(std::array<S, N> &arr) {
  qsort(arr.data(), arr.size(), sizeof(S), compare);
}



================================================
FILE: labs/core_bound/function_inlining_1/solution.h
================================================

#include <array>
#include <cstddef>
#include <cstdint>

// Assume this constant never changes
constexpr size_t N = 10000;

struct S {
  uint32_t key1;
  uint32_t key2;
};

void init(std::array<S, N> &arr);
void solution(std::array<S, N> &arr);



================================================
FILE: labs/core_bound/function_inlining_1/validate.cpp
================================================

#include "solution.h"
#include <iostream>
#include <stdlib.h>

static int originalCompare(const void *lhs, const void *rhs) {
  auto &a = *reinterpret_cast<const S *>(lhs);
  auto &b = *reinterpret_cast<const S *>(rhs);

  if (a.key1 < b.key1)
    return -1;

  if (a.key1 > b.key1)
    return 1;

  if (a.key2 < b.key2)
    return -1;

  if (a.key2 > b.key2)
    return 1;

  return 0;
}

static void originalSolution(std::array<S, N> &arr) {
  qsort(arr.data(), arr.size(), sizeof(S), originalCompare);
}

int main() {
  std::array<S, N> arr;
  init(arr);

  auto expected = arr;
  solution(arr);
  originalSolution(expected);

  for (size_t i = 0; i < N; i++) {
    if (arr[i].key1 != expected[i].key1) {
      std::cerr << "Validation Failed. Result[" << i
                << "].key1 = " << arr[i].key1 << ". Expected[" << i
                << "].key1 = " << expected[i].key1 << std::endl;
      return 1;
    }

    if (arr[i].key2 != expected[i].key2) {
      std::cerr << "Validation Failed. Result[" << i
                << "].key2 = " << arr[i].key2 << ". Expected[" << i
                << "].key2 = " << expected[i].key2 << std::endl;
      return 1;
    }
  }

  std::cout << "Validation Successful" << std::endl;
  return 0;
}



================================================
FILE: labs/core_bound/vectorization_1/README.md
================================================
[<img src="../../../img/Vectorization1-Intro.png">](https://www.youtube.com/watch?v=osfIC5uO0G8&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d&index=12)

[Sequence alignment](https://en.wikipedia.org/wiki/Sequence_alignment) is an important algorithm in many bioinformatics applications and pipelines. The goal of the alignment is to gain insights about their biological  relation. In particular, one is interested how the sequences diverged from a common ancestor by evolutionary events like point mutations or insertions and deletions in the respective sequences.
This problem, however, has quadratic complexity and optimizing it can have a great benefit in many applications.
Since many bioinformatic problems start with the alignment of millions of short sequence pieces of length 150 to 300 symbols, we can gain great performance improvements by using SIMD vectors. In this lab you will learn how the algorithm can be improved by transforming the data layout and exposing SIMD computations.

[<img src="../../../img/Vectorization1-Summary.png">](https://www.youtube.com/watch?v=OvM6eAh8wBc&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d&index=12)


Author: @rrahn.


================================================
FILE: labs/core_bound/vectorization_1/bench.cpp
================================================
#include "benchmark/benchmark.h"
#include "solution.hpp"

static void bench_compute_alignment(benchmark::State &state) {
  auto [sequences1, sequences2] = init();

  for (auto _ : state) {
    auto res = compute_alignment(sequences1, sequences2);
    benchmark::DoNotOptimize(res);
  }
}

// Register the functions as a benchmark
BENCHMARK(bench_compute_alignment);

// Run the benchmark
BENCHMARK_MAIN();



================================================
FILE: labs/core_bound/vectorization_1/CMakeLists.txt
================================================
cmake_minimum_required(VERSION 3.3)

project(lab)

set(CMAKE_CXX_STANDARD 17)

string(REGEX MATCH "^(.*)[\\/]labs[\\/].*$" repo "${CMAKE_CURRENT_SOURCE_DIR}")
include(${CMAKE_MATCH_1}/tools/labs.cmake)



================================================
FILE: labs/core_bound/vectorization_1/init.cpp
================================================
#include "solution.hpp"
#include <algorithm>
#include <random>

// Initialises a pair of sequence collections given a fixed sequence size.
std::pair<std::vector<sequence_t>, std::vector<sequence_t>> init() {
  std::mt19937_64 random_engine{};
  // Simulate DNA alphabet with 4 symbols.
  std::uniform_int_distribution<uint16_t> symbol_distribution(0u, 4u);

  auto generate_sequences = [&]() -> std::vector<sequence_t> {
    std::vector<sequence_t> sequences{};
    sequences.resize(sequence_count_v);

    for (sequence_t &sequence : sequences) {
      std::generate(sequence.begin(), sequence.end(),
                    [&]()
                    { return static_cast<uint8_t>(symbol_distribution(random_engine)); });
    }
    return sequences;
  };

  return std::pair{generate_sequences(), generate_sequences()};
}



================================================
FILE: labs/core_bound/vectorization_1/solution.cpp
================================================
#include "solution.hpp"
#include <algorithm>
#include <cassert>
#include <type_traits>

// The alignment algorithm which computes the alignment of the given sequence
// pairs.
result_t compute_alignment(std::vector<sequence_t> const &sequences1,
                           std::vector<sequence_t> const &sequences2) {
  result_t result{};

  for (size_t sequence_idx = 0; sequence_idx < sequences1.size();
       ++sequence_idx) {
    using score_t = int16_t;
    using column_t = std::array<score_t, sequence_size_v + 1>;

    sequence_t const &sequence1 = sequences1[sequence_idx];
    sequence_t const &sequence2 = sequences2[sequence_idx];

    /*
     * Initialise score values.
     */
    score_t gap_open{-11};
    score_t gap_extension{-1};
    score_t match{6};
    score_t mismatch{-4};

    /*
     * Setup the matrix.
     * Note we can compute the entire matrix with just one column in memory,
     * since we are only interested in the last value of the last column in the
     * score matrix.
     */
    column_t score_column{};
    column_t horizontal_gap_column{};
    score_t last_vertical_gap{};

    /*
     * Initialise the first column of the matrix.
     */
    horizontal_gap_column[0] = gap_open;
    last_vertical_gap = gap_open;

    for (size_t i = 1; i < score_column.size(); ++i) {
      score_column[i] = last_vertical_gap;
      horizontal_gap_column[i] = last_vertical_gap + gap_open;
      last_vertical_gap += gap_extension;
    }

    /*
     * Compute the main recursion to fill the matrix.
     */
    for (unsigned col = 1; col <= sequence2.size(); ++col) {
      score_t last_diagonal_score =
          score_column[0]; // Cache last diagonal score to compute this cell.
      score_column[0] = horizontal_gap_column[0];
      last_vertical_gap = horizontal_gap_column[0] + gap_open;
      horizontal_gap_column[0] += gap_extension;

      for (unsigned row = 1; row <= sequence1.size(); ++row) {
        // Compute next score from diagonal direction with match/mismatch.
        score_t best_cell_score =
            last_diagonal_score +
            (sequence1[row - 1] == sequence2[col - 1] ? match : mismatch);
        // Determine best score from diagonal, vertical, or horizontal
        // direction.
        best_cell_score = std::max(best_cell_score, last_vertical_gap);
        best_cell_score = std::max(best_cell_score, horizontal_gap_column[row]);
        // Cache next diagonal value and store optimum in score_column.
        last_diagonal_score = score_column[row];
        score_column[row] = best_cell_score;
        // Compute the next values for vertical and horizontal gap.
        best_cell_score += gap_open;
        last_vertical_gap += gap_extension;
        horizontal_gap_column[row] += gap_extension;
        // Store optimum between gap open and gap extension.
        last_vertical_gap = std::max(last_vertical_gap, best_cell_score);
        horizontal_gap_column[row] =
            std::max(horizontal_gap_column[row], best_cell_score);
      }
    }

    // Report the best score.
    result[sequence_idx] = score_column.back();
  }

  return result;
}



================================================
FILE: labs/core_bound/vectorization_1/solution.hpp
================================================
#include <array>   // std::array
#include <cstddef> // size_t
#include <cstdint> // fixed width types
#include <utility> // std::pair
#include <vector>  // std::vector

inline constexpr size_t sequence_size_v = 200; // The length of the generated sequences.
inline constexpr size_t sequence_count_v = 16; // The number of sequences to generate for both sequence collections.

using sequence_t = std::array<uint8_t, sequence_size_v>;
using result_t = std::array<int16_t, sequence_count_v>;

result_t compute_alignment(std::vector<sequence_t> const &, std::vector<sequence_t> const &);
std::pair<std::vector<sequence_t>, std::vector<sequence_t>> init();



================================================
FILE: labs/core_bound/vectorization_1/validate.cpp
================================================
#include "solution.hpp"
#include <iostream>

static bool equals(const result_t &result, const result_t &expected) {
  size_t errors{};
  for (size_t i = 0; i < expected.size(); ++i) {
    if (expected[i] != result[i]) {
      ++errors;
      std::cerr << "Result[" << i << "] = " << result[i] << " Expected[" << i
                << "] = " << expected[i] << std::endl;
    }
  }
  return 0 == errors;
}

int main() {
  auto [sequences1, sequences2] = init();

  auto computed_result = compute_alignment(sequences1, sequences2);

  result_t expected_result{};
  for (size_t sequence_idx = 0; sequence_idx < sequences1.size();
       ++sequence_idx) {
    using score_t = int16_t;
    using column_t = std::array<score_t, sequence_size_v + 1>;

    sequence_t const &sequence1 = sequences1[sequence_idx];
    sequence_t const &sequence2 = sequences2[sequence_idx];

    /*
     * Initialise score values.
     */
    score_t gap_open{-11};
    score_t gap_extension{-1};
    score_t match{6};
    score_t mismatch{-4};

    /*
     * Setup the matrix.
     * Note we can compute the entire matrix with just one column in memory,
     * since we are only interested in the last value of the last column in the
     * score matrix.
     */
    column_t score_column{};
    column_t horizontal_gap_column{};
    score_t last_vertical_gap{};

    /*
     * Initialise the first column of the matrix.
     */
    horizontal_gap_column[0] = gap_open;
    last_vertical_gap = gap_open;

    for (size_t i = 1; i < score_column.size(); ++i) {
      score_column[i] = last_vertical_gap;
      horizontal_gap_column[i] = last_vertical_gap + gap_open;
      last_vertical_gap += gap_extension;
    }

    /*
     * Compute the main recursion to fill the matrix.
     */
    for (unsigned col = 1; col <= sequence2.size(); ++col) {
      score_t last_diagonal_score =
          score_column[0]; // Cache last diagonal score to compute this cell.
      score_column[0] = horizontal_gap_column[0];
      last_vertical_gap = horizontal_gap_column[0] + gap_open;
      horizontal_gap_column[0] += gap_extension;

      for (unsigned row = 1; row <= sequence1.size(); ++row) {
        score_t best_cell_score =
            last_diagonal_score +
            (sequence1[row - 1] == sequence2[col - 1] ? match : mismatch);

        best_cell_score = std::max(best_cell_score, last_vertical_gap);
        best_cell_score = std::max(best_cell_score, horizontal_gap_column[row]);
        last_diagonal_score = score_column[row];
        score_column[row] = best_cell_score;

        best_cell_score += gap_open;
        last_vertical_gap += gap_extension;
        horizontal_gap_column[row] += gap_extension;

        last_vertical_gap = std::max(last_vertical_gap, best_cell_score);
        horizontal_gap_column[row] =
            std::max(horizontal_gap_column[row], best_cell_score);
      }
    }

    // Report the best score.
    expected_result[sequence_idx] = score_column.back();
  }

  if (!equals(computed_result, expected_result)) {
    std::cerr << "Validation Failed." << std::endl;
    return 1;
  }

  std::cout << "Validation Successful" << std::endl;
  return 0;
}



================================================
FILE: labs/core_bound/vectorization_2/README.md
================================================
[<img src="../../../img/Vectorization2_button.png">](https://www.youtube.com/watch?v=m4SWal8EAgM&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d)

This is a second lab about [auto vectorization](https://llvm.org/docs/Vectorizers.html). The subject of this lab assignment is a part of a checksum algorithm from the 80s, which has risen from the popularity of the Internet and [accompanying needs to validate transmitted packets](https://www.alpharithms.com/internet-checksum-calculation-steps-044921/). Even the problem is old, similar issues may exist nowadays in production code.

Modern compilers handle simple loops very well, including horizontal additions. In this lab computations inside the loop are slightly more difficult: we do an "add carry" operation. Some compilers recognize "add carry" and others don't. The [carry flag](https://en.wikipedia.org/wiki/Binary_number#Binary_arithmetic) is still a dark area in C++ while it exists more than 40 years. In this lab assignment, you will practice fixing auto-vectorization, which will improve performance significantly.

Hint: the [RFC 1071](http://www.faqs.org/rfcs/rfc1071.html) paper in the section "2. Calculating the Checksum" describes possible techniques to speed up this assignment. Also, clang can help to find [causes](https://llvm.org/docs/Vectorizers.html#diagnostics) of bad performance.



================================================
FILE: labs/core_bound/vectorization_2/bench.cpp
================================================

#include "benchmark/benchmark.h"
#include "solution.hpp"

static void bench1(benchmark::State &state) {
  // Init benchmark data
  Blob blob;
  init(blob);

  // Run the benchmark
  for (auto _ : state) {
    auto output = checksum(blob);
    benchmark::DoNotOptimize(output);
  }
}

// Register the function as a benchmark and measure time in microseconds
BENCHMARK(bench1)->Unit(benchmark::kMicrosecond);

// Run the benchmark
BENCHMARK_MAIN();



================================================
FILE: labs/core_bound/vectorization_2/CMakeLists.txt
================================================
cmake_minimum_required(VERSION 3.3)

project(lab)

string(REGEX MATCH "^(.*)[\\/]labs[\\/].*$" repo "${CMAKE_CURRENT_SOURCE_DIR}")
include(${CMAKE_MATCH_1}/tools/labs.cmake)



================================================
FILE: labs/core_bound/vectorization_2/init.cpp
================================================
#include "solution.hpp"
#include <limits>
#include <random>

void init(Blob &blob) {
  std::random_device r;
  std::default_random_engine generator(r());
  std::uniform_int_distribution<uint16_t> distribution(
      0, std::numeric_limits<uint16_t>::max());

  for (std::size_t i = 0; i < N; i++) {
    blob[i] = distribution(generator);
  }
}



================================================
FILE: labs/core_bound/vectorization_2/solution.cpp
================================================
#include "solution.hpp"

uint16_t checksum(const Blob &blob) {
  uint16_t acc = 0;
  for (auto value : blob) {
    acc += value;
    acc += acc < value; // add carry
  }
  return acc;
}



================================================
FILE: labs/core_bound/vectorization_2/solution.hpp
================================================

#include <array>
#include <cstdint>

// Assume this constant never changes
constexpr std::size_t N = 64 * 1024;

using Blob = std::array<uint16_t, N>;

void init(Blob &blob);
uint16_t checksum(const Blob &blob);



================================================
FILE: labs/core_bound/vectorization_2/validate.cpp
================================================

#include "solution.hpp"
#include <iostream>

uint16_t original_checksum(const Blob &blob) {
  uint16_t acc = 0;
  for (auto value : blob) {
    acc += value;
    acc += acc < value; // add carry
  }
  return acc;
}

int main() {
  // Init benchmark data
  Blob blob;
  init(blob);

  auto original_result = original_checksum(blob);
  auto result = checksum(blob);

  if (original_result != result) {
    std::cerr << "Validation Failed. Original result = " << original_result
              << "; Modified version returned = " << result << "\n";
    return 1;
  }

  std::cout << "Validation Successful" << std::endl;
  return 0;
}



================================================
FILE: labs/data_driven/README.md
================================================
# Data Driven

This is a collection of labs that have opportunities to improve performance using data-driven techniques.

- Specialize a hot switch statement
- Specialize an indirect function call
- Optimize a hot function for early exit

Work in progress...



================================================
FILE: labs/frontend_bound/README.md
================================================
# FrontEnd Bound

This is a collection of labs with performance bound by the CPU FrontEnd. Here are some of the topics we plan to cover:

* Basic Block reordering (using builtin_expect)
* Basic Block placement (loop alignment)
* Using Link-Time (LTO) and Profile-Guided (PGO) Optimizations
* Optimizing for ITLB (utilizing large pages)

**Work in progress...**

Let us know if you have any suggestion for a new lab assignment.



================================================
FILE: labs/memory_bound/README.md
================================================
# Memory Bound

[<img src="../../img/MemoryBoundIntro.png">](https://www.youtube.com/watch?v=jxK6GAyp8XE&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d)

This is a collection of labs with performance bound by memory accesses. Here are some of the topics we plan to cover:

* Access data sequentially (loop interchange)
* Array-Of-Structures to Structures-Of-Arrays and back
* Packing and padding the data
* Grouping hot data
* Optimizing dynamic memory allocation (custom allocators)
* Software memory prefetching
* Optimizing for DTLB (utilizing large pages)

**Work in progress...**

Let us know if you have any suggestion for a new lab assignment.



================================================
FILE: labs/memory_bound/data_packing/README.md
================================================
# Data packing

This is a lab about data packing.

[<img src="../../../img/DataPacking1Intro.png">](https://www.youtube.com/watch?v=-V-oIXrqA2s&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d)

You can decrease the memory traffic of the application if you pack the data more efficiently.
Some of the ways to do that include:

* Eliminate compiler-added padding.
* Use types that require less memory or less precision e.g. (int -> short, double -> float).
* Use bitfields to pack the data even further.

**Note 1:** Data Packing Summary video mentions branch mispredictions as a primary bottleneck for this lab. This is no longer true since the main source of branch mispredictions (std::sort) was replaced by counting sort.

**Note 2:** Bit Fields are implementation-specific. If you run the solution presented in the video on Windows, you may notice that the size of the structure is larger than you'd expect. The reason for this is a Microsoft-specific undocumented behavior that refuses to pack bit fields of varying types. Consider this if you want to pass performance tests on the Zen platform.

[<img src="../../../img/DataPacking1Summary.png">](https://www.youtube.com/watch?v=ta096PQ6gTg&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d)



================================================
FILE: labs/memory_bound/data_packing/bench.cpp
================================================
#include "benchmark/benchmark.h"
#include "solution.h"

static void bench1(benchmark::State &state) {
  std::vector<S> arr(N);
  init(arr);

  for (auto _ : state) {
    solution(arr);
    benchmark::DoNotOptimize(arr);
  }
}

// Register the function as a benchmark
BENCHMARK(bench1)->Unit(benchmark::kMillisecond);

// Run the benchmark
BENCHMARK_MAIN();



================================================
FILE: labs/memory_bound/data_packing/CMakeLists.txt
================================================
cmake_minimum_required(VERSION 3.3)

project(lab)

string(REGEX MATCH "^(.*)[\\/]labs[\\/].*$" repo "${CMAKE_CURRENT_SOURCE_DIR}")
include(${CMAKE_MATCH_1}/tools/labs.cmake)



================================================
FILE: labs/memory_bound/data_packing/init.cpp
================================================
#include "solution.h"
#include <random>

S create_entry(int first_value, int second_value) {
  S entry;

  entry.i = first_value;
  entry.s = static_cast<short>(second_value);
  entry.l = static_cast<long long>(first_value * second_value);
  entry.d = static_cast<double>(first_value) / maxRandom;
  entry.b = first_value < second_value;

  return entry;
}

void init(std::vector<S> &arr) {
  std::default_random_engine generator;
  std::uniform_int_distribution<int> distribution(minRandom, maxRandom - 1);

  for (int i = 0; i < N; i++) {
    int random_int1 = distribution(generator);
    int random_int2 = distribution(generator);

    arr[i] = create_entry(random_int1, random_int2);
  }
}



================================================
FILE: labs/memory_bound/data_packing/solution.cpp
================================================
#include "solution.h"
#include <algorithm>
#include <array>
#include <random>

void solution(std::vector<S> &arr) {
  // 1. shuffle
  static std::random_device rd;
  static std::mt19937 g(rd());
  std::shuffle(arr.begin(), arr.end(), g);

  // 2. counting sort
  constexpr int cntSize = maxRandom - minRandom + 1;
  std::array<int, cntSize> cnt{};
  for (const auto& v : arr) {
    ++cnt[v.i - minRandom + 1];
  }
  for (int i = 1; i < cntSize; ++i) {
    cnt[i] += cnt[i - 1];
  }
  std::vector<S> sorted(N);
  for (const auto& v : arr) {
    sorted[cnt[v.i - minRandom]++] = v;
  }
  arr = sorted;
}



================================================
FILE: labs/memory_bound/data_packing/solution.h
================================================
#include <vector>

// Assume those constants never change
constexpr int N = 1000000;
constexpr int minRandom = 0;
constexpr int maxRandom = 100;

// FIXME: this data structure can be reduced in size
struct S {
  int i;
  long long l;
  short s;
  double d;
  bool b;

  bool operator<(const S &s) const { return this->i < s.i; }
};

void init(std::vector<S> &arr);
S create_entry(int first_value, int second_value);
void solution(std::vector<S> &arr);



================================================
FILE: labs/memory_bound/data_packing/validate.cpp
================================================
#include "solution.h"
#include <algorithm>
#include <iostream>

template <typename Received_t, typename Expected_t>
static void reportError(const char *var_name, Received_t received,
                     Expected_t expected, int first_value, int second_value) {
  std::cerr << "Validation Failed. Value " << var_name << " is " << received
            << ". Expected is " << expected << " for intialization values "
            << first_value << " and " << second_value << std::endl;
}

bool check_entry(int first, int second) {
  S entry = create_entry(first, second);

  bool isValid = true;

  if (entry.i != first) {
    reportError("i", entry.i, first, first, second);
    isValid = false;
  }

  if (entry.s != second) {
    reportError("s", entry.s, second, first, second);
    isValid = false;
  }

  const auto expected_l = static_cast<short>(first * second);
  if (entry.l != expected_l) {
    reportError("l", entry.l, expected_l, first, second);
    isValid = false;
  }
  
  const auto expected_d = static_cast<double>(first) / maxRandom;
  if (std::abs(float(entry.d - expected_d)) > 0.001) {
    reportError("d", entry.d, expected_d, first, second);
    isValid = false;
  }

  const auto expected_b = (first < second);
  if (entry.b != expected_b) {
    reportError("b", entry.b, expected_b, first, second);
    isValid = false;
  }

  return isValid;
}

std::ostream& operator<<(std::ostream& os, const S& s) {
  os << "{ i: " << s.i << ", s: " << s.s << ", l: " << s.l << ", d: " << s.d << ", b: " << s.b << " }";
  return os;
}

int main() {
  std::vector<S> arr(N);
  init(arr);

  auto expected = arr;
  solution(arr);
  if (!std::is_sorted(arr.begin(), arr.end())) {
    std::cerr << "Validation Failed. Array is not properly sorted." << std::endl;
    return 1;
  }
  auto cmp_eq = [](const S a, const S b) {
    return std::tie(a.i, a.s, a.l, a.d, a.b) == std::tie(b.i, b.s, b.l, b.d, b.b);
  };
  auto cmp_less = [](const S a, const S b) {
    return std::tie(a.i, a.s, a.l, a.d, a.b) < std::tie(b.i, b.s, b.l, b.d, b.b);
  };
  std::sort(expected.begin(), expected.end(), cmp_less);
  std::sort(arr.begin(), arr.end(), cmp_less);

  for (int i = 0; i < N; i++) {
    if (!cmp_eq(arr[i], expected[i])) {
      std::cerr << "Validation Failed. Result[" << i << "] = " << arr[i]
                << ". Expected[" << i << "] = " << expected[i] << std::endl;
      return 1;
    }
  }

  bool checks_passed = check_entry(minRandom, minRandom);
  checks_passed = check_entry(minRandom, maxRandom) && checks_passed;
  checks_passed = check_entry(minRandom + 1, maxRandom - 1) && checks_passed;
  checks_passed = check_entry(maxRandom, minRandom) && checks_passed;
  checks_passed = check_entry(maxRandom, maxRandom) && checks_passed;

  if (!checks_passed) {
    return 2;
  }

  std::cout << "Validation Successful" << std::endl;
  return 0;
}



================================================
FILE: labs/memory_bound/false_sharing_1/README.md
================================================
[<img src="../../../img/FalseSharing1.png">](https://www.youtube.com/watch?v=uRmQSHsZoxE&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d)


This lab assignment focuses on improving performance by eliminating false sharing. In this lab, we
have several threads that modify data located close together in memory in parallel. This causes a lot
of overhead, because the individual cores must transfer cache lines containing the modified data amongst
themselves to satisfy cache coherence.

Your task here is to eliminate the false sharing by making sure that each thread will access a separate
cache line.

Expected speedup: at least 60%.

Authored-by: Jakub Beránek (@Kobzol)


================================================
FILE: labs/memory_bound/false_sharing_1/bench.cpp
================================================
#include "benchmark/benchmark.h"
#include "solution.hpp"

#include <numeric>
#include <thread>

static void bench1(benchmark::State &state) {
  const auto size = 1024 * 1024;

  std::vector<uint32_t> data;
  data.reserve(size);

  for (int i = 0; i < size; i++) {
    data.push_back(i);
  }

  // Use thread count from 1 to <number of HW threads>
  size_t max_threads = std::thread::hardware_concurrency();
  std::vector<int> threads(max_threads);
  std::iota(threads.begin(), threads.end(), 1);

  for (auto _ : state) {
    for (auto thread_count : threads) {
      auto result = solution(data, thread_count);
      benchmark::DoNotOptimize(result);
    }
  }
}

// Register the function as a benchmark
BENCHMARK(bench1)->UseRealTime()->Unit(
    benchmark::kMillisecond); // ->Iterations(100)

// Run the benchmark
BENCHMARK_MAIN();



================================================
FILE: labs/memory_bound/false_sharing_1/CMakeLists.txt
================================================
cmake_minimum_required(VERSION 3.3)

project(lab)

find_package(OpenMP REQUIRED)
if (OPENMP_FOUND)
    set (CMAKE_CXX_FLAGS "${CMAKE_CXX_FLAGS} ${OpenMP_CXX_FLAGS}")
    set (CMAKE_EXE_LINKER_FLAGS "${CMAKE_EXE_LINKER_FLAGS} ${OpenMP_EXE_LINKER_FLAGS}")
endif()

string(REGEX MATCH "^(.*)[\\/]labs[\\/].*$" repo "${CMAKE_CURRENT_SOURCE_DIR}")
include(${CMAKE_MATCH_1}/tools/labs.cmake)



================================================
FILE: labs/memory_bound/false_sharing_1/solution.cpp
================================================
#include "solution.hpp"
#include <atomic>
#include <cstring>
#include <omp.h>
#include <vector>

std::size_t solution(const std::vector<uint32_t> &data, int thread_count) {
  // Using std::atomic counters to disallow compiler to promote `target`
  // memory location into a register. This way we ensure that the store
  // to `target` stays inside the loop.
  struct Accumulator {
    std::atomic<uint32_t> value = 0;
  };
  std::vector<Accumulator> accumulators(thread_count);

#pragma omp parallel num_threads(thread_count) default(none)                   \
    shared(accumulators, data)
  {
    int target_index = omp_get_thread_num();
    auto &target = accumulators[target_index];

#pragma omp for
    for (int i = 0; i < data.size(); i++) {
      // Perform computation on each input
      auto item = data[i];
      item += 1000;
      item ^= 0xADEDAE;
      item |= (item >> 24);

      // Write result to accumulator
      target.value += item % 13;
    }
  }

  std::size_t result = 0;
  for (const auto &accumulator : accumulators) {
    result += accumulator.value;
  }
  return result;
}



================================================
FILE: labs/memory_bound/false_sharing_1/solution.hpp
================================================
#include <cstdint>
#include <vector>

std::size_t solution(const std::vector<uint32_t> &data, int thread_count);



================================================
FILE: labs/memory_bound/false_sharing_1/validate.cpp
================================================
#include "solution.hpp"

#include <iostream>
#include <numeric>
#include <thread>

size_t original_solution(const std::vector<uint32_t> &data) {
  size_t value = 0;

  for (int i = 0; i < data.size(); i++) {
    auto item = data[i];
    item += 1000;
    item ^= 0xADEDAE;
    item |= (item >> 24);

    value += item % 13;
  }

  return value;
}

int main() {
  const auto size = 16 * 1024 * 1024;

  std::vector<uint32_t> data;
  data.reserve(size);

  for (int i = 0; i < size; i++) {
    data.push_back(i);
  }

  auto original_result = original_solution(data);

  // Use thread count from 1 to <number of HW threads>
  size_t max_threads = std::thread::hardware_concurrency();
  std::vector<int> threads(max_threads);
  std::iota(threads.begin(), threads.end(), 1);

  for (auto thread_count : threads) {
    auto result = solution(data, thread_count);
    if (original_result != result) {
      std::cerr << "Validation Failed for " << thread_count
                << " thread(s). Original result = " << original_result
                << "; Modified version returned = " << result << "\n";
      return 1;
    }
  }

  std::cout << "Validation Successful" << std::endl;
  return 0;
}



================================================
FILE: labs/memory_bound/huge_pages_1/README.md
================================================
# Finite element operator evaluation

## Motivation and problem description
The finite element method is a discretization technique used mainly for physics simulations.
The physical domain (usually 2D or 3D) where the physical problem is defined is broken up into a mesh of small, geometrically simple subdomains called elements (much like a surface is broken down into triangles in computer graphics).
The continuous fields representing physical quantities (e.g. density, pressure, temperature) are approximated using a finite number of values, which represent the values of the fields at the vertices (nodes) of the elements.
For this reason, these values are usually referred to as nodal values.
The partial differential equations describing the physics to be simulated are expressed as systems of linear algebraic equations, with the nodal values being the unknowns.
These algebraic systems are usually quite large, and therefore must be solved using (super-)computers.

Since the resulting system of algebraic equations is usually solved using iterative methods (e.g. the [conjugate gradient method](https://en.wikipedia.org/wiki/Conjugate_gradient_method)), it is not necessary to explicitly store the matrix describing it in memory.
It is sufficient to be able to evaluate the action of this matrix on a vector (compute the matrix-vector product).
This approach is usually referred to as matrix-free.

In this lab, you are meant to optimize a piece of code which evaluates the aforementioned matrix-vector product for a structural problem involving a truss.
The truss consists of many bars, each of which is represented using a single finite element.
To evaluate the matrix-free operator, we iterate over all elements, compute the local 4x4 matrix, gather the local 4-element left-hand side vector, perform the multiplication, and then scatter the result into the global right-hand side vector.
This example is rather simple (at the level of a 2nd year mechanical engineering course), but it illustrates the gather-scatter memory access pattern, which is ubiquitous in various simulation codes across the globe.

**Note**: The above description of the finite element method is extremely simplified, and is only meant to give a high level overview of the problem.

## Hint
Note that the compiler generates fairly optimal code for the floating-point computations, so there are little gains to be had by optimizing those.
Instead, focus on the memory access pattern, which is extremely random, meaning many distant memory addresses are accessed in rapid succession, which puts stress on the TLB.
This situation could be alleviated by allocating the memory which is accessed in a random fashion on huge pages (see [HugePagesSetupTips](HugePagesSetupTips.md)).
For the convenience of your solution, all such allocations are done using the `allocateDoublesArray` function.
In fact, this is the only place of the code which is modified in the suggested solution.

Authored-by: @kubagalecki



================================================
FILE: labs/memory_bound/huge_pages_1/AllocateDoublesArray.hpp
================================================
#include <iostream>
#include <memory>

#if defined(__linux__) || defined(__linux) || defined(linux) ||                \
    defined(__gnu_linux__)
#define ON_LINUX
#elif defined(__APPLE__) && defined(__MACH__)
#define ON_MACOS
#elif defined(_WIN32) || defined(_WIN64)
#define ON_WINDOWS
#endif

#if defined(ON_LINUX)

// HINT: allocate huge pages using mmap/munmap
// NOTE: See HugePagesSetupTips.md for how to enable huge pages in the OS
#include <sys/mman.h>

#elif defined(ON_WINDOWS)

// HINT: allocate huge pages using VirtualAlloc/VirtualFree
// NOTE: See HugePagesSetupTips.md for how to enable huge pages in the OS.
// The following boilerplate has been included to save you some time. You'll
// need to call `setRequiredPrivileges()` once per program run to tell the OS
// that you want to use huge pages. Additionally, you'll need to set the
// relevant user account privilege. The following code should do this for you,
// provided you run it as admin (run as admin -> reboot -> you're set to run as
// user).
// HINT: A good way to execute a function once per program run is to call it in
// the initialization of a function static variable.

#define UNICODE
#define _UNICODE

#include <windows.h>

#include <Sddl.h>
#include <ntsecapi.h>
#include <ntstatus.h>

// Based on
// https://stackoverflow.com/questions/42354504/enable-large-pages-in-windows-programmatically
namespace detail {
inline void InitLsaString(PLSA_UNICODE_STRING LsaString, LPWSTR String) {
  DWORD StringLength;

  if (String == NULL) {
    LsaString->Buffer = NULL;
    LsaString->Length = 0;
    LsaString->MaximumLength = 0;
    return;
  }

  StringLength = wcslen(String);
  LsaString->Buffer = String;
  LsaString->Length = (USHORT)StringLength * sizeof(WCHAR);
  LsaString->MaximumLength = (USHORT)(StringLength + 1) * sizeof(WCHAR);
}

inline auto openProcToken(DWORD desired_access) {
  using handle_t = std::pointer_traits<HANDLE>::element_type;
  constexpr auto handle_cleanup = [](HANDLE ptr) { CloseHandle(ptr); };
  using ret_t = std::unique_ptr<handle_t, decltype(+handle_cleanup)>;

  HANDLE handle{};
  if (!OpenProcessToken(GetCurrentProcess(), desired_access, &handle))
    throw std::runtime_error{"OpenProcessToken failed"};
  return ret_t{handle, +handle_cleanup};
}

inline auto getUserToken() {
  auto proc_token = detail::openProcToken(TOKEN_QUERY);

  // Probe the buffer size reqired for PTOKEN_USER structure
  DWORD dwbuf_sz = 0;
  if (!GetTokenInformation(proc_token.get(), TokenUser, nullptr, 0,
                              &dwbuf_sz) &&
      (GetLastError() != ERROR_INSUFFICIENT_BUFFER))
    throw std::runtime_error{"GetTokenInformation failed"};

  // Retrieve the token information in a TOKEN_USER structure
  constexpr auto deleter = [](PTOKEN_USER ptr) { free(ptr); };
  PTOKEN_USER ptr = (PTOKEN_USER)malloc(dwbuf_sz);
  std::unique_ptr<TOKEN_USER, decltype(deleter)> user_token{ptr, deleter};
  if (!GetTokenInformation(proc_token.get(), TokenUser, user_token.get(),
                              dwbuf_sz, &dwbuf_sz))
    throw std::runtime_error{"GetTokenInformation failed"};

  return user_token;
}

inline void adjustAccountPrivilege() {
  auto user_token = getUserToken();

  LSA_OBJECT_ATTRIBUTES obj_attrib{};
  LSA_HANDLE policy_handle;
  if (LsaOpenPolicy(nullptr, &obj_attrib,
                    POLICY_CREATE_ACCOUNT | POLICY_LOOKUP_NAMES,
                    &policy_handle))
    throw std::runtime_error{"LsaOpenPolicy failed"};

  LSA_UNICODE_STRING privilege_string;
  InitLsaString(&privilege_string, SE_LOCK_MEMORY_NAME);
  if (LsaAddAccountRights(policy_handle, user_token->User.Sid,
                          &privilege_string, 1))
    throw std::runtime_error{"LsaAddAccountRights failed"};
}

inline bool enableProcPrivilege() {
  auto proc_token = openProcToken(TOKEN_QUERY | TOKEN_ADJUST_PRIVILEGES);

  TOKEN_PRIVILEGES priv_token{};
  priv_token.PrivilegeCount = 1;
  priv_token.Privileges->Attributes = SE_PRIVILEGE_ENABLED;

  if (!LookupPrivilegeValue(NULL, SE_LOCK_MEMORY_NAME,
                               &priv_token.Privileges->Luid))
    throw std::runtime_error{"LookupPrivilegeValue failed"};

  if (!AdjustTokenPrivileges(proc_token.get(), FALSE, &priv_token, 0,
                                nullptr, 0))
    throw std::runtime_error{"AdjustTokenPrivileges failed"};

  if (GetLastError() == ERROR_NOT_ALL_ASSIGNED)
    return false;
  else
    return true;
}
} // namespace detail

inline bool setRequiredPrivileges() {
  if (detail::enableProcPrivilege())
    return true;
  else {
    std::clog << "It seems that your user account does not have the privilege "
                 "required to allocate huge pages. The program will now "
                 "attempt to give you this privilege. This requires the "
                 "program to be run as admin."
              << std::endl;
    detail::adjustAccountPrivilege();
    std::clog << "The required privilege has been set successfully. Please log "
                 "out and log back in for the changes to take effect. This "
                 "program will now terminate."
              << std::endl;
    std::terminate();
    return false;
  }
}

#endif

// Allocate an array of doubles of size `size`, return it as a
// std::unique_ptr<double[], D>, where `D` is a custom deleter type
inline auto allocateDoublesArray(size_t size) {
  // Allocate memory
  double *alloc = new double[size];
  // remember to cast the pointer to double* if your allocator returns void*

  // Deleters can be conveniently defined as lambdas, but you can explicitly
  // define a class if you're not comfortable with the syntax
  auto deleter = [/* state = ... */](double *ptr) { delete[] ptr; };

  return std::unique_ptr<double[], decltype(deleter)>(alloc,
                                                      std::move(deleter));

  // The above is equivalent to:
  // return std::make_unique<double[]>(size);
  // The more verbose version is meant to demonstrate the use of a custom
  // (potentially stateful) deleter
}



================================================
FILE: labs/memory_bound/huge_pages_1/bench.cpp
================================================
#include "AllocateDoublesArray.hpp"
#include "GenerateMesh.hpp"
#include "benchmark/benchmark.h"
#include "solution.hpp"

static void bench1(benchmark::State &state) {
  try {
    // Mesh
    constexpr unsigned n_nodes_x = 800, n_nodes_y = 20000,
                       n_nodes = n_nodes_x * n_nodes_y;
    constexpr unsigned seed = 0xaf173e8au;
    const auto x_alloc = allocateDoublesArray(n_nodes);
    const auto y_alloc = allocateDoublesArray(n_nodes);
    const auto topology =
        generateMesh(n_nodes_x, n_nodes_y, x_alloc.get(), y_alloc.get(), seed);
    const double *x = x_alloc.get();
    const double *y = y_alloc.get();

    // Generate random left-hand side
    const auto lhs_alloc = allocateDoublesArray(2 * n_nodes);
    double *lhs = lhs_alloc.get();
    std::mt19937 prng{std::random_device{}()};
    auto dist = std::uniform_real_distribution<double>{0., 42.};
    std::generate_n(lhs, 2 * n_nodes, [&] { return dist(prng); });

    // Right-hand side
    const auto rhs_alloc = allocateDoublesArray(2 * n_nodes);
    double *rhs = rhs_alloc.get();

    // Run the benchmark
    for (auto _ : state) {
      solution(topology, n_nodes, x, y, lhs, rhs);
      benchmark::DoNotOptimize(rhs);
      benchmark::ClobberMemory();
    }
    state.SetBytesProcessed(state.iterations() * topology.size() * 4 *
                            sizeof(double));

    // Cleanup via RAII
  } catch (const std::bad_alloc &) {
    std::cerr << "std::bad_alloc was thrown\n";
    throw;
  } catch (const std::exception &e) {
    std::cerr << "The following exception was thrown:\n" << e.what() << '\n';
    throw;
  } catch (...) {
    std::cerr << "Unknown exception was thrown\n";
    throw;
  }
}

// Register the function as a benchmark and measure time in microseconds
BENCHMARK(bench1)->Name("Apply matrix-free operator")->Unit(benchmark::kSecond);

// Run the benchmark
BENCHMARK_MAIN();



================================================
FILE: labs/memory_bound/huge_pages_1/CMakeLists.txt
================================================
cmake_minimum_required(VERSION 3.3)

project(lab)

string(REGEX MATCH "^(.*)[\\/]labs[\\/].*$" repo "${CMAKE_CURRENT_SOURCE_DIR}")
include(${CMAKE_MATCH_1}/tools/labs.cmake)



================================================
FILE: labs/memory_bound/huge_pages_1/GenerateMesh.cpp
================================================
#include "GenerateMesh.hpp"

#include <algorithm>
#include <numeric>

auto generateMesh(unsigned n_nodes_x, unsigned n_nodes_y, double *x, double *y,
                  unsigned seed) -> std::vector<std::array<unsigned, 2>> {
  const unsigned n_nodes = n_nodes_x * n_nodes_y;

  // Topology
  std::vector<std::array<unsigned, 2>> topology;
  topology.reserve((n_nodes_x - 1) * (n_nodes_y - 1) * 3 + (n_nodes_x - 1) +
                   (n_nodes_y - 1));
  for (unsigned j = 0; j < n_nodes_y - 1; ++j) {
    for (unsigned i = 0; i < n_nodes_x - 1; ++i) {
      const unsigned base = n_nodes_x * j + i;
      topology.push_back(std::array<unsigned, 2>{base, base + 1});
      topology.push_back(std::array<unsigned, 2>{base, base + n_nodes_x});
      topology.push_back(std::array<unsigned, 2>{base, base + n_nodes_x + 1});
    }
    topology.push_back(std::array<unsigned, 2>{n_nodes_x * (j + 1) - 1,
                                               n_nodes_x * (j + 2) - 1});
  }
  for (unsigned i = 0; i < n_nodes_x - 1; ++i)
    topology.push_back(std::array<unsigned, 2>{
        n_nodes_x * (n_nodes_y - 1) + i, n_nodes_x * (n_nodes_y - 1) + i + 1});

  // Node coords
  std::vector<double> x_unshuffled(n_nodes);
  std::vector<double> y_unshuffled(n_nodes);
  unsigned coord_ind = 0;
  for (unsigned j = 0; j < n_nodes_y; ++j)
    for (unsigned i = 0; i < n_nodes_x; ++i) {
      x_unshuffled[coord_ind] = i;
      y_unshuffled[coord_ind] = j;
      ++coord_ind;
    }

  // Shuffle
  std::mt19937 prng{seed};
  std::vector<unsigned> permutation(n_nodes);
  std::iota(permutation.begin(), permutation.end(), 0u);
  std::shuffle(permutation.begin(), permutation.end(), prng);
  unsigned i = 0;
  for (auto p : permutation) {
    x[p] = x_unshuffled[i];
    y[p] = y_unshuffled[i];
    ++i;
  }
  for (auto &[n1, n2] : topology) {
    n1 = permutation[n1];
    n2 = permutation[n2];
  }
  std::shuffle(topology.begin(), topology.end(), prng);
  return topology;
}



================================================
FILE: labs/memory_bound/huge_pages_1/GenerateMesh.hpp
================================================
#include <array>
#include <random>
#include <vector>

// Generate an example mesh describing a 2D truss.
// In this example, the nodes are distributed on a cartesian grid, the topology
// of the mesh is as follows:
/*
 * o-o-o-o-o-o  ^
 * |\|\|\|\|\|  |
 * o-o-o-o-o-o  |  n_nodes_y layers
 * |\|\|\|\|\|  |
 * o-o-o-o-o-o  |
 *
 * ----------->
 * n_nodes_x layers
 *
 */
// n_nodes_x, n_nodes_y - see sketch above
// x, y - arrays where node coordinates will be written, need to have space
//        allocated for at least (n_nodes_x*n_nodes_y) doubles
// seed - seed for RNG
//
// returns topology (see solution.hpp)
auto generateMesh(unsigned n_nodes_x, unsigned n_nodes_y, double *x, double *y,
                  unsigned seed = std::random_device{}())
    -> std::vector<std::array<unsigned, 2>>;



================================================
FILE: labs/memory_bound/huge_pages_1/HugePagesSetupTips.md
================================================
# Tips on enabling hugepages in the OS

## Windows

 To utilize huge pages on Windows, one needs to enable `SeLockMemoryPrivilege` [security policy](https://docs.microsoft.com/en-us/windows/security/threat-protection/security-policy-settings/lock-pages-in-memory).
 This can be done programatically via the Windows API, or alternatively via the security policy GUI (see guide below).

1. Hit start -> search "secpol.msc", launch it.
2. On the left select "Local Policies" -> "User Rights Assignment", then double-click on "Lock pages in memory"

![Lock pages in memory](img/i1.png)

3. Add your user and reboot the machine

![Add user](img/i2.png)

4. Check that huge pages are used at runtime with [RAMMap](https://docs.microsoft.com/en-us/sysinternals/downloads/rammap)

## Linux

### Explicit hugepages

 To explicitly allocate a fixed number of huge pages, one can use [libhugetlbfs](https://github.com/libhugetlbfs/libhugetlbfs):

 ```bash
$ sudo apt install libhugetlbfs-bin
$ sudo hugeadm --create-global-mounts
$ sudo hugeadm --pool-pages-min 2M:128
```

This is roughly the equivalent of executing the following commands which do not require libhugetlbfs (see the [kernel docs](https://www.kernel.org/doc/Documentation/vm/hugetlbpage.txt)):

```bash
$ echo 128 > /proc/sys/vm/nr_hugepages
$ mount -t hugetlbfs                                                      \
    -o uid=<value>,gid=<value>,mode=<value>,pagesize=<value>,size=<value>,\
    min_size=<value>,nr_inodes=<value> none /mnt/huge
```

You should be able to observe the effect in `/proc/meminfo`:

```bash
$ watch -n1 "cat /proc/meminfo  | grep huge -i"
AnonHugePages:      2048 kB
ShmemHugePages:        0 kB
FileHugePages:         0 kB
HugePages_Total:     128    <== 128 huge pages allocated
HugePages_Free:      128
HugePages_Rsvd:        0
HugePages_Surp:        0
Hugepagesize:       2048 kB
Hugetlb:          262144 kB <== 256MB of space occupied
```

### Transparent hugepages

To allow application use transparent Huge Pages on Linux one should make sure, that `/sys/kernel/mm/transparent_hugepage/enabled` is `always` or `madvise`. 

In the system-wide mode (`always`) the kernel will automatically collpase regular pages and promote them into a huge page. It works even for applications that are not aware of THPs, so you don't have to change the code yourself. Enable system-wide mode with:
```bash
echo "always" | sudo tee /sys/kernel/mm/transparent_hugepage/enabled
```

With the `madvise` option, THP is enabled only inside memory regions attributed with `MADV_HUGEPAGE` via `madvise` system call. For example:

```cpp
void ptr = mmap(nullptr, size, PROT_READ | PROT_WRITE | PROT_EXEC,
                MAP_PRIVATE | MAP_ANONYMOUS, -1 , 0);
madvise(ptr, size, MADV_HUGEPAGE);
// use the memory region `ptr`
munmap(ptr, size);
```

When applications are allocating huge pages via `madvise` and `mmap`, you can observe the effect in `/proc/meminfo` under `AnonHugePages`.



================================================
FILE: labs/memory_bound/huge_pages_1/solution.cpp
================================================
#include "solution.hpp"

#include <algorithm>
#include <cmath>

//////////////////////////////////////////////////////////////
//                       ATTENTION                          //
// You are not meant to modify this file. Please focus on   //
// AllocateDoublesArray.hpp                                 //
//////////////////////////////////////////////////////////////

auto computeLocalProduct(const std::array<double, 4> &coords,
                         const std::array<double, 4> &lhs_local)
    -> std::array<double, 4> {
  const auto [x1, y1, x2, y2] = coords;
  const auto dx = x2 - x1;
  const auto dy = y2 - y1;
  const auto dx2 = dx * dx;
  const auto dy2 = dy * dy;
  const auto dxdy = dx * dy;

  std::array<std::array<double, 4>, 4> K;
  K[0][0] = dx2;
  K[0][1] = dxdy;
  K[0][2] = -dx2;
  K[0][3] = -dxdy;
  K[1][0] = dxdy;
  K[1][1] = dy2;
  K[1][2] = -dxdy;
  K[1][3] = -dy2;
  for (unsigned c = 2; c < 4; ++c)
    for (unsigned r = 0; r < 4; ++r)
      K[c][r] = -K[c - 2][r];

  std::array<double, 4> mult_result{};
  for (unsigned c = 0; c < 4; ++c)
    for (unsigned r = 0; r < 4; ++r)
      mult_result[r] += K[c][r] * lhs_local[c];

  const auto L = std::sqrt(dx2 + dy2);
  constexpr auto E = 210e9;
  constexpr auto A = 3.14 * 1e-2 * 1e-2;
  const auto C = E * A / (L * L * L);
  for (auto &a : mult_result)
    a *= C;

  return mult_result;
}

auto computeDofs(unsigned n1, unsigned n2) -> std::array<unsigned, 4> {
  std::array<unsigned, 4> dofs;
  dofs[0] = n1 * 2;
  dofs[1] = n1 * 2 + 1;
  dofs[2] = n2 * 2;
  dofs[3] = n2 * 2 + 1;
  return dofs;
}

auto gatherGlobal(unsigned n1, unsigned n2, const double *rhs_global)
    -> std::array<double, 4> {
  const auto dofs = computeDofs(n1, n2);
  std::array<double, 4> vals;
  for (unsigned i = 0; i < dofs.size(); ++i)
    vals[i] = rhs_global[dofs[i]];
  return vals;
}

void scatterLocal(unsigned n1, unsigned n2, const std::array<double, 4> &vals,
                  double *rhs_global) {
  const auto dofs = computeDofs(n1, n2);
  for (unsigned i = 0; i < dofs.size(); ++i)
    rhs_global[dofs[i]] += vals[i];
}

// Local contrbution of the element described by the nodes (n1, n2). Remaining
// arguments are the same as the arguments of solution(...)
void processsElement(unsigned n1, unsigned n2, const double *x, const double *y,
                     const double *lhs, double *rhs) {
  const auto lhs_vals = gatherGlobal(n1, n2, lhs);
  std::array<double, 4> coords;
  coords[0] = x[n1];
  coords[1] = y[n1];
  coords[2] = x[n2];
  coords[3] = y[n2];
  const auto local_prod = computeLocalProduct(coords, lhs_vals);
  scatterLocal(n1, n2, local_prod, rhs);
}

void solution(const std::vector<std::array<unsigned, 2>> &topo,
              unsigned n_nodes, const double *x, const double *y,
              const double *lhs, double *rhs) {
  std::fill(rhs, rhs + n_nodes * 2, 0.);
  for (const auto [n1, n2] : topo)
    processsElement(n1, n2, x, y, lhs, rhs);
}



================================================
FILE: labs/memory_bound/huge_pages_1/solution.hpp
================================================
#include <array>
#include <vector>

// Evaluate matrix-free operator for a 2D truss
//
// topo - topology of the mesh. Each entry in the vector represents a single
//        element, described by the 2 IDs of the nodes of the element.
// n_nodes - total number of nodes in the mesh
// x, y - arrays containing the coordinates of the nodes - i-th entry contains
//        the coordinates of the i-th node
// lhs - left-hand side vector - this is the vector which is to be multiplied by
//       the stiffness matrix. It has a length of 2 * n_nodes (2 DOFs per node)
// rhs - right-hand side - this is the vector where we want to write the result
//       of the multiplication (same length as lhs)
void solution(const std::vector<std::array<unsigned, 2>> &topo,
              unsigned n_nodes, const double *x, const double *y,
              const double *lhs, double *rhs);



================================================
FILE: labs/memory_bound/huge_pages_1/validate.cpp
================================================
#include "AllocateDoublesArray.hpp"
#include "GenerateMesh.hpp"
#include "solution.hpp"

#include <algorithm>
#include <cmath>
#include <iostream>
#include <numeric>
#include <random>

static const auto seed = std::random_device{}();
static constexpr unsigned n_nodes_x = 100, n_nodes_y = 200,
                          n_nodes = n_nodes_x * n_nodes_y;

template <typename Allocator> auto solve(Allocator &&alloc) {
  const auto x_alloc = alloc(n_nodes);
  const auto y_alloc = alloc(n_nodes);
  const auto topology =
      generateMesh(n_nodes_x, n_nodes_y, x_alloc.get(), y_alloc.get(), seed);
  const double *x = x_alloc.get();
  const double *y = y_alloc.get();

  // Generate random left-hand side
  const auto lhs_alloc = alloc(2 * n_nodes);
  double *lhs = lhs_alloc.get();
  std::mt19937 prng{seed};
  auto dist = std::uniform_real_distribution<double>{0., 42.};
  std::generate_n(lhs, 2 * n_nodes, [&] { return dist(prng); });

  // Right-hand side
  auto rhs_alloc = alloc(2 * n_nodes);
  double *rhs = rhs_alloc.get();

  // Eval operator
  solution(topology, n_nodes, x, y, lhs, rhs);

  return rhs_alloc;
}

int main() {
  try {
    const auto sol_user =
        solve([](size_t size) { return allocateDoublesArray(size); });
    const auto sol_valid =
        solve([](size_t size) { return std::make_unique<double[]>(size); });
    const auto L2_error = std::sqrt(std::transform_reduce(
        sol_user.get(), sol_user.get() + 2 * n_nodes, sol_valid.get(), 0.,
        std::plus<>{}, [](double a, double b) { return (a - b) * (a - b); }));

    if (L2_error > 1e-9) {
      std::cerr
          << "Validation Failed. The error between the result of the "
             "evaluation "
             "of the original and user-supplied operators exceeded 1e-9\n";
      return EXIT_FAILURE;
    }

    std::cout << "Validation Successful\n";
    return EXIT_SUCCESS;

  } catch (const std::bad_alloc &) {
    std::cerr << "Validation failed. std::bad_alloc was thrown\n";
    return EXIT_FAILURE;
  } catch (const std::exception &e) {
    std::cerr << "Validation failed. The following exception was thrown:\n"
              << e.what() << '\n';
    return EXIT_FAILURE;
  } catch (...) {
    std::cerr << "Validation failed. Unknown exception was thrown\n";
    return EXIT_FAILURE;
  }
}



================================================
FILE: labs/memory_bound/loop_interchange_1/README.md
================================================
This is a lab about [loop interchange](https://en.wikipedia.org/wiki/Loop_interchange).

[<img src="../../../img/LoopInterchange1Intro.png">](https://www.youtube.com/watch?v=TLDR_nO9XVc&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d)

[Matrix multiplication](https://en.wikipedia.org/wiki/Matrix_multiplication) is an important building block for many numerical algorithms. In this lab assignment, we compute the integer power of a given real square matrix.
The binary representation of the power significantly reduces the number of matrix operations. Still, the code has a major performance flaw. Your job is to find it out.

[<img src="../../../img/LoopInterchane1Summary.png">](https://www.youtube.com/watch?v=G6BbPB37sYg&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d)



================================================
FILE: labs/memory_bound/loop_interchange_1/bench.cpp
================================================

#include "benchmark/benchmark.h"
#include "solution.h"
#include <memory>

static void bench1(benchmark::State &state) {
  std::unique_ptr<Matrix> a(new Matrix());
  init(*a);

  std::unique_ptr<Matrix> b(new Matrix());
  zero(*b);

  for (auto _ : state) {
    *b = power(*a, 2021);
    benchmark::DoNotOptimize(b);
  }
}

// Register the function as a benchmark
BENCHMARK(bench1);

// Run the benchmark
BENCHMARK_MAIN();



================================================
FILE: labs/memory_bound/loop_interchange_1/CMakeLists.txt
================================================
cmake_minimum_required(VERSION 3.3)

project(lab)

string(REGEX MATCH "^(.*)[\\/]labs[\\/].*$" repo "${CMAKE_CURRENT_SOURCE_DIR}")
include(${CMAKE_MATCH_1}/tools/labs.cmake)



================================================
FILE: labs/memory_bound/loop_interchange_1/init.cpp
================================================

#include "solution.h"
#include <cmath>
#include <limits>
#include <random>

void init(Matrix &matrix) {
  std::default_random_engine generator;
  std::uniform_real_distribution<float> distribution(-0.95f, 0.95f);

  for (int i = 0; i < N; i++) {
    float sum = 0;
    for (int j = 0; j < N; j++) {
      float value = distribution(generator);
      sum += value * value;
      matrix[i][j] = value;
    }

    // Normalize rows
    if (sum >= std::numeric_limits<float>::min()) {
      float scale = 1.0f / std::sqrt(sum);
      for (int j = 0; j < N; j++) {
        matrix[i][j] *= scale;
      }
    }
  }
}



================================================
FILE: labs/memory_bound/loop_interchange_1/solution.cpp
================================================

#include "solution.h"
#include <memory>
#include <string_view>

// Make zero matrix
void zero(Matrix &result) {
  for (int i = 0; i < N; i++) {
    for (int j = 0; j < N; j++) {
      result[i][j] = 0;
    }
  }
}

// Make identity matrix
void identity(Matrix &result) {
  for (int i = 0; i < N; i++) {
    for (int j = 0; j < N; j++) {
      result[i][j] = 0;
    }
    result[i][i] = 1;
  }
}

// Multiply two square matrices
void multiply(Matrix &result, const Matrix &a, const Matrix &b) {
  zero(result);

  for (int i = 0; i < N; i++) {
    for (int j = 0; j < N; j++) {
      for (int k = 0; k < N; k++) {
        result[i][j] += a[i][k] * b[k][j];
      }
    }
  }
}

// Compute integer power of a given square matrix
Matrix power(const Matrix &input, const uint32_t k) {
  // Temporary products
  std::unique_ptr<Matrix> productCurrent(new Matrix());
  std::unique_ptr<Matrix> productNext(new Matrix());

  // Temporary elements = a^(2^integer)
  std::unique_ptr<Matrix> elementCurrent(new Matrix());
  std::unique_ptr<Matrix> elementNext(new Matrix());

  // Initial values
  identity(*productCurrent);
  *elementCurrent = input;

  // Use binary representation of k to be O(log(k))
  for (auto i = k; i > 0; i /= 2) {
    if (i % 2 != 0) {
      // Multiply the product by element
      multiply(*productNext, *productCurrent, *elementCurrent);
      std::swap(productNext, productCurrent);

      // Exit early to skip next squaring
      if (i == 1)
        break;
    }

    // Square an element
    multiply(*elementNext, *elementCurrent, *elementCurrent);
    std::swap(elementNext, elementCurrent);
  }

  return std::move(*productCurrent);
}



================================================
FILE: labs/memory_bound/loop_interchange_1/solution.h
================================================

#include <array>
#include <cstdint>

// Assume this constant never changes
constexpr int N = 400;

// Square matrix 400 x 400
using Matrix = std::array<std::array<float, N>, N>;

void zero(Matrix &result);
void identity(Matrix &result);
void multiply(Matrix &result, const Matrix &a, const Matrix &b);
Matrix power(const Matrix &input, const uint32_t k);

void init(Matrix &matrix);



================================================
FILE: labs/memory_bound/loop_interchange_1/validate.cpp
================================================

#include "solution.h"
#include <algorithm>
#include <cmath>
#include <iostream>
#include <limits>
#include <memory>

static bool equals(const Matrix &a, const Matrix &b) {
  constexpr int maxErrors = 10;
  const float epsilon = std::sqrt(std::numeric_limits<float>::epsilon());

  int errors = 0;
  for (int i = 0; i < N; i++) {
    for (int j = 0; j < N; j++) {
      float va = a[i][j];
      float vb = b[i][j];
      float error = std::abs(va - vb);
      if (error >= epsilon) {
        std::cerr << "Result[" << i << ", " << j << "] = " << va
                  << ". Expected[" << i << ", " << j << "] = " << vb
                  << std::endl;
        if (++errors >= maxErrors)
          return false;
      }
    }
  }
  return 0 == errors;
}

int main() {
  constexpr int k = 15;
  constexpr int k1 = 5;

  std::unique_ptr<Matrix> a(new Matrix());
  std::unique_ptr<Matrix> b(new Matrix());
  std::unique_ptr<Matrix> c(new Matrix());
  std::unique_ptr<Matrix> d(new Matrix());

  init(*a);
  zero(*b);
  identity(*c);
  identity(*d);
  {
    multiply(*b, *a, *d);
    if (!equals(*b, *a)) {
      std::cerr << "Validation Failed. a * 1" << std::endl;
      return 1;
    }
  }
  {
    multiply(*b, *a, *a);
    *c = power(*a, 2);
    if (!equals(*b, *c)) {
      std::cerr << "Validation Failed. a^2" << std::endl;
      return 1;
    }
  }
  *b = power(*a, k);
  *c = power(*a, k1);
  *d = power(*a, k - k1);
  multiply(*a, *c, *d);
  if (!equals(*a, *b)) {
    std::cerr << "Validation Failed. a^k" << std::endl;
    return 1;
  }

  std::cout << "Validation Successful" << std::endl;
  return 0;
}



================================================
FILE: labs/memory_bound/loop_interchange_2/README.md
================================================
This is a lab about [loop interchange](https://en.wikipedia.org/wiki/Loop_interchange), which is more advanced than the previous one.

[<img src="../../../img/LoopInterchange2-Intro.png">](https://www.youtube.com/watch?v=vsvdtOgBHWo&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d)

In this lab assignment you will optimize [Gaussian blur](https://en.wikipedia.org/wiki/Gaussian_blur) algorithm applied to a grayscale image.
Modern cameras have good matrices and produce big files. How fast can modern CPU filter a camera shot?
Significant speedup has been already achieved by two passes of 1-dimensional digital filter instead of a plain 2D convolution.

[<img src="../../../img/LoopInterchange2-Summary.png">](https://www.youtube.com/watch?v=uUPOKCT8lyo&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d)



================================================
FILE: labs/memory_bound/loop_interchange_2/bench.cpp
================================================

#include "benchmark/benchmark.h"
#include "solution.h"
#include <cstdio>
#include <iostream>

// Variables for passed arguments
static std::string input, output;

static void bench1(benchmark::State &state) {
  // Delete an output file for the case of possible crash
  std::remove(output.data());

  Grayscale image;
  if (image.load(input, kMaxImageDimension)) {
    decltype(Grayscale::data) result(new uint8_t[image.size]);
    decltype(Grayscale::data) temp(new uint8_t[image.size]);
    if (result && temp) {
      for (auto _ : state) {
        blur(result.get(), image.data.get(), image.width, image.height,
             temp.get());
        benchmark::DoNotOptimize(image);
      }

      std::swap(image.data, result);
      image.save(output);
      return;
    }
  }

  state.SkipWithError("An IO problem");
}

// Register the function as a benchmark
BENCHMARK(bench1);

// Run the benchmark
int main(int argc, char **argv) {
  constexpr int mandatoryArgumentsCount = 2;
  if (argc < 1 + mandatoryArgumentsCount) {
    std::cerr << "Usage: input.pgm output.pgm [--name=value...]" << std::endl;
    return 1;
  }
  input = argv[1];
  output = argv[2];

  ::benchmark::Initialize(&argc, argv);
  if (::benchmark::ReportUnrecognizedArguments(argc - mandatoryArgumentsCount,
                                               argv + mandatoryArgumentsCount))
    return 1;
  ::benchmark::RunSpecifiedBenchmarks();
  return 0;
}



================================================
FILE: labs/memory_bound/loop_interchange_2/CMakeLists.txt
================================================
cmake_minimum_required(VERSION 3.3)

project(lab)

set(VALIDATE_ARGS "${CMAKE_CURRENT_SOURCE_DIR}/pexels-pixabay-434334.pbm" "${CMAKE_CURRENT_SOURCE_DIR}/output-golden.pgm")
set(LAB_ARGS "${CMAKE_CURRENT_SOURCE_DIR}/pexels-pixabay-434334.pbm" "output.pgm")

string(REGEX MATCH "^(.*)[\\/]labs[\\/].*$" repo "${CMAKE_CURRENT_SOURCE_DIR}")
include(${CMAKE_MATCH_1}/tools/labs.cmake)



================================================
FILE: labs/memory_bound/loop_interchange_2/solution.cpp
================================================

#include "solution.h"
#include <algorithm>
#include <fstream>
#include <ios>

// Applies Gaussian blur in independent vertical lines
static void filterVertically(uint8_t *output, const uint8_t *input,
                             const int width, const int height,
                             const int *kernel, const int radius,
                             const int shift) {
  const int rounding = 1 << (shift - 1);

  for (int c = 0; c < width; c++) {
    // Top part of line, partial kernel
    for (int r = 0; r < std::min(radius, height); r++) {
      // Accumulation
      int dot = 0;
      int sum = 0;
      auto p = &kernel[radius - r];
      for (int y = 0; y <= std::min(r + radius, height - 1); y++) {
        int weight = *p++;
        dot += input[y * width + c] * weight;
        sum += weight;
      }

      // Normalization
      int value = static_cast<int>(dot / static_cast<float>(sum) + 0.5f);
      output[r * width + c] = static_cast<uint8_t>(value);
    }

    // Middle part of computations with full kernel
    for (int r = radius; r < height - radius; r++) {
      // Accumulation
      int dot = 0;
      for (int i = 0; i < radius + 1 + radius; i++) {
        dot += input[(r - radius + i) * width + c] * kernel[i];
      }

      // Fast shift instead of division
      int value = (dot + rounding) >> shift;
      output[r * width + c] = static_cast<uint8_t>(value);
    }

    // Bottom part of line, partial kernel
    for (int r = std::max(radius, height - radius); r < height; r++) {
      // Accumulation
      int dot = 0;
      int sum = 0;
      auto p = kernel;
      for (int y = r - radius; y < height; y++) {
        int weight = *p++;
        dot += input[y * width + c] * weight;
        sum += weight;
      }

      // Normalization
      int value = static_cast<int>(dot / static_cast<float>(sum) + 0.5f);
      output[r * width + c] = static_cast<uint8_t>(value);
    }
  }
}

// Applies Gaussian blur in independent horizontal lines
static void filterHorizontally(uint8_t *output, const uint8_t *input,
                               const int width, const int height,
                               const int *kernel, const int radius,
                               const int shift) {
  const int rounding = 1 << (shift - 1);

  for (int r = 0; r < height; r++) {
    // Left part of line, partial kernel
    for (int c = 0; c < std::min(radius, width); c++) {
      // Accumulation
      int dot = 0;
      int sum = 0;
      auto p = &kernel[radius - c];
      for (int x = 0; x <= std::min(c + radius, width - 1); x++) {
        int weight = *p++;
        dot += input[r * width + x] * weight;
        sum += weight;
      }

      // Normalization
      int value = static_cast<int>(dot / static_cast<float>(sum) + 0.5f);
      output[r * width + c] = static_cast<uint8_t>(value);
    }

    // Middle part of computations with full kernel
    for (int c = radius; c < width - radius; c++) {
      // Accumulation
      int dot = 0;
      for (int i = 0; i < radius + 1 + radius; i++) {
        dot += input[r * width + c - radius + i] * kernel[i];
      }

      // Fast shift instead of division
      int value = (dot + rounding) >> shift;
      output[r * width + c] = static_cast<uint8_t>(value);
    }

    // Right part of line, partial kernel
    for (int c = std::max(radius, width - radius); c < width; c++) {
      // Accumulation
      int dot = 0;
      int sum = 0;
      auto p = kernel;
      for (int x = c - radius; x < width; x++) {
        int weight = *p++;
        dot += input[r * width + x] * weight;
        sum += weight;
      }

      // Normalization
      int value = static_cast<int>(dot / static_cast<float>(sum) + 0.5f);
      output[r * width + c] = static_cast<uint8_t>(value);
    }
  }
}

// Applies Gaussian blur to a grayscale image
void blur(uint8_t *output, const uint8_t *input, const int width,
          const int height, uint8_t *temp) {
  // Integer Gaussian blur with kernel size 5
  // https://en.wikipedia.org/wiki/Kernel_(image_processing)
  constexpr int radius = 2;
  constexpr int kernel[radius + 1 + radius] = {1, 4, 6, 4, 1};
  // An alternative to division by power of two = sum(kernel)
  constexpr int shift = 4;

  // A pair of 1-dimensional passes to achieve 2-dimensional transform
  filterVertically(temp, input, width, height, kernel, radius, shift);
  filterHorizontally(output, temp, width, height, kernel, radius, shift);
}

// Loads grayscale image. Format is
// https://people.sc.fsu.edu/~jburkardt/data/pgmb/pgmb.html Function doesn't
// support comments.
bool Grayscale::load(const std::string &filename, const int maxSize) {
  data.reset();

  std::ifstream input(filename.data(),
                      std::ios_base::in | std::ios_base::binary);
  if (input.is_open()) {
    std::string line;
    input >> line;
    if (line == "P5") {
      int amplitude;
      input >> width >> height >> amplitude;

      char c;
      input.unsetf(std::ios_base::skipws);
      input >> c;

      if ((width > 0) && (width <= maxSize) && (height > 0) &&
          (height <= maxSize) && (amplitude >= 0) && (amplitude <= 255) &&
          (c == '\n')) {
        size = static_cast<size_t>(width) * static_cast<size_t>(height);
        data.reset(new uint8_t[size]);
        if (data) {
          input.read(reinterpret_cast<char *>(data.get()), size);
          if (input.fail()) {
            data.reset();
          }
        }
      }
    }

    input.close();
  }

  return !!data;
}

// Saves grayscale image. Format is
// https://people.sc.fsu.edu/~jburkardt/data/pgmb/pgmb.html
void Grayscale::save(const std::string &filename) {
  std::ofstream output(filename.data(),
                       std::ios_base::out | std::ios_base::binary);
  if (output.is_open()) {
    output << "P5" << std::endl
           << width << ' ' << height << std::endl
           << "255" << std::endl;
    if (data) {
      output.write(reinterpret_cast<const char *>(data.get()), size);
    }
    output.close();
  }
}



================================================
FILE: labs/memory_bound/loop_interchange_2/solution.h
================================================

#include <cstdint>
#include <memory>
#include <string>

// Applies Gaussian blur to a grayscale image
void blur(uint8_t *output, const uint8_t *input, const int width,
          const int height, uint8_t *temp);

struct Grayscale {
  std::unique_ptr<uint8_t[]> data;
  size_t size = 0;
  int width = 0, height = 0;

  bool load(const std::string &filename, const int maxSize);
  void save(const std::string &filename);
};

constexpr int kMaxImageDimension = 32 * 1024;



================================================
FILE: labs/memory_bound/loop_interchange_2/validate.cpp
================================================

#include "solution.h"
#include <cstring>
#include <iostream>

int main(int argc, char **argv) {
  constexpr int mandatoryArgumentsCount = 2;
  if (argc != 1 + mandatoryArgumentsCount) {
    std::cerr << "Usage: input.pgm output-golden.pgm" << std::endl;
    return 1;
  }
  const std::string input = argv[1];
  const std::string outputGolden = argv[2];

  Grayscale image;
  if (image.load(input, kMaxImageDimension)) {
    Grayscale image2;
    if (image2.load(outputGolden, kMaxImageDimension)) {
      // Copied & pasted
      {
        decltype(Grayscale::data) result(new uint8_t[image.size]);
        decltype(Grayscale::data) temp(new uint8_t[image.size]);
        if (!result || !temp) {
          std::cerr << "Validation Failed. Out of memory" << std::endl;
          return 1;
        }

        blur(result.get(), image.data.get(), image.width, image.height,
             temp.get());
        std::swap(image.data, result);
      }

      if ((image.width != image2.width) || (image.height != image2.height)) {
        std::cerr << "Validation Failed. Wrong image dimensions " << image.width
                  << 'x' << image.height << std::endl;
        return 1;
      }

      auto p1 = image.data.get();
      auto p2 = image2.data.get();
      if (std::memcmp(p1, p2, image.size) == 0) {
        std::cout << "Validation Successful" << std::endl;
        return 0;
      }

      std::cerr << "Validation Failed. Distinct images" << std::endl;
      int downcount = 10;
      for (size_t i = 0; i < image.size; i++) {
        if (p1[i] != p2[i]) {
          std::cerr << "Result[" << i << "] = " << static_cast<int>(p1[i])
                    << ". Expected[" << i << "] = " << static_cast<int>(p2[i])
                    << std::endl;
          if (--downcount <= 0)
            break;
        }
      }
      return 1;
    }
  }

  std::cerr << "Validation Failed. An IO problem" << std::endl;
  return 1;
}



================================================
FILE: labs/memory_bound/loop_tiling_1/README.md
================================================
[<img src="../../../img/LoopTiling1.png">](https://www.youtube.com/watch?v=wPcDgju8VkI&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d)

Loop tiling (blocking) is an important technique that you can use to speed up code that is working with multi-dimensional arrays. If one of the memory access patterns on your array is column-wise, or if in the code you are accessing the same data several times in the loop, this technique can be very beneficial for the performance. It is often seen in matrix multiplication and matrix rotation operations, to speed them up.

Every time the CPU loads a new element of a matrix, it also fetches a few neighboring elements (cache line) belonging to the same row. If matrices are big and you are accessing a matrix column-wise, performance of your code may suffer from poor cache utilization. Because by the time you access the second element in the first row, it's no longer in the cache since it was replaced by the cache lines with elements from other rows of the matrix.

So, instead of going through the whole matrix at once, you can split it into small chunks, which entirely fit into a CPU cache. By processing matrix in blocks (tiles), you are reusing the elements of the matrix which are in the CPU cache and this will give your code a speed boost. Picking the right value for the TILE_SIZE is experimental and depends both on the HW architecture and the algorithm itself. Hint: you can use Roofline Performance analysis (in Intel Advisor or other tools) to determine what's limiting performance of the loop.

Authored-by: @ibogosavljevic



================================================
FILE: labs/memory_bound/loop_tiling_1/bench.cpp
================================================

#include "benchmark/benchmark.h"
#include "solution.hpp"

static void bench1(benchmark::State &state) {
  constexpr int N = 2000;

  MatrixOfDoubles in;
  MatrixOfDoubles out;
  in.resize(N, std::vector<double>(N, 0.0));
  out.resize(N, std::vector<double>(N, 0.0));

  // Init benchmark data
  initMatrix(in);

  // Run the benchmark
  for (auto _ : state) {
    auto output = solution(in, out);
    benchmark::DoNotOptimize(output);
  }
}

// Register the function as a benchmark and measure time in microseconds
BENCHMARK(bench1)->Unit(benchmark::kMillisecond);

// Run the benchmark
BENCHMARK_MAIN();



================================================
FILE: labs/memory_bound/loop_tiling_1/CMakeLists.txt
================================================
cmake_minimum_required(VERSION 3.3)

project(lab)

string(REGEX MATCH "^(.*)[\\/]labs[\\/].*$" repo "${CMAKE_CURRENT_SOURCE_DIR}")
include(${CMAKE_MATCH_1}/tools/labs.cmake)



================================================
FILE: labs/memory_bound/loop_tiling_1/init.cpp
================================================
#include "solution.hpp"

void initMatrix(MatrixOfDoubles &m) {
  auto size = m.size();
  for (int i = 0; i < size; i++)
    for (int j = 0; j < size; j++)
      m[i][j] = (i + j) % 1024;
}



================================================
FILE: labs/memory_bound/loop_tiling_1/solution.cpp
================================================
#include "solution.hpp"
#include <algorithm>

bool solution(MatrixOfDoubles &in, MatrixOfDoubles &out) {
  int size = in.size();
  for (int i = 0; i < size; i++) {
    for (int j = 0; j < size; j++) {
      out[i][j] = in[j][i];
    }
  }
  return out[0][size - 1];
}



================================================
FILE: labs/memory_bound/loop_tiling_1/solution.hpp
================================================
#include <vector>

using MatrixOfDoubles = std::vector<std::vector<double>>;
void initMatrix(MatrixOfDoubles& m);
bool solution(MatrixOfDoubles& in, MatrixOfDoubles& out);



================================================
FILE: labs/memory_bound/loop_tiling_1/validate.cpp
================================================
#include "solution.hpp"
#include <iostream>

bool original_solution(MatrixOfDoubles &in, MatrixOfDoubles &out) {
  auto size = in.size();
  for (int i = 0; i < size; i++)
    for (int j = 0; j < size; j++)
      out[i][j] = in[j][i];

  return out[0][size - 1];
}

bool matrices_equal(MatrixOfDoubles &m1, MatrixOfDoubles &m2) {
  if (m1.size() != m2.size())
    return false;

  auto size = m1.size();
  for (int i = 0; i < size; i++)
    for (int j = 0; j < size; j++)
      if (m1[i][j] != m2[i][j])
        return false;

  return true;
}

int main() {
  MatrixOfDoubles in;
  MatrixOfDoubles out;
  MatrixOfDoubles out_golden;

  constexpr int N = 2001;
  in.resize(N, std::vector<double>(N, 0.0));
  out.resize(N, std::vector<double>(N, 0.0));
  out_golden.resize(N, std::vector<double>(N, 0.0));

  // Init benchmark data
  initMatrix(in);

  original_solution(in, out_golden);
  solution(in, out);

  if (!matrices_equal(out, out_golden)) {
    std::cerr << "Validation Failed\n";
    return 1;
  }

  std::cout << "Validation Successful\n";
  return 0;
}



================================================
FILE: labs/memory_bound/mem_alignment_1/README.md
================================================
## Memory Alignment

*Yes, it is matrix multiplication... again*

Contrary to what some people believe or may have heard somewhere, memory alignment is still required in some cases to achieve optimal performance. This lab assignment is one such case. First, a little introduction.

A typical case where data alignment is important is SIMD code, where loads and stores access large chunks of data with a single operation. In most processors, the L1 cache is designed to be able to read/write data at any alignment. Generally, even if a load/store is misaligned but does not cross the cache line boundary, it won't have any performance penalty. However, when a load or store crosses cache line boundary, such access requires two cache line reads (*split load/store*). It requires using a *split register*, which keeps the two parts and once both parts are fetched, they are combined into a single register. The number of split registers is limited. When executed sporadically, split accesses generally complete without any observable performance impact to overall execution. However, if that happens frequently, misaligned memory accesses will suffer delays.

Our simple matrix multiply generates SIMD instructions. For small-size matrices we use a regular version with loop interchange to achive cache-friendly accesses and vectorized code. For larger sizes, we rolled up a version that uses Loop Blocking. We provide all the boiler-plate code so that you only need to change a couple of lines.

When a matrix is misaligned, split loads happen very frequently which causes performance problems. In this lab you need to fix that. **Important**: It's not enough to only align the offset of a matrix, but also each row of the matrix has to be aligned. To do that you can insert dummy columns.

For AVX2 code, it is enough when each row is aligned at 32-byte boundary and for SSE and ARM Neon only 16-byte alignment is required. However, AVX-512 requires 64-byte alignment. To be on the safe side, you can align at the cacheline boundary. Keep in mind, in Apple processors (such as M1, M2 and later), L2 cache operates on 128-byte cache lines.

If you're actively using Intel's topdown methodology (TMA), then it will be reflected under `Memory_Bound -> L1_Bound -> Split Loads` category. When you improve the alignment, observe the change in the following events: `mem_inst_retired.split_loads`, and `mem_inst_retired.split_stores`.

Keep in mind, that performance penalty applies to both loads *and* stores, so all matrices should be aligned.


================================================
FILE: labs/memory_bound/mem_alignment_1/bench.cpp
================================================

#include "benchmark/benchmark.h"
#include "solution.h"
#include <memory>

template <class ...Args>
static void bench1(benchmark::State &state, Args&&... args) {
  auto args_tuple = std::make_tuple(std::move(args)...);
  size_t N = std::get<0>(args_tuple);
  const int K = n_columns(N);

  Matrix a1; a1.resize(N * K);  initRandom(a1, N, K);
  Matrix b1; b1.resize(N * K);  initRandom(b1, N, K);
  Matrix c1; c1.resize(N * K);  initZero  (c1, N, K);

  for (auto _ : state) {
    if (N < 100) {
      // for small matrices we can use a very simple GEMM implementation
      interchanged_matmul(a1.data(), b1.data(), c1.data(), N, K);
    } else {
      // for large matrices we use a blocked version
      blocked_matmul(a1.data(), b1.data(), c1.data(), N, K);
    }
    benchmark::DoNotOptimize(c1);
  }
}

// To make CI testing fast, we disabled most of the test cases below.
// However, we encourage you to benchmark many different matrix sizes.

// On macOS, it seems that the OS always properly aligns 
// matrices with sizes of powers of two, e.g. 64, 128, etc.
// That's why we don't see speedups on macOS for such matrices.

BENCHMARK_CAPTURE(bench1, _63,  63)->Unit(benchmark::kMicrosecond);
#ifndef ON_MACOS
BENCHMARK_CAPTURE(bench1, _64,  64)->Unit(benchmark::kMicrosecond);
#endif
BENCHMARK_CAPTURE(bench1, _65,  65)->Unit(benchmark::kMicrosecond);
//BENCHMARK_CAPTURE(bench1, _71,  71)->Unit(benchmark::kMicrosecond);
//BENCHMARK_CAPTURE(bench1, _72,  72)->Unit(benchmark::kMicrosecond);
//BENCHMARK_CAPTURE(bench1, _73,  73)->Unit(benchmark::kMicrosecond);
//BENCHMARK_CAPTURE(bench1, _79,  79)->Unit(benchmark::kMicrosecond);
//BENCHMARK_CAPTURE(bench1, _80,  80)->Unit(benchmark::kMicrosecond);
//BENCHMARK_CAPTURE(bench1, _81,  81)->Unit(benchmark::kMicrosecond);
//BENCHMARK_CAPTURE(bench1, _127, 127)->Unit(benchmark::kMicrosecond);
#ifndef ON_MACOS
BENCHMARK_CAPTURE(bench1, _128, 128)->Unit(benchmark::kMicrosecond);
#endif
//BENCHMARK_CAPTURE(bench1, _129, 129)->Unit(benchmark::kMicrosecond);
//BENCHMARK_CAPTURE(bench1, _255, 255)->Unit(benchmark::kMicrosecond);
#ifndef ON_MACOS
BENCHMARK_CAPTURE(bench1, _256, 256)->Unit(benchmark::kMicrosecond);
#endif
//BENCHMARK_CAPTURE(bench1, _257, 257)->Unit(benchmark::kMicrosecond);
BENCHMARK_CAPTURE(bench1, _511, 511)->Unit(benchmark::kMicrosecond);
#ifndef ON_MACOS
BENCHMARK_CAPTURE(bench1, _512, 512)->Unit(benchmark::kMicrosecond);
#endif
BENCHMARK_CAPTURE(bench1, _513, 513)->Unit(benchmark::kMicrosecond);
//BENCHMARK_CAPTURE(bench1, _1023, 1023)->Unit(benchmark::kMicrosecond);
#ifndef ON_MACOS
BENCHMARK_CAPTURE(bench1, _1024, 1024)->Unit(benchmark::kMicrosecond);
#endif
//BENCHMARK_CAPTURE(bench1, _1025, 1025)->Unit(benchmark::kMicrosecond);

// Run the benchmark
BENCHMARK_MAIN();



================================================
FILE: labs/memory_bound/mem_alignment_1/CMakeLists.txt
================================================
cmake_minimum_required(VERSION 3.3)

project(lab)

string(REGEX MATCH "^(.*)[\\/]labs[\\/].*$" repo "${CMAKE_CURRENT_SOURCE_DIR}")
include(${CMAKE_MATCH_1}/tools/labs.cmake)



================================================
FILE: labs/memory_bound/mem_alignment_1/solution.cpp
================================================

#include "solution.h"
#include <random>

// ******************************************
// Change this function
// ******************************************
// This function allows you to change the number of columns in a matrix. 
// In other words, it defines how many elements are in each row.
// hint: you need to allocate dummy columns to achieve proper data alignment.
int n_columns(int N) {  
  return N;
}
// ******************************************

// DO NOT change any of the functions below.
// The following applies to all functions below:
// You will notice the functions have `K` argument in addition to `N`.
// This is because these functions are prepared for matrices with aligned rows.
// I.e. a matrix has N x N elements, but its actual dimensions are N x K since
// it has padding. However, only N x N elements are used.
void initRandom(Matrix &matrix, int N, int K) {
  std::default_random_engine generator;
  std::uniform_real_distribution<float> distribution(-0.95f, 0.95f);
  for (int i = 0; i < N; i++)
    for (int j = 0; j < N; j++)
      matrix[i * K + j] = distribution(generator);
}

void initZero(Matrix &matrix, int N, int K) {
  for (int i = 0; i < N; i++)
    for (int j = 0; j < N; j++)
      matrix[i * K + j] = 0.0f;
}

void copyFromMatrix(const Matrix &from, Matrix &to, int N, int K) {
  for (int i = 0; i < N; i++)
    for (int j = 0; j < N; j++)
      to[i * K + j] = from[i * N + j];
}

// A simple GEMM. Use only for small matrices (up to 100 x 100)
void interchanged_matmul(float* RESTRICT A, 
                         float* RESTRICT B,
                         float* RESTRICT C, int N, int K) {
  for (int i = 0; i < N; ++i)
    for (int k = 0; k < N; ++k)
      for (int j = 0; j < N; ++j)
        C[i * K + j] += A[i * K + k] * B[k * K + j];
}

// Here is a blocked version for larger matrix sizes (e.g. 512 x 512 and beyond).
void blocked_matmul(float* RESTRICT A, 
                    float* RESTRICT B,
                    float* RESTRICT C, int N, int K) {
  constexpr int blockSize = 64;
  for (int ii = 0; ii < N; ii += blockSize)
    for (int kk = 0; kk < N; kk += blockSize)
      for (int jj = 0; jj < N; jj += blockSize)
        for (int i = ii; i < std::min(ii + blockSize, N); ++i)
          for (int k = kk; k < std::min(kk + blockSize, N); ++k)
            for (int j = jj; j < std::min(jj + blockSize, N); ++j)                        
              C[i * K + j] += A[i * K + k] * B[k * K + j];
}



================================================
FILE: labs/memory_bound/mem_alignment_1/solution.h
================================================
#include <memory>
#include <vector>

#if defined(__APPLE__) && defined(__MACH__)
  // In Apple processors (such as M1, M2 and later), L2 cache operates on 128B cache lines.
  #define ON_MACOS
  #define CACHELINE_SIZE 128
#else
  #define CACHELINE_SIZE 64
#endif

#if defined(_MSC_VER)
  #define RESTRICT __restrict
#else
  #define RESTRICT __restrict__
#endif

template <typename T>
class CacheLineAlignedAllocator {
public:
  using value_type = T;
  static std::align_val_t constexpr ALIGNMENT{CACHELINE_SIZE};
  [[nodiscard]] T* allocate(std::size_t N) {
    return reinterpret_cast<T*>(::operator new[](N * sizeof(T), ALIGNMENT));
  }
  void deallocate(T* allocPtr, [[maybe_unused]] std::size_t N) {
    ::operator delete[](allocPtr, ALIGNMENT);
  }
};
template<typename T> 
using AlignedVector = std::vector<T, CacheLineAlignedAllocator<T> >;

// ******************************************
// Change this place
// ******************************************
// hint: use AlignedVector instead of std::vector 
//       to align the beginning of a matrix
using Matrix = std::vector<float>;
// ******************************************

static bool isCacheLineAligned(const Matrix& m) {
  uint64_t ptr = (uint64_t)m.data();
  return ptr % CACHELINE_SIZE == 0;
}

int n_columns(int N);
void initRandom(Matrix &matrix, int N, int K);
void initZero(Matrix &matrix, int N, int K);
void copyFromMatrix(const Matrix &from, Matrix &to, int N, int K);
void interchanged_matmul(float* RESTRICT A, 
                         float* RESTRICT B,
                         float* RESTRICT C, int N, int K);
void blocked_matmul     (float* RESTRICT A, 
                         float* RESTRICT B,
                         float* RESTRICT C, int N, int K);


================================================
FILE: labs/memory_bound/mem_alignment_1/validate.cpp
================================================

#include "solution.h"
#include <cmath>
#include <iostream>

static void original_matmul(float* RESTRICT A, 
                            float* RESTRICT B,
                            float* RESTRICT C, int N) {
  for (int i = 0; i < N; ++i)
    for (int k = 0; k < N; ++k)
      for (int j = 0; j < N; ++j)
        C[i * N + j] += A[i * N + k] * B[k * N + j];
}

// Both matrices have N x N elements, but matrix A can have padding, 
// so matrix A can have dimensions N x K, even though only N x N are used.
static bool equals(const Matrix &a, const Matrix &b, int N, int K) {
  constexpr int maxErrors = 10;
  const float epsilon = std::sqrt(std::numeric_limits<float>::epsilon());

  int errors = 0;
  for (int i = 0; i < N; i++) {
    for (int j = 0; j < N; j++) {
      float va = a[i * K + j];
      float vb = b[i * N + j];
      float error = std::abs(va - vb);
      if (error >= epsilon) {
        std::cerr << "Result[" << i << ", " << j << "] = " << va
                  << ". Expected[" << i << ", " << j << "] = " << vb
                  << std::endl;
        if (++errors >= maxErrors)
          return false;
      }
    }
  }
  return 0 == errors;
}

int smokeTest() {
  const int N = 5;
    Matrix a1 = {
         0.12f, -0.34f,  0.56f,  0.78f, -0.90f,
         0.11f,  0.22f, -0.33f,  0.44f,  0.55f,
        -0.66f,  0.77f, -0.88f,  0.99f,  0.10f,
         0.21f,  0.32f,  0.43f,  0.54f,  0.65f,
        -0.12f, -0.23f, -0.34f, -0.45f,  0.56f
    };

    Matrix b1 = {
         0.45f, -0.55f,  0.65f, -0.75f,  0.85f,
        -0.15f,  0.25f, -0.35f,  0.45f, -0.55f,
         0.85f, -0.75f,  0.65f, -0.55f,  0.45f,
        -0.25f,  0.35f, -0.45f,  0.55f, -0.65f,
         0.55f, -0.45f,  0.35f, -0.25f,  0.15f
    };

    Matrix expected = {
        -0.109f,  0.107f, -0.105f,  0.103f, -0.101f,
        -0.0715f, 0.1485f,-0.2255f, 0.3025f,-0.3795f,
        -1.353f,  1.517f, -1.681f,  1.845f, -2.009f,
         0.6345f,-0.4615f, 0.2885f,-0.1155f,-0.0575f,
         0.112f, -0.146f,  0.18f,  -0.214f,  0.248f
    };

  Matrix c1; c1.resize(N * N);  initZero (c1, N, N);
  original_matmul    (a1.data(), b1.data(), c1.data(), N);
  if (!equals(c1, expected, N, N))
    return 1;

  const int K = n_columns(N);
  Matrix a2; a2.resize(N * K);  copyFromMatrix(a1, a2, N, K);
  Matrix b2; b2.resize(N * K);  copyFromMatrix(b1, b2, N, K);
  Matrix c2; c2.resize(N * K);  initZero      (c2, N, K);

  interchanged_matmul(a2.data(), b2.data(), c2.data(), N, K);
  if (!equals(c2, expected, N, K))
    return 1;

  initZero      (c2, N, K);
  blocked_matmul(a2.data(), b2.data(), c2.data(), N, K);
  if (!equals(c2, expected, N, K))
    return 1;

  return 0;
}

int testSize(int N) {
  const int K = n_columns(N);

  Matrix a1; a1.resize(N * N);  initRandom    (a1, N, N);
  Matrix b1; b1.resize(N * N);  initRandom    (b1, N, N);
  Matrix c1; c1.resize(N * N);  initZero      (c1, N, N);
  Matrix a2; a2.resize(N * K);  copyFromMatrix(a1, a2, N, K);
  Matrix b2; b2.resize(N * K);  copyFromMatrix(b1, b2, N, K);
  Matrix c2; c2.resize(N * K);  initZero      (c2, N, K);

  original_matmul    (a1.data(), b1.data(), c1.data(), N);
  interchanged_matmul(a2.data(), b2.data(), c2.data(), N, K);
  if (!equals(c2, c1, N, K)) {
    std::cerr << "Validation Failed: interchanged_matmul " << N << std::endl;
    return 1;
  }

  initZero      (c2, N, K);
  blocked_matmul(a2.data(), b2.data(), c2.data(), N, K);
  if (!equals(c2, c1, N, K)) {
    std::cerr << "Validation Failed: blocked_matmul " << N << std::endl;
    return 1;
  }

  return 0;
}

int main() {
  if (smokeTest()) {
    std::cerr << "Smoke test failed: " << std::endl;
    return 1;
  }
  if (testSize(1))  return 1;
  if (testSize(10)) return 1;
  if (testSize(63)) return 1;
  if (testSize(64)) return 1;
  if (testSize(65)) return 1;
  if (testSize(127)) return 1;
  if (testSize(128)) return 1;
  if (testSize(129)) return 1;
  if (testSize(255)) return 1;
  if (testSize(256)) return 1;
  if (testSize(257)) return 1;
  if (testSize(511)) return 1;
  if (testSize(512)) return 1;
  if (testSize(513)) return 1;  
  if (testSize(1023)) return 1;
  if (testSize(1024)) return 1;
  if (testSize(1025)) return 1;    
  std::cout << "Validation Successful" << std::endl;  
}



================================================
FILE: labs/memory_bound/mem_order_violation_1/README.md
================================================
This lab features an oldie-but-goodie Otsu's thresholding[^1] to convert a grayscale[^2] image to a binary[^3] image. One of the key parts in this algorithm is calculating a histogram of a grayscale image, i.e., calculate how many times a certain color appears in the image. Since the input image is 8-bit grayscale, there are only 256 different colors.

```cpp
std::array<uint32_t, 256> hist;
hist.fill(0);
for (int i = 0; i < image.width * image.height; ++i)
  hist[image.data[i]]++;
```

The implementation of the histogram algortihm is very simple but it has one nasty property. For each pixel on the image, you need to 1) read the current value of the corresponding color of the pixel, 2) increment it and 3) store it back.

When updates of the same color in the histogram occur at relatively high rates, the processor may not have completed updating pixel `i` prior to beginning pixel `i+1`. In such cases, a processor predicts whether the value loaded for the `i+1` update will come from memory or from the `i`'s store. If from memory, the two updates can be performed in parallel, otherwise the processor must serialize the updates.

Simple example: if you have the following pixels in the image:
```
0xFF 0xFF 0xFF 0xFF 0xFF 0xFF ...
```
Then all updates to `hist[0xFF]` will be serialized.

Think about how you can workaround this problem. Hint: you can use aditional memory.

Bonus exercise1: what would be the worst and the best cases for the original implementation and your solution?

Input images were taken from here: https://people.sc.fsu.edu/~jburkardt/data/pgmb/pgmb.html

[^1]: https://en.wikipedia.org/wiki/Otsu%27s_method
[^2]: https://en.wikipedia.org/wiki/Grayscale
[^3]: https://en.wikipedia.org/wiki/Binary_image



================================================
FILE: labs/memory_bound/mem_order_violation_1/bench.cpp
================================================

#include "benchmark/benchmark.h"
#include "solution.h"
#include "DataPaths.h"

constexpr const char *file_names[] = {bird, coins, pepper, pixabay};

static void bench1(benchmark::State &state) {
  const char *input = file_names[state.range(0)];
  GrayscaleImage image;
  if (!image.load(input, kMaxImageDimension)) {
    state.SkipWithError("An IO problem");
    return;
  }

  std::string output = state.name() + "-binary.pgm";
  // Delete an output file
  std::remove(output.data());

  // Only benchmark the histogram part
  std::array<uint32_t, 256> hist;
  for (auto _ : state) {
    hist = computeHistogram(image);
    benchmark::DoNotOptimize(hist);
  }
  
  // Proceed with the rest of the algorithm
  auto totalPixels = image.height * image.width;
  int threshold = calcOtsuThreshold(hist, totalPixels);
  // Apply Otsu's thresholding
  for (int i = 0; i < totalPixels; ++i)
    image.data[i] = (image.data[i] >= threshold) ? 255 : 0;
  // save the output
  image.save(output); 
}

// Register the bench1 function as a benchmark
BENCHMARK(bench1)->Unit(benchmark::kMicrosecond)->Arg(0)->Name("bird");
BENCHMARK(bench1)->Unit(benchmark::kMicrosecond)->Arg(1)->Name("coins");
BENCHMARK(bench1)->Unit(benchmark::kMicrosecond)->Arg(2)->Name("pepper");
BENCHMARK(bench1)->Unit(benchmark::kMillisecond)->Arg(3)->Name("pixabay");

BENCHMARK_MAIN();


================================================
FILE: labs/memory_bound/mem_order_violation_1/CMakeLists.txt
================================================
cmake_minimum_required(VERSION 3.3)

project(lab)

set(LAB_DATA_PATH "${CMAKE_CURRENT_SOURCE_DIR}/data")
set(BIRD_PATH "${LAB_DATA_PATH}/bird.pgm")
set(COINS_PATH "${LAB_DATA_PATH}/coins.pgm")
set(PEPPER_PATH "${LAB_DATA_PATH}/pepper.pgm")
set(PIXABAY_PATH "${CMAKE_CURRENT_SOURCE_DIR}/../loop_interchange_2/pexels-pixabay-434334.pbm")
configure_file(DataPaths.h.in "${CMAKE_CURRENT_SOURCE_DIR}/DataPaths.h")

set(PEPPER_REF_PATH "${LAB_DATA_PATH}/pepper-binary-ref.pgm")
set(VALIDATE_ARGS "${PEPPER_PATH}" "${PEPPER_REF_PATH}")

string(REGEX MATCH "^(.*)[\\/]labs[\\/].*$" repo "${CMAKE_CURRENT_SOURCE_DIR}")
include(${CMAKE_MATCH_1}/tools/labs.cmake)


================================================
FILE: labs/memory_bound/mem_order_violation_1/DataPaths.h.in
================================================
inline constexpr auto bird = "@BIRD_PATH@";
inline constexpr auto coins = "@COINS_PATH@";
inline constexpr auto pepper = "@PEPPER_PATH@";
inline constexpr auto pixabay = "@PIXABAY_PATH@";



================================================
FILE: labs/memory_bound/mem_order_violation_1/solution.cpp
================================================

#include "solution.h"
#include <algorithm>
#include <fstream>
#include <stdint.h>
#include <cmath>
#include <ios>

// ******************************************
// ONLY THE FOLLOWING FUNCTION IS BENCHMARKED
// Compute the histogram of image pixels
std::array<uint32_t, 256> computeHistogram(const GrayscaleImage& image) {
  std::array<uint32_t, 256> hist;
  hist.fill(0);
  for (int i = 0; i < image.width * image.height; ++i)
    hist[image.data[i]]++;
  return hist;
}
// ******************************************

// Calculate Otsu's Threshold
int calcOtsuThreshold(const std::array<uint32_t, 256>& hist, int totalPixels) {
  // normalize histogram
  std::array<double, 256> normHist;
  for (int i = 0; i < 256; ++i)
    normHist[i] = (double)hist[i] / totalPixels;

  double maxVariance = 0;
  int optimalThreshold = 0;

  // Find the optimal threshold
  for (int t = 0; t < 256; ++t) {
    double weight1 = 0, weight2 = 0, mean1 = 0, mean2 = 0;

    for (int i = 0; i <= t; ++i) {
      weight1 += normHist[i];
      mean1 += i * normHist[i];
    }

    for (int i = t + 1; i < 256; ++i) {
      weight2 += normHist[i];
      mean2 += i * normHist[i];
    }

    if (weight1 == 0 || weight2 == 0) continue;

    mean1 /= weight1;
    mean2 /= weight2;

    double variance = weight1 * weight2 * std::pow(mean1 - mean2, 2);

    if (variance > maxVariance) {
      maxVariance = variance;
      optimalThreshold = t;
    }
  }

  return optimalThreshold;
}

// Function to apply the threshold to create a binary image
void applyOtsuThreshold(GrayscaleImage& image) {
  // Compute the histogram
  std::array<uint32_t, 256> hist = computeHistogram(image);
  auto totalPixels = image.height * image.width;
  int threshold = calcOtsuThreshold(hist, totalPixels);
  // Apply Otsu's thresholding
  for (int i = 0; i < totalPixels; ++i)
    image.data[i] = (image.data[i] >= threshold) ? 255 : 0;
}

// Loads GrayscaleImage image. Format is
// https://people.sc.fsu.edu/~jburkardt/data/pgmb/pgmb.html 
bool GrayscaleImage::load(const std::string &filename, const int maxSize) {
  data.reset();

  std::ifstream input(filename.data(),
                      std::ios_base::in | std::ios_base::binary);
  if (input.is_open()) {
    std::string line;
    input >> line;
    if (line == "P5") {
      int amplitude;
      input >> width >> height >> amplitude;

      char c;
      input.unsetf(std::ios_base::skipws);
      input >> c;
      if (c == '\r')
        input >> c;

      if ((width > 0) && (width <= maxSize) && (height > 0) &&
          (height <= maxSize) && (amplitude >= 0) && (amplitude <= 255) &&
          (c == '\n')) {
        size = static_cast<size_t>(width) * static_cast<size_t>(height);
        data.reset(new uint8_t[size]);
        if (data) {
          input.read(reinterpret_cast<char *>(data.get()), size);
          if (input.fail()) {
            data.reset();
          }
        }
      }
    }

    input.close();
  }

  return !!data;
}

// Saves GrayscaleImage image. Format is
// https://people.sc.fsu.edu/~jburkardt/data/pgmb/pgmb.html
void GrayscaleImage::save(const std::string &filename) {
  std::ofstream output(filename.data(),
                       std::ios_base::out | std::ios_base::binary);
  if (output.is_open()) {
    output << "P5" << std::endl
           << width << ' ' << height << std::endl
           << "255" << std::endl;
    if (data) {
      output.write(reinterpret_cast<const char *>(data.get()), size);
    }
    output.close();
  }
}



================================================
FILE: labs/memory_bound/mem_order_violation_1/solution.h
================================================
#include <cstdint>
#include <memory>
#include <array>
#include <string>

// https://en.wikipedia.org/wiki/Grayscale
struct GrayscaleImage {
  std::unique_ptr<uint8_t[]> data;
  size_t size = 0;
  int width = 0;
  int height = 0;

  bool load(const std::string &filename, const int maxSize);
  void save(const std::string &filename);
};

// Binary (aka monochrome) image
// https://en.wikipedia.org/wiki/Binary_image
// We will represent binary image in the same way as grayscale.
using BinaryImage = GrayscaleImage;

constexpr int kMaxImageDimension = 32 * 1024;

std::array<uint32_t, 256> computeHistogram(const GrayscaleImage& image);
std::array<uint32_t, 256> computeHistogram_solution(const GrayscaleImage& image);
int calcOtsuThreshold(const std::array<uint32_t, 256>& hist, int totalPixels);
void applyOtsuThreshold(GrayscaleImage& image);



================================================
FILE: labs/memory_bound/mem_order_violation_1/validate.cpp
================================================

#include "solution.h"
#include <cstring>
#include <iostream>

static std::array<uint32_t, 256> computeHistogram_original(const GrayscaleImage& image) {
  std::array<uint32_t, 256> hist;
  hist.fill(0);
  for (int i = 0; i < image.width * image.height; ++i)
    hist[image.data[i]]++;
  return hist;
}

int main(int argc, char **argv) {
  constexpr int mandatoryArgumentsCount = 2;
  if (argc != 1 + mandatoryArgumentsCount) {
    std::cerr << "Usage: input.pgm output-golden.pgm" << std::endl;
    return 1;
  }
  const std::string input = argv[1];
  const std::string outputGolden = argv[2];

  GrayscaleImage image;
  if (!image.load(input, kMaxImageDimension)) {
    std::cerr << "Cannot load input image. Validation Failed." << std::endl;
    return 1;
  }

  // smoke test
  auto h1 = computeHistogram(image);
  auto h2 = computeHistogram_original(image);
  if (h1 != h2) {
    std::cerr << "Validation Failed. Smoke test fails" << std::endl;
    int downcount = 10;
    for (size_t i = 0; i < h1.size(); i++) {
      if (h1[i] != h2[i]) {
        std::cerr << "Result[" << i << "] = " << static_cast<int>(h1[i])
                  << ". Expected[" << i << "] = " << static_cast<int>(h2[i])
                  << std::endl;
        if (--downcount <= 0)
          break;
      }
    }
  }

  // testing the whole algorithm on a real image
  BinaryImage goldenImage;
  if (!goldenImage.load(outputGolden, kMaxImageDimension)) {
    std::cerr << "Cannot load golden image. Validation Failed." << std::endl;
    return 1;
  }
  applyOtsuThreshold(image);

  if ((image.width != goldenImage.width) || (image.height != goldenImage.height)) {
    std::cerr << "Validation Failed. Wrong image dimensions " << image.width
              << 'x' << image.height << std::endl;
    return 1;
  }

  auto p1 = image.data.get();
  auto p2 = goldenImage.data.get();
  if (std::memcmp(p1, p2, image.size) == 0) {
    std::cout << "Validation Successful" << std::endl;
    return 0;
  }

  std::cerr << "Validation Failed. Distinct images" << std::endl;
  int downcount = 10;
  for (size_t i = 0; i < image.size; i++) {
    if (p1[i] != p2[i]) {
      std::cerr << "Result[" << i << "] = " << static_cast<int>(p1[i])
                << ". Expected[" << i << "] = " << static_cast<int>(p2[i])
                << std::endl;
      if (--downcount <= 0)
        break;
    }
  }
  return 1;  
}



================================================
FILE: labs/memory_bound/mem_order_violation_1/data/bird.pgm
================================================
[Binary file]


================================================
FILE: labs/memory_bound/mem_order_violation_1/data/coins.pgm
================================================
Error reading file with 'utf-8': 'utf-8' codec can't decode byte 0x87 in position 1959: invalid start byte


================================================
FILE: labs/memory_bound/mem_order_violation_1/data/pepper-binary-ref.pgm
================================================
[Binary file]


================================================
FILE: labs/memory_bound/mem_order_violation_1/data/pepper.pgm
================================================
[Binary file]


================================================
FILE: labs/memory_bound/swmem_prefetch_1/README.md
================================================
# Software memory prefetching

[<img src="../../../img/SWMemPrefetch1-Intro.png">](https://www.youtube.com/watch?v=yTkaLNuUCXw&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d)

When the CPU data prefetcher cannot figure out the memory access pattern, software prefetching comes in handy. The idea is to use special instructions that tell the CPU: "Hey, I plan to use this memory location a bit later, could you fetch it for me while I do other stuff so it waits for me when I am back".

In GCC and CLANG, you can use `__builtin_prefetch` to ask the CPU to prefetch data. Say, for example, that you are going to access an element of array `my_array[index]`, where `index` is some random number. To prefetch it, you will use `__builtin_prefetch(&my_array[index]);` or `__builtin_prefetch(&my_array + index);`.

Prefetching can benefit the performance, but it can also hurt the performance. It benefits it if the piece of data you are trying to access is not in the data cache. It hurts it if it is. So most of the time, it pays off when there are random memory accesses on a large data structure, such as a tree or a hash map.

An additional prerequisite for the speedup with prefetching is that between the time you request prefetching, and the time you actually access your data, some time needs to pass (known as "prefetching window"). Immediately accessing data that you want to prefetch will not give the expected results.

[<img src="../../../img/SWMemPrefetch1-Summary.png">](https://www.youtube.com/watch?v=XkzTTh-CEUc&list=PLRWO2AL1QAV6bJAU2kgB4xfodGID43Y5d)

Authored-by: @ibogosavljevic



================================================
FILE: labs/memory_bound/swmem_prefetch_1/bench.cpp
================================================

#include "benchmark/benchmark.h"
#include "solution.hpp"
#include <memory>

static void bench1(benchmark::State &state) {
  // Init benchmark data
  auto hash_map = std::make_unique<hash_map_t>(HASH_MAP_SIZE);
  std::vector<int> lookups;
  lookups.reserve(NUMBER_OF_LOOKUPS);
  init(hash_map.get(), lookups);

  // Run the benchmark
  for (auto _ : state) {
    auto output = solution(hash_map.get(), lookups);
    benchmark::DoNotOptimize(output);
  }
}

// Register the function as a benchmark and measure time in microseconds
BENCHMARK(bench1)->Unit(benchmark::kMillisecond);

// Run the benchmark
BENCHMARK_MAIN();



================================================
FILE: labs/memory_bound/swmem_prefetch_1/CMakeLists.txt
================================================
cmake_minimum_required(VERSION 3.3)

project(lab)

# Optional program arguments, for example:
# set(VALIDATE_ARGS "${CMAKE_CURRENT_SOURCE_DIR}/input.file" "${CMAKE_CURRENT_SOURCE_DIR}/output.file")
# set(LAB_ARGS "${CMAKE_CURRENT_SOURCE_DIR}/input.file" "output.file")

string(REGEX MATCH "^(.*)[\\/]labs[\\/].*$" repo "${CMAKE_CURRENT_SOURCE_DIR}")
include(${CMAKE_MATCH_1}/tools/labs.cmake)



================================================
FILE: labs/memory_bound/swmem_prefetch_1/init.cpp
================================================
#include "solution.hpp"
#include <limits>
#include <random>

void init(hash_map_t *hash_map, std::vector<int> &lookups) {
  std::default_random_engine generator;
  std::uniform_int_distribution<int> distribution(
      0, std::numeric_limits<int>::max());
  for (int i = 0; i < HASH_MAP_SIZE; i++) {
    hash_map->insert(distribution(generator));
  }

  for (int i = 0; i < NUMBER_OF_LOOKUPS; i++) {
    lookups.push_back(distribution(generator));
  }
}


================================================
FILE: labs/memory_bound/swmem_prefetch_1/solution.cpp
================================================
#include "solution.hpp"

static int getSumOfDigits(int n) {
  int sum = 0;
  while (n != 0) {
    sum = sum + n % 10;
    n = n / 10;
  }
  return sum;
}

int solution(const hash_map_t *hash_map, const std::vector<int> &lookups) {
  int result = 0;

  for (int val : lookups) {
    if (hash_map->find(val))
      result += getSumOfDigits(val);
  }

  return result;
}



================================================
FILE: labs/memory_bound/swmem_prefetch_1/solution.hpp
================================================
#include <vector>
#include <limits>

static constexpr std::size_t HASH_MAP_SIZE = 32 * 1024 * 1024 - 5;
static constexpr std::size_t NUMBER_OF_LOOKUPS = 1024 * 1024;

class hash_map_t {
    static constexpr int UNUSED = std::numeric_limits<int>::max();
    std::vector<int> m_vector;
    std::size_t N_Buckets;
public:
    hash_map_t(std::size_t size) : m_vector(size, UNUSED), N_Buckets(size) {}

    bool insert(int val) {
        int bucket = val % N_Buckets;
        if (m_vector[bucket] == UNUSED) {
            m_vector[bucket] = val;
            return true;
        }
        return false;
    }

    bool find(int val) const {
        int bucket = val % N_Buckets;
        return m_vector[bucket] != UNUSED;
    }
};

void init(hash_map_t* hash_map, std::vector<int>& lookups);
int solution(const hash_map_t* hash_map, const std::vector<int>& lookups);


================================================
FILE: labs/memory_bound/swmem_prefetch_1/validate.cpp
================================================

#include "solution.hpp"
#include <iostream>
#include <memory>

static int getSumOfDigits(int n) {
  int sum = 0;
  while (n != 0) {
    sum = sum + n % 10;
    n = n / 10;
  }
  return sum;
}

static int original_solution(const hash_map_t *hash_map,
                             const std::vector<int> &lookups) {
  int result = 0;

  for (int val : lookups) {
    if (hash_map->find(val))
      result += getSumOfDigits(val);
  }

  return result;
}

int main() {
  // Init benchmark data
  auto hash_map = std::make_unique<hash_map_t>(HASH_MAP_SIZE);
  std::vector<int> lookups;
  lookups.reserve(NUMBER_OF_LOOKUPS);
  init(hash_map.get(), lookups);

  auto original_result = original_solution(hash_map.get(), lookups);
  auto result = solution(hash_map.get(), lookups);

  if (original_result != result) {
    std::cerr << "Validation Failed. Original result = " << original_result
              << "; Modified version returned = " << result << "\n";
    return 1;
  }

  std::cout << "Validation Successful" << std::endl;
  return 0;
}



================================================
FILE: labs/misc/README.md
================================================
# Misc

This is a collection of lab assignments that don't fall into any other category. Also, here we could have generic excercises, i.e. benchmarks and workloads which suffer from multiple performance bottlenecks, for example binary search. Here are some ideas what could be covered here:

* Various data-driven transformations, e.g. [this](https://easyperf.