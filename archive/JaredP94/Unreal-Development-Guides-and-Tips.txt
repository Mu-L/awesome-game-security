Project Path: arc_JaredP94_Unreal-Development-Guides-and-Tips_fokadur2

Source Tree:

```txt
arc_JaredP94_Unreal-Development-Guides-and-Tips_fokadur2
├── CODE_OF_CONDUCT.md
├── Content
│   ├── Basics
│   │   ├── ActorLightSources.md
│   │   ├── AddingContentToAProject.md
│   │   ├── ImprovedSceneLighting.md
│   │   └── LevelCreation.md
│   ├── Chaos
│   │   └── PluginConfig.md
│   ├── DevPipelines
│   │   ├── ImportingAndExporting.md
│   │   ├── LODsAndMeshMerge.md
│   │   ├── LightShadowPostProcess.md
│   │   ├── MaterialsI.md
│   │   ├── MaterialsII.md
│   │   ├── MaterialsIII.md
│   │   ├── MaterialsIV.md
│   │   ├── Reflections.md
│   │   ├── StaticMeshes.md
│   │   ├── TextureStreaming.md
│   │   ├── Textures.md
│   │   └── Volumes.md
│   └── RTRT
│       ├── AmbientOcclusion.md
│       ├── GlobalIllumination.md
│       ├── PathTracer.md
│       ├── PerformanceDebug.md
│       ├── Reflections.md
│       ├── RequirementsConfig.md
│       ├── ShadowsPostProcess.md
│       └── Translucency.md
├── LICENSE
├── README.md
├── _config.yml
├── _layouts
│   └── default.html
├── assets
│   ├── css
│   │   └── style.scss
│   └── images
│       └── background.jpg
└── static
    └── images
        ├── LOD.gif
        ├── basics.gif
        ├── chaos_destruction.gif
        ├── coding_fire.gif
        ├── star_wars.gif
        └── ue4_logo.png

```

`CODE_OF_CONDUCT.md`:

```md
# Contributor Covenant Code of Conduct

## Our Pledge

In the interest of fostering an open and welcoming environment, we as
contributors and maintainers pledge to making participation in our project and
our community a harassment-free experience for everyone, regardless of age, body
size, disability, ethnicity, sex characteristics, gender identity and expression,
level of experience, education, socio-economic status, nationality, personal
appearance, race, religion, or sexual identity and orientation.

## Our Standards

Examples of behavior that contributes to creating a positive environment
include:

* Using welcoming and inclusive language
* Being respectful of differing viewpoints and experiences
* Gracefully accepting constructive criticism
* Focusing on what is best for the community
* Showing empathy towards other community members

Examples of unacceptable behavior by participants include:

* The use of sexualized language or imagery and unwelcome sexual attention or
 advances
* Trolling, insulting/derogatory comments, and personal or political attacks
* Public or private harassment
* Publishing others' private information, such as a physical or electronic
 address, without explicit permission
* Other conduct which could reasonably be considered inappropriate in a
 professional setting

## Our Responsibilities

Project maintainers are responsible for clarifying the standards of acceptable
behavior and are expected to take appropriate and fair corrective action in
response to any instances of unacceptable behavior.

Project maintainers have the right and responsibility to remove, edit, or
reject comments, commits, code, wiki edits, issues, and other contributions
that are not aligned to this Code of Conduct, or to ban temporarily or
permanently any contributor for other behaviors that they deem inappropriate,
threatening, offensive, or harmful.

## Scope

This Code of Conduct applies both within project spaces and in public spaces
when an individual is representing the project or its community. Examples of
representing a project or community include using an official project e-mail
address, posting via an official social media account, or acting as an appointed
representative at an online or offline event. Representation of a project may be
further defined and clarified by project maintainers.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported by contacting the project team at jaredping@yahoo.com. All
complaints will be reviewed and investigated and will result in a response that
is deemed necessary and appropriate to the circumstances. The project team is
obligated to maintain confidentiality with regard to the reporter of an incident.
Further details of specific enforcement policies may be posted separately.

Project maintainers who do not follow or enforce the Code of Conduct in good
faith may face temporary or permanent repercussions as determined by other
members of the project's leadership.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage], version 1.4,
available at https://www.contributor-covenant.org/version/1/4/code-of-conduct.html

[homepage]: https://www.contributor-covenant.org

For answers to common questions about this code of conduct, see
https://www.contributor-covenant.org/faq

```

`Content/Basics/ActorLightSources.md`:

```md
# Actor Light Sources

Actors can be used to create dynamic lighting within a scene. This is generally seen with ceiling lights, fires, torches, etc.

## Fire Torch Example
* Within the *Content Browser*, select the **Add New** button and then the **Blueprint Class**. In the next screen, select the parent class to be an **Actor** class.

* Open the blueprint (ensure the full editor view is open).

* Within the *Viewport* pane, drag in the static mesh to be used (in this case, a fire torch). Ensure that the static mesh is a child of the **DefaultSceneRoot** component.

* Add the particle component which is to be the aesthetic light source of the Actor (in this case, a fire particle component). Ensure the particle component is a child of the **DefaultSceneRoot** component.

* Adjust the particle component to be positioned at the correct location within the static mesh (in this case, the holder area of the fire torch).

* In order to physically emit light into the level, the particle component requires a light source. Within the *Components* pane, select the **Add Component** button and then the **Point Light**. Ensure the point light component is a child of the **DefaultSceneRoot** component.

* Adjust the point light component to be positioned within the particle component. Sometimes placing the light component in an offset position to the particle component will yield a more rewarding lighting effect so be sure to test what works best for your actor and scene.

* In the *Details* pane of the **Point Light** component, adjust the **Light Attention** setting in the **Light** section to a realistic value (in this case, **500.0**).

* In the same section, adjust the **Light Color** setting to an appropriate color (in this case, an orange-based colour).

* Once the actor has been created in the blueprint editor, **Compile** and **Save** the blueprint.

## Light Flicker Effects
* Within the *Event Graph* pane, add a **Delay** block to the **Event BeginPlay** block. Source a **Random Float in Range** block into the **Delay** parameter using **Min** and **Max** values of **0.0** and **0.2** respectively. This now adds a random delay in the fire ignition of the torch.

* Add a **Set Intensity** block to the *Event Graph*. Source a *reference* to the **Point Light** component into the **Target** parameter. Source a **Random Float in Range** block into the **New Intensity** parameter using **Min** and **Max** values of **900.0** and **3000.0** respectively. This now adds a variable intensity for each torch instance.

* Connect the **Delay** block success pin to the trigger input of the **Set Intensity** block. This creates the sequence required for a light flicker.

* Connect the **Set Intensity** success pin to the trigger input of the **Delay** block. This creates the loop for infinite light flickering.

* Once the actor has been created in the blueprint editor, **Compile** and **Save** the blueprint.

## Using Actor Light Sources in a Level
* In the main editor window, drag the blueprint instances into the scene and position as necessary.

* Build all lighting for the level.
```

`Content/Basics/AddingContentToAProject.md`:

```md
# Adding Content To A Project

There are many ways for adding existing content to a new project. Any content you import can be found under the *Content* directory. The common methods include:

## Content Packs
* Within the editor, select the **Add New** button from the *content browser*, followed by **Add Feature or Content Pack**.

* Select the pack you would like to include (i.e. Starter Content).

## Marketplace Content
* Marketplace content packs are stored with the *vault* of your epic games launcher *library*.

* Locate the target pack and select the **Add To Project** button, followed by selecting the destination project.
   
## Migrating Content from Existing Projects
* Open the project which contains the content you wish to migrate.

* Select the asset(s) you wish to migrate.

* **Right Click** then hover over **Asset Actions** and select **Migrate**.

* All content relating to the asset(s) will be migrated.

* Within the file browser pop-up, navigate to the destination project and place the migrated files in the *Content* directory.
   
## Importing Content from Applications
* Importable content includes:
  
  * Static meshes
  
  * Sound files
  
  * Images
  
  * Skeletal meshes
  
  * Alembic Animations
  
  * CAD projects

* This process will be discussed in further detail soon.
```

`Content/Basics/ImprovedSceneLighting.md`:

```md
# Improved Scene Lighting

Currently, your scene lighting may be quite harsh with overexposure and lack of light in shadow cast areas. These factors can be mitigated as follows:

## Cast Shadows
* Since the directional light in the scene does not make use of bounced light (Ray Tracing will not be used in this instance), an artificial bounced light is required by using the *Sky Light*.

* Add a **Sky Light** from the *Modes* panel.

* Set the **Location** to **[0, 0, 400]** to hover the sky light above the level origin.

* This will result in artificial bounced light in cast shadow areas.

* Note that the default parameters are recommended and any adjustment should occur within the scene light sources rather than the sky light itself.

## Automatic Light Exposure
* Moving the camera around the scene will result in automatic light exposure which may increase the difficulty of correctly balancing the scene lighting. A *Post Process Volume* allows for control of all light in the scene through a single controller.

* Add a **Post Process Volume** from the *Modes* panel.

* Set the **Location** to **[0, 0, 0]** to place the post process volume at the level origin.

* Under the **Lens** section of the *Details* pane for the post process volume, enable the **Min Brightness** and **Max Brightness** options with respective values of **1.0** each. This enforces the standard light exposure within the volume constraints.

* Under the **Post Process Volume Settings** section, enable the **Infinite Extent (Unbound)** option. This enforces the standard light exposure across the entire level bounds.

## Realistic Sky Effects
* The scene is lacking a realistic looking sky.

* Add a **BP_Sky_Sphere** from the *Modes* panel.

* Set the **Location** to **[0, 0, 0]** to place the post process volume at the level origin.

* The sky sphere offers optimal effects when linked to a directional light, as with atmospheric fog.

* Under the **Default** section of the *Details* pane for the sky sphere, select the dropdown for the **Directional Light Actor** setting and select the directional light in the level.

## Environmental Light Tweaking
* Environmental lighting can be customised to a range of settings to meet the requirements of the level design. This is such an example:

* Under the **Light** section of the *Details* pane for the directional light, set the **Intensity** setting to a value of **1.0 lux** for a dusk-like effect.

* Rotate the directional light to be at an appropriate angle for a dusk-like setting. Note that the sun spot does not update, and the sky sphere needs to be disabled temporarily to see the expected changes. Thereafter, re-enable the sky sphere and select the **Refresh Material** setting under the *Details* pane.

* To enable sun rays from the sun spot, enable the **Light Shaft Occlusion** and **Light Shaft Bloom** settings under the **Light Shafts** section of the *Details* pane. To reduce the glaring effect, set the **Sun Brightness** setting to a value of **1.0** under the **Default** section in the *Details* pane of the sky sphere.

* To add some lighting dynamism to scene, set the values of the **Bloom Scale** and **Bloom Threshold** settings to **0.55** and **0.15** respectively under the **Light Shafts** section in the *Details* pane of the directional light.
```

`Content/Basics/LevelCreation.md`:

```md
# Level Creation

Some core elements are generally required when creating a new level. These include:

## Level Population
* A new level is created without any assets.

* Be sure to add some meshes so that something is rendered in the level.

## Level Lighting
* Levels are physics based, thus a light source is required to view anything in the level.

* Adding a **Directional Light** from the *Lights* section of the *Modes* panel will render your level.

* Set the **Location** of the directional light to **0, 0, 100** to have the light hover above the level origin.

## Quick Tiling
* When tiling your level with meshes, the process can be sped up for drafting sake.

* Increase the snap size to something relative to the ground tile.

* Duplicate and place new tiles using **Alt + Left Click** and drag to the required location.

* Select a number of tiles to duplicate multiple tiles at a time.

## Player Start Location
* Starting the game will result in the character spawning in the corner of the map and possibly infinitely falling if no tiles are present at that location.

* Add a **Player Start** from the *Modes* panel.

* Change the **Location** of the player start to **[0, 0, 100]** to have the spawn point at the level origin.

## Sky Lighting
* Meshes are currently being rendered, but the sky is still filled with darkness.

* Add an **Atmospheric Fog** from the *Modes* panel to illuminate the sky.

* Set the **Location** of the atmospheric fog to **[0, 0, 300]** to have the fog source hover above the level origin.

## Sun Lighting
* Currently, the sun is seen to be lying on the horizon in the distance.

* The sun can be controlled by attached it to the directional light in the level.

* Select the **Directional Light** from the *World Outliner*.

* Search for **Fog** in the *Details Panel Search* bar.

* Check the box for **Atmosphere / Fog Sun Light**.

* The fog colour show now change to the sky light colour.

* The sun spot can now be rotated to cast shadows in the level.

## Reflection Capture
* A realistic reflection profile needs to be present within the level.

* Add a **Sphere Reflection Capture** from the *Modes* panel.

* Set the **Location** to **[0, 0, 500]** to hover the reflection capture above the level origin.

* Select the **Build** dropdown then select **Build Reflection Captures**.

## Mesh Addition
* The level is now ready for meshes to be added and the level design to be realised.

* Be sure to make use of *Filters* in the content browser to easily identify all available meshes within the project.
```

`Content/Chaos/PluginConfig.md`:

```md
# Requirements and Configuration

A summarised guide on the engine requirements for using Chaos physics within your projects. As well as project configuration to enable the required subset of Chaos features.

## Software Requirements
* Unreal Engine version 4.23 or later is required to access the Chaos Physics features.

* Engine versions 4.23 through 4.25 require source builds, and have produced varied results when trying to use Chaos since it has been in beta. For the sake of feature completeness and reliability of feature access, I will not delve into those versions (if you need to use one of these versions, see the *Setting up Chaos Destruction* section of the [documentation](https://docs.unrealengine.com/en-US/Engine/Chaos/ChaosDestruction/ChaosDestructionOverview/index.html))

* Engine version 4.26 is the first to offer Chaos in a production-ready state and is included in the launcher version. At the time of writing, 4.26p1 is available for download through the Epic Games Launcher. **NOTE: This has been reverted in the main binary version of 4.26, however, a separate _4.26-Chaos_ binary has been made available via the launcher**

* If porting an existing project, note that NVIDIA PhysX has been deprecated in 4.26 and Chaos is now the default physics engine.

## Project Configuration

* A collection of different plugins are required based on the physics feature required within a project. These are detailed below and will be updated as more use-cases are added:
  
  * **Physics Destruction:**

    * Chaos Editor

    * Chaos Solver

    * Chaos Niagara

    * Planar Cut

    * Editable Mesh

    * Geometry

    * Geometry Cache

    * Field System

* Restart the editor once the plugin configuration is complete.
  

## Engine Changelog
* This section summarises any general Chaos Physics improvements/modifications as new engine versions are made available.
  
* **UE 4.26-Chaos (currently preview 2)**: 
  
  * First binary release candidate

```

`Content/DevPipelines/ImportingAndExporting.md`:

```md
# Importing and Exporting

A summarised guide on the processes related to importing and exporting static, skeletal and 3D meshes, re-importing assets, auto re-import and full scene import from DCC applications as well as exporting assets from Unreal.

## Exporting Static Meshes
* These should be exported using the **FBX** format.

* Within the export configuration window, tick the **Smoothing Groups**, **Triangulate** and **Preserve Edge Orientation** options under the **Geometry** section. 

* It is generally recommended to disable all other configuration properties so it is clear which properties of the mesh will be imported.

## Exporting Skeletal Meshes
* These should be exported using the **FBX** format.

* Within the export configuration window, tick the **Smoothing Groups**, **Triangulate** and **Preserve Edge Orientation** options under the **Geometry** section. This prepares the static mesh component of the skeletal mesh.

* Proceed to tick the **Animation** option under the **Animation** section and **Deformations** and **Skins** options under the **Deformations** section.

* It is generally recommended to disable all other configuration properties so it is clear which properties of the mesh will be imported.

## 3D Mesh Import
* These can be imported in the same way as [Texture Imports](/Content/DevPipelines/Textures.md#importing-textures). Unreal attempts to automatically configure the import settings but some generally require some tweaking depending on the asset type.

* When importing **Static Meshes**, the following import parameters require attention:
   
   * Auto Generate Collision (**Enable**)
   
   * Generate Light Map UVs (**Enable** but **may want to disable** depending on the UVs that have been added from the DCC application)
   
   * Transform Vertex to Absolute (**Enable**)
   
   * Import Materials (**Disable** unless materials are exported within the mesh)
   
   * Import Textures (**Disable** unless textures are exported within the mesh)

* When importing **Skeletal Meshes**, the following import parameters require attention:
   
   * Skeletal Mesh (**Enable**)
   
   * Import Animations (**Enable**)
   
   * Import Materials (**Disable** unless materials are exported within the mesh)
   
   * Import Textures (**Disable** unless textures are exported within the mesh)

## Re-Importing Assets
* This is useful for ensuring Unreal is using the latest version of a modified asset.

* This can be achieved in a variety of methods:
   
   * **Right click** within the *Content browser* the asset and select **Reimport**
   
   * Within the *asset viewer* window select the **Reimport** button from the *toolbar*
   
   * **Drag & Drop** the asset from a *file browser* window into the *Content browser*

## Auto Re-Importing
* This feature works by constantly monitoring defined directories for any changes. When a change occurs, the modified asset is automatically re-imported into Unreal.

* To configure this functionality, define **Directories to Monitor** under the **Auto Reimport** section of **Loading & Saving** tab within the **Editor Preferences**.

* It may prove beneficial to enable the **Monitor Content Directories** parameter within the same section.

## Full Scene Import
* Entire levels can be imported from DCC applications into Unreal.

* This supports a single import which can include all of the following:
   
   * Static meshes
   
   * Skeletal meshes
   
   * Animations
   
   * Materials (limited import support)
   
   * Textures
   
   * Rigid mesh
   
   * Morph targets
   
   * Cameras (without any animation)
   
   * Lights

* This can be done by selecting the **Import Into Level...** option under the **Actors** section within the **File** menu.

## Exporting Assets from Unreal
* Any importable assets can also be exported from Unreal.

* When exporting **Textures**, **Static Meshes** and **Skeletal Meshes** out of a project for use in other applications, simply **Right Click** on the asset and select **Export...** from the **Asset Actions** options.

* When exporting **any kind of asset** out of a project and into another, simply **Right Click** out of a project and into another, on the asset and select **Migrate...** from the **Asset Actions** options.
```

`Content/DevPipelines/LODsAndMeshMerge.md`:

```md
# Levels of Detail (LODs) and Static Mesh Merging

A summarised guide on more advanced LOD concepts and practices, benefits and use of the merge actor tool as well as the benefits of using Hierarchical Level of Detail (HLOD) for distance scaling.

## UE4 Automatic LOD Creation Tools
* As mentioned in the [Static meshes](StaticMeshes.md) section, LODs can be created for meshes before they are imported into UE4. However, should you opt not to create the LODs or the application not support LODs, UE4 offers a range of tools to facilitate automatic LOD creation.

* Within the static mesh viewer, when selecting an **LOD Group** under the **LOD Settings** section of the *Details pane*, the **BaseEngine.ini** file is parsed to determine the number of LODs required along with other LOD settings which can be configured in the *Details pane*.

* Configuring the **Reduction Settings** within the **LOD[number] (i.e LOD1)** section of the *Details pane* determines what graphical fidelity is prioritised as each LOD is generated (i.e Preserve silhouettes, triangles, textures, etc.).

* Selecting an option from the **LOD Group** will automatically load predefined **reduction settings**, which provide an ideal LOD reduction for the type of static mesh, and generate the ideal number of LODs for that type.

* To manually customise the generated LODs, simply reduce the **Number of LODs** setting to **1** and select **Apply Changes**. Thereafter, increase the **Number of LODs** to the desired amount and select **Apply changes**. This generates LODs without any reduction and only differ based on the screen size of the mesh.

* To manually adjust the screen size at which each LOD is used, **Un-tick** the **Auto Compute LOD Distances** box under the **LOD Settings** section. The target screen sizes can then be manually entered.

* To force a specific LOD to always be rendered on a mesh, simply enter the **LOD number** in the **Forced LOD Mode** field under the **Rendering** section of the *Details pane* after the target mesh has been selected.

* Maintaining a minimum level of detail is achievable through enabling the **Override Min LOD** option and entering a **Min LOD** value under the **Rendering** section of the *Details pane* after the target mesh has been selected. This ensures that no further reduction occurs once the minimum specified LOD is loaded.

## Merge Actor Tool
* This tool facilitates the ability to merge background objects together in order to reduce their **draw call** and **material count**. This is done by merging the static meshes and materials into a singular mesh and material respectively, thus reducing the memory consumption and rendering cost. The result is almost indistinguishable as the triangle count remains unchanged (in most cases), preserving the visual fidelity.

* Within the UE4 editor, select all the static meshes from the **World Outliner** pane which are to be merged. Then access the merge tool by navigating to **Window -> Developer Tools -> Merge Actors**.

* A window will then appear which allows for the selected meshes to be confirmed along with a range of settings for the resultant merged mesh.

* Noteworthy **Mesh Settings**:
  
  * Enabling the **Pivot Point at Zero** setting sets the pivot point of the merged mesh to **[0, 0, 0]**. Hence when dragging the merged mesh into the world and setting its **transform** to **[0, 0, 0]**, it will be placed in the exact location of the meshes before they were merged.
  
  * Setting the **LODSelection Type** option to **Use specific LOD level** allows for a specific LOD level to be used. It is advisable to select the **base LOD level (0)** which preserves the highest quality of the merged mesh. Further LODs can then be generated on the merged mesh thereafter if required.

* Noteworthy **Material Settings**:
  
  * Enabling the **Merge Materials** setting allows for all mesh materials to be combined into a singular material. This option is enabled by default when setting the **LODSelection Type** option to **Use all LOD levels**.
  
  * Adjusting the **Texture Size** setting determines the resulting texture size of the merged materials, which yields a performance gain. It is advisable to not reduce the size to below **1024 x 1024** unless the result is a very small mesh or very far away.
  
  * Ensure the **Blend Mode** option is configured to the type of materials which are being used in the meshes (i.e masked material).

* Noteworthy **Landscape Culling** settings:
  
  * Enabling the **Use Landscape Culling** setting allows for any triangles which intersect with the landscape to be culled, which yields a performance gain.
  
  * Enabling the **Replace Source Actors** setting will result in any selected actors being replaced by the mesh that results from the merge.

* Once the merge has completed, the selected meshes can be deleted and the merged mesh can be dragged into the scene. It should position itself in the same position after the mesh **transform** has been reset.

## Hierarchical Level of Detail Tool
* This tool blends the idea of LODs and the mesh merge tool. When an HLOD is applied, at a certain viewing distance, groups of meshes will be merged with  results containing a few materials rather than all the original materials. Furthermore, an automatic LOD will be applied based on the distance of the mesh.

* To enable the HLOD tool, enable the **Enable Hierarchical LOD** option under the **LODSystem** section of the *World Settings* pane. Properties under the **Hierarchical LODSetup** setting should automatically be generated.

* Open the HLOD tool by navigating to **Window -> Hierarchical LOD Outliner**.

* Select the **Generate Clusters** button to create clusters to encapsulate groups of meshes within the scene. These will be generated with a default **Desired Bound Radius** which can be modified under the **Cluster Generation settings** section of the **HLOD Level**. Alter the value to encapsulate more/fewer meshes within a single mesh.

* Another way in which the volume radius can be adjusted is to select a mesh which should be included and drag it into the target grouping volume. This will result in the target volume automatically resizing itself to contain the selected mesh. This is useful when dealing with sizeable meshes which are not contained within any generated grouping volumes.

* These groups meshes will not be rendered until a certain LOD distance is reached, thus leaving the original meshes unchanged until that distance is reached.

* Once the groupings are finalised, select the **Generate Proxy Meshes** button to begin the merge operation. This essentially runs a similar process to the **Merge Actor Tool** but with most of it automatically handled. Note that this can be quite a time consuming process depending on the meshes and materials involved.

* Once complete, the outcome can be easily verified by selecting individual meshes at close range (as before) and then moving the camera significantly further away from the meshes and attempting to select the same mesh. At a distance, the merged group of meshes becomes selected as the group of meshes has been replaced by the cluster mesh.
```

`Content/DevPipelines/LightShadowPostProcess.md`:

```md
# Lighting, Shadowing, and Post Processing

A summarised guide on how these components can dramatically affect performance, along with where to look to control their impact on your scene. These components generally overlap with each other and more often than not are responsible for the most performance degradation as their over-use is very appealing.

## Lighting
* It is important to be knowledgeable about the different light types in ue4 and what each type does. Furthermore, it is useful to understand the process of building lighting.

* There are three lighting mobility types within ue4:
    
    * **Static** - no properties can be changed at runtime **[cheap]**.
    
    * **Stationary** - can change its colour and brightness at runtime but cannot move, rotate or change influence size **[moderate]**.
    
    * **Movable** - capable of changing all properties at runtime **[expensive]**.
  
  * The mobility type of a light can be set within the **Mobility** setting under the **Transform** section of the light in the *Details pane*.
  
  * When building scene lighting, ue4 offers four quality presets:
    
    * **Preview** - gets the point across, but is at least fast **[preview]**.
    
    * **Medium** - looks better, takes a bit longer to calculate **[better preview]**.
    
    * **High** -  looks good, takes some time **[pre-shipping]**.
    
    * **Production** - looks great, takes a long time **[shipping]**.

## Shadowing [WIP]
* Since there is no perfect method for shadowing, ue4 offers a variety of shadowing methods to cater for various cases such as large objects in the scene versus small surface detail.

* Ue4 offers two main shadow types:
    
	* **Static**:
    
       * Static light type
       
	   * Inexpensive
       
	   * No scene interaction
    
	* **Dynamic**:
       
	   * Stationary and Movable
       
	   * Expensive
       
	   * Full scene interaction
    
	* Ue4 also offers some exotic shadow types:
        
		* **Cascaded** - divides the view frustum into a series of distance-based shadow cascades, each of which with steadily lower resolution as you move farther from the camera. Beyond the range of the **Dynamic Shadow Distance** property, the system blends back into static baked shadows.
        
		* **Distance Field** - enables you to shadow at farther distances than traditional Cascaded Shadow Maps (CSM) with a directional light.
        
		* **Contact** - a great way to improve the visual depth and fidelity of your scene because they provide a more accurate approximation of shadowing, allowing you to add a contoured shadow that might not be achieved with other shadowing algorithms.

## Post Process
* This is an area which eats up a large amount of performance. Post process effects are created by placing a **post process volume** in the scene (locatable within the *Modes pane*).

* Enabling the **Unbound** setting under the **Post Process Volume Settings** section within the *Details pane* of the volume allows for this volume to manage all post process effects within the scene and ensures they are visible throughout the world.

* Since the post process volume offers such a vast range of effects, the best approach is to pay close attention to the scene **frames per second (fps)** as each setting is enabled. Attempt to achieve the ideal aesthetic with a minimal number of post process effects to maximise the scene performance.
```

`Content/DevPipelines/MaterialsI.md`:

```md
# Materials I: Basics

A summarised guide on the concepts and uses of physical based rendering, material domains, material instances and master materials along with best practices for materials.

## Physical Based Rendering (PBR)
* PBR utilises simplified calculations which aim to describe light interaction with different physical surfaces.

* PBR is  helpful in unifying the art production pipeline as there is no longer a requirement for unique materials which are dependent on the type of light the surface is exposed to.

## Material Domain
* This determines how the material attributes will be evaluated.

* **Material Domain** ([additional details](https://docs.unrealengine.com/en-us/Resources/ContentExamples/MaterialProperties/1_5)) attribute defines the usage of a material and is is configurable as:
  
   * Surface (default - used for any kind of geometry)

   * Deferred Decals (used by Decal Actor)

   * Light Function (applied to lights at LightFunctions)

   * PostProcess (used as Blendable Material in PostProcessing chain)

   * User Interface (used for UMG or Slate UI)

* **Blend Mode** ([additional details](https://docs.unrealengine.com/en-us/Resources/ContentExamples/MaterialProperties/1_1)) attribute defines the foundation of a material and is configurable as:

   * Masked (surface which requires selective visibility)

   * Opaque (surface through which light neither passes nor penetrates)

   * Translucent (surface which requires some form of transparency)

   * Additive (add material pixels to background pixels)

   * Modulate (multiplies value of material against background pixels)

* **Shading Model** ([additional details](https://docs.unrealengine.com/en-US/Engine/Rendering/Materials/MaterialProperties/LightingModels)) attribute controls light reflection of a material and is configurable as:

   * Unlit (only outputs Emmissive for colour)

   * Default Lit (uses direct and indirect lighting as well as specularity for reflections)

   * Subsurface (light penetrates surface and then diffuses throughout it)

   * Preintegrated Skin (similar to Subsurface but with low performance cost skin rendering on human characters)

   * Clear Coat (simulate multilayer materials that have a thing translucent layer of the surface)

   * Subsurface Profile (similar to Subsurface and Preintegrated Skin but with higher performance cost skin rendering)

   * Two Sided Foliage (gives foliage more natural and uniform look when being lit)

## Materials
* These provide a way for Unreal to manipulate and display textures on an object.

* Materials are built using the **Material Editor** and consist of HLSL (High Language Shader Language) code blocks to manage tinting, blending, etc.

* Materials have to be compiled before they can be displayed or used in-game. Saving the material will automatically compile it.

* Once compiled, the material is considered to be static and cannot change during runtime.

## Material Instances
* These are special materials which allow for value and texture changes at runtime. A recompilation is not required when changing the instance attributes.

* Material instances can be accessed and modified within timelines and blueprints to generate impressive visual effects.

* There is a discrete performance improvement in using material instances over materials but this is only really noticed at scale.

## Master Materials
* These provide the base functionality which a material instance is able to use and modify at runtime such as base colour, roughness, textures, etc.

* Instance editable attributes can be identified through the **Param** keyword on the master material attributes.

## Master Materials Best Practices
* Use multiple master materials so that each target component has its own master material (i.e unique master materials for environmental objects, characters, weapons, etc).

* Do not attempt to use a single master material for all objects. It will likely be unable to offer the broad customisation required, possibly incur performance costs and limits the options available to the artist.

## Master Materials Concepts
* There are a number of steps involved in the creation of a master material that will ensure it is performant and compatible on any target platform.

* **Material Functions** facilitate the sharing and reuse of parts of the **Material Graph**.

* **RGB Mask Packing** stores various **Textures** in the **R**, **G** and **B** channels of a **Texture**. Pay careful attention to which textures are assigned to each channel for future use.

* **Static Switches** allows for binary control of entire code paths in a material. This can be used for selectively applying high resolution textures to certain objects but not others.

* **Feature Level Switches** facilitates the creation of a single material which is cross-platform. This takes in multiple versions of the same material to build a cross-platform material.
```

`Content/DevPipelines/MaterialsII.md`:

```md
# Materials II: Master Materials and Material Functions

A summarised guide on configuring a master material as well as creating and making use of material functions.

## Creating Master Materials
* Within the *Content browser* create a new material and open it in the *Material viewer* window.

* **Parameterise** the options which are intended to be used by instances. This is done by adding a **VectorParameter**, assigning it a **Parameter Name**, and assigning a **Group** under the **General** section of the *Details* pane.

* Thereafter, connect the **VectorParameter** node to the material parameter which is expected to change with instances (i.e base colour).

## Adding Textures to Master Materials
* As previously mentioned, asset textures can be changed by material instances at run time.

* Select the desired texture within the *Content browser*.

* Within the *Material viewer* window of the master material, hold the **T key** and click on an empty space to create a **Texture Sample** node. 

* **Right click** the texture sample and select **Convert to Parameter** to have the texture converted to a **texture object**. This now allows the texture to be modified in instances.

* Assign the texture object a **Parameter Name** and **Group**.

## Creating Material Functions
* Material functions are a way of sharing shader code between multiple materials.

* Within the *Content browser*, **right click** and select **Material Function** from the **Materials & Textures** option.

## Basic Material Function Example
* In this example, the goal is to configure the material function to implement basic texture tiling which can be shared between materials.

* Open the material function within its viewer to edit the function.

* Within the **Material Expression Function Output** section of the *Details* pane, enter an **Output Name** and **Description**. This defines the function name and a brief description of what it does.

* Add a **TextureCoordinate** node as well as a **Function Input** node. Within the function input, define an **Input Name**, **Description** and **Input Type**. The objective of this is to multiply the number of tiles.

* Add a **Multiply** node and connect the inputs to the **TextureCoordinate** and **Function Input** nodes.

* Connect the result of the **Multiply** node to the **Output TitleOut** node.

* Finally, select **Apply**.

* Adjusting the scalar function input will result in varying previewed output.

* This function can now be added to multiple materials and connected to the **Input UVs** of **texture parameters** to enable the tiling.
```

`Content/DevPipelines/MaterialsIII.md`:

```md
# Materials III: Material Instances

A summarised guide on parent (master) materials and their children, creating and using material instances and overriding parent material functionality.

## Parent - Child Relationship
* This relationship mimics that of a parent (master) material and a child (instance) of that material.

* The child can inherit any of the properties of the parent, but not combine them (i.e parent with red and blue produces child with red or blue).

## Creating Material Instances
* There are two methods of creating a material instance within unreal.

* The first involves **right clicking** on the target master material and select **Create Material Instance** within the *Content browser* pane.

* The second involves **right clicking** within the *Content browser* pane and selecting **Material Instance** from the **Materials & Textures** group. Thereafter, open the material instance and select the parent material from the **Parent** parameter under the **General** section of the *Details* pane.

## Using Material Instances
* The material instances do not make use of any inherited parameters by default.

* These can be enabled and configured within the **Parameter Groups** section of the *Details* pane within the material viewer.

## Overriding Parent Material Functionality
* Certain functionalities of the parent material can be overridden by the material instance.

* The overridable parameters can be found in the **Material Property Overrides** group under the **General** section of the *Details* pane.

* These are use-case specific, where the **Two Sided** property, for example, is helpful in ensuring that the material is always rendered even when facing away.
```

`Content/DevPipelines/MaterialsIV.md`:

```md
# Materials IV: Vertex Animation Materials

A summarised guide on vertex animation concepts, performance considerations and use cases along with an example of creating a vertex animation material.

## Vertex Animations
* These are used to cheaply convey subtle movement for complex objects (i.e foliage, water, cloth, etc).

* The animations are rendered by the GPU as vertices are continuously being slightly offset within a given mesh.

* The downside to this is that physics interactions are not entirely accurate since the CPU calculates the interaction without knowledge of the offsets which are occurring.

* Thus vertex animation should be used a secondary line of animation in cases such as added perceived realism within level scenery where interactivity is not required.

## Vertex Animation Foliage Configuration
* Consider the case where a tree needs to be animated using vertex animation. Two materials are used within the tree mesh, namely a material for the trunk and a material for the foliage component. The latter will then use vertex animation whilst the former will not.

* Create a new material which will be used for the vertex animation. Ensure the material is prefixed with **M_VT** to indicate it is a vertex animation material.

* Open the material viewer for the newly created material.

* Set the **Blend Mode** parameter to **Masked** within the **Material** section under the *Details* pane. This is because a masked texture will be used to give the leaves their appearance.

* Set the **Two Sided** parameter to **Enabled** within the same section. This ensures the tree foliage appears correctly at any angle.

* Add a **Texture Sample** node with the masked foliage material and connect its output to the **Base Color** of the vertex material. Furthermore, connect the **Alpha** of the node to the **Opacity Mask** of the vertex material.

* Add a **Texture Sample** node with the normal foliage material and connect its output to the **Normal** of the vertex material.

* Add a **Decimal** node and connect its output to the **Roughness** of the vertex material. Set a value of **0.5** to get the leaves a more realistic appearance.

* Add a **Simple Grass Wind** node and connect its output to the **World Position Offset** of the vertex material.

* Add two **Decimal** nodes. Connect the output of the first to the **Wind Intensity** and **Wind Weight** inputs of the **Simple Grass Wind** and set its value to **0.5**. Connect the output of the second to the **Additional WPO** input of the **Simple Grass Wind**.

* Replace the foliage material of the tree with the created vertex animation material to yield the animated effect.
```

`Content/DevPipelines/Reflections.md`:

```md
# Reflections

A summarised guide on extracting the best performance from reflections. This includes understanding and making use of reflection actor types, screen space, sphere, box and planar reflections, and yielding higher quality reflections.

## Screen Space Reflections (SSR)
* These are much more efficient than Planar Reflections when it comes to rendering, but are also much less reliable:

    * Sphere Reflection Capture **[cheap]**

    * Box Reflection Capture **[moderate]**

* Each reflection is controlled by the particular actor which is placed into the scene.

* The intended reflection can be applied by simply dragging the type of reflection actor into the scene.

* Within the **Reflection Capture** section of the *Details pane*:

    * The **Influence Radius** setting is responsible for controlling the area of the reflection.

    * Selecting the **Update Captures** button will update the cubemap of the reflection.

    * The **Reflection Source Type** option determines whether the reflection is based on its surroundings (**Captured Scene**) or using a cubemap from a different scene (**Captured Scene**).

* Sphere reflection capture is best used with encapsulating groups whereby a single sphere will encapsulate the entire area where reflections are required and subsequent smaller spheres are placed in areas of interest. Use enough to get the desired effect, but don't overuse as this will eventually ruin the scene and become expensive. 

* Box reflection capture is best suited for areas such as corridors as they can produce artefacts.

* The **reflections view mode** is helpful in determining the correct layout of reflection capture actors.

## Planar Reflections
* These can give more accurate looking reflections than screen space reflections provide but come with a higher rendering cost. This is due to planar reflections actually rendering the level again from the direction of the reflection. The cost is thus proportional to the rendering cost of the scene which requires the reflections.

* These need to be enabled within the *Project Settings* by selecting the **Support global clip plane for Planar Reflections** setting within the **Rendering** section and restarting the editor.

* Within the **Planar Reflection** section of the *Details pane*:

    * Enabling the **Render Scene Two-Sided** setting will reduce any noted artefacts at reflection edges. Note: ensure that the water plane is added to the **Hidden Actors** as it will not block the reflection.

## Improving SSR
* Although SSRs are more efficient, they do not cater for dynamic objects within the scene. This can be catered for with SSR post process effects.

* These include three Settings:

    * Intensity - enable/fade/disable the SSR feature by percentage (avoid numbers between **0** and **1** for consistency).

    * Quality - [**0**=lowest quality] while [**100**=maximum quality] (**50** is the default to provide better performance).

    * Max Roughness - used to determine what roughness is to be used for fading the SSR (**0.8** works well, smaller can run faster).

* Ensure the dynamic object is always contained within the SSR container.

## Higher Quality Reflections
* There are a few options available to increase the quality of scene reflections.

* Due to being a real-time engine, reflection capture resolution is generally reduced. This can be increased by increasing the **Reflection Capture Resolution** setting under the **Rendering** section in *Project Settings*.

* Within the scene skylight settings, increase the **Cubemap Resolution** settings in the *Details pane*.

* Within the static mesh editor, enable the **Use High Precision Tangent Basis** under the **LOD** section in the *Details pane* for higher accuracy normals on the meshes.

* Improved mesh rendering interpolation can be obtained by setting the **GBuffer Format** setting in the **Rendering** section in *Project Settings* to **High Precision Normals**.

* Furthermore, higher mesh tessellation will translate to improved rendering interpolation of the reflected meshes.
```

`Content/DevPipelines/StaticMeshes.md`:

```md
# Static Meshes

A summarised guide on the components of static meshes and the best practices to be used when creating performance optimised static meshes.

## System Units
* Consistent use of a specific unit is required to ensure no scaling issues occur.

* Unreal utilises **centimeters** as its unit of measurement. Thus **1 Unreal unit = 1 Centimeter**.

* Ensure that the DCC (i.e 3ds Max) system / scene scale is set to centimeters.

## Triangle Counts
* The number of triangle counts in a static mesh is inversely proportional to the project performance. Thus optimising the triangle count is essential.

* Do not waste a large number of triangles in modelling small details (i.e nuts and bolts) as the user will not notice the superior level of detail for such small objects.

* Always display your triangle count as you model the mesh. This can be done in the DCC software as well as the static mesh viewer in Unreal.

## Material IDs
* These are used to identify which polygon faces get specific materials assigned to them.

* The performance drawback relates to the number of material IDs as each ID associated to a material will cause the object to be rendered again (i.e 5 material IDs prompt the object to be rendered 5 times before the complete object is ready for rendering).

* Small props should generally only have a single material ID where as a character may have 2 or 3.

## Pivot Points
* This is the point of reference for the object to be placed in the level with reference to the target location.

* Ensure that the pivot point always matches the origin of the object. This prevents awkward placement within the level as a location offset will not need to be considered.

* Furthermore, an offset pivot point will cause location offset when rotating or scaling the object in Unreal.

## Lightmaps
* These are used to store complex light and shadow information inside a texture. This is due to textures being cheap and efficient at storing this type of data. Hence the performance cost is low.

## Lightmap UVs
* These are maps which contain the lighting information for each face of the object.

* Each face must be laid out in a **0 to 1 UV Space**.

* Each face must also be unique. Thus no face is allowed to overlap on the map. Should an overlap occur, incorrect lighting will occur on certain faces.

* Lightmap UV information should be stored in the **second** map channel.

* Lightmap resolution can be adjusted, if required, by changing the **Light Map Resolution** parameter under the **Static Mesh Settings** section in the *Details* pane of the static mesh.

## Collision Meshes
* These are responsible for managing collision detection of static meshes, facilitating collision driven events (i.e car impact).

* Collision meshes should follow the naming convention **UCX_[FullNameOfMesh]_[CollisionNumber]**.

* There are two ways of using collision meshes inside Unreal. The first involves creating the collision mesh in the DCC application and importing it along with the static mesh geometry. The second involves adding a collision mesh of choice from the *Collision* option in the toolbar of static mesh viewer.

* When using the former method, ensure that **Auto Generate Collision**, **Import Materials** and **Import Textures** are unchecked when importing.

* When attempting to add a collision mesh for an organic static mesh (i.e rubble), it is difficult to generate an optimised solution. Unreal caters for this by offering **Convex Decomposition** which offers a fairly accurate optimised collision generation. This can be created by setting the desired **Accuracy** and **Max Hull Verts** parameters in the *Convex Decomposition* pane in the static mesh viewer. Thereafter select **Apply** to generate the collision mesh.

## Limiting Overdraw
* This effect is generally encountered when dealing with static meshes that include transparency or opacity (i.e foliage). This results in the GPU evaluating areas which don't contain any useful information and thus will not be drawn.

* This can be partially mitigated by adding vertices to clip some of the static mesh so that transparent areas are limited.

* Unreal offers a number of tools to identify and limit the effects of overdraw. 

* The first is **Shader Complexity Mode**. Within the editor, overdraw effects can be visualised by selecting **Lit** then selecting **Shader Complexity** from the **Optimization Viewmodes** list.

## Level of Detail (LOD)
* LODs are lower triangle versions of the same mesh.

* These are important as they help lower the rendering cost of distant objects.

* They can be created by hand or programmatically.

* Typical LOD reduction scales are **75 %**, **35 %** and finally **12 %**.

* LODs can be created within the DCC application and imported into Unreal with the rest of the static mesh geometry. When importing, ensure that the **Import Mesh LODs** parameter is checked.

* LODs can be created within Unreal by selecting an appropriate **LOD Group** under the **LOD Settings** section in the *Details* pane of the static mesh viewer. Unreal then generates a set of LODs which matches the **Number of LODs** parameter in the same section.
```

`Content/DevPipelines/TextureStreaming.md`:

```md
# Texture Streaming

A summarised guide on the concepts of texture streaming, increasing the texture streaming pool size and disabling texture streaming.

## Texture Streaming
* This denotes the detail of the textures which are to be viewed.

* Texture streaming is responsible for handling the transition between different mipmaps as the camera distance is changed.

* As the camera moves closer to the texture, the texture streaming pool will become more full due to the larger mipmaps being streamed.
   
## Increasing Texture Streaming Pool Size
* Warnings may arise when attempting to render extremely high detail textures within the scene. This is typically common in ArchViz projects.

* This can be mitigated by increasing the texture streaming pool size in two ways.

* The first method entails using the *Console*, which can be opened with the **tilde** key, with the command:
	```cpp
	r.Streaming.PoolSize = [DesiredSizeInMB]
	```
        
* The second method entails editing the **DefaultEngine.ini** file which is a more permanent solution if the issue is reoccurring. Within the file locate the **[/Script/Engine.RendererSettings]** section and add the line:
	```cpp
	r.Streaming.PoolSize = [DesiredSizeInMB]
	```

## Disabling Texture Streaming
* This is useful when the highest resolution texture is desired at any given camera distance. 

* This will severely impact performance if applied to all project textures.

* Applicable cases generally include UI elements and text containing textures which the user is required to read with clarity.

* Within the texture viewer window, **enable** the **Never Stream** parameter under the **Texture** section of the *Details* pane.

```

`Content/DevPipelines/Textures.md`:

```md
# Textures

A summarised guide on optimal settings and best practices used in the creation of textures.

## Naming Convention
* Using an appropriate naming convention is useful in grouping/parsing assets within a project.

* Prefix texture assets with a **T_** (i.e **T_Car_Texture_00**).

* Append texture assets with the suffix that corresponds to the category of the texture (i.e **T_Car_Texture_00_N** corresponds to the *Texture Normal*).

## Texture Creation
* Texture axes should always be a **power of 2** (i.e **2, 4, 8, 16, 32, 64, 128, 256, 512, 1024, 2048, 4096, 8192**). This is required due to the manner in which the textures are loaded into memory as well as to adhere to Unreal's optimisation techniques that include *mip mapping* and *texture streaming*.

* Textures are not required to be square, but rather to adhere to the power rule (i.e **512 x 64**, **8192 x 1024**, etc).

* Following this process allows for LODs to become functional on the texture as a correctly created texture will feature a number of *MIP maps* which facilitates the scaling requirement for LODs.

## Handling Alpha Information
* There are two ways of storing alpha information in a texture - **Embedded** and **Separate**.

* Making use of the **Separate** alpha is ideal as it will be compressed when imported into Unreal versus the **Embedded** alpha which will be imported in an uncompressed manner.

* Making use of the **Separate** alpha also allows for size control which is independent to the **Base** color size.

* Should you wish to retain the high resolution of the alpha information then the **Embedded** alpha is more useful. Note that this will have **double** the cost of the **Separate** alpha.

## RGB Mask Packing
* This is a method used to reduce the number of textures and amount of memory used throughout the project. It is generally used within VFX and character model applications. The method involves packing multiple masks together into the **R**, **G**, **B**, and **A** channels of a single image which is then exported.

* When using this method, only black and white information will be accessible from the texture, so some form of color parameter multiplication will be required to obtain the respective color information.

* Uncheck the **sRGB** parameter under the **Texture** section of the *Details* pane. This then supports the channel extraction.

* When using the texture on a material, set the **Sampler Type** to **Masks** under the **Material Expression Texture Base** section of the *Details* pane. This is required as disabling **sRGB** on the texture will disable **gamma correction** on the texture. Mask textures do not require gamma correction as they simply inform the renderer of whether a pixel should be visible or not.

## Texture Formats
* Unreal supports a range of Texture file formats:

  * PNG (Embedded Alpha support)

  * PSD (Embedded Alpha support)

  * TGA (Embedded Alpha support)

  * BMP

  * FLOAT

  * PCX

  * IPG

  * EXR

  * DDS (Cubemap Texture)

  * HDR (Cubemap Texture - Exception to the *Power of 2* rule)

## MIP Mapping
* This is a key feature in facilitating good performance within a project. It can be thought of as LODs for textures.

* MIP map generation occurs when a texture is imported into Unreal. In most cases, no interaction is required unless for a very specific use case. Such a case is where shimmering or aliasing is noticed on an object. This can be adjusted by selecting one of the **Sharpen** configurations from the **Mip Gen Settings** option under the **Level Of Detail** section in the *Details* pane of the texture.

* This is used to apply a resolution of the texture which is better suited to the render size of the object, rather than incurred the memory cost of rendering the full resolution texture where the full detail cannot be told apart from the scaled down variant.

<a name="importing-textures"></a>

## Importing Textures
* There are two ways of importing textures into Unreal, namely the **Drag and Drop** and **Import** methods.

* The **Drag and Drop** method simply requires a texture to be dragged into the *Content Browser* from a *Windows Explorer Window*. The import is automatically handled.

* The **Import** method requires the **Import** button in the *Content Browser* to be selected. This opens a *Windows Explorer Window* to navigate to and select the required texture.

* Unreal will assess the file name of the texture to decide the appropriate type of texture being imported (refer to this [Naming Convention Guide](https://github.com/Allar/ue4-style-guide#anc)).

## Texture Groups
* These groups serve to manage how textures are used and displayed within a project. Each group determines the size at which the texture will be drawn within the project, how the texture is minified or magnified and what type of filtering is applied to the texture.

* Thus it is imperative that correct group assignment of each texture is performed.

* Group assignment is done by changing the **Texture Group** property of the **Level Of Detail** section in the *Details* pane of the texture.

* Such an example of a defined texture group configuration:  
	```cpp
	TEXTUREGROUP_World=(MinLODSize=1,MaxLODSize=8192,LODBias=1,MinMagFilter=aniso,MipFilter=point)
	```

## Texture Compression
* Texture compression can be adjusted at any time in the editor.

* Open the target texture from the *Content Browser*.

* Select the desired **Compression Settings** type under the **Compression** section in the *Details* pane of the texture.

* Refer to this [Texture Compression Document](https://docs.unrealengine.com/en-us/Editor/Content/Types/Textures/TextureCompressionSettings) for information on each type of texture compression.

* Certain types of compression will require the **Compress Without Alpha** property to be set. Consult the above document to determine the required configuration.
```

`Content/DevPipelines/Volumes.md`:

```md
# Volumes

A summarised guide on what volumes are and how to make use of Lightmass volumes as well as Cull Distance volumes.

## Brief Intro to Volumes
* Volumes are specific actors which can be placed into a scene to determine a range of interaction factors ranging including controlling the player movement area, affecting how sound will reverberate and affecting lighting or visibility.

* Ue4 offers a wide range of volumes which can be located within the *Modes pane* (full range of volume types can be found [here](https://docs.unrealengine.com/en-US/Engine/Actors/Volumes/index.html)).

* Lightmass and Cull Distance volumes are a highly featured volume within ue4 and thus their usage should be optimal where possible.


## Using Lightmass Volumes
* These volumes have two main purposes within ue4:

    * They determine the bounds of the lightmass simulation (i.e the biggest and smallest areas to be calculated within the simulation). Without this, a large amount of calculation time could be wasted on areas which may not contain any light within the scene. The lightmass volume thus ensures only player-visible areas are added to the light calculation.

    * They provide dynamic objects (i.e. characters) with information about the static lit environment. This is done through lightmass importance to identify areas of interest to determine what lighting surrounds the dynamic objects.

    * Always ensure that the volume within the scene covers all playable areas.

    * The **Lightmass Character Indirect Detail Volume** increases the number of samples which are placed within the lightmass volumes. This is generally used in a scene such an elevator where the character is going to traverse an area with an insufficient amount of samples. The number of samples within this volume can be controlled through the **Static Lighting Level Scale** setting under the **Lightmass** section of the *Details pane*. Be wary of the memory cost induced by a larger number of samples.

## Using Cull Distance Volumes
* This is an optimisation tool which allows for objects above a specified size and distance from the camera to stop being rendered.

* Both the size and distance properties must be met for the cull to occur. These are the **Size** and **Distance** properties within a cull distance element under the **Cull Distance Volume** settings in the *Details pane*.

* A number of size and distance combinations can be created to cater for different groups of objects being rendered.

* Ensure that the **Allow Cull Distance** setting is enabled under the **LOD** section of the *Details pane* for the target objects.

* The ideal application of this volume should be that of a safety net, whereby each target object should already have its own **Desired Max Draw Distance** setting defined and the volume simply caters for objects which may not have stopped rendering as desired.
```

`Content/RTRT/AmbientOcclusion.md`:

```md
# Ray-Traced Ambient Occlusion

A summarised guide on utilising ray-traced ambient occlusion to accurately represent the physical handling of light in areas without direct exposure. As well as performance optimisations including intensity control, radius limiting and samples per pixel.

## Realistic Reflections
* Ray-traced ambient occlusion (RTAO) accurately shadows areas blocking ambient lighting better grounding objects in the environment, such as shadowing the corners and edges where walls meet or adding depth to the crevices and wrinkles in skin.

* When compared with Screen Space Ambient Occlusion (SSAO), RTAO grounds objects and adds depth to the scene to produce natural looking shadowing in indirectly lit areas. These differences are easily noted in the comparison below:
  
    ![Screen Space Ambient Occlusion](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/RT_AO_Disabled.jpg)
    *Image 1: Scene rendered with Screen Space Ambient Occlusion*

    ![Ray-Traced Ambient Occlusion](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/RT_AO_Enabled.jpg)
    *Image 2: Scene rendered with Ray-Traced Ambient Occlusion*

* RTAO can be enabled by **ticking** the **Samples Per Pixel** box and setting the value to **greater than 0** under the **Ray Tracing Ambient Occlusion** settings of the **Post Process Volume** in the *Details pane*.
  
* Key optimisations exist to find a balance between accuracy and performance.

## Optimisation
* There are a multitude of settings which help balance the quality versus performance of RTAO. The exact value of each setting will depend on the requirements and components of your scene. These settings are found under the **Ambient Occlusion** and **Ray Tracing Ambient Occlusion** sections of the **Post Process Volume** in the *Details pane*:

  * **Intensity**: Defines how much ambient occlusion affects non-direct lighting for RTAO. Lower values decrease the effect while higher values increase how strong the effect is. These differences are easily noted in the comparison below:
  
    ![Ray-Traced Ambient Occlusion Intensity 0.75](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/RTAO_75.jpg)
    *Image 3: Scene rendered with Ray-Traced Ambient Occlusion Intensity value of 0.75*

    ![Ray-Traced Ambient Occlusion Intensity 1.00](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/RTAO_100.jpg)
    *Image 4: Scene rendered with Ray-Traced Ambient Occlusion Intensity value of 1.00*

  * **Radius**: Controls the distance in Unreal Units that ambient occlusion affects.

  * **Samples Per Pixel**: Sets the number of samples to use per pixel for RTAO. Additional samples decrease performance while increasing quality and accuracy. Set to **1** sample per pixel by default.
```

`Content/RTRT/GlobalIllumination.md`:

```md
# Ray-Traced Global Illumination

A summarised guide on utilising ray-traced global illumination to add real-time light interaction within the scene. As well as performance optimisations including max bounce control and samples per pixel.

## Real-time interaction
* Ray-traced global illumination (RTGI) facilitates real-time interactive bounce lighting to areas not directly lit by a given light source. This provides real-time shadow casting and dynamic material interaction for a truly realistic scene.

* When compared with a Sky Light, RTGI prevents the harshly contrasted light within scenes and facilitates a truly dynamic lighting system. These differences are easily noted in the comparison below:
  
    ![Sky Light Only](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/RT_GI_Disabled.jpg)
    *Image 1: Scene rendered with Sky Light only*

    ![Ray-Traced Global Illumination](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/RT_GI_Enabled.jpg)
    *Image 2: Scene rendered with Ray-Traced Global Illumination*

* RTGI can be enabled by **ticking** the **Enabled** under the **Ray Tracing Global Illumination** settings of the **Post Process Volume** in the *Details pane*.
  
* Key optimisations exist to find a balance between accuracy and performance as RTGI is extremely expensive as the number of bounces increase within a scene.

## Optimisation
* There are a multitude of settings which help balance the quality versus performance of RTGI. The exact value of each setting will depend on the requirements and components of your scene. These settings are found under the **Ray Tracing Global Illumination** section of the **Post Process Volume** in the *Details pane*:

  * **Max Bounces**: Sets the maximum number of bounces of light that will be used by RTGI. Increased number of bounces translates to a more realistic scene but yield becomes exponentially more expensive. Set to **1** bounce by default.

  * **Samples Per Pixel**: Sets the number of samples to use per pixel for RTGI. Additional samples decrease performance while increasing quality and accuracy. Set to **1** sample per pixel by default.

* **UE4 4.24 (experimental)**: A more efficient method of RTGI has been introduced. This can be enabled by using the following console command:
  ```
  r.RayTracing.GlobalIllumination.EnableFinalGather 1
  ```
  Additionally, the **Samples Per Pixel** setting should be set to **8**.
```

`Content/RTRT/PathTracer.md`:

```md
# Path Tracer Benchmarking

A summarised guide on understanding and using the Path Tracer tool for creating realistic environments. This includes the intention and benefits of the tool, along with how to use it and additional configurations when using the tool.

## Purpose and Benefits
* UE4 provides a companion tool to the Ray Tracer that includes a full Path Tracer. This tool is useful to generate reference images called a **Ground Truth**. The Path Tracer is similar to other offline renderers in how it is used, like [V-Ray](https://www.chaosgroup.com/) and [Arnold](https://www.arnoldrenderer.com/). It works by casting many rays into the scene to gather information about light and color to shade a given pixel. 

* Where ray tracing is great for real-time graphics, path tracing techniques are better for generating an unbiased target result because it's not limited by the number of samples it can use, making it good for comparing against real-time ray tracing features.

* A scene comparison using the Ray-Tracer and Path Tracer is shown below (note that not all materials and lighting effects are fully supported in the comparison):

    ![Ray Traced](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/PathTracer/RayTracer.jpg)
    *Image 1: Scene rendered using Ray Tracer*

    ![Path Tracer](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/PathTracer/PathTracer.jpg)
    *Image 2: Scene rendered using Path Tracer*

* For artists and programmers, the unbiased nature of the Path Tracer’s ground truth image makes it invaluable to have built right into the engine for comparison. It also removes the need for additional third-party software or plugins to generate these comparison results. For artists, it means being able to fine-tune materials and lighting setups more quickly. For programmers, it improves workflow and iteration times when tuning and validating the look of their real-time algorithms for techniques like Denoising.

## Configuration and Usage
* To make use of the Path Tracer, ensure that ray-tracing has been enabled within the project. Thereafter, **enable** the Path Tracer by selecting the **Path Tracing** option from the **View Modes** dropdown menu as shown below:

    ![Enable Path Tracer](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/PathTracer/PathTracerViewMode.jpg)  
    *Image 3: Path Tracing option under View Modes dropdown*

* The Path Tracer uses a progressive accumulation method whereby it's continuously adding samples while the camera is not moving. It also uses adaptive sampling to trace additional rays for the pixels that produce a higher amount of noise, as shown in the image below. The pixels start to fill in with final shading color after a few moments depending on the complexity of the scene and the materials being sampled.

    ![Path Tracer Noise](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/PathTracer/PathTracerConvergence.jpg)  
    *Image 4: Visible noise due to adaptive sampling*

* The noise can be mitigated by setting the **Max Bounces**, that rays should travel, and **Samples Per Pixel**, for convergence, settings under the **PathTracing** section of the *Post Process Volume* settings.

## Notes
* Additional properties and adjustable settings can be found under the console variables related to:  
  ```
  r.PathTracing.*
  ```

* The current implementation of the Path Tracer is missing features or workflows that would make it a production-ready replacement for final pixel renders. Instead, it’s current implementation is best suited for comparison reference.

* The Path Tracer enables future research and development to be considered for content creation workflows such as progressive light builds, cinematic rendering, and even for non-rendering applications such as audio simulation in virtual reality (VR), physics collision and hit detection, and artificial intelligence (AI).
```

`Content/RTRT/PerformanceDebug.md`:

```md
# Performance Analysis and Debugging

A summarised guide on using performance analysis and debugging tools within RTRT environments. These include GPU statistics, ray-tracing resource usage, ray-tracing debug view modes, evaluating denoiser quality and on-the-go ray-tracing management.

## GPU Profiling
* The live GPU profiler provides real-time per-frame stats for the major rendering categories. To use the live GPU profiler, press the **Backtick key** to open the console and then input the following command:
  
  ```
  stat GPU
  ```

  The live GPU profiler can also be accessed from **Stat sub-menu** in the **Viewport Options** dropdown. Ray-tracing features will appear within the profiler as shown below:
  
  ![GPU Profiler](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/GPUStats1.jpg)
  *Image 1: GPU Profiler containing Ray-Tracing features*

## Ray-Tracing Resource Profiling
* The Ray-Tracing resource usage profiler shows relevant statistics. To use the Ray-Tracing resource profiler, press the **Backtick key** to open the console and then input the following command:
  
  ```
  Stat D3D12RayTracing
  ```

  Ray-Tracing resource consumption statistics will appear within the profiler as shown below:
  
  ![Ray-Tracing Profiler](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/StatD3D12RayTracing.jpg)
  *Image 2: Ray-Tracing resource profiler showing relevant statistics*

## Debug View Modes
* A number of ray-tracing debug view modes can be found in the **Ray Tracing Debug** option under the **View Mode** dropdown. This location and list of debug modes is shown below:

  ![Ray-Tracing Debug View Modes](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/RT_DebugOptions.png)
  *Image 3: Ray-Tracing Debug View Modes*

## Denoiser Quality Evaluation
* Quality evaluation of the denoiser for various ray-tracing effects can be performed in the following ways:

  * Disable **Temporal Anti-Aliasing** and **Depth of Field**: Both of these are running in linear color space in Unreal Engine's renderer. They do some HDR color weighting tricks to avoid aliasing between shadows and highlights.

  * Compare the **Denoised single sample per pixel** with an **Undenoised single sample per pixel**: The result will look incorrect due to the energy difference and that the denoiser is darkening the shadows too much. However, a single sample per pixel will look brighter due to the tonemapper's non-linear operation. For a better comparison, the **Denoised single sample per pixel** should be tested against an **Undenoised multiple samples per pixel**. An example of the comparison is shown below:

    ![Denoised Single Sample Per Pixel](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/RT_Denoiser_SingleSample.jpg)
    *Image 4: Rendered scene with Denoised Single Sample per Pixel*

    ![Undenoised Multiple Samples per Pixel](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/RT_Denoiser_MultiSamples.jpg)
    *Image 5: Rendered scene with Undenoised Multiple Samples per Pixel*

    The denoised single sample per pixel will not be perfect due to information loss. However, when compared to undenoised multiple samples per pixel, the results are consistent. Also, keep in mind that the Denoiser supports up to **four samples per pixel**, which improves the quality and more closely matches the undenoised multiple samples per pixel result.

## Ray-Tracing Management
* All ray-tracing effects can be enabled and disabled on the go through the use of console commands. Press the **Backtick key** to open the console and then input the following command:
  
    ```
    r.raytracing.ForceAllRayTracingEffects [DesiredState]
    ```

    where a **DesiredState** value of **0** and **1** will disable and enable all ray-tracing effects respectively.

## Material Management
* Complex Materials can affect performance of ray-tracing features. To test performance impact, press the **Backtick key** to open the console and then input the following command:
  
    ```
    r.RayTracing.EnableMaterials
    ```

* Use the **Cast Ray Traced Shadows** checkbox to set whether this material casts ray-traced shadows. This is useful for controlling specific elements of your materials assigned to geometry that should or should not cast a ray-traced shadow.

* Use the **Ray Tracing Quality Switch Replace Node** to replace entire parts of your material logic to lower the cost of features like RTGI, RT Reflections, and RT Translucency with less complex logic. This is a global change that affects all ray-tracing effects. 
  
    Below is an example where the **Normal** logic path renders as seen in the scene. The **Ray Tracing** path uses less complex logic for effects in Ray-Tracing, such as RTGI and Reflections where textures, normals, and roughness can be come an expensive added cost.

    ![Ray Tracing Quality Switch Replace Node Example](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/RT_MaterialQualitySwitch.png)
    *Image 6: Ray Tracing Quality Switch Replace Node Example*

## Geometry Considerations
* Geometry with small holes or lots of little details can impact performance, such as foliage and fences. 

* Indoor environments are slower to render than outdoors ones. For example, when light enters from outside, areas that are directly lit is faster than points that are indirectly lit. Also, you have to consider that more ray-tracing features are being used, such as reflections and translucency
```

`Content/RTRT/Reflections.md`:

```md
# Ray-Traced Reflections

A summarised guide on utilising ray-traced reflections to capture dynamic reflections which are sourced out of the camera view for an accurately simulated environment. Performance optimisations will be presented which includes roughness control, distance limiting, number of bounces, samples per pixel, and shadow control.

## Realistic Reflections
* Ray-traced reflections simulate accurate environment reflections that can support multiple bounces to create inter-reflection for reflective surfaces. 
  
* When compared with Screen Space Reflections (SSR), planar reflections, or even reflection probes, ray-traced reflections captures the entire scene dynamically and is not limited to static captures or objects within the current camera view to be visible in the reflection. These differences are easily noted in the comparison below:

    ![Screen Space Reflections](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/RT_Reflections_Disabled.jpg)
    *Image 1: Scene rendered with Screen Space Reflections*

    ![Ray-Traced Reflections](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/RT_Reflections_Enabled-1.jpg)
    *Image 2: Scene rendered with Ray-Traced Reflections*
  
* These can be enabled by **ticking** the **Type** box and setting the dropdown to **Ray Tracing** under the **Reflections** settings of the **Post Process Volume** in the *Details pane*.
  
* Due to the reflection simulation not being limited to what is within the camera view, the computational cost is exceptionally high depending on the number of reflections to compute. Key optimisations exist to find a balance between accuracy and performance.

## Optimisation
* There are a multitude of settings which help balance the quality versus performance of ray-traced reflections. The exact value of each setting will depend on the requirements and components of your scene. These settings are found under the **Ray Tracing Reflections** section of the **Post Process Volume** in the *Details pane*:

  * **Max Roughness**: Sets the maximum roughness value that ray-traced reflections will be visible before falling back to raster methods that are less expensive. Reflection contribution is smoothly faded when close to the roughness threshold and this parameter behaves similarly to SSR’s **Max Roughness** setting. Lower values fall back to other methods more quickly. Scene roughness can be viewed by selecting the **Roughness** option under the **Buffer Visualization** settings of the editor *View Mode*.

  * **Max Bounces**: Sets the maximum number of bounces that ray-traced reflections uses. More bounces create inter-reflection but comes at a higher cost. Set to **1** bounce by default.

  * **Samples Per Pixel**: Sets the number of samples to use per pixel for ray-traced reflections. Additional samples decrease performance while increasing quality and accuracy. Set to **1** sample per pixel by default.

  * **Shadows**: Sets how shadows should be reflected. Choose between:

    * **Hard Shadows** which has no soft shadows

    * **Area Shadows** to have soft shadowing like ray-traced shadows

    * **Disable** to disable shadowing in ray-traced reflections

* RT reflections can be expensive when rendering multiple bounces with reflections inside of reflections. Without multiple bounces, the intra-reflected material will appear black. To use **Reflection Capture Actors** as the last bounce in RT reflections, press the **Backtick key** to open the console and then input the following command:
  
    ```
    r.RayTracing.Reflections.ReflectionCaptures 1
    ```
    For example, you can have a single bounce of RT reflection, then use a reflection capture for the second bounce, saving performance. If you use two bounces of RT reflection, then the third bounce would be the reflection capture. This example is shown below:

    ![Single Bounce RT Reflection](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/1_RTRRefCapture.jpg)
    *Image 3: Single Bounce RT Reflection with no Reflection Capture Fallback*

    ![Single Bounce RT Reflection](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/2_RTRRefCapture.jpg)
    *Image 4: Two Bounces RT Reflection with no Reflection Capture Fallback*

    ![Ray-Traced Reflections](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/3_RTRRefCapture.jpg)
    *Image 5: Single Bounce RT Reflection with Reflection Capture Fallback*
```

`Content/RTRT/RequirementsConfig.md`:

```md
# Requirements and Configuration

A summarised guide on the hardware and software requirements for using ray-tracing within your projects. As well as ue4 configuration to enable the features to be accessed and utilised as expected.

## Hardware Requirements
* A ray-tracing supported GPU is required to make use of the RTRT features in ue4.
  
* At the current time of writing, these GPUs are only offered by NVIDIA which include the following:
    
    | **Turing Architecture** | **Volta Architecture** | **Pascal Architecture** |
    |-------------------------|------------------------|-------------------------|
    |Titan RTX                |Titan V                 |Titan XP                 |
    |RTX 2080 Ti              |                        |Titan X                  |
    |RTX 2080                 |                        |GTX 1080 Ti              |
    |RTX 2070                 |                        |GTX 1080                 |
    |RTX 2070                 |                        |GTX 1070 Ti              |
    |GTX 1660 Ti              |                        |GTX 1070                 |
    |GTX 1660                 |                        |GTX 1060 (6GB edition)   |

* It should be noted that not all supported GPUs are capable of supporting the full set of RTRT features:
    
    | **RTX Products**        | **Non-RTX Products** |
    |-------------------------|------------------------|
    |High ray count           |Low ray count           |
    |Complex RTRT effects     |Basic RTRT effects      |
    |Multiple RTRT effects    |                        |

## Software Requirements
* A Windows operating system is required as the RTRT features make use of DirectX Raytracing (DXR). Additionally, a minimum build version of 1809 is required.

* Unreal Engine version 4.22 or later is required to access the RTRT features.

* These RTRT features then need to be enabled within the *Project Settings*:
  
  * Set the **Default RHI** setting to **DirectX 12** in the **Platforms->Windows** section.
  
  * Enable the **Ray Tracing** setting in the **Engine->Rendering** section.
  
  * If the **Support Compute Skincache** setting is not enabled, a dialogue will appear prompting confirmation for the setting to be enabled - click **Yes**.
  
  * Restart ue4 to effect the configured settings.

## Engine Changelog
* This section summarises any general ray-tracing improvements/modifications as new engine versions are made available.
  
* **UE 4.22**: 
  
  **Added ray tracing low level support.**
  * Implemented a low level layer on top of UE DirectX 12 that provides support for DXR and allows creating and using ray tracing shaders (ray generation shaders, hit shaders, etc) to add ray tracing effects.
  
  **Added high level ray tracing features.**
  * Rect area lights
  
  * Soft shadows
  
  * Reflections
  
  * Reflected shadows
  
  * Ambient occlusion
  
  * RTGI (ray traced global illumination)
  
  * Translucency
  
  * Clearcoat
  
  * IBL
  
  * Sky
  
  * Geometry types
  
  * Texture LOD
  
  * Denoiser
  
  * Path tracer

* **UE 4.23**:
  
  Ray Tracing support has received many optimizations and stability improvements in addition to several important new features, including performance and stability enhancements, additional geometry and material support, and multi-bounce reflection fallback.

* **UE 4.24**:
  
  Stability and performance improvements, including support for static meshes that use vertex animation.
```

`Content/RTRT/ShadowsPostProcess.md`:

```md
# Ray-Traced Shadows and Post Process Volume

A summarised guide on creating ray-traced shadows and how to tweak their softness for realistic content. As well as the use of the post process volume and the respective ray tracing and path tracing features it can offer and control.

## Ray-Traced Shadows
* These simulate soft area lighting effects for objects in the environment. This means that based on the light’s source size or source angle, an object’s shadow will have sharper shadows near the contact surface than farther away where it softens and widens. This can be noted in the comparison below:

    ![Raster Shadows using Shadowmaps](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/RT_Shadows_Disabled-3.jpg)
    *Image 1: Scene rendered with Raster Shadows using Shadowmaps*

    ![Ray-Traced Soft Shadows](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/RT_Shadows_Enabled-3.jpg)
    *Image 2: Scene rendered with Ray-Traced Soft Shadows*

* Shadows can be cast by any light source. This is activated by **Enabling** the **Cast Raytraced Shadow** property under the **Light** section in the *Details pane*. Each type of light source then needs to be configured, to control the softness of the cast shadow, in the following ways:
  
  * **Directional Light**: modify the **Source Angle** property.

  * **Point** and **Spot Lights**: modify the **Source Radius** property.
  
  * **Rect Light**: modify the **Barn Door Angle** and **Barn Door Length** to shape and soften the shadow softness.

* Each configured property will control the softness observed in cast shadows. A higher value translates to a softer shadow.

## Post Process Volume
* This is used in the scene to control ray tracing and path tracing features and properties. Volumes can be added to different areas for interiors and exteriors to facilitate the customisable features and desired quality level. They allow the control of **Ray Traced Reflections**, **Translucency**, **Global Illumination**, **Ambient Occlusion**, and the **Path Tracer**.

* The image below highlights all the available ray tracing and path tracing properties which can be customised within the volume:

  ![Post Process Volume Settings](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/PPV_Settings.jpg)
  *Image 3: Post Process Volume settings*

* The post process volume can be placed into the scene by dragging it in from the *Modes pane*.

* In order to have the ray traced properties affect the entire scene, **enable** the **Infinite Extent (Unbound)** property under the **Post Process Volume Settings** section in the *Details pane*.
```

`Content/RTRT/Translucency.md`:

```md
# Ray-Traced Translucency

A summarised guide on utilising ray-traced translucency to accurately represent the physical handling of light and reflections on transparent materials. As well as performance optimisations including roughness control, refraction ray limiting, samples per pixel, reflection shadows and refraction control.

## Realistic Translucency
* Ray-traced translucency provides a physically realistic representation of reflection, absorption, and refraction properties for transparent surfaces within a scene. These differences are easily noted in the comparison below:
  
    ![Raster Translucency](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/RT_Translucency_Disabled.jpg)
    *Image 1: Scene rendered with Raster Translucency*

    ![Ray-Traced Translucency](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/RT_Translucency_Enabled.jpg)
    *Image 2: Scene rendered with Ray-Traced Translucency*

* This can be enabled by **ticking** the **Type** box and setting the dropdown to **Ray Tracing** under the **Translucency** settings of the **Post Process Volume** in the *Details pane*.
  
* The performance trade-off is less than that of ray-traced reflections but it is still important to manage the performance cost. Key optimisations exist to find a balance between accuracy and performance.

## Index of Refraction
* With ray-traced translucency, Index of Refraction (IOR) is controlled with the Material's **Specular** value clamped between **0** and **1**. This is how IOR is determined with a real-world material as well. An example of variable IOR is shown below:

    ![IOR Specular 0.0](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/RT_Refraction_0.jpg)
    *Image 3: Scene rendered with IOR Specular value of 0.0*

    ![IOR SPecular 0.5](https://docs.unrealengine.com/Images/Engine/Rendering/RayTracing/RT_Refraction_1.jpg)
    *Image 4: Scene rendered with IOR Specular value of 0.5*

* Within the *Post Process Volume* **Translucency** and **Ray Tracing Translucency** sections, use the following guidelines to control IOR with a ray-traced translucent material:
  
  * **Enable** the **Type** box and select the **Ray Tracing** dropdown option.
  
  * **Enable** the **Refraction** option.

  *  Set the **Max Refraction Rays** to a high enough bumber of bounces to see the other side of the material. For example, a single bounce would not be enough to see objects behind it, but several bounces may be.

## Optimisation
* There are a multitude of settings which help balance the quality versus performance of ray-traced translucency. The exact value of each setting will depend on the requirements and components of your scene. These settings are found under the **Ray Tracing Translucency** section of the **Post Process Volume** in the *Details pane*:

  * **Max Roughness**: Sets the maximum roughness value that ray-traced translucency will be visible before falling back to raster methods which are less expensive. Translucency contribution is smoothly faded when close to the roughness threshold and this parameter behaves similarly to SSR’s **Max Roughness** setting. Lower values fall back to other methods more quickly.

  * **Max Refraction Rays**: Sets the maximum number of refraction rays that ray-traced translucency uses. Additional samples decrease performance while increasing quality and accuracy. Set to **3** refraction rays by default.

  * **Samples Per Pixel**: Sets the number of samples to use per pixel for ray-traced translucency. Additional samples decrease performance while increasing quality and accuracy. Set to **1** sample per pixel by default.

  * **Shadows**: Sets how shadows should be reflected. Choose between:

    * **Hard Shadows** which has no soft shadows

    * **Area Shadows** to have soft shadowing like ray-traced shadows

    * **Disable** to disable shadowing in ray-traced translucency
  
  * **Refraction**: Sets whether refraction should be enabled or not for ray-traced translucency. If disabled, rays will not scatter and only travel in the same direction as before the intersection event.
```

`LICENSE`:

```
MIT License

Copyright (c) 2019 Jared Ping

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

```

`README.md`:

```md
# Unreal Development Guides and Tips

![Real Time Ray Tracing](static/images/ue4_logo.png)

Range of content including high-level concept explanations, detailed tutorials, performance considerations, shortcuts and other useful content that aims to improve your Unreal Engine 4 development journey.

Built with the community in mind. The end goal is to become a centralised knowledge base which will compliment official documentation as well as help a range of developers, whether just starting out or seasoned veterans experimenting with new features.

**Be sure to bookmark as updates are ongoing <(^_^<)**

## Content Directory

### Basic Scene Creation

![Real Time Ray Tracing](static/images/basics.gif)

Short guides/tricks on creating a level with aesthetically pleasing elements and lighting. Introduces dynamic light and actor light sources. Also considers pre-made content imports for quick starting.

*  [Adding content to a project](Content/Basics/AddingContentToAProject.md)
*  [Level creation](Content/Basics/LevelCreation.md)
*  [Improved scene lighting](Content/Basics/ImprovedSceneLighting.md)
*  [Actor light sources](Content/Basics/ActorLightSources.md)

### Improving Development Pipelines

![Real Time Ray Tracing](static/images/LOD.gif)

Concepts/guides on cross-platform performance. Strong focus on optimisation and performance considerations in projects in conjunction with best practices. Covers a range of areas including Textures, Meshes, Materials, Texture Streaming, LODs, Lighting, Volumes and Reflections.

*  [Textures](Content/DevPipelines/Textures.md)
*  [Texture streaming](Content/DevPipelines/TextureStreaming.md)
*  [Static meshes](Content/DevPipelines/StaticMeshes.md)
*  [Importing and Exporting](Content/DevPipelines/ImportingAndExporting.md)
*  [Levels of Detail (LODs) and Static mesh merging](Content/DevPipelines/LODsAndMeshMerge.md)
*  [Materials I: Basics](Content/DevPipelines/MaterialsI.md)
*  [Materials II: Master materials and Material functions](Content/DevPipelines/MaterialsII.md)
*  [Materials III: Material instances](Content/DevPipelines/MaterialsIII.md)
*  [Materials IV: Vertex animation materials](Content/DevPipelines/MaterialsIV.md)
*  [Light, Shadow, and Post Process](Content/DevPipelines/LightShadowPostProcess.md)
*  [Volumes](Content/DevPipelines/Volumes.md)
*  [Reflections](Content/DevPipelines/Reflections.md)

### Real Time Ray Tracing (RTRT)

![Real Time Ray Tracing](static/images/star_wars.gif)

Concepts/guides on using how to make use of RTRT. Covers the hardware requirements to use the feature, basic discussion of each ray tracing component and how to implement each component in UE4. Furthermore, some additional command line features are mentioned and useful RTRT development tips.

* [Requirements and Configuration](Content/RTRT/RequirementsConfig.md)
* [Ray-Traced Shadows and Post Process Volume](Content/RTRT/ShadowsPostProcess.md)
* [Ray-Traced Reflections](Content/RTRT/Reflections.md)
* [Ray-Traced Translucency](Content/RTRT/Translucency.md)
* [Ray-Traced Ambient Occlusion](Content/RTRT/AmbientOcclusion.md)
* [Ray-Traced Global Illumination](Content/RTRT/GlobalIllumination.md)
* [Performance Analysis and Debugging](Content/RTRT/PerformanceDebug.md)
* [Path Tracer Benchmarking](Content/RTRT/PathTracer.md)

### Chaos Physics

![Chaos Physics](static/images/chaos_destruction.gif)

Concepts/guides on using Chaos Physics. Covers how to configure projects to use required Chaos features, destruction, vehicle physics, and the Chaos Fields system for controlling force fields to achieve a range of results. Note that Chaos Physics is currently in preview release and features are subject to change.

* [Plugin Configuration](Content/Chaos/PluginConfig.md)

### Converting Blueprints To C++

![BP Conversion](static/images/coding_fire.gif)

Concepts/guides on the benefits of using Blueprints versus C++. Covers the strengths and weaknesses of each approach, basic C++ architecture for maintainable design and the process of converting Blueprints to C++ implementations.

* [Blueprints vs C++]()

## Interesting Resources

* [Unreal Fest 2018 Presentations + Slides](https://www.unrealengine.com/en-US/events/unreal-fest-europe-2018)
* [Unreal Fest 2019 Presentations + Slides](https://www.unrealengine.com/en-US/events/unreal-fest-europe-2019)
* [Ray Tracing Gems: High-quality and real-time rendering with DXR and other APIs](http://www.realtimerendering.com/raytracinggems/unofficial_RayTracingGems_v1.6.pdf)

## References
* [Unreal Documentation](https://docs.unrealengine.com/)
* [Unreal Academy](https://academy.unrealengine.com/)
* [Unreal Wiki](https://ue4community.wiki/) (Lacks support for recent engine versions)
* [UE4 Trello Roadmap](https://trello.com/b/TTAVI7Ny/ue4-roadmap) (No longer updated post 4.25)
* [UE4 Public Roadmap](https://portal.productboard.com/epicgames/1-unreal-engine-public-roadmap)

## Contributing

You'd like to help make this guide even more awesome? Seems like today's my lucky day! In order to maintain consistency of the guide and its code base, please adhere to the following steps, and I'd be pleased to include your additions.

**Step 1: Choose what to do**

If you've got no idea how to help, feel free to read through the existing content and look for ways to enhance it, be it grammar changes, content addition, media attachments or a GIF demonstration.

If you know exactly what is missing, [open a new issue](https://github.com/JaredP94/Unreal-Development-Guides-and-Tips/issues/new) to begin a short discussion about your idea and how it fits the guide. If we all agree, you're good to go!

**Step 2: Fork the project and check out the code**

The guide is to be community developed using the [GitFlow branching model](http://nvie.com/posts/a-successful-git-branching-model/). In order to contribute, you should check out the latest master branch, and create a new section or enhancement branch to be merged back.

**Step 3: Implement your new feature or enhancement**

The guide is ideally meant to target the latest version of Unreal Engine 4 and so it's always best to fact check your content against the latest version of documentation.

**Step 4: Open a pull request**

Finally, [open a pull request](https://help.github.com/articles/creating-a-pull-request/) so we can review your changes together, and finally integrate it into the guide.

```

`_config.yml`:

```yml
theme: jekyll-theme-leap-day
```

`_layouts/default.html`:

```html
<!doctype html>
<html lang="{{ site.lang | default: "en-US" }}">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

{% seo %}
    <link rel="stylesheet" href="{{ '/assets/css/style.css?v=' | append: site.github.build_revision | relative_url }}">
    <script src="https://code.jquery.com/jquery-3.3.0.min.js" integrity="sha256-RTQy8VOmNlT6b2PIRur37p6JEBZUE7o8wPgMvu18MC4=" crossorigin="anonymous"></script>
    <script src="{{ '/assets/js/main.js' | relative_url }}"></script>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">

  </head>
  <body>

      <header>
        <h1>{{ page.title | default: site.title | default: site.github.repository_name }}</h1>
        <p>{{ page.description | default: site.description | default: site.github.project_tagline }}</p>
      </header>

      <div id="banner">
        <span id="logo"></span>

        <a href="https://jaredp94.github.io/Unreal-Development-Guides-and-Tips/" class="button fork"><strong>Back To Landing Page</strong></a>
        <a href="{{ site.github.repository_url }}" class="button fork view-hub"><strong>View On GitHub</strong></a>
        {% if site.show_downloads %}
          <div class="downloads">
            <span>Downloads:</span>
            <ul>
              <li><a href="{{ site.github.zip_url }}" class="button">ZIP</a></li>
              <li><a href="{{ site.github.tar_url }}" class="button">TAR</a></li>
            </ul>
          </div>
        {% endif %}
      </div><!-- end banner -->

    <div class="wrapper">
      <nav>
        <ul></ul>
      </nav>
      <section>
        {{ content }}

      </section>
      <footer>
        {% if site.github.is_project_page %}
          <p>Project maintained by <a href="{{ site.github.owner_url }}">{{ site.github.owner_name }}</a></p>
        {% endif %}
      </footer>
    </div>

    {% if site.google_analytics %}
      <script>
        (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
        (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
        m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
        })(window,document,'script','//www.google-analytics.com/analytics.js','ga');
        ga('create', '{{ site.google_analytics }}', 'auto');
        ga('send', 'pageview');
      </script>
    {% endif %}
  </body>
</html>
```

`assets/css/style.scss`:

```scss
---
---

@import "{{ site.theme }}";
body {
    font: 15px/22px 'Quattrocento Sans', "Helvetica Neue", Helvetica, Arial, sans-serif !important;
    background: url(../images/background.jpg) !important;
}
footer {
    background: white !important;
    border-radius: 3px !important;
    width: 160px !important;
    padding: 10px 20px 10px 10px !important;
    margin-left: -540px !important;
}
nav {
    background: white !important;
    border-radius: 3px !important;
    padding: 10px 20px 0px 0px !important;
    margin-left: -600px !important;
}
header {
    background: black !important;
}
.view-hub {
    left: 77.3% !important;
}
```