Project Path: arc_zinja-coder_apktool-mcp-server_ct6f90nk

Source Tree:

```txt
arc_zinja-coder_apktool-mcp-server_ct6f90nk
‚îú‚îÄ‚îÄ CODE_OF_CONDUCT.md
‚îú‚îÄ‚îÄ CONTRIBUTING.md
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ SECURITY.md
‚îú‚îÄ‚îÄ apktool_mcp_server.py
‚îú‚îÄ‚îÄ docs
‚îÇ   ‚îî‚îÄ‚îÄ assets
‚îÇ       ‚îî‚îÄ‚îÄ apktool-mcp-server-banner.png
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ requirements.txt
‚îú‚îÄ‚îÄ test.sh
‚îî‚îÄ‚îÄ uv.lock

```

`CODE_OF_CONDUCT.md`:

```md
# Contributor Covenant Code of Conduct

## Our Pledge

We as members, contributors, and leaders pledge to make participation in our
community a harassment-free experience for everyone, regardless of age, body
size, visible or invisible disability, ethnicity, sex characteristics, gender
identity and expression, level of experience, education, socio-economic status,
nationality, personal appearance, race, religion, or sexual identity
and orientation.

We pledge to act and interact in ways that contribute to an open, welcoming,
diverse, inclusive, and healthy community.

## Our Standards

Examples of behavior that contributes to a positive environment for our
community include:

* Demonstrating empathy and kindness toward other people
* Being respectful of differing opinions, viewpoints, and experiences
* Giving and gracefully accepting constructive feedback
* Accepting responsibility and apologizing to those affected by our mistakes,
  and learning from the experience
* Focusing on what is best not just for us as individuals, but for the
  overall community

Examples of unacceptable behavior include:

* The use of sexualized language or imagery, and sexual attention or
  advances of any kind
* Trolling, insulting or derogatory comments, and personal or political attacks
* Public or private harassment
* Publishing others' private information, such as a physical or email
  address, without their explicit permission
* Other conduct which could reasonably be considered inappropriate in a
  professional setting

## Enforcement Responsibilities

Community leaders are responsible for clarifying and enforcing our standards of
acceptable behavior and will take appropriate and fair corrective action in
response to any behavior that they deem inappropriate, threatening, offensive,
or harmful.

Community leaders have the right and responsibility to remove, edit, or reject
comments, commits, code, wiki edits, issues, and other contributions that are
not aligned to this Code of Conduct, and will communicate reasons for moderation
decisions when appropriate.

## Scope

This Code of Conduct applies within all community spaces, and also applies when
an individual is officially representing the community in public spaces.
Examples of representing our community include using an official e-mail address,
posting via an official social media account, or acting as an appointed
representative at an online or offline event.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported to the community leaders responsible for enforcement at
Discussion.
All complaints will be reviewed and investigated promptly and fairly.

All community leaders are obligated to respect the privacy and security of the
reporter of any incident.

## Enforcement Guidelines

Community leaders will follow these Community Impact Guidelines in determining
the consequences for any action they deem in violation of this Code of Conduct:

### 1. Correction

**Community Impact**: Use of inappropriate language or other behavior deemed
unprofessional or unwelcome in the community.

**Consequence**: A private, written warning from community leaders, providing
clarity around the nature of the violation and an explanation of why the
behavior was inappropriate. A public apology may be requested.

### 2. Warning

**Community Impact**: A violation through a single incident or series
of actions.

**Consequence**: A warning with consequences for continued behavior. No
interaction with the people involved, including unsolicited interaction with
those enforcing the Code of Conduct, for a specified period of time. This
includes avoiding interactions in community spaces as well as external channels
like social media. Violating these terms may lead to a temporary or
permanent ban.

### 3. Temporary Ban

**Community Impact**: A serious violation of community standards, including
sustained inappropriate behavior.

**Consequence**: A temporary ban from any sort of interaction or public
communication with the community for a specified period of time. No public or
private interaction with the people involved, including unsolicited interaction
with those enforcing the Code of Conduct, is allowed during this period.
Violating these terms may lead to a permanent ban.

### 4. Permanent Ban

**Community Impact**: Demonstrating a pattern of violation of community
standards, including sustained inappropriate behavior,  harassment of an
individual, or aggression toward or disparagement of classes of individuals.

**Consequence**: A permanent ban from any sort of public interaction within
the community.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage],
version 2.0, available at
https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.

Community Impact Guidelines were inspired by [Mozilla's code of conduct
enforcement ladder](https://github.com/mozilla/diversity).

[homepage]: https://www.contributor-covenant.org

For answers to common questions about this code of conduct, see the FAQ at
https://www.contributor-covenant.org/faq. Translations are available at
https://www.contributor-covenant.org/translations.

```

`CONTRIBUTING.md`:

```md
# Contributing to apktool-mcp-server

Thank you for considering contributing to the project! We welcome contributions that improve functionality, performance, documentation, or overall code quality.

## How to Contribute

1. **Fork the repository**
   - Click "Fork" at the top-right of the repository page.
   
2. **Clone your fork**
   ```bash
   git clone https://github.com/your-username/apktool-mcp-server.git
   
   # Create a new branch
   git checkout -b your-feature-branch
   ```

3. **Make your changes**

   - Follow the coding style used in the project.

   - Keep commits atomic and meaningful.

   - Add/update tests if necessary.

   - Update documentation if behavior changes.

4. **Test your changes**

   - Make sure everything builds and works properly.

   - Run existing tests and new ones you add.

5. **Submit a Pull Request**

   - Push your branch to your fork.

   - Open a pull request against the main branch.

   - Fill out the Pull Request Template.

6. **Code Style and Practices**

   - Write clear, concise commit messages.

   - Keep pull requests focused and small.

   - Document any new features or major changes.

   - Maintain backward compatibility where possible.

### Development Requirements

   - Python 3.10+ for apktool-mcp-server

   - Familiarity with MCP, jadx, and Android reverse engineering concepts is a plus.

### Communication

If you plan to contribute a larger feature or change, please open an issue first to discuss it.

**Thanks for helping make this project better! You are awesome and thanks in advance.**

```

`LICENSE`:

```
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [yyyy] [name of copyright owner]

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.

```

`README.md`:

```md
<div align="center">

# apktool-mcp-server (Part of Zin's Reverse Engineering MCP Suite)

‚ö° Fully automated MCP server built on top of apktool to analyze Android APKs using LLMs like Claude ‚Äî uncover vulnerabilities, parse manifests, and reverse engineer effortlessly.

![GitHub contributors apktool-mcp-server](https://img.shields.io/github/contributors/zinja-coder/apktool-mcp-server)
![GitHub all releases](https://img.shields.io/github/downloads/zinja-coder/apktool-mcp-server/total)
![GitHub release (latest by SemVer)](https://img.shields.io/github/downloads/zinja-coder/apktool-mcp-server/latest/total)
![Latest release](https://img.shields.io/github/release/zinja-coder/apktool-mcp-server.svg)
![Python 3.10+](https://img.shields.io/badge/python-3%2E10%2B-blue)
[![License](http://img.shields.io/:license-apache-blue.svg)](http://www.apache.org/licenses/LICENSE-2.0.html)

</div>

<!-- It is a still in early stage of development, so expects bugs, crashes and logical erros.-->

<div align="center">
    <img alt="banner" height="480px" widht="620px" src="https://github.com/user-attachments/assets/eb9037f2-d1c7-45e0-8871-ca8aaade0dd0">
</div>

<!--![apktool-mcp-server-banner.png](docs/assets/apktool-mcp-server-banner.png)-->

Image generated using AI tools.

---

## ü§ñ What is apktool-mcp-server?

**apktool-mcp-server** is a MCP server for the [Apk Tool](https://github.com/iBotPeaches/apktool) that integrates directly with [Model Context Protocol (MCP)](https://github.com/anthropic/mcp) to provide **live reverse engineering support with LLMs like Claude**.

Think: "Decompile ‚Üí Context-Aware Code Review ‚Üí AI Recommendations" ‚Äî all in real time.

Watch the demo!

https://github.com/user-attachments/assets/d50251b8-6b1c-4341-b18e-ae54eb24a847

- **Solving the CTFs**



https://github.com/user-attachments/assets/c783a604-a636-4e70-9fa8-37e3d219b20b


## Other projects in Zin MCP Suite
 - **[JADX-AI-MCP](https://github.com/zinja-coder/jadx-ai-mcp)**
 - **[JADX-MCP-Server](https://github.com/zinja-coder/jadx-mcp-server)**
 - **[ZIN-MCP-Client](https://github.com/zinja-coder/zin-mcp-client)**

## Current MCP Tools

The following MCP tools are available:

- `build_apk()` ‚Äî Build an APK from a decoded APKTool Project.
- `get_manifest()` ‚Äî Get the AndroidManifest.xml content from a decoded APK project. 
- `get_apktool_yml()` ‚Äî Get apktool.yml information from a decoded APK project. 
- `list_smali_directories()` ‚Äî List all smali directories in a project. 
- `list_smali_files()` ‚Äî List smali files in a specific smali directory, optinally filtered by package prefix.
- `get_smali_file()` ‚Äî Get content of a specific smali file by class name. 
- `modify_smali_file()` ‚Äî Modify the content of a specific smali file. 
- `list_resources()` ‚Äî List resources in a project, optionally filtered by resource type. 
- `get_resource_file()` ‚Äî Get Content of a specific resource file. 
- `modify_resource_file()` ‚Äî Modify the content of a specific resource file. 
- `search_in_file()` ‚Äî Search for a pattern in files with specified extensions. 
- `clean_project()` ‚Äî Clean a project directory to prepare for rebuilding.
- `decode_apk()` ‚Äî Decode an APK file using APKTool, extracting resources and smali code. 

---

## üóíÔ∏è Sample Prompts


### üîç Basic Code Understanding

- ‚ÄúList all smali directories for the dvac project.‚Äù

- ‚ÄúShow me all the smali files under the package prefix com.vulnerable.component in the dvac project.‚Äù

- ‚ÄúGet the smali code for the class com.vulnerable.component.MainActivity.‚Äù

- ‚ÄúCompare MainActivity.smali with its previous version and show differences.‚Äù

- ‚ÄúSearch for usage of startActivity in smali files of dvac project.‚Äù

### üõ°Ô∏è Vulnerability Detection

- ‚ÄúAnalyze declared permissions in the dvac AndroidManifest.xml and flag dangerous ones.‚Äù

- ‚ÄúSearch for hardcoded URLs or IPs in all .xml and .smali files in the project.‚Äù

- ‚ÄúFind all uses of PendingIntent.getActivity in smali files.‚Äù

- ‚ÄúCheck for exported activities or receivers in dvac‚Äôs AndroidManifest.xml.‚Äù

- ‚ÄúList all smali files that access android.permission.SEND_SMS or READ_CONTACTS.‚Äù

### üõ†Ô∏è Reverse Engineering Helpers

- ‚ÄúDecode this APK: dvac.apk and create a project called dvac.‚Äù

- ‚ÄúCreate a new APKTool project called test-harness.‚Äù

- ‚ÄúClean the dvac project before rebuild.‚Äù

- ‚ÄúExtract DEX files from dvac project for external analysis.‚Äù

- ‚ÄúModify MainActivity.smali to insert a log line at the beginning of onCreate().‚Äù

### üì¶ Static Analysis

- ‚ÄúGet the complete AndroidManifest.xml from dvac project.‚Äù

- ‚ÄúShow the contents of apktool.yml for the dvac project.‚Äù

- ‚ÄúList all resource files of type layout.‚Äù

- ‚ÄúSearch for the word password in all resource and smali files.‚Äù

- ‚ÄúCheck which permissions are used and compare them against typical over-permissioning risks.‚Äù

### ü§ñ AI Code Modification

- ‚ÄúModify the onCreate() method in MainActivity.smali to add a toast message.‚Äù

- ‚ÄúReplace all http:// links with https:// in strings.xml.‚Äù

- ‚ÄúAdd the android:exported=false attribute to all activities in the AndroidManifest.xml.‚Äù

- ‚ÄúPatch the method validateLogin in LoginManager.smali to always return true.‚Äù

- ‚ÄúAdd logging statements to every method in MainActivity.smali.‚Äù

### üìÑ Documentation & Metadata

- ‚ÄúList all decoded APKTool projects in the workspace.‚Äù

- ‚ÄúShow me the apktool.yml config to review the version, original APK metadata, and compression settings.‚Äù

- ‚ÄúGet all available Android devices connected via ADB. (To be migrated to ADB MCP Server.)‚Äù

- ‚ÄúGet metadata about the project dvac from its apktool.yml.‚Äù

- ‚ÄúCheck which APKTool version is currently installed on the server.‚Äù
---

## üõ†Ô∏è Getting Started 
### 1. Downlaod from Releases: https://github.com/zinja-coder/apktool-mcp-server/releases

```bash
# 0. Download and install apktool
https://apktool.org/docs/install

# 1. Test whether apktool has been correctly configured in the environment variables
$ apktool -version

# 2. Download the apktool-mcp-server-<version>.zip
https://github.com/zinja-coder/apktool-mcp-server/releases

# 3. 
unzip apktool-mcp-server-<version>.zip

‚îúapktool-mcp-server/
  ‚îú‚îÄ‚îÄ apktool_mcp_server.py
  ‚îú‚îÄ‚îÄ requirements.txt
  ‚îú‚îÄ‚îÄ README.md
  ‚îú‚îÄ‚îÄ LICENSE

# 4. Navigate to apktool-mcp-server directory
cd apktool-mcp-server

# 5. This project uses uv - https://github.com/astral-sh/uv instead of pip for dependency management.
    ## a. Install uv (if you dont have it yet)
curl -LsSf https://astral.sh/uv/install.sh | sh
    ## b. OPTIONAL, if for any reasons, you get dependecy errors in apktool-mcp-server, Set up the environment
uv venv
source .venv/bin/activate  # or .venv\Scripts\activate on Windows
    ## c. OPTIONAL Install dependencies
uv pip install httpx fastmcp

# The setup for apktool-mcp-server is done.
```

## 2. Running on Local LLM Using Ollama and Zin MCP Client - Recommended

<div align="center">
    <a href="https://github.com/zinja-coder/zin-mcp-client">
    <img alt="zin-mcp-client" height="360px" widht="480px" src="https://github.com/user-attachments/assets/0e8e0ecd-0520-422e-a007-03dc62c4118e">
    </a>
</div>

‚ö° Lightweight, Fast, Simple, CLI-Based MCP Client for STDIO MCP Servers, to fill the gap and provide bridge between your local LLMs running Ollama and MCP Servers.

Check Now: https://github.com/zinja-coder/zin-mcp-client

Demo: Coming soon...

## ü§ñ 3. Claude Desktop Setup

Make sure Claude Desktop is running with MCP enabled.

For instance, I have used following for Kali Linux: https://github.com/aaddrick/claude-desktop-debian

Configure and add MCP server to LLM file:
```bash
nano ~/.config/Claude/claude_desktop_config.json
```

   - Windows: `%APPDATA%\Claude\claude_desktop_config.json`
   - macOS: `~/Library/Application Support/Claude/claude_desktop_config.json`

And following content in it:
```json
{
    "mcpServers": {
        "apktool-mcp-server": {
            "command": "/<path>/<to>/uv", 
            "args": [
                "--directory",
                "</PATH/TO/>apktool-mcp-server/",
                "run",
                "apktool_mcp_server.py"
            ]
        }
    }
}
```

Replace:

- `path/to/uv` with the actual path to your `uv` executable
- `path/to/apktool-mcp-server` with the absolute path to where you cloned this
repository

Then, navigate code and interact via real-time code review prompts using the built-in integration.

## 4. Cherry Studio Setup

If you want to configure the MCP tool in Cherry Studio, you can refer to the following configuration.
- Type: stdio
- command: uv
- argument:
```bash
--directory
path/to/apktool-mcp-server
run
apktool_mcp_server.py
```
- `path/to/apktool-mcp-server` with the absolute path to where you cloned this
repository

## To report bugs, issues, feature suggestion, Performance issue, general question, Documentation issue.
 - Kindly open an issue with respective template.

 - Tested on Claude Desktop Client, support for other AI will be tested soon!

## üôè Credits

This project is a MCP Server for [Apktool](https://github.com/iBotPeaches/apktool), an amazing open-source Android reverse engineering tool created and maintained by [@iBotPeaches](https://github.com/iBotPeaches). All core APK decoding and resource processing logic belongs to them. I have only extended it to support my MCP server with AI capabilities.

[üìé Original README (Apktool)](https://github.com/iBotPeaches/apktool)

The original README.md from Apktool is included here in this repository for reference and credit.

Also huge thanks to [@aaddrick](https://github.com/aaddrick) for developing Claude desktop for Debian based Linux.

And in last, thanks to [@anthropics](https://github.com/anthropics) for developing the Model Context Protocol and [@FastMCP](https://github.com/jlowin/fastmcp) team.

And all open source project maintainers and contributos which provies libraries and dependencies to make project like this possible.

## üìÑ License

apktool-mcp-server and all related projects inherits the Apache 2.0 

## ‚öñÔ∏è Legal Warning

**Disclaimer**

The tools `apktool-mcp-server` and all related tools under this project are intended strictly for educational, research, and ethical security assessment purposes. They are provided "as-is" without any warranties, expressed or implied. Users are solely responsible for ensuring that their use of these tools complies with all applicable laws, regulations, and ethical guidelines.

By using `apktool-mcp-server`, you agree to use them only in environments you are authorized to test, such as applications you own or have explicit permission to analyze. Any misuse of these tools for unauthorized reverse engineering, infringement of intellectual property rights, or malicious activity is strictly prohibited.

The developers of `apktool-mcp-server` shall not be held liable for any damage, data loss, legal consequences, or other consequences resulting from the use or misuse of these tools. Users assume full responsibility for their actions and any impact caused by their usage.

Use responsibly. Respect intellectual property. Follow ethical hacking practices.

---

## üôå Contribute or Support

## Contributing

[![Contributions Welcome](https://img.shields.io/badge/contributions-welcome-brightgreen.svg?style=flat-square)](CONTRIBUTE.md)

- Found it useful? Give it a ‚≠êÔ∏è
- Got ideas? Open an [issue](https://github.com/zinja-coder/apktool-mcp-server/issues) or submit a PR
- Built something on top? DM me or mention me ‚Äî I‚Äôll add it to the README!

---
## Audited and Received Assessment Badge

[![MseeP.ai Security Assessment Badge](https://mseep.net/pr/zinja-coder-apktool-mcp-server-badge.png)](https://mseep.ai/app/zinja-coder-apktool-mcp-server)

Thank you Mseep.net for auditing and providing Assessment Badge.
---

Built with ‚ù§Ô∏è for the reverse engineering and AI communities.

```

`SECURITY.md`:

```md
# Security Policy
---
### Reporting a Vulnerability

To report a security issue, please open a new [security advisory](https://github.com/zinja-coder/jadx-ai/security/advisories). Please fill the steps you took to create the issue, affected versions, and, if known, mitigations for the issue. We will check and respond within 3 working days. If the issue is confirmed as a vulnerability, we will apply required mitigations at the next release.

```

`apktool_mcp_server.py`:

```py
# /// script
# requires-python = ">=3.10"
# dependencies = [ "fastmcp", "logging", "argparse" ]
# ///

"""
Copyright (c) 2025 apktool mcp server developer(s) (https://github.com/zinja-coder/apktool-mcp-server)
See the file 'LICENSE' for copying permission
"""

import logging
import subprocess
import os
import shutil
import argparse
import json
import time
import xml.etree.ElementTree as ET
from typing import List, Union, Dict, Optional, Callable, Any
from fastmcp import FastMCP

# Set up logging configuration
logger = logging.getLogger()
logger.setLevel(logging.INFO)

# Console handler for logging to the console
console_handler = logging.StreamHandler()
console_handler.setLevel(logging.INFO)
console_handler.setFormatter(logging.Formatter('%(asctime)s - %(levelname)s - %(message)s'))
logger.addHandler(console_handler)

# Parse arguments
parser = argparse.ArgumentParser("APKTool MCP Server")
parser.add_argument("--http", help="Serve MCP Server over HTTP stream.", action="store_true", default=False)
parser.add_argument("--port", help="Specify the port number for --http to serve on. (default:8652)", default=8652, type=int)
parser.add_argument("--workspace", help="Specify workspace directory for APK projects", default="apktool_mcp_server_workspace", type=str)
parser.add_argument("--timeout", help="Default timeout for APKTool commands in seconds", default=300, type=int)
args = parser.parse_args()

# Initialize the MCP server
mcp = FastMCP("APKTool-MCP Server with Advanced Features")

# Current workspace for decoded APK projects
WORKSPACE_DIR = os.environ.get("APKTOOL_WORKSPACE", args.workspace)
DEFAULT_TIMEOUT = args.timeout

# Ensure workspace directory exists
os.makedirs(WORKSPACE_DIR, exist_ok=True)

class PaginationUtils:
    """Utility class for handling pagination across different MCP tools"""
    
    # Configuration constants
    DEFAULT_PAGE_SIZE = 100
    MAX_PAGE_SIZE = 10000
    MAX_OFFSET = 1000000
    
    @staticmethod
    def validate_pagination_params(offset: int, count: int) -> tuple[int, int]:
        """Validate and normalize pagination parameters"""
        offset = max(0, min(offset, PaginationUtils.MAX_OFFSET))
        count = max(0, min(count, PaginationUtils.MAX_PAGE_SIZE))
        return offset, count
    
    @staticmethod
    def handle_pagination(
        items: List[Any],
        offset: int = 0,
        count: int = 0,
        data_type: str = "paginated-list",
        items_key: str = "items",
        item_transformer: Optional[Callable[[Any], Any]] = None
    ) -> Dict[str, Any]:
        """
        Generic pagination handler for list data
        
        Args:
            items: List of items to paginate
            offset: Starting offset
            count: Number of items to return (0 means use default)
            data_type: Type identifier for the response
            items_key: Key name for items in response
            item_transformer: Optional function to transform items
            
        Returns:
            Paginated response dictionary
        """
        if items is None:
            items = []
            
        total_items = len(items)
        
        # Validate parameters
        offset, count = PaginationUtils.validate_pagination_params(offset, count)
        
        # Determine effective limit
        if count == 0:
            effective_limit = min(PaginationUtils.DEFAULT_PAGE_SIZE, max(0, total_items - offset))
        else:
            effective_limit = min(count, max(0, total_items - offset))
        
        # Calculate bounds
        start_index = min(offset, total_items)
        end_index = min(start_index + effective_limit, total_items)
        has_more = end_index < total_items
        
        # Extract and transform paginated subset
        paginated_items = items[start_index:end_index]
        if item_transformer:
            paginated_items = [item_transformer(item) for item in paginated_items]
        
        # Build response
        result = {
            "type": data_type,
            items_key: paginated_items,
            "pagination": {
                "total": total_items,
                "offset": offset,
                "limit": effective_limit,
                "count": len(paginated_items),
                "has_more": has_more
            }
        }
        
        # Add navigation helpers
        if has_more:
            result["pagination"]["next_offset"] = end_index
            
        if offset > 0:
            prev_offset = max(0, offset - effective_limit)
            result["pagination"]["prev_offset"] = prev_offset
            
        # Page calculations
        if effective_limit > 0:
            current_page = (offset // effective_limit) + 1
            total_pages = (total_items + effective_limit - 1) // effective_limit
            result["pagination"]["current_page"] = current_page
            result["pagination"]["total_pages"] = total_pages
            result["pagination"]["page_size"] = effective_limit
            
        return result

class ValidationUtils:
    """Utility class for input validation"""
    
    @staticmethod
    def validate_path(path: str, must_exist: bool = True) -> Dict[str, Union[bool, str]]:
        """Validate file/directory path"""
        if not path or not isinstance(path, str):
            return {"valid": False, "error": "Path cannot be empty"}
            
        if must_exist and not os.path.exists(path):
            return {"valid": False, "error": f"Path does not exist: {path}"}
            
        return {"valid": True}
    
    @staticmethod
    def validate_class_name(class_name: str) -> Dict[str, Union[bool, str]]:
        """Validate Java class name format"""
        if not class_name or not isinstance(class_name, str):
            return {"valid": False, "error": "Class name cannot be empty"}
            
        if not class_name.replace('.', '').replace('_', '').replace('$', '').replace('/', '').isalnum():
            return {"valid": False, "error": "Invalid class name format"}
            
        return {"valid": True}
     
    @staticmethod
    def validate_search_pattern(pattern: str) -> Dict[str, Union[bool, str]]:
        """Validate search pattern"""
        if not pattern or not isinstance(pattern, str):
            return {"valid": False, "error": "Search pattern cannot be empty"}
            
        if len(pattern) > 1000:
            return {"valid": False, "error": "Search pattern too long (max 1000 characters)"}
            
        return {"valid": True}

# Enhanced command runner with better error handling
def run_command(command: List[str], timeout: int = DEFAULT_TIMEOUT, cwd: Optional[str] = None) -> Dict[str, Union[str, int, bool]]:
    """Enhanced command runner with comprehensive error handling"""
    try:
        logger.info(f"Running command: {' '.join(command)}")
        
        # Input validation
        if not command or not all(isinstance(arg, str) for arg in command):
            return {
                "success": False,
                "error": "Invalid command format"
            }
        
        result = subprocess.run(
            command,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            text=True,
            check=True,
            timeout=timeout,
            cwd=cwd
        )
        
        logger.info(f"Command completed successfully with return code {result.returncode}")
        return {
            "success": True,
            "stdout": result.stdout,
            "stderr": result.stderr,
            "returncode": result.returncode,
            "command": " ".join(command)
        }
        
    except subprocess.CalledProcessError as e:
        logger.error(f"Command failed with return code {e.returncode}: {e.stderr}")
        return {
            "success": False,
            "stdout": e.stdout or "",
            "stderr": e.stderr or "",
            "returncode": e.returncode,
            "error": f"Command failed with return code {e.returncode}",
            "command": " ".join(command)
        }
        
    except subprocess.TimeoutExpired as e:
        logger.error(f"Command timed out after {timeout} seconds")
        return {
            "success": False,
            "error": f"Command timed out after {timeout} seconds",
            "command": " ".join(command)
        }
        
    except FileNotFoundError:
        return {
            "success": False,
            "error": "APKTool not found. Please ensure APKTool is installed and in PATH"
        }
        
    except Exception as e:
        logger.error(f"Unexpected error running command: {str(e)}")
        return {
            "success": False,
            "error": f"Unexpected error: {str(e)}",
            "command": " ".join(command)
        }

# Health check functionality
@mcp.tool()
async def health_check() -> Dict:
    """
    Check the health status of the APKTool MCP server and APKTool installation.
    
    Returns:
        Dictionary containing server status and APKTool availability
    """
    try:
        # Check APKTool installation
        apktool_result = run_command(["apktool", "--version"], timeout=10)
        
        result = {
            "server_status": "running",
            "workspace_dir": WORKSPACE_DIR,
            "workspace_exists": os.path.exists(WORKSPACE_DIR),
            "apktool_available": apktool_result["success"],
            "timestamp": time.time()
        }
        
        if apktool_result["success"]:
            result["apktool_version"] = apktool_result["stdout"].strip()
        else:
            result["apktool_error"] = apktool_result["error"]
            
        logger.info("APKTool MCP Server: Health check completed")
        return result
        
    except Exception as e:
        logger.error(f"Health check error: {str(e)}")
        return {
            "server_status": "error",
            "error": str(e),
            "timestamp": time.time()
        }

# Enhanced MCP Tools with validation and better error handling

@mcp.tool()
async def decode_apk(
    apk_path: str,
    force: bool = True,
    no_res: bool = False,
    no_src: bool = False,
    output_dir: Optional[str] = None,
    timeout: int = DEFAULT_TIMEOUT
) -> Dict:
    """
    Decode an APK file using APKTool with comprehensive validation and error handling.
    
    Args:
        apk_path: Path to the APK file to decode
        force: Force delete destination directory if it exists
        no_res: Do not decode resources
        no_src: Do not decode sources
        output_dir: Custom output directory (optional)
        timeout: Command timeout in seconds
        
    Returns:
        Dictionary with operation results including validation details
    """
    # Input validation
    path_validation = ValidationUtils.validate_path(apk_path, must_exist=True)
    if not path_validation["valid"]:
        return {"success": False, "error": path_validation["error"]}
    
    if not apk_path.lower().endswith(('.apk', '.xapk')):
        return {"success": False, "error": "File must have .apk or .xapk extension"}
    
    # Determine output directory
    if output_dir is None:
        apk_name = os.path.basename(apk_path).rsplit('.', 1)[0]
        output_dir = os.path.join(WORKSPACE_DIR, apk_name)
    
    # Build command
    command = ["apktool", "d", apk_path, "-o", output_dir]
    if force:
        command.append("-f")
    if no_res:
        command.append("-r")
    if no_src:
        command.append("-s")
    
    result = run_command(command, timeout=timeout)
    
    if result["success"]:
        # Additional validation - check if output directory was created
        if os.path.exists(output_dir):
            result["output_dir"] = output_dir
            result["workspace"] = WORKSPACE_DIR
            
            # Get basic project info
            manifest_path = os.path.join(output_dir, "AndroidManifest.xml")
            apktool_yml_path = os.path.join(output_dir, "apktool.yml")
            
            result["has_manifest"] = os.path.exists(manifest_path)
            result["has_apktool_yml"] = os.path.exists(apktool_yml_path)
        else:
            result["warning"] = "Decode reported success but output directory not found"
    
    return result

@mcp.tool()
async def build_apk(
    project_dir: str,
    output_apk: Optional[str] = None,
    debug: bool = True,
    force_all: bool = False,
    timeout: int = DEFAULT_TIMEOUT
) -> Dict:
    """
    Build an APK file from a decoded APKTool project with enhanced validation.
    
    Args:
        project_dir: Path to the APKTool project directory
        output_apk: Optional output APK path
        debug: Build with debugging info
        force_all: Force rebuild all files
        timeout: Command timeout in seconds
        
    Returns:
        Dictionary with operation results and build information
    """
    # Input validation
    path_validation = ValidationUtils.validate_path(project_dir, must_exist=True)
    if not path_validation["valid"]:
        return {"success": False, "error": path_validation["error"]}
    
    if not os.path.isdir(project_dir):
        return {"success": False, "error": f"Project path is not a directory: {project_dir}"}
    
    # Check for required files
    apktool_yml = os.path.join(project_dir, "apktool.yml")
    manifest_xml = os.path.join(project_dir, "AndroidManifest.xml")
    
    if not os.path.exists(apktool_yml):
        return {"success": False, "error": "apktool.yml not found. Is this a valid APKTool project?"}
    
    if not os.path.exists(manifest_xml):
        return {"success": False, "error": "AndroidManifest.xml not found. Is this a valid APKTool project?"}
    
    # Build command
    command = ["apktool", "b", project_dir]
    if debug:
        command.append("-d")
    if force_all:
        command.append("-f")
    if output_apk:
        command.extend(["-o", output_apk])
    
    result = run_command(command, timeout=timeout)
    
    if result["success"]:
        # Determine built APK path
        if not output_apk:
            output_apk = os.path.join(project_dir, "dist", os.path.basename(project_dir) + ".apk")
        
        if os.path.exists(output_apk):
            result["apk_path"] = output_apk
            result["apk_size"] = os.path.getsize(output_apk)
        else:
            result["warning"] = f"Build succeeded but APK not found at expected path: {output_apk}"
    
    return result

@mcp.tool()
async def get_manifest(project_dir: str) -> Dict:
    """
    Get the AndroidManifest.xml content from a decoded APK project with validation.
    
    Args:
        project_dir: Path to the APKTool project directory
        
    Returns:
        Dictionary with manifest content, metadata, and validation results
    """
    # Input validation
    path_validation = ValidationUtils.validate_path(project_dir, must_exist=True)
    if not path_validation["valid"]:
        return {"success": False, "error": path_validation["error"]}
    
    manifest_path = os.path.join(project_dir, "AndroidManifest.xml")
    if not os.path.exists(manifest_path):
        return {
            "success": False,
            "error": f"AndroidManifest.xml not found in {project_dir}",
            "expected_path": manifest_path
        }
    
    try:
        with open(manifest_path, 'r', encoding="utf-8") as f:
            content = f.read()
 
        result = {
            "success": True,
            "manifest": content,
            "path": manifest_path,
            "size": os.path.getsize(manifest_path),
            "encoding": "utf-8"
        }
        
        return result
        
    except Exception as e:
        logger.error(f"Error reading manifest: {str(e)}")
        return {
            "success": False,
            "error": f"Failed to read AndroidManifest.xml: {str(e)}",
            "path": manifest_path
        }

@mcp.tool()
async def get_apktool_yml(project_dir: str) -> Dict:
    """
    Get apktool.yml information from a decoded APK project with validation.
    
    Args:
        project_dir: Path to APKTool project directory
        
    Returns:
        Dictionary with apktool.yml content, metadata, and validation results
    """
    # Input validation
    path_validation = ValidationUtils.validate_path(project_dir, must_exist=True)
    if not path_validation["valid"]:
        return {"success": False, "error": path_validation["error"]}
    
    yml_path = os.path.join(project_dir, "apktool.yml")
    if not os.path.exists(yml_path):
        return {
            "success": False,
            "error": f"apktool.yml not found in {project_dir}",
            "expected_path": yml_path
        }
    
    try:
        with open(yml_path, 'r', encoding="utf-8") as f:
            content = f.read()
                    
        result = {
            "success": True,
            "content": content,
            "path": yml_path,
            "size": os.path.getsize(yml_path),
            "encoding": "utf-8"
        }
         
        return result
        
    except Exception as e:
        logger.error(f"Error reading apktool.yml: {str(e)}")
        return {
            "success": False,
            "error": f"Failed to read apktool.yml: {str(e)}",
            "path": yml_path
        }

@mcp.tool()
async def list_smali_directories(project_dir: str) -> Dict:
    """
    List all smali directories in a project with enhanced metadata.
    
    Args:
        project_dir: Path to the APKTool project directory
        
    Returns:
        Dictionary with list of smali directories and metadata
    """
    # Input validation
    path_validation = ValidationUtils.validate_path(project_dir, must_exist=True)
    if not path_validation["valid"]:
        return {"success": False, "error": path_validation["error"]}
    
    try:
        smali_dirs = []
        for d in os.listdir(project_dir):
            dir_path = os.path.join(project_dir, d)
            if d.startswith("smali") and os.path.isdir(dir_path):
                # Count files in smali directory
                file_count = 0
                try:
                    for root, _, files in os.walk(dir_path):
                        file_count += len([f for f in files if f.endswith('.smali')])
                except Exception as e:
                    logger.warning(f"Error counting files in {dir_path}: {e}")
                    file_count = 0
                
                smali_dirs.append({
                    "name": d,
                    "path": dir_path,
                    "smali_file_count": file_count
                })
        
        return {
            "success": True,
            "smali_dirs": smali_dirs,
            "count": len(smali_dirs)
        }
        
    except Exception as e:
        logger.error(f"Error listing smali directories: {str(e)}")
        return {
            "success": False,
            "error": f"Failed to list smali directories: {str(e)}"
        }

@mcp.tool()
async def list_smali_files(
    project_dir: str,
    smali_dir: str = "smali",
    package_prefix: Optional[str] = None,
    offset: int = 0,
    count: int = 0
) -> Dict:
    """
    List smali files with pagination support and enhanced filtering.
    
    Args:
        project_dir: Path to the APKTool project directory
        smali_dir: Which smali directory to use (smali, smali_classes2, etc.)
        package_prefix: Optional package prefix to filter by (e.g., "com.example")
        offset: Starting offset for pagination
        count: Number of items to return (0 means use default)
        
    Returns:
        Paginated dictionary with list of smali files and metadata
    """
    # Input validation
    path_validation = ValidationUtils.validate_path(project_dir, must_exist=True)
    if not path_validation["valid"]:
        return {"success": False, "error": path_validation["error"]}
    
    smali_path = os.path.join(project_dir, smali_dir)
    if not os.path.exists(smali_path):
        # Get available smali directories
        try:
            smali_dirs = [d for d in os.listdir(project_dir)
                         if d.startswith("smali") and os.path.isdir(os.path.join(project_dir, d))]
        except Exception:
            smali_dirs = []
        
        return {
            "success": False,
            "error": f"Smali directory not found: {smali_path}",
            "available_dirs": smali_dirs
        }
    
    try:
        smali_files = []
        search_root = smali_path
        
        # Handle package filtering
        if package_prefix:
            # Validate package name format
            if not package_prefix.replace('.', '').replace('_', '').replace('$', '').isalnum():
                return {"success": False, "error": "Invalid package prefix format"}
            
            package_path = os.path.join(smali_path, package_prefix.replace('.', os.path.sep))
            if not os.path.exists(package_path):
                return {
                    "success": False,
                    "error": f"Package not found: {package_prefix}",
                    "expected_path": package_path
                }
            search_root = package_path
        
        # Recursively find all .smali files
        for root, _, files in os.walk(search_root):
            for file in files:
                if file.endswith(".smali"):
                    file_path = os.path.join(root, file)
                    rel_path = os.path.relpath(file_path, smali_path)
                    class_name = rel_path.replace(os.path.sep, '.').replace('.smali', '')
                    
                    smali_files.append({
                        "class_name": class_name,
                        "file_path": file_path,
                        "rel_path": rel_path,
                        "size": os.path.getsize(file_path)
                    })
        
        # Sort by class name for consistent results
        smali_files.sort(key=lambda x: x["class_name"])
        
        # Apply pagination
        paginated_result = PaginationUtils.handle_pagination(
            items=smali_files,
            offset=offset,
            count=count,
            data_type="smali-files",
            items_key="smali_files"
        )
        
        # Add metadata
        paginated_result["success"] = True
        paginated_result["smali_dir"] = smali_dir
        paginated_result["package_prefix"] = package_prefix
        paginated_result["search_root"] = search_root
        
        return paginated_result
        
    except Exception as e:
        logger.error(f"Error listing smali files: {str(e)}")
        return {
            "success": False,
            "error": f"Failed to list smali files: {str(e)}"
        }

@mcp.tool()
async def get_smali_file(project_dir: str, class_name: str) -> Dict:
    """
    Get content of a specific smali file by class name with validation.
    
    Args:
        project_dir: Path to the APKTool project directory
        class_name: Full class name (e.g., com.example.MyClass)
        
    Returns:
        Dictionary with smali file content and metadata
    """
    # Input validation
    path_validation = ValidationUtils.validate_path(project_dir, must_exist=True)
    if not path_validation["valid"]:
        return {"success": False, "error": path_validation["error"]}
    
    class_validation = ValidationUtils.validate_class_name(class_name)
    if not class_validation["valid"]:
        return {"success": False, "error": class_validation["error"]}
    
    try:
        # Look for the class in all smali directories
        smali_dirs = [d for d in os.listdir(project_dir)
                     if d.startswith("smali") and os.path.isdir(os.path.join(project_dir, d))]
        
        for smali_dir in smali_dirs:
            file_path = os.path.join(
                project_dir,
                smali_dir,
                class_name.replace('.', os.path.sep) + '.smali'
            )
            
            if os.path.exists(file_path):
                with open(file_path, 'r', encoding="utf-8") as f:
                    content = f.read()
                
                return {
                    "success": True,
                    "content": content,
                    "file_path": file_path,
                    "smali_dir": smali_dir,
                    "size": os.path.getsize(file_path),
                    "class_name": class_name,
                    "encoding": "utf-8"
                }
        
        return {
            "success": False,
            "error": f"Smali file not found for class: {class_name}",
            "searched_dirs": smali_dirs
        }
        
    except Exception as e:
        logger.error(f"Error getting smali file: {str(e)}")
        return {
            "success": False,
            "error": f"Failed to get smali file: {str(e)}"
        }

@mcp.tool()
async def modify_smali_file(
    project_dir: str,
    class_name: str,
    new_content: str,
    create_backup: bool = True
) -> Dict:
    """
    Modify smali file content with validation and backup support.
    
    Args:
        project_dir: Path to the APKTool project directory
        class_name: Full class name (e.g., com.example.MyClass)
        new_content: New content for the smali file
        create_backup: Whether to create a backup of the original file
        
    Returns:
        Dictionary with operation results and metadata
    """
    # Input validation
    path_validation = ValidationUtils.validate_path(project_dir, must_exist=True)
    if not path_validation["valid"]:
        return {"success": False, "error": path_validation["error"]}
    
    class_validation = ValidationUtils.validate_class_name(class_name)
    if not class_validation["valid"]:
        return {"success": False, "error": class_validation["error"]}
     
    try:
        # Find the smali file
        smali_dirs = [d for d in os.listdir(project_dir)
                     if d.startswith("smali") and os.path.isdir(os.path.join(project_dir, d))]
        
        file_path = None
        for smali_dir in smali_dirs:
            test_path = os.path.join(
                project_dir,
                smali_dir,
                class_name.replace('.', os.path.sep) + '.smali'
            )
            
            if os.path.exists(test_path):
                file_path = test_path
                break
        
        if not file_path:
            return {
                "success": False,
                "error": f"Smali file not found for class: {class_name}",
                "searched_dirs": smali_dirs
            }
        
        # Get original content size
        original_size = os.path.getsize(file_path)
        
        # Create backup if requested
        backup_path = None
        if create_backup:
            backup_path = f"{file_path}.bak.{int(time.time())}"
            shutil.copy2(file_path, backup_path)
        
        # Write new content
        with open(file_path, 'w', encoding='utf-8') as f:
            f.write(new_content)
        
        return {
            "success": True,
            "message": f"Successfully modified {file_path}",
            "file_path": file_path,
            "backup_path": backup_path,
            "class_name": class_name,
            "original_size": original_size,
            "new_size": len(new_content),
            "backup_created": backup_path is not None
        }
        
    except Exception as e:
        logger.error(f"Error modifying smali file: {str(e)}")
        return {
            "success": False,
            "error": f"Failed to modify smali file: {str(e)}"
        }

@mcp.tool()
async def list_resources(
    project_dir: str,
    resource_type: Optional[str] = None,
    offset: int = 0,
    count: int = 0
) -> Dict:
    """
    List resources with pagination support and enhanced metadata.
    
    Args:
        project_dir: Path to the APKTool project directory
        resource_type: Optional resource type to filter by (e.g., "layout", "drawable")
        offset: Starting offset for pagination
        count: Number of items to return (0 means use default)
        
    Returns:
        Paginated dictionary with list of resources and metadata
    """
    # Input validation
    path_validation = ValidationUtils.validate_path(project_dir, must_exist=True)
    if not path_validation["valid"]:
        return {"success": False, "error": path_validation["error"]}
    
    res_path = os.path.join(project_dir, "res")
    if not os.path.exists(res_path):
        return {
            "success": False,
            "error": f"Resources directory not found: {res_path}"
        }
    
    try:
        if resource_type:
            # List resources of specific type
            type_path = os.path.join(res_path, resource_type)
            if not os.path.exists(type_path):
                # Get available resource types
                resource_types = [
                    d for d in os.listdir(res_path)
                    if os.path.isdir(os.path.join(res_path, d))
                ]
                
                return {
                    "success": False,
                    "error": f"Resource type directory not found: {resource_type}",
                    "available_types": resource_types
                }
            
            resources = []
            for item in os.listdir(type_path):
                item_path = os.path.join(type_path, item)
                if os.path.isfile(item_path):
                    resources.append({
                        "name": item,
                        "path": item_path,
                        "size": os.path.getsize(item_path),
                        "type": resource_type,
                        "extension": os.path.splitext(item)[1],
                        "modified_time": os.path.getmtime(item_path)
                    })
            
            # Sort by name
            resources.sort(key=lambda x: x["name"])
            
            # Apply pagination
            paginated_result = PaginationUtils.handle_pagination(
                items=resources,
                offset=offset,
                count=count,
                data_type="resources",
                items_key="resources"
            )
            
            paginated_result["success"] = True
            paginated_result["resource_type"] = resource_type
            paginated_result["resource_path"] = type_path
            
            return paginated_result
        
        else:
            # List all resource types with counts
            resource_types = []
            for item in os.listdir(res_path):
                type_path = os.path.join(res_path, item)
                if os.path.isdir(type_path):
                    try:
                        files = [f for f in os.listdir(type_path) if os.path.isfile(os.path.join(type_path, f))]
                        resource_count = len(files)
                        
                        # Calculate total size
                        total_size = 0
                        for f in files:
                            try:
                                total_size += os.path.getsize(os.path.join(type_path, f))
                            except:
                                pass
                        
                        resource_types.append({
                            "type": item,
                            "path": type_path,
                            "count": resource_count,
                            "total_size": total_size
                        })
                    except Exception as e:
                        logger.warning(f"Error processing resource type {item}: {e}")
                        resource_types.append({
                            "type": item,
                            "path": type_path,
                            "count": 0,
                            "total_size": 0,
                            "error": str(e)
                        })
            
            # Sort by type name
            resource_types.sort(key=lambda x: x["type"])
            
            # Apply pagination
            paginated_result = PaginationUtils.handle_pagination(
                items=resource_types,
                offset=offset,
                count=count,
                data_type="resource-types",
                items_key="resource_types"
            )
            
            paginated_result["success"] = True
            
            return paginated_result
        
    except Exception as e:
        logger.error(f"Error listing resources: {str(e)}")
        return {
            "success": False,
            "error": f"Failed to list resources: {str(e)}"
        }

@mcp.tool()
async def get_resource_file(project_dir: str, resource_type: str, resource_name: str) -> Dict:
    """
    Get content of a specific resource file with validation and metadata.
    
    Args:
        project_dir: Path to the APKTool project directory
        resource_type: Resource type (e.g., "layout", "drawable")
        resource_name: Name of the resource file
        
    Returns:
        Dictionary with resource file content and metadata
    """
    # Input validation
    path_validation = ValidationUtils.validate_path(project_dir, must_exist=True)
    if not path_validation["valid"]:
        return {"success": False, "error": path_validation["error"]}
    
    if not resource_type or not resource_name:
        return {"success": False, "error": "Resource type and name are required"}
    
    resource_path = os.path.join(project_dir, "res", resource_type, resource_name)
    if not os.path.exists(resource_path):
        return {
            "success": False,
            "error": f"Resource file not found: {resource_path}",
            "expected_path": resource_path
        }
    
    try:
        file_size = os.path.getsize(resource_path)
        is_text_file = True
        
        # Try to read as text first
        try:
            with open(resource_path, 'r', encoding="utf-8") as f:
                content = f.read()
            encoding = "utf-8"
        except UnicodeDecodeError:
            is_text_file = False
            content = None
            encoding = None
        
        
        if is_text_file and content is not None:    
            result = {
                "success": True,
                "content": content,
                "path": resource_path,
                "size": file_size,
                "resource_type": resource_type,
                "resource_name": resource_name,
                "encoding": encoding
            }
            
            return result
        else:
            # Binary file
            return {
                "success": False,
                "error": "This appears to be a binary resource file and cannot be read as text",
                "path": resource_path,
                "size": file_size,
                "resource_type": resource_type,
                "resource_name": resource_name,
                "is_binary": True,
                "is_text": False
            }
        
    except Exception as e:
        logger.error(f"Error getting resource file: {str(e)}")
        return {
            "success": False,
            "error": f"Failed to get resource file: {str(e)}"
        }

@mcp.tool()
async def modify_resource_file(
    project_dir: str,
    resource_type: str,
    resource_name: str,
    new_content: str,
    create_backup: bool = True
) -> Dict:
    """
    Modify the content of a specific resource file with validation and backup support.
    
    Args:
        project_dir: Path to the APKTool project directory
        resource_type: Resource type (e.g., "layout", "values")
        resource_name: Name of the resource file
        new_content: New content for the resource file
        create_backup: Whether to create a backup of the original file
        
    Returns:
        Dictionary with operation results and metadata
    """
    # Input validation
    path_validation = ValidationUtils.validate_path(project_dir, must_exist=True)
    if not path_validation["valid"]:
        return {"success": False, "error": path_validation["error"]}
    
    if not resource_type or not resource_name:
        return {"success": False, "error": "Resource type and name are required"}
    
    resource_path = os.path.join(project_dir, "res", resource_type, resource_name)
    if not os.path.exists(resource_path):
        return {
            "success": False,
            "error": f"Resource file not found: {resource_path}",
            "expected_path": resource_path
        }
    
    try:
        # Get original file info
        original_size = os.path.getsize(resource_path)
        
        # Create backup if requested
        backup_path = None
        if create_backup:
            backup_path = f"{resource_path}.bak.{int(time.time())}"
            shutil.copy2(resource_path, backup_path)
        
        # Write new content
        with open(resource_path, 'w', encoding="utf-8") as f:
            f.write(new_content)
        
        result = {
            "success": True,
            "message": f"Successfully modified {resource_path}",
            "path": resource_path,
            "backup_path": backup_path,
            "resource_type": resource_type,
            "resource_name": resource_name,
            "original_size": original_size,
            "new_size": len(new_content),
            "backup_created": backup_path is not None
        }
         
        return result
        
    except Exception as e:
        logger.error(f"Error modifying resource file: {str(e)}")
        return {
            "success": False,
            "error": f"Failed to modify resource file: {str(e)}"
        }

@mcp.tool()
async def search_in_files(
    project_dir: str,
    search_pattern: str,
    file_extensions: List[str] = [".smali", ".xml"],
    max_results: int = 100,
    offset: int = 0,
    count: int = 0,
    case_sensitive: bool = False
) -> Dict:
    """
    Search for patterns in files with pagination and enhanced filtering.
    
    Args:
        project_dir: Path to the APKTool project directory
        search_pattern: Text pattern to search for
        file_extensions: List of file extensions to search in
        max_results: Maximum total results to collect before pagination
        offset: Starting offset for pagination
        count: Number of items to return (0 means use default)
        case_sensitive: Whether search should be case sensitive
        
    Returns:
        Paginated dictionary with search results and metadata
    """
    # Input validation
    path_validation = ValidationUtils.validate_path(project_dir, must_exist=True)
    if not path_validation["valid"]:
        return {"success": False, "error": path_validation["error"]}
    
    pattern_validation = ValidationUtils.validate_search_pattern(search_pattern)
    if not pattern_validation["valid"]:
        return {"success": False, "error": pattern_validation["error"]}
    
    if not file_extensions or not isinstance(file_extensions, list):
        return {"success": False, "error": "File extensions must be a non-empty list"}
    
    try:
        results = []
        search_stats = {
            "files_searched": 0,
            "files_matched": 0,
            "total_matches": 0,
            "search_truncated": False,
            "directories_searched": 0,
            "start_time": time.time()
        }
        
        # Prepare search pattern
        pattern = search_pattern if case_sensitive else search_pattern.lower()
        
        # Walk through project directory
        for root, dirs, files in os.walk(project_dir):
            search_stats["directories_searched"] += 1
            
            for file in files:
                if len(results) >= max_results:
                    search_stats["search_truncated"] = True
                    break
                
                if any(file.endswith(ext) for ext in file_extensions):
                    file_path = os.path.join(root, file)
                    search_stats["files_searched"] += 1
                    
                    try:
                        with open(file_path, 'r', encoding="utf-8") as f:
                            content = f.read()
                        
                        # Perform search
                        search_content = content if case_sensitive else content.lower()
                        if pattern in search_content:
                            search_stats["files_matched"] += 1
                            
                            # Count matches in this file and find line numbers
                            matches_in_file = search_content.count(pattern)
                            search_stats["total_matches"] += matches_in_file
                            
                            # Find line numbers of matches
                            lines = content.splitlines()
                            line_matches = []
                            for i, line in enumerate(lines, 1):
                                search_line = line if case_sensitive else line.lower()
                                if pattern in search_line:
                                    line_matches.append({
                                        "line_number": i,
                                        "line_content": line.strip()[:200],  # Truncate long lines
                                        "matches_in_line": search_line.count(pattern)
                                    })
                            
                            rel_path = os.path.relpath(file_path, project_dir)
                            results.append({
                                "file": rel_path,
                                "path": file_path,
                                "size": os.path.getsize(file_path),
                                "matches": matches_in_file,
                                "extension": os.path.splitext(file)[1],
                                "line_matches": line_matches[:10],  # Limit to first 10 line matches
                                "total_line_matches": len(line_matches)
                            })
                    
                    except UnicodeDecodeError:
                        # Skip binary files
                        continue
                    except Exception as e:
                        logger.warning(f"Error reading file {file_path}: {str(e)}")
                        continue
            
            if search_stats["search_truncated"]:
                break
        
        search_stats["end_time"] = time.time()
        search_stats["duration"] = search_stats["end_time"] - search_stats["start_time"]
        
        # Sort by number of matches (descending) then by file name
        results.sort(key=lambda x: (-x["matches"], x["file"]))
        
        # Apply pagination
        paginated_result = PaginationUtils.handle_pagination(
            items=results,
            offset=offset,
            count=count,
            data_type="search-results",
            items_key="results"
        )
        
        # Add search metadata
        paginated_result["success"] = True
        paginated_result["search_pattern"] = search_pattern
        paginated_result["case_sensitive"] = case_sensitive
        paginated_result["file_extensions"] = file_extensions
        paginated_result["search_stats"] = search_stats
        
        return paginated_result
        
    except Exception as e:
        logger.error(f"Error searching in files: {str(e)}")
        return {
            "success": False,
            "error": f"Failed to search in files: {str(e)}"
        }

@mcp.tool()
async def clean_project(project_dir: str, backup: bool = True) -> Dict:
    """
    Clean a project directory to prepare for rebuilding with enhanced backup support.
    
    Args:
        project_dir: Path to the APKTool project directory
        backup: Whether to create a backup of build directories before cleaning
        
    Returns:
        Dictionary with operation results and cleanup details
    """
    # Input validation
    path_validation = ValidationUtils.validate_path(project_dir, must_exist=True)
    if not path_validation["valid"]:
        return {"success": False, "error": path_validation["error"]}
    
    try:
        dirs_to_clean = ["build", "dist", "temp"]
        files_to_clean = ["*.tmp", "*.log"]
        cleaned_dirs = []
        cleaned_files = []
        backed_up = []
        
        # Clean directories
        for dir_name in dirs_to_clean:
            dir_path = os.path.join(project_dir, dir_name)
            if os.path.exists(dir_path):
                if backup:
                    # Create backup
                    backup_path = f"{dir_path}_backup_{int(time.time())}"
                    shutil.copytree(dir_path, backup_path)
                    backed_up.append({
                        "original": dir_path,
                        "backup": backup_path,
                        "type": "directory"
                    })
                
                # Calculate size before removal
                dir_size = 0
                file_count = 0
                for root, dirs, files in os.walk(dir_path):
                    for file in files:
                        file_path = os.path.join(root, file)
                        try:
                            dir_size += os.path.getsize(file_path)
                            file_count += 1
                        except:
                            pass
                
                # Remove directory
                shutil.rmtree(dir_path)
                cleaned_dirs.append({
                    "path": dir_path,
                    "size_freed": dir_size,
                    "files_removed": file_count
                })
        
        # Clean specific files
        import glob
        for pattern in files_to_clean:
            pattern_path = os.path.join(project_dir, pattern)
            for file_path in glob.glob(pattern_path):
                if os.path.isfile(file_path):
                    file_size = os.path.getsize(file_path)
                    
                    if backup:
                        backup_path = f"{file_path}.bak.{int(time.time())}"
                        shutil.copy2(file_path, backup_path)
                        backed_up.append({
                            "original": file_path,
                            "backup": backup_path,
                            "type": "file"
                        })
                    
                    os.remove(file_path)
                    cleaned_files.append({
                        "path": file_path,
                        "size": file_size
                    })
        
        total_size_freed = sum(d["size_freed"] for d in cleaned_dirs) + sum(f["size"] for f in cleaned_files)
        total_files_removed = sum(d["files_removed"] for d in cleaned_dirs) + len(cleaned_files)
        
        return {
            "success": True,
            "cleaned_directories": cleaned_dirs,
            "cleaned_files": cleaned_files,
            "backed_up_items": backed_up,
            "total_size_freed": total_size_freed,
            "total_files_removed": total_files_removed,
            "backup_created": len(backed_up) > 0
        }
        
    except Exception as e:
        logger.error(f"Error cleaning project: {str(e)}")
        return {
            "success": False,
            "error": f"Failed to clean project: {str(e)}"
        }

@mcp.tool()
async def analyze_project_structure(project_dir: str) -> Dict:
    """
    Analyze the structure of a decoded APK project and provide comprehensive metadata.
    
    Args:
        project_dir: Path to the APKTool project directory
        
    Returns:
        Dictionary with detailed project analysis
    """
    # Input validation
    path_validation = ValidationUtils.validate_path(project_dir, must_exist=True)
    if not path_validation["valid"]:
        return {"success": False, "error": path_validation["error"]}
    
    try:
        analysis = {
            "project_path": project_dir,
            "analysis_time": time.time(),
            "is_valid_project": False,
            "project_size": 0,
            "file_counts": {},
            "directory_structure": {},
            "smali_analysis": {},
            "resource_analysis": {},
            "manifest_analysis": {},
            "errors": []
        }
        
        # Check if it's a valid APKTool project
        required_files = ["AndroidManifest.xml", "apktool.yml"]
        missing_files = []
        
        for file in required_files:
            if not os.path.exists(os.path.join(project_dir, file)):
                missing_files.append(file)
        
        analysis["is_valid_project"] = len(missing_files) == 0
        if missing_files:
            analysis["errors"].append(f"Missing required files: {', '.join(missing_files)}")
        
        # Calculate total project size and file counts
        total_size = 0
        file_counts = {}
        
        for root, dirs, files in os.walk(project_dir):
            for file in files:
                file_path = os.path.join(root, file)
                try:
                    size = os.path.getsize(file_path)
                    total_size += size
                    
                    ext = os.path.splitext(file)[1].lower()
                    if not ext:
                        ext = "(no extension)"
                    
                    if ext not in file_counts:
                        file_counts[ext] = {"count": 0, "size": 0}
                    
                    file_counts[ext]["count"] += 1
                    file_counts[ext]["size"] += size
                    
                except Exception as e:
                    analysis["errors"].append(f"Error processing file {file_path}: {str(e)}")
        
        analysis["project_size"] = total_size
        analysis["file_counts"] = file_counts
        
        # Directory structure analysis
        directories = {}
        for item in os.listdir(project_dir):
            item_path = os.path.join(project_dir, item)
            if os.path.isdir(item_path):
                try:
                    # Count files in directory
                    file_count = 0
                    dir_size = 0
                    
                    for root, _, files in os.walk(item_path):
                        file_count += len(files)
                        for file in files:
                            try:
                                dir_size += os.path.getsize(os.path.join(root, file))
                            except:
                                pass
                    
                    directories[item] = {
                        "path": item_path,
                        "file_count": file_count,
                        "size": dir_size
                    }
                except Exception as e:
                    analysis["errors"].append(f"Error analyzing directory {item}: {str(e)}")
        
        analysis["directory_structure"] = directories
        
        # Smali analysis
        smali_dirs = [d for d in directories.keys() if d.startswith("smali")]
        smali_analysis = {
            "smali_directories": smali_dirs,
            "total_smali_files": 0,
            "package_distribution": {}
        }
        
        for smali_dir in smali_dirs:
            smali_path = os.path.join(project_dir, smali_dir)
            for root, _, files in os.walk(smali_path):
                smali_files = [f for f in files if f.endswith('.smali')]
                smali_analysis["total_smali_files"] += len(smali_files)
                
                # Analyze package distribution
                for file in smali_files:
                    rel_path = os.path.relpath(root, smali_path)
                    if rel_path != ".":
                        package = rel_path.replace(os.path.sep, ".")
                        top_level_package = package.split(".")[0] if "." in package else package
                        
                        if top_level_package not in smali_analysis["package_distribution"]:
                            smali_analysis["package_distribution"][top_level_package] = 0
                        smali_analysis["package_distribution"][top_level_package] += 1
        
        analysis["smali_analysis"] = smali_analysis
        
        # Resource analysis
        res_path = os.path.join(project_dir, "res")
        resource_analysis = {
            "has_resources": os.path.exists(res_path),
            "resource_types": {},
            "total_resource_files": 0
        }
        
        if os.path.exists(res_path):
            try:
                for item in os.listdir(res_path):
                    type_path = os.path.join(res_path, item)
                    if os.path.isdir(type_path):
                        files = [f for f in os.listdir(type_path) if os.path.isfile(os.path.join(type_path, f))]
                        total_size = sum(os.path.getsize(os.path.join(type_path, f)) for f in files)
                        
                        resource_analysis["resource_types"][item] = {
                            "file_count": len(files),
                            "total_size": total_size
                        }
                        resource_analysis["total_resource_files"] += len(files)
            except Exception as e:
                analysis["errors"].append(f"Error analyzing resources: {str(e)}")
        
        analysis["resource_analysis"] = resource_analysis
        
        # Manifest analysis
        manifest_path = os.path.join(project_dir, "AndroidManifest.xml")
        manifest_analysis = {
            "exists": os.path.exists(manifest_path),
            "size": 0,
            "package_name": None,
            "activities": [],
            "permissions": [],
            "services": []
        }
        
        if os.path.exists(manifest_path):
            try:
                manifest_analysis["size"] = os.path.getsize(manifest_path)
                
                with open(manifest_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                try:
                    root = ET.fromstring(content)
                    
                    # Extract package name
                    manifest_analysis["package_name"] = root.get("package")
                    
                    # Extract activities
                    for activity in root.findall(".//activity"):
                        name = activity.get("{http://schemas.android.com/apk/res/android}name")
                        if name:
                            manifest_analysis["activities"].append(name)
                    
                    # Extract permissions
                    for perm in root.findall(".//uses-permission"):
                        name = perm.get("{http://schemas.android.com/apk/res/android}name")
                        if name:
                            manifest_analysis["permissions"].append(name)
                    
                    # Extract services
                    for service in root.findall(".//service"):
                        name = service.get("{http://schemas.android.com/apk/res/android}name")
                        if name:
                            manifest_analysis["services"].append(name)
                            
                except ET.ParseError as e:
                    analysis["errors"].append(f"Manifest XML parsing error: {str(e)}")
                    
            except Exception as e:
                analysis["errors"].append(f"Error analyzing manifest: {str(e)}")
        
        analysis["manifest_analysis"] = manifest_analysis
        
        return {
            "success": True,
            "analysis": analysis
        }
        
    except Exception as e:
        logger.error(f"Error analyzing project structure: {str(e)}")
        return {
            "success": False,
            "error": f"Failed to analyze project structure: {str(e)}"
        }

@mcp.tool()
async def get_workspace_info() -> Dict:
    """
    Get information about the APKTool MCP server workspace and current projects.
    
    Returns:
        Dictionary with workspace information and project list
    """
    try:
        workspace_info = {
            "workspace_path": WORKSPACE_DIR,
            "workspace_exists": os.path.exists(WORKSPACE_DIR),
            "projects": [],
            "total_projects": 0,
            "total_workspace_size": 0,
            "free_space": 0
        }
        
        if not os.path.exists(WORKSPACE_DIR):
            return {
                "success": False,
                "error": f"Workspace directory does not exist: {WORKSPACE_DIR}",
                "workspace_info": workspace_info
            }
        
        # Get disk usage information
        try:
            import shutil
            total, used, free = shutil.disk_usage(WORKSPACE_DIR)
            workspace_info["free_space"] = free
            workspace_info["total_disk_space"] = total
            workspace_info["used_disk_space"] = used
        except Exception as e:
            logger.warning(f"Could not get disk usage info: {e}")
        
        # Scan for projects
        projects = []
        total_size = 0
        
        for item in os.listdir(WORKSPACE_DIR):
            item_path = os.path.join(WORKSPACE_DIR, item)
            if os.path.isdir(item_path):
                # Check if it looks like an APKTool project
                has_manifest = os.path.exists(os.path.join(item_path, "AndroidManifest.xml"))
                has_apktool_yml = os.path.exists(os.path.join(item_path, "apktool.yml"))
                
                is_apktool_project = has_manifest and has_apktool_yml
                
                # Calculate project size
                project_size = 0
                file_count = 0
                
                try:
                    for root, _, files in os.walk(item_path):
                        for file in files:
                            file_path = os.path.join(root, file)
                            try:
                                project_size += os.path.getsize(file_path)
                                file_count += 1
                            except:
                                pass
                except Exception as e:
                    logger.warning(f"Error calculating size for {item_path}: {e}")
                
                total_size += project_size
                
                project_info = {
                    "name": item,
                    "path": item_path,
                    "is_apktool_project": is_apktool_project,
                    "has_manifest": has_manifest,
                    "has_apktool_yml": has_apktool_yml,
                    "size": project_size,
                    "file_count": file_count,
                    "modified_time": os.path.getmtime(item_path)
                }
                
                # Get additional info if it's a valid project
                if is_apktool_project:
                    try:
                        # Read package name from manifest
                        manifest_path = os.path.join(item_path, "AndroidManifest.xml")
                        with open(manifest_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        root = ET.fromstring(content)
                        project_info["package_name"] = root.get("package")
                        
                        # Count smali directories
                        smali_dirs = [d for d in os.listdir(item_path) 
                                     if d.startswith("smali") and os.path.isdir(os.path.join(item_path, d))]
                        project_info["smali_directories"] = len(smali_dirs)
                        
                    except Exception as e:
                        logger.warning(f"Error getting additional info for {item}: {e}")
                
                projects.append(project_info)
        
        # Sort projects by modification time (newest first)
        projects.sort(key=lambda x: x["modified_time"], reverse=True)
        
        workspace_info["projects"] = projects
        workspace_info["total_projects"] = len(projects)
        workspace_info["total_workspace_size"] = total_size
        workspace_info["apktool_projects"] = len([p for p in projects if p["is_apktool_project"]])
        
        return {
            "success": True,
            "workspace_info": workspace_info
        }
        
    except Exception as e:
        logger.error(f"Error getting workspace info: {str(e)}")
        return {
            "success": False,
            "error": f"Failed to get workspace info: {str(e)}"
        }

def main():
    print("=" * 80)
    print("APKTool MCP Server")
    print("By ZinjaCoder (https://github.com/zinja-coder)")
    print("To Report Issues: https://github.com/zinja-coder/apktool-mcp-server/issues")
    print("=" * 80)
    print()
    
    # Display configuration
    print("Configuration:")
    print(f"  Workspace Directory: {WORKSPACE_DIR}")
    print(f"  Default Timeout: {DEFAULT_TIMEOUT}s")
    print(f"  HTTP Mode: {'Enabled' if args.http else 'Disabled'}")
    if args.http:
        print(f"  HTTP Port: {args.port}")
    print()
    
    # Perform initial health check
    print("Performing initial health check...")
    try:
        import asyncio
        health_result = asyncio.run(health_check())
        
        if health_result.get("server_status") == "running":
            print("Server Status: Running")
        else:
            print("Server Status: Error")
        
        if health_result.get("apktool_available"):
            print(f"APKTool Available: {health_result.get('apktool_version', 'Version unknown')}")
        else:
            print("APKTool Not Available")
            print(f"Error: {health_result.get('apktool_error', 'Unknown error')}")
        
        if health_result.get("workspace_exists"):
            print(f"Workspace Directory: {WORKSPACE_DIR}")
        else:
            print(f"Workspace Directory: {WORKSPACE_DIR} (will be created)")
            os.makedirs(WORKSPACE_DIR, exist_ok=True)
        
        # Get workspace info
        workspace_result = asyncio.run(get_workspace_info())
        if workspace_result.get("success"):
            info = workspace_result["workspace_info"]
            print(f"Workspace Projects: {info.get('total_projects', 0)} total")
            print(f"APKTool Projects: {info.get('apktool_projects', 0)}")
            
            if info.get("free_space"):
                free_gb = info["free_space"] / (1024**3)
                print(f"  Free Space: {free_gb:.1f} GB")
        
    except Exception as e:
        print(f"Health check failed: {e}")
    
    print()
    print("Available MCP Tools:")
    tools = [
        "health_check", "decode_apk", "build_apk", "get_manifest", 
        "get_apktool_yml", "list_smali_directories", "list_smali_files", 
        "get_smali_file", "modify_smali_file", "list_resources", 
        "get_resource_file", "modify_resource_file", "search_in_files", 
        "clean_project", "analyze_project_structure", "get_workspace_info"
    ]
    
    for i, tool in enumerate(tools, 1):
        print(f"  {i:2d}. {tool}")
    
    print()
    print("Starting MCP server...")
    
    if args.http:
        print(f"Server will be available at: http://127.0.0.1:{args.port}")
        mcp.run(transport="streamable-http", port=args.port)
    else:
        print("Server running in stdio mode")
        mcp.run()

if __name__ == "__main__":
    main()

```

`pyproject.toml`:

```toml
[project]
name = "apktool-mcp-server"
version = "0.1.0"
description = "Add your description here"
readme = "README.md"
requires-python = ">=3.13"
dependencies = [
    "fastmcp>=2.2.0",
    "logging>=0.4.9.6",
]

```

`requirements.txt`:

```txt
fastmcp
logging

```

`test.sh`:

```sh
#!/usr/bin/env bash

###
# This is the test script to test the working of APKTool MCP Server.
# 
# Prerequisites:
# 1. Ensure APKTool is installed and available in PATH
# 2. Have DVAC_FINAL.apk file in the current directory
# 3. Start the APKTool MCP server in HTTP stream mode on port 8652
# 4. Command for step 3: `python apktool_mcp_server.py --http --port 8652`
#
# Usage: ./test_apktool.sh
###

set -euo pipefail

MCP_URL="${MCP_URL:-http://127.0.0.1:8652/mcp/}"
ACCEPT_HDR="application/json, text/event-stream"
CONTENT_HDR="application/json"
APK_PATH="DVAC_FINAL.apk"

# Helper: extract data: JSON items from SSE and drop [DONE]
sse_to_json() {
    grep '^data: ' | sed 's/^data: //' | grep -v '^\[DONE\]$'
}

# 1) Initialize, capture session id header
echo "== Initialize MCP Session =="
INIT_RESP_HEADERS=$(mktemp)
curl -i -s -X POST "$MCP_URL" \
    -H "Content-Type: $CONTENT_HDR" \
    -H "Accept: $ACCEPT_HDR" \
    -d '{
        "jsonrpc":"2.0",
        "method":"initialize",
        "params":{
            "protocolVersion":"2024-11-05",
            "capabilities":{},
            "clientInfo":{"name":"apktool-test-automation","version":"1.0.0"}
        },
        "id":1
    }' | tee "$INIT_RESP_HEADERS" >/dev/null

SESSION_ID=$(awk -F': ' 'BEGIN{IGNORECASE=1} /^mcp-session-id:/ {print $2}' "$INIT_RESP_HEADERS" | tr -d '\r')
if [[ -z "${SESSION_ID:-}" ]]; then
    echo "Failed to obtain MCP-Session-Id header" >&2
    exit 1
fi
echo "Session: $SESSION_ID"

# 2) Send notifications/initialized (no output expected)
curl -s -X POST "$MCP_URL" \
    -H "Content-Type: $CONTENT_HDR" \
    -H "Accept: $ACCEPT_HDR" \
    -H "Mcp-Session-Id: $SESSION_ID" \
    -d '{"jsonrpc":"2.0","method":"notifications/initialized","params":{}}' >/dev/null

# 3) Discover available tools
echo "== Available Tools =="
TOOLS_JSON=$(curl -s -X POST "$MCP_URL" \
    -H "Content-Type: $CONTENT_HDR" \
    -H "Accept: $ACCEPT_HDR" \
    -H "Mcp-Session-Id: $SESSION_ID" \
    -d '{"jsonrpc":"2.0","method":"tools/list","params":{},"id":2}' \
    | sse_to_json | tail -n 1)

echo "$TOOLS_JSON" | jq -r '.result.tools[].name'

# Helper: call a tool with JSON arguments
call_tool() {
    local name="$1"
    local args_json="$2" # must be a valid JSON object string
    local id="${3:-1000}"
    
    curl -s -X POST "$MCP_URL" \
        -H "Content-Type: $CONTENT_HDR" \
        -H "Accept: $ACCEPT_HDR" \
        -H "Mcp-Session-Id: $SESSION_ID" \
        -d "{
            \"jsonrpc\":\"2.0\",
            \"method\":\"tools/call\",
            \"params\":{
                \"name\":\"$name\",
                \"arguments\":$args_json
            },
            \"id\":$id
        }" \
        | sse_to_json
}

echo "== Running APKTool MCP Server Tests =="

# 4) Health check
echo "--- health_check ---"
call_tool "health_check" '{}' 10 | jq -r '.result.content[0].text // .result // .error?.message // .'

# 5) Get workspace info
echo "--- get_workspace_info ---"
call_tool "get_workspace_info" '{}' 11 | jq -r '.result.content[0].text // .result // .error?.message // .' | jq -r '.workspace_info.projects[]? | {name, is_apktool_project, package_name} // .'

# Check if APK file exists, if not skip decode test
if [[ -f "$APK_PATH" ]]; then
    echo "--- decode_apk ---"
    APK_FULL_PATH=$(realpath "$APK_PATH" 2>/dev/null || echo "$APK_PATH")
    call_tool "decode_apk" "{\"apk_path\":\"$APK_FULL_PATH\",\"force\":true}" 12 | jq -r '.result.content[0].text // .result // .error?.message // .'
    
    # Wait a moment for decode to complete
    sleep 2
    PROJECT_DIR="apktool_mcp_server_workspace/DVAC_FINAL"
else
    echo "--- decode_apk (skipped - APK not found) ---"
    echo "APK file $APK_PATH not found, using existing project"
    # Use existing project from workspace info - check what's available
    PROJECT_DIR="apktool_mcp_server_workspace/DVAC-FINAL"  # Note the hyphen based on workspace info
fi

# 7) Get decoded project directory (use existing project if decode skipped)
echo "Using project directory: $PROJECT_DIR"

# 8) Get manifest content
echo "--- get_manifest ---"
call_tool "get_manifest" "{\"project_dir\":\"$PROJECT_DIR\"}" 13 | jq -r '.result.content[0].text // .result // .error?.message // .' | jq -r '.manifest[0:300] // .error // .'

# 9) Get apktool.yml
echo "--- get_apktool_yml ---"
call_tool "get_apktool_yml" "{\"project_dir\":\"$PROJECT_DIR\"}" 14 | jq -r '.result.content[0].text // .result // .error?.message // .' | jq -r '.content[0:200] // .error // .'

# 10) List smali directories
echo "--- list_smali_directories ---"
call_tool "list_smali_directories" "{\"project_dir\":\"$PROJECT_DIR\"}" 15 | jq -r '.result.content[0].text // .result // .error?.message // .' | jq -r '.smali_dirs[]?.name // .error // .'

# 11) List smali files with pagination
echo "--- list_smali_files (offset=0,count=20) ---"
call_tool "list_smali_files" "{\"project_dir\":\"$PROJECT_DIR\",\"smali_dir\":\"smali\",\"offset\":0,\"count\":20}" 16 | jq -r '.result.content[0].text // .result // .error?.message // .' | jq -r '.smali_files[]?.class_name // .error // .' | head -5

# 12) List smali files with package filter
echo "--- list_smali_files (package filter: com.zin) ---"
call_tool "list_smali_files" "{\"project_dir\":\"$PROJECT_DIR\",\"package_prefix\":\"com.zin\"}" 17 | jq -r '.result.content[0].text // .result // .error?.message // .' | jq -r '.smali_files[]?.class_name // .error // .' | head -5

# 13) Get specific smali file
echo "--- get_smali_file ---"
call_tool "get_smali_file" "{\"project_dir\":\"$PROJECT_DIR\",\"class_name\":\"com.zin.dvac.MainActivity\"}" 18 | jq -r '.result.content[0].text // .result // .error?.message // .' | jq -r '.content[0:300] // .error // .'

# 14) List all resource types
echo "--- list_resources (all types) ---"
call_tool "list_resources" "{\"project_dir\":\"$PROJECT_DIR\"}" 19 | jq -r '.result.content[0].text // .result // .error?.message // .' | jq -r '.resource_types[]?.type // .error // .'

# 15) List specific resource type with pagination
echo "--- list_resources (layout, offset=0,count=10) ---"
call_tool "list_resources" "{\"project_dir\":\"$PROJECT_DIR\",\"resource_type\":\"layout\",\"offset\":0,\"count\":10}" 20 | jq -r '.result.content[0].text // .result // .error?.message // .' | jq -r '.resources[]?.name // .error // .' | head -5

# 16) Get specific resource file
echo "--- get_resource_file ---"
call_tool "get_resource_file" "{\"project_dir\":\"$PROJECT_DIR\",\"resource_type\":\"layout\",\"resource_name\":\"activity_main.xml\"}" 21 | jq -r '.result.content[0].text // .result // .error?.message // .' | jq -r '.content[0:200] // .error // .'

# 17) Search in files
echo "--- search_in_files (search for 'onCreate') ---"
call_tool "search_in_files" "{\"project_dir\":\"$PROJECT_DIR\",\"search_pattern\":\"onCreate\",\"file_extensions\":[\".smali\"],\"max_results\":10}" 22 | jq -r '.result.content[0].text // .result // .error?.message // .' | jq -r '.results[]?.file // .error // .' | head -5

# 18) Search with pagination (fix the jq syntax error)
echo "--- search_in_files (with pagination, search for 'Activity') ---"
call_tool "search_in_files" "{\"project_dir\":\"$PROJECT_DIR\",\"search_pattern\":\"Activity\",\"offset\":0,\"count\":5,\"case_sensitive\":false}" 23 | jq -r '.result.content[0].text // .result // .error?.message // .' | jq -r '.results[]? | "\(.file) (\(.matches) matches)" // .error // .' | head -5

# 19) Analyze project structure
echo "--- analyze_project_structure ---"
call_tool "analyze_project_structure" "{\"project_dir\":\"$PROJECT_DIR\"}" 24 | jq -r '.result.content[0].text // .result // .error?.message // .' | jq -r '.analysis | {is_valid_project, project_size, total_smali_files: .smali_analysis.total_smali_files, total_resource_files: .resource_analysis.total_resource_files} // .error // .'

# 20) Clean project (with backup)
echo "--- clean_project ---"
call_tool "clean_project" "{\"project_dir\":\"$PROJECT_DIR\",\"backup\":true}" 25 | jq -r '.result.content[0].text // .result // .error?.message // .' | jq -r '.cleaned_directories[]?.path // .error // "No directories to clean"'

# 21) Build APK
echo "--- build_apk ---"
call_tool "build_apk" "{\"project_dir\":\"$PROJECT_DIR\",\"debug\":true}" 26 | jq -r '.result.content[0].text // .result // .error?.message // .' | jq -r '.apk_path // .error // .'

# 22) Example of modifying a smali file (commented out for safety)
echo "--- modify_smali_file (example - commented out for safety) ---"
# Uncomment the line below to test file modification
call_tool "modify_smali_file" '{"project_dir":"'$PROJECT_DIR'","class_name":"com.zin.dvac.MainActivity","new_content":"# Modified smali content\n.class public Lcom/zin/dvac/MainActivity;\n.super Landroid/app/Activity;","create_backup":true}' 27 | jq -r '.result.content[0].text // .result // .error?.message // .'
echo "Skipped - modify_smali_file (enable manually if needed)"

# 23) Example of modifying a resource file (commented out for safety)
echo "--- modify_resource_file (example - commented out for safety) ---"
# Uncomment the line below to test resource modification
call_tool "modify_resource_file" '{"project_dir":"'$PROJECT_DIR'","resource_type":"values","resource_name":"strings.xml","new_content":"<?xml version=\"1.0\" encoding=\"utf-8\"?>\n<resources>\n    <string name=\"app_name\">Modified DVAC</string>\n</resources>","create_backup":true}' 28 | jq -r '.result.content[0].text // .result // .error?.message // .'
echo "Skipped - modify_resource_file (enable manually if needed)"

# 24) Final workspace info to see changes
echo "--- get_workspace_info (final) ---"
call_tool "get_workspace_info" '{}' 29 | jq -r '.result.content[0].text // .result // .error?.message // .' | jq -r '.workspace_info.projects[]? | {name, is_apktool_project, size} // .error // .'

echo "== Test Completed Successfully =="
echo "Note: Some modification operations were skipped for safety."
echo "To test file modifications, uncomment the relevant lines in the script."

# Cleanup temp file
rm -f "$INIT_RESP_HEADERS"

```

`uv.lock`:

```lock
version = 1
revision = 1
requires-python = ">=3.13"

[[package]]
name = "annotated-types"
version = "0.7.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/ee/67/531ea369ba64dcff5ec9c3402f9f51bf748cec26dde048a2f973a4eea7f5/annotated_types-0.7.0.tar.gz", hash = "sha256:aff07c09a53a08bc8cfccb9c85b05f1aa9a2a6f23728d790723543408344ce89", size = 16081 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/78/b6/6307fbef88d9b5ee7421e68d78a9f162e0da4900bc5f5793f6d3d0e34fb8/annotated_types-0.7.0-py3-none-any.whl", hash = "sha256:1f02e8b43a8fbbc3f3e0d4f0f4bfc8131bcb4eebe8849b8e5c773f3a1c582a53", size = 13643 },
]

[[package]]
name = "anyio"
version = "4.9.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "idna" },
    { name = "sniffio" },
]
sdist = { url = "https://files.pythonhosted.org/packages/95/7d/4c1bd541d4dffa1b52bd83fb8527089e097a106fc90b467a7313b105f840/anyio-4.9.0.tar.gz", hash = "sha256:673c0c244e15788651a4ff38710fea9675823028a6f08a5eda409e0c9840a028", size = 190949 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/a1/ee/48ca1a7c89ffec8b6a0c5d02b89c305671d5ffd8d3c94acf8b8c408575bb/anyio-4.9.0-py3-none-any.whl", hash = "sha256:9f76d541cad6e36af7beb62e978876f3b41e3e04f2c1fbf0884604c0a9c4d93c", size = 100916 },
]

[[package]]
name = "apktool-mcp-server"
version = "0.1.0"
source = { virtual = "." }
dependencies = [
    { name = "fastmcp" },
    { name = "logging" },
]

[package.metadata]
requires-dist = [
    { name = "fastmcp", specifier = ">=2.2.0" },
    { name = "logging", specifier = ">=0.4.9.6" },
]

[[package]]
name = "certifi"
version = "2025.1.31"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/1c/ab/c9f1e32b7b1bf505bf26f0ef697775960db7932abeb7b516de930ba2705f/certifi-2025.1.31.tar.gz", hash = "sha256:3d5da6925056f6f18f119200434a4780a94263f10d1c21d032a6f6b2baa20651", size = 167577 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/38/fc/bce832fd4fd99766c04d1ee0eead6b0ec6486fb100ae5e74c1d91292b982/certifi-2025.1.31-py3-none-any.whl", hash = "sha256:ca78db4565a652026a4db2bcdf68f2fb589ea80d0be70e03929ed730746b84fe", size = 166393 },
]

[[package]]
name = "click"
version = "8.1.8"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "colorama", marker = "sys_platform == 'win32'" },
]
sdist = { url = "https://files.pythonhosted.org/packages/b9/2e/0090cbf739cee7d23781ad4b89a9894a41538e4fcf4c31dcdd705b78eb8b/click-8.1.8.tar.gz", hash = "sha256:ed53c9d8990d83c2a27deae68e4ee337473f6330c040a31d4225c9574d16096a", size = 226593 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/7e/d4/7ebdbd03970677812aac39c869717059dbb71a4cfc033ca6e5221787892c/click-8.1.8-py3-none-any.whl", hash = "sha256:63c132bbbed01578a06712a2d1f497bb62d9c1c0d329b7903a866228027263b2", size = 98188 },
]

[[package]]
name = "colorama"
version = "0.4.6"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/d8/53/6f443c9a4a8358a93a6792e2acffb9d9d5cb0a5cfd8802644b7b1c9a02e4/colorama-0.4.6.tar.gz", hash = "sha256:08695f5cb7ed6e0531a20572697297273c47b8cae5a63ffc6d6ed5c201be6e44", size = 27697 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d1/d6/3965ed04c63042e047cb6a3e6ed1a63a35087b6a609aa3a15ed8ac56c221/colorama-0.4.6-py2.py3-none-any.whl", hash = "sha256:4f1d9991f5acc0ca119f9d443620b77f9d6b33703e51011c16baf57afb285fc6", size = 25335 },
]

[[package]]
name = "dotenv"
version = "0.9.9"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "python-dotenv" },
]
wheels = [
    { url = "https://files.pythonhosted.org/packages/b2/b7/545d2c10c1fc15e48653c91efde329a790f2eecfbbf2bd16003b5db2bab0/dotenv-0.9.9-py2.py3-none-any.whl", hash = "sha256:29cf74a087b31dafdb5a446b6d7e11cbce8ed2741540e2339c69fbef92c94ce9", size = 1892 },
]

[[package]]
name = "exceptiongroup"
version = "1.2.2"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/09/35/2495c4ac46b980e4ca1f6ad6db102322ef3ad2410b79fdde159a4b0f3b92/exceptiongroup-1.2.2.tar.gz", hash = "sha256:47c2edf7c6738fafb49fd34290706d1a1a2f4d1c6df275526b62cbb4aa5393cc", size = 28883 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/02/cc/b7e31358aac6ed1ef2bb790a9746ac2c69bcb3c8588b41616914eb106eaf/exceptiongroup-1.2.2-py3-none-any.whl", hash = "sha256:3111b9d131c238bec2f8f516e123e14ba243563fb135d3fe885990585aa7795b", size = 16453 },
]

[[package]]
name = "fastmcp"
version = "2.2.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "dotenv" },
    { name = "exceptiongroup" },
    { name = "httpx" },
    { name = "mcp" },
    { name = "openapi-pydantic" },
    { name = "rich" },
    { name = "typer" },
    { name = "websockets" },
]
sdist = { url = "https://files.pythonhosted.org/packages/e8/5f/0ad05fb3cca4529a994a7446da554c0ecf2a91bcf3a076261e29b5043ff1/fastmcp-2.2.0.tar.gz", hash = "sha256:4d9373705ebd9e3de807005ed732b8955c6eb74e4b47595752f461c1c689f231", size = 918342 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/69/1d/266a86204e658d9133382e7f260d4cabb75fb18ac2e03efc953e25ebe20f/fastmcp-2.2.0-py3-none-any.whl", hash = "sha256:077bdf3f37f423688f1356db0f6ed0864e001de712bce41ad4939fa8b38d7149", size = 75793 },
]

[[package]]
name = "h11"
version = "0.14.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/f5/38/3af3d3633a34a3316095b39c8e8fb4853a28a536e55d347bd8d8e9a14b03/h11-0.14.0.tar.gz", hash = "sha256:8f19fbbe99e72420ff35c00b27a34cb9937e902a8b810e2c88300c6f0a3b699d", size = 100418 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/95/04/ff642e65ad6b90db43e668d70ffb6736436c7ce41fcc549f4e9472234127/h11-0.14.0-py3-none-any.whl", hash = "sha256:e3fe4ac4b851c468cc8363d500db52c2ead036020723024a109d37346efaa761", size = 58259 },
]

[[package]]
name = "httpcore"
version = "1.0.8"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "certifi" },
    { name = "h11" },
]
sdist = { url = "https://files.pythonhosted.org/packages/9f/45/ad3e1b4d448f22c0cff4f5692f5ed0666658578e358b8d58a19846048059/httpcore-1.0.8.tar.gz", hash = "sha256:86e94505ed24ea06514883fd44d2bc02d90e77e7979c8eb71b90f41d364a1bad", size = 85385 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/18/8d/f052b1e336bb2c1fc7ed1aaed898aa570c0b61a09707b108979d9fc6e308/httpcore-1.0.8-py3-none-any.whl", hash = "sha256:5254cf149bcb5f75e9d1b2b9f729ea4a4b883d1ad7379fc632b727cec23674be", size = 78732 },
]

[[package]]
name = "httpx"
version = "0.28.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "anyio" },
    { name = "certifi" },
    { name = "httpcore" },
    { name = "idna" },
]
sdist = { url = "https://files.pythonhosted.org/packages/b1/df/48c586a5fe32a0f01324ee087459e112ebb7224f646c0b5023f5e79e9956/httpx-0.28.1.tar.gz", hash = "sha256:75e98c5f16b0f35b567856f597f06ff2270a374470a5c2392242528e3e3e42fc", size = 141406 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/2a/39/e50c7c3a983047577ee07d2a9e53faf5a69493943ec3f6a384bdc792deb2/httpx-0.28.1-py3-none-any.whl", hash = "sha256:d909fcccc110f8c7faf814ca82a9a4d816bc5a6dbfea25d6591d6985b8ba59ad", size = 73517 },
]

[[package]]
name = "httpx-sse"
version = "0.4.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/4c/60/8f4281fa9bbf3c8034fd54c0e7412e66edbab6bc74c4996bd616f8d0406e/httpx-sse-0.4.0.tar.gz", hash = "sha256:1e81a3a3070ce322add1d3529ed42eb5f70817f45ed6ec915ab753f961139721", size = 12624 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e1/9b/a181f281f65d776426002f330c31849b86b31fc9d848db62e16f03ff739f/httpx_sse-0.4.0-py3-none-any.whl", hash = "sha256:f329af6eae57eaa2bdfd962b42524764af68075ea87370a2de920af5341e318f", size = 7819 },
]

[[package]]
name = "idna"
version = "3.10"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/f1/70/7703c29685631f5a7590aa73f1f1d3fa9a380e654b86af429e0934a32f7d/idna-3.10.tar.gz", hash = "sha256:12f65c9b470abda6dc35cf8e63cc574b1c52b11df2c86030af0ac09b01b13ea9", size = 190490 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/76/c6/c88e154df9c4e1a2a66ccf0005a88dfb2650c1dffb6f5ce603dfbd452ce3/idna-3.10-py3-none-any.whl", hash = "sha256:946d195a0d259cbba61165e88e65941f16e9b36ea6ddb97f00452bae8b1287d3", size = 70442 },
]

[[package]]
name = "logging"
version = "0.4.9.6"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/93/4b/979db9e44be09f71e85c9c8cfc42f258adfb7d93ce01deed2788b2948919/logging-0.4.9.6.tar.gz", hash = "sha256:26f6b50773f085042d301085bd1bf5d9f3735704db9f37c1ce6d8b85c38f2417", size = 96029 }

[[package]]
name = "markdown-it-py"
version = "3.0.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "mdurl" },
]
sdist = { url = "https://files.pythonhosted.org/packages/38/71/3b932df36c1a044d397a1f92d1cf91ee0a503d91e470cbd670aa66b07ed0/markdown-it-py-3.0.0.tar.gz", hash = "sha256:e3f60a94fa066dc52ec76661e37c851cb232d92f9886b15cb560aaada2df8feb", size = 74596 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/42/d7/1ec15b46af6af88f19b8e5ffea08fa375d433c998b8a7639e76935c14f1f/markdown_it_py-3.0.0-py3-none-any.whl", hash = "sha256:355216845c60bd96232cd8d8c40e8f9765cc86f46880e43a8fd22dc1a1a8cab1", size = 87528 },
]

[[package]]
name = "mcp"
version = "1.6.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "anyio" },
    { name = "httpx" },
    { name = "httpx-sse" },
    { name = "pydantic" },
    { name = "pydantic-settings" },
    { name = "sse-starlette" },
    { name = "starlette" },
    { name = "uvicorn" },
]
sdist = { url = "https://files.pythonhosted.org/packages/95/d2/f587cb965a56e992634bebc8611c5b579af912b74e04eb9164bd49527d21/mcp-1.6.0.tar.gz", hash = "sha256:d9324876de2c5637369f43161cd71eebfd803df5a95e46225cab8d280e366723", size = 200031 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/10/30/20a7f33b0b884a9d14dd3aa94ff1ac9da1479fe2ad66dd9e2736075d2506/mcp-1.6.0-py3-none-any.whl", hash = "sha256:7bd24c6ea042dbec44c754f100984d186620d8b841ec30f1b19eda9b93a634d0", size = 76077 },
]

[[package]]
name = "mdurl"
version = "0.1.2"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/d6/54/cfe61301667036ec958cb99bd3efefba235e65cdeb9c84d24a8293ba1d90/mdurl-0.1.2.tar.gz", hash = "sha256:bb413d29f5eea38f31dd4754dd7377d4465116fb207585f97bf925588687c1ba", size = 8729 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/b3/38/89ba8ad64ae25be8de66a6d463314cf1eb366222074cfda9ee839c56a4b4/mdurl-0.1.2-py3-none-any.whl", hash = "sha256:84008a41e51615a49fc9966191ff91509e3c40b939176e643fd50a5c2196b8f8", size = 9979 },
]

[[package]]
name = "openapi-pydantic"
version = "0.5.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "pydantic" },
]
sdist = { url = "https://files.pythonhosted.org/packages/02/2e/58d83848dd1a79cb92ed8e63f6ba901ca282c5f09d04af9423ec26c56fd7/openapi_pydantic-0.5.1.tar.gz", hash = "sha256:ff6835af6bde7a459fb93eb93bb92b8749b754fc6e51b2f1590a19dc3005ee0d", size = 60892 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/12/cf/03675d8bd8ecbf4445504d8071adab19f5f993676795708e36402ab38263/openapi_pydantic-0.5.1-py3-none-any.whl", hash = "sha256:a3a09ef4586f5bd760a8df7f43028b60cafb6d9f61de2acba9574766255ab146", size = 96381 },
]

[[package]]
name = "pydantic"
version = "2.11.3"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "annotated-types" },
    { name = "pydantic-core" },
    { name = "typing-extensions" },
    { name = "typing-inspection" },
]
sdist = { url = "https://files.pythonhosted.org/packages/10/2e/ca897f093ee6c5f3b0bee123ee4465c50e75431c3d5b6a3b44a47134e891/pydantic-2.11.3.tar.gz", hash = "sha256:7471657138c16adad9322fe3070c0116dd6c3ad8d649300e3cbdfe91f4db4ec3", size = 785513 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/b0/1d/407b29780a289868ed696d1616f4aad49d6388e5a77f567dcd2629dcd7b8/pydantic-2.11.3-py3-none-any.whl", hash = "sha256:a082753436a07f9ba1289c6ffa01cd93db3548776088aa917cc43b63f68fa60f", size = 443591 },
]

[[package]]
name = "pydantic-core"
version = "2.33.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/17/19/ed6a078a5287aea7922de6841ef4c06157931622c89c2a47940837b5eecd/pydantic_core-2.33.1.tar.gz", hash = "sha256:bcc9c6fdb0ced789245b02b7d6603e17d1563064ddcfc36f046b61c0c05dd9df", size = 434395 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/7a/24/eed3466a4308d79155f1cdd5c7432c80ddcc4530ba8623b79d5ced021641/pydantic_core-2.33.1-cp313-cp313-macosx_10_12_x86_64.whl", hash = "sha256:70af6a21237b53d1fe7b9325b20e65cbf2f0a848cf77bed492b029139701e66a", size = 2033551 },
    { url = "https://files.pythonhosted.org/packages/ab/14/df54b1a0bc9b6ded9b758b73139d2c11b4e8eb43e8ab9c5847c0a2913ada/pydantic_core-2.33.1-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:282b3fe1bbbe5ae35224a0dbd05aed9ccabccd241e8e6b60370484234b456266", size = 1852785 },
    { url = "https://files.pythonhosted.org/packages/fa/96/e275f15ff3d34bb04b0125d9bc8848bf69f25d784d92a63676112451bfb9/pydantic_core-2.33.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:4b315e596282bbb5822d0c7ee9d255595bd7506d1cb20c2911a4da0b970187d3", size = 1897758 },
    { url = "https://files.pythonhosted.org/packages/b7/d8/96bc536e975b69e3a924b507d2a19aedbf50b24e08c80fb00e35f9baaed8/pydantic_core-2.33.1-cp313-cp313-manylinux_2_17_armv7l.manylinux2014_armv7l.whl", hash = "sha256:1dfae24cf9921875ca0ca6a8ecb4bb2f13c855794ed0d468d6abbec6e6dcd44a", size = 1986109 },
    { url = "https://files.pythonhosted.org/packages/90/72/ab58e43ce7e900b88cb571ed057b2fcd0e95b708a2e0bed475b10130393e/pydantic_core-2.33.1-cp313-cp313-manylinux_2_17_ppc64le.manylinux2014_ppc64le.whl", hash = "sha256:6dd8ecfde08d8bfadaea669e83c63939af76f4cf5538a72597016edfa3fad516", size = 2129159 },
    { url = "https://files.pythonhosted.org/packages/dc/3f/52d85781406886c6870ac995ec0ba7ccc028b530b0798c9080531b409fdb/pydantic_core-2.33.1-cp313-cp313-manylinux_2_17_s390x.manylinux2014_s390x.whl", hash = "sha256:2f593494876eae852dc98c43c6f260f45abdbfeec9e4324e31a481d948214764", size = 2680222 },
    { url = "https://files.pythonhosted.org/packages/f4/56/6e2ef42f363a0eec0fd92f74a91e0ac48cd2e49b695aac1509ad81eee86a/pydantic_core-2.33.1-cp313-cp313-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:948b73114f47fd7016088e5186d13faf5e1b2fe83f5e320e371f035557fd264d", size = 2006980 },
    { url = "https://files.pythonhosted.org/packages/4c/c0/604536c4379cc78359f9ee0aa319f4aedf6b652ec2854953f5a14fc38c5a/pydantic_core-2.33.1-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.whl", hash = "sha256:e11f3864eb516af21b01e25fac915a82e9ddad3bb0fb9e95a246067398b435a4", size = 2120840 },
    { url = "https://files.pythonhosted.org/packages/1f/46/9eb764814f508f0edfb291a0f75d10854d78113fa13900ce13729aaec3ae/pydantic_core-2.33.1-cp313-cp313-musllinux_1_1_aarch64.whl", hash = "sha256:549150be302428b56fdad0c23c2741dcdb5572413776826c965619a25d9c6bde", size = 2072518 },
    { url = "https://files.pythonhosted.org/packages/42/e3/fb6b2a732b82d1666fa6bf53e3627867ea3131c5f39f98ce92141e3e3dc1/pydantic_core-2.33.1-cp313-cp313-musllinux_1_1_armv7l.whl", hash = "sha256:495bc156026efafd9ef2d82372bd38afce78ddd82bf28ef5276c469e57c0c83e", size = 2248025 },
    { url = "https://files.pythonhosted.org/packages/5c/9d/fbe8fe9d1aa4dac88723f10a921bc7418bd3378a567cb5e21193a3c48b43/pydantic_core-2.33.1-cp313-cp313-musllinux_1_1_x86_64.whl", hash = "sha256:ec79de2a8680b1a67a07490bddf9636d5c2fab609ba8c57597e855fa5fa4dacd", size = 2254991 },
    { url = "https://files.pythonhosted.org/packages/aa/99/07e2237b8a66438d9b26482332cda99a9acccb58d284af7bc7c946a42fd3/pydantic_core-2.33.1-cp313-cp313-win32.whl", hash = "sha256:ee12a7be1742f81b8a65b36c6921022301d466b82d80315d215c4c691724986f", size = 1915262 },
    { url = "https://files.pythonhosted.org/packages/8a/f4/e457a7849beeed1e5defbcf5051c6f7b3c91a0624dd31543a64fc9adcf52/pydantic_core-2.33.1-cp313-cp313-win_amd64.whl", hash = "sha256:ede9b407e39949d2afc46385ce6bd6e11588660c26f80576c11c958e6647bc40", size = 1956626 },
    { url = "https://files.pythonhosted.org/packages/20/d0/e8d567a7cff7b04e017ae164d98011f1e1894269fe8e90ea187a3cbfb562/pydantic_core-2.33.1-cp313-cp313-win_arm64.whl", hash = "sha256:aa687a23d4b7871a00e03ca96a09cad0f28f443690d300500603bd0adba4b523", size = 1909590 },
    { url = "https://files.pythonhosted.org/packages/ef/fd/24ea4302d7a527d672c5be06e17df16aabfb4e9fdc6e0b345c21580f3d2a/pydantic_core-2.33.1-cp313-cp313t-macosx_11_0_arm64.whl", hash = "sha256:401d7b76e1000d0dd5538e6381d28febdcacb097c8d340dde7d7fc6e13e9f95d", size = 1812963 },
    { url = "https://files.pythonhosted.org/packages/5f/95/4fbc2ecdeb5c1c53f1175a32d870250194eb2fdf6291b795ab08c8646d5d/pydantic_core-2.33.1-cp313-cp313t-manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:7aeb055a42d734c0255c9e489ac67e75397d59c6fbe60d155851e9782f276a9c", size = 1986896 },
    { url = "https://files.pythonhosted.org/packages/71/ae/fe31e7f4a62431222d8f65a3bd02e3fa7e6026d154a00818e6d30520ea77/pydantic_core-2.33.1-cp313-cp313t-win_amd64.whl", hash = "sha256:338ea9b73e6e109f15ab439e62cb3b78aa752c7fd9536794112e14bee02c8d18", size = 1931810 },
]

[[package]]
name = "pydantic-settings"
version = "2.9.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "pydantic" },
    { name = "python-dotenv" },
    { name = "typing-inspection" },
]
sdist = { url = "https://files.pythonhosted.org/packages/67/1d/42628a2c33e93f8e9acbde0d5d735fa0850f3e6a2f8cb1eb6c40b9a732ac/pydantic_settings-2.9.1.tar.gz", hash = "sha256:c509bf79d27563add44e8446233359004ed85066cd096d8b510f715e6ef5d268", size = 163234 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/b6/5f/d6d641b490fd3ec2c4c13b4244d68deea3a1b970a97be64f34fb5504ff72/pydantic_settings-2.9.1-py3-none-any.whl", hash = "sha256:59b4f431b1defb26fe620c71a7d3968a710d719f5f4cdbbdb7926edeb770f6ef", size = 44356 },
]

[[package]]
name = "pygments"
version = "2.19.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/7c/2d/c3338d48ea6cc0feb8446d8e6937e1408088a72a39937982cc6111d17f84/pygments-2.19.1.tar.gz", hash = "sha256:61c16d2a8576dc0649d9f39e089b5f02bcd27fba10d8fb4dcc28173f7a45151f", size = 4968581 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/8a/0b/9fcc47d19c48b59121088dd6da2488a49d5f72dacf8262e2790a1d2c7d15/pygments-2.19.1-py3-none-any.whl", hash = "sha256:9ea1544ad55cecf4b8242fab6dd35a93bbce657034b0611ee383099054ab6d8c", size = 1225293 },
]

[[package]]
name = "python-dotenv"
version = "1.1.0"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/88/2c/7bb1416c5620485aa793f2de31d3df393d3686aa8a8506d11e10e13c5baf/python_dotenv-1.1.0.tar.gz", hash = "sha256:41f90bc6f5f177fb41f53e87666db362025010eb28f60a01c9143bfa33a2b2d5", size = 39920 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/1e/18/98a99ad95133c6a6e2005fe89faedf294a748bd5dc803008059409ac9b1e/python_dotenv-1.1.0-py3-none-any.whl", hash = "sha256:d7c01d9e2293916c18baf562d95698754b0dbbb5e74d457c45d4f6561fb9d55d", size = 20256 },
]

[[package]]
name = "rich"
version = "14.0.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "markdown-it-py" },
    { name = "pygments" },
]
sdist = { url = "https://files.pythonhosted.org/packages/a1/53/830aa4c3066a8ab0ae9a9955976fb770fe9c6102117c8ec4ab3ea62d89e8/rich-14.0.0.tar.gz", hash = "sha256:82f1bc23a6a21ebca4ae0c45af9bdbc492ed20231dcb63f297d6d1021a9d5725", size = 224078 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/0d/9b/63f4c7ebc259242c89b3acafdb37b41d1185c07ff0011164674e9076b491/rich-14.0.0-py3-none-any.whl", hash = "sha256:1c9491e1951aac09caffd42f448ee3d04e58923ffe14993f6e83068dc395d7e0", size = 243229 },
]

[[package]]
name = "shellingham"
version = "1.5.4"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/58/15/8b3609fd3830ef7b27b655beb4b4e9c62313a4e8da8c676e142cc210d58e/shellingham-1.5.4.tar.gz", hash = "sha256:8dbca0739d487e5bd35ab3ca4b36e11c4078f3a234bfce294b0a0291363404de", size = 10310 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e0/f9/0595336914c5619e5f28a1fb793285925a8cd4b432c9da0a987836c7f822/shellingham-1.5.4-py2.py3-none-any.whl", hash = "sha256:7ecfff8f2fd72616f7481040475a65b2bf8af90a56c89140852d1120324e8686", size = 9755 },
]

[[package]]
name = "sniffio"
version = "1.3.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/a2/87/a6771e1546d97e7e041b6ae58d80074f81b7d5121207425c964ddf5cfdbd/sniffio-1.3.1.tar.gz", hash = "sha256:f4324edc670a0f49750a81b895f35c3adb843cca46f0530f79fc1babb23789dc", size = 20372 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/e9/44/75a9c9421471a6c4805dbf2356f7c181a29c1879239abab1ea2cc8f38b40/sniffio-1.3.1-py3-none-any.whl", hash = "sha256:2f6da418d1f1e0fddd844478f41680e794e6051915791a034ff65e5f100525a2", size = 10235 },
]

[[package]]
name = "sse-starlette"
version = "2.2.1"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "anyio" },
    { name = "starlette" },
]
sdist = { url = "https://files.pythonhosted.org/packages/71/a4/80d2a11af59fe75b48230846989e93979c892d3a20016b42bb44edb9e398/sse_starlette-2.2.1.tar.gz", hash = "sha256:54470d5f19274aeed6b2d473430b08b4b379ea851d953b11d7f1c4a2c118b419", size = 17376 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/d9/e0/5b8bd393f27f4a62461c5cf2479c75a2cc2ffa330976f9f00f5f6e4f50eb/sse_starlette-2.2.1-py3-none-any.whl", hash = "sha256:6410a3d3ba0c89e7675d4c273a301d64649c03a5ef1ca101f10b47f895fd0e99", size = 10120 },
]

[[package]]
name = "starlette"
version = "0.46.2"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "anyio" },
]
sdist = { url = "https://files.pythonhosted.org/packages/ce/20/08dfcd9c983f6a6f4a1000d934b9e6d626cff8d2eeb77a89a68eef20a2b7/starlette-0.46.2.tar.gz", hash = "sha256:7f7361f34eed179294600af672f565727419830b54b7b084efe44bb82d2fccd5", size = 2580846 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/8b/0c/9d30a4ebeb6db2b25a841afbb80f6ef9a854fc3b41be131d249a977b4959/starlette-0.46.2-py3-none-any.whl", hash = "sha256:595633ce89f8ffa71a015caed34a5b2dc1c0cdb3f0f1fbd1e69339cf2abeec35", size = 72037 },
]

[[package]]
name = "typer"
version = "0.15.2"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "click" },
    { name = "rich" },
    { name = "shellingham" },
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/8b/6f/3991f0f1c7fcb2df31aef28e0594d8d54b05393a0e4e34c65e475c2a5d41/typer-0.15.2.tar.gz", hash = "sha256:ab2fab47533a813c49fe1f16b1a370fd5819099c00b119e0633df65f22144ba5", size = 100711 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/7f/fc/5b29fea8cee020515ca82cc68e3b8e1e34bb19a3535ad854cac9257b414c/typer-0.15.2-py3-none-any.whl", hash = "sha256:46a499c6107d645a9c13f7ee46c5d5096cae6f5fc57dd11eccbbb9ae3e44ddfc", size = 45061 },
]

[[package]]
name = "typing-extensions"
version = "4.13.2"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/f6/37/23083fcd6e35492953e8d2aaaa68b860eb422b34627b13f2ce3eb6106061/typing_extensions-4.13.2.tar.gz", hash = "sha256:e6c81219bd689f51865d9e372991c540bda33a0379d5573cddb9a3a23f7caaef", size = 106967 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/8b/54/b1ae86c0973cc6f0210b53d508ca3641fb6d0c56823f288d108bc7ab3cc8/typing_extensions-4.13.2-py3-none-any.whl", hash = "sha256:a439e7c04b49fec3e5d3e2beaa21755cadbbdc391694e28ccdd36ca4a1408f8c", size = 45806 },
]

[[package]]
name = "typing-inspection"
version = "0.4.0"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "typing-extensions" },
]
sdist = { url = "https://files.pythonhosted.org/packages/82/5c/e6082df02e215b846b4b8c0b887a64d7d08ffaba30605502639d44c06b82/typing_inspection-0.4.0.tar.gz", hash = "sha256:9765c87de36671694a67904bf2c96e395be9c6439bb6c87b5142569dcdd65122", size = 76222 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/31/08/aa4fdfb71f7de5176385bd9e90852eaf6b5d622735020ad600f2bab54385/typing_inspection-0.4.0-py3-none-any.whl", hash = "sha256:50e72559fcd2a6367a19f7a7e610e6afcb9fac940c650290eed893d61386832f", size = 14125 },
]

[[package]]
name = "uvicorn"
version = "0.34.2"
source = { registry = "https://pypi.org/simple" }
dependencies = [
    { name = "click" },
    { name = "h11" },
]
sdist = { url = "https://files.pythonhosted.org/packages/a6/ae/9bbb19b9e1c450cf9ecaef06463e40234d98d95bf572fab11b4f19ae5ded/uvicorn-0.34.2.tar.gz", hash = "sha256:0e929828f6186353a80b58ea719861d2629d766293b6d19baf086ba31d4f3328", size = 76815 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/b1/4b/4cef6ce21a2aaca9d852a6e84ef4f135d99fcd74fa75105e2fc0c8308acd/uvicorn-0.34.2-py3-none-any.whl", hash = "sha256:deb49af569084536d269fe0a6d67e3754f104cf03aba7c11c40f01aadf33c403", size = 62483 },
]

[[package]]
name = "websockets"
version = "15.0.1"
source = { registry = "https://pypi.org/simple" }
sdist = { url = "https://files.pythonhosted.org/packages/21/e6/26d09fab466b7ca9c7737474c52be4f76a40301b08362eb2dbc19dcc16c1/websockets-15.0.1.tar.gz", hash = "sha256:82544de02076bafba038ce055ee6412d68da13ab47f0c60cab827346de828dee", size = 177016 }
wheels = [
    { url = "https://files.pythonhosted.org/packages/cb/9f/51f0cf64471a9d2b4d0fc6c534f323b664e7095640c34562f5182e5a7195/websockets-15.0.1-cp313-cp313-macosx_10_13_universal2.whl", hash = "sha256:ee443ef070bb3b6ed74514f5efaa37a252af57c90eb33b956d35c8e9c10a1931", size = 175440 },
    { url = "https://files.pythonhosted.org/packages/8a/05/aa116ec9943c718905997412c5989f7ed671bc0188ee2ba89520e8765d7b/websockets-15.0.1-cp313-cp313-macosx_10_13_x86_64.whl", hash = "sha256:5a939de6b7b4e18ca683218320fc67ea886038265fd1ed30173f5ce3f8e85675", size = 173098 },
    { url = "https://files.pythonhosted.org/packages/ff/0b/33cef55ff24f2d92924923c99926dcce78e7bd922d649467f0eda8368923/websockets-15.0.1-cp313-cp313-macosx_11_0_arm64.whl", hash = "sha256:746ee8dba912cd6fc889a8147168991d50ed70447bf18bcda7039f7d2e3d9151", size = 173329 },
    { url = "https://files.pythonhosted.org/packages/31/1d/063b25dcc01faa8fada1469bdf769de3768b7044eac9d41f734fd7b6ad6d/websockets-15.0.1-cp313-cp313-manylinux_2_17_aarch64.manylinux2014_aarch64.whl", hash = "sha256:595b6c3969023ecf9041b2936ac3827e4623bfa3ccf007575f04c5a6aa318c22", size = 183111 },
    { url = "https://files.pythonhosted.org/packages/93/53/9a87ee494a51bf63e4ec9241c1ccc4f7c2f45fff85d5bde2ff74fcb68b9e/websockets-15.0.1-cp313-cp313-manylinux_2_5_i686.manylinux1_i686.manylinux_2_17_i686.manylinux2014_i686.whl", hash = "sha256:3c714d2fc58b5ca3e285461a4cc0c9a66bd0e24c5da9911e30158286c9b5be7f", size = 182054 },
    { url = "https://files.pythonhosted.org/packages/ff/b2/83a6ddf56cdcbad4e3d841fcc55d6ba7d19aeb89c50f24dd7e859ec0805f/websockets-15.0.1-cp313-cp313-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl", hash = "sha256:0f3c1e2ab208db911594ae5b4f79addeb3501604a165019dd221c0bdcabe4db8", size = 182496 },
    { url = "https://files.pythonhosted.org/packages/98/41/e7038944ed0abf34c45aa4635ba28136f06052e08fc2168520bb8b25149f/websockets-15.0.1-cp313-cp313-musllinux_1_2_aarch64.whl", hash = "sha256:229cf1d3ca6c1804400b0a9790dc66528e08a6a1feec0d5040e8b9eb14422375", size = 182829 },
    { url = "https://files.pythonhosted.org/packages/e0/17/de15b6158680c7623c6ef0db361da965ab25d813ae54fcfeae2e5b9ef910/websockets-15.0.1-cp313-cp313-musllinux_1_2_i686.whl", hash = "sha256:756c56e867a90fb00177d530dca4b097dd753cde348448a1012ed6c5131f8b7d", size = 182217 },
    { url = "https://files.pythonhosted.org/packages/33/2b/1f168cb6041853eef0362fb9554c3824367c5560cbdaad89ac40f8c2edfc/websockets-15.0.1-cp313-cp313-musllinux_1_2_x86_64.whl", hash = "sha256:558d023b3df0bffe50a04e710bc87742de35060580a293c2a984299ed83bc4e4", size = 182195 },
    { url = "https://files.pythonhosted.org/packages/86/eb/20b6cdf273913d0ad05a6a14aed4b9a85591c18a987a3d47f20fa13dcc47/websockets-15.0.1-cp313-cp313-win32.whl", hash = "sha256:ba9e56e8ceeeedb2e080147ba85ffcd5cd0711b89576b83784d8605a7df455fa", size = 176393 },
    { url = "https://files.pythonhosted.org/packages/1b/6c/c65773d6cab416a64d191d6ee8a8b1c68a09970ea6909d16965d26bfed1e/websockets-15.0.1-cp313-cp313-win_amd64.whl", hash = "sha256:e09473f095a819042ecb2ab9465aee615bd9c2028e4ef7d933600a8401c79561", size = 176837 },
    { url = "https://files.pythonhosted.org/packages/fa/a8/5b41e0da817d64113292ab1f8247140aac61cbf6cfd085d6a0fa77f4984f/websockets-15.0.1-py3-none-any.whl", hash = "sha256:f7a866fbc1e97b5c617ee4116daaa09b722101d4a3c170c787450ba409f9736f", size = 169743 },
]

```