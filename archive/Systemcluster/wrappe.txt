Project Path: arc_Systemcluster_wrappe_hzibcxz_

Source Tree:

```txt
arc_Systemcluster_wrappe_hzibcxz_
├── Cargo.toml
├── LICENSE
├── README.md
├── build.rs
├── src
│   ├── args.rs
│   ├── compress.rs
│   ├── main.rs
│   └── types.rs
└── startpe
    ├── Cargo.toml
    ├── Cross.toml
    └── src
        ├── decompress.rs
        ├── main.rs
        ├── once.rs
        ├── permissions.rs
        ├── prefetch.rs
        ├── types.rs
        └── versioning.rs

```

`Cargo.toml`:

```toml
[package]

name = "wrappe"
description = "Packer for creating self-contained single-binary applications from executables and directories"
version = "1.0.4"
license = "BSD-2-Clause"
authors = ["Christian Sdunek <me@systemcluster.me>"]
categories = ["compression", "filesystem", "command-line-utilities"]
keywords = ["compression", "binary", "executable", "packer", "filesystem"]
edition = "2021"
rust-version = "1.77.2"
include = [
  "Cargo.toml",
  "src/**/*",
  "startpe.tar",
  "build.rs",
  "LICENSE",
]
build = "build.rs"
readme = "README.md"
repository = "https://github.com/Systemcluster/wrappe"

[[bin]]

name = "wrappe"
path = "src/main.rs"

[workspace]

members = [
  ".",
  "startpe",
]

[profile.release]

codegen-units = 1
debug = false
debug-assertions = false
incremental = false
lto = "fat"
opt-level = 's'
panic = "abort"
strip = "symbols"

[profile.dev]

panic = "abort"
opt-level = 0

[dependencies]

staticfilemap = { version = "0.8.0", default-features = false, features = ["zstd", "multithread"] }
editpe = { version = "0.2.1", default-features = false, features = ["std"] }

clap = { version = "4.5.21", features = ["std", "color", "suggestions", "derive", "unicode", "wrap_help"] }
color-backtrace = "0.6.1"
console = "0.15.8"
indicatif = "0.17.9"
jwalk = "0.8.1"
num_cpus = "1.16.0"
path-slash = "0.2.1"
rand = "0.8.5"
rayon = "1.10.0"
sysinfo = "0.32.0"
twox-hash = { version = "1.6.3", default-features = false }
zerocopy = "0.8.10"
zstd = { version = "0.13.2", default-features = false, features = ["zstdmt", "zdict_builder"] }

[build-dependencies]

jwalk = "0.8.1"
which = "7.0.0"
tar = "0.4.43"

```

`LICENSE`:

```
Copyright (c) 2020 Christian Sdunek <me@systemcluster.me> and the wrappe contributors

Redistribution and use in source and binary forms, with or without modification, are permitted
provided that the following conditions are met:

1. Redistributions of source code must retain the above copyright notice, this list of conditions
and the following disclaimer.

2. Redistributions in binary form must reproduce the above copyright notice, this list of
conditions and the following disclaimer in the documentation and/or other materials provided with
the distribution.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR
IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND
FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR
CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE,
DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER
IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT
OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

```

`README.md`:

```md
# wrappe

[![Release](https://img.shields.io/github/release/Systemcluster/wrappe)](https://github.com/Systemcluster/wrappe/releases)
[![Crates.io](https://img.shields.io/crates/v/wrappe)](https://crates.io/crates/wrappe)
[![Tests & Checks](https://img.shields.io/github/actions/workflow/status/Systemcluster/wrappe/tests.yml?label=tests%20%26%20checks)](https://github.com/Systemcluster/wrappe/actions/workflows/tests.yml)

**Packer for creating self-contained single-binary applications from executables and directories.**

## Features

* Packing of executables and their dependencies into single self-contained binaries
* Compression of packed payloads with Zstandard
* Streaming decompression with minimal memory overhead
* Compression and decompression of files in parallel
* Decompression only when necessary by checking existing files
* Automatic transfer of resources including icons and version information
* Platform support for Windows, macOS, Linux and more

With wrappe you can distribute your application and its files as a single executable without the need for an installer, while resulting in a smaller file size and faster startup than many alternatives.

## Usage

### Download

A snapshot build of the latest version can be found on the [release page](https://github.com/Systemcluster/wrappe/releases).

Snapshot builds contain runners for Windows (`x86_64-pc-windows-gnu`), macOS (`x86_64-apple-darwin` and `aarch64-apple-darwin`) and Linux (`x86_64-unknown-linux-musl`), allowing packing for these platforms without additional setup.

Alternatively wrappe can be installed with `cargo`, see the [compilation](#compilation) section for more info on how to compile wrappe with additional runners for other platforms.

### Example

```shell
wrappe --compression 16 app app/diogenes.exe packed.exe
```

### Details

Run `wrappe` with an `input` directory, the `command` to launch and  the `output` filename to create a single-binary executable.
The input directory and all contained files and links will be packed. The command must be an executable file within the input directory that should be launched after unpacking.

```text
wrappe [OPTIONS] <input> <command> [output] [-- <ARGUMENTS>...]

Arguments:
  <input>         Path to the input directory
  <command>       Path to the executable to start after unpacking
  [output]        Path to or filename of the output executable
  [ARGUMENTS]...  Command line arguments to pass to the executable

Options:
  -r, --runner <RUNNER>
        Platform to pack for (see --list-runners for available options) [default: native]
  -c, --compression <COMPRESSION>
        Zstd compression level (0-22) [default: 8]
  -t, --unpack-target <UNPACK_TARGET>
        Unpack directory target (temp, local, cwd) [default: temp]
  -d, --unpack-directory <UNPACK_DIRECTORY>
        Unpack directory name [default: inferred from input directory]
  -v, --versioning <VERSIONING>
        Versioning strategy (sidebyside, replace, none) [default: sidebyside]
  -e, --verification <VERIFICATION>
        Verification of existing unpacked data (existence, checksum, none) [default: existence]
  -s, --version-string <VERSION_STRING>
        Version string override [default: randomly generated]
  -i, --show-information <SHOW_INFORMATION>
        Information output details (title, verbose, none) [default: title]
  -n, --console <CONSOLE>
        Show or attach to a console window (auto, always, never, attach) [default: auto]
  -w, --current-dir <CURRENT_DIR>
        Working directory of the command (inherit, unpack, runner, command) [default: inherit]
  -u, --cleanup
        Cleanup the unpack directory after exit
  -o, --once
        Allow only one running instance
  -z, --build-dictionary
        Build compression dictionary
  -l, --list-runners
        Print available runners
  -h, --help
        Print help
  -V, --version
        Print version
```

Additional arguments for the packed executable can be specified after `--` and will automatically be passed to the command when launched.

If the packed executable needs to access packed files by relative path and expects a certain working directory, use the [`--current-dir`](#current-dir) option to set it to its parent directory or the unpack directory. The `WRAPPE_UNPACK_DIR` and `WRAPPE_LAUNCH_DIR` environment variables will always be set for the command with the paths to the unpack directory and the inherited working directory.

Packed Windows executables will have their subsystem, icons and other resources automatically transferred to the output executable through [editpe](https://github.com/Systemcluster/editpe).

### Options

The packing and unpacking behavior is highly customizable. The default options are suitable for most use cases, but can be adjusted to fit specific requirements.

#### runner

This option specifies which runner will be used for the output executable. The runner is the pre-built executable that unpacks the payload and starts the packed command.
Partial matches are accepted if unambiguous, for instance `windows` will be accepted if only one runner for Windows is available.

It defaults to the native runner for the current platform. Additional runners have to be included at compile time, see the compilation section for more info.

#### compression

This option controls the Zstandard compression level. Accepted values range from `0` to `22`. Higher compression levels will result in smaller output files, but will also increase the packing time.

It defaults to `8`.

#### unpack-target

This option specifies the directory the packed files are unpacked to. Accepted values are:

* `temp`: The files will be unpacked to the systems temporary directory.
* `local`: The files will be unpacked to the local data directory, usually `User/AppData/Local` on Windows and `/home/user/.local/share` on Linux.
* `cwd`: The files will be unpacked to the working directory of the runner executable.

It defaults to `temp`.

#### unpack-directory

This option specifies the unpack directory name inside the [`unpack-target`](#unpack-target). It defaults to the name of the input file or directory.

#### versioning

This option specifies the versioning strategy. Accepted values are:

* `sidebyside`: An individual directory will be created for every version. An already unpacked version will not be unpacked again.
* `replace`: Already unpacked files from a different version will be overwritten. Unpacked files from the same version will not be upacked again.
* `none`: Packed files are always unpacked and already unpacked files will be overwritten.

It defaults to `sidebyside`. The version is determined by a unique identifier generated during the packing process or specified with the [`version-string`](#version-string) option.

Using `replace` or `none` might cause unpacking to fail if another instance of the packed executable is already running unless the [`once`](#once) option is set.

#### verification

This option specifies the verification of the unpacked payload before skipping extraction. Accepted values are:

* `existence`: All files in the payload will be checked for existence.
* `checksum`: A checksum for all files will be calculated and compared with the checksum calculated during the packing process.
* `none`: No verification will be performed. Unpacking will be skipped if the unpack directory exists and was created with the same version string.

It defaults to `existence`. This option has no effect when [`versioning`](#versioning) is set to `none`.

#### version-string

This option specifies the version string. It defaults to a randomly generated string of 8 characters.

#### show-information

This option controls the information output of the runner. Accepted values are:

* `title`: The runner will output the `wrappe` version and the unpack directory.
* `verbose`: The runner will output various additional details like unpack status, configuration and payload size.
* `none`: The runner will show no additional output.

It defaults to `title`. Error information is always shown when applicable. Windows runners using the GUI subsystem will only show information output when launched from a console and this option is set to `verbose`, or a console is attached or opened through the [`console`](#console) option.

#### console

This option controls if the runner should attach to a console or if a console window should be opened when launching a Windows application from the Windows explorer. Accepted values are:

* `auto`: Select the console behavior based on the subsystem of the input executable if available. If not available, it will fall back to `never` for Windows runners, and `always` for all other runners.
* `always` Always attach to or open a console. The runner will block the console until the packed executable exits.
* `never`: Never open or attach to a console. The runner will immediately exit after launching the packed executable.
* `attach`: Never open a new console window, but attach to an existing console if available. The runner will unblock the console immediately, but output will still be shown.

It defaults to `auto`. This option currently only affects Windows runners, other runners will always attach to a console if available. This option will also not prevent packed Windows command line applications from opening a console on their own when launched from the Windows explorer.

#### current-dir

This option changes the working directory of the packed executable. Accepted values are:

* `inherit`: The working directory will be inherited from the runner. This is usually the directory containing the runner or the directory from which the runner was launched.
* `unpack`: The working directory will be set to the unpack directory. This is the top-level directory of the unpacked payload.
* `runner`: The working directory will be set to the directory containing the runner, with all symbolic links resolved.
* `command`: The working directory will be set to the directory containing the unpacked executable. This will either be the unpack directory or a subdirectory within the unpacked payload.

It defaults to `inherit`.

#### cleanup

This option controls if the unpacking directory should be deleted after exiting the packed executable.

It can also be set at runtime by setting the `STARTPE_CLEANUP` environment variable to `1`.

#### once

This option prevents multiple instances of the packed executable from running at the same time. When set, the runner will check for running processes on the system and will exit immediately if a running instance of the executable is found during startup.

This option currently only affects Windows and Linux runners. On Windows, if the packed executable is a GUI application, the runner will bring its window into the foreground and activate it.

#### build-dictionary

This option builds a zstandard compression dictionary from the input files and stores it in the output executable. This can improve the compression ratio when many small and similar files are packed.

At least 8 input files are required to build a dictionary, and at most 128 KB of data from each input file will be sampled.

Building a dictionary can increase the packing time and can in some cases negatively affect the compression ratio. It is recommended to test the results with and without this option to determine whether it is beneficial for the specific use case.

## Performance

Wrappe is optimized for compression ratio and decompression speed, generally matching or outperforming other packers in terms of both. It uses a custom metadata format designed for parallel iteration and decompression and compact storage of file information. Packed files are concurrently decompressed from the memory-mapped executable directly to disk, while extraction is skipped when the files are already unpacked to enable fast startup of packed executables with minimal overhead.

> As an example, a 400 MB PyInstaller one-directory output with 1500 files packed with wrappe at maximum compression level results in a 100 MB executable that unpacks and starts in around 500 milliseconds on a modern Windows system on the first run and instantly on subsequent runs. This is around 50% faster and only 5% larger than the same project packed by PyInstaller in one-file mode with UPX compression, which unpacks and loads into memory on every run.

Generally, on a reasonably modern system, the decompression speed of wrappe is limited by the read and write speed of the system and storage medium.

## Compilation

Compiling wrappe will also compile a runner for your current platform by default.

```shell
cargo install wrappe
```

To compile and include additional runners for other platforms, specify the desired [target triples](https://doc.rust-lang.org/stable/rustc/platform-support.html) in the `WRAPPE_TARGETS` environment variable.

```shell
WRAPPE_TARGETS=x86_64-unknown-linux-gnu;x86_64-pc-windows-msvc cargo install wrappe
```

Target-specific [rustflags](https://doc.rust-lang.org/cargo/reference/config.html#buildrustflags) for runners can be configured through the `WRAPPE_TARGET_RUSTFLAGS_{target triple}` environment variable.

### Cross Compilation

Additional targets need to be available to `cargo` for cross compilation. Targets can be installed with `rustup`, for example `rustup target add x86_64-unknown-linux-musl`.

Some cross compilation targets require certain `AR`, `CC` and `CXX` environment variables to be set. Target-specific `AR`, `CC` and `CXX` can be configured through the `WRAPPE_TARGET_{AR|CC|CXX}_{target triple}` environment variables.

Cross compilation of additional runners can alternatively be performed through [cross](https://github.com/rust-embedded/cross) when available and the `WRAPPE_USE_CROSS` environment variable is set to `true`.

When including runners for multiple macOS targets, the `WRAPPE_MACOS_UNIVERSAL` environment variable can be set to a list of targets to build a universal runner with `lipo` containing the specified architectures, for example `x86_64-apple-darwin;aarch64-apple-darwin`. This runner will be included as `universal-apple-darwin`.

```

`build.rs`:

```rs
use std::{
    env::{var, vars},
    fs::{File, create_dir_all},
    ops::Deref,
    path::{Path, PathBuf},
    process::Command,
};

use jwalk::WalkDir;
use tar::Archive;
use which::which;


const TARGETS_ENV: &str = "WRAPPE_TARGETS";
const FILES_ENV: &str = "WRAPPE_FILES";
const USE_CROSS_ENV: &str = "WRAPPE_USE_CROSS";
const MACOS_UNIVERSAL_ENV: &str = "WRAPPE_MACOS_UNIVERSAL";
const STARTER_NAME: &str = "startpe";


fn get_runner_targets() -> Vec<String> {
    let rustc = var("RUSTC").unwrap();
    let native_target = var("TARGET").unwrap();
    let mut active_targets = Vec::from([native_target]);
    let requested_targets = var(TARGETS_ENV);
    if let Ok(requested_targets) = requested_targets {
        let mut requested_targets = requested_targets.split(';').collect::<Vec<&str>>();
        requested_targets.sort_unstable();
        requested_targets.dedup();
        let available_targets = Command::new(rustc)
            .arg("--print")
            .arg("target-list")
            .output()
            .expect("couldn't get available build target triples");
        let available_targets = String::from_utf8(available_targets.stdout)
            .expect("couldn't get available build target triples, output invalid");
        let available_targets = available_targets.lines().collect::<Vec<&str>>();
        for target in requested_targets {
            if active_targets.contains(&target.to_string()) {
                continue;
            }
            if !available_targets.contains(&target) {
                let matches = available_targets
                    .iter()
                    .filter(|t| t.contains(target))
                    .collect::<Vec<_>>();
                if matches.len() == 1 {
                    active_targets.push(matches[0].to_string());
                } else {
                    panic!(
                        "couldn't build for target {}, target does not exist",
                        &target
                    );
                }
            } else {
                active_targets.push(target.to_string());
            }
        }
    }
    active_targets
}

fn compile_runner(starter_dir: &Path, target: &str, out_dir: &str) -> bool {
    eprintln!("compiling runner for target {}", &target);
    let profile = var("PROFILE").unwrap();
    let native_target = var("TARGET").unwrap();
    let cargo = PathBuf::from(var("CARGO").unwrap()).canonicalize().unwrap();
    let use_cross = var(USE_CROSS_ENV) == Ok("true".into()) || var(USE_CROSS_ENV) == Ok("1".into());
    let mut command = if target == native_target || !use_cross {
        Command::new(cargo)
    } else {
        Command::new(which("cross").unwrap_or(cargo))
    };
    if let Some(hash) = get_git_hash() {
        command.env("GIT_HASH", hash);
    }
    for (env, _) in vars() {
        if env.starts_with("CARGO") {
            command.env_remove(&env);
        }
        if env.starts_with("RUSTC") {
            command.env_remove(&env);
        }
    }
    command.env_remove("HOST");
    if target != native_target {
        command.env_remove("CC");
        command.env_remove("CXX");
        command.env_remove("AR");
    }
    for set in &["CC", "CXX", "AR"] {
        if let Ok(var) = var(format!("WRAPPE_TARGET_{}_{}", set, target)) {
            command.env(set, var);
        }
    }
    let mut rustflags = None;
    if target == native_target {
        if let Ok(var) = var("RUSTFLAGS") {
            rustflags = Some(var);
        }
    }
    if let Ok(var) = var(format!("WRAPPE_TARGET_RUSTFLAGS_{}", target)) {
        rustflags = Some(var);
    }
    if let Some(mut rustflags) = rustflags {
        if !rustflags.contains("-Ctarget-feature") && !rustflags.contains("-C target-feature") {
            rustflags = format!("{} -Ctarget-feature=+crt-static", rustflags);
        }
        command.env("RUSTFLAGS", rustflags);
    } else {
        command.env("RUSTFLAGS", "-Ctarget-feature=+crt-static");
    }
    command
        .current_dir(starter_dir)
        .arg("build")
        .arg("--target")
        .arg(target)
        .arg("--target-dir")
        .arg(out_dir);
    if profile == "release" {
        command.arg("--release");
    }
    eprintln!("running {:?}", command);
    let status = command
        .status()
        .unwrap_or_else(|e| panic!("couldn't compile runner for target {}: {}", &target, e));
    if status.success() {
        if let Ok(var) = var(format!("WRAPPE_TARGET_STRIP_{}", target)) {
            strip_runner(target, out_dir, &profile, &var).unwrap();
        }
    }
    status.success()
}

fn strip_runner(target: &str, out_dir: &str, profile: &str, strip: &str) -> Option<()> {
    eprintln!("stripping runner for target {} with {}", target, strip);
    let strip = if strip.starts_with('"') && strip.ends_with('"') {
        &strip[1..strip.len() - 1]
    } else {
        strip
    };
    let (strip, args) = strip.split_once(' ').unwrap_or((strip, ""));
    let strip = which(strip.trim())
        .map_err(|e| {
            eprintln!("couldn't find strip for target {}: {}", target, e);
        })
        .ok()?;
    let args = args
        .split(' ')
        .map(|arg| arg.trim())
        .filter(|arg| !arg.is_empty());
    let mut command = Command::new(strip);
    let path = format!(
        "{}/{}/{}/{}{}",
        out_dir,
        target,
        profile,
        STARTER_NAME,
        if target.contains("windows") {
            ".exe"
        } else {
            ""
        }
    );
    command.args(args).arg(path);
    let status = command
        .status()
        .map_err(|e| eprintln!("couldn't strip runner for target {}: {}", target, e))
        .ok()?;
    status.success().then_some(())
}

fn create_universal_macos_binary(
    files: &[(String, String)], combine: &[&str], out_dir: &str,
) -> Option<String> {
    let lipo = which("lipo")
        .map_err(|e| {
            eprintln!("couldn't find lipo for creating universal binary: {}", e);
        })
        .ok()?;
    let universal = format!("{}/universal", out_dir);
    create_dir_all(&universal)
        .map_err(|e| {
            eprintln!("couldn't create universal directory: {}", e);
        })
        .ok()?;
    let universal = format!("{}/{}", universal, STARTER_NAME);
    let mut args = ["-create", "-output", &universal].to_vec();
    args.extend(combine.iter().map(|target| {
        files
            .iter()
            .find(|(t, _)| t == target)
            .map(|(_, file)| file.deref())
            .unwrap()
    }));
    let status = Command::new(lipo)
        .args(args)
        .status()
        .map_err(|e| eprintln!("couldn't create universal binary: {}", e))
        .ok()?;
    if status.success() {
        Some(universal)
    } else {
        None
    }
}

fn get_git_hash() -> Option<String> {
    if !Path::new(".git").is_dir() {
        return None;
    }
    which("git").ok().and_then(|git| {
        Command::new(git)
            .args(["rev-parse", "--short", "HEAD"])
            .output()
            .ok()
            .and_then(|output| {
                String::from_utf8(output.stdout)
                    .map(|output| output.trim().into())
                    .ok()
            })
    })
}

fn unpack_starter(target: &str) -> PathBuf {
    if PathBuf::from(STARTER_NAME).is_dir() {
        return PathBuf::from(STARTER_NAME);
    }
    eprintln!("unpacking starter {}.tar", STARTER_NAME);
    let tar_path = PathBuf::from(STARTER_NAME).with_extension("tar");
    if !tar_path.is_file() {
        panic!("couldn't find {}.tar", STARTER_NAME);
    }
    let tar = File::open(tar_path)
        .unwrap_or_else(|err| panic!("couldn't open {}.tar: {}", STARTER_NAME, err));
    let mut archive = Archive::new(tar);
    let target_dir = PathBuf::from(target).join(STARTER_NAME);
    archive
        .unpack(&target_dir)
        .unwrap_or_else(|err| panic!("couldn't unpack {}.tar: {}", STARTER_NAME, err));
    target_dir
}

fn main() {
    println!("cargo:rerun-if-env-changed=OUT_DIR");
    println!("cargo:rerun-if-env-changed=PROFILE");
    println!("cargo:rerun-if-env-changed=TARGET");
    println!("cargo:rerun-if-env-changed={}", TARGETS_ENV);
    println!("cargo:rerun-if-changed=build.rs");
    if let Some(hash) = get_git_hash() {
        println!("cargo:rustc-env=GIT_HASH={}", hash);
        println!(
            "cargo:rustc-env=CARGO_PKG_VERSION={} ({})",
            var("CARGO_PKG_VERSION").unwrap(),
            hash
        );
    }
    println!("cargo:rerun-if-changed=.git/HEAD");
    let out_dir = var("OUT_DIR").unwrap();
    let starter_dir = unpack_starter(&out_dir);
    for entry in WalkDir::new(&starter_dir)
        .into_iter()
        .filter_map(|e| e.ok())
    {
        println!("cargo:rerun-if-changed={}", entry.path().display());
    }
    if let Ok(macosx_target) = var("MACOSX_DEPLOYMENT_TARGET") {
        println!("cargo:rustc-env=MACOSX_DEPLOYMENT_TARGET={}", macosx_target);
    }
    let active_targets = get_runner_targets();
    for target in &active_targets {
        let status = compile_runner(&starter_dir, target, &out_dir);
        if !status {
            panic!("couldn't build for target {}, build failed", target);
        }
    }
    let profile = var("PROFILE").unwrap();
    let mut files = active_targets
        .iter()
        .map(|target| {
            (
                target.clone(),
                format!(
                    "{}/{}/{}/{}{}",
                    out_dir,
                    target,
                    profile,
                    STARTER_NAME,
                    if target.contains("windows") {
                        ".exe"
                    } else {
                        ""
                    }
                ),
            )
        })
        .collect::<Vec<_>>();
    if let Ok(macos_universal) = var(MACOS_UNIVERSAL_ENV) {
        let combine = macos_universal
            .split(';')
            .map(|c| c.trim())
            .collect::<Vec<_>>();
        if combine
            .iter()
            .all(|target| active_targets.contains(&target.to_string()))
        {
            let file = create_universal_macos_binary(&files, &combine, &out_dir).unwrap();
            files.push(("universal-apple-darwin".to_string(), file));
        } else {
            panic!(
                "couldn't create universal binary, target {} not in active targets",
                combine
                    .iter()
                    .find(|target| !active_targets.contains(&target.to_string()))
                    .unwrap()
            );
        }
    }
    let targets = files
        .iter()
        .map(|(target, _)| target.clone())
        .collect::<Vec<_>>()
        .join(";");
    let files = files
        .iter()
        .map(|(_, file)| file.clone())
        .collect::<Vec<_>>()
        .join(";");
    println!("cargo:rustc-env={}={}", TARGETS_ENV, targets);
    println!("cargo:rustc-env={}={}", FILES_ENV, files);
}

```

`src/args.rs`:

```rs
use std::{
    ffi::OsString,
    path::{Path, PathBuf},
};

use console::style;
use rand::{
    distributions::{Alphanumeric, Distribution},
    thread_rng,
};
use staticfilemap::StaticFileMap;

use crate::types::{ARGS_SIZE, NAME_SIZE};

#[derive(StaticFileMap)]
#[parse("env")]
#[names("WRAPPE_TARGETS")]
#[files("WRAPPE_FILES")]
#[compression(16)]
#[algorithm("zstd")]
struct StarterMap;

pub fn list_runners() {
    println!("{}:", style("available runners").blue().bright());
    println!(
        "  {} {}",
        StarterMap::keys()[0],
        style("(default)").bold().dim()
    );
    for runner in &StarterMap::keys()[1..] {
        println!("  {}", runner);
    }
}

pub fn get_runner_name(name: &str) -> &'static str {
    if name == "native" || name == "default" {
        return StarterMap::keys()[0];
    }
    StarterMap::get_match_index(name)
        .map(|id| StarterMap::keys()[id])
        .unwrap_or_else(|| {
            println!(
                "{}: {}",
                style("not a valid runner").red(),
                style(name).red()
            );
            list_runners();
            std::process::exit(-1);
        })
}

pub fn get_runner(name: &str) -> &'static [u8] {
    let runner_name = if name == "native" || name == "default" {
        StarterMap::keys()[0]
    } else {
        name
    };
    StarterMap::get_match(runner_name).unwrap_or_else(|| {
        println!(
            "{}: {}",
            style("not a valid runner").red(),
            style(runner_name).red()
        );
        list_runners();
        std::process::exit(-1);
    })
}

pub fn get_unpack_target(directory: &str) -> u8 {
    match directory.to_lowercase().as_str() {
        "temp" => 0,
        "default" => 0,
        "local" => 1,
        "cwd" => 2,
        _ => {
            println!(
                "{}: {}",
                style("not a valid target directory").red(),
                style(directory).red(),
            );
            println!(
                "{}: temp {}, local, cwd",
                style("available target directories").blue().bright(),
                style("(default)").bold().dim()
            );
            std::process::exit(-1);
        }
    }
}

pub fn get_versioning(versioning: &str) -> u8 {
    match versioning.to_lowercase().as_str() {
        "sidebyside" => 0,
        "default" => 0,
        "replace" => 1,
        "none" => 2,
        _ => {
            println!(
                "{}: {}",
                style("not a valid versioning strategy").red(),
                style(versioning).red(),
            );
            println!(
                "{}: sidebyside {}, replace",
                style("available versioning strategies").blue().bright(),
                style("(default)").bold().dim()
            );
            std::process::exit(-1);
        }
    }
}

pub fn get_version(version: Option<&str>) -> String {
    let mut version = if let Some(version) = version {
        if version.len() > 16 {
            println!(
                "{}",
                style("version specifier is longer than 16 characters").red(),
            );
            std::process::exit(-1);
        }
        if version.is_empty() {
            println!("{}", style("version specifier is empty").red());
            std::process::exit(-1);
        }
        version.chars().collect::<Vec<_>>()
    } else {
        Alphanumeric
            .sample_iter(thread_rng())
            .map(char::from)
            .take(8)
            .collect::<Vec<_>>()
    };
    version.resize(16, 0 as char);
    version.iter().collect()
}

pub fn get_verification(verification: &str) -> u8 {
    match verification.to_lowercase().as_str() {
        "none" => 0,
        "default" => 1,
        "existence" => 1,
        "checksum" => 2,
        _ => {
            println!(
                "{}: {}",
                style("not a valid verification option").red(),
                style(verification).red(),
            );
            println!(
                "{}: none, existence {}, checksum",
                style("available verification options").blue().bright(),
                style("(default)").bold().dim()
            );
            std::process::exit(-1);
        }
    }
}

pub fn get_show_information(show_information: &str) -> u8 {
    match show_information.to_lowercase().as_str() {
        "none" => 0,
        "default" => 1,
        "title" => 1,
        "verbose" => 2,
        _ => {
            println!(
                "{}: {}",
                style("not a valid information details option").red(),
                style(show_information).red(),
            );
            println!(
                "{}: none, title {}, verbose",
                style("available information details options")
                    .blue()
                    .bright(),
                style("(default)").bold().dim()
            );
            std::process::exit(-1);
        }
    }
}

pub fn get_show_console(show_console: &str, runner_name: &str) -> u8 {
    match show_console.to_lowercase().as_str() {
        "auto" => {
            if runner_name.contains("windows") {
                0
            } else {
                1
            }
        }
        "never" => 0,
        "always" => 1,
        "attach" => 2,
        _ => {
            println!(
                "{}: {}",
                style("not a valid console option").red(),
                style(show_console).red(),
            );
            println!(
                "{}: auto {}, always, never",
                style("available console options").blue().bright(),
                style("(default)").bold().dim()
            );
            std::process::exit(-1);
        }
    }
}

pub fn get_current_dir(current_dir: &str) -> u8 {
    match current_dir.to_lowercase().as_str() {
        "inherit" => 0,
        "unpack" => 1,
        "runner" => 2,
        "command" => 3,
        _ => {
            println!(
                "{}: {}",
                style("not a valid current directory option").red(),
                style(current_dir).red(),
            );
            println!(
                "{}: inherit {}, directory, runner, command",
                style("available current directory options").blue().bright(),
                style("(default)").bold().dim()
            );
            std::process::exit(-1);
        }
    }
}

pub fn get_source(source: &Path) -> PathBuf {
    let source = Path::new(&std::env::current_dir().unwrap()).join(source);
    let source = std::fs::canonicalize(&source).unwrap_or_else(|_| {
        println!(
            "{}: {}",
            style("input path does not exist").red(),
            source.display()
        );
        std::process::exit(-1);
    });
    if !source.is_dir() && !source.is_file() {
        println!(
            "{}: {}",
            style("input path is not a file or directory").red(),
            source.display()
        );
        std::process::exit(-1);
    }
    source
}

pub fn get_output(output: Option<&Path>, command_path: &Path) -> PathBuf {
    let output = output
        .map(|path| path.as_os_str().to_owned())
        .unwrap_or_else(|| {
            let name = command_path
                .file_name()
                .unwrap_or_else(|| {
                    println!(
                        "{}",
                        style("couldn't infer output path from the command path").red()
                    );
                    std::process::exit(-1);
                })
                .to_owned();
            let mut prefix = OsString::from("packed-");
            prefix.push(name);
            prefix
        });
    let output = Path::new(&std::env::current_dir().unwrap()).join(output);
    if !output.parent().map(|path| path.is_dir()).unwrap_or(false) {
        println!(
            "{}: {}",
            style("output path has no parent directory").red(),
            output.parent().unwrap().display()
        );
        std::process::exit(-1);
    }
    if output.is_dir() {
        println!(
            "{}: {}",
            style("output path is a directory").red(),
            output.display()
        );
        std::process::exit(-1);
    }
    std::fs::canonicalize(output.parent().unwrap())
        .unwrap_or_else(|_| {
            println!(
                "{}: {}",
                style("output path is invalid").red(),
                output.display()
            );
            std::process::exit(-1);
        })
        .join(output.file_name().unwrap())
}

pub fn get_unpack_directory(directory: Option<&str>, source: &Path) -> [u8; NAME_SIZE] {
    let directory = if let Some(directory) = directory {
        directory.as_bytes()
    } else {
        source
            .file_name()
            .unwrap_or_else(|| {
                println!(
                    "{}",
                    style("couldn't infer unpack directory name from the input directory").red()
                );
                std::process::exit(-1);
            })
            .to_str()
            .unwrap_or_else(|| {
                println!(
                    "{}",
                    style("couldn't infer unpack directory name from the input directory, not valid utf8").red()
                );
                std::process::exit(-1);
            })
            .as_bytes()
    };
    if directory.len() >= NAME_SIZE {
        println!(
            "{}",
            style("unpack directory name is longer than 127 characters").red()
        );
        std::process::exit(-1);
    }
    let mut _directory = [0; NAME_SIZE];
    _directory[0..directory.len()].copy_from_slice(directory);
    _directory
}

pub fn get_command_path(command: &Path, source: &Path) -> PathBuf {
    let source = if source.is_file() {
        source.parent().unwrap_or_else(|| {
            println!("{}", style("source path has no parent").red());
            std::process::exit(-1);
        })
    } else {
        source
    };
    let command = match std::fs::canonicalize(source.join(command)) {
        Err(_) => std::fs::canonicalize(Path::new(&std::env::current_dir().unwrap()).join(command)),
        command => command,
    }
    .unwrap_or_else(|e| {
        println!("{}: {}", style("command path is invalid").red(), e);
        std::process::exit(-1);
    });
    if !command.is_file() {
        println!("{}", style("command path is not a file").red());
        std::process::exit(-1);
    }
    let command = if source.is_dir() {
        command.strip_prefix(source).unwrap_or_else(|_| {
            println!(
                "{}",
                style("command path is not contained in the source directory").red()
            );
            std::process::exit(-1);
        })
    } else {
        command.strip_prefix(source).unwrap_or_else(|_| {
            println!(
                "{}",
                style("command path is not contained in the source directory").red()
            );
            std::process::exit(-1);
        })
    };
    command.to_owned()
}

pub fn get_command(command_path: &Path) -> [u8; NAME_SIZE] {
    let command = command_path
        .to_str()
        .unwrap_or_else(|| {
            println!("{}", style("command path is not valid utf8").red());
            std::process::exit(-1);
        })
        .as_bytes();
    if command.len() >= NAME_SIZE {
        println!(
            "{}",
            style("command path is longer than 127 characters").red()
        );
        std::process::exit(-1);
    }
    let mut _command = [0; NAME_SIZE];
    _command[0..command.len()].copy_from_slice(command);
    _command
}

pub fn get_arguments(arguments: &[String]) -> [u8; ARGS_SIZE] {
    let arguments = arguments.join("\u{1f}");
    let arguments = arguments.as_bytes();
    if arguments.len() >= ARGS_SIZE {
        println!(
            "{}",
            style("arguments list is longer than 127 characters").red(),
        );
        std::process::exit(-1);
    }
    let mut _arguments = [0; ARGS_SIZE];
    _arguments[0..arguments.len()].copy_from_slice(arguments);
    _arguments
}

```

`src/compress.rs`:

```rs
use std::{
    env::temp_dir,
    fs::{File, read_link, remove_file, symlink_metadata},
    hash::Hasher,
    io::{BufReader, Cursor, Read, Result, Seek, Write, copy},
    path::Path,
    sync::{
        Arc, Mutex,
        atomic::{AtomicU64, Ordering},
    },
    time::SystemTime,
};

use jwalk::WalkDir;
use path_slash::PathExt;
use rand::{
    distributions::{Alphanumeric, Distribution},
    thread_rng,
};
use rayon::prelude::*;
use sysinfo::System;
use twox_hash::XxHash64;
use zstd::{Encoder, dict::EncoderDictionary};

use crate::types::*;

pub const HASH_SEED: u64 = 1246736989840;

pub struct HashReader<R: Read, H: Hasher> {
    reader: R,
    hasher: H,
}
impl<R: Read, H: Hasher> HashReader<R, H> {
    pub fn new(reader: R, hasher: H) -> Self { HashReader { reader, hasher } }

    pub fn finish(self) -> u64 { self.hasher.finish() }
}
impl<R: Read, H: Hasher> Read for HashReader<R, H> {
    fn read(&mut self, buf: &mut [u8]) -> Result<usize> {
        let bytes = self.reader.read(buf)?;
        if bytes > 0 {
            self.hasher.write(&buf[0..bytes]);
        }
        Ok(bytes)
    }
}

pub fn copy_encode<R: Read, W: Write>(
    mut source: R, destination: W, level: i32, threads: u32, dict: Option<&EncoderDictionary>,
) -> Result<()> {
    let mut encoder = if let Some(dict) = dict {
        Encoder::with_prepared_dictionary(destination, dict)?
    } else {
        Encoder::new(destination, level)?
    };
    encoder.multithread(threads)?;
    copy(&mut source, &mut encoder)?;
    encoder.finish()?;
    Ok(())
}

/// Compress the payload in `source` and write it into `target`.
/// The data is written subsequently in the following order:
/// - compressed file contents
/// - compression dictionary
/// - compressed sections
///   - directory sections
///   - file section headers
///   - symlink sections
/// - payload section header
#[allow(clippy::too_many_arguments)]
pub fn compress<
    T: AsRef<Path>,
    W: Write + Seek + Sync + Send,
    X: AsRef<Path>,
    P: Fn() + Sync + Send,
    E: Fn(&str) + Sync + Send,
    S: Fn(&str) + Sync + Send,
    I: Fn(&str) + Sync + Send,
>(
    source: T, target: &mut W, exclude: X, compression: u32, build_dict: bool,
    progress_callback: P, error_callback: E, step_callback: S, info_callback: I,
) -> (u64, u64, u64) {
    let source: &Path = source.as_ref();
    let exclude: &Path = exclude.as_ref();

    let num_cpus = num_cpus::get() as u64;
    let system = System::new_with_specifics(
        sysinfo::RefreshKind::new().with_memory(sysinfo::MemoryRefreshKind::new().with_ram()),
    );
    let memory = system.total_memory();
    let in_memory_limit = memory / num_cpus * 1000;

    let entries = WalkDir::new(source)
        .skip_hidden(false)
        .sort(true)
        .into_iter()
        .filter(|entry| {
            if let Err(e) = entry {
                error_callback(&format!("couldn't read entry: {}", e));
                return false;
            }
            true
        })
        .collect::<Vec<_>>();

    let source: &Path = if source.is_dir() {
        source
    } else {
        source.parent().unwrap()
    };

    // create compression dictionary
    let dictionary_data = if build_dict {
        step_callback("creating compression dictionary");
        let mut sizes = Vec::new();
        let mut sample = Vec::new();
        let _ = entries
            .iter()
            .filter_map(|entry| {
                // zstd dictionary data is limited to 4GB
                if sample.len() >= 4 * 1024 * 1024 * 1024 - 128 * 1024 {
                    return None;
                }
                let entry = entry.as_ref().ok()?;
                if !entry.file_type().is_file() {
                    return None;
                }
                let entry = entry.path();
                if entry == exclude {
                    return None;
                }
                if entry.file_name()?.len() > NAME_SIZE {
                    return None;
                }
                let file = File::open(&entry).ok()?;
                let size = BufReader::new(file.take(128 * 1024))
                    .read_to_end(&mut sample)
                    .ok()?;
                sizes.push(size);
                Some(())
            })
            .count();
        if sizes.len() < 8 {
            error_callback("couldn't build dictionary: not enough samples");
            None
        } else {
            let dict = zstd::dict::from_continuous(&sample, &sizes, 128 * 1024).unwrap();
            info_callback(&format!(
                "built {:.2}MB dictionary from {:.2}MB of data",
                dict.len() as f64 / 1024.0 / 1024.0,
                sample.len() as f64 / 1024.0 / 1024.0
            ));
            Some(dict)
        }
    } else {
        None
    };

    let dictionary = dictionary_data
        .as_ref()
        .map(|dict| EncoderDictionary::copy(dict, compression as i32));

    let mut directories = Vec::<DirectorySection>::new();
    // start with the source directory as parent 0
    let mut parents = Vec::<String>::from(["".to_string()]);

    // enumerate directories
    let _ = entries
        .iter()
        .filter_map(|entry| {
            let entry = entry.as_ref().ok()?;
            if !entry.file_type().is_dir() {
                return None;
            }
            let entry = entry.path();
            if entry == exclude {
                error_callback(&format!("skipping excluded file: {}", entry.display()));
                return None;
            }
            let entry = entry.strip_prefix(source).ok()?;

            if entry.file_name()?.len() > NAME_SIZE {
                error_callback(&format!(
                    "skipping directory with name longer than {}: {}",
                    NAME_SIZE,
                    entry.display()
                ));
                return None;
            }

            step_callback(&entry.display().to_string());

            let name = entry.file_name()?.to_str()?;

            parents.push(entry.to_slash()?.into_owned());

            let parent = entry.parent().unwrap().to_slash().unwrap();
            let parent = match parents.iter().position(|element| element == &parent) {
                Some(index) => index,
                None => {
                    error_callback(&format!(
                        "skipping directory with no included parent: {}",
                        entry.display()
                    ));
                    return None;
                }
            };

            let mut name_array = [0; NAME_SIZE];
            name_array[0..name.len()].copy_from_slice(name.as_bytes());
            directories.push(DirectorySection {
                name:   name_array,
                parent: parent as u32,
            });

            progress_callback();
            Some(())
        })
        .count();

    let zero = target.stream_position().unwrap();
    let archive = Arc::new(Mutex::new(target));

    let files = Arc::new(Mutex::new(Vec::<FileSectionHeader>::new()));
    let links = Arc::new(Mutex::new(Vec::<String>::new()));

    let read = AtomicU64::new(0);

    // compress and append files
    let _ = entries
        .par_iter()
        .filter_map(|entry| {
            let entry = entry.as_ref().ok()?;
            if !entry.file_type().is_file() {
                return None;
            }
            let entry = entry.path();
            if entry == exclude {
                error_callback(&format!("skipping excluded file: {}", entry.display()));
                return None;
            }

            if entry.file_name()?.len() > NAME_SIZE {
                error_callback(&format!(
                    "skipping file with name longer than: {}: {}",
                    NAME_SIZE,
                    entry.display()
                ));
                return None;
            }

            step_callback(&entry.strip_prefix(source).ok()?.display().to_string());

            let parent = entry.strip_prefix(source).ok()?.parent()?.to_slash()?;
            let parent = match parents.iter().position(|element| element == &parent) {
                Some(index) => index,
                None => {
                    error_callback(&format!(
                        "skipping file with no included parent: {}",
                        entry.display()
                    ));
                    return None;
                }
            };

            let name = entry.file_name()?.to_str()?;

            let file = File::open(&entry);
            if let Err(e) = file {
                error_callback(&format!("couldn't open {}: {}", entry.display(), e));
                return None;
            }
            let file = file.ok()?;

            let mut in_memory = true;
            let mut meta_len = 0;
            let meta = file.metadata();
            if let Ok(ref meta) = meta {
                meta_len = meta.len();
                if meta_len > in_memory_limit {
                    in_memory = false;
                }
            }

            let mut start = 0;
            let mut end = 0;
            let mut compressed_hash = 0;
            let mut reader = HashReader::new(file, XxHash64::with_seed(HASH_SEED));

            if in_memory {
                let mut data = Vec::new();
                let mut reader = BufReader::new(&mut reader);
                if let Err(e) = copy_encode(
                    &mut reader,
                    &mut data,
                    compression as i32,
                    0,
                    dictionary.as_ref(),
                ) {
                    error_callback(&format!("couldn't compress {}: {}", entry.display(), e));
                    return None;
                }

                let mut archive = archive.lock();
                if let Ok(ref mut archive) = archive {
                    start = archive.stream_position().unwrap();
                    let mut hasher =
                        HashReader::new(Cursor::new(&data), XxHash64::with_seed(HASH_SEED));
                    if let Err(e) = copy(&mut hasher, archive.by_ref()) {
                        error_callback(&format!(
                            "couldn't write {} to archive: {}",
                            entry.display(),
                            e
                        ));
                        return None;
                    }
                    compressed_hash = hasher.finish();
                    end = archive.stream_position().unwrap();
                }
            } else {
                step_callback(&format!(
                    "{} (compressing large file to disk)",
                    entry.display(),
                ));
                let cache_path = temp_dir().join(
                    Alphanumeric
                        .sample_iter(thread_rng())
                        .map(char::from)
                        .take(16)
                        .collect::<String>(),
                );

                if let Err(e) = (|| -> Result<()> {
                    let mut reader = BufReader::new(&mut reader);
                    let mut cache = File::create(&cache_path)?;
                    copy_encode(
                        &mut reader,
                        &cache,
                        compression as i32,
                        u64::min(num_cpus / 2, meta_len / in_memory_limit + 1) as u32,
                        dictionary.as_ref(),
                    )?;
                    cache.flush()?;
                    cache.sync_all()?;
                    Ok(())
                })() {
                    error_callback(&format!("couldn't compress {}: {}", entry.display(), e));
                    return None;
                }

                if let Err(e) = (|| -> Result<()> {
                    let cache = File::open(&cache_path)?;
                    let mut reader = BufReader::new(&cache);
                    let mut archive = archive.lock();
                    let mut hasher = HashReader::new(&mut reader, XxHash64::with_seed(HASH_SEED));
                    if let Ok(ref mut archive) = archive {
                        start = archive.stream_position().unwrap();
                        copy(&mut hasher, archive.by_ref())?;
                        end = archive.stream_position().unwrap();
                    }
                    compressed_hash = hasher.finish();
                    Ok(())
                })() {
                    error_callback(&format!(
                        "couldn't write {} to archive: {}",
                        entry.display(),
                        e
                    ));
                    return None;
                }

                let _ = remove_file(cache_path);
            }
            let file_hash = reader.finish();

            read.fetch_add(meta_len, Ordering::AcqRel);

            let mut name_array = [0; NAME_SIZE];
            name_array[0..name.len()].copy_from_slice(name.as_bytes());
            let mut header = FileSectionHeader {
                name: name_array,
                parent: parent as u32,
                position: start - zero,
                size: end - start,
                file_hash,
                compressed_hash,
                time_accessed_nanos: 0,
                time_accessed_seconds: 0,
                time_modified_nanos: 0,
                time_modified_seconds: 0,
                mode: 0,
                readonly: 0,
            };

            if let Ok(ref meta) = meta {
                if let Ok(accessed) = meta.accessed() {
                    if let Ok(accessed) = accessed.duration_since(SystemTime::UNIX_EPOCH) {
                        header.time_accessed_seconds = accessed.as_secs();
                        header.time_accessed_nanos = accessed.subsec_nanos();
                    }
                }
                if let Ok(modified) = meta.modified() {
                    if let Ok(modified) = modified.duration_since(SystemTime::UNIX_EPOCH) {
                        header.time_modified_seconds = modified.as_secs();
                        header.time_modified_nanos = modified.subsec_nanos();
                    }
                }
                header.readonly = meta.permissions().readonly() as u8;
                #[cfg(any(unix, target_os = "redox"))]
                {
                    use std::os::unix::fs::PermissionsExt;
                    header.mode = meta.permissions().mode();
                }
            }

            let mut files = files.lock();
            if let Ok(ref mut files) = files {
                files.push(header);
                let mut links = links.lock();
                if let Ok(ref mut links) = links {
                    links.push(entry.strip_prefix(source).ok()?.to_slash()?.into_owned());
                }
            }

            progress_callback();
            Some(())
        })
        .count();

    let symlinks = Arc::new(Mutex::new(Vec::<SymlinkSection>::new()));

    // enumerate symlinks
    let _ = entries
        .par_iter()
        .filter_map(|entry| {
            let entry = entry.as_ref().ok()?;
            if !entry.file_type().is_symlink() {
                return None;
            }
            let entry = entry.path();
            if entry == exclude {
                error_callback(&format!("skipping excluded file: {}", entry.display()));
                return None;
            }

            if entry.file_name()?.len() > NAME_SIZE {
                error_callback(&format!(
                    "skipping file with name longer than: {}: {}",
                    NAME_SIZE,
                    entry.display()
                ));
                return None;
            }

            step_callback(&entry.strip_prefix(source).ok()?.display().to_string());

            let parent = entry.strip_prefix(source).ok()?.parent()?.to_slash()?;
            let parent = match parents.iter().position(|element| element == &parent) {
                Some(index) => index,
                None => {
                    error_callback(&format!(
                        "skipping file with no included parent: {}",
                        entry.display()
                    ));
                    return None;
                }
            };

            let meta = symlink_metadata(&entry);
            let name = entry.file_name()?.to_str()?;

            let link = read_link(&entry);
            if let Err(ref e) = link {
                error_callback(&format!("couldn't read link {}: {}", entry.display(), e));
                return None;
            }
            let link = link.ok()?;
            let link = link.strip_prefix(".").unwrap_or(&link);
            let link = entry.parent().unwrap().join(link);
            let link = link.canonicalize();
            if let Err(e) = link {
                error_callback(&format!(
                    "link could not be canonicalized, skipping {}: {}",
                    entry.display(),
                    e
                ));
                return None;
            }
            let link = link.ok()?;
            let is_file = link.is_file();
            let link = link.strip_prefix(source);
            if let Err(e) = link {
                error_callback(&format!(
                    "link points to outside the directory, skipping {}: {}",
                    entry.display(),
                    e
                ));
                return None;
            }
            let link = link.ok()?;

            let target = if is_file {
                let link = link.to_slash()?;
                match links
                    .lock()
                    .unwrap()
                    .iter()
                    .position(|element| element == &link)
                {
                    Some(index) => index,
                    None => {
                        error_callback(&format!(
                            "skipping link with no included target: {}",
                            entry.display()
                        ));
                        return None;
                    }
                }
            } else {
                let link = link.to_slash()?;
                match parents.iter().position(|element| element == &link) {
                    Some(index) => index,
                    None => {
                        error_callback(&format!(
                            "skipping link with no included target: {}",
                            entry.display()
                        ));
                        return None;
                    }
                }
            };

            let mut name_array = [0; NAME_SIZE];
            name_array[0..name.len()].copy_from_slice(name.as_bytes());
            let mut header = SymlinkSection {
                name:                  name_array,
                parent:                parent as u32,
                kind:                  is_file as u8,
                target:                target as u32,
                time_accessed_nanos:   0,
                time_accessed_seconds: 0,
                time_modified_nanos:   0,
                time_modified_seconds: 0,
                mode:                  0,
                readonly:              0,
            };

            if let Ok(ref meta) = meta {
                if let Ok(accessed) = meta.accessed() {
                    if let Ok(accessed) = accessed.duration_since(SystemTime::UNIX_EPOCH) {
                        header.time_accessed_seconds = accessed.as_secs();
                        header.time_accessed_nanos = accessed.subsec_nanos();
                    }
                }
                if let Ok(modified) = meta.modified() {
                    if let Ok(modified) = modified.duration_since(SystemTime::UNIX_EPOCH) {
                        header.time_modified_seconds = modified.as_secs();
                        header.time_modified_nanos = modified.subsec_nanos();
                    }
                }
                header.readonly = meta.permissions().readonly() as u8;
                #[cfg(any(unix, target_os = "redox"))]
                {
                    use std::os::unix::fs::PermissionsExt;
                    header.mode = meta.permissions().mode();
                }
            }

            let mut symlinks = symlinks.lock();
            if let Ok(ref mut symlinks) = symlinks {
                symlinks.push(header);
            }

            progress_callback();
            Some(())
        })
        .count();

    let mut target = archive.lock().unwrap();
    let end = target.stream_position().unwrap();

    // write sections
    let mut hasher = XxHash64::with_seed(HASH_SEED);
    if let Some(dict) = &dictionary_data {
        target.write_all(dict).unwrap();
    }
    let sections_buffer = Vec::new();
    let mut sections_buffer = Cursor::new(sections_buffer);
    for section in directories.iter() {
        hasher.write(section.as_bytes());
        sections_buffer.write_all(section.as_bytes()).unwrap();
    }
    for section in files.lock().unwrap().iter() {
        hasher.write(section.as_bytes());
        sections_buffer.write_all(section.as_bytes()).unwrap();
    }
    for section in symlinks.lock().unwrap().iter() {
        hasher.write(section.as_bytes());
        sections_buffer.write_all(section.as_bytes()).unwrap();
    }
    let sections_buffer = sections_buffer.into_inner();
    let mut sections_buffer = Cursor::new(&sections_buffer);
    let sections_start = target.stream_position().unwrap();
    copy_encode(
        &mut sections_buffer,
        target.by_ref(),
        compression as i32,
        0,
        None,
    )
    .unwrap();
    let sections_size = target.stream_position().unwrap() - sections_start;

    // write payload header
    let payload_header = PayloadHeader {
        kind: 0,
        directory_sections: directories.len() as u64,
        file_sections: files.lock().unwrap().len() as u64,
        symlink_sections: symlinks.lock().unwrap().len() as u64,
        dictionary_size: dictionary_data.map_or(0, |dict| dict.len() as u64),
        section_hash: hasher.finish(),
        payload_size: end - zero,
        sections_size,
    };
    target.write_all(payload_header.as_bytes()).unwrap();
    target.flush().unwrap();
    let written = target.stream_position().unwrap();

    (
        payload_header.len() as u64,
        read.load(Ordering::Acquire),
        written - zero,
    )
}

```

`src/main.rs`:

```rs
use std::{
    error::Error,
    fs::File,
    io::{BufWriter, Cursor, Write},
    path::PathBuf,
    time::{Duration, SystemTime},
};

use clap::Parser;
use console::{Emoji, style};
use editpe::Image;
use indicatif::{ProgressBar, ProgressStyle};
use jwalk::WalkDir;
use zstd::stream::copy_decode;

mod types;
use types::*;

mod compress;
use compress::compress;

mod args;
use args::*;

#[derive(Parser)]
#[clap(about)]
pub struct Args {
    /// Platform to pack for (see --list-runners for available options)
    #[arg(short = 'r', long, default_value = "native")]
    runner:           String,
    /// Zstd compression level (0-22)
    #[arg(short = 'c', long, default_value = "8")]
    compression:      u32,
    /// Unpack directory target (temp, local, cwd)
    #[arg(short = 't', long, default_value = "temp")]
    unpack_target:    String,
    /// Unpack directory name [default: inferred from input directory]
    #[arg(short = 'd', long)]
    unpack_directory: Option<String>,
    /// Versioning strategy (sidebyside, replace, none)
    #[arg(short = 'v', long, default_value = "sidebyside")]
    versioning:       String,
    /// Verification of existing unpacked data (existence, checksum, none)
    #[arg(short = 'e', long, default_value = "existence")]
    verification:     String,
    /// Version string override [default: randomly generated]
    #[arg(short = 's', long)]
    version_string:   Option<String>,
    /// Information output details (title, verbose, none)
    #[arg(short = 'i', long, default_value = "title")]
    show_information: String,
    /// Show or attach to a console window (auto, always, never, attach)
    #[arg(short = 'n', long, default_value = "auto")]
    console:          String,
    /// Working directory of the command (inherit, unpack, runner, command)
    #[arg(short = 'w', long, default_value = "inherit")]
    current_dir:      String,
    /// Cleanup the unpack directory after exit
    #[arg(short = 'u', long, default_value = "false")]
    cleanup:          bool,
    /// Only allow one instance of the application to run
    #[arg(short = 'o', long, default_value = "false")]
    once:             bool,
    /// Build compression dictionary
    #[arg(short = 'z', long, default_value = "false")]
    build_dictionary: bool,
    /// Print available runners
    #[arg(short = 'l', long)]
    #[allow(dead_code)]
    list_runners:     bool,
    /// Path to the input directory
    #[arg(name = "input")]
    input:            PathBuf,
    /// Path to the executable to start after unpacking
    #[arg(name = "command")]
    command:          PathBuf,
    /// Path to or filename of the output executable
    #[arg(name = "output")]
    output:           Option<PathBuf>,
    /// Command line arguments to pass to the executable
    #[arg(last = true)]
    arguments:        Vec<String>,
    /// Print version
    #[arg(short = 'V', long)]
    #[allow(dead_code)]
    version:          bool,
}

fn main() {
    color_backtrace::install();

    if std::env::args().any(|arg| arg == "-l" || arg == "--list-runners") {
        list_runners();
        std::process::exit(0);
    }

    println!(
        "{}",
        style(format!(
            "{} {}",
            env!("CARGO_PKG_NAME"),
            env!("CARGO_PKG_VERSION"),
        ))
        .bold()
        .bright(),
    );

    if std::env::args().any(|arg| arg == "-V" || arg == "--version") {
        std::process::exit(0);
    }

    let args = Args::parse();

    let runner = get_runner(&args.runner);
    let runner_name = get_runner_name(&args.runner);
    let unpack_target = get_unpack_target(&args.unpack_target);
    let versioning = get_versioning(&args.versioning);
    let version = get_version(args.version_string.as_deref());
    let source = get_source(&args.input);
    let command_path = get_command_path(&args.command, &source);
    let command = get_command(&command_path);
    let output = get_output(args.output.as_deref(), &command_path);
    let unpack_directory = get_unpack_directory(args.unpack_directory.as_deref(), &source);
    let verification = get_verification(&args.verification);
    let show_information = get_show_information(&args.show_information);
    let arguments = get_arguments(&args.arguments);
    let current_dir = get_current_dir(&args.current_dir);

    let mut show_console = get_show_console(&args.console, runner_name);
    let once = if args.once { 1 } else { 0 };
    let cleanup = if args.cleanup { 1 } else { 0 };

    if (versioning == 1 || versioning == 2) && once == 0 {
        println!(
            "{} {} {} {} {}",
            style("note: chosen versioning").yellow().dim(),
            style(&args.versioning).yellow().bold(),
            style("without option").yellow().dim(),
            style("once").yellow().bold(),
            style("can cause unpacking to fail while the application is already running").dim(),
        );
    }
    if versioning == 2 && verification != 0 {
        println!(
            "{} {} {}",
            style("note: verification will be ignored with")
                .yellow()
                .dim(),
            style(&args.versioning).yellow().bold(),
            style("versioning").yellow().dim(),
        );
    }
    if once == 1 && !(runner_name.contains("windows") || runner_name.contains("linux")) {
        println!(
            "{} {} {} {}",
            style("note: option").yellow().dim(),
            style("once").yellow().bold(),
            style("is only supported for Windows and Linux runners")
                .yellow()
                .dim(),
            style(format!("(target: {})", runner_name)).yellow().dim(),
        );
    }
    if show_console != 2 && !runner_name.contains("windows") {
        println!(
            "{}",
            style("note: setting console mode is only supported for Windows runners")
                .yellow()
                .dim(),
        );
    }

    if output == source {
        println!(
            "{}: {}",
            style("output file can't be the input file").red(),
            output.display()
        );
        std::process::exit(-1);
    }
    let file = File::create(&output).unwrap_or_else(|_| {
        println!(
            "{}: {}",
            style("couldn't create output file").red(),
            output.display()
        );
        std::process::exit(-1);
    });

    let canonical_current_dir = std::fs::canonicalize(std::env::current_dir().unwrap()).unwrap();
    let relative_source = source
        .strip_prefix(&canonical_current_dir)
        .unwrap_or(&source);
    let relative_source = if relative_source.components().count() == 0 {
        &canonical_current_dir
    } else {
        relative_source
    };
    let count = if source.is_dir() {
        println!(
            "{} {}counting contents of {}…",
            style("[1/4]").bold().dim(),
            Emoji("🔍 ", ""),
            style(relative_source.display()).blue().bright()
        );
        WalkDir::new(&source).skip_hidden(false).into_iter().count() as u64 - 1
    } else {
        println!(
            "{} {}checking {}…",
            style("[1/4]").bold().dim(),
            Emoji("🔍 ", ""),
            style(relative_source.display()).blue().bright()
        );
        1
    };

    println!(
        "{} {}writing runner {} for target {}…",
        style("[2/4]").bold().dim(),
        Emoji("📃 ", ""),
        style(
            &output
                .strip_prefix(&canonical_current_dir)
                .unwrap_or(&output)
                .display()
        )
        .blue()
        .bright(),
        style(&runner_name).magenta(),
    );
    let mut writer = BufWriter::new(file);
    if runner_name.contains("windows") {
        let mut decompressed = Vec::new();
        copy_decode(Cursor::new(runner), &mut decompressed).unwrap();

        let decompressed = (|| -> Result<Vec<u8>, Box<dyn Error>> {
            let mut runner_image = Image::parse(&decompressed)?;
            runner_image.set_subsystem(if show_console == 1 { 3 } else { 2 });
            Ok(runner_image.data().to_owned())
        })()
        .unwrap_or_else(|error| {
            println!(
                "      {}{} {}",
                Emoji("❗ ", ""),
                style("failed to set subsystem for runner:").yellow(),
                style(error).yellow()
            );
            decompressed
        });
        let decompressed = (|| -> Result<Vec<u8>, Box<dyn Error>> {
            let mut runner_image = Image::parse(&decompressed)?;
            let command_path = if source.is_file() {
                source.clone()
            } else {
                source.join(get_command_path(&args.command, &source))
            };
            let command_data = std::fs::read(command_path)?;
            let command_image = Image::parse(command_data)?;
            let command_resources = command_image
                .resource_directory()
                .cloned()
                .unwrap_or_default();
            if args.console == "auto" {
                show_console = if command_image.subsystem() == 3 { 1 } else { 0 };
                runner_image.set_subsystem(command_image.subsystem());
            }
            runner_image.set_resource_directory(command_resources)?;
            Ok(runner_image.data().to_owned())
        })()
        .unwrap_or_else(|error| {
            println!(
                "      {}{} {}",
                Emoji("❗ ", ""),
                style("failed to copy resources to runner:").yellow(),
                style(error).yellow()
            );
            decompressed
        });

        writer.write_all(&decompressed).unwrap();
    } else {
        copy_decode(Cursor::new(&runner), &mut writer).unwrap();
    }

    println!(
        "{} {}compressing {} files and directories…",
        style("[3/4]").bold().dim(),
        Emoji("🚚 ", ""),
        style(count).magenta(),
    );
    let bar_progress =
        ProgressBar::new(0).with_style(
            ProgressStyle::default_bar()
                .template("{spinner:.green} {elapsed_precise} [{wide_bar:.green}] {pos}/{len}\n{spinner:.green} {wide_msg}").unwrap(),
        );
    bar_progress.set_length(count);
    bar_progress.set_position(0);
    bar_progress.enable_steady_tick(Duration::from_millis(12));
    let now = SystemTime::now();
    let (compressed, read, written) = compress(
        &source,
        &mut writer,
        &output,
        args.compression,
        args.build_dictionary,
        || {
            bar_progress.inc(1);
        },
        |message| {
            bar_progress.inc(1);
            bar_progress.println(format!(
                "      {}{}",
                Emoji("❗ ", ""),
                style(message).red()
            ));
        },
        |message| {
            bar_progress.set_message(format!("{}", style(message).blue().bright()));
        },
        |message| {
            bar_progress.println(format!(
                "      {}{}",
                Emoji("💡 ", ""),
                style(message).dim()
            ));
        },
    );
    bar_progress.finish_and_clear();
    writer.flush().unwrap();

    println!(
        "      {}{}",
        Emoji("💾 ", ""),
        style(format!(
            "{:.2}MB read, {:.2}MB written, {:.2}% of original size",
            read as f64 / 1024.0 / 1024.0,
            written as f64 / 1024.0 / 1024.0,
            (written as f64 / read as f64) * 100.0
        ))
        .dim(),
    );
    println!(
        "      {}{}",
        Emoji("📍 ", ""),
        style(format!(
            "took {:.2}s",
            now.elapsed().unwrap_or_default().as_secs_f64()
        ))
        .dim(),
    );
    println!(
        "      {}{} {} {}{}",
        Emoji("✨ ", ""),
        style("successfully compressed").green(),
        style(compressed).magenta(),
        style("files and directories").green(),
        if compressed < count {
            style(format!(" (skipped {})", count - compressed))
                .bold()
                .red()
        } else {
            style(String::new())
        }
    );

    println!(
        "{} {}writing startup configuration…",
        style("[4/4]").bold().dim(),
        Emoji("📃 ", "")
    );

    let info = StarterInfo {
        signature: WRAPPE_SIGNATURE,
        show_console,
        current_dir,
        verification,
        show_information,
        cleanup,
        uid: version.as_bytes().try_into().unwrap(),
        unpack_target,
        versioning,
        unpack_directory,
        once,
        command,
        arguments,
        wrappe_format: WRAPPE_FORMAT,
    };
    writer.write_all(info.as_bytes()).unwrap();

    writer.flush().unwrap();
    drop(writer);

    #[cfg(any(unix, target_os = "redox"))]
    {
        use ::std::{
            fs::{metadata, set_permissions},
            os::unix::prelude::*,
        };
        let mode = metadata(&output)
            .map(|metadata| metadata.permissions().mode())
            .unwrap_or(0o755);
        set_permissions(&output, PermissionsExt::from_mode(mode | 0o111)).unwrap_or_else(|e| {
            eprintln!(
                "      {} failed to set permissions for {}: {}",
                Emoji("❗ ", ""),
                output.display(),
                e
            )
        });
    }

    println!("      {}{}", Emoji("✨ ", ""), style("done!").green());
}

```

`src/types.rs`:

```rs
pub use zerocopy::{Immutable, IntoBytes, KnownLayout};

pub const WRAPPE_FORMAT: u8 = 204;
pub const WRAPPE_SIGNATURE: [u8; 8] = [0x50, 0x45, 0x33, 0x44, 0x41, 0x54, 0x41, 0x00];
pub const NAME_SIZE: usize = 128;
pub const ARGS_SIZE: usize = 512;

#[repr(C, packed)]
#[derive(IntoBytes, Immutable, KnownLayout)]
pub struct StarterInfo {
    pub signature:        [u8; 8],
    pub show_console:     u8,
    pub current_dir:      u8,
    pub verification:     u8,
    pub show_information: u8,
    pub uid:              [u8; 16],
    pub unpack_target:    u8,
    pub versioning:       u8,
    pub once:             u8,
    pub cleanup:          u8,
    pub wrappe_format:    u8,
    pub unpack_directory: [u8; NAME_SIZE],
    pub command:          [u8; NAME_SIZE],
    pub arguments:        [u8; ARGS_SIZE],
}

#[repr(C, packed)]
#[derive(IntoBytes, Immutable, KnownLayout)]
pub struct PayloadHeader {
    pub directory_sections: u64,
    pub file_sections:      u64,
    pub symlink_sections:   u64,
    pub dictionary_size:    u64,
    pub section_hash:       u64,
    pub payload_size:       u64,
    pub sections_size:      u64,
    pub kind:               u8,
}
impl PayloadHeader {
    pub fn len(&self) -> u64 {
        self.directory_sections + self.file_sections + self.symlink_sections
    }
}
#[repr(C, packed)]
#[derive(IntoBytes, Immutable, KnownLayout)]
pub struct DirectorySection {
    pub name:   [u8; NAME_SIZE],
    pub parent: u32,
}
#[repr(C, packed)]
#[derive(IntoBytes, Immutable, KnownLayout)]
pub struct FileSectionHeader {
    pub position:              u64,
    pub size:                  u64,
    pub name:                  [u8; NAME_SIZE],
    pub file_hash:             u64,
    pub compressed_hash:       u64,
    pub time_accessed_seconds: u64,
    pub time_modified_seconds: u64,
    pub parent:                u32,
    pub mode:                  u32,
    pub time_accessed_nanos:   u32,
    pub time_modified_nanos:   u32,
    pub readonly:              u8,
}
#[repr(C, packed)]
#[derive(IntoBytes, Immutable, KnownLayout)]
pub struct SymlinkSection {
    pub name:                  [u8; NAME_SIZE],
    pub parent:                u32,
    pub target:                u32,
    pub time_accessed_seconds: u64,
    pub time_modified_seconds: u64,
    pub time_accessed_nanos:   u32,
    pub time_modified_nanos:   u32,
    pub mode:                  u32,
    pub kind:                  u8,
    pub readonly:              u8,
}

```

`startpe/Cargo.toml`:

```toml
[package]

name = "startpe"
description = "Runner for Packed Executables"
version = "1.0.4"
license = "BSD-2-Clause"
authors = ["Christian Sdunek <me@systemcluster.me>"]
edition = "2021"
rust-version = "1.77.2"
publish = false
repository = "https://github.com/Systemcluster/wrappe"

[[bin]]

name = "startpe"
path = "src/main.rs"

[features]

default = ["prefetch", "once"]
prefetch = []
once = ["dep:procfs"]

[profile.release]

codegen-units = 1
debug = false
debug-assertions = false
incremental = false
lto = "fat"
opt-level = 's'
panic = "abort"
strip = "symbols"

[dependencies]

dirs = "5.0.1"
filetime = "0.2.25"
fslock-guard = "0.2.0"
memchr = "2.7.4"
memmap2 = "0.9.5"
rayon = "1.10.0"
twox-hash = { version = "1.6.3", default-features = false }
zerocopy = { version = "0.8.10", features = ["derive"] }
zstd = { version = "0.13.2", default-features = false, features = [] }

[target.'cfg(windows)'.dependencies]

windows-sys = { version = "0.59.0", features = ["Win32_Foundation", "Win32_System_Console", "Win32_System_LibraryLoader", "Win32_System_Threading", "Win32_System_Diagnostics", "Win32_System_Diagnostics_ToolHelp", "Win32_System_ProcessStatus", "Win32_UI_WindowsAndMessaging"] }

[target.'cfg(target_os = "linux")'.dependencies]

procfs = { version = "0.17.0", default-features = false, optional = true }

```

`startpe/Cross.toml`:

```toml
[build.env]
passthrough = [
  "RUSTFLAGS",
  "GIT_HASH",
  "MACOSX_DEPLOYMENT_TARGET",
]

```

`startpe/src/decompress.rs`:

```rs
use std::{
    fs::{File, create_dir_all, read_link, remove_dir, remove_file},
    hash::Hasher,
    io::{BufReader, BufWriter, Read, Result, copy, sink},
    mem::size_of,
    path::{Path, PathBuf},
    thread::sleep,
    time::Duration,
};

#[cfg(windows)]
use std::os::windows::fs::OpenOptionsExt;

use filetime::{FileTime, set_file_times, set_symlink_file_times};
use rayon::iter::{IntoParallelRefIterator, ParallelIterator};
use twox_hash::XxHash64;
use zerocopy::Ref;
use zstd::{Decoder, dict::DecoderDictionary, zstd_safe::DCtx};

use crate::{types::*, versioning::*};

pub const HASH_SEED: u64 = 1246736989840;
pub const LOCK_FILE: &str = "._wrappe_lock_";

pub struct HashReader<R: Read, H: Hasher> {
    reader: R,
    hasher: H,
}
impl<R: Read, H: Hasher> HashReader<R, H> {
    pub fn new(reader: R, hasher: H) -> Self { HashReader { reader, hasher } }

    pub fn finish(self) -> u64 { self.hasher.finish() }
}
impl<R: Read, H: Hasher> Read for HashReader<R, H> {
    fn read(&mut self, buf: &mut [u8]) -> Result<usize> {
        let bytes = self.reader.read(buf)?;
        if bytes > 0 {
            self.hasher.write(&buf[0..bytes]);
        }
        Ok(bytes)
    }
}

/// Decompress the payload and section data in `mmap` into `unpack_dir`.
/// The data is expected to be in the following order at the end of `mmap`:
/// - compressed file contents
/// - compression dictionary
/// - compressed sections
///   - directory sections
///   - file section headers
///   - symlink sections
/// - payload section header
pub fn decompress(
    mmap: &[u8], unpack_dir: &Path, verification: u8, mut should_extract: bool, version: &str,
    show_information: u8,
) -> bool {
    // read payload header sections
    let payload_header_start = mmap.len() - size_of::<PayloadHeader>();
    let payload_header = Ref::into_ref(
        Ref::<_, PayloadHeader>::from_bytes(&mmap[payload_header_start..])
            .expect("couldn't read payload header"),
    );

    let directory_sections = payload_header.directory_sections as usize;
    let file_sections = payload_header.file_sections as usize;
    let symlink_sections = payload_header.symlink_sections as usize;
    let dictionary_size = payload_header.dictionary_size as usize;
    let payload_size = payload_header.payload_size as usize;
    let sections_size = payload_header.sections_size as usize;
    if show_information >= 2 {
        println!(
            "payload: {} directories, {} files, {} symlinks ({} total)",
            directory_sections,
            file_sections,
            symlink_sections,
            payload_header.len()
        );
        println!("dictionary size: {}", dictionary_size);
        println!("payload size: {}", payload_size);
    }

    let mut sections = Vec::with_capacity(sections_size);
    let mut reader = BufReader::with_capacity(
        DCtx::in_size(),
        &mmap[payload_header_start - sections_size..payload_header_start],
    );
    let mut decoder = Decoder::new(&mut reader).unwrap();
    copy(&mut decoder, &mut sections)
        .unwrap_or_else(|e| panic!("couldn't decompress payload sections: {}", e));

    let directory_sections_start = 0;
    let file_sections_start =
        directory_sections_start + directory_sections * size_of::<DirectorySection>();
    let symlink_sections_start =
        file_sections_start + file_sections * size_of::<FileSectionHeader>();

    let dictionary_start = payload_header_start - sections_size - dictionary_size;
    let files_start = dictionary_start - payload_size;

    let mut section_hasher = XxHash64::with_seed(HASH_SEED);

    if show_information >= 2 {
        println!("reading sections...");
    }
    let dictionary = if dictionary_size > 0 {
        Some(DecoderDictionary::copy(
            &mmap[dictionary_start..payload_header_start - sections_size],
        ))
    } else {
        None
    };
    let directories = sections[directory_sections_start..file_sections_start]
        .chunks(size_of::<DirectorySection>())
        .enumerate()
        .fold(
            // start with the unpack directory as parent 0
            Vec::<PathBuf>::from([PathBuf::from("")]),
            |mut directories, (i, section)| {
                let section_start = directory_sections_start + i * size_of::<DirectorySection>();
                section_hasher.write(section);
                let section = Ref::into_ref(
                    Ref::<_, DirectorySection>::from_bytes(
                        &sections[section_start..section_start + size_of::<DirectorySection>()],
                    )
                    .expect("couldn't read payload header"),
                );
                directories.push(
                    directories[section.parent as usize].join(
                        std::str::from_utf8(
                            &section.name[0..(section
                                .name
                                .iter()
                                .position(|&c| c == b'\0')
                                .unwrap_or(section.name.len()))],
                        )
                        .unwrap(),
                    ),
                );
                directories
            },
        );
    let files = sections[file_sections_start..symlink_sections_start]
        .chunks(size_of::<FileSectionHeader>())
        .enumerate()
        .map(|(i, section)| {
            let section_start = file_sections_start + i * size_of::<FileSectionHeader>();
            section_hasher.write(section);
            let section = Ref::into_ref(
                Ref::<_, FileSectionHeader>::from_bytes(
                    &sections[section_start..section_start + size_of::<FileSectionHeader>()],
                )
                .expect("couldn't read payload header"),
            );
            (
                section,
                std::str::from_utf8(
                    &section.name[0..(section
                        .name
                        .iter()
                        .position(|&c| c == b'\0')
                        .unwrap_or(section.name.len()))],
                )
                .unwrap(),
            )
        })
        .collect::<Vec<_>>();
    let symlinks = sections[symlink_sections_start..]
        .chunks(size_of::<SymlinkSection>())
        .enumerate()
        .map(|(i, section)| {
            let section_start = symlink_sections_start + i * size_of::<SymlinkSection>();
            section_hasher.write(section);
            let section = Ref::into_ref(
                Ref::<_, SymlinkSection>::from_bytes(
                    &sections[section_start..section_start + size_of::<SymlinkSection>()],
                )
                .expect("couldn't read payload header"),
            );
            (
                section,
                std::str::from_utf8(
                    &section.name[0..(section
                        .name
                        .iter()
                        .position(|&c| c == b'\0')
                        .unwrap_or(section.name.len()))],
                )
                .unwrap(),
            )
        })
        .collect::<Vec<_>>();

    let section_hash = section_hasher.finish();
    if section_hash != payload_header.section_hash {
        let expected = payload_header.section_hash;
        panic!(
            "section hash ({}) differs from expected section hash ({})",
            section_hash, expected
        );
    }

    // verify files
    if verification > 0 && !should_extract && file_sections > 0 {
        if show_information >= 2 {
            println!("verifying files...");
        }
        should_extract = !files.par_iter().all(|(file, file_name)| {
            let path = unpack_dir
                .join(&directories[file.parent as usize])
                .join(file_name);
            if !path.is_file() {
                eprintln!("verification failed: not a file: {}", path.display());
                return false;
            }
            if verification == 2 {
                // verify checksums
                #[cfg(windows)]
                let target = File::options()
                    .read(true)
                    .custom_flags(0x08000000) // FILE_FLAG_SEQUENTIAL_SCAN
                    .open(&path);
                #[cfg(not(windows))]
                let target = File::options().read(true).open(&path);
                if target.is_err() {
                    eprintln!(
                        "verification failed: couldn't open file: {}",
                        path.display()
                    );
                    return false;
                }
                let target = target.unwrap();
                let mut hasher = XxHash64::with_seed(HASH_SEED);
                let mut reader = HashReader::new(&target, &mut hasher);
                if copy(&mut reader, &mut sink()).is_err() {
                    eprintln!(
                        "verification failed: couldn't read file: {}",
                        path.display()
                    );
                    return false;
                };
                let file_hash = hasher.finish();
                if file_hash != file.file_hash {
                    let expected = file.file_hash;
                    eprintln!(
                        "verification failed: file hash ({}) differs from expected file hash ({}): {}",
                        file_hash,
                        expected,
                        path.display()
                    );
                    return false;
                }
            }
            true
        });
    }

    // verify symlinks
    if verification > 0 && !should_extract && symlink_sections > 0 {
        if show_information >= 2 {
            println!("verifying symlinks...");
        }
        should_extract = !symlinks.par_iter().all(|(symlink, symlink_name)| {
            let path = unpack_dir
                .join(&directories[symlink.parent as usize])
                .join(symlink_name);
            let link = read_link(&path);
            if link.is_err() {
                eprintln!(
                    "verification failed: not a valid symlink: {}",
                    path.display()
                );
                return false;
            }
            let link = link.unwrap();
            if !link.starts_with(unpack_dir) {
                eprintln!(
                    "verification failed: symlink points to target outside the target directory: {}",
                    path.display()
                );
                return false;
            }
            // directory symlink
            if symlink.kind == 0 {
                let target = unpack_dir.join(&directories[symlink.target as usize]);
                if link != target
                {
                    eprintln!(
                        "verification failed: symlink points to wrong target: {} (expected: {})",
                        target.display(),
                        link.display(),
                    );
                    return false;
                }
            }
            // file symlink
            if symlink.kind == 1 {
                let (file, file_name) = files[symlink.target as usize];
                let target = unpack_dir
                    .join(&directories[file.parent as usize])
                    .join(file_name);
                if target != link
                {
                    eprintln!(
                        "verification failed: symlink points to wrong target: {} (expected: {})",
                        target.display(),
                        link.display(),
                    );
                    return false;
                }
            }
            true
        });
    }

    if should_extract {
        #[cfg(feature = "prefetch")]
        let mut prefetch_handle = None;
        #[cfg(feature = "prefetch")]
        // prefetch memory mapped data if it is larger than 512 MB
        if mmap.len() - files_start > 512 * 1024 * 1024 {
            if show_information >= 2 {
                println!("prefetching memory...");
            }
            prefetch_handle = crate::prefetch::prefetch_memory(mmap, files_start);
        }

        // create directories
        if show_information >= 2 {
            println!("creating directories...");
        }
        directories.iter().for_each(|directory| {
            let path = unpack_dir.join(directory);
            create_dir_all(&path).unwrap_or_else(|e| {
                panic!("couldn't create directory {}: {}", path.display(), e);
            });
        });

        // unpack files
        if show_information >= 2 {
            println!("unpacking...");
        }
        files.par_iter().for_each(|(file, file_name)| {
            let path = unpack_dir
                .join(&directories[file.parent as usize])
                .join(file_name);
            let content = &mmap[files_start + file.position as usize
                ..files_start + (file.position + file.size) as usize];
            let mut reader = HashReader::new(content, XxHash64::with_seed(HASH_SEED));
            {
                let mut reader = BufReader::with_capacity(DCtx::in_size(), &mut reader);
                let output = File::options()
                    .write(true)
                    .create(true)
                    .truncate(true)
                    .open(&path)
                    .unwrap_or_else(|e| panic!("failed to create file {}: {}", path.display(), e));
                let mut output = BufWriter::with_capacity(DCtx::out_size(), output);
                let decoder = if let Some(dict) = &dictionary {
                    Decoder::with_prepared_dictionary(&mut reader, dict)
                } else {
                    Decoder::with_buffer(&mut reader)
                };
                let mut decoder = decoder.unwrap_or_else(|e| {
                    panic!("failed to create decoder for {}: {}", path.display(), e)
                });
                copy(&mut decoder, &mut output)
                    .unwrap_or_else(|e| panic!("failed to unpack file {}: {}", path.display(), e));
            }
            let compressed_hash = reader.finish();
            if file.compressed_hash != compressed_hash {
                let expected = file.compressed_hash;
                panic!(
                    "compressed file hash ({}) differs from expected hash ({}) for {}",
                    compressed_hash,
                    expected,
                    path.display()
                );
            }
            #[cfg(windows)]
            {
                use ::std::fs::{metadata, set_permissions};
                let meta = metadata(&path);
                if let Ok(ref meta) = meta {
                    let read = file.readonly != 0;
                    let mut perm = meta.permissions();
                    perm.set_readonly(read);
                    set_permissions(&path, perm).unwrap_or_else(|e| {
                        eprintln!("failed to set permissions for {}: {}", path.display(), e)
                    });
                }
            }
            #[cfg(any(unix, target_os = "redox"))]
            {
                use ::std::{
                    fs::{Permissions, set_permissions},
                    os::unix::prelude::*,
                };
                let mode = file.mode;
                let mut perm: Permissions = PermissionsExt::from_mode(mode);
                let read = file.readonly != 0;
                perm.set_readonly(read);
                set_permissions(&path, perm).unwrap_or_else(|e| {
                    eprintln!("failed to set permissions for {}: {}", path.display(), e)
                });
            }
            set_file_times(
                &path,
                FileTime::from_unix_time(
                    file.time_accessed_seconds as i64,
                    file.time_accessed_nanos,
                ),
                FileTime::from_unix_time(
                    file.time_modified_seconds as i64,
                    file.time_modified_nanos,
                ),
            )
            .unwrap_or_else(|e| println!("failed to set file times for {}: {}", path.display(), e));
        });

        // create symlinks
        #[cfg(not(any(windows, unix, target_os = "redox")))]
        {
            eprintln!("skipping symlink creation on unsupported platform");
        }
        #[cfg(any(windows, unix, target_os = "redox"))]
        {
            if show_information >= 2 {
                println!("creating symlinks...");
            }
            symlinks.par_iter().for_each(|(symlink, symlink_name)| {
                let path = unpack_dir
                    .join(&directories[symlink.parent as usize])
                    .join(symlink_name);
                // directory symlink
                if symlink.kind == 0 {
                    if path.exists() {
                        remove_dir(&path).unwrap_or_else(|e| {
                            panic!(
                                "failed to remove existing symlink {}: {}",
                                path.display(),
                                e
                            )
                        });
                    }
                    while path.exists() {
                        sleep(Duration::from_millis(20));
                    }
                    let target = unpack_dir.join(&directories[symlink.target as usize]);
                    #[cfg(windows)]
                    {
                        use ::std::os::windows::fs::symlink_dir;
                        symlink_dir(target, &path).unwrap_or_else(|e| {
                            panic!("failed to create symlink {}: {}", path.display(), e)
                        });
                    }
                    #[cfg(any(unix, target_os = "redox"))]
                    {
                        use ::std::os::unix::fs::symlink;
                        symlink(target, &path).unwrap_or_else(|e| {
                            panic!("failed to create symlink {}: {}", path.display(), e)
                        });
                    }
                }
                // file symlink
                if symlink.kind == 1 {
                    if path.exists() {
                        remove_file(&path).unwrap_or_else(|e| {
                            panic!(
                                "failed to remove existing symlink {}: {}",
                                path.display(),
                                e
                            )
                        });
                    }
                    while path.exists() {
                        sleep(Duration::from_millis(20));
                    }
                    let (file, file_name) = files[symlink.target as usize];
                    let target = unpack_dir
                        .join(&directories[file.parent as usize])
                        .join(file_name);
                    #[cfg(windows)]
                    {
                        use ::std::os::windows::fs::symlink_file;
                        symlink_file(target, &path).unwrap_or_else(|e| {
                            panic!("failed to create symlink {}: {}", path.display(), e)
                        });
                    }
                    #[cfg(any(unix, target_os = "redox"))]
                    {
                        use ::std::os::unix::fs::symlink;
                        symlink(target, &path).unwrap_or_else(|e| {
                            panic!("failed to create symlink {}: {}", path.display(), e)
                        });
                    }
                    set_symlink_file_times(
                        &path,
                        FileTime::from_unix_time(
                            symlink.time_accessed_seconds as i64,
                            symlink.time_accessed_nanos,
                        ),
                        FileTime::from_unix_time(
                            symlink.time_modified_seconds as i64,
                            symlink.time_modified_nanos,
                        ),
                    )
                    .unwrap_or_else(|e| {
                        eprintln!("failed to set file times for {}: {}", path.display(), e)
                    });
                }
            });
        }

        set_version(unpack_dir, version);

        #[cfg(feature = "prefetch")]
        if let Some(prefetch_result) = prefetch_handle {
            let _ = prefetch_result
                .join()
                .map_err(|e| eprintln!("failed to join prefetch thread: {:?}", e))
                .map(|r| r.map_err(|e| eprintln!("failed to prefetch memory: {}", e)));
        }
    }

    should_extract
}

```

`startpe/src/main.rs`:

```rs
use std::{
    env::{current_exe, var_os},
    fs::{File, create_dir_all, read_link, remove_dir, remove_dir_all},
    io::Write,
    mem::size_of,
    panic::set_hook,
    process::Command,
    time::SystemTime,
};

#[cfg(windows)]
use std::os::windows::fs::OpenOptionsExt;

#[cfg(any(unix, target_os = "redox"))]
use std::os::unix::process::CommandExt;
#[cfg(not(any(unix, target_os = "redox")))]
use std::process::Stdio;

#[cfg(windows)]
use windows_sys::Win32::System::Console::{ATTACH_PARENT_PROCESS, AttachConsole};

use fslock_guard::LockFileGuard;
use memchr::memmem;
use memmap2::MmapOptions;
use zerocopy::Ref;

mod types;
use types::*;

mod decompress;
use decompress::*;

mod permissions;
use permissions::*;

mod versioning;
use versioning::*;

#[cfg(feature = "prefetch")]
mod prefetch;

#[cfg(feature = "once")]
mod once;

fn main() {
    set_hook(Box::<_>::new(move |panic| {
        if let Some(message) = panic.payload().downcast_ref::<&str>() {
            eprintln!("error: {}", message);
        } else if let Some(message) = panic.payload().downcast_ref::<String>() {
            eprintln!("error: {}", message);
        } else {
            eprintln!("error: {}", panic);
        }
        #[cfg(windows)]
        {
            use std::sync::atomic::{AtomicBool, Ordering};
            static WRITTEN: AtomicBool = AtomicBool::new(false);
            if WRITTEN.swap(true, Ordering::Relaxed) {
                return;
            }
            let now = SystemTime::now()
                .duration_since(SystemTime::UNIX_EPOCH)
                .unwrap_or_default();
            if let Ok(mut file) = File::create(format!(
                "error-{}-{}.txt",
                now.as_secs(),
                now.subsec_millis()
            )) {
                let _ = writeln!(file, "An error occurred while starting the application.");
                let _ = writeln!(file, "Please report this error to the developers.");
                let _ = writeln!(file);
                let _ = writeln!(file, "{}", panic);
            }
        }
    }));

    let mut exe = current_exe().expect("couldn't get handle to current executable");
    while let Ok(link) = read_link(&exe) {
        exe = link;
    }
    #[cfg(windows)]
    let file = File::options()
        .read(true)
        .custom_flags(0x10000000) // FILE_FLAG_RANDOM_ACCESS
        .open(&exe)
        .expect("couldn't open current executable");
    #[cfg(not(windows))]
    let file = File::options()
        .read(true)
        .open(&exe)
        .expect("couldn't open current executable");

    let mmap = unsafe {
        MmapOptions::new()
            .map(&file)
            .expect("couldn't memory map current executable")
    };
    let end = mmap.len();
    if end < size_of::<StarterInfo>() {
        panic!("file is too small ({} < {})", end, size_of::<StarterInfo>())
    }

    let mut signature = Vec::with_capacity(8);
    signature.extend_from_slice(&WRAPPE_SIGNATURE_1[..4]);
    signature.extend_from_slice(&WRAPPE_SIGNATURE_2[..4]);

    let mut info_start = end - size_of::<StarterInfo>();
    if mmap[info_start..info_start + 8] != signature[..] {
        if let Some(pos) = memmem::rfind(&mmap[..], &signature) {
            info_start = pos;
        } else {
            panic!("couldn't find starter info")
        }
    }

    if info_start + size_of::<StarterInfo>() > end {
        panic!(
            "starter info is too small ({} < {})",
            end - info_start,
            size_of::<StarterInfo>()
        )
    }
    let info = Ref::into_ref(
        Ref::<_, StarterInfo>::from_bytes(&mmap[info_start..info_start + size_of::<StarterInfo>()])
            .expect("couldn't read starter info"),
    );
    if info.signature != signature[..] {
        panic!("file signature is invalid")
    }
    if info.wrappe_format != WRAPPE_FORMAT {
        panic!(
            "runner version ({}) differs from wrapper version ({})",
            WRAPPE_FORMAT, info.wrappe_format
        );
    }

    let mut show_information = info.show_information;
    let show_console = info.show_console;

    if show_information < 2 && var_os("STARTPE_FORCE_VERBOSE").is_some() {
        show_information = 2;
    }

    #[cfg(not(windows))]
    let console_attached = false;
    #[cfg(windows)]
    let mut console_attached = false;
    #[cfg(windows)]
    if show_console == 2 || (show_console == 0 && show_information == 2) {
        console_attached = unsafe { AttachConsole(ATTACH_PARENT_PROCESS) != 0 };
    }

    if show_information >= 1 {
        println!(
            "{} {}{}",
            env!("CARGO_PKG_NAME"),
            env!("CARGO_PKG_VERSION"),
            option_env!("GIT_HASH")
                .map(|hash| format!(" ({})", hash))
                .unwrap_or_default()
        );
    }

    if info.unpack_directory.is_empty() {
        panic!("empty unpack directory name")
    }
    let unpack_dir_name = std::str::from_utf8(
        &info.unpack_directory[0..(info
            .unpack_directory
            .iter()
            .position(|&c| c == b'\0')
            .unwrap_or(info.unpack_directory.len()))],
    )
    .unwrap();
    if show_information >= 1 {
        println!("{}", unpack_dir_name);
    }

    let version = std::str::from_utf8(
        &info.uid[0..(info
            .uid
            .iter()
            .position(|&c| c == b'\0')
            .unwrap_or(info.uid.len()))],
    )
    .unwrap();
    if show_information >= 2 {
        println!();
        println!("version: {}", version);
        println!(
            "show console: {} (attached: {})",
            show_console, console_attached
        );
    }

    let mut unpack_root = match info.unpack_target {
        0 => std::env::temp_dir(),
        1 => dirs::data_local_dir().unwrap(),
        2 => std::env::current_dir().unwrap(),
        _ => panic!("invalid unpack target"),
    };
    unpack_root = unpack_root.join(unpack_dir_name);
    let mut unpack_dir = unpack_root.clone();
    if info.versioning == 0 {
        unpack_dir = unpack_dir.join(version);
    }
    if show_information >= 2 {
        println!("target directory: {}", unpack_dir.display());
    }

    let command_name = std::str::from_utf8(
        &info.command[0..(info
            .command
            .iter()
            .position(|&c| c == b'\0')
            .unwrap_or(info.command.len()))],
    )
    .unwrap();
    let run_path = &unpack_dir.join(command_name);
    if show_information >= 2 {
        println!("runpath: {}", run_path.display());
    }

    create_dir_all(&unpack_dir)
        .unwrap_or_else(|e| panic!("couldn't create directory {}: {}", unpack_dir.display(), e));

    let lockfile = if info.once == 1 {
        let lockfile = LockFileGuard::try_lock(unpack_dir.join(LOCK_FILE))
            .unwrap_or_else(|e| panic!("couldn't lock file: {}", e));
        if lockfile.is_none() {
            println!("another instance is already unpacking, exiting...");
            return;
        }
        lockfile.unwrap()
    } else {
        LockFileGuard::lock(unpack_dir.join(LOCK_FILE)).unwrap_or_else(|e| {
            panic!("couldn't lock file: {}", e);
        })
    };

    #[cfg(feature = "once")]
    if info.once == 1 {
        if show_information >= 2 {
            println!("checking for running processes...");
        }
        let running = once::check_instance(run_path).unwrap();
        if running {
            println!("another instance is already running, exiting...");
            return;
        }
    }

    let cleanup: bool;
    if let Some(var) = var_os("STARTPE_CLEANUP") {
        cleanup = var == "1"
    } else {
        cleanup = info.cleanup == 1
    }

    let should_extract = match info.versioning {
        0 => get_version(&unpack_dir) != version,
        1 => get_version(&unpack_dir) != version,
        _ => true,
    };

    let verification = if !should_extract {
        info.verification
    } else {
        0
    };
    if show_information >= 2 {
        println!("should verify: {}", verification);
        println!("should extract: {}", should_extract);
        println!("should cleanup: {}", cleanup);
    }

    if should_extract || verification > 0 {
        let now = SystemTime::now();
        let extracted = decompress(
            &mmap[..info_start],
            &unpack_dir,
            verification,
            should_extract,
            version,
            show_information,
        );
        if extracted {
            if show_information >= 2 {
                println!(
                    "decompressed in {}ms",
                    now.elapsed().unwrap_or_default().as_millis()
                );
            }
            set_executable_permissions(run_path);
        }
    }

    drop(lockfile);

    let baked_arguments = std::str::from_utf8(
        &info.arguments[0..(info
            .arguments
            .iter()
            .position(|&c| c == b'\0')
            .unwrap_or(info.arguments.len()))],
    )
    .expect("couldn't parse baked arguments");
    let baked_arguments = baked_arguments
        .split('\u{1f}')
        .map(|arg| arg.trim().to_string())
        .filter(|arg| !arg.is_empty())
        .collect::<Vec<_>>();
    if show_information >= 2 && !baked_arguments.is_empty() {
        println!("baked arguments: {:?}", baked_arguments);
    }

    let forwarded_arguments = std::env::args().skip(1).collect::<Vec<_>>();
    if show_information >= 2 && !forwarded_arguments.is_empty() {
        println!("forwarded arguments: {:?}", forwarded_arguments);
    }

    let launch_dir = std::env::current_dir().unwrap();
    let current_dir = match info.current_dir {
        0 => &launch_dir,
        1 => &unpack_dir,
        2 => exe.parent().unwrap(),
        3 => run_path.parent().unwrap(),
        _ => panic!("invalid current directory"),
    };
    if show_information >= 2 {
        println!("current dir: {}", current_dir.display());
    }

    drop(mmap);
    drop(file);

    if show_information >= 2 {
        println!("running...");
    }

    if console_attached && show_console == 0 {
        let _ = std::io::stdout().flush();
    }

    let mut command = Command::new(run_path);
    command.args(baked_arguments);
    command.args(forwarded_arguments);
    command.env("WRAPPE_UNPACK_DIR", unpack_dir.as_os_str());
    command.env("WRAPPE_LAUNCH_DIR", launch_dir.as_os_str());
    command.current_dir(current_dir);

    #[cfg(not(any(unix, target_os = "redox")))]
    {
        if show_console == 0 || (show_console == 2 && !console_attached) {
            command.stdout(Stdio::null());
            command.stderr(Stdio::null());
            command.stdin(Stdio::null());
        }
    }
    if cleanup {
        let mut child = command
            .spawn()
            .unwrap_or_else(|e| panic!("failed to run {}: {}", run_path.display(), e));
        let status = child
            .wait()
            .unwrap_or_else(|e| panic!("failed to run {}: {}", run_path.display(), e));
        let _ = remove_dir_all(unpack_dir);
        let _ = remove_dir(unpack_root);
        std::process::exit(status.code().unwrap_or(1))
    } else {
        #[cfg(any(unix, target_os = "redox"))]
        {
            let e = command.exec();
            panic!("failed to run {}: {}", run_path.display(), e);
        }
        #[cfg(not(any(unix, target_os = "redox")))]
        {
            #[allow(clippy::zombie_processes)]
            let mut child = command
                .spawn()
                .unwrap_or_else(|e| panic!("failed to run {}: {}", run_path.display(), e));
            if show_console == 1 || (show_console == 2 && console_attached) {
                let status = child
                    .wait()
                    .unwrap_or_else(|e| panic!("failed to run {}: {}", run_path.display(), e));
                std::process::exit(status.code().unwrap_or(1))
            }
        }
    }
}

```

`startpe/src/once.rs`:

```rs
use std::path::Path;

#[cfg(windows)]
pub fn check_instance(run_path: &Path) -> Result<bool, std::io::Error> {
    use core::ffi::c_void;
    use std::{ffi::OsString, os::windows::ffi::OsStringExt};
    use windows_sys::Win32::{
        System::{
            Diagnostics::ToolHelp::{
                CreateToolhelp32Snapshot, PROCESSENTRY32W, Process32FirstW, Process32NextW,
                TH32CS_SNAPPROCESS,
            },
            Threading::{
                OpenProcess, PROCESS_QUERY_LIMITED_INFORMATION, QueryFullProcessImageNameW,
            },
        },
        UI::WindowsAndMessaging::EnumWindows,
    };

    unsafe extern "system" fn enum_windows_proc(hwnd: *mut c_void, lparam: isize) -> i32 {
        use windows_sys::Win32::UI::WindowsAndMessaging::{
            GetWindowThreadProcessId, SW_SHOW, SetForegroundWindow, ShowWindow,
        };
        let mut process_id = 0;
        unsafe {
            GetWindowThreadProcessId(hwnd, &mut process_id);
        }
        if process_id == lparam as u32 {
            unsafe { ShowWindow(hwnd, SW_SHOW) };
            let result = unsafe { SetForegroundWindow(hwnd) };
            if result == 0 {
                return 1;
            }
            0
        } else {
            1
        }
    }

    let snapshot = unsafe { CreateToolhelp32Snapshot(TH32CS_SNAPPROCESS, 0) };
    if snapshot.is_null() {
        return Err(std::io::Error::last_os_error());
    }
    let mut entry = unsafe { std::mem::zeroed::<PROCESSENTRY32W>() };
    entry.dwSize = std::mem::size_of::<PROCESSENTRY32W>() as u32;
    if unsafe { Process32FirstW(snapshot, &mut entry) } != 0 {
        let command_name = run_path.file_name().unwrap().to_os_string();
        let mut path = [0u16; 1024];
        loop {
            let process_name: &[u16] = unsafe {
                std::slice::from_raw_parts(
                    entry.szExeFile.as_ptr().cast::<u16>(),
                    entry
                        .szExeFile
                        .iter()
                        .take(entry.szExeFile.len())
                        .position(|&c| c == 0)
                        .unwrap_or(entry.szExeFile.len()),
                )
            };
            let process_name = OsString::from_wide(process_name);
            if process_name == command_name {
                let process = unsafe {
                    OpenProcess(PROCESS_QUERY_LIMITED_INFORMATION, 0, entry.th32ProcessID)
                };
                let mut len = path.len() as u32;
                let result =
                    unsafe { QueryFullProcessImageNameW(process, 0, path.as_mut_ptr(), &mut len) };
                if result == 0 {
                    return Err(std::io::Error::last_os_error());
                }
                let path = OsString::from_wide(&path[..len as usize]);
                if path == run_path.as_os_str() {
                    let result =
                        unsafe { EnumWindows(Some(enum_windows_proc), entry.th32ProcessID as _) };
                    if result == 0 {
                        let err = std::io::Error::last_os_error();
                        if err.raw_os_error() != Some(0) {
                            return Err(err);
                        }
                    }
                    return Ok(true);
                }
            }
            if unsafe { Process32NextW(snapshot, &mut entry) } == 0 {
                break;
            }
        }
    }

    Ok(false)
}

#[cfg(target_os = "linux")]
pub fn check_instance(run_path: &Path) -> Result<bool, std::io::Error> {
    let processes = procfs::process::all_processes();
    if let Err(_e) = processes {
        #[cfg(debug_assertions)]
        eprintln!("error: {}", _e);
        return Ok(false);
    }
    for proc in processes.unwrap() {
        match proc {
            Ok(p) => match p.exe() {
                Ok(exe) => {
                    if exe == run_path {
                        return Ok(true);
                    }
                }
                Err(_e) => {
                    #[cfg(debug_assertions)]
                    eprintln!("error: {}", _e);
                    continue;
                }
            },
            Err(_e) => {
                #[cfg(debug_assertions)]
                eprintln!("error: {}", _e);
                continue;
            }
        }
    }
    Ok(false)
}

#[cfg(not(any(windows, target_os = "linux")))]
#[inline(always)]
pub fn check_instance(_: &Path) -> Result<bool, std::io::Error> { Ok(false) }

```

`startpe/src/permissions.rs`:

```rs
use std::path::Path;

#[cfg(any(unix, target_os = "redox"))]
pub fn set_executable_permissions(path: &Path) {
    use ::std::{
        fs::{Permissions, metadata, set_permissions},
        os::unix::prelude::*,
    };
    let meta = metadata(path);
    if let Ok(ref meta) = meta {
        let mut perm: Permissions = meta.permissions();
        perm.set_mode(perm.mode() | 0o110);
        set_permissions(path, perm).unwrap_or_else(|e| {
            eprintln!(
                "failed to set executable permissions for {}: {}",
                path.display(),
                e
            )
        });
    }
}

#[cfg(not(any(unix, target_os = "redox")))]
pub fn set_executable_permissions(_: &Path) {}

```

`startpe/src/prefetch.rs`:

```rs
use std::{io::Result, thread::JoinHandle};

#[cfg(windows)]
pub fn prefetch_memory(mmap: &[u8], offset: usize) -> Option<JoinHandle<Result<()>>> {
    use core::{ffi::c_void, ptr::null_mut};
    use windows_sys::{
        Win32::{
            Foundation::HANDLE,
            System::{
                LibraryLoader::{GetProcAddress, LOAD_LIBRARY_SEARCH_SYSTEM32, LoadLibraryExA},
                Threading::GetCurrentProcess,
            },
        },
        core::PCSTR,
    };

    let virtual_address = mmap.as_ptr() as usize + offset;
    let number_of_bytes = mmap.len() - offset;
    Some(std::thread::spawn(move || {
        fn get_function(library: PCSTR, function: PCSTR) -> Result<*const c_void> {
            let module =
                unsafe { LoadLibraryExA(library, null_mut(), LOAD_LIBRARY_SEARCH_SYSTEM32) };
            if module.is_null() {
                Err(std::io::Error::last_os_error())?;
            }
            let address = unsafe { GetProcAddress(module, function) };
            if address.is_none() {
                Err(std::io::Error::last_os_error())?;
            }
            Ok(address.unwrap() as *const _)
        }
        type PrefetchVirtualMemory = unsafe extern "system" fn(
            hProcess: HANDLE,
            NumberOfEntries: usize,
            VirtualAddresses: *mut WIN32_MEMORY_RANGE_ENTRY,
            Flags: u32,
        ) -> u32;
        #[repr(C)]
        #[allow(non_camel_case_types, non_snake_case)]
        struct WIN32_MEMORY_RANGE_ENTRY {
            VirtualAddress: *const c_void,
            NumberOfBytes:  usize,
        }
        // Dynamically load PrefetchVirtualMemory since it is only available on Windows 8 and later
        let prefetch_fn = unsafe {
            #[allow(clippy::manual_c_str_literals)]
            match get_function(
                b"kernel32.dll\0".as_ptr() as _,
                b"PrefetchVirtualMemory\0".as_ptr() as _,
            ) {
                Err(e) => return Err(e),
                Ok(f) => std::mem::transmute::<*const _, PrefetchVirtualMemory>(f),
            }
        };
        let mut memory = WIN32_MEMORY_RANGE_ENTRY {
            VirtualAddress: virtual_address as *mut _,
            NumberOfBytes:  number_of_bytes as _,
        };
        let process = unsafe { GetCurrentProcess() };
        if process.is_null() {
            Err(std::io::Error::last_os_error())?;
        }
        let result = unsafe { prefetch_fn(process, 1, &mut memory as *mut _, 0) };
        if result == 0 {
            Err(std::io::Error::last_os_error())?;
        }
        Ok(())
    }))
}

#[cfg(not(windows))]
#[inline(always)]
pub fn prefetch_memory(_: &[u8], _: usize) -> Option<JoinHandle<Result<()>>> { None }

```

`startpe/src/types.rs`:

```rs
pub use zerocopy::{FromBytes, Immutable, KnownLayout};

pub const WRAPPE_FORMAT: u8 = 204;
pub const WRAPPE_SIGNATURE_1: [u8; 6] = [0x50, 0x45, 0x33, 0x44, 0x00, 0x00];
pub const WRAPPE_SIGNATURE_2: [u8; 4] = [0x41, 0x54, 0x41, 0x00];
pub const NAME_SIZE: usize = 128;
pub const ARGS_SIZE: usize = 512;

#[repr(C, packed)]
#[derive(FromBytes, Immutable, KnownLayout)]
pub struct StarterInfo {
    pub signature:        [u8; 8],
    pub show_console:     u8,
    pub current_dir:      u8,
    pub verification:     u8,
    pub show_information: u8,
    pub uid:              [u8; 16],
    pub unpack_target:    u8,
    pub versioning:       u8,
    pub once:             u8,
    pub cleanup:          u8,
    pub wrappe_format:    u8,
    pub unpack_directory: [u8; NAME_SIZE],
    pub command:          [u8; NAME_SIZE],
    pub arguments:        [u8; ARGS_SIZE],
}

#[repr(C, packed)]
#[derive(FromBytes, Immutable, KnownLayout)]
pub struct PayloadHeader {
    pub directory_sections: u64,
    pub file_sections:      u64,
    pub symlink_sections:   u64,
    pub dictionary_size:    u64,
    pub section_hash:       u64,
    pub payload_size:       u64,
    pub sections_size:      u64,
    pub kind:               u8,
}
impl PayloadHeader {
    pub fn len(&self) -> u64 {
        self.directory_sections + self.file_sections + self.symlink_sections
    }
}
#[repr(C, packed)]
#[derive(FromBytes, Immutable, KnownLayout)]
pub struct DirectorySection {
    pub name:   [u8; NAME_SIZE],
    pub parent: u32,
}
#[repr(C, packed)]
#[derive(FromBytes, Immutable, KnownLayout)]
pub struct FileSectionHeader {
    pub position:              u64,
    pub size:                  u64,
    pub name:                  [u8; NAME_SIZE],
    pub file_hash:             u64,
    pub compressed_hash:       u64,
    pub time_accessed_seconds: u64,
    pub time_modified_seconds: u64,
    pub parent:                u32,
    pub mode:                  u32,
    pub time_accessed_nanos:   u32,
    pub time_modified_nanos:   u32,
    pub readonly:              u8,
}
#[repr(C, packed)]
#[derive(FromBytes, Immutable, KnownLayout)]
pub struct SymlinkSection {
    pub name:                  [u8; NAME_SIZE],
    pub parent:                u32,
    pub target:                u32,
    pub time_accessed_seconds: u64,
    pub time_modified_seconds: u64,
    pub time_accessed_nanos:   u32,
    pub time_modified_nanos:   u32,
    pub mode:                  u32,
    pub kind:                  u8,
    pub readonly:              u8,
}

```

`startpe/src/versioning.rs`:

```rs
use std::{
    fs::{read_to_string, write},
    path::Path,
};

const VERSION_FILE: &str = "._wrappe_uid_";

pub fn get_version(target: &Path) -> String {
    read_to_string(target.join(VERSION_FILE)).unwrap_or_else(|_| "0".to_string())
}

pub fn set_version(target: &Path, version: &str) {
    write(target.join(VERSION_FILE), version).unwrap()
}

```