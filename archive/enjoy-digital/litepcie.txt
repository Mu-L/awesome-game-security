Project Path: arc_enjoy-digital_litepcie_umdd3kc9

Source Tree:

```txt
arc_enjoy-digital_litepcie_umdd3kc9
├── CONTRIBUTORS
├── LICENSE
├── MANIFEST.in
├── README.md
├── bench
│   ├── acorn.py
│   ├── fk33.py
│   ├── kc705.py
│   ├── kcu105.py
│   ├── test_ltssm_tracer.py
│   └── xcu1525.py
├── doc
│   ├── architecture.png
│   └── enjoy_digital.png
├── examples
│   ├── __init__.py
│   ├── ac701.yml
│   ├── acorn.yml
│   └── kcu105.yml
├── litepcie
│   ├── __init__.py
│   ├── common.py
│   ├── core
│   │   ├── __init__.py
│   │   ├── common.py
│   │   ├── crossbar.py
│   │   ├── endpoint.py
│   │   ├── msi.py
│   │   └── rootport.py
│   ├── frontend
│   │   ├── __init__.py
│   │   ├── axi.py
│   │   ├── dma.py
│   │   ├── ptm
│   │   │   ├── __init__.py
│   │   │   ├── core.py
│   │   │   ├── sniffer.py
│   │   │   └── sniffer_tap.v
│   │   └── wishbone.py
│   ├── gen.py
│   ├── phy
│   │   ├── __init__.py
│   │   ├── axis_adapters.py
│   │   ├── c5pciephy.py
│   │   ├── common.py
│   │   ├── gw5apciephy.py
│   │   ├── lfcpnxpciephy.py
│   │   ├── s7pciephy.py
│   │   ├── uspciephy.py
│   │   └── usppciephy.py
│   ├── software
│   │   ├── __init__.py
│   │   ├── kernel
│   │   │   ├── Makefile
│   │   │   ├── README
│   │   │   ├── config.h
│   │   │   ├── flags.h
│   │   │   ├── init.sh
│   │   │   ├── litepcie.h
│   │   │   ├── liteuart.c
│   │   │   ├── litex.h
│   │   │   └── main.c
│   │   └── user
│   │       ├── Makefile
│   │       ├── liblitepcie
│   │       │   ├── liblitepcie.h
│   │       │   ├── litepcie_dma.c
│   │       │   ├── litepcie_dma.h
│   │       │   ├── litepcie_flash.c
│   │       │   ├── litepcie_flash.h
│   │       │   ├── litepcie_helpers.c
│   │       │   └── litepcie_helpers.h
│   │       ├── litepcie_test.c
│   │       └── litepcie_util.c
│   └── tlp
│       ├── __init__.py
│       ├── common.py
│       ├── controller.py
│       ├── depacketizer.py
│       └── packetizer.py
├── setup.py
└── test
    ├── __init__.py
    ├── common.py
    ├── model
    │   ├── __init__.py
    │   ├── chipset.py
    │   ├── host.py
    │   ├── phy.py
    │   └── tlp.py
    ├── test_axis_adapter_cross_width_properties.py
    ├── test_dma.py
    ├── test_examples.py
    ├── test_m_axis_cq_adapter.py
    ├── test_m_axis_rc_adapter.py
    ├── test_s_axis_cc_adapter.py
    ├── test_s_axis_rq_adapter.py
    └── test_wishbone.py

```

`CONTRIBUTORS`:

```
LiteX ecosystem would not exist without the collaborative work of contributors! Here is below the
list of all the LitePCIe contributors.

In the source code, each file list the main authors/contributors:
- author(s) that created the initial content.
- contributor(s) that added essential features/improvements.

If you think you should be in this list and don't find yourself, write to florent@enjoy-digital.fr
and we'll fix it!

Contributors:
Copyright (c) 2021      Ahmad Fatoum <ahmad@a3f.at>
Copyright (c) 2020      Antmicro <Antmicro.com>
Copyright (c) 2018      Felix Held <felix-github@felixheld.de>
Copyright (c) 2015-2025 Florent Kermarrec <florent@enjoy-digital.fr>
Copyright (c) 2021-2025 Gwenhael Goavec-Merou <gwenhael@enjoy-digital.fr>
Copyright (c) 2019-2021 Ilia Sergachev <ilia.sergachev@pm.me>
Copyright (c) 2023-2024 John Simons <jammsimons@gmail.com>
Copyright (c) 2024      Liam Murphy <liampm32@gmail.com>
Copyright (c) 2022      Steve Kelly <kd2cca@gmail.com>
Copyright (c) 2022-2024 Sylvain Munaut <tnt@246tNt.com>
Copyright (c) 2021      Tim Besard <tim.besard@gmail.com>
Copyright (c) 2017      Tim 'mithro' Ansell <me@mith.ro>
Copyright (c) 2023-2024 Tim Paine <3105306+timkpaine@users.noreply.github.com>
Copyright (c) 2025      Tomas Šervenikas <t.servenikas@limemicro.com>
Copyright (c) 2021      tongchen126 <tongchen126@gmail.com>
Copyright (c) 2024      Vladimir Pinchuk <vladimir.pinchuk01@gmail.com>

```

`LICENSE`:

```
Unless otherwise noted, LitePCIe is Copyright 2015-2024 / EnjoyDigital

Redistribution and use in source and binary forms, with or without modification,
are permitted provided that the following conditions are met:

1. Redistributions of source code must retain the above copyright notice, this
   list of conditions and the following disclaimer.
2. Redistributions in binary form must reproduce the above copyright notice,
   this list of conditions and the following disclaimer in the documentation
   and/or other materials provided with the distribution.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND
ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED
WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT OWNER OR CONTRIBUTORS BE LIABLE FOR
ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES
(INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES;
LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON
ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT
(INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS
SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.


Other authors retain ownership of their contributions. If a submission can
reasonably be considered independently copyrightable, it's yours and we
encourage you to claim it with appropriate copyright notices. This submission
then falls under the "otherwise noted" category. All submissions are strongly
encouraged to use the two-clause BSD license reproduced above.

```

`MANIFEST.in`:

```in
graft litepcie

include CONTRIBUTORS
include LICENSE

graft doc

prune bench
prune examples
prune test

```

`README.md`:

```md
```
                                  __   _ __      ___  _________
                                 / /  (_) /____ / _ \/ ___/  _/__
                                / /__/ / __/ -_) ___/ /___/ // -_)
                               /____/_/\__/\__/_/   \___/___/\__/

                               Copyright 2015-2024 / EnjoyDigital

                            A small footprint and configurable PCIe core
                                     powered by Migen & LiteX
```

[![](https://github.com/enjoy-digital/litepcie/workflows/ci/badge.svg)](https://github.com/enjoy-digital/litepcie/actions) ![License](https://img.shields.io/badge/License-BSD%202--Clause-orange.svg) [![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/enjoy-digital/litepcie)


[> Intro
--------
LitePCIe provides a small footprint and configurable PCIe core.

LitePCIe is part of LiteX libraries whose aims are to lower entry level of
complex FPGA cores by providing simple, elegant and efficient implementations
of components used in today's SoC such as Ethernet, SATA, PCIe, SDRAM Controller...

Using Migen to describe the HDL allows the core to be highly and easily configurable.

LitePCIe can be used as LiteX library or can be integrated with your standard
design flow by generating the verilog rtl that you will use as a standard core.

<p align="center"><img src="https://github.com/enjoy-digital/litepcie/raw/master/doc/architecture.png" width="800"></p>

[> Features
-----------
PHY:
  - Xilinx Ultrascale(+) (up to PCIe Gen3 X16).
  - Xilinx 7-Series (up to PCIe Gen2 X8).
  - Intel Cyclone5  (up to PCIe Gen2 X4).
  - 64/128/256/512-bit datapath.
  - Clock domain crossing.

Core:
  - TLP layer.
  - Reordering.
  - MSI (Single, Multi-vector)/MSI-X.
  - Crossbar.

Frontend:
  - DMA (with Scatter-Gather).
  - MMAP (AXI/Wishbone Slave/Master).
  - PTM (on Xilinx 7-Series/Gen2 X1 for now).

Software:
  - Linux Driver (MMAP and DMA).

[> FPGA Proven
---------------
LitePCIe is already used in commercial and open-source designs:
- 3G-SDI Capture/Playback board: http://www.enjoy-digital.fr/experience/pcie_3g_sdi.jpg
- SDR MIMO 2x2 board: https://www.amarisoft.com/products-lte-ue-ots-sdr-pcie/#sdr
- SDR MIMO 4x4 board: http://www.enjoy-digital.fr/experience/pcie_ad937x.jpg
- SDR CPRI board: http://www.enjoy-digital.fr/experience/pcie_sfp.jpg
- PCIe TLP sniffer/injector: https://ramtin-amin.fr/#nvmedma
- and others commercial designs...

[> Possible improvements
------------------------
- add standardized interfaces (AXI, Avalon-ST)
- add Intel Stratix support
- add Lattice support
- add more documentation
- ... See below Support and consulting :)

If you want to support these features, please contact us at florent [AT]
enjoy-digital.fr.

[> Getting started
------------------
1. Install Python 3.8+ and FPGA vendor's development tools.
2. Install LiteX and the cores by following the LiteX's wiki [installation guide](https://github.com/enjoy-digital/litex/wiki/Installation).
3. You can find examples of integration of the core with LiteX in LiteX-Boards and in the examples directory.

[> Tests
--------
Unit tests are available in ./test/.
To run all the unit tests:
```sh
$ ./setup.py test
```

Tests can also be run individually:
```sh
$ python3 -m unittest test.test_name
```

[> License
----------
LitePCIe is released under the very permissive two-clause BSD license. Under
the terms of this license, you are authorized to use LitePCIe for closed-source
proprietary designs.
Even though we do not require you to do so, those things are awesome, so please
do them if possible:
 - tell us that you are using LitePCIe
 - cite LitePCIe in publications related to research it has helped
 - send us feedback and suggestions for improvements
 - send us bug reports when something goes wrong
 - send us the modifications and improvements you have done to LitePCIe.

[> Support and consulting
-------------------------
We love open-source hardware and like sharing our designs with others.

LitePCIe is developed and maintained by EnjoyDigital.

If you would like to know more about LitePCIe or if you are already a happy
user and would like to extend it for your needs, EnjoyDigital can provide standard
commercial support as well as consulting services.

So feel free to contact us, we'd love to work with you! (and eventually shorten
the list of the possible improvements :)

[> Contact
----------
E-mail: florent [AT] enjoy-digital.fr

```

`bench/acorn.py`:

```py
#!/usr/bin/env python3

#
# This file is part of LitePCIe.
#
# Copyright (c) 2022 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

import os
import yaml
import argparse

from migen import *

from litex.gen import *

from litex_boards.platforms import sqrl_acorn

from litex.soc.cores.clock import S7PLL
from litex.soc.interconnect.csr import *
from litex.soc.integration.soc_core import *
from litex.soc.integration.builder import *

from litepcie.phy import s7pciephy

# CRG ----------------------------------------------------------------------------------------------

class _CRG(LiteXModule):
    def __init__(self, platform, sys_clk_freq):
        self.cd_sys = ClockDomain()

        # # #

        # PLL
        self.pll = pll = S7PLL(speedgrade=-2)
        pll.register_clkin(platform.request("clk200"), 200e6)
        pll.create_clkout(self.cd_sys, sys_clk_freq)

# LitePCIeSoC --------------------------------------------------------------------------------------

class LitePCIeSoC(SoCMini):
    def __init__(self,  platform, sys_clk_freq=int(125e6)):
        # CRG --------------------------------------------------------------------------------------
        self.crg = _CRG(platform, sys_clk_freq)

        # SoCMini ----------------------------------------------------------------------------------
        SoCMini.__init__(self, platform, sys_clk_freq, ident="LitePCIe standalone example design on Acorn")

        # LitePCIe core generation -----------------------------------------------------------------
        core_config = yaml.load(open("../examples/acorn.yml").read(), Loader=yaml.Loader)
        os.system("litepcie_gen ../examples/acorn.yml")

        # LitePCIe instance ------------------------------------------------------------------------
        pcie_pads  = platform.request("pcie_x4")
        litepcie_core_params = dict(
            # Clk / Rst ----------------------------------------------------------------------------
            i_clk                    = ClockSignal("sys"),
            i_rst                    = ResetSignal("sys"),

            # PCIe pins ----------------------------------------------------------------------------
            i_pcie_rst_n             = pcie_pads.rst_n,
            i_pcie_clk_p             = pcie_pads.clk_p,
            i_pcie_clk_n             = pcie_pads.clk_n,
            i_pcie_rx_p              = pcie_pads.rx_p,
            i_pcie_rx_n              = pcie_pads.rx_n,
            o_pcie_tx_p              = pcie_pads.tx_p,
            o_pcie_tx_n              = pcie_pads.tx_n,

            # AXI MMAP -----------------------------------------------------------------------------
            o_mmap_axi_lite_awvalid  = Open(),
            i_mmap_axi_lite_awready  = 1,
            o_mmap_axi_lite_awaddr   = Open(),

            o_mmap_axi_lite_wvalid   = Open(),
            i_mmap_axi_lite_wready   = 0,
            o_mmap_axi_lite_wstrb    = Open(),
            o_mmap_axi_lite_wdata    = Open(),

            i_mmap_axi_lite_bvalid   = 0,
            o_mmap_axi_lite_bready   = Open(),
            i_mmap_axi_lite_bresp    = 0,

            o_mmap_axi_lite_arvalid  = Open(),
            i_mmap_axi_lite_arready  = 0,
            o_mmap_axi_lite_araddr   = Open(),

            i_mmap_axi_lite_rvalid   = 0,
            o_mmap_axi_lite_rready   = Open(),
            i_mmap_axi_lite_rdata    = 0,
            i_mmap_axi_lite_rresp    = 0,

            # AXI ST DMA0 --------------------------------------------------------------------------
            i_dma0_writer_axi_tvalid = 0,
            o_dma0_writer_axi_tready = Open(),
            i_dma0_writer_axi_tlast  = 0,
            i_dma0_writer_axi_tdata  = 0,

            o_dma0_reader_axi_tvalid = Open(),
            i_dma0_reader_axi_tready = 0,
            o_dma0_reader_axi_tlast  = Open(),
            o_dma0_reader_axi_tdata  = Open(),

            # AXI ST DMA1 --------------------------------------------------------------------------
            i_dma1_writer_axi_tvalid = 0,
            o_dma1_writer_axi_tready = Open(),
            i_dma1_writer_axi_tlast  = 0,
            i_dma1_writer_axi_tdata  = 0,

            o_dma1_reader_axi_tvalid = Open(),
            i_dma1_reader_axi_tready = 0,
            o_dma1_reader_axi_tlast  = Open(),
            o_dma1_reader_axi_tdata  = Open(),

            # AXI ST DMA2 --------------------------------------------------------------------------
            i_dma2_writer_axi_tvalid = 0,
            o_dma2_writer_axi_tready = Open(),
            i_dma2_writer_axi_tlast  = 0,
            i_dma2_writer_axi_tdata  = 0,

            o_dma2_reader_axi_tvalid = Open(),
            i_dma2_reader_axi_tready = 0,
            o_dma2_reader_axi_tlast  = Open(),
            o_dma2_reader_axi_tdata  = Open(),

            # AXI ST DMA3 --------------------------------------------------------------------------
            i_dma3_writer_axi_tvalid = 0,
            o_dma3_writer_axi_tready = Open(),
            i_dma3_writer_axi_tlast  = 0,
            i_dma3_writer_axi_tdata  = 0,

            o_dma3_reader_axi_tvalid = Open(),
            i_dma3_reader_axi_tready = 0,
            o_dma3_reader_axi_tlast  = Open(),
            o_dma3_reader_axi_tdata  = Open(),

            # Interrupts ---------------------------------------------------------------------------
            i_msi_irqs               = 0,
        )
        self.specials += Instance("litepcie_core", **litepcie_core_params)
        platform.add_period_constraint(pcie_pads.clk_p, 1e9/100e6)
        platform.toolchain.pre_placement_commands.append("set_false_path -from [get_clocks userclk2] -to [get_clocks litepciesoc_clkout]")
        platform.toolchain.pre_placement_commands.append("set_false_path -from [get_clocks litepciesoc_clkout] -to [get_clocks userclk2]")

        # LitePCIe sources -------------------------------------------------------------------------
        # LitePCIe core
        platform.add_source("build/gateware/litepcie_core.v")
        # Xilinx PHY
        phy_path = os.path.dirname(s7pciephy.__file__)
        platform.add_source(os.path.join(phy_path, "xilinx_s7_gen2", "pcie_pipe_clock.v"))
        platform.add_source(os.path.join(phy_path, "xilinx_s7_gen2", "pcie_s7_support.v"))
        config = {
                "Bar0_Scale"         : "Megabytes",
                "Bar0_Size"          : 128, # FIXME: Use core_config["phy_bar0_size"].
                "Buf_Opt_BMA"        : True,
                "Component_Name"     : "pcie",
                "Device_ID"          : 7024,
                "IntX_Generation"    : False,
                "Interface_Width"    : "128_bit",
                "Legacy_Interrupt"   : None,
                "Multiple_Message_Capable"  : '1_vector',
                "Link_Speed"         : "5.0_GT/s",
                "MSI_64b"            : False,
                "Max_Payload_Size"   : "512_bytes",
                "Maximum_Link_Width" : "X4",
                "PCIe_Blk_Locn"      : "X0Y0",
                "Ref_Clk_Freq"       : "100_MHz",
                "Trans_Buf_Pipeline" : None,
                "Trgt_Link_Speed"    : "4'h2",
                "User_Clk_Freq"      : 125,
            }
        ip_tcl = []
        ip_tcl.append("create_ip -vendor xilinx.com -name pcie_7x -module_name pcie_s7")
        ip_tcl.append("set obj [get_ips pcie_s7]")
        ip_tcl.append("set_property -dict [list \\")
        for config, value in config.items():
            ip_tcl.append("CONFIG.{} {} \\".format(config, '{{' + str(value) + '}}'))
        ip_tcl.append(f"] $obj")
        ip_tcl.append("synth_ip $obj")
        platform.toolchain.pre_synthesis_commands += ip_tcl

# Build --------------------------------------------------------------------------------------------

def main():
    parser = argparse.ArgumentParser(description="LitePCIe SoC on Acorn")
    parser.add_argument("--build",  action="store_true", help="Build bitstream")
    parser.add_argument("--load",   action="store_true", help="Load bitstream (to SRAM)")
    args = parser.parse_args()

    platform = sqrl_acorn.Platform()
    soc      = LitePCIeSoC(platform)
    builder  = Builder(soc)
    builder.build(run=args.build)

    if args.load:
        prog = soc.platform.create_programmer()
        prog.load_bitstream(os.path.join(builder.gateware_dir, soc.build_name + ".bit"))

if __name__ == "__main__":
    main()

```

`bench/fk33.py`:

```py
#!/usr/bin/env python3

#
# This file is part of LitePCIe.
#
# Copyright (c) 2020 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

import os
import argparse

from migen import *

from litex.gen import *

from litex_boards.platforms import sqrl_fk33

from litex.soc.cores.clock import USPPLL
from litex.soc.interconnect.csr import *
from litex.soc.integration.soc_core import *
from litex.soc.integration.builder import *

from litepcie.phy.usppciephy import USPHBMPCIEPHY
from litepcie.core import LitePCIeEndpoint, LitePCIeMSI
from litepcie.frontend.dma import LitePCIeDMA
from litepcie.frontend.wishbone import LitePCIeWishboneBridge
from litepcie.software import generate_litepcie_software

# CRG ----------------------------------------------------------------------------------------------

class _CRG(LiteXModule):
    def __init__(self, platform, sys_clk_freq):
        self.cd_sys = ClockDomain()

        # # #

        # PLL
        self.pll = pll = USPPLL(speedgrade=-2)
        pll.register_clkin(platform.request("clk200"), 200e6)
        pll.create_clkout(self.cd_sys, sys_clk_freq)

# LitePCIeSoC --------------------------------------------------------------------------------------

class LitePCIeSoC(SoCMini):
    configs = {
        # Gen3  data_width, sys_clk_freq
        "gen3:x4" : (128, int(200e6)),
        "gen3:x8" : (256, int(200e6)),
        "gen3:x16": (512, int(200e6)),
    }
    def __init__(self, platform, speed="gen3", nlanes=4):
        data_width, sys_clk_freq = self.configs[speed + f":x{nlanes}"]

        # SoCMini ----------------------------------------------------------------------------------
        SoCMini.__init__(self, platform, sys_clk_freq, ident=f"LitePCIe example design on FK33 ({speed}:x{nlanes})")

        # CRG --------------------------------------------------------------------------------------
        self.crg = _CRG(platform, sys_clk_freq)

        # JTAGBone ---------------------------------------------------------------------------------
        self.add_jtagbone()

        # PCIe -------------------------------------------------------------------------------------
        # PHY
        self.pcie_phy = USPHBMPCIEPHY(platform, platform.request(f"pcie_x{nlanes}"),
            speed      = speed,
            data_width = data_width,
            bar0_size  = 0x20000,
        )
        self.pcie_phy.add_ltssm_tracer()

        # Endpoint
        self.pcie_endpoint = LitePCIeEndpoint(self.pcie_phy,
            endianness           = "little",
            max_pending_requests = 8
        )

        # Wishbone bridge
        self.pcie_bridge = LitePCIeWishboneBridge(self.pcie_endpoint,
            base_address = self.mem_map["csr"])
        self.bus.add_master(master=self.pcie_bridge.wishbone)

        # DMA0
        self.pcie_dma0 = LitePCIeDMA(self.pcie_phy, self.pcie_endpoint,
            with_buffering = True, buffering_depth=1024,
            with_loopback  = True)

        # DMA1
        self.pcie_dma1 = LitePCIeDMA(self.pcie_phy, self.pcie_endpoint,
            with_buffering = True, buffering_depth=1024,
            with_loopback  = True)

        self.add_constant("DMA_CHANNELS", 2)
        self.add_constant("DMA_ADDR_WIDTH", 32)

        # MSI
        self.pcie_msi = LitePCIeMSI()
        self.comb += self.pcie_msi.source.connect(self.pcie_phy.msi)
        self.interrupts = {
            "PCIE_DMA0_WRITER":    self.pcie_dma0.writer.irq,
            "PCIE_DMA0_READER":    self.pcie_dma0.reader.irq,
            "PCIE_DMA1_WRITER":    self.pcie_dma1.writer.irq,
            "PCIE_DMA1_READER":    self.pcie_dma1.reader.irq,
        }
        for i, (k, v) in enumerate(sorted(self.interrupts.items())):
            self.comb += self.pcie_msi.irqs[i].eq(v)
            self.add_constant(k + "_INTERRUPT", i)

# Build --------------------------------------------------------------------------------------------

def main():
    parser = argparse.ArgumentParser(description="LitePCIe SoC on FK33")
    parser.add_argument("--build",  action="store_true", help="Build bitstream")
    parser.add_argument("--driver", action="store_true", help="Generate LitePCIe driver")
    parser.add_argument("--load",   action="store_true", help="Load bitstream (to SRAM)")
    parser.add_argument("--speed",  default="gen3",      help="PCIe speed: gen3")
    parser.add_argument("--nlanes", default=4,           help="PCIe lanes: 4 (default), 8 or 16")
    args = parser.parse_args()

    platform = sqrl_fk33.Platform()
    soc      = LitePCIeSoC(platform, speed=args.speed, nlanes=int(args.nlanes))
    builder  = Builder(soc, output_dir="build/fk33", csr_csv="csr.csv")
    builder.build(build_name="fk33", run=args.build)

    if args.driver:
        generate_litepcie_software(soc, os.path.join(builder.output_dir, "driver"))

    if args.load:
        prog = soc.platform.create_programmer()
        prog.load_bitstream(os.path.join(builder.gateware_dir, soc.build_name + ".bit"))

if __name__ == "__main__":
    main()

```

`bench/kc705.py`:

```py
#!/usr/bin/env python3

#
# This file is part of LitePCIe.
#
# Copyright (c) 2015-2020 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

import os
import argparse

from migen import *

from litex.gen import *

from litex_boards.platforms import xilinx_kc705

from litex.soc.cores.clock import S7MMCM
from litex.soc.interconnect.csr import *
from litex.soc.integration.soc_core import *
from litex.soc.integration.builder import *

from litepcie.phy.s7pciephy import S7PCIEPHY
from litepcie.core import LitePCIeEndpoint, LitePCIeMSI
from litepcie.frontend.dma import LitePCIeDMA
from litepcie.frontend.wishbone import LitePCIeWishboneBridge
from litepcie.software import generate_litepcie_software

# CRG ----------------------------------------------------------------------------------------------

class _CRG(LiteXModule):
    def __init__(self, platform, sys_clk_freq):
        self.cd_sys = ClockDomain()

        # # #

        # PLL
        self.pll = pll = S7MMCM(speedgrade=-2)
        pll.register_clkin(platform.request("clk200"), 200e6)
        pll.create_clkout(self.cd_sys, sys_clk_freq)

# LitePCIeSoC --------------------------------------------------------------------------------------

class LitePCIeSoC(SoCMini):
    configs = {
        # Gen2  data_width, sys_clk_freq
        "gen2:x1": (64,   int(125e6)),
        "gen2:x4": (128,  int(200e6)),
        "gen2:x8": (128,  int(200e6)),
    }
    def __init__(self, platform, speed="gen2", nlanes=4):
        data_width, sys_clk_freq = self.configs[speed + f":x{nlanes}"]

        # SoCMini ----------------------------------------------------------------------------------
        SoCMini.__init__(self, platform, sys_clk_freq, ident=f"LitePCIe example design on KC705 ({speed}:x{nlanes})")

        # CRG --------------------------------------------------------------------------------------
        self.crg = _CRG(platform, sys_clk_freq)

        # UARTBone ---------------------------------------------------------------------------------
        self.add_uartbone()

        # PCIe -------------------------------------------------------------------------------------
        # PHY
        self.pcie_phy = S7PCIEPHY(platform, platform.request(f"pcie_x{nlanes}"),
            data_width = data_width,
            bar0_size  = 0x20000,
        )
        self.pcie_phy.add_ltssm_tracer()

        # Endpoint
        self.pcie_endpoint = LitePCIeEndpoint(self.pcie_phy,
            endianness           = "big",
            max_pending_requests = 8
        )

        # Wishbone bridge
        self.pcie_bridge = LitePCIeWishboneBridge(self.pcie_endpoint,
            base_address = self.mem_map["csr"])
        self.bus.add_master(master=self.pcie_bridge.wishbone)

        # DMA0
        self.pcie_dma0 = LitePCIeDMA(self.pcie_phy, self.pcie_endpoint,
            with_buffering = True, buffering_depth=1024,
            with_loopback  = True)

        # DMA1
        self.pcie_dma1 = LitePCIeDMA(self.pcie_phy, self.pcie_endpoint,
            with_buffering = True, buffering_depth=1024,
            with_loopback  = True)

        self.add_constant("DMA_CHANNELS", 2)
        self.add_constant("DMA_ADDR_WIDTH", 32)

        # MSI
        self.pcie_msi = LitePCIeMSI()
        self.comb += self.pcie_msi.source.connect(self.pcie_phy.msi)
        self.interrupts = {
            "PCIE_DMA0_WRITER":    self.pcie_dma0.writer.irq,
            "PCIE_DMA0_READER":    self.pcie_dma0.reader.irq,
            "PCIE_DMA1_WRITER":    self.pcie_dma1.writer.irq,
            "PCIE_DMA1_READER":    self.pcie_dma1.reader.irq,
        }
        for i, (k, v) in enumerate(sorted(self.interrupts.items())):
            self.comb += self.pcie_msi.irqs[i].eq(v)
            self.add_constant(k + "_INTERRUPT", i)

# Build --------------------------------------------------------------------------------------------

def main():
    parser = argparse.ArgumentParser(description="LitePCIe SoC on KC705")
    parser.add_argument("--build",  action="store_true", help="Build bitstream")
    parser.add_argument("--driver", action="store_true", help="Generate LitePCIe driver")
    parser.add_argument("--load",   action="store_true", help="Load bitstream (to SRAM)")
    parser.add_argument("--nlanes", default=4,           help="PCIe lanes: 1, 4 (default) or 8")
    args = parser.parse_args()

    platform = xilinx_kc705.Platform()
    soc      = LitePCIeSoC(platform, nlanes=int(args.nlanes))
    builder  = Builder(soc, output_dir="build/kc705", csr_csv="csr.csv")
    builder.build(build_name="kc705", run=args.build)

    if args.driver:
        generate_litepcie_software(soc, os.path.join(builder.output_dir, "driver"))

    if args.load:
        prog = soc.platform.create_programmer()
        prog.load_bitstream(os.path.join(builder.gateware_dir, soc.build_name + ".bit"))

if __name__ == "__main__":
    main()

```

`bench/kcu105.py`:

```py
#!/usr/bin/env python3

#
# This file is part of LitePCIe.
#
# Copyright (c) 2020 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

import os
import argparse

from migen import *

from litex.gen import *

from litex_boards.platforms import xilinx_kcu105

from litex.soc.cores.clock import USPLL
from litex.soc.interconnect.csr import *
from litex.soc.integration.soc_core import *
from litex.soc.integration.builder import *

from litepcie.phy.uspciephy import USPCIEPHY
from litepcie.core import LitePCIeEndpoint, LitePCIeMSI
from litepcie.frontend.dma import LitePCIeDMA
from litepcie.frontend.wishbone import LitePCIeWishboneBridge
from litepcie.software import generate_litepcie_software

# CRG ----------------------------------------------------------------------------------------------

class _CRG(LiteXModule):
    def __init__(self, platform, sys_clk_freq):
        self.clock_domains.cd_sys = ClockDomain()

        # # #

        # PLL
        self.pll = pll = USPLL(speedgrade=-2)
        pll.register_clkin(platform.request("clk125"), 125e6)
        pll.create_clkout(self.cd_sys, sys_clk_freq)

# LitePCIeSoC --------------------------------------------------------------------------------------

class LitePCIeSoC(SoCMini):
    configs = {
        # Gen3  data_width, sys_clk_freq
        "gen3:x4": (128, int(200e6)),
        "gen3:x8": (256, int(200e6)),
    }
    def __init__(self, platform, speed="gen3", nlanes=4):
        data_width, sys_clk_freq = self.configs[speed + f":x{nlanes}"]

        # SoCMini ----------------------------------------------------------------------------------
        SoCMini.__init__(self, platform, sys_clk_freq, ident=f"LitePCIe example design on KCU105 ({speed}:x{nlanes})")

        # CRG --------------------------------------------------------------------------------------
        self.crg = _CRG(platform, sys_clk_freq)

        # UARTBone ---------------------------------------------------------------------------------
        self.add_uartbone()

        # PCIe -------------------------------------------------------------------------------------
        # PHY
        self.pcie_phy = USPCIEPHY(platform, platform.request(f"pcie_x{nlanes}"),
            speed      = speed,
            data_width = data_width,
            bar0_size  = 0x20000,
        )
        self.pcie_phy.add_ltssm_tracer()

        # Endpoint
        self.pcie_endpoint = LitePCIeEndpoint(self.pcie_phy,
            endianness           = "little",
            max_pending_requests = 8
        )

        # Wishbone bridge
        self.pcie_bridge = LitePCIeWishboneBridge(self.pcie_endpoint,
            base_address = self.mem_map["csr"])
        self.bus.add_master(master=self.pcie_bridge.wishbone)

        # DMA0
        self.pcie_dma0 = LitePCIeDMA(self.pcie_phy, self.pcie_endpoint,
            with_buffering = True, buffering_depth=1024,
            with_loopback  = True)

        # DMA1
        self.pcie_dma1 = LitePCIeDMA(self.pcie_phy, self.pcie_endpoint,
            with_buffering = True, buffering_depth=1024,
            with_loopback  = True)

        self.add_constant("DMA_CHANNELS", 2)
        self.add_constant("DMA_ADDR_WIDTH", 32)

        # MSI
        self.pcie_msi = LitePCIeMSI()
        self.comb += self.pcie_msi.source.connect(self.pcie_phy.msi)
        self.interrupts = {
            "PCIE_DMA0_WRITER":    self.pcie_dma0.writer.irq,
            "PCIE_DMA0_READER":    self.pcie_dma0.reader.irq,
            "PCIE_DMA1_WRITER":    self.pcie_dma1.writer.irq,
            "PCIE_DMA1_READER":    self.pcie_dma1.reader.irq,
        }
        for i, (k, v) in enumerate(sorted(self.interrupts.items())):
            self.comb += self.pcie_msi.irqs[i].eq(v)
            self.add_constant(k + "_INTERRUPT", i)

# Build --------------------------------------------------------------------------------------------

def main():
    parser = argparse.ArgumentParser(description="LitePCIe SoC on KCU105")
    parser.add_argument("--build",  action="store_true", help="Build bitstream")
    parser.add_argument("--driver", action="store_true", help="Generate LitePCIe driver")
    parser.add_argument("--load",   action="store_true", help="Load bitstream (to SRAM)")
    parser.add_argument("--speed",  default="gen3",      help="PCIe speed: gen3")
    parser.add_argument("--nlanes", default=4,           help="PCIe lanes: 4 (default) or 8")
    args = parser.parse_args()

    platform = xilinx_kcu105.Platform()
    soc      = LitePCIeSoC(platform, speed=args.speed, nlanes=int(args.nlanes))
    builder  = Builder(soc, output_dir="build/kcu105", csr_csv="csr.csv")
    builder.build(build_name="kcu105", run=args.build)

    if args.driver:
        generate_litepcie_software(soc, os.path.join(builder.output_dir, "driver"))

    if args.load:
        prog = soc.platform.create_programmer()
        prog.load_bitstream(os.path.join(builder.gateware_dir, soc.build_name + ".bit"))

if __name__ == "__main__":
    main()

```

`bench/test_ltssm_tracer.py`:

```py
#!/usr/bin/env python3

#
# This file is part of LitePCIe.
#
# Copyright (c) 2022 Sylvain Munaut <tnt@246tNt.com>
# SPDX-License-Identifier: BSD-2-Clause

import os
import argparse
import socket

from litex import RemoteClient

# PCIe LTSSM Dictionary for Xilinx 7-Series --------------------------------------------------------

PCIE_LTSSM_7SERIES = {
    0x00 : "Detect Quiet",
    0x01 : "Detect Quiet",
    0x02 : "Detect Active",
    0x03 : "Detect Active",
    0x04 : "Polling Active",
    0x05 : "Polling Configuration",
    0x06 : "Polling Compliance, Pre_Send_EIOS",
    0x07 : "Polling Compliance, Pre_Timeout",
    0x08 : "Polling Compliance, Send_Pattern",
    0x09 : "Polling Compliance, Post_Send_EIOS",
    0x0A : "Polling Compliance, Post_Timeout",
    0x0B : "Configuration Linkwidth, State 0",
    0x0C : "Configuration Linkwidth, State 1",
    0x0D : "Configuration Linkwidth, Accept 0",
    0x0E : "Configuration Linkwidth, Accept 1",
    0x0F : "Configuration Lanenum Wait",
    0x10 : "Configuration Lanenum, Accept",
    0x11 : "Configuration Complete x1",
    0x12 : "Configuration Complete x2",
    0x13 : "Configuration Complete x4",
    0x14 : "Configuration Complete x8",
    0x15 : "Configuration Idle",
    0x16 : "L0",
    0x17 : "L1 Entry0",
    0x18 : "L1 Entry1",
    0x19 : "L1 Entry2 (also used for the L2/L3 Ready pseudo state)",
    0x1A : "L1 Idle",
    0x1B : "L1 Exit",
    0x1C : "Recovery Rcvrlock",
    0x1D : "Recovery Rcvrcfg",
    0x1E : "Recovery Speed_0",
    0x1F : "Recovery Speed_1",
    0x20 : "Recovery Idle",
    0x21 : "Hot Reset",
    0x22 : "Disabled Entry 0",
    0x23 : "Disabled Entry 1",
    0x24 : "Disabled Entry 2",
    0x25 : "Disabled Idle",
    0x26 : "Root Port, Configuration, Linkwidth State 0",
    0x27 : "Root Port, Configuration, Linkwidth State 1",
    0x28 : "Root Port, Configuration, Linkwidth State 2",
    0x29 : "Root Port, Configuration, Link Width Accept 0",
    0x2A : "Root Port, Configuration, Link Width Accept 1",
    0x2B : "Root Port, Configuration, Lanenum_Wait",
    0x2C : "Root Port, Configuration, Lanenum_Accept",
    0x2D : "Timeout To Detect",
    0x2E : "Loopback Entry0",
    0x2F : "Loopback Entry1",
    0x30 : "Loopback Active0",
    0x31 : "Loopback Exit0",
    0x32 : "Loopback Exit1",
    0x33 : "Loopback Master Entry0",
}

# PCIe LTSSM Dictionary for Xilinx UltraScale and UltraScale+ --------------------------------------

PCIE_LTSSM_ULTRASCALE = {
    0x00 : "Detect.Quiet",
    0x01 : "Detect.Active",
    0x02 : "Polling.Active",
    0x03 : "Polling.Compliance",
    0x04 : "Polling.Configuration",
    0x05 : "Configuration.Linkwidth.Start",
    0x06 : "Configuration.Linkwidth.Accept",
    0x07 : "Configuration.Lanenum.Accept",
    0x08 : "Configuration.Lanenum.Wait",
    0x09 : "Configuration.Complete",
    0x0A : "Configuration.Idle",
    0x0B : "Recovery.RcvrLock",
    0x0C : "Recovery.Speed",
    0x0D : "Recovery.RcvrCfg",
    0x0E : "Recovery.Idle",
    0x10 : "L0",
    0x11 : "Rx_L0s.Entry",
    0x12 : "Rx_L0s.Idle",
    0x13 : "Rx_L0s.FTS",
    0x14 : "Tx_L0s.Entry",
    0x15 : "Tx_L0s.Idle",
    0x16 : "Tx_L0s.FTS",
    0x19 : "L2.Idle",
    0x1A : "L2.TransmitWake",
    0x20 : "Disabled",
    0x21 : "Loopback_Entry_Master",
    0x22 : "Loopback_Active_Master",
    0x23 : "Loopback_Exit_Master",
    0x24 : "Loopback_Entry_Slave",
    0x25 : "Loopback_Active_Slave",
    0x26 : "Loopback_Exit_Slave",
    0x27 : "Hot_Reset",
    0x28 : "Recovery_Equalization_Phase0",
    0x29 : "Recovery_Equalization_Phase1",
    0x2A : "Recovery_Equalization_Phase2",
    0x2B : "Recovery_Equalization_Phase3",
}

# PCIe LTSSM Tracer --------------------------------------------------------------------------------
def main():
    parser = argparse.ArgumentParser(description="LitePCIe LTSSM tracer.")
    parser.add_argument("--csr-csv", default="csr.csv", help="CSR configuration file")
    parser.add_argument("--port",    default="1234",    help="Host bind port.")
    parser.add_argument("--family",  default='7series', help="FPGA family.", choices=["7series", "ultrascale"])
    args = parser.parse_args()

    bus = RemoteClient(
        csr_csv = args.csr_csv,
        port    = int(args.port, 0)
    )
    bus.open()

    ltssm_dict = {
        "7series"    : PCIE_LTSSM_7SERIES,
        "ultrascale" : PCIE_LTSSM_ULTRASCALE
    }[args.family]

    # Read history
    while True:
        v = bus.regs.pcie_phy_ltssm_tracer_history.read()

        ltssm_new = (v >>  0) & 0x3f
        ltssm_old = (v >>  6) & 0x3f
        overflow  = (v >> 30) & 1
        valid     = (v >> 31) & 1
        if not valid:
            break
        print(f"[0x{ltssm_old:02x}] {ltssm_dict.get(ltssm_old, 'reserved'):<32s} -> [0x{ltssm_new:02x}] {ltssm_dict.get(ltssm_new, 'reserved'):<32s}{('[Overflow, possible unknown intermediate states]' if overflow else ''):s}")

if __name__ == "__main__":
    main()

```

`bench/xcu1525.py`:

```py
#!/usr/bin/env python3

#
# This file is part of LitePCIe.
#
# Copyright (c) 2020 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

import os
import argparse

from migen import *

from litex.gen import *

from litex_boards.platforms import sqrl_xcu1525

from litex.soc.cores.clock import USPPLL
from litex.soc.interconnect.csr import *
from litex.soc.integration.soc_core import *
from litex.soc.integration.builder import *

from litepcie.phy.usppciephy import USPPCIEPHY
from litepcie.core import LitePCIeEndpoint, LitePCIeMSI
from litepcie.frontend.dma import LitePCIeDMA
from litepcie.frontend.wishbone import LitePCIeWishboneBridge
from litepcie.software import generate_litepcie_software

# CRG ----------------------------------------------------------------------------------------------

class _CRG(LiteXModule):
    def __init__(self, platform, sys_clk_freq):
        self.cd_sys = ClockDomain()

        # # #

        # PLL
        self.pll = pll = USPPLL(speedgrade=-2)
        pll.register_clkin(platform.request("clk300"), 300e6)
        pll.create_clkout(self.cd_sys, sys_clk_freq)

# LitePCIeSoC --------------------------------------------------------------------------------------

class LitePCIeSoC(SoCMini):
    configs = {
        # Gen3  data_width, sys_clk_freq
        "gen3:x4" : (128, int(200e6)),
        "gen3:x8" : (256, int(200e6)),
        "gen3:x16": (512, int(200e6)),
    }
    def __init__(self, platform, speed="gen3", nlanes=4):
        data_width, sys_clk_freq = self.configs[speed + f":x{nlanes}"]

        # SoCMini ----------------------------------------------------------------------------------
        SoCMini.__init__(self, platform, sys_clk_freq, ident=f"LitePCIe example design on XCU1525 ({speed}:x{nlanes})")

        # CRG --------------------------------------------------------------------------------------
        self.crg = _CRG(platform, sys_clk_freq)

        # UARTBone ---------------------------------------------------------------------------------
        self.add_uartbone()

        # PCIe -------------------------------------------------------------------------------------
        # PHY
        self.pcie_phy = USPPCIEPHY(platform, platform.request(f"pcie_x{nlanes}"),
            speed      = speed,
            data_width = data_width,
            bar0_size  = 0x20000,
        )
        self.pcie_phy.add_ltssm_tracer()
        platform.add_false_path_constraints(self.crg.cd_sys.clk, self.pcie_phy.cd_pcie.clk)

        # Endpoint
        self.pcie_endpoint = LitePCIeEndpoint(self.pcie_phy,
            endianness           = "little",
            max_pending_requests = 8
        )

        # Wishbone bridge
        self.pcie_bridge = LitePCIeWishboneBridge(self.pcie_endpoint,
            base_address = self.mem_map["csr"])
        self.bus.add_master(master=self.pcie_bridge.wishbone)

        # DMA0
        self.pcie_dma0 = LitePCIeDMA(self.pcie_phy, self.pcie_endpoint,
            with_buffering = True, buffering_depth=1024,
            with_loopback  = True)

        # DMA1
        self.pcie_dma1 = LitePCIeDMA(self.pcie_phy, self.pcie_endpoint,
            with_buffering = True, buffering_depth=1024,
            with_loopback  = True)

        self.add_constant("DMA_CHANNELS", 2)
        self.add_constant("DMA_ADDR_WIDTH", 32)

        # MSI
        self.pcie_msi = LitePCIeMSI()
        self.comb += self.pcie_msi.source.connect(self.pcie_phy.msi)
        self.interrupts = {
            "PCIE_DMA0_WRITER":    self.pcie_dma0.writer.irq,
            "PCIE_DMA0_READER":    self.pcie_dma0.reader.irq,
            "PCIE_DMA1_WRITER":    self.pcie_dma1.writer.irq,
            "PCIE_DMA1_READER":    self.pcie_dma1.reader.irq,
        }
        for i, (k, v) in enumerate(sorted(self.interrupts.items())):
            self.comb += self.pcie_msi.irqs[i].eq(v)
            self.add_constant(k + "_INTERRUPT", i)

# Build --------------------------------------------------------------------------------------------

def main():
    parser = argparse.ArgumentParser(description="LitePCIe SoC on XCU1525")
    parser.add_argument("--build",  action="store_true", help="Build bitstream")
    parser.add_argument("--driver", action="store_true", help="Generate LitePCIe driver")
    parser.add_argument("--load",   action="store_true", help="Load bitstream (to SRAM)")
    parser.add_argument("--speed",  default="gen3",      help="PCIe speed: gen3")
    parser.add_argument("--nlanes", default=4,           help="PCIe lanes: 4 (default), 8 or 16")
    args = parser.parse_args()

    platform = sqrl_xcu1525.Platform()
    soc      = LitePCIeSoC(platform, speed=args.speed, nlanes=int(args.nlanes))
    builder  = Builder(soc, output_dir="build/xcu1525", csr_csv="csr.csv")
    builder.build(build_name="xcu1525", run=args.build)

    if args.driver:
        generate_litepcie_software(soc, os.path.join(builder.output_dir, "driver"))

    if args.load:
        prog = soc.platform.create_programmer()
        prog.load_bitstream(os.path.join(builder.gateware_dir, soc.build_name + ".bit"))

if __name__ == "__main__":
    main()

```

`examples/ac701.yml`:

```yml
#
# This file is part of LitePCIe.
#
# Copyright (c) 2019-2024 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

{
    # PHY ----------------------------------------------------------------------
    "phy"                     : "S7PCIEPHY", # Type of PCIe PHY
    "phy_device"              : "xc7a",      # Type of Device
    "phy_lanes"               : 4,           # Number of lanes
    "phy_pcie_data_width"     : 128,         # PCIe data_width
    "phy_data_width"          : 128,         # Bus data_width
    "phy_bar0_size"           : 0x40000,     # BAR0 size

    # Clocking -----------------------------------------------------------------
    "clk_freq"                : 125e6, # User Clk Freq (AXI MMAP/DMA)
    "clk_external"            : False, # Use external User provided Clk

    # Endpoint -----------------------------------------------------------------
    "ep_max_pending_requests" : 8,
    "ep_address_width"        : 32,

    # Control ------------------------------------------------------------------
    "ctrl"                    : False,

    # MMAP Master --------------------------------------------------------------
    "mmap"                    : True,
    "mmap_base"               : 0x00020000,
    "mmap_size"               : 0x00020000,

    # MMAP Slave ---------------------------------------------------------------
    "mmap_slave"              : True,
    "mmap_slave_axi_full"     : True,

    # DMA channels -------------------------------------------------------------
    "dma_channels"            : 4,    # Number of DMA channels
    "dma_buffering"           : 8192, # Buffering for each channel (in bytes)
    "dma_loopback"            : True, # Enable DMA loopback capability
    "dma_synchronizer"        : True, # Enable DMA synchronizer capability
    "dma_monitor"             : True, # Enable DMA monitoring capability

    # MSI IRQs -----------------------------------------------------------------
    "msi_irqs"                : 16, # Number or MSI IRQs
}

```

`examples/acorn.yml`:

```yml
#
# This file is part of LitePCIe.
#
# Copyright (c) 2019-2024 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

{
    # PHY ----------------------------------------------------------------------
    "phy"                     : "S7PCIEPHY", # Type of PCIe PHY
    "phy_device"              : "xc7a",      # Type of Device
    "phy_lanes"               : 4,           # Number of lanes
    "phy_pcie_data_width"     : 128,         # PCIe data_width
    "phy_data_width"          : 128,         # Bus data_width
    "phy_bar0_size"           : 0x40000,     # BAR0 size

    # Clocking -----------------------------------------------------------------
    "clk_freq"                : 125e6,        # User Clk Freq (AXI MMAP/DMA)
    "clk_external"            : True,         # Use external User provided Clk

    # Endpoint -----------------------------------------------------------------
    "ep_max_pending_requests" : 8,
    "ep_address_width"        : 32,

    # Control ------------------------------------------------------------------
    "ctrl"                    : False,

    # MMAP Master --------------------------------------------------------------
    "mmap"                    : True,
    "mmap_base"               : 0x00020000,
    "mmap_size"               : 0x00020000,

    # MMAP Slave ---------------------------------------------------------------
    "mmap_slave"              : True,
    "mmap_slave_axi_full"     : True,

    # DMA channels -------------------------------------------------------------
    "dma_channels"            : 4,     # Number of DMA channels
    "dma_buffering"           : 1024,  # Buffering for each channel (in bytes)
    "dma_loopback"            : True,  # Enable DMA loopback capability
    "dma_synchronizer"        : False, # Enable DMA synchronizer capability
    "dma_monitor"             : False, # Enable DMA monitoring capability

    # MSI IRQs -----------------------------------------------------------------
    "msi_irqs"                : 16, # Number or MSI IRQs
}

```

`examples/kcu105.yml`:

```yml
#
# This file is part of LitePCIe.
#
# Copyright (c) 2019-2024 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

{
    # PHY ----------------------------------------------------------------------
    "phy"                     : "USPCIEPHY", # Type of PCIe PHY
    "phy_device"              : "xcku",      # Type of Device
    "phy_lanes"               : 4,           # Number of lanes
    "phy_pcie_data_width"     : 128,         # PCIe data_width
    "phy_data_width"          : 128,         # Bus data_width
    "phy_bar0_size"           : 0x40000,     # BAR0 size

    # Clocking -----------------------------------------------------------------
    "clk_freq"                : 125e6, # User Clk Freq (AXI MMAP/DMA)
    "clk_external"            : False, # Use external User provided Clk

    # Endpoint -----------------------------------------------------------------
    "ep_max_pending_requests" : 8,
    "ep_address_width"        : 64,

    # Control ------------------------------------------------------------------
    "ctrl"                    : False,

    # MMAP Master --------------------------------------------------------------
    "mmap"                    : True,
    "mmap_base"               : 0x00020000,
    "mmap_size"               : 0x00020000,

    # MMAP Slave ---------------------------------------------------------------
    "mmap_slave"              : True,

    # DMA channels -------------------------------------------------------------
    "dma_channels": {
        "dma0": {
            "dma_writer"              : True,  # Enable DMA Writer.
            "dma_reader"              : True,  # Disable DMA Reader.
            "dma_buffering"           : 8192,  # Buffering for each channel (in bytes)
            "dma_loopback"            : False, # Disable DMA loopback capability
            "dma_synchronizer"        : False, # Disable DMA synchronizer capability
            "dma_monitor"             : True,  # Enable DMA monitoring capability
        },
        "dma1": {
            "dma_writer"              : True,  # Enable DMA Writer.
            "dma_reader"              : True,  # Disable DMA Reader.
            "dma_buffering"           : 8192,  # Buffering for each channel (in bytes)
            "dma_loopback"            : False, # Disable DMA loopback capability
            "dma_synchronizer"        : False, # Disable DMA synchronizer capability
            "dma_monitor"             : True,  # Enable DMA monitoring capability
        },
    },

    # MSI IRQs -----------------------------------------------------------------
    "msi_irqs"                : 16, # Number or MSI IRQs
}

```

`litepcie/common.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2015-2023 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

from migen import *

from litex.gen import *

from litex.soc.interconnect import stream
from litex.soc.interconnect.stream import *
from litex.soc.interconnect.packet import *

# Constants/Helpers --------------------------------------------------------------------------------

KB = 1024
MB = 1024*KB
GB = 1024*MB

def get_bar_mask(size):
    mask = 0
    found = 0
    for i in range(32):
        if size%2:
            found = 1
        if found:
            mask |= (1 << i)
        size = size >> 1
    return mask

# Layouts ------------------------------------------------------------------------------------------

def phy_layout(data_width):
    layout = [
        ("dat", data_width),
        ("be",  data_width//8)
    ]
    return EndpointDescription(layout)

def configuration_layout(data_width, address_width=32):
    layout = [
        # Request Parameters.
        ("req_id",          16), # Requester ID.
        ("we",               1), # Configuration type; 0 : Read / 1 : Write.
        ("bus_number",       8), # Configuration Bus number.
        ("device_no",        5), # Configuration Device number.
        ("func",             3), # Configuration Function number.
        ("ext_reg",          3), # Configuration Extended Register.
        ("register_no",      6), # Configuration Register number.
        ("tag",              8), # Configuration tag.

        # Data Stream.
        ("dat", data_width),

        # Internal LitePCIe Routing/Identification.
        ("channel", 8), # Crossbar's channel (Used for internal routing).
    ]
    return EndpointDescription(layout)

def request_layout(data_width, address_width=32, with_configuration=False):
    layout = [
        # Request Parameters.
        ("req_id",          16), # Requester ID.
        ("we",               1), # Request type; 0 : Read / 1 : Write.
        ("adr",  address_width), # Request address (In Bytes).
        ("len",             10), # Request length (In Dwords).
        ("tag",              8), # Request tag.

        # Data Stream.
        ("dat", data_width),

        # Internal LitePCIe Routing/Identification.
        ("channel", 8), # Crossbar's channel (Used for internal routing).
        ("user_id", 8), # Packet identification (Used for packet delimitation).
    ]

    if with_configuration:
        layout += [
            ("is_cfg",       1), # 0: Memory / 1: Configuration (Type 0).

            # CFG addressing.
            ("bus_number",   8),
            ("device_no",    5),
            ("func",         3),
            ("ext_reg",      3),
            ("register_no",  6),
        ]

    return EndpointDescription(layout)

def completion_layout(data_width, address_width=32):
    layout = [
        # Completion Parameters.
        ("req_id",          16), # Requester ID.
        ("cmp_id",          16), # Completion ID.
        ("adr",  address_width), # Completion address (In Bytes).
        ("len",             10), # Completion length (In Dwords).
        ("end",              1), # Completion end (Current packet is the last).
        ("err",              1), # Completion error.
        ("tag",              8), # Completion tag.

        # Data Stream.
        ("dat",     data_width),

        # Internal LitePCIe Routing/Identification.
        ("channel", 8), # Crossbar's channel (Used for internal routing).
        ("user_id", 8)  # Packet identification (Used for packet delimitation).
    ]
    return EndpointDescription(layout)

def ptm_layout(data_width):
    layout = [
        ("request",       1), # Request.
        ("response",      1), # Response.
        ("requester_id", 16), # Requester ID.
        ("length",       10), # Length.
        ("message_code",  8), # Message Code.
        ("master_time",  64), # Master Time.

        # Data Stream.
        ("dat", data_width),

        # Internal LitePCIe Routing/Identification.
        ("channel", 8), # Crossbar's channel (Used for internal routing).
    ]
    return EndpointDescription(layout)


def msi_layout():
    return [("dat", 8)]

def dma_layout(data_width):
    layout = [("data", data_width)]
    return EndpointDescription(layout)

```

`litepcie/core/__init__.py`:

```py
from litepcie.core.endpoint import LitePCIeEndpoint
from litepcie.core.msi import LitePCIeMSI, LitePCIeMSIMultiVector, LitePCIeMSIX

```

`litepcie/core/common.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2015-2023 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

from migen import *

from litex.gen import *

from litepcie.common import *

# LitePCIe Internal Ports --------------------------------------------------------------------------

class LitePCIeSlaveInternalPort:
    def __init__(self, data_width, address_width=32, address_decoder=None):
        self.address_decoder = address_decoder
        self.sink   = stream.Endpoint(completion_layout(data_width))
        self.source = stream.Endpoint(request_layout(data_width))


class LitePCIeMasterInternalPort:
    def __init__(self, data_width, address_width=32, channel=None, write_only=False, read_only=False, with_configuration=False):
        self.channel    = channel
        self.write_only = write_only
        self.read_only  = read_only
        self.sink   = stream.Endpoint(request_layout(data_width, address_width, with_configuration))
        self.source = stream.Endpoint(completion_layout(data_width))

# LitePCIe User Ports ------------------------------------------------------------------------------

class LitePCIeSlavePort:
    def __init__(self, port):
        self.address_decoder = port.address_decoder
        self.sink   = port.source
        self.source = port.sink


class LitePCIeMasterPort:
    def __init__(self, port):
        self.channel = port.channel
        self.sink    = port.source
        self.source  = port.sink

```

`litepcie/core/crossbar.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2015-2023 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

from migen import *

from litex.gen import *

from litepcie.common         import *
from litepcie.core.common    import *
from litepcie.tlp.controller import LitePCIeTLPController

# LitePCIe Crossbar --------------------------------------------------------------------------------

class LitePCIeCrossbar(LiteXModule):
    def __init__(self, data_width, address_width, max_pending_requests, cmp_bufs_buffered=True, with_configuration=False):
        self.data_width           = data_width
        self.address_width        = address_width
        self.max_pending_requests = max_pending_requests
        self.cmp_bufs_buffered    = cmp_bufs_buffered
        self.with_configuration   = with_configuration

        self.master     = LitePCIeMasterInternalPort(data_width, address_width, with_configuration=with_configuration)
        self.slave      = LitePCIeSlaveInternalPort(data_width)
        self.phy_master = LitePCIeMasterPort(self.master)
        self.phy_slave  = LitePCIeSlavePort(self.slave)

        self.tlp_ctrl_rst = Signal()

        self.user_masters         = []
        self.user_masters_channel = 0
        self.user_slaves          = []

    def get_slave_port(self, address_decoder):
        s = LitePCIeSlaveInternalPort(
            data_width      = self.data_width,
            address_decoder = address_decoder)
        self.user_slaves.append(s)
        return LitePCIeSlavePort(s)

    def get_master_port(self, write_only=False, read_only=False):
        m = LitePCIeMasterInternalPort(
            data_width         = self.data_width,
            address_width      = self.address_width,
            channel            = self.user_masters_channel,
            write_only         = write_only,
            read_only          = read_only,
            with_configuration = self.with_configuration,
        )
        self.user_masters_channel += 1
        self.user_masters.append(m)
        return LitePCIeMasterPort(m)

    def filter_masters(self, write_only, read_only):
        masters = []
        for m in self.user_masters:
            if m.write_only == write_only and m.read_only == read_only:
                masters.append(m)
        return masters

    def slave_dispatch_arbitrate(self, slaves, slave):
        # Dispatch ---------------------------------------------------------------------------------
        s_sources    = [s.source for s in slaves]
        s_dispatcher = Dispatcher(slave.source, s_sources, one_hot=True)
        self.submodules += s_dispatcher
        for i, s in enumerate(slaves):
                self.comb += s_dispatcher.sel[i].eq(s.address_decoder(slave.source.adr))

        # Arbitrate --------------------------------------------------------------------------------
        s_sinks   = [s.sink for s in slaves]
        s_arbiter = Arbiter(s_sinks, slave.sink)
        self.submodules += s_arbiter

    def master_arbitrate_dispatch(self, masters, master, dispatch=True):
        # Arbitrate --------------------------------------------------------------------------------
        m_sinks   = [m.sink for m in masters]
        m_arbiter = Arbiter(m_sinks, master.sink)
        self.submodules += m_arbiter

        # Dispatch ---------------------------------------------------------------------------------
        if dispatch:
            m_sources    = [m.source for m in masters]
            m_dispatcher = Dispatcher(master.source, m_sources, one_hot=True)
            self.submodules += m_dispatcher
            for i, m in enumerate(masters):
                if m.channel is not None:
                    self.comb += m_dispatcher.sel[i].eq(master.source.channel == m.channel)
        else:
            # Connect to first master.
            self.comb += master.source.connect(masters[0].source)

    def do_finalize(self):
        # Slave path -------------------------------------------------------------------------------
        # - Dispatch request to user sources (according to address decoder).
        # - Arbitrate completion from user sinks.
        if self.user_slaves != []:
            self.slave_dispatch_arbitrate(self.user_slaves, self.slave)

        # Master path ------------------------------------------------------------------------------
        # Abritrate requests from user sinks
        # Dispatch completion to user sources (according to channel)

        #           +-------+
        #  reqs---> |  RD   |
        #  cmps<--- | PORTS |---------+
        #           +-------+     +---+----+   +----------+
        #                         |Arb/Disp|-->|Controller|--+
        #           +-------+     +---+----+   +----------+  |
        #  reqs---> |  RW   |         |                      |
        #  cmps<--- | PORTS |---------+                      |
        #           +-------+                            +---+----+
        #                                                |Arb/Disp|<--> to/from  Packetizer/
        #           +-------+                            +---+----+              Depacketizer
        #  reqs---> |  WR   |     +--------+                 |
        #  cmps<--- | PORTS |-----|Arb/Disp|-----------------+
        #           +-------+     +--------+
        #
        # The controller blocks RD requests when the max number of pending requests have been sent
        # (max_pending_requests parameters).
        # To avoid blocking write_only ports when RD requests are blocked, a separate arbitration
        # stage is used.

        if self.user_masters != []:
            masters = []

            # Arbitrate / dispatch read_only / read_write ports and insert controller --------------
            rd_rw_masters = self.filter_masters(False, True)
            rd_rw_masters += self.filter_masters(False, False)
            if rd_rw_masters != []:
                rd_rw_master = LitePCIeMasterInternalPort(self.data_width, self.address_width)
                controller   = LitePCIeTLPController(
                    data_width           = self.data_width,
                    address_width        = self.address_width,
                    max_pending_requests = self.max_pending_requests,
                    cmp_bufs_buffered    = self.cmp_bufs_buffered,
                    with_configuration   = self.with_configuration,
                )
                self.submodules.controller = controller
                self.comb += controller.ctrl_rst.eq(self.tlp_ctrl_rst)
                self.master_arbitrate_dispatch(rd_rw_masters, controller.master_in)
                masters.append(controller.master_out)

            # Arbitrate / dispatch write_only ports ------------------------------------------------
            wr_masters = self.filter_masters(True, False)
            if wr_masters != []:
                wr_master = LitePCIeMasterInternalPort(self.data_width, self.address_width, with_configuration=self.with_configuration)
                self.master_arbitrate_dispatch(wr_masters, wr_master)
                masters.append(wr_master)

            # Final Arbitrate / dispatch stage -----------------------------------------------------
            self.master_arbitrate_dispatch(masters, self.master, False)

```

`litepcie/core/endpoint.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2015-2023 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

from migen import *

from litex.gen import *

from litex.soc.interconnect.csr import *

from litepcie.tlp.depacketizer import LitePCIeTLPDepacketizer
from litepcie.tlp.packetizer   import LitePCIeTLPPacketizer
from litepcie.core.crossbar    import LitePCIeCrossbar

# LitePCIe Endpoint --------------------------------------------------------------------------------

class LitePCIeEndpoint(LiteXModule):
    def __init__(self, phy, max_pending_requests=4, address_width=32, endianness="big",
        cmp_bufs_buffered  = True,
        with_ptm           = False,
        with_configuration = False,
        address_mask       = None,
    ):
        self.phy                  = phy
        self.max_pending_requests = max_pending_requests

        # # #

        # Parameters.
        optional_packetizer_capabilities   = []
        optional_depacketizer_capabilities = []
        if with_ptm:
            optional_packetizer_capabilities   = ["PTM"]
            optional_depacketizer_capabilities = ["PTM", "CONFIGURATION"]
        # Default to PHY BAR0 aperture mask for memory requests.
        if address_mask is None:
            address_mask = getattr(phy, "bar0_mask", 0)

        # TLP Packetizer / Depacketizer ------------------------------------------------------------

        if hasattr(phy, "sink") and hasattr(phy, "source"):
            # Shared Request/Completion channels
            self.depacketizer = depacketizer = LitePCIeTLPDepacketizer(
                data_width   = phy.data_width,
                endianness   = endianness,
                address_mask = address_mask,
                capabilities = ["REQUEST", "COMPLETION"] + optional_depacketizer_capabilities,
            )
            self.packetizer = packetizer = LitePCIeTLPPacketizer(
                data_width    = phy.data_width,
                endianness    = endianness,
                address_width = address_width,
                capabilities  = ["REQUEST", "COMPLETION"] + optional_packetizer_capabilities,
            )
            self.comb += [
                phy.source.connect(depacketizer.sink),
                packetizer.source.connect(phy.sink)
            ]
            req_source = depacketizer.req_source
            cmp_sink   = packetizer.cmp_sink
            req_sink   = packetizer.req_sink
            cmp_source = depacketizer.cmp_source
        else:
            if with_ptm:
                raise NotImplementedError
            # Separate Request/Completion channels
            self.cmp_depacketizer = cmp_depacketizer = LitePCIeTLPDepacketizer(
                data_width   = phy.data_width,
                endianness   = endianness,
                address_mask = address_mask,
                capabilities = ["COMPLETION"] + (["CONFIGURATION"] if with_configuration else []),
            )
            self.req_depacketizer = req_depacketizer = LitePCIeTLPDepacketizer(
                data_width   = phy.data_width,
                endianness   = endianness,
                address_mask = address_mask,
                capabilities = ["REQUEST"],
            )
            self.cmp_packetizer = cmp_packetizer = LitePCIeTLPPacketizer(
                data_width    = phy.data_width,
                endianness    = endianness,
                address_width = address_width,
                capabilities  = ["COMPLETION"],
            )
            self.req_packetizer = req_packetizer = LitePCIeTLPPacketizer(
                data_width    = phy.data_width,
                endianness    = endianness,
                address_width = address_width,
                capabilities  = ["REQUEST"] + (["CONFIGURATION"] if with_configuration else []),
            )
            self.comb += [
                phy.cmp_source.connect(cmp_depacketizer.sink),
                phy.req_source.connect(req_depacketizer.sink),
                cmp_packetizer.source.connect(phy.cmp_sink),
                req_packetizer.source.connect(phy.req_sink),
            ]
            req_source = req_depacketizer.req_source
            cmp_sink   = cmp_packetizer.cmp_sink
            req_sink   = req_packetizer.req_sink
            cmp_source = cmp_depacketizer.cmp_source

        # Crossbar ---------------------------------------------------------------------------------

        self.crossbar = crossbar = LitePCIeCrossbar(
            data_width           = phy.data_width,
            address_width        = address_width,
            max_pending_requests = max_pending_requests,
            cmp_bufs_buffered    = cmp_bufs_buffered,
            with_configuration   = with_configuration,
        )
        self.tlp_ctrl_rst = crossbar.tlp_ctrl_rst

        # Slave: HOST initiates the transactions ---------------------------------------------------

        self.comb += [
            req_source.connect(crossbar.phy_slave.sink),
            crossbar.phy_slave.source.connect(cmp_sink),
        ]

        # Master: FPGA initiates the transactions --------------------------------------------------

        self.comb += [
            crossbar.phy_master.source.connect(req_sink),
            cmp_source.connect(crossbar.phy_master.sink),
        ]

```

`litepcie/core/msi.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2015-2023 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

from migen import *

from litex.gen import *

from litex.soc.interconnect.csr     import *
from litex.soc.interconnect.csr_bus import SRAM

from litepcie.common import *

# LitePCIeMSI --------------------------------------------------------------------------------------

class LitePCIeMSI(LiteXModule):
    def __init__(self, width=32):
        self.irqs   = Signal(width)
        self.source = stream.Endpoint(msi_layout())

        self.enable = CSRStorage(width, description="""MSI Enable Control.\n
           Write bit(s) to ``1`` to enable corresponding MSI IRQ(s).""")
        self.clear  = CSRStorage(width, description="""MSI Clear Control.\n
           Write bit(s) to ``1`` to clear corresponding MSI IRQ(s).""")
        self.vector = CSRStatus(width,  description="""MSI Vector Status.\n
           Current MSI IRQs vector value.""")

        # # #

        enable = Signal(width)
        clear  = Signal(width)
        vector = Signal(width)

        # Memorize and clear IRQ Vector ------------------------------------------------------------
        self.comb += If(self.clear.re, clear.eq(self.clear.storage))
        self.comb += enable.eq(self.enable.storage)
        self.comb += self.vector.status.eq(vector)
        self.sync += vector.eq(enable & ((vector & ~clear) | self.irqs))

        # Generate MSI -----------------------------------------------------------------------------
        msi = Signal(width)
        self.comb += self.source.valid.eq(msi != 0)
        self.sync += [
            msi.eq((msi | self.irqs) & enable),
            If(self.source.ready,
                msi.eq(self.irqs & enable)
            )
        ]

# LitePCIeMSIMultiVector ---------------------------------------------------------------------------

class LitePCIeMSIMultiVector(LiteXModule):
  def __init__(self, width=32):
        self.irqs   = Signal(width)
        self.source = stream.Endpoint(msi_layout())

        self.enable = CSRStorage(width, description="""MSI Enable Control.\n
           Write bit(s) to ``1`` to enable corresponding MSI IRQ(s).""")

        # # #

        enable = Signal(width)
        clear  = Signal(width)
        vector = Signal(width)

        # Memorize and clear IRQ Vector ------------------------------------------------------------
        self.comb += enable.eq(self.enable.storage)
        self.sync += vector.eq(enable & ((vector & ~clear) | self.irqs))

        # Generate MSI -----------------------------------------------------------------------------
        for i in reversed(range(width)): # Priority given to lower indexes.
            self.comb += [
                If(vector[i],
                    self.source.valid.eq(1),
                    self.source.dat.eq(i),
                    If(self.source.ready,
                        clear.eq(1 << i)
                    )
                )
            ]

# LitePCIeMSIX -------------------------------------------------------------------------------------

class LitePCIeMSIX(LiteXModule):
    def __init__(self, endpoint, width=32, default_enable=0):
        assert width <= 64
        self.irqs           = Signal(width)
        self.enable         = CSRStorage(width, description="""MSI-X Enable Control.\n
           Write bit(s) to ``1`` to enable corresponding MSI-X IRQ(s).""",
           reset = default_enable*(2**width-1))
        if width <= 32:
            self.reserved0 = CSRStorage() # For 64-bit alignment.
        self.pba            = CSRStatus(width, description="""MSI-X PBA Table.""")
        if width <= 32:
            self.reserved1 = CSRStorage() # For 64-bit alignment.
        self.specials.table = Memory(4*32, width, init=[0b1 for _ in range(width)]) # MSI-X Table / Masked by default.

        # # #

        enable = Signal(width)
        clear  = Signal(width)
        vector = Signal(width)

        # Memorize and clear IRQ Vector ------------------------------------------------------------
        self.comb += enable.eq(self.enable.storage)
        self.sync += vector.eq(enable & ((vector & ~clear) | self.irqs))
        self.comb += self.pba.status.eq(vector)

        # Generate MSI-X ---------------------------------------------------------------------------
        msix_valid          = Signal()
        msix_num            = Signal(max=width)
        msix_clear          = Signal(width)
        msix_clear_on_ready = Signal(width)

        for i in reversed(range(width)): # Priority given to lower indexes.
            self.comb += [
                If(vector[i],
                    msix_valid.eq(1),
                    msix_num.eq(i),
                    msix_clear.eq(1 << i),
                )
            ]

        # Send MSI-X as TLP-Write ------------------------------------------------------------------
        self.port       = port       = endpoint.crossbar.get_master_port()
        self.table_port = table_port = self.table.get_port(has_re=True)
        self.specials += table_port

        # Table decoding.
        msix_adr  = table_port.dat_r[96:128] # Lower Address.
        msix_dat  = table_port.dat_r[32:64]  # Message Data.
        msix_mask = table_port.dat_r[0]      # Mask, when set to 1, MSI-X message is not generated.

        # FSM.
        self.fsm = fsm = FSM(reset_state="IDLE")
        fsm.act("IDLE",
            table_port.adr.eq(msix_num),
            table_port.re.eq(1),
            If(msix_valid,
                NextValue(msix_clear_on_ready, msix_clear),
                NextState("ISSUE-WRITE")
            )
        )
        self.comb += [
            port.source.channel.eq(port.channel),
            port.source.first.eq(1),
            port.source.last.eq(1),
            port.source.adr.eq(msix_adr),
            port.source.req_id.eq(endpoint.phy.id),
            port.source.tag.eq(0),
            port.source.len.eq(1),
            port.source.dat.eq(msix_dat),
        ]
        fsm.act("ISSUE-WRITE",
            port.source.valid.eq(~msix_mask),
            port.source.we.eq(1),
            If(port.source.ready | msix_mask,
                clear.eq(msix_clear_on_ready),
                NextState("IDLE")
            )
        )

```

`litepcie/core/rootport.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2015-2026 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

from migen import *

from litex.gen import *

from litex.soc.interconnect.csr import *

from litepcie.core.endpoint import LitePCIeEndpoint

# LitePCIe RootPort --------------------------------------------------------------------------------

class LitePCIeRootPort(LitePCIeEndpoint):
    def __init__(self, phy, **kwargs):
        # FIXME: Endpoint is now role-agnostic; consider a shared base class for Endpoint/RootPort.
        kwargs.setdefault("address_mask", 0)
        LitePCIeEndpoint.__init__(self, phy, **kwargs)

```

`litepcie/frontend/axi.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2020 Antmicro <www.antmicro.com>
# SPDX-License-Identifier: BSD-2-Clause

from migen import *

from litex.gen import *

from litex.soc.interconnect import axi, stream

from litepcie.common       import *
from litepcie.frontend.dma import descriptor_layout, LitePCIeDMAWriter, LitePCIeDMAReader

# LitePCIeAXISlave ---------------------------------------------------------------------------------

class LitePCIeAXISlave(LiteXModule):
    def __init__(self, endpoint, data_width=32, id_width=1):
        self.axi = axi.AXIInterface(data_width=data_width, id_width=id_width)

        # # #

        aw_id = Signal(id_width)
        ar_id = Signal(id_width)
        r_len = Signal(8)

        desc_rd = stream.Endpoint(descriptor_layout())
        desc_wr = stream.Endpoint(descriptor_layout())

        port_rd = endpoint.crossbar.get_master_port(read_only=True)
        port_wr = endpoint.crossbar.get_master_port(write_only=True)

        # AXI Write Path ---------------------------------------------------------------------------

        # DMA / FIFO / Converter
        self.dma_wr = dma_wr = LitePCIeDMAWriter(
            endpoint = endpoint,
            port     = port_wr,
            with_table = False)
        self.fifo_wr = fifo_wr = stream.SyncFIFO(descriptor_layout(), 16)
        self.conv_wr = conv_wr = stream.Converter(nbits_from=data_width, nbits_to=endpoint.phy.data_width)

        # Flow
        self.comb += [
            desc_wr.connect(fifo_wr.sink),
            fifo_wr.source.connect(dma_wr.desc_sink),
            conv_wr.source.connect(dma_wr.sink),
        ]

        # FSM (Convert AXI Write Requests to LitePCIe's DMA Descriptors).
        self.comb += desc_wr.address.eq(self.axi.aw.addr)                       # Start address (byte addressed)
        self.comb += desc_wr.length.eq((self.axi.aw.len + 1) * (data_width//8)) # Transfer length (in bytes)

        self.fsm_wr = fsm_wr = FSM(reset_state="WRITE-IDLE")
        fsm_wr.act("WRITE-IDLE",
            self.axi.aw.ready.eq(desc_wr.ready),
            desc_wr.valid.eq(self.axi.aw.valid),
            If(self.axi.aw.valid & self.axi.aw.ready,
                NextValue(aw_id, self.axi.aw.id), # Save id to use it on b channel.
                NextState("WRITE-MONITOR"),
            )
        )

        self.comb += [
            conv_wr.sink.data.eq(self.axi.w.data),
            conv_wr.sink.last.eq(self.axi.w.last),
        ]
        fsm_wr.act("WRITE-MONITOR",
            conv_wr.sink.valid.eq(self.axi.w.valid),
            self.axi.w.ready.eq(conv_wr.sink.ready),
            If(self.axi.w.valid & self.axi.w.ready & self.axi.w.last,
                NextState("WRITE-RESP"),
            )
        )

        self.comb += [
            self.axi.b.id.eq(aw_id),
            self.axi.b.resp.eq(0),
        ]
        fsm_wr.act("WRITE-RESP",
            self.axi.b.valid.eq(1),
            If(self.axi.b.ready,
                NextState("WRITE-IDLE"), # Write done
            )
        )

        # AXI Read Path ----------------------------------------------------------------------------

        # DMA / FIFO / Converter
        self.dma_rd = dma_rd = LitePCIeDMAReader(
            endpoint = endpoint,
            port     = port_rd,
            with_table = False)
        self.fifo_rd = fifo_rd = stream.SyncFIFO(descriptor_layout(), 16)
        self.conv_rd = conv_rd = stream.Converter(nbits_from=endpoint.phy.data_width, nbits_to=data_width)

        # Flow
        self.comb += [
            desc_rd.connect(fifo_rd.sink),
            fifo_rd.source.connect(dma_rd.desc_sink),
            dma_rd.source.connect(conv_rd.sink),
        ]

        # FSM (Convert AXI Read Requests to LitePCIe's DMA Descriptors).
        self.comb += desc_rd.address.eq(self.axi.ar.addr)                       # Starting address (byte addressed)
        self.comb += desc_rd.length.eq((self.axi.ar.len + 1) * (data_width//8)) # Transfer length (in bytes)

        self.fsm_rd = fsm_rd = FSM(reset_state="READ-IDLE")
        fsm_rd.act("READ-IDLE",
            self.axi.ar.ready.eq(desc_rd.ready),
            desc_rd.valid.eq(self.axi.ar.valid),
            If(self.axi.ar.valid & self.axi.ar.ready,
                NextValue(ar_id, self.axi.ar.id), # Save id to use it on r channel.
                NextValue(r_len, self.axi.ar.len),
                NextState("READ-MONITOR"),
            )
        )

        self.comb += [
            self.axi.r.data.eq(conv_rd.source.data),
            self.axi.r.last.eq(r_len == 0),
            # We need to provide the same id that was provided on aw channel for the duration of the transfer.
            self.axi.r.id.eq(ar_id),
            self.axi.r.resp.eq(0),
        ]
        fsm_rd.act("READ-MONITOR",
            self.axi.r.valid.eq(conv_rd.source.valid),
            conv_rd.source.ready.eq(self.axi.r.ready),
            If(self.axi.r.ready & self.axi.r.valid,
                NextValue(r_len, r_len - 1),
                If(self.axi.r.last, # Check if we finished the whole AXI transaction.
                    NextState("READ-IDLE"),
                )
            )
        )


```

`litepcie/frontend/dma.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2015-2023 Florent Kermarrec <florent@enjoy-digital.fr>
# Copyright (c) 2020 Antmicro <www.antmicro.com>
# SPDX-License-Identifier: BSD-2-Clause

from migen import *

from litex.gen import *

from litex.soc.interconnect     import stream
from litex.soc.interconnect.csr import *

from litepcie.common     import *
from litepcie.tlp.common import *

# Constants/Layouts --------------------------------------------------------------------------------

def descriptor_layout(address_width=32, with_user_id=False):
    layout = [("address", address_width), ("length",  24), ("irq_disable", 1), ("last_disable", 1)]
    if with_user_id:
        layout += [("user_id", 8)]
    return EndpointDescription(layout)


# LitePCIeDMAScatterGather --------------------------------------------------------------------------

class LitePCIeDMAScatterGather(LiteXModule):
    """LitePCIe DMA Scatter-Gather

    Software programmable table storing a list of DMA descriptors.

                               Mode
                                │
                              ┌─▼─┐  ┌───────────────────┐
       Descriptor to program  │   │  │                   │
             (Prog Mode) ─────►   │  │                   │
                              │   │  │    ScatterGather  │
                              │   ├──►     Table(FIFO)   ├──┬───► Descriptor (To DMA).
                          ┌───►   │  │                   │  │
                          │   │   │  │                   │  │
                          │   └───┘  └───────────────────┘  │
                          │                                 │
                          └─────────────────────────────────┘
                                    Refill (Loop Mode)


    A DMA descriptor is composed of:
    - a 32/64-bit address: The base address of the Host where the data stream should be written/read.
    - a 24-bit length : The length of the data stream (bytes).
    - a 8-bit control : Dynamic controls (ex: Disable IRQ generation, disable Last handling).

    The table is implemented as a FIFO initially filled by software. Once enabled, the DMA gets the
    descriptors from this table and executes them.

    This module has two modes:
    - Prog mode: Used to program the table by software and for cases where automatic refill of the
    table is not needed: A descriptor is only executed once and when all the descriptors have been
    executed (ie the table is empty), the DMA just stops until the next software refill.
    - Loop mode: Used once the table has been filled by software in PROG mode and allow continuous
    Scatter-Gather DMA: Each descriptor sent to the DMA is refilled to the table.

    In Loop mode, a loop status is maintained by the hardware for the software synchronization of the
    DMA buffers. (Even if a MSI IRQ is generated after a descriptor has been executed, since IRQ can
    potentially be lost, it's safer for the software to just use the hardware loop status than to
    maintain a software loop status based MSI IRQ reception).
    """
    def __init__(self, depth, address_width=32):
        assert address_width in [32, 64]
        # Stream Endpoint.
        self.source = source = stream.Endpoint(descriptor_layout(address_width=address_width))

        # Control/Status.
        self.value = CSRStorage(64, reset_less=True, fields=[
            CSRField("address_lsb",  size=32, description="32-bit LSB Address of the descriptor (bytes-aligned)."),
            CSRField("length",       size=24, description="24-bit Length  of the descriptor (in bytes)."),
            CSRField("irq_disable",  size=1,  description="IRQ Disable Control of the descriptor."),
            CSRField("last_disable", size=1,  description="Last Disable Control of the descriptor.")
            ], description="64-bit DMA descriptor to be written to the table.")
        self.we = CSRStorage(32, description="Write and 32-bit MSB Address of the descriptor (bytes-aligned)", fields=[
            CSRField("address_msb", size=32, description="32-bit MSB Address of the descriptor (bytes-aligned), in 64-bit mode."),
        ])
        self.loop_prog_n = CSRStorage(description="""Mode Selection.\n
            ``0``: **Prog** mode / ``1``: **Loop** mode.\n
            **Prog** mode should be used to program the table by software and for cases where automatic
            refill of the table is not needed: A descriptor is only executed once and when all the
            descriptors have been executed (ie the table is empty), the DMA just stops until the next
            software refill.\n
            **Loop** mode should be used once the table has been filled by software in **Prog** mode
            and allow continuous Scatter-Gather DMA: Each descriptor sent to the DMA is refilled to the table.
            """)
        self.loop_status = CSRStatus(fields=[
            CSRField("index", size=16, description= "Index of the last descriptor executed in the DMA descriptor table."),
            CSRField("count", size=16, description= "Loops of the DMA descriptor table since started."),
            ], description="Loop monitoring for software synchronization.")
        self.level = CSRStatus(bits_for(depth), description="Number descriptors in the table.")
        self.reset = CSRStorage(description="A write to this register resets the table.")

        # # #

        # Table (FIFO) -----------------------------------------------------------------------------
        table = stream.SyncFIFO(descriptor_layout(address_width=address_width), depth)
        table = ResetInserter()(table)
        self.submodules += table
        self.comb += table.reset.eq(self.reset.storage & self.reset.re)
        self.comb += self.level.status.eq(table.level)

        # Table Write logic ------------------------------------------------------------------------
        def table_sink_address_map():
            address_map = []
            address_map.append(table.sink.address[0:32].eq(self.value.fields.address_lsb))
            if address_width == 64:
                address_map.append(table.sink.address[32:64].eq(self.we.fields.address_msb))
            return address_map

        prog_mode = (self.loop_prog_n.storage == 0)
        loop_mode = (self.loop_prog_n.storage == 1)
        self.sync += [
            # In Prog mode, the Table is filled through the CSRs.
            If(prog_mode,
                *table_sink_address_map(),
                table.sink.length.eq(self.value.fields.length),
                table.sink.irq_disable.eq(self.value.fields.irq_disable),
                table.sink.last_disable.eq(self.value.fields.last_disable),
                table.sink.first.eq(table.level == 0),
                table.sink.valid.eq(self.we.re),
            # In Loop mode, the Table is automatically refilled.
            ).Else(
                table.source.connect(table.sink, omit={"valid", "ready"}),
                table.sink.valid.eq(table.source.valid & table.source.ready),
            )
        ]

        # Table Read logic -------------------------------------------------------------------------
        self.comb += table.source.connect(source)

        # Loop Status (For Software Sychronization in Loop mode) -----------------------------------
        loop_first = Signal()
        loop_index = self.loop_status.fields.index
        loop_count = self.loop_status.fields.count
        self.sync += [
            # Reset Loop Index/Count on Table reset.
            If(table.reset,
                loop_first.eq(1),
                loop_index.eq(0),
                loop_count.eq(0),
            # When a Descriptor is consumned...
            ).Elif(table.source.valid & table.source.ready,
                # Update Loop Status with current Loop Index/Count.
                # Loop Mode.
                If(loop_mode & table.source.first,
                    # Reset Index.
                    loop_index.eq(0),
                    # Increment Count (except on first since we want (index, count) == (0,0)).
                    loop_first.eq(0),
                    loop_count.eq(loop_count + Cat(~loop_first)),
                # Prog Mode.
                ).Else(
                    # Increment Index.
                    loop_index.eq(loop_index + 1),
                    # Increment Count.
                    If(loop_index == (2**16-1),
                        loop_count.eq(loop_count + 1)
                    )
                )
            )
        ]

# LitePCIeDMADescriptorSplitter --------------------------------------------------------------------

class LitePCIeDMADescriptorSplitter(LiteXModule):
    """LitePCIe DMA Descriptor Splitter

    Splits descriptors from LitePCIeDMAScatterGather in shorter descriptors of:
    - Maximum Payload Size for Writes.
    - Maximum Request Size for Reads.

    Descriptors from LitePCIeDMAScatterGather have a maximum length of 16Mb (24-bits). It is not
    possible to do such long Writes/Reads on the PCIe bus. At the PCIe enumeration, Maximum Payload
    and Request Sizes are negotiated between the Host and the Device. Writes are limited to Maximum
    Payload Size, Reads are limited to Maximum Request Size. Each descriptor is then split in
    several shorter descriptors.
    """
    def __init__(self, max_size, address_width):
        # Stream Endpoints.
        self.sink   =   sink = stream.Endpoint(descriptor_layout(address_width=address_width))
        self.source = source = stream.Endpoint(descriptor_layout(address_width=address_width, with_user_id=True))

        self.terminate = Signal() # Early Termination.

        # # #

        # Signals.
        # --------
        length      = Signal(24)
        length_next = Signal(24)

        # FSM.
        # ----
        self.fsm = fsm = FSM(reset_state="IDLE")
        fsm.act("IDLE",
            # Set/Clear signals.
            NextValue(source.first, 1),
            NextValue(source.last,  0),
            NextValue(source.address, sink.address),
            NextValue(length, sink.length),
            If(sink.length > max_size,
                NextValue(source.length, max_size)
            ).Else(
                NextValue(source.last, 1),
                NextValue(source.length, sink.length)
            ),
            # Wait for a descriptor and go to RUN.
            If(sink.valid,
                NextState("RUN")
            )
        )
        self.comb += [
            source.irq_disable.eq(sink.irq_disable),
            source.last_disable.eq(sink.last_disable),
        ]
        fsm.act("RUN",
            source.valid.eq(1),
            # When descriptor is accepted...
            If(source.ready,
                # Clear first.
                NextValue(source.first, 0),
                # Update address.
                NextValue(source.address, source.address + max_size),
                # Update length/last.
                NextValue(length, length_next),
                If(length_next > max_size,
                    NextValue(source.length, max_size)
                ).Else(
                    NextValue(source.last, 1),
                    NextValue(source.length, length_next),
                ),
                # On last or terminate...
                If(source.last | self.terminate,
                    # Accept Descriptor.
                    sink.ready.eq(1),
                    # Increment User-ID.
                    NextValue(source.user_id, source.user_id + 1),
                    # Return to IDLE..
                    NextState("IDLE")
                )
            )
        )
        self.comb += length_next.eq(length - max_size) # Outside of FSM for timings.

# LitePCIeDMAReader --------------------------------------------------------------------------------

class LitePCIeDMAReader(LiteXModule):
    """LitePCIe DMA Reader

    Generates a data stream from Host's memory.

    This module allows Scatter-Gather DMAs from Host's memory to data stream in the FPGA. The DMA
    descriptors, stored in a software programmable table, are split and executed as Read Requests
    on the PCIe bus.

    A Read Request is only sent to the Host when enough space is available in the Data FIFO to store
    the requested data.

    A MSI IRQ can be generated when a descriptor has been executed.
    """
    def __init__(self, endpoint, port, with_table=True, table_depth=256, address_width=32, data_width=None):
        self.port       = port
        self.data_width = data_width or endpoint.phy.data_width
        # Stream Endpoint.
        self.source = stream.Endpoint(dma_layout(self.data_width))

        # Control.
        self._enable = CSRStorage(size=2, description="DMA Reader Control. Write ``1`` to enable DMA Reader.", reset=0 if with_table else 1)

        # IRQ.
        self.irq = Signal()

        # # #

        # CSR/Parameters ---------------------------------------------------------------------------
        self.enable = enable = self._enable.storage[0]

        length_shift          = log2_int(endpoint.phy.data_width//8)
        max_words_per_request = max_request_size//(endpoint.phy.data_width//8)
        max_pending_words     = endpoint.max_pending_requests*max_words_per_request

        # Table ------------------------------------------------------------------------------------
        if with_table:
            self.table = LitePCIeDMAScatterGather(table_depth, address_width=address_width)
        else:
            self.desc_sink = stream.Endpoint(descriptor_layout(address_width=address_width)) # Expose a Descriptor sink.

        # Splitter ---------------------------------------------------------------------------------
        # DMA descriptors need to be splitted in descriptors of max_request_size (negotiated at link-up)
        splitter = LitePCIeDMADescriptorSplitter(
            max_size      = endpoint.phy.max_request_size,
            address_width = address_width
        )
        splitter = ResetInserter()(splitter)
        self.splitter = splitter
        if with_table:
            self.comb += self.table.source.connect(splitter.sink)
        else:
            self.comb += self.desc_sink.connect(splitter.sink)

        # User ID ----------------------------------------------------------------------------------
        last_user_id = Signal(8, reset=255)
        self.sync += If(port.sink.valid & port.sink.first & port.sink.ready,
            last_user_id.eq(port.sink.user_id)
        )

        # Data Converter ---------------------------------------------------------------------------

        self.data_conv = stream.Converter(endpoint.phy.data_width, self.data_width)
        self.comb += self.data_conv.source.connect(self.source)

        # Data FIFO --------------------------------------------------------------------------------
        data_fifo_depth = 4*max_pending_words
        data_fifo = SyncFIFO(dma_layout(endpoint.phy.data_width), data_fifo_depth, buffered=True)
        self.data_fifo = ResetInserter()(data_fifo)
        self.comb += [
            # Connect Data FIFO to Data Converter.
            data_fifo.source.connect(self.data_conv.sink),
            # When Enabled, connect Sink to Data FIFO.
            If(enable,
                port.sink.connect(data_fifo.sink, keep={"valid", "ready"}),
                data_fifo.sink.data.eq(port.sink.dat),
                data_fifo.sink.first.eq(port.sink.first & (port.sink.user_id != last_user_id)),
            # Else accept incoming Port Data.
            ).Else(
                port.sink.ready.eq(1)
            )
        ]

        # Pending words ----------------------------------------------------------------------------
        pending_words         = Signal(max=data_fifo_depth + 1)
        pending_words_queue   = Signal.like(pending_words)
        pending_words_dequeue = Signal.like(pending_words)
        self.comb += [
            # Queue Pending words as Read Requests are emitted.
            If(splitter.source.valid & splitter.source.ready,
                pending_words_queue.eq(splitter.source.length[length_shift:])
            ),
            # Dequeue Pending words as Read Responses are received.
            If(data_fifo.source.valid & data_fifo.source.ready,
                pending_words_dequeue.eq(1)
            ),
        ]
        # Update Pending words.
        self.sync += pending_words.eq(pending_words + pending_words_queue - pending_words_dequeue)
        self.sync += If(~enable, pending_words.eq(0))

        # FSM --------------------------------------------------------------------------------------
        self.fsm = fsm = FSM(reset_state="IDLE")
        fsm.act("IDLE",
            # Reset Splitter/FIFO when disabled.
            If(~enable,
                splitter.reset.eq(1),
                data_fifo.reset.eq(1),
            # Else wait for a Descriptor and to have enough Space to generate the Request.
            ).Elif(splitter.source.valid & (pending_words < (data_fifo_depth - max_words_per_request)),
                NextState("MEM-RD-REQ"),
            )
        )
        # Report Idle Status.
        self.sync += self._enable.storage[1].eq(fsm.ongoing("IDLE"))
        # Request Data-Path.
        self.comb += [
            port.source.channel.eq(port.channel),
            port.source.user_id.eq(splitter.source.user_id),
            port.source.first.eq(1),
            port.source.last.eq(1),
            port.source.we.eq(0),
            port.source.adr.eq(splitter.source.address),
            port.source.len.eq(splitter.source.length[2:]),
            port.source.req_id.eq(endpoint.phy.id),
            port.source.dat.eq(0),
        ]
        fsm.act("MEM-RD-REQ",
            # Request Control-Path.
            port.source.valid.eq(1),
            # When Request is accepted...
            If(port.source.ready,
                # Accept Descriptor.
                splitter.source.ready.eq(1),
                # Return to Idle.
                NextState("IDLE"),
            )
        )

        # IRQ --------------------------------------------------------------------------------------
        self.comb += If(splitter.source.valid & splitter.source.ready & splitter.source.last,
            self.irq.eq(~splitter.source.irq_disable)
        )

# LitePCIeDMAWriter --------------------------------------------------------------------------------

class LitePCIeDMAWriter(LiteXModule):
    """LitePCIe DMA Writer

    Stores a data stream to Host's memory.

    This module allows Scatter-Gather DMAs from a data stream in the FPGA to Host's memory. The DMA
    descriptors, stored in a software programmable table, are split and executed as Write Requests
    on the PCIe bus.

    A Write Request is only sent to the Host when enough data are available for the current split
    descriptor.

    A MSI IRQ can be generated when a descriptor has been executed.
    """
    def __init__(self, endpoint, port, with_table=True, table_depth=256, address_width=32, data_width=None):
        self.port       = port
        self.data_width = data_width or endpoint.phy.data_width
        # Stream Endpoint.
        self.sink = stream.Endpoint(dma_layout(self.data_width))

        # Control.
        self._enable = CSRStorage(size=2, description="DMA Writer Control. Write ``1`` to enable DMA Writer.", reset=0 if with_table else 1)

        # IRQ.
        self.irq = Signal()

        # # #

        # CSR/Parameters ---------------------------------------------------------------------------
        self.enable = enable = self._enable.storage[0]

        length_shift          = log2_int(endpoint.phy.data_width//8)
        max_words_per_request = max_payload_size//(endpoint.phy.data_width//8)

        # Table ------------------------------------------------------------------------------------
        if with_table:
            self.table = LitePCIeDMAScatterGather(table_depth, address_width)
        else:
            self.desc_sink = stream.Endpoint(descriptor_layout(address_width=address_width)) # Expose a Descriptor sink.

        # Splitter ---------------------------------------------------------------------------------
        # DMA descriptors need to be splitted in descriptors of max_request_size (negotiated at link-up)
        splitter = LitePCIeDMADescriptorSplitter(
            max_size      = endpoint.phy.max_payload_size,
            address_width = address_width
        )
        splitter = ResetInserter()(splitter)
        self.splitter = splitter
        if with_table:
            self.comb += self.table.source.connect(splitter.sink)
        else:
            self.comb += self.desc_sink.connect(splitter.sink)

        # Data Converter ---------------------------------------------------------------------------

        self.data_conv = stream.Converter(self.data_width, endpoint.phy.data_width)
        self.comb += self.sink.connect(self.data_conv.sink)

        # Data FIFO --------------------------------------------------------------------------------
        data_fifo_depth = 4*max_words_per_request
        data_fifo = stream.SyncFIFO([("data", endpoint.phy.data_width)], data_fifo_depth, buffered=True)
        self.data_fifo = ResetInserter()(data_fifo)
        # By default, accept incoming stream when disabled.
        self.comb += self.data_conv.source.ready.eq(1)
        # When Enabled, connect Data Converter to Data FIFO.
        self.comb += If(enable, self.data_conv.source.connect(data_fifo.sink))

        # FSM --------------------------------------------------------------------------------------
        req_count = Signal.like(splitter.source.length)
        self.fsm = fsm = FSM(reset_state="IDLE")
        fsm.act("IDLE",
            # Reset Request Count.
            NextValue(req_count, 0),
            # Reset Splitter/FIFO when disabled.
            If(~enable,
                splitter.reset.eq(1),
                data_fifo.reset.eq(1),
            # Else wait for a Descriptor and to have enough Data to generate the Request.
            ).Elif(splitter.source.valid & (data_fifo.level >= splitter.source.length[length_shift:]),
                NextState("MEM-WR"),
            )
        )
        # Report Idle Status.
        self.sync += self._enable.storage[1].eq(fsm.ongoing("IDLE"))
        # Request Data-Path.
        self.comb += [
            port.source.channel.eq(port.channel),
            port.source.user_id.eq(splitter.source.user_id),
            port.source.first.eq(req_count == 0),
            port.source.last.eq( req_count == (splitter.source.length[length_shift:] - 1)),
            port.source.we.eq(1),
            port.source.adr.eq(splitter.source.address),
            port.source.req_id.eq(endpoint.phy.id),
            port.source.tag.eq(0),
            port.source.len.eq(splitter.source.length[2:]),
            port.source.dat.eq(data_fifo.source.data),
        ]
        # Early termination on last (Optional, can be dynamically disabled).
        self.comb += splitter.terminate.eq(data_fifo.source.last & ~splitter.source.last_disable)

        fsm.act("MEM-WR",
            # Request Control-Path.
            port.source.valid.eq(1),
            # When Request is accepted...
            If(port.source.ready,
                # Increment Request Count.
                NextValue(req_count, req_count + 1),
                # Accept Data (Only when not terminated).
                data_fifo.source.ready.eq(~splitter.terminate),
                # When last...
                If(port.source.last,
                    # Accept Descriptor.
                    splitter.source.ready.eq(1),
                    # Accept Data (Force).
                    data_fifo.source.ready.eq(1),
                    # Return to Idle.
                    NextState("IDLE"),
                )
            )
        )

        # IRQ --------------------------------------------------------------------------------------
        self.comb += If(splitter.source.valid & splitter.source.ready & splitter.source.last,
            self.irq.eq(~splitter.source.irq_disable)
        )

# LitePCIeDMALoopback ------------------------------------------------------------------------------

class LitePCIeDMALoopback(LiteXModule):
    """LitePCIe DMA Loopback

    Optional DMA Reader to DMA Writer loopback.

    For software development or system bring-up/check, being able to do a DMA loopback in the FPGA
    is very useful. This module allows doing a DMA Reader to DMA Writer loopback that can be enabled
    by a CSR. When enabled, user data stream from the DMA Reader is no longer generated, the same
    goes for user data stream to the DMA Writer that is no longer consumed.
    """
    def __init__(self, data_width):
        self.enable      = CSRStorage(description="""DMA Loopback Enable Control.\n
         Write ``1`` to enable DMA internal loopback (DMA Reader to DMA Writer).""")

        self.sink        = stream.Endpoint(dma_layout(data_width))
        self.source      = stream.Endpoint(dma_layout(data_width))

        self.next_source = stream.Endpoint(dma_layout(data_width))
        self.next_sink   = stream.Endpoint(dma_layout(data_width))

        # # #

        self.comb += [
            If(self.enable.storage,
                self.sink.connect(self.source)
            ).Else(
                self.sink.connect(self.next_source),
                self.next_sink.connect(self.source)
            )
        ]

# LitePCIeDMASynchronizer --------------------------------------------------------------------------

class LitePCIeDMASynchronizer(LiteXModule):
    """LitePCIe DMA Synchronizer

    Optional DMA synchronization.

    For some applications (Software Defined Radio, Video, ...), DMA start needs to be precisely
    synchronized to an internal signal of the FPGA (PPS for example for an SDR applications). This
    module allows releasing precisely one or both of the DMA Writer/Reader data streams.
    """
    def __init__(self, data_width):
        self.bypass      = CSRStorage()
        self.enable      = CSRStorage(fields=[
            CSRField("mode", size=2, values=[
                ("``0b00``", "Synchronization disabled."),
                ("``0b01``", "Reader and Writer to PPS Synchronization enabled."),
                ("``0b10``", "PPS Synchronization enabled."),
                ("``0b11``", "Reserved."),
            ]
        )])
        self.ready       = Signal(reset=1)
        self.pps         = Signal()

        self.sink        = stream.Endpoint(dma_layout(data_width))
        self.source      = stream.Endpoint(dma_layout(data_width))

        self.next_source = stream.Endpoint(dma_layout(data_width))
        self.next_sink   = stream.Endpoint(dma_layout(data_width))

        # # #

        self.synced = synced = Signal()

        self.sync += [
            # Bypass.
            If(self.bypass.storage,
                synced.eq(1)
            # Synchro Disabled.
            ).Elif(self.enable.fields.mode == 0b00,
                synced.eq(0)
            # Synchro Enabled.
            ).Else(
                # On PPS and with external ready signal:
                If(self.ready & self.pps,
                    # TX/RX Synchronization, make sure TX has data.
                    If((self.enable.fields.mode == 0b01) & self.sink.valid,
                        synced.eq(1)
                    ),
                    # Synchronization only on PPS. Reader and Writer are independent
                    If(self.enable.fields.mode == 0b10,
                        synced.eq(1)
                    )
                )
            )
        ]
        self.comb += [
            If(synced,
                self.sink.connect(self.next_source),
                self.next_sink.connect(self.source),
            ).Else(
                # Block sink
                self.next_source.valid.eq(0),
                self.sink.ready.eq(0),

                # Ack next_sink
                self.source.valid.eq(0),
                self.next_sink.ready.eq(1),
            )
        ]

# LitePCIeDMABuffering -----------------------------------------------------------------------------

class LitePCIeDMABuffering(LiteXModule):
    """LitePCIe DMA Buffering

    Optional DMA buffering with dynamically configurable depth.

    For some applications (Software Defined Radio, Video, ...), the user module consuming the data
    from the DMA Reader works at fixed rate and does not handle backpressure. (The same also applies
    to the user module generating the data to the DMA Writer). Since the PCIe bus is shared, gaps
    appears in the streams and our Writes/Reads can't be absorbed/produced at a fixed rate. A minimum
    of buffering is needed to make sure the gaps are smoothed and not propagated to user modules.
    """
    def __init__(self, data_width, with_writer, with_reader, writer_depth, reader_depth, dynamic_depth=True):
        self.sink        = stream.Endpoint(dma_layout(data_width))
        self.source      = stream.Endpoint(dma_layout(data_width))

        self.next_source = stream.Endpoint(dma_layout(data_width))
        self.next_sink   = stream.Endpoint(dma_layout(data_width))

        self.writer_enable = Signal()
        self.reader_enable = Signal()

        # Reader FIFO Control/Status.
        if with_reader:
            assert bits_for(reader_depth) < 24
            self.reader_fifo_control = CSRStorage(fields=[
                CSRField("depth", offset=0, size=24, reset=reader_depth,
                    description="DMA Reader FIFO depth (in {}-bit words).".format(data_width)),
                CSRField("scratch",    offset=24, size=4, description="Software Scratchpad."),
                CSRField("level_mode", offset=31, values=[
                    ("``0b0``", "Report Instantaneous level."),
                    ("``0b1``", "Report `Minimal` level since last clear.")
                ])
            ])
            self.reader_fifo_status = CSRStatus(fields=[
                CSRField("level", offset=0, size=24,
                    description="DMA Reader FIFO level (in {}-bit words).".format(data_width))
                ])

        # Writer FIFO Control/Status.
        if with_writer:
            assert bits_for(writer_depth) < 24
            self.writer_fifo_control = CSRStorage(fields=[
                CSRField("depth", offset=0, size=24, reset=writer_depth,
                    description="DMA Writer FIFO depth (in {}-bit words).".format(data_width)),
                CSRField("scratch",    offset=24, size=4, description="Software Scratchpad."),
                CSRField("level_mode", offset=31, values=[
                    ("``0b0``", "Report Instantaneous level."),
                    ("``0b1``", "Report `Maximal` level since last clear.")
                ])
            ])
            self.writer_fifo_status = CSRStatus(fields=[
                CSRField("level", offset=0, size=24,
                    description="DMA Writer FIFO level (in {}-bit words).".format(data_width))
                ])

        # # #

        depth_shift = log2_int(data_width//8)

        # Reader FIFO.
        if with_reader:
            reader_fifo = ResetInserter()(SyncFIFO(dma_layout(data_width), reader_depth//(data_width//8), buffered=True))
            self.submodules += reader_fifo
            self.comb += [
                reader_fifo.reset.eq(~self.reader_enable),
                # Connect Reader Sink to Reader FIFO when Level < Configured Depth.
                self.sink.connect(reader_fifo.sink, omit={"valid", "ready"}),
                If((reader_fifo.level < self.reader_fifo_control.fields.depth[depth_shift:]) | (not dynamic_depth),
                    self.sink.connect(reader_fifo.sink, keep={"valid", "ready"})
                ),
                # Connect Reader FIFO to Reader Source.
                reader_fifo.source.connect(self.next_source),
            ]

            # Store Min.
            reader_fifo_level_min = Signal.like(reader_fifo.level)
            self.sync += If(reader_fifo.level < reader_fifo_level_min, reader_fifo_level_min.eq(reader_fifo.level))
            # Clear on Status write or when in Instantaneous mode.
            reader_fifo_level_clr = (self.reader_fifo_status.re | (self.reader_fifo_control.fields.level_mode == 0))
            self.sync += If(reader_fifo_level_clr, reader_fifo_level_min.eq(2**len(reader_fifo_level_min)-1))
            # Return Reader FIFO level.
            self.comb += [
                # Instantaneous.
                If(self.reader_fifo_control.fields.level_mode == 0,
                    self.reader_fifo_status.fields.level[depth_shift:].eq(reader_fifo.level)
                # Min.
                ).Else(
                    self.reader_fifo_status.fields.level[depth_shift:].eq(reader_fifo_level_min)
                )
            ]

        # Writer FIFO.
        if with_writer:
            writer_fifo = ResetInserter()(SyncFIFO(dma_layout(data_width), writer_depth//(data_width//8), buffered=True))
            self.submodules += writer_fifo
            self.comb += [
                writer_fifo.reset.eq(~self.writer_enable),
                # Connect Writer Sink to Writer FIFO when Level < Configured Depth.
                self.next_sink.connect(writer_fifo.sink, omit={"valid", "ready"}),
                If((writer_fifo.level < self.writer_fifo_control.fields.depth[depth_shift:]) | (not dynamic_depth),
                    self.next_sink.connect(writer_fifo.sink, keep={"valid", "ready"})
                ),
                # Connect Writer FIFO to Writer Source.
                writer_fifo.source.connect(self.source),
            ]

            # Store Max.
            writer_fifo_level_max = Signal.like(writer_fifo.level)
            self.sync += If(writer_fifo.level > writer_fifo_level_max, writer_fifo_level_max.eq(writer_fifo.level))
            # Clear on Status write or when in Instantaneous mode.
            writer_fifo_level_clr = (self.writer_fifo_status.re | (self.writer_fifo_control.fields.level_mode == 0))
            self.sync += If(writer_fifo_level_clr, writer_fifo_level_max.eq(0))
            # Return Writer FIFO level.
            self.comb += [
                # Instantaneous.
                If(self.writer_fifo_control.fields.level_mode == 0,
                    self.writer_fifo_status.fields.level[depth_shift:].eq(writer_fifo.level)
                # Min.
                ).Else(
                    self.writer_fifo_status.fields.level[depth_shift:].eq(writer_fifo_level_max)
                )
            ]

# LitePCIeDMAStatus --------------------------------------------------------------------------------

class LitePCIeDMAStatus(LiteXModule):
    """LitePCIe DMA Status

    Optional DMA Status writer to Host Memory.

    LitePCIeDMAStatus writes 16 x 32-bit words to the Host memory. The first 8 words are reserved for
    the internal DMA status and the last 8 words for optional external status. The mapping as follows:

    0:    Sync Word (0x5aa55aa5).
    1:    DMA Writer Loop Status 32-bit LSB.
    2:    DMA Reader Loop Status 32-bit LSB.
    3:    DMA Writer Loop Status 32-bit MSB (Optional).
    4:    DMA Reader Loop Status 32-bit MSB (Optional).
    3-7:  Reserved
    8-15: External (Optional, from user logic/design).

    The Update to the Host Memory can be triggered from the following events:
    - External (From user logic/design).
    - DMA Writer IRQ.
    - DMA Reader IRQ.
    Allowing a Synchronous or Asynchrounous update with the DMAs.
    """
    def __init__(self, endpoint, writer, reader, address_width=32, status_width=32):
        assert status_width in [32, 64]
        self.control = CSRStorage(fields=[
            CSRField("enable", offset=0, size=1, description="Status Enable"),
            CSRField("update", offset=4, size=2, description="Status Update Event", values=[
                ("``0b00``", "External."),
                ("``0b01``", "DMA Writer IRQ."),
                ("``0b10``", "DMA Reader IRQ."),
                ("``0b11``", "Software."),
            ]),
        ])
        self.address_lsb = CSRStorage(32, description="Status Base Address (LSB) on Host.")
        self.address_msb = CSRStorage(32, description="Status Base Address (MSB) on Host.")

        self.external_update = Signal()
        self.external_status = Array([Signal(32) for _ in range(8)])

        # # #


        # Create Status Array.
        # --------------------
        status = Array([Signal(32) for _ in range(16)])
        # 0-7:  Internal.
        sync_word = 0x5aa55aa5
        self.comb += [
            status[0].eq(0x5aa55aa5),
            status[1].eq(writer.table.loop_status.status),
            status[2].eq(reader.table.loop_status.status),
        ]
        if status_width == 64:
            class DMAStatusMSB(LiteXModule):
                def __init__(self, enable, lsb):
                    self.value = value = Signal(32)

                    # # #

                    lsb_new  = lsb[-16:]
                    lsb_last = Signal(16)

                    self.sync += [
                        lsb_last.eq(lsb_new),
                        If((lsb_new == 0x0000) & (lsb_last == 0xffff),
                            value.eq(value + 1)
                        ),
                        If(enable == 0,
                            value.eq(0)
                        ),
                    ]

            self.writer_status_msb = DMAStatusMSB(
                enable = writer.enable,
                lsb    = writer.table.loop_status.status,
            )
            self.reader_status_msb = DMAStatusMSB(
                enable = reader.enable,
                lsb    = reader.table.loop_status.status,
            )
            self.comb += [
                status[3].eq(self.writer_status_msb.value),
                status[4].eq(self.reader_status_msb.value),
            ]

        # 7-15: External.
        for i in range(8):
            self.comb += status[8 + i].eq(self.external_status[i])

        # Update Event.
        # -------------
        update = Signal()
        update_cases = {
            0b00: update.eq(self.external_update),
            0b01: update.eq(writer.irq),
            0b10: update.eq(reader.irq),
            0b11: update.eq(self.control.re),
        }
        self.comb += Case(self.control.fields.update, update_cases)

        # Update Logic.
        # -------------
        port   = endpoint.crossbar.get_master_port(write_only=True)
        dwords = len(port.source.dat)//32
        offset = Signal(4)
        assert len(status)%dwords == 0

        self.fsm = fsm = FSM(reset_state="IDLE")
        fsm.act("IDLE",
            If(self.control.fields.enable,
                If(update,
                    NextValue(offset, 0),
                    NextState("WORDS-WRITE")
                )
            )
        )
        fsm.act("WORDS-UPDATE",
            NextValue(offset, offset + dwords),
            If(offset == (len(status) - dwords),
                NextState("IDLE")
            ).Else(
                NextState("WORDS-DELAY")
            )
        )
        fsm.act("WORDS-DELAY",
            NextState("WORDS-WRITE")
        )
        self.sync += [
            port.source.channel.eq(port.channel),
            port.source.first.eq(1),
            port.source.last.eq(1),
            port.source.req_id.eq(endpoint.phy.id),
            port.source.tag.eq(0),
            port.source.len.eq(dwords),
            port.source.adr.eq({
                32:              (0x0000_0000 << 32) + self.address_lsb.storage + (offset << 2),
                64: (self.address_msb.storage << 32) + self.address_lsb.storage + (offset << 2),
            }[address_width]),
        ]
        for n in range(dwords):
            self.sync += port.source.dat[32*n:32*(n+1)].eq(status[offset + n])

        fsm.act("WORDS-WRITE",
            port.source.valid.eq(1),
            port.source.we.eq(1),
            If(port.source.ready,
                NextState("WORDS-UPDATE")
            )
        )

# LitePCIeDMA --------------------------------------------------------------------------------------

class LitePCIeDMA(LiteXModule):
    """LitePCIe DMA

    Scatter-Gather bi-directional DMA:
    - Generates a data stream from Host's memory.
    - Stores a data stream to Host's memory.

    Optional buffering, loopback, synchronization and monitoring.
    """
    def __init__(self, phy, endpoint, with_table=True, table_depth=256, address_width=32, data_width=None,
        with_writer       = True,
        with_reader       = True,
        # Loopback.
        with_loopback     = False,
        # Synchronizer.
        with_synchronizer = False,
        # Buffering.
        with_buffering    = False, buffering_depth=256*8, writer_buffering_depth=None, reader_buffering_depth=None,
        # Monitor.
        with_monitor      = False,
        # Status.
        with_status       = False, status_width=32,
    ):
        # Parameters -------------------------------------------------------------------------------
        self.data_width = data_width or phy.data_width

        # Endoints ---------------------------------------------------------------------------------
        self.sink   = stream.Endpoint(dma_layout(self.data_width))
        self.source = stream.Endpoint(dma_layout(self.data_width))

        # Writer/Reader ----------------------------------------------------------------------------
        if with_writer:
            self.writer = LitePCIeDMAWriter(
                endpoint             = endpoint,
                port                 = endpoint.crossbar.get_master_port(write_only=True),
                with_table           = with_table,
                table_depth          = table_depth,
                address_width        = address_width,
                data_width           = self.data_width,
            )
            self.comb += self.sink.connect(self.writer.sink)

        if with_reader:
            self.reader = LitePCIeDMAReader(
                endpoint             = endpoint,
                port                 = endpoint.crossbar.get_master_port(read_only=True),
                with_table           = with_table,
                table_depth          = table_depth,
                address_width        = address_width,
                data_width           = self.data_width,
            )
            self.comb += self.reader.source.connect(self.source)

        # Loopback ---------------------------------------------------------------------------------
        if with_loopback:
            if not (with_writer and with_reader):
                raise ValueError("Loopback capability requires DMAWriter and DMAReader to be enabled.")
            self.loopback = LitePCIeDMALoopback(self.data_width)
            self.add_plugin_module(self.loopback)

        # Synchronizer -----------------------------------------------------------------------------
        if with_synchronizer:
            if not (with_writer and with_reader):
                raise ValueError("Synchronizer capability requires DMAWriter and DMAReader to be enabled.")
            self.synchronizer = LitePCIeDMASynchronizer(self.data_width)
            self.add_plugin_module(self.synchronizer)

        # Buffering --------------------------------------------------------------------------------
        if with_buffering:
            writer_depth = writer_buffering_depth if writer_buffering_depth is not None else buffering_depth
            reader_depth = reader_buffering_depth if reader_buffering_depth is not None else buffering_depth
            self.buffering = LitePCIeDMABuffering(
                data_width   = self.data_width,
                with_reader  = with_reader,
                with_writer  = with_writer,
                reader_depth = reader_depth,
                writer_depth = writer_depth,
            )
            if with_writer:
                self.comb += self.buffering.writer_enable.eq(self.writer.enable)
            if with_reader:
                self.comb += self.buffering.reader_enable.eq(self.reader.enable)

            self.add_plugin_module(self.buffering)

        # Monitor ----------------------------------------------------------------------------------
        if with_monitor:
            if with_writer:
                self.writer_monitor = stream.Monitor(self.sink,   count_width=16, with_overflows=True)
            if with_reader:
                self.reader_monitor = stream.Monitor(self.source, count_width=16, with_underflows=True)

        # Status -----------------------------------------------------------------------------------
        if with_status:
            if not (with_writer and with_reader):
                raise ValueError("Status capability requires DMAWriter and DMAReader to be enabled.")
            self.status = LitePCIeDMAStatus(
                endpoint      = endpoint,
                writer        = self.writer,
                reader        = self.reader,
                address_width = address_width,
                status_width  = status_width,

            )

    def add_plugin_module(self, m):
        self.comb += [
            self.source.connect(m.sink),
            m.source.connect(self.sink)
        ]
        self.sink, self.source = m.next_sink, m.next_source

```

`litepcie/frontend/ptm/__init__.py`:

```py
#
# This file is part of LitePCIe-PTM.
#
# Copyright (c) 2023 NetTimeLogic
# Copyright (c) 2023 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

from litepcie.frontend.ptm.sniffer import PCIePTMSniffer
from litepcie.frontend.ptm.core    import PTMCapabilities, PTMRequester

```

`litepcie/frontend/ptm/core.py`:

```py
#
# This file is part of LitePCIe-PTM.
#
# Copyright (c) 2023 NetTimeLogic
# Copyright (c) 2023 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

from migen import *

from litex.gen import *
from litex.gen.genlib.misc import WaitTimer

from litex.soc.interconnect.csr    import *
from litex.soc.interconnect import stream

from litepcie.common import phy_layout

# PTM Constants ------------------------------------------------------------------------------------

PTM_REQUEST_MESSAGE_CODE   = 0b01010010 # PTM Request.
PTM_RESPONSE_MESSAGE_CODE  = 0b01010011 # PTM Response without timing information.
PTM_RESPONSED_MESSAGE_CODE = 0b01010011 # PTM Response with timing information.

# PTM Capabilities Constants -----------------------------------------------------------------------

PTM_STRUCTURE_REGS = 3

PTM_HEADER_REG      = 0x00
PTM_CAPABILITY_REG  = 0x04
PTM_CONTROL_REG     = 0x08

PTM_HEADER_ID_OFFSET      = 0
PTM_HEADER_VERSION_OFFSET = 16

PTM_CAPABILITY_REQUESTER_CAPABLE_OFFSET = 0
PTM_CAPABILITY_RESPONDER_CAPABLE_OFFSET = 1
PTM_CAPABILITY_ROOT_CAPABLE_OFFSET      = 2
PTM_CAPABILITY_CLOCK_GRANULARITY_OFFSET = 8

PTM_CONTROL_ENABLE_OFFSET                = 0
PTM_CONTROL_ROOT_SELECT_OFFSET           = 1
PTM_CONTROL_EFFECTIVE_GRANULARITY_OFFSET = 8

# PTM Capabilities ---------------------------------------------------------------------------------

class PTMCapabilities(LiteXModule):
    def __init__(self, pcie_endpoint,
        requester_capable = True,
        responder_capable = False,
        root_capable      = False,
        clock_granularity = 8e-9,
    ):
        # Outputs.
        self.ptm_enable                = Signal()
        self.ptm_root_select           = Signal()
        self.ptm_effective_granularity = Signal(8)

        # # #

        # Signals.
        reg  = Signal(10)
        dat  = Signal(32)

        # PTM Capability Structure Initial Content.
        ptm_capability_init = {
           PTM_HEADER_REG      : ((1 << PTM_HEADER_VERSION_OFFSET) * 0x01 |
                                  (1 << PTM_HEADER_ID_OFFSET)      * 0x1f),
           PTM_CAPABILITY_REG  : ((1 << PTM_CAPABILITY_REQUESTER_CAPABLE_OFFSET) * requester_capable |
                                  (1 << PTM_CAPABILITY_RESPONDER_CAPABLE_OFFSET) * responder_capable |
                                  (1 << PTM_CAPABILITY_ROOT_CAPABLE_OFFSET)      * root_capable      |
                                  (1 << PTM_CAPABILITY_CLOCK_GRANULARITY_OFFSET) * int(clock_granularity*1e9)),
           PTM_CONTROL_REG     : ((1 << PTM_CONTROL_ENABLE_OFFSET)                * 0 |
                                  (1 << PTM_CONTROL_ROOT_SELECT_OFFSET)           * 0 |
                                  (1 << PTM_CONTROL_EFFECTIVE_GRANULARITY_OFFSET) * 0),
        }

        # PTM Capability Structure Memory.
        mem = Memory(32, PTM_STRUCTURE_REGS, init=[ptm_capability_init[4*i] for i in range(PTM_STRUCTURE_REGS)])
        mem_wr_port   = mem.get_port(write_capable=True)
        mem_rd_port   = mem.get_port(async_read=True)
        mem_ctrl_port = mem.get_port(async_read=True)
        self.specials += mem, mem_wr_port, mem_rd_port, mem_ctrl_port

        # PTM Capability Configuration/Completion Endpoints
        self.conf_ep = conf_ep = pcie_endpoint.depacketizer.conf_source
        self.comp_ep = comp_ep = pcie_endpoint.crossbar.get_slave_port(address_decoder=lambda a: 0).source

        # PTM Capability FSM.
        self.fsm = fsm = FSM(reset_state="IDLE")
        fsm.act("IDLE",
            If(conf_ep.valid,
                If(conf_ep.we,
                    NextState("WRITE-MEM")
                ).Else(
                    NextState("READ-MEM")
                )
            )
        )
        self.comb += reg.eq((Cat(conf_ep.register_no, conf_ep.ext_reg) - 0x6B)) # FIXME: Expose.
        fsm.act("WRITE-MEM",
            conf_ep.ready.eq(1),
            mem_wr_port.adr.eq(reg),
            mem_wr_port.we.eq(1),
            mem_wr_port.dat_w.eq(conf_ep.dat),
            NextState("IDLE")
        )
        fsm.act("READ-MEM",
            mem_rd_port.adr.eq(reg),
            NextValue(dat, mem_rd_port.dat_r),
            NextState("SEND-COMPLETION")
        )

        fsm.act("SEND-COMPLETION",
            comp_ep.valid.eq(1),
            comp_ep.first.eq(1),
            comp_ep.last.eq(1),
            comp_ep.len.eq(1),
            comp_ep.err.eq(0),
            comp_ep.tag.eq(conf_ep.tag),
            comp_ep.adr.eq(0),
            comp_ep.cmp_id.eq(pcie_endpoint.phy.id),
            comp_ep.req_id.eq(conf_ep.req_id),
            comp_ep.dat.eq(dat),
            If(comp_ep.valid & comp_ep.ready,
                conf_ep.ready.eq(1),
                NextState("IDLE")
            )
        )

        # PTM Control Outputs.
        self.comb += [
            mem_ctrl_port.adr.eq(PTM_CONTROL_REG//4),
            self.ptm_enable.eq(               (mem_ctrl_port.dat_r >> PTM_CONTROL_ENABLE_OFFSET)                & 0b1),
            self.ptm_root_select.eq(          (mem_ctrl_port.dat_r >> PTM_CONTROL_ROOT_SELECT_OFFSET)           & 0b1),
            self.ptm_effective_granularity.eq((mem_ctrl_port.dat_r >> PTM_CONTROL_EFFECTIVE_GRANULARITY_OFFSET) & 0b1111_1111),
        ]

# PTM Requester ------------------------------------------------------------------------------------

class PTMRequester(LiteXModule):
    def __init__(self, pcie_endpoint, pcie_ptm_sniffer, sys_clk_freq, with_csr=True):
        # Inputs.
        self.enable     = Signal()
        self.trigger    = Signal()
        self.invalidate = Signal()

        # Outputs.
        self.valid       = Signal()
        self.busy        = Signal()
        self.update      = Signal()
        self.master_time = Signal(64)
        self.link_delay  = Signal(32)
        self.t1          = Signal(64)
        self.t4          = Signal(64)

        # Time.
        self.time_clk = Signal()
        self.time_rst = Signal()
        self.time     = Signal(64)

        # CSRs.
        if with_csr:
            self.add_csr(sys_clk_freq)

        # # #

        # Time Clock Domain Crossing.
        self.cd_time = ClockDomain(name="ptm_requester_time")
        self.comb += [
            self.cd_time.clk.eq(self.time_clk),
            self.cd_time.rst.eq(self.time_rst),
        ]
        time_cdc = stream.ClockDomainCrossing([("time", 64)],
            cd_from  = "ptm_requester_time",
            cd_to    = "sys",
        )
        self.submodules += time_cdc
        self.comb += [
            time_cdc.sink.valid.eq(1),
            time_cdc.sink.time.eq(self.time),
            time_cdc.source.ready.eq(1),
        ]
        time = Signal(64)
        self.sync += If(time_cdc.source.valid,
            time.eq(time_cdc.source.time)
        )

        # PTM Request Endpoint.
        self.req_ep = req_ep = pcie_endpoint.packetizer.ptm_sink

        # PTM Response Endpoint.
        self.res_ep = res_ep = pcie_ptm_sniffer.source

        # PTM Request Timer.
        self.req_timer = req_timer = WaitTimer(1e-6*sys_clk_freq)

        # PTM Requester FSM.
        self.fsm = fsm = ResetInserter()(FSM(reset_state="START"))
        self.comb += fsm.reset.eq(~self.enable)
        fsm.act("START",
            If(self.enable,
                NextState("INVALID-PTM-CONTEXT")
            )
        )
        fsm.act("INVALID-PTM-CONTEXT",
            If(self.trigger,
                NextState("ISSUE-PTM-REQUEST")
            )
        )
        fsm.act("ISSUE-PTM-REQUEST",
            self.busy.eq(1),
            req_ep.valid.eq(1),
            req_ep.request.eq(1),
            req_ep.response.eq(0),
            req_ep.first.eq(1),
            req_ep.last.eq(1),
            req_ep.length.eq(0),
            req_ep.requester_id.eq(pcie_endpoint.phy.id),
            req_ep.message_code.eq(PTM_REQUEST_MESSAGE_CODE),
            If(req_ep.ready,
                NextValue(self.t1, time),
                NextState("WAIT-PTM-RESPONSE")
            )
        )
        self.comb += pcie_ptm_sniffer.source.ready.eq(1)
        fsm.act("WAIT-PTM-RESPONSE",
            self.busy.eq(1),
            If(pcie_ptm_sniffer.source.valid,
                If(pcie_ptm_sniffer.source.message_code == PTM_RESPONSE_MESSAGE_CODE,
                    If(pcie_ptm_sniffer.source.master_time == 0, # FIXME: Add Response/ResponseD indication.
                        NextState("WAIT-1-US")
                    ).Else(
                        NextValue(self.update, 1),
                        NextValue(self.master_time, pcie_ptm_sniffer.source.master_time),
                        NextValue(self.link_delay,  pcie_ptm_sniffer.source.link_delay),
                        NextValue(self.t4, time),
                        NextState("VALID-PTM-CONTEXT")
                    )
                )
            )
        )
        fsm.act("WAIT-1-US",
            self.req_timer.wait.eq(1),
            If(self.req_timer.done,
                NextState("ISSUE-PTM-REQUEST")
            )
        )
        fsm.act("VALID-PTM-CONTEXT",
            self.valid.eq(1),
            NextValue(self.update, 0),
            If(self.trigger,
                NextState("ISSUE-PTM-REQUEST")
            ),
            If(self.invalidate,
                NextState("INVALID-PTM-CONTEXT")
            )
        )

    def add_csr(self, sys_clk_freq, default_enable=0, phy_tx_delay=40e-9, phy_rx_delay=100e-9):
        self._control = CSRStorage(fields=[
            CSRField("enable", size=1, offset=0, values=[
                ("``0b0``", "PTM Requester Disabled."),
                ("``0b1``", "PTM Requester Enabled."),
            ], reset=default_enable),
            CSRField("trigger", size=1, offset=1, pulse=True),
        ])
        self._status = CSRStatus(fields=[
            CSRField("valid", size=1, offset=0, values=[
                ("``0b0``", "PTM Context Invalid."),
                ("``0b1``", "PTM Context Valid."),
            ]),
            CSRField("busy", size=1, offset=1, values=[
                ("``0b0``", "PTM Request Done."),
                ("``0b1``", "PTM Request Ongoing."),
            ]),

        ])
        self._phy_tx_delay = CSRStatus(32, reset=int(phy_tx_delay*1e9), description="PHY TX logic delay (in ns).")
        self._phy_rx_delay = CSRStatus(32, reset=int(phy_rx_delay*1e9), description="PHY RX logic delay (in ns).")
        self._master_time  = CSRStatus(64, description="Last PTM Master Time (in ns).")
        self._link_delay   = CSRStatus(32, description="Last PTM Link Delay (in ns).")
        self._t1_time      = CSRStatus(64, description="Last PTM T1 Time (in ns).")
        self._t4_time      = CSRStatus(64, description="Last PTM T4 Time (in ns).")

        # # #

        self.comb += [
            # Control.
            self.enable.eq(self._control.fields.enable),
            self.trigger.eq(self._control.fields.trigger),
            # Status.
            self._status.fields.valid.eq(self.valid),
            self._status.fields.busy.eq(self.busy),
            # Time.
            self._master_time.status.eq(self.master_time),
            self._link_delay.status.eq(self.link_delay),
            self._t1_time.status.eq(self.t1),
            self._t4_time.status.eq(self.t4),
        ]

```

`litepcie/frontend/ptm/sniffer.py`:

```py
#
# This file is part of LitePCIe-PTM.
#
# Copyright (c) 2023 NetTimeLogic
# Copyright (c) 2019-2023 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

import os

from migen import *

from litex.gen import *

from litex.soc.interconnect import stream

from litepcie.common     import phy_layout
from litepcie.tlp.common import fmt_type_dict

from litepcie.tlp.depacketizer import LitePCIeTLPDepacketizer

# Helpers ------------------------------------------------------------------------------------------

def K(x, y):
    """K code generator ex: K(28, 5) is COM Symbol"""
    return (y << 5) | x

def D(x, y):
    """D code generator"""
    return (y << 5) | x

# Symbols (6.3.5) ----------------------------------------------------------------------------------

class Symbol:
    """Symbol definition with name, 8-bit value and description"""
    def __init__(self, name, value, description=""):
        self.name        = name
        self.value       = value
        self.description = description

SKP =  Symbol("SKP", K(28, 1), "Skip")
SDP =  Symbol("SDP", K(28, 2), "Start Data Packet")
EDB =  Symbol("EDB", K(28, 3), "End Bad")
SUB =  Symbol("SUB", K(28, 4), "Decode Error Substitution")
COM =  Symbol("COM", K(28, 5), "Comma")
RSD =  Symbol("RSD", K(28, 6), "Reserved")
SHP =  Symbol("SHP", K(27, 7), "Start Header Packet")
END =  Symbol("END", K(29, 7), "End")
SLC =  Symbol("SLC", K(30, 7), "Start Link Command")
EPF =  Symbol("EPF", K(23, 7), "End Packet Framing")

symbols = [SKP, SDP, EDB, SUB, COM, RSD, SHP, END, SLC, EPF]

# Endianness Swap ----------------------------------------------------------------------------------

class EndiannessSwap(LiteXModule):
    """Swap the data bytes/ctrl bits of stream"""
    def __init__(self, sink, source):
        assert len(sink.data) == len(source.data)
        assert len(sink.ctrl) == len(source.ctrl)
        self.comb += sink.connect(source, omit={"data", "ctrl"})
        n = len(sink.ctrl)
        for i in range(n):
            self.comb += source.data[8*i:8*(i+1)].eq(sink.data[8*(n-1-i):8*(n-1-i+1)])
            self.comb += source.ctrl[i].eq(sink.ctrl[n-1-i])

# Scrambler Unit (Appendix B) ----------------------------------------------------------------------

@ResetInserter()
@CEInserter()
class ScramblerUnit(Module):
    """Scrambler Unit

    This module generates the scrambled datas for the USB3.0 link (X^16 + X^5 + X^4 + X^3 + 1 polynom).
    """
    def __init__(self, reset=0xffff):
        self.value = Signal(32)

        # # #

        new = Signal(16)
        cur = Signal(16, reset=reset)

        self.comb += [
            new[0].eq(cur[0]  ^ cur[6] ^ cur[8]  ^ cur[10]),
            new[1].eq(cur[1]  ^ cur[7] ^ cur[9]  ^ cur[11]),
            new[2].eq(cur[2]  ^ cur[8] ^ cur[10] ^ cur[12]),
            new[3].eq(cur[3]  ^ cur[6] ^ cur[8]  ^ cur[9]  ^ cur[10] ^ cur[11] ^ cur[13]),
            new[4].eq(cur[4]  ^ cur[6] ^ cur[7]  ^ cur[8]  ^ cur[9]  ^ cur[11] ^ cur[12] ^ cur[14]),
            new[5].eq(cur[5]  ^ cur[6] ^ cur[7]  ^ cur[9]  ^ cur[12] ^ cur[13] ^ cur[15]),
            new[6].eq(cur[0]  ^ cur[6] ^ cur[7]  ^ cur[8]  ^ cur[10] ^ cur[13] ^ cur[14]),
            new[7].eq(cur[1]  ^ cur[7] ^ cur[8]  ^ cur[9]  ^ cur[11] ^ cur[14] ^ cur[15]),
            new[8].eq(cur[0]  ^ cur[2] ^ cur[8]  ^ cur[9]  ^ cur[10] ^ cur[12] ^ cur[15]),
            new[9].eq(cur[1]  ^ cur[3] ^ cur[9]  ^ cur[10] ^ cur[11] ^ cur[13]),
            new[10].eq(cur[0] ^ cur[2] ^ cur[4]  ^ cur[10] ^ cur[11] ^ cur[12] ^ cur[14]),
            new[11].eq(cur[1] ^ cur[3] ^ cur[5]  ^ cur[11] ^ cur[12] ^ cur[13] ^ cur[15]),
            new[12].eq(cur[2] ^ cur[4] ^ cur[6]  ^ cur[12] ^ cur[13] ^ cur[14]),
            new[13].eq(cur[3] ^ cur[5] ^ cur[7]  ^ cur[13] ^ cur[14] ^ cur[15]),
            new[14].eq(cur[4] ^ cur[6] ^ cur[8]  ^ cur[14] ^ cur[15]),
            new[15].eq(cur[5] ^ cur[7] ^ cur[9]  ^ cur[15]),

            self.value[0].eq(cur[15]),
            self.value[1].eq(cur[14]),
            self.value[2].eq(cur[13]),
            self.value[3].eq(cur[12]),
            self.value[4].eq(cur[11]),
            self.value[5].eq(cur[10]),
            self.value[6].eq(cur[9]),
            self.value[7].eq(cur[8]),
            self.value[8].eq(cur[7]),
            self.value[9].eq(cur[6]),
            self.value[10].eq(cur[5]),
            self.value[11].eq(cur[4]  ^ cur[15]),
            self.value[12].eq(cur[3]  ^ cur[14] ^ cur[15]),
            self.value[13].eq(cur[2]  ^ cur[13] ^ cur[14] ^ cur[15]),
            self.value[14].eq(cur[1]  ^ cur[12] ^ cur[13] ^ cur[14]),
            self.value[15].eq(cur[0]  ^ cur[11] ^ cur[12] ^ cur[13]),
            self.value[16].eq(cur[10] ^ cur[11] ^ cur[12] ^ cur[15]),
            self.value[17].eq(cur[9]  ^ cur[10] ^ cur[11] ^ cur[14]),
            self.value[18].eq(cur[8]  ^ cur[9]  ^ cur[10] ^ cur[13]),
            self.value[19].eq(cur[7]  ^ cur[8]  ^ cur[9]  ^ cur[12]),
            self.value[20].eq(cur[6]  ^ cur[7]  ^ cur[8]  ^ cur[11]),
            self.value[21].eq(cur[5]  ^ cur[6]  ^ cur[7]  ^ cur[10]),
            self.value[22].eq(cur[4]  ^ cur[5]  ^ cur[6]  ^ cur[9]  ^ cur[15]),
            self.value[23].eq(cur[3]  ^ cur[4]  ^ cur[5]  ^ cur[8]  ^ cur[14]),
            self.value[24].eq(cur[2]  ^ cur[3]  ^ cur[4]  ^ cur[7]  ^ cur[13] ^ cur[15]),
            self.value[25].eq(cur[1]  ^ cur[2]  ^ cur[3]  ^ cur[6]  ^ cur[12] ^ cur[14]),
            self.value[26].eq(cur[0]  ^ cur[1]  ^ cur[2]  ^ cur[5]  ^ cur[11] ^ cur[13] ^ cur[15]),
            self.value[27].eq(cur[0]  ^ cur[1]  ^ cur[4]  ^ cur[10] ^ cur[12] ^ cur[14]),
            self.value[28].eq(cur[0]  ^ cur[3]  ^ cur[9]  ^ cur[11] ^ cur[13]),
            self.value[29].eq(cur[2]  ^ cur[8]  ^ cur[10] ^ cur[12]),
            self.value[30].eq(cur[1]  ^ cur[7]  ^ cur[9]  ^ cur[11]),
            self.value[31].eq(cur[0]  ^ cur[6]  ^ cur[8]  ^ cur[10]),
        ]
        self.sync += cur.eq(new)

# Scrambler (Appendix B) ---------------------------------------------------------------------------

class Scrambler(Module):
    """Scrambler

    This module scrambles the TX data/ctrl stream. K codes shall not be scrambled.
    """
    def __init__(self, reset=0x7dbd):
        self.enable = Signal(reset=1)
        self.sink   =   sink = stream.Endpoint([("data", 32), ("ctrl", 4)])
        self.source = source = stream.Endpoint([("data", 32), ("ctrl", 4)])

        # # #

        self.submodules.unit = unit = ScramblerUnit(reset=reset)
        self.comb += unit.ce.eq(sink.valid & sink.ready)
        self.comb += sink.connect(source)
        for i in range(4):
            self.comb += [
                If(~self.enable | sink.ctrl[i], # K codes shall not be scrambled.
                    source.data[8*i:8*(i+1)].eq(sink.data[8*i:8*(i+1)])
                ).Else(
                    source.data[8*i:8*(i+1)].eq(sink.data[8*i:8*(i+1)] ^ unit.value[8*i:8*(i+1)])
                )
            ]

# Raw Descrambler (Scrambler + Auto-Synchronization) (Appendix B) ----------------------------------

class RawDescrambler(Module):
    """Descrambler

    This module descrambles the RX data/ctrl stream. K codes shall not be scrambled. The descrambler
    automatically synchronizes itself to the incoming stream and resets the scrambler unit when COM
    characters are seen.
    """
    def __init__(self, reset=0xffff):
        self.enable = Signal(reset=1)
        self.sink   =   sink = stream.Endpoint([("data", 32), ("ctrl", 4)])
        self.source = source = stream.Endpoint([("data", 32), ("ctrl", 4)])

        # # #

        scrambler = Scrambler(reset=reset)
        self.submodules += scrambler
        self.comb += scrambler.enable.eq(self.enable)

        # Synchronize on COM
        for i in range(4):
            self.comb += [
                If(sink.valid &
                   sink.ready &
                   (sink.data[8*i:8*(i+1)] == COM.value) &
                   sink.ctrl[i],
                   scrambler.unit.reset.eq(1)
                )
            ]

        # Descramble data
        self.comb += [
            sink.connect(scrambler.sink),
            scrambler.source.connect(source)
        ]

# Raw Word Aligner ---------------------------------------------------------------------------------

class RawWordAligner(LiteXModule):
    """Raw Word Aligner

    Align RX Words by analyzing the location of the COM/K-codes (configurable) in the RX stream.
    """
    def __init__(self):
        self.enable = Signal(reset=1)
        self.sink   = sink   = stream.Endpoint([("data", 32), ("ctrl", 4)])
        self.source = source = stream.Endpoint([("data", 32), ("ctrl", 4)])

        # # #

        update      = Signal()
        alignment   = Signal(2)
        alignment_d = Signal(2)

        buf = stream.Buffer([("data", 32), ("ctrl", 4)])
        self.submodules += buf
        self.comb += [
            sink.connect(buf.sink),
            source.valid.eq(sink.valid & buf.source.valid),
            buf.source.ready.eq(sink.valid & source.ready),
        ]

        # Alignment detection
        for i in reversed(range(4)):
            self.comb += [
                If(sink.valid & sink.ready,
                    If(sink.ctrl[i] & (sink.data[8*i:8*(i+1)] == COM.value),
                        update.eq(1),
                        alignment.eq(i)
                    )
                )
            ]
        self.sync += [
            If(sink.valid & sink.ready,
                If(self.enable & update,
                    alignment_d.eq(alignment)
                )
            )
        ]

        # Data selection
        data = Cat(buf.source.data, sink.data)
        ctrl = Cat(buf.source.ctrl, sink.ctrl)
        cases = {}
        for i in range(4):
            cases[i] = [
                source.data.eq(data[8*i:]),
                source.ctrl.eq(ctrl[1*i:]),
            ]
        self.comb += Case(alignment_d, cases)

# Raw Datapath -------------------------------------------------------------------------------------

class RawDatapath(LiteXModule):
    """Raw Datapath

    This module realizes the:
    - Data-width adaptation (from transceiver's data-width to 32-bit).
    - Clock domain crossing (from transceiver's RX clock to system clock).
    - Words alignment.

    """
    def __init__(self, clock_domain="sys", phy_dw=16):
        self.sink   = stream.Endpoint([("data", phy_dw), ("ctrl", phy_dw//8)])
        self.source = stream.Endpoint([("data",     32), ("ctrl",         4)])

        # # #

        # Data-width adaptation
        converter = stream.StrideConverter(
            [("data", phy_dw), ("ctrl", phy_dw//8)],
            [("data",     32), ("ctrl",         4)],
            reverse=False)
        converter = stream.BufferizeEndpoints({"sink":   stream.DIR_SINK})(converter)
        converter = ClockDomainsRenamer(clock_domain)(converter)
        self.converter = converter

        # Clock domain crossing
        cdc = stream.AsyncFIFO([("data", 32), ("ctrl", 4)], 8, buffered=True)
        cdc = ClockDomainsRenamer({"write": clock_domain, "read": "sys"})(cdc)
        self.cdc = cdc

        # Words alignment
        word_aligner = RawWordAligner()
        word_aligner = stream.BufferizeEndpoints({"source": stream.DIR_SOURCE})(word_aligner)
        self.word_aligner = word_aligner

        # Flow
        self.submodules += stream.Pipeline(
            self.sink,
            converter,
            cdc,
            word_aligner,
            self.source,
        )

# TLP Aligner --------------------------------------------------------------------------------------

class TLPAligner(LiteXModule):
    def __init__(self):
        self.sink   = sink   = stream.Endpoint([("data", 32), ("ctrl", 4)])
        self.source = source = stream.Endpoint([("data", 32), ("ctrl", 4)])

        # # #

        first        = Signal()
        alignment    = Signal(2)
        sink_ctrl_d  = Signal(4)
        sink_ctrl_dd = Signal(4)
        sink_data_d  = Signal(32)
        sink_data_dd = Signal(32)

        self.comb += sink.ready.eq(1)
        self.sync += [
            If(sink.valid,
                sink_data_d.eq(sink.data),
                sink_data_dd.eq(sink_data_d),
                sink_ctrl_d.eq(sink.ctrl),
                sink_ctrl_dd.eq(sink_ctrl_d)
            )
        ]

        self.fsm = fsm = FSM(reset_state="IDLE")
        fsm.act("IDLE",
            If(sink.valid,
                If(sink.ctrl[0] & (sink.data[0*8:1*8] == 0xfb),
                   NextValue(alignment, 0b00),
                   NextState("RECEIVE-0")
                ),
                If(sink.ctrl[1] & (sink.data[1*8:2*8] == 0xfb),
                   NextValue(alignment, 0b01),
                   NextState("RECEIVE-0")
                ),
                If(sink.ctrl[2] & (sink.data[2*8:3*8] == 0xfb),
                   NextValue(alignment, 0b10),
                   NextState("RECEIVE-0")
                ),
                If(sink.ctrl[3] & (sink.data[3*8:4*8] == 0xfb),
                   NextValue(alignment, 0b11),
                   NextState("RECEIVE-0")
                )
            ),
        )
        fsm.act("RECEIVE-0",
            If(sink.valid,
                NextValue(first, 1),
                NextState("RECEIVE-1")
            )
        )
        fsm.act("RECEIVE-1",
            If(sink.valid,
                source.valid.eq(1),
                NextValue(first, 0),
                Case(alignment, {
                    0b00 : [
                        source.data[8*0:8*1].eq(sink_data_dd[8*3:8*4]),
                        source.data[8*1:8*2].eq(sink_data_d [8*0:8*1]),
                        source.data[8*2:8*3].eq(sink_data_d [8*1:8*2]),
                        source.data[8*3:8*4].eq(sink_data_d [8*2:8*3]),
                        source.ctrl[0].eq(sink_ctrl_dd[3]),
                        source.ctrl[1].eq(sink_ctrl_d [0]),
                        source.ctrl[2].eq(sink_ctrl_d [1]),
                        source.ctrl[3].eq(sink_ctrl_d [2]),
                    ],
                    0b01 : [
                        source.data[8*0:8*1].eq(sink_data_d[8*0:8*1]),
                        source.data[8*1:8*2].eq(sink_data_d[8*1:8*2]),
                        source.data[8*2:8*3].eq(sink_data_d[8*2:8*3]),
                        source.data[8*3:8*4].eq(sink_data_d[8*3:8*4]),
                        source.ctrl[0].eq(sink_ctrl_d[0]),
                        source.ctrl[1].eq(sink_ctrl_d[1]),
                        source.ctrl[2].eq(sink_ctrl_d[2]),
                        source.ctrl[3].eq(sink_ctrl_d[3]),
                    ],
                    0b10 : [
                        source.data[8*0:8*1].eq(sink_data_d[8*1:8*2]),
                        source.data[8*1:8*2].eq(sink_data_d[8*2:8*3]),
                        source.data[8*2:8*3].eq(sink_data_d[8*3:8*4]),
                        source.data[8*3:8*4].eq(sink.data  [8*0:8*1]),
                        source.ctrl[0].eq(sink_ctrl_d[1]),
                        source.ctrl[1].eq(sink_ctrl_d[2]),
                        source.ctrl[2].eq(sink_ctrl_d[3]),
                        source.ctrl[3].eq(sink.ctrl  [0]),
                    ],
                    0b11 : [
                        source.data[8*0:8*1].eq(sink_data_d[8*2:8*3]),
                        source.data[8*1:8*2].eq(sink_data_d[8*3:8*4]),
                        source.data[8*2:8*3].eq(sink.data  [8*0:8*1]),
                        source.data[8*3:8*4].eq(sink.data  [8*1:8*2]),
                        source.ctrl[0].eq(sink_ctrl_d[2]),
                        source.ctrl[1].eq(sink_ctrl_d[3]),
                        source.ctrl[2].eq(sink.ctrl  [0]),
                        source.ctrl[3].eq(sink.ctrl  [1]),
                    ],
                }),
            ),
            If(sink.valid & ~first,
                If(sink_ctrl_dd[0] & (sink_data_dd[0*8:1*8] == 0xfd),
                   source.last.eq(1),
                   NextState("IDLE")
                ),
                If(sink_ctrl_dd[1] & (sink_data_dd[1*8:2*8] == 0xfd),
                   source.last.eq(1),
                   NextState("IDLE")
                ),
                If(sink_ctrl_dd[2] & (sink_data_dd[2*8:3*8] == 0xfd),
                   source.last.eq(1),
                   NextState("IDLE")
                ),
                If(sink_ctrl_dd[3] & (sink_data_dd[3*8:4*8] == 0xfd),
                   source.last.eq(1),
                   NextState("IDLE")
                )
            ),
        )


# TLP Endianness Swap ------------------------------------------------------------------------------

class TLPEndiannessSwap(LiteXModule):
    def __init__(self):
        self.sink   = sink   = stream.Endpoint([("data", 32), ("ctrl", 4)])
        self.source = source = stream.Endpoint([("data", 32), ("ctrl", 4)])

        # # #

        self.submodules += EndiannessSwap(sink, source)

# TLP Filter/Formater ------------------------------------------------------------------------------

class TLPFilterFormater(LiteXModule):
    def __init__(self):
        self.sink   = sink   = stream.Endpoint([("data", 32), ("ctrl", 4)])
        self.source = source = stream.Endpoint(phy_layout(64))

        # # #

        # Signals.
        count = Signal(32)

        # Always accept incoming data.
        self.comb += sink.ready.eq(1)

        # Data-FIFO (For eventual source unavailability absorbtion).
        self.fifo = fifo = stream.SyncFIFO(phy_layout(32), depth=4, buffered=True)

        # Data-Width Converter: 32-bit to 64-bit.
        self.conv = conv = stream.StrideConverter(
            description_from = phy_layout(32),
            description_to   = phy_layout(64),
            reverse          = False
        )
        self.comb += [
            fifo.sink.be.eq(0b1111),
            fifo.source.connect(conv.sink),
            conv.source.connect(self.source),
        ]

        # FSM.
        self.fsm = fsm = FSM(reset_state="IDLE")
        fsm.act("IDLE",
            If(sink.valid,
                # PTM Request.
                If(sink.data[24:32] == fmt_type_dict["ptm_req"],
                    fifo.sink.valid.eq(1),
                    fifo.sink.dat.eq(sink.data),
                    NextValue(count, 3 - 1), # 3DWs Header.
                    NextState("RECEIVE")
                # PTM Response.
                ).Elif(sink.data[24:32] == fmt_type_dict["ptm_res"],
                    fifo.sink.valid.eq(1),
                    fifo.sink.dat.eq(sink.data),
                    NextValue(count, 4 - 1), # 4DWs Header.
                    NextState("RECEIVE")
                ).Else(
                    NextState("END")
                )
            )
        )
        fsm.act("RECEIVE",
            If(sink.valid,
                fifo.sink.valid.eq(1),
                fifo.sink.dat.eq(sink.data),
                NextValue(count, count - 1),
                If(count == 0,
                    fifo.sink.last.eq(1),
                    NextState("END")
                ),
                If(sink.last,
                    fifo.sink.last.eq(1),
                    NextState("IDLE")
                )
            )
        )
        fsm.act("END",
            If(sink.valid & sink.last,
                NextState("IDLE")
            )
        )

# PCIe PTM Sniffer ---------------------------------------------------------------------------------

class PCIePTMSniffer(LiteXModule):
    def __init__(self, rx_rst_n, rx_clk, rx_data, rx_ctrl):
        self.source = source = stream.Endpoint([("message_code", 8), ("master_time", 64), ("link_delay", 32)])
        assert len(rx_data) == 16
        assert len(rx_ctrl) == 2

        # # #

        # Clocking.
        self.cd_sniffer = ClockDomain()
        self.comb += self.cd_sniffer.clk.eq(rx_clk)
        self.comb += self.cd_sniffer.rst.eq(~rx_rst_n)

        # Raw Sniffing.
        self.raw_datapath    = ClockDomainsRenamer("sniffer")(RawDatapath(phy_dw=16))
        self.raw_descrambler = ClockDomainsRenamer("sniffer")(RawDescrambler())
        self.comb += [
            self.raw_datapath.sink.valid.eq(1),
            self.raw_datapath.sink.data.eq(rx_data),
            self.raw_datapath.sink.ctrl.eq(rx_ctrl),
            self.raw_datapath.source.connect(self.raw_descrambler.sink),
        ]

        # TLP Sniffing.
        self.tlp_aligner         = ClockDomainsRenamer("sniffer")(TLPAligner())
        self.tlp_endianness_swap = ClockDomainsRenamer("sniffer")(TLPEndiannessSwap())
        self.tlp_filter_formater = ClockDomainsRenamer("sniffer")(TLPFilterFormater())

        self.submodules += stream.Pipeline(
            self.raw_descrambler,
            self.tlp_aligner,
            self.tlp_endianness_swap,
            self.tlp_filter_formater,
        )

        # TLP Depacketizer. FIXME: Direct inject TLPs in LitePCIe through an Arbiter.
        self.tlp_depacketizer = ClockDomainsRenamer("sniffer")(LitePCIeTLPDepacketizer(
            data_width   = 64,
            endianness   = "big",
            address_mask = 0,
            capabilities = ["PTM"],
        ))
        self.comb += self.tlp_filter_formater.source.connect(self.tlp_depacketizer.sink)

        # TLP CDC.
        self.cdc = cdc = stream.ClockDomainCrossing(
            layout  = self.source.description,
            cd_from = "sniffer",
            cd_to   = "sys",
        )
        self.comb += [
            self.tlp_depacketizer.ptm_source.connect(cdc.sink, keep={"valid", "ready", "master_time"}),
            cdc.sink.message_code.eq(self.tlp_depacketizer.ptm_source.message_code),
            cdc.sink.master_time[ 0:32].eq(self.tlp_depacketizer.ptm_source.master_time[32:64]),
            cdc.sink.master_time[32:64].eq(self.tlp_depacketizer.ptm_source.master_time[ 0:32]),
            cdc.sink.link_delay.eq(reverse_bytes(self.tlp_depacketizer.ptm_source.dat[32:64])),
            cdc.source.connect(self.source)
        ]

    def add_sources(self, platform):
        cdir = os.path.abspath(os.path.dirname(__file__))
        platform.add_source(os.path.join(cdir, "sniffer_tap.v"))

```

`litepcie/frontend/ptm/sniffer_tap.v`:

```v
module sniffer_tap (
    (* mark_debug = "true" *)
    input wire         rst_n_in,
    (* mark_debug = "true" *)
    input wire         clk_in,
    (* mark_debug = "true" *)
    input wire [15:0]  rx_data_in,
    (* mark_debug = "true" *)
    input wire [1:0]   rx_ctl_in,

    output wire        rst_n_out,
    output wire        clk_out,
    output wire [15:0] rx_data_out,
    output wire [1:0]  rx_ctl_out
);

    assign rst_n_out   = rst_n_in;
    assign clk_out     = clk_in;
    assign rx_data_out = rx_data_in;
    assign rx_ctl_out  = rx_ctl_in;

endmodule
```

`litepcie/frontend/wishbone.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2015-2023 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

from migen import *

from litex.gen import *
from litex.gen.genlib.misc import WaitTimer

from litex.soc.interconnect import wishbone

from litepcie.common import *

# Helpers ------------------------------------------------------------------------------------------

def map_wishbone_dat(address, data, wishbone_dat, qword_aligned=False):
    return [
        If(qword_aligned,
            If(address[2],
                wishbone_dat.eq(data[:32])
            ).Else(
                wishbone_dat.eq(data[32:])
            )
        ).Else(
            wishbone_dat.eq(data[:32])
        )
    ]

# LitePCIeWishboneMaster ---------------------------------------------------------------------------

class LitePCIeWishboneMaster(LiteXModule):
    def __init__(self, endpoint,
        address_decoder = lambda a: 1,
        base_address    = 0x00000000,
        qword_aligned   = False):
        self.bus = self.wishbone = wishbone.Interface()

        # # #

        # Get Slave port from Crossbar.
        port = endpoint.crossbar.get_slave_port(address_decoder)

        # Wishbone Master FSM.
        self.fsm = fsm = FSM(reset_state="IDLE")
        fsm.act("IDLE",
            If(port.sink.valid & port.sink.first,
                If(port.sink.we,
                    NextState("DO-WRITE")
                ).Else(
                    NextState("DO-READ")
                )
            ).Else(
                port.sink.ready.eq(1)
            )
        )
        self.sync += [
            self.bus.sel.eq(0xf),
            self.bus.adr.eq(port.sink.adr[2:] + (base_address >> 2)),
            map_wishbone_dat(
                address       = port.sink.adr,
                data          = port.sink.dat,
                wishbone_dat  = self.bus.dat_w,
                qword_aligned = qword_aligned,
            ),
        ]
        fsm.act("DO-WRITE",
            self.bus.stb.eq(1),
            self.bus.we.eq(1),
            self.bus.cyc.eq(1),
            If(self.bus.ack,
                port.sink.ready.eq(1),
                NextState("IDLE")
            )
        )
        update_dat = Signal()
        fsm.act("DO-READ",
            self.bus.stb.eq(1),
            self.bus.we.eq(0),
            self.bus.cyc.eq(1),
            If(self.bus.ack,
                update_dat.eq(1),
                NextState("ISSUE-READ-COMPLETION")
            )
        )
        self.sync += [
            port.source.first.eq(1),
            port.source.last.eq(1),
            port.source.len.eq(1),
            port.source.err.eq(0),
            port.source.tag.eq(port.sink.tag),
            port.source.adr.eq(port.sink.adr),
            port.source.cmp_id.eq(endpoint.phy.id),
            port.source.req_id.eq(port.sink.req_id),
            If(update_dat,
                port.source.dat.eq(self.bus.dat_r)
            )
        ]
        fsm.act("ISSUE-READ-COMPLETION",
            port.source.valid.eq(1),
            If(port.source.ready,
                port.sink.ready.eq(1),
                NextState("IDLE")
            )
        )

class LitePCIeWishboneBridge(LitePCIeWishboneMaster): pass # initial name

# LitePCIeWishboneSlave ----------------------------------------------------------------------------

class LitePCIeWishboneSlave(LiteXModule):
    def __init__(self, endpoint, address_width=32, data_width=32, addressing="word", qword_aligned=False):
        assert data_width == 32
        self.bus = self.wishbone = wishbone.Interface(
            address_width = address_width,
            data_width    = data_width,
            addressing    = addressing,
        )

        # # #

        # Timeout.
        self.timeout = timeout = WaitTimer(2**16)

        # Get Master port from Crossbar.
        port = endpoint.crossbar.get_master_port()

        # Wishbone Slave FSM.
        self.fsm = fsm = FSM(reset_state="IDLE")
        fsm.act("IDLE",
            If(self.bus.stb & self.bus.cyc,
                If(self.bus.we,
                    NextState("ISSUE-WRITE")
                ).Else(
                    NextState("ISSUE-READ")
                )
            )
        )
        ashift = {"byte" : 0, "word" : 2}[addressing]
        self.comb += [
            port.source.channel.eq(port.channel),
            port.source.first.eq(1),
            port.source.last.eq(1),
            port.source.adr[ashift:].eq(self.bus.adr),
            port.source.req_id.eq(endpoint.phy.id),
            port.source.tag.eq(0),
            port.source.len.eq(1),
            port.source.dat.eq(self.bus.dat_w),
        ]
        fsm.act("ISSUE-WRITE",
            timeout.wait.eq(1),
            port.source.valid.eq(1),
            port.source.we.eq(1),
            If(port.source.ready | timeout.done,
                self.bus.ack.eq(1),
                self.bus.err.eq(timeout.done),
                NextState("IDLE")
            )
        )
        fsm.act("ISSUE-READ",
            timeout.wait.eq(1),
            port.source.valid.eq(1),
            port.source.we.eq(0),
            If(port.source.ready | timeout.done,
                NextState("RECEIVE-READ-COMPLETION")
            )
        )
        fsm.act("RECEIVE-READ-COMPLETION",
            timeout.wait.eq(1),
            port.sink.ready.eq(1),
            If((port.sink.valid & port.sink.first) | timeout.done,
                map_wishbone_dat(
                    address       = port.sink.adr,
                    data          = port.sink.dat,
                    wishbone_dat  = self.bus.dat_r,
                    qword_aligned = qword_aligned,
                ),
                self.bus.ack.eq(1),
                self.bus.err.eq(timeout.done),
                NextState("IDLE")
            )
        )

```

`litepcie/gen.py`:

```py
#!/usr/bin/env python3

#
# This file is part of LitePCIe.
#
# Copyright (c) 2019-2023 Florent Kermarrec <florent@enjoy-digital.fr>
# Copyright (c) 2020 Antmicro <www.antmicro.com>
# SPDX-License-Identifier: BSD-2-Clause

"""
LitePCIe standalone core generator

LitePCIe aims to be directly used as a python package when the SoC is created using LiteX. However,
for some use cases it could be interesting to generate a standalone verilog file of the core:
- integration of the core in a SoC using a more traditional flow.
- need to version/package the core.
- avoid Migen/LiteX dependencies.
- etc...

The standalone core is generated from a YAML configuration file that allows the user to generate
easily a custom configuration of the core.

Current version of the generator is limited to:
- Xilinx 7-Series.
- Xilinx Ultrascale.
- Altera Cyclone V.
- Gowin GW5AT.
- Lattice LFCPNX.
"""

import yaml
import argparse
import subprocess

from migen import *
from migen.genlib.resetsync import AsyncResetSynchronizer

from litex.gen import *

from litex.soc.cores.clock          import *
from litex.soc.interconnect.csr     import *
from litex.soc.interconnect         import wishbone
from litex.soc.interconnect.axi     import *
from litex.soc.integration.soc      import SoCRegion
from litex.soc.integration.soc_core import *
from litex.soc.integration.builder  import *

from litepcie.phy.c5pciephy     import C5PCIEPHY
from litepcie.phy.lfcpnxpciephy import LFCPNXPCIEPHY
from litepcie.phy.gw5apciephy   import GW5APCIEPHY
from litepcie.phy.s7pciephy     import S7PCIEPHY
from litepcie.phy.uspciephy     import USPCIEPHY
from litepcie.phy.usppciephy    import USPPCIEPHY

from litepcie.core import LitePCIeEndpoint, LitePCIeMSI, LitePCIeMSIMultiVector, LitePCIeMSIX

from litepcie.frontend.dma      import LitePCIeDMA
from litepcie.frontend.wishbone import LitePCIeWishboneMaster, LitePCIeWishboneSlave
from litepcie.frontend.axi      import LitePCIeAXISlave
from litepcie.frontend.ptm      import PCIePTMSniffer
from litepcie.frontend.ptm      import PTMCapabilities, PTMRequester

from litepcie.software import generate_litepcie_software_headers

from litex.build.generic_platform import *


# IOs/Interfaces -----------------------------------------------------------------------------------

def get_clk_ios():
    return [
        # Clk / Rst.
        ("clk", 0, Pins(1)),
        ("rst", 0, Pins(1))
    ]

def get_pcie_ios(phy_lanes=4):
    return [
        ("pcie", 0,
            Subsignal("rst_n", Pins(1)),
            Subsignal("clk_p", Pins(1)),
            Subsignal("clk_n", Pins(1)),
            Subsignal("rx_p",  Pins(phy_lanes)),
            Subsignal("rx_n",  Pins(phy_lanes)),
            Subsignal("tx_p",  Pins(phy_lanes)),
            Subsignal("tx_n",  Pins(phy_lanes)),
        ),
    ]

def get_axi_dma_ios(_id, data_width, with_writer=True, with_reader=True):
    ios = []

    # Enables.
    enables = []
    if with_writer:
        enables += [Subsignal("writer_enable", Pins(1))]
    if with_reader:
        enables += [Subsignal("reader_enable", Pins(1))]
    ios += [("dma{}_status".format(_id), 0, *enables)]

    # DMA Writer AXI.
    if with_writer:
        ios += [
            ("dma{}_writer_axi".format(_id), 0,
                Subsignal("tvalid", Pins(1)),
                Subsignal("tready", Pins(1)),
                Subsignal("tlast",  Pins(1)),
                Subsignal("tdata",  Pins(data_width)),
                Subsignal("tuser",  Pins(1)), # Use for tfirst.
            )
        ]

    # DMA Reader AXI.
    if with_reader:
        ios += [
            ("dma{}_reader_axi".format(_id), 0,
                Subsignal("tvalid", Pins(1)),
                Subsignal("tready", Pins(1)),
                Subsignal("tlast",  Pins(1)),
                Subsignal("tdata",  Pins(data_width)),
                Subsignal("tuser",  Pins(1)), # Use for tfirst.
            )
        ]

    return ios

def get_msi_irqs_ios(width=16):
    return [("msi_irqs", 0, Pins(width))]


def get_ptm_ios(phy_lanes=4):
    return [
        ("ptm", 0,
            Subsignal("time_clk", Pins(1)),
            Subsignal("time_rst", Pins(1)),
            Subsignal("time_ns",  Pins(64)),
        ),
    ]

# CRG ----------------------------------------------------------------------------------------------

class LitePCIeCRG(LiteXModule):
    def __init__(self, platform, sys_clk_freq, clk_external):
        self.cd_sys = ClockDomain()

        # # #

        # Create/Get Clk/Rst IOs.
        platform.add_extension(get_clk_ios())
        clk = platform.request("clk")
        rst = platform.request("rst")

        # Get PCIe Clk/Rst.
        pcie_clk = ClockSignal("pcie")
        pcie_rst = ResetSignal("pcie")

        # External Clk mode: Clk is provided by the User logic.
        if clk_external:
            self.comb += self.cd_sys.clk.eq(clk)
            self.specials += AsyncResetSynchronizer(self.cd_sys, rst | pcie_rst)

        # Internal Clk mode: Clk is provided to the User logic by the LitePCIe standalone core.
        else:
            self.comb += [
                clk.eq(pcie_clk),
                rst.eq(pcie_rst),
                self.cd_sys.clk.eq(pcie_clk),
                self.cd_sys.rst.eq(pcie_rst),
            ]

# Core ---------------------------------------------------------------------------------------------

class LitePCIeCore(SoCMini):
    SoCMini.mem_map["csr"] = 0x00000000
    SoCMini.csr_map = {
        "ctrl"             : 0,
        "crg"              : 1,
        "pcie_phy"         : 2,
        "pcie_msi"         : 3,
        "pcie_msi_table"   : 4,
        "ptm_capabilities" : 5,
        "ptm_requester"    : 6,
    }
    def __init__(self, platform, core_config):
        platform.add_extension(get_pcie_ios(core_config["phy_lanes"]))
        platform.add_extension(get_msi_irqs_ios(width=core_config["msi_irqs"]))
        sys_clk_freq = float(core_config.get("clk_freq", 125e6))

        # Parameters -------------------------------------------------------------------------------

        ep_address_width        = core_config.get("ep_address_width", 32)
        ep_max_pending_requests = core_config.get("ep_max_pending_requests", 4)

        # SoCMini ----------------------------------------------------------------------------------
        SoCMini.__init__(self, platform, clk_freq=sys_clk_freq,
            csr_data_width = 32,
            csr_ordering   = core_config.get("csr_ordering", "big"),
            ident          = "LitePCIe standalone core",
            ident_version  = True
        )

        # CRG --------------------------------------------------------------------------------------
        clk_external = core_config.get("clk_external", False)
        self.crg = LitePCIeCRG(platform, sys_clk_freq, clk_external)

        # Control ----------------------------------------------------------------------------------
        if core_config.get("ctrl", False):
            axi = AXILiteInterface(data_width=32, address_width=32)
            platform.add_extension(axi.get_ios("ctrl_axi_lite"))
            axi_pads = platform.request("ctrl_axi_lite")
            self.comb += axi.connect_to_pads(axi_pads, mode="slave")
            self.bus.add_master(name="ctrl", master=axi)

        # PCIe PHY ---------------------------------------------------------------------------------
        self.pcie_phy = core_config["phy"](platform, platform.request("pcie"),
            pcie_data_width = core_config.get("phy_pcie_data_width", 64),
            data_width      = core_config["phy_data_width"],
            bar0_size       = core_config["phy_bar0_size"])

        # PCIe Endpoint ----------------------------------------------------------------------------
        self.pcie_endpoint = LitePCIeEndpoint(self.pcie_phy,
            endianness           = self.pcie_phy.endianness,
            address_width        = ep_address_width,
            max_pending_requests = ep_max_pending_requests,
            with_ptm             = core_config.get("ptm", False),
        )

        # PCIe Wishbone Master ---------------------------------------------------------------------
        pcie_wishbone_master = LitePCIeWishboneMaster(self.pcie_endpoint,
            qword_aligned = self.pcie_phy.qword_aligned)
        self.submodules += pcie_wishbone_master
        self.bus.add_master(master=pcie_wishbone_master.wishbone)

        # PCIe MMAP Master -------------------------------------------------------------------------
        if core_config.get("mmap", False):
            mmap_base        = core_config["mmap_base"]
            mmap_size        = core_config["mmap_size"]
            mmap_translation = core_config.get("mmap_translation", 0x00000000)
            mmap_region      = SoCRegion(origin=mmap_base, size=mmap_size, cached=False)
            wb = wishbone.Interface(data_width=32)
            self.bus.add_slave(name="mmap", slave=wb, region=mmap_region)
            axi = AXILiteInterface(data_width=32, address_width=32)
            wb2axi = Wishbone2AXILite(wb, axi, base_address=-mmap_translation)
            self.submodules += wb2axi
            platform.add_extension(axi.get_ios("mmap_axi_lite"))
            axi_pads = platform.request("mmap_axi_lite")
            self.comb += axi.connect_to_pads(axi_pads, mode="master")

        # PCIe MMAP Slave --------------------------------------------------------------------------
        if core_config.get("mmap_slave", False):
            # AXI-Full
            if core_config.get("mmap_slave_axi_full", False):
                pcie_axi_slave = LitePCIeAXISlave(self.pcie_endpoint, data_width=128)
                self.submodules += pcie_axi_slave
                platform.add_extension(pcie_axi_slave.axi.get_ios("mmap_slave_axi"))
                axi_pads = platform.request("mmap_slave_axi")
                self.comb += pcie_axi_slave.axi.connect_to_pads(axi_pads, mode="slave")
            # AXI-Lite
            else:
                platform.add_extension(axi.get_ios("mmap_slave_axi_lite"))
                axi_pads = platform.request("mmap_slave_axi_lite")
                wb = wishbone.Interface(data_width=32)
                axi = AXILiteInterface(data_width=32, address_width=32)
                self.comb += axi.connect_to_pads(axi_pads, mode="slave")
                axi2wb = AXILite2Wishbone(axi, wb)
                self.submodules += axi2wb
                pcie_wishbone_slave = LitePCIeWishboneSlave(self.pcie_endpoint,
                    qword_aligned=self.pcie_phy.qword_aligned)
                self.submodules += pcie_wishbone_slave
                self.comb += wb.connect(pcie_wishbone_slave.wishbone)

        # PCIe DMA ---------------------------------------------------------------------------------
        pcie_dmas = []

        # Parameters.
        # -----------

        dmas_params = []

        class DMAParams:
            def __init__(self, writer, reader, buffering, loopback, synchronizer, monitor, data_width):
                self.writer       = writer
                self.reader       = reader
                self.buffering    = buffering
                self.loopback     = loopback
                self.synchronizer = synchronizer
                self.monitor      = monitor
                self.data_width   = data_width

        # DMA Channels configured separately.
        if isinstance(core_config.get("dma_channels"), dict):
            print(core_config.get("dma_channels"))
            for name, params in core_config["dma_channels"].items():
                dma_params = DMAParams(
                    data_width   = params.get("dma_data_width",    core_config["phy_data_width"]),
                    writer       = params.get("dma_writer",        True),
                    reader       = params.get("dma_reader",        True),
                    buffering    = params.get("dma_buffering",     1024),
                    loopback     = params.get("dma_loopback",      True),
                    synchronizer = params.get("dma_synchronizer", False),
                    monitor      = params.get("dma_monitor",      False),
                )
                dmas_params.append(dma_params)

        # DMA Channels configured identically.
        else:
            for n in range(core_config["dma_channels"]):
                dma_params = DMAParams(
                    data_width   = core_config.get("dma_data_width",    core_config["phy_data_width"]),
                    writer       = core_config.get("dma_writer",        True),
                    reader       = core_config.get("dma_reader",        True),
                    buffering    = core_config.get("dma_buffering",     1024),
                    loopback     = core_config.get("dma_loopback",      True),
                    synchronizer = core_config.get("dma_synchronizer", False),
                    monitor      = core_config.get("dma_monitor",      False),
                )
                dmas_params.append(dma_params)

        self.add_constant("DMA_CHANNELS",   len(dmas_params))
        self.add_constant("DMA_ADDR_WIDTH", ep_address_width)

        # PCIe DMAs.
        # ----------
        for i, dma_params in enumerate(dmas_params):
            # DMA.
            # ----
            pcie_dma = LitePCIeDMA(self.pcie_phy, self.pcie_endpoint,
                address_width     = ep_address_width,
                data_width        = dma_params.data_width,
                with_writer       = dma_params.writer,
                with_reader       = dma_params.reader,
                with_buffering    = dma_params.buffering != 0,
                buffering_depth   = dma_params.buffering,
                with_loopback     = dma_params.loopback,
                with_synchronizer = dma_params.synchronizer,
                with_monitor      = dma_params.monitor,
            )
            # DMA Endpoint Buffers (For timings).
            # -------------------------------
            pcie_dma = stream.BufferizeEndpoints({"sink"   : stream.DIR_SINK})(pcie_dma)
            pcie_dma = stream.BufferizeEndpoints({"source" : stream.DIR_SOURCE})(pcie_dma)
            self.add_module(f"pcie_dma{i}", pcie_dma)

            # DMA IOs.
            # --------
            platform.add_extension(get_axi_dma_ios(i,
                data_width  = dma_params.data_width,
                with_writer = dma_params.writer,
                with_reader = dma_params.reader,
            ))
            dma_status_ios = platform.request(f"dma{i}_status")

            # DMA Writer <-> IOs Connection.
            # ------------------------------
            if dma_params.writer:
                dma_writer_ios = platform.request(f"dma{i}_writer_axi")
                self.comb += [
                    # Status IOs.
                    dma_status_ios.writer_enable.eq(pcie_dma.writer.enable),

                    # Writer IOs.
                    pcie_dma.sink.valid.eq(dma_writer_ios.tvalid & pcie_dma.writer.enable),
                    dma_writer_ios.tready.eq(pcie_dma.sink.ready & pcie_dma.writer.enable),
                    pcie_dma.sink.last.eq(dma_writer_ios.tlast),
                    pcie_dma.sink.data.eq(dma_writer_ios.tdata),
                    pcie_dma.sink.first.eq(dma_writer_ios.tuser),
                ]

            # DMA Reader <-> IOs Connection.
            # ------------------------------
            if dma_params.reader:
                dma_reader_ios = platform.request(f"dma{i}_reader_axi")
                self.comb += [
                    # Status IOs.
                    dma_status_ios.reader_enable.eq(pcie_dma.reader.enable),

                    # Reader IOs.
                    dma_reader_ios.tvalid.eq(pcie_dma.source.valid & pcie_dma.reader.enable),
                    pcie_dma.source.ready.eq(dma_reader_ios.tready | ~pcie_dma.reader.enable),
                    dma_reader_ios.tlast.eq(pcie_dma.source.last),
                    dma_reader_ios.tdata.eq(pcie_dma.source.data),
                    dma_reader_ios.tuser.eq(pcie_dma.source.first),
                ]

        # PCIe MSI ---------------------------------------------------------------------------------
        if core_config.get("msi_x", False):
            assert core_config["msi_irqs"] <= 32
            msi_x_default_enable = int(core_config.get("msi_x_default_enable", False))
            self.pcie_msi = LitePCIeMSIX(self.pcie_endpoint, width=64, default_enable=msi_x_default_enable)
            self.comb += self.pcie_msi.irqs[32:32+core_config["msi_irqs"]].eq(platform.request("msi_irqs"))
        else:
            assert core_config["msi_irqs"] <= 16
            if core_config.get("msi_multivector", False):
                self.pcie_msi = LitePCIeMSIMultiVector(width=32)
            else:
                self.pcie_msi = LitePCIeMSI(width=32)
            self.comb += self.pcie_msi.source.connect(self.pcie_phy.msi)
            self.comb += self.pcie_msi.irqs[16:16+core_config["msi_irqs"]].eq(platform.request("msi_irqs"))
        self.interrupts = {}
        for i in range(len(dmas_params)):
            pcie_dma = getattr(self, f"pcie_dma{i}")
            if hasattr(pcie_dma, "writer"):
                self.interrupts[f"pcie_dma{i}_writer"] = pcie_dma.writer.irq
            if hasattr(pcie_dma, "reader"):
                self.interrupts[f"pcie_dma{i}_reader"] = pcie_dma.reader.irq
        for i, (k, v) in enumerate(sorted(self.interrupts.items())):
            self.comb += self.pcie_msi.irqs[i].eq(v)
            self.add_constant(k.upper() + "_INTERRUPT", i)
        assert len(self.interrupts.keys()) <= 16

        # PCIe PTM ---------------------------------------------------------------------------------
        if core_config.get("ptm", False):

            # PCIe PTM Sniffer ---------------------------------------------------------------------

            # Since Xilinx PHY does not allow redirecting PTM TLP Messages to the AXI inferface, we have
            # to sniff the GTPE2 -> PCIE2 RX Data to re-generate PTM TLP Messages.

            # Sniffer Signals.
            # ----------------
            sniffer_rst_n   = Signal()
            sniffer_clk     = Signal()
            sniffer_rx_data = Signal(16)
            sniffer_rx_ctl  = Signal(2)

            # Sniffer Tap.
            # ------------
            rx_data = Signal(16)
            rx_ctl  = Signal(2)
            self.sync.pclk += rx_data.eq(rx_data + 1)
            self.sync.pclk += rx_ctl.eq(rx_ctl + 1)
            self.specials += Instance("sniffer_tap",
                i_rst_n_in    = 1,
                i_clk_in     = ClockSignal("pclk"),
                i_rx_data_in = rx_data, # /!\ Fake, will be re-connected post-synthesis /!\.
                i_rx_ctl_in  = rx_ctl,  # /!\ Fake, will be re-connected post-synthesis /!\.

                o_rst_n_out   = sniffer_rst_n,
                o_clk_out     = sniffer_clk,
                o_rx_data_out = sniffer_rx_data,
                o_rx_ctl_out  = sniffer_rx_ctl,
            )

            # Sniffer.
            # --------
            self.pcie_ptm_sniffer = PCIePTMSniffer(
                rx_rst_n = sniffer_rst_n,
                rx_clk   = sniffer_clk,
                rx_data  = sniffer_rx_data,
                rx_ctrl  = sniffer_rx_ctl,
            )
            self.pcie_ptm_sniffer.add_sources(platform)

            # Sniffer Post-Synthesis connections.
            # -----------------------------------
            pcie_ptm_sniffer_connections = []
            for n in range(2):
                pcie_ptm_sniffer_connections.append((
                    f"pcie_s7/inst/inst/gt_top_i/gt_rx_data_k_wire_filter[{n}]", # Src.
                    f"pcie_ptm_sniffer_tap/rx_ctl_in[{n}]",                      # Dst.
                ))
            for n in range(16):
                pcie_ptm_sniffer_connections.append((
                    f"pcie_s7/inst/inst/gt_top_i/gt_rx_data_wire_filter[{n}]", # Src.
                    f"pcie_ptm_sniffer_tap/rx_data_in[{n}]",                   # Dst.
                ))
            for _from, _to in pcie_ptm_sniffer_connections:
                platform.toolchain.pre_optimize_commands.append(f"set pin_driver [get_nets -of [get_pins {_to}]]")
                platform.toolchain.pre_optimize_commands.append(f"disconnect_net -net $pin_driver -objects {_to}")
                platform.toolchain.pre_optimize_commands.append(f"connect_net -hier -net {_from} -objects {_to}")

            # PTM IOs ------------------------------------------------------------------------------
            platform.add_extension(get_ptm_ios())
            ptm_ios = platform.request("ptm")

            # PTM Capabilities ---------------------------------------------------------------------
            self.ptm_capabilities = PTMCapabilities(
                pcie_endpoint     = self.pcie_endpoint,
                requester_capable = True,
            )

            # PTM Requester ------------------------------------------------------------------------
            self.ptm_requester = PTMRequester(
                pcie_endpoint    = self.pcie_endpoint,
                pcie_ptm_sniffer = self.pcie_ptm_sniffer,
                sys_clk_freq     = sys_clk_freq,
            )
            self.comb += [
                self.ptm_requester.time_clk.eq(ptm_ios.time_clk),
                self.ptm_requester.time_rst.eq(ptm_ios.time_rst),
                self.ptm_requester.time.eq(ptm_ios.time_ns)
            ]

    def generate_documentation(self, build_name, **kwargs):
        from litex.soc.doc import generate_docs
        generate_docs(self, "documentation".format(build_name),
            project_name = "LitePCIe standalone core",
            author       = "Enjoy-Digital")
        os.system("sphinx-build -M html documentation/ documentation/_build".format(build_name, build_name))

# Build --------------------------------------------------------------------------------------------

def main():
    parser = argparse.ArgumentParser(description="LitePCIe standalone core generator")
    parser.add_argument("config", help="YAML config file")
    parser.add_argument("--doc",  action="store_true", help="Build documentation")
    args = parser.parse_args()
    core_config = yaml.load(open(args.config).read(), Loader=yaml.Loader)

    # Convert YAML elements to Python/LiteX --------------------------------------------------------
    for k, v in core_config.items():
        replaces = {"False": False, "True": True, "None": None}
        for r in replaces.keys():
            if v == r:
                core_config[k] = replaces[r]

    # Generate core --------------------------------------------------------------------------------
    if core_config["phy"]  == "C5PCIEPHY":
        from litex.build.altera import AlteraPlatform
        platform = AlteraPlatform("", io=[])
        core_config["phy"] = C5PCIEPHY
    elif core_config["phy"] == "LFCPNXPCIEPHY":
        from litex.build.lattice import LatticePlatform
        platform = LatticePlatform(core_config["phy_device"], io=[], toolchain="radiant")
        core_config["phy"] = LFCPNXPCIEPHY
    elif core_config["phy"] == "GW5APCIEPHY":
        from litex.build.gowin import GowinPlatform
        platform = GowinPlatform(core_config["phy_device"], io=[], toolchain="gowin")
        core_config["phy"] = GW5APCIEPHY
    elif core_config["phy"] == "S7PCIEPHY":
        from litex.build.xilinx import XilinxPlatform
        platform = XilinxPlatform(core_config["phy_device"], io=[], toolchain="vivado")
        core_config["phy"] = S7PCIEPHY
    elif core_config["phy"] == "USPCIEPHY":
        from litex.build.xilinx import XilinxPlatform
        platform = XilinxPlatform(core_config["phy_device"], io=[], toolchain="vivado")
        core_config["phy"] = USPCIEPHY
    elif core_config["phy"] == "USPPCIEPHY":
        from litex.build.xilinx import XilinxPlatform
        platform = XilinxPlatform(core_config["phy_device"], io=[], toolchain="vivado")
        core_config["phy"] = USPPCIEPHY
    else:
        raise ValueError("Unsupported PCIe PHY: {}".format(core_config["phy"]))
    soc      = LitePCIeCore(platform, core_config)
    builder  = Builder(soc, output_dir="build", compile_gateware=False)
    builder.build(build_name="litepcie_core", regular_comb=True)
    generate_litepcie_software_headers(soc, "./")

    if args.doc:
        soc.generate_documentation("litepcie_core")

if __name__ == "__main__":
    main()

```

`litepcie/phy/axis_adapters.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2020-2026 Enjoy-Digital <enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

from migen import *

from litex.gen import *

# Xilinx AXIS adaptation is implemented in LiteX/Migen (Python) to avoid
# duplicated legacy Verilog per-family/per-width variants.


def _pack_keep_cc(tkeep, data_width):
    # CC keep packing follows the legacy wrapper behavior:
    # - 128/256b: one output bit per 4-bit nibble, set when nibble is non-zero.
    # - 512b: one output bit per nibble, copied from nibble bit0.
    if data_width == 128:
        return Cat(*[(tkeep[4*i:4*(i + 1)] != 0) for i in range(4)])
    if data_width == 256:
        return Cat(*[(tkeep[4*i:4*(i + 1)] != 0) for i in range(8)])
    return Cat(*[tkeep[4*i] for i in range(16)])


def _pack_keep_rq(tkeep, data_width):
    # RQ keep packing follows the legacy wrapper behavior:
    # - 128b: one output bit per 4-bit nibble, set when nibble is non-zero.
    # - 256/512b: one output bit per nibble, copied from nibble bit0.
    if data_width == 128:
        return Cat(*[(tkeep[4*i:4*(i + 1)] != 0) for i in range(4)])
    return Cat(*[tkeep[4*i] for i in range(data_width // 32)])


def _rq_upper_user(discontinue):
    return Cat(
        C(0, 3),
        discontinue,
        C(0, 1),
        C(0, 2),
        C(0, 8),
        C(0, 1),
        C(0, 4),
        C(0, 32),
    )


class MAxisRCAdapter(LiteXModule):
    """Adapt Xilinx RC AXIS (hard IP format) to LitePCIe RC stream format."""
    def __init__(self, data_width):
        assert data_width in [128, 256, 512]
        keep_width = data_width // 8

        # Raw RC AXIS from Xilinx hard IP.
        self.s_axis_tdata  = Signal(data_width)
        self.s_axis_tkeep  = Signal(keep_width // 4)
        self.s_axis_tlast  = Signal()
        self.s_axis_tready = Signal(4)
        self.s_axis_tuser  = Signal(85)
        self.s_axis_tvalid = Signal()

        # Adapted RC AXIS to LitePCIe PHY datapath.
        self.m_axis_tdata  = Signal(data_width)
        self.m_axis_tkeep  = Signal(keep_width)
        self.m_axis_tlast  = Signal()
        self.m_axis_tready = Signal()
        self.m_axis_tuser  = Signal(85)
        self.m_axis_tvalid = Signal()
        self.m_axis_sop    = Signal()

        # -----------------------------------------------------------------------------------------

        rc_cnt = Signal(2)
        self.sync += [
            If(self.s_axis_tvalid & self.s_axis_tready[0],
                If(self.s_axis_tlast,
                    rc_cnt.eq(0)
                ).Elif(~rc_cnt[1],
                    rc_cnt.eq(rc_cnt + 1)
                )
            )
        ]
        self.comb += self.m_axis_sop.eq(rc_cnt == 0)

        poisoning   = Signal()
        poisoning_l = Signal()
        self.comb += poisoning.eq(self.s_axis_tdata[46])
        self.sync += [
            If(self.s_axis_tvalid & self.m_axis_sop,
                poisoning_l.eq(poisoning)
            )
        ]

        dwlen       = Signal(10)
        attr        = Signal(2)
        tc          = Signal(3)
        bytecnt     = Signal(12)
        cmpstatus   = Signal(3)
        completerid = Signal(16)
        lowaddr     = Signal(7)
        tag         = Signal(8)
        requesterid = Signal(16)
        fmt         = Signal(3)
        typ         = Signal(5)

        self.comb += [
            dwlen.eq(self.s_axis_tdata[32:42]),
            attr.eq(self.s_axis_tdata[92:94]),
            tc.eq(self.s_axis_tdata[89:92]),
            bytecnt.eq(self.s_axis_tdata[16:28]),
            cmpstatus.eq(self.s_axis_tdata[43:46]),
            completerid.eq(self.s_axis_tdata[72:88]),
            lowaddr.eq(self.s_axis_tdata[0:7]),
            tag.eq(self.s_axis_tdata[64:72]),
            requesterid.eq(self.s_axis_tdata[48:64]),
            If(self.s_axis_tdata[29],
                If(bytecnt == 0,
                    fmt.eq(0b000),
                    typ.eq(0b01011)
                ).Else(
                    fmt.eq(0b010),
                    typ.eq(0b01011)
                )
            ).Else(
                If(bytecnt == 0,
                    fmt.eq(0b000),
                    typ.eq(0b01010)
                ).Else(
                    fmt.eq(0b010),
                    typ.eq(0b01010)
                )
            )
        ]

        header0 = Signal(64)
        header1 = Signal(64)
        self.comb += [
            header0.eq(Cat(
                dwlen,
                C(0, 2),
                attr,
                C(0, 1),  # ep
                C(0, 1),  # td
                C(0, 4),
                tc,
                C(0, 1),
                typ,
                fmt,
                bytecnt,
                C(0, 1),  # bmc
                cmpstatus,
                completerid
            )),
            header1.eq(Cat(
                lowaddr,
                C(0, 1),
                tag,
                requesterid,
                self.s_axis_tdata[96:128]
            ))
        ]

        poisoning_out = Signal()
        self.comb += poisoning_out.eq(Mux(self.m_axis_sop, poisoning, poisoning_l))

        self.comb += [
            self.m_axis_tvalid.eq(self.s_axis_tvalid),
            self.m_axis_tlast.eq(self.s_axis_tlast),
            self.s_axis_tready.eq(Replicate(self.m_axis_tready, 4)),
        ]

        if data_width == 128:
            self.comb += [
                If(self.m_axis_sop,
                    self.m_axis_tdata.eq(Cat(header0, header1))
                ).Else(
                    self.m_axis_tdata.eq(self.s_axis_tdata)
                ),
                If(self.m_axis_sop,
                    self.m_axis_tkeep.eq(Replicate(C(1, 1), keep_width))
                ).Else(
                    self.m_axis_tkeep.eq(self.s_axis_tuser[:keep_width])
                ),
                self.m_axis_tuser.eq(Cat(
                    self.s_axis_tuser[42],
                    poisoning_out,
                    C(0, 8),
                    C(0, 4),
                    self.m_axis_sop,
                    C(0, 2),
                    C(0, 5),
                    C(0, 63)
                ))
            ]
        else:
            self.comb += [
                If(self.m_axis_sop,
                    self.m_axis_tdata.eq(Cat(header0, header1, self.s_axis_tdata[128:data_width]))
                ).Else(
                    self.m_axis_tdata.eq(self.s_axis_tdata)
                ),
                If(self.m_axis_sop,
                    self.m_axis_tkeep.eq(Cat(C(0xFFF, 12), self.s_axis_tuser[12:keep_width]))
                ).Else(
                    self.m_axis_tkeep.eq(self.s_axis_tuser[:keep_width])
                ),
                self.m_axis_tuser.eq(Cat(
                    self.s_axis_tuser[42],
                    poisoning_out,
                    C(0, 8),
                    C(0, 5),
                    C(0, 2),
                    C(0, 5),
                    C(0, 63)
                ))
            ]


class MAxisCQAdapter(LiteXModule):
    """Adapt Xilinx CQ AXIS (hard IP format) to LitePCIe CQ stream format."""
    def __init__(self, data_width):
        assert data_width in [128, 256, 512]
        keep_width = data_width // 8

        # Raw CQ AXIS from Xilinx hard IP.
        self.s_axis_tdata  = Signal(data_width)
        self.s_axis_tkeep  = Signal(keep_width // 4)
        self.s_axis_tlast  = Signal()
        self.s_axis_tready = Signal(4)
        self.s_axis_tuser  = Signal(256)
        self.s_axis_tvalid = Signal()

        # Adapted CQ AXIS to LitePCIe PHY datapath.
        self.m_axis_tdata  = Signal(data_width)
        self.m_axis_tkeep  = Signal(keep_width)
        self.m_axis_tlast  = Signal()
        self.m_axis_tready = Signal()
        self.m_axis_tuser  = Signal(85)
        self.m_axis_tvalid = Signal()
        self.m_axis_sop    = Signal()

        # -----------------------------------------------------------------------------------------

        tdata_hdr = Signal(64)
        self.comb += tdata_hdr.eq(self.s_axis_tdata[64:128])

        dwlen       = Signal(10)
        attr        = Signal(2)
        tc          = Signal(3)
        tag         = Signal(8)
        requesterid = Signal(16)
        reqtype     = Signal(4)
        fmt         = Signal(3)
        typ         = Signal(5)
        read_req    = Signal()

        self.comb += [
            dwlen.eq(tdata_hdr[0:10]),
            attr.eq(tdata_hdr[60:62]),
            tc.eq(tdata_hdr[57:60]),
            tag.eq(tdata_hdr[32:40]),
            requesterid.eq(tdata_hdr[16:32]),
            reqtype.eq(tdata_hdr[11:15]),
            Case(reqtype, {
                0b0000: [fmt.eq(0b000), typ.eq(0b00000)],
                0b0111: [fmt.eq(0b000), typ.eq(0b00001)],
                0b0001: [fmt.eq(0b010), typ.eq(0b00000)],
                0b0010: [fmt.eq(0b000), typ.eq(0b00010)],
                0b0011: [fmt.eq(0b010), typ.eq(0b00010)],
                0b1000: [fmt.eq(0b000), typ.eq(0b00100)],
                0b1010: [fmt.eq(0b010), typ.eq(0b00100)],
                0b1001: [fmt.eq(0b000), typ.eq(0b00101)],
                0b1011: [fmt.eq(0b010), typ.eq(0b00101)],
                "default": [fmt.eq(0), typ.eq(0)],
            }),
            read_req.eq(fmt[:2] == 0),
        ]

        cnt       = Signal(2)
        tlast_lat = Signal()
        self.sync += [
            If(self.s_axis_tvalid & self.s_axis_tready[0],
                If(self.s_axis_tlast,
                    cnt.eq(0)
                ).Elif(~cnt[1],
                    cnt.eq(cnt + 1)
                )
            )
        ]

        sop    = Signal()
        second = Signal()
        self.comb += [
            sop.eq((cnt == 0) & ~tlast_lat),
            second.eq(cnt == 1),
            self.m_axis_sop.eq(sop),
        ]

        tuser_barhit = Signal(8)
        self.sync += [
            If(self.s_axis_tvalid & sop,
                tuser_barhit.eq(Cat(tdata_hdr[11:15], tdata_hdr[48:51], C(0, 1)))
            )
        ]

        header = Signal(64)
        self.sync += [
            If(self.s_axis_tvalid & sop,
                header.eq(Cat(
                    dwlen,
                    C(0, 2),
                    attr,
                    C(0, 1),  # ep
                    C(0, 1),  # td
                    C(0, 4),
                    tc,
                    C(0, 1),
                    typ,
                    fmt,
                    self.s_axis_tuser[0:8],  # be (128/256), overwritten in 512 branch.
                    tag,
                    requesterid
                ))
            )
        ]

        ready_a = Signal()
        self.comb += ready_a.eq(((cnt == 0) | self.m_axis_tready) & ~tlast_lat)
        self.comb += self.s_axis_tready.eq(Replicate(ready_a, 4))

        if data_width == 128:
            read_l        = Signal()
            tlast_dly_en  = Signal()
            tdata_a1      = Signal(128)
            tlast_be1     = Signal(16)
            ecrc          = Signal()
            hiaddr_mask   = Signal(32)

            self.comb += hiaddr_mask.eq(Mux(read_l, 0, self.s_axis_tdata[0:32]))

            self.sync += [
                If(self.s_axis_tvalid & sop,
                    read_l.eq(read_req)
                ),
                If(self.s_axis_tvalid & self.s_axis_tready[0],
                    tdata_a1.eq(self.s_axis_tdata),
                    tlast_be1.eq(self.s_axis_tuser[8:24])
                ),
                ecrc.eq(self.s_axis_tuser[41]),
                If(self.s_axis_tvalid & sop,
                    header.eq(Cat(
                        dwlen,
                        C(0, 2),
                        attr,
                        C(0, 1),
                        C(0, 1),
                        C(0, 4),
                        tc,
                        C(0, 1),
                        typ,
                        fmt,
                        self.s_axis_tuser[0:8],
                        tag,
                        requesterid
                    ))
                )
            ]

            self.sync += [
                If(tlast_lat & self.m_axis_tready,
                    tlast_dly_en.eq(0)
                ).Elif(self.s_axis_tvalid & sop,
                    If(read_req,
                        tlast_dly_en.eq(1)
                    ).Else(
                        tlast_dly_en.eq(dwlen[:2] != 1)
                    )
                )
            ]

            self.sync += [
                If(tlast_lat & self.m_axis_tready,
                    tlast_lat.eq(0)
                ).Elif(self.s_axis_tvalid & self.s_axis_tready[0] & self.s_axis_tlast,
                    If(sop | tlast_dly_en,
                        tlast_lat.eq(1)
                    )
                )
            ]

            self.comb += [
                self.m_axis_tlast.eq(Mux(tlast_dly_en, tlast_lat, self.s_axis_tlast)),
                self.m_axis_tvalid.eq((self.s_axis_tvalid & (cnt != 0)) | tlast_lat),
                If(read_l | second,
                    self.m_axis_tdata.eq(Cat(header, tdata_a1[0:32], hiaddr_mask))
                ).Else(
                    self.m_axis_tdata.eq(Cat(tdata_a1[32:128], self.s_axis_tdata[0:32]))
                ),
                If(read_l,
                    self.m_axis_tkeep.eq(C(0x0FFF, keep_width))
                ).Elif(tlast_lat,
                    self.m_axis_tkeep.eq(Cat(tlast_be1[4:16], C(0, 4)))
                ).Else(
                    self.m_axis_tkeep.eq(C((1 << keep_width) - 1, keep_width))
                ),
                self.m_axis_tuser.eq(Cat(
                    ecrc,
                    C(0, 1),
                    tuser_barhit,
                    C(0, 5),
                    C(0, 2),
                    C(0, 5),
                    C(0, 63)
                ))
            ]
        elif data_width == 256:
            rdwr_l       = Signal()
            tlast_dly_en = Signal()
            tdata_a1     = Signal(256)
            tlast_be1    = Signal(32)

            self.sync += [
                If(self.s_axis_tvalid & sop,
                    rdwr_l.eq(self.s_axis_tlast)
                ),
                If(self.s_axis_tvalid & self.s_axis_tready[0],
                    tdata_a1.eq(self.s_axis_tdata),
                    tlast_be1.eq(self.s_axis_tuser[8:40])
                ),
                If(self.s_axis_tvalid & sop,
                    header.eq(Cat(
                        dwlen,
                        C(0, 2),
                        attr,
                        C(0, 1),
                        C(0, 1),
                        C(0, 4),
                        tc,
                        C(0, 1),
                        typ,
                        fmt,
                        self.s_axis_tuser[0:8],
                        tag,
                        requesterid
                    ))
                )
            ]

            self.sync += [
                If(tlast_lat & self.m_axis_tready,
                    tlast_dly_en.eq(0)
                ).Elif(self.s_axis_tvalid & sop,
                    tlast_dly_en.eq(self.s_axis_tlast | (dwlen[:3] != 5))
                )
            ]

            self.sync += [
                If(tlast_lat & self.m_axis_tready,
                    tlast_lat.eq(0)
                ).Elif(self.s_axis_tvalid & self.s_axis_tready[0] & self.s_axis_tlast,
                    If(sop | tlast_dly_en,
                        tlast_lat.eq(1)
                    )
                )
            ]

            self.comb += [
                self.m_axis_tlast.eq(Mux(tlast_dly_en, tlast_lat, self.s_axis_tlast)),
                self.m_axis_tvalid.eq((self.s_axis_tvalid & (cnt != 0)) | tlast_lat),
                If(rdwr_l | second,
                    self.m_axis_tdata.eq(Cat(header, tdata_a1[0:32], tdata_a1[128:256], self.s_axis_tdata[0:32]))
                ).Else(
                    self.m_axis_tdata.eq(Cat(tdata_a1[32:256], self.s_axis_tdata[0:32]))
                ),
                If(rdwr_l,
                    self.m_axis_tkeep.eq(Cat(C(0xFFF, 12), tlast_be1[16:32], C(0, 4)))
                ).Elif(tlast_lat,
                    self.m_axis_tkeep.eq(Cat(tlast_be1[4:32], C(0, 4)))
                ).Else(
                    self.m_axis_tkeep.eq(C((1 << keep_width) - 1, keep_width))
                ),
                self.m_axis_tuser.eq(Cat(
                    self.s_axis_tuser[41],
                    C(0, 1),
                    tuser_barhit,
                    C(0, 5),
                    C(0, 2),
                    C(0, 5),
                    C(0, 63)
                ))
            ]
        else:
            rdwr_l       = Signal()
            tlast_dly_en = Signal()
            tdata_a1     = Signal(512)
            tlast_be1    = Signal(64)
            be_512       = Signal(8)

            self.comb += be_512.eq(Cat(self.s_axis_tuser[0:4], self.s_axis_tuser[8:12]))

            self.sync += [
                If(self.s_axis_tvalid & sop,
                    rdwr_l.eq(self.s_axis_tlast)
                ),
                If(self.s_axis_tvalid & self.s_axis_tready[0],
                    tdata_a1.eq(self.s_axis_tdata),
                    tlast_be1.eq(self.s_axis_tuser[16:80])
                ),
                If(self.s_axis_tvalid & sop,
                    header.eq(Cat(
                        dwlen,
                        C(0, 2),
                        attr,
                        C(0, 1),
                        C(0, 1),
                        C(0, 4),
                        tc,
                        C(0, 1),
                        typ,
                        fmt,
                        be_512,
                        tag,
                        requesterid
                    ))
                )
            ]

            self.sync += [
                If(tlast_lat & self.m_axis_tready,
                    tlast_dly_en.eq(0)
                ).Elif(self.s_axis_tvalid & sop,
                    tlast_dly_en.eq(self.s_axis_tlast | (dwlen[:4] != 13))
                )
            ]

            self.sync += [
                If(tlast_lat & self.m_axis_tready,
                    tlast_lat.eq(0)
                ).Elif(self.s_axis_tvalid & self.s_axis_tready[0] & self.s_axis_tlast,
                    If(sop | tlast_dly_en,
                        tlast_lat.eq(1)
                    )
                )
            ]

            self.comb += [
                self.m_axis_tlast.eq(Mux(tlast_dly_en, tlast_lat, self.s_axis_tlast)),
                self.m_axis_tvalid.eq((self.s_axis_tvalid & (cnt != 0)) | tlast_lat),
                If(rdwr_l | second,
                    self.m_axis_tdata.eq(Cat(header, tdata_a1[0:32], tdata_a1[128:512], self.s_axis_tdata[0:32]))
                ).Else(
                    self.m_axis_tdata.eq(Cat(tdata_a1[32:512], self.s_axis_tdata[0:32]))
                ),
                If(rdwr_l,
                    self.m_axis_tkeep.eq(Cat(C(0xFFF, 12), tlast_be1[16:64], C(0, 4)))
                ).Elif(tlast_lat,
                    self.m_axis_tkeep.eq(Cat(tlast_be1[4:64], C(0, 4)))
                ).Else(
                    self.m_axis_tkeep.eq(C((1 << keep_width) - 1, keep_width))
                ),
                self.m_axis_tuser.eq(Cat(
                    self.s_axis_tuser[96],
                    C(0, 1),
                    tuser_barhit,
                    C(0, 5),
                    C(0, 2),
                    C(0, 5),
                    C(0, 63)
                ))
            ]


class SAxisCCAdapter(LiteXModule):
    """Adapt LitePCIe CC stream format to Xilinx CC AXIS (hard IP format)."""
    def __init__(self, data_width):
        assert data_width in [128, 256, 512]
        keep_width = data_width // 8

        # LitePCIe CC AXIS (input).
        self.s_axis_tdata  = Signal(data_width)
        self.s_axis_tkeep  = Signal(keep_width)
        self.s_axis_tlast  = Signal()
        self.s_axis_tready = Signal()
        self.s_axis_tuser  = Signal(4)
        self.s_axis_tvalid = Signal()

        # Raw CC AXIS to Xilinx hard IP (output).
        self.m_axis_tdata  = Signal(data_width)
        self.m_axis_tkeep  = Signal(keep_width // 4)
        self.m_axis_tlast  = Signal()
        self.m_axis_tready = Signal()
        self.m_axis_tuser  = Signal(33)
        self.m_axis_tvalid = Signal()

        # -----------------------------------------------------------------------------------------

        cnt = Signal(2)
        self.sync += [
            If(self.s_axis_tvalid & self.m_axis_tready,
                If(self.s_axis_tlast,
                    cnt.eq(0)
                ).Elif(~cnt[1],
                    cnt.eq(cnt + 1)
                )
            )
        ]
        tfirst = Signal()
        self.comb += tfirst.eq(cnt == 0)

        tkeep_or = Signal(keep_width // 4)
        self.comb += tkeep_or.eq(_pack_keep_cc(self.s_axis_tkeep, data_width))

        lowaddr     = Signal(7)
        bytecnt     = Signal(13)
        lockedrdcmp = Signal()
        dwordcnt    = Signal(10)
        cmpstatus   = Signal(3)
        poison      = Signal()
        requesterid = Signal(16)
        tag         = Signal(8)
        completerid = Signal(16)
        tc          = Signal(3)
        attr        = Signal(3)
        td          = Signal()
        self.comb += [
            lowaddr.eq(self.s_axis_tdata[64:71]),
            bytecnt.eq(Cat(self.s_axis_tdata[32:44], C(0, 1))),
            lockedrdcmp.eq(self.s_axis_tdata[24:30] == 0b001011),
            dwordcnt.eq(self.s_axis_tdata[0:10]),
            cmpstatus.eq(self.s_axis_tdata[45:48]),
            poison.eq(self.s_axis_tdata[14]),
            requesterid.eq(self.s_axis_tdata[80:96]),
            tag.eq(self.s_axis_tdata[72:80]),
            completerid.eq(self.s_axis_tdata[48:64]),
            tc.eq(self.s_axis_tdata[20:23]),
            attr.eq(Cat(self.s_axis_tdata[12:14], C(0, 1))),
            td.eq(self.s_axis_tdata[15] | self.s_axis_tuser[0]),
        ]

        header0 = Signal(64)
        header1 = Signal(64)
        self.comb += [
            header0.eq(Cat(
                lowaddr,
                C(0, 1),
                C(0, 2),  # at
                C(0, 6),
                bytecnt,
                lockedrdcmp,
                C(0, 2),
                dwordcnt,
                cmpstatus,
                poison,
                C(0, 2),
                requesterid
            )),
            header1.eq(Cat(
                tag,
                completerid,
                C(0, 1),  # completerid_en
                tc,
                attr,
                td,
                self.s_axis_tdata[96:128]
            ))
        ]

        self.comb += [
            self.s_axis_tready.eq(self.m_axis_tready),
            self.m_axis_tvalid.eq(self.s_axis_tvalid),
            self.m_axis_tlast.eq(self.s_axis_tlast),
            self.m_axis_tkeep.eq(tkeep_or),
            self.m_axis_tuser.eq(Cat(self.s_axis_tuser[3])),
        ]
        if data_width == 128:
            self.comb += [
                If(tfirst,
                    self.m_axis_tdata.eq(Cat(header0, header1))
                ).Else(
                    self.m_axis_tdata.eq(self.s_axis_tdata)
                )
            ]
        else:
            self.comb += [
                If(tfirst,
                    self.m_axis_tdata.eq(Cat(header0, header1, self.s_axis_tdata[128:data_width]))
                ).Else(
                    self.m_axis_tdata.eq(self.s_axis_tdata)
                )
            ]


class SAxisRQAdapter(LiteXModule):
    """Adapt LitePCIe RQ stream format to Xilinx RQ AXIS (hard IP format)."""
    def __init__(self, data_width):
        assert data_width in [128, 256, 512]
        keep_width = data_width // 8
        tuser_width = 137 if data_width == 512 else 60

        # LitePCIe RQ AXIS (input).
        self.s_axis_tdata  = Signal(data_width)
        self.s_axis_tkeep  = Signal(keep_width)
        self.s_axis_tlast  = Signal()
        self.s_axis_tready = Signal()
        self.s_axis_tuser  = Signal(4)
        self.s_axis_tvalid = Signal()

        # Raw RQ AXIS to Xilinx hard IP (output).
        self.m_axis_tdata  = Signal(data_width)
        self.m_axis_tkeep  = Signal(keep_width // 4)
        self.m_axis_tlast  = Signal()
        self.m_axis_tready = Signal()
        self.m_axis_tuser  = Signal(tuser_width)
        self.m_axis_tvalid = Signal()

        # -----------------------------------------------------------------------------------------

        tkeep_or = Signal(keep_width // 4)
        self.comb += tkeep_or.eq(_pack_keep_rq(self.s_axis_tkeep, data_width))

        dwlen = Signal(11)
        reqtype = Signal(4)
        self.comb += [
            dwlen.eq(Cat(self.s_axis_tdata[0:10], C(0, 1))),
            If(Cat(self.s_axis_tdata[24:29], self.s_axis_tdata[30:32]) == 0b0000000,
                reqtype.eq(0b0000)
            ).Elif(Cat(self.s_axis_tdata[24:29], self.s_axis_tdata[30:32]) == 0b0000001,
                reqtype.eq(0b0111)
            ).Elif(Cat(self.s_axis_tdata[24:29], self.s_axis_tdata[30:32]) == 0b0100000,
                reqtype.eq(0b0001)
            ).Elif(self.s_axis_tdata[24:32] == 0b00000010,
                reqtype.eq(0b0010)
            ).Elif(self.s_axis_tdata[24:32] == 0b01000010,
                reqtype.eq(0b0011)
            ).Elif(self.s_axis_tdata[24:32] == 0b00000100,
                reqtype.eq(0b1000)
            ).Elif(self.s_axis_tdata[24:32] == 0b01000100,
                reqtype.eq(0b1010)
            ).Elif(self.s_axis_tdata[24:32] == 0b00000101,
                reqtype.eq(0b1001)
            ).Elif(self.s_axis_tdata[24:32] == 0b01000101,
                reqtype.eq(0b1011)
            ).Else(
                reqtype.eq(0b1111)
            )
        ]

        poisoning    = Signal()
        requesterid  = Signal(16)
        tag          = Signal(8)
        tc           = Signal(3)
        attr         = Signal(3)
        ecrc         = Signal()
        tdata_header = Signal(64)
        self.comb += [
            poisoning.eq(self.s_axis_tdata[14] | self.s_axis_tuser[1]),
            requesterid.eq(self.s_axis_tdata[48:64]),
            tag.eq(self.s_axis_tdata[40:48]),
            tc.eq(self.s_axis_tdata[20:23]),
            attr.eq(Cat(self.s_axis_tdata[12:14], C(0, 1))),
            ecrc.eq(self.s_axis_tdata[15] | self.s_axis_tuser[0]),
            tdata_header.eq(Cat(
                dwlen,
                reqtype,
                poisoning,
                requesterid,
                tag,
                C(0, 16),  # completerid
                C(0, 1),   # requester_en
                tc,
                attr,
                ecrc
            ))
        ]

        firstbe = Signal(4)
        lastbe  = Signal(4)
        self.comb += [
            firstbe.eq(self.s_axis_tdata[32:36]),
            lastbe.eq(self.s_axis_tdata[36:40]),
        ]

        if data_width == 128:
            cnt          = Signal(2)
            tlast_dly_en = Signal()
            tlast_lat    = Signal()
            firstbe_l    = Signal(4)
            lastbe_l     = Signal(4)
            tdata_l      = Signal(32)

            tfirst = Signal()
            read   = Signal()
            write  = Signal()
            self.comb += [
                tfirst.eq((cnt == 0) & ~tlast_lat),
                read.eq(self.s_axis_tdata[30:32] == 0),
                write.eq(~read),
            ]

            ready_ff = Signal()
            self.comb += [
                ready_ff.eq(self.m_axis_tready & ~tlast_lat),
                self.s_axis_tready.eq(ready_ff),
            ]

            self.sync += [
                If(self.s_axis_tvalid & ready_ff,
                    If(self.s_axis_tlast,
                        cnt.eq(0)
                    ).Elif(~cnt[1],
                        cnt.eq(cnt + 1)
                    )
                ),
                If(self.s_axis_tvalid & tfirst & ready_ff & write,
                    tlast_dly_en.eq(self.s_axis_tdata[0:2] == 1)
                ),
                If(tlast_lat & self.m_axis_tready,
                    tlast_lat.eq(0)
                ).Elif(self.s_axis_tvalid & self.s_axis_tlast & self.m_axis_tready,
                    If(tfirst,
                        tlast_lat.eq(write)
                    ).Else(
                        tlast_lat.eq(tlast_dly_en)
                    )
                ),
                If(self.s_axis_tvalid & tfirst,
                    firstbe_l.eq(firstbe),
                    lastbe_l.eq(lastbe)
                ),
                If(self.s_axis_tvalid & ready_ff,
                    tdata_l.eq(self.s_axis_tdata[96:128])
                )
            ]

            upper_user = Signal(52)
            self.comb += upper_user.eq(_rq_upper_user(self.s_axis_tuser[3]))
            self.comb += [
                self.m_axis_tlast.eq(Mux(tfirst, read, Mux(tlast_dly_en, tlast_lat, self.s_axis_tlast))),
                self.m_axis_tvalid.eq(self.s_axis_tvalid | tlast_lat),
                self.m_axis_tdata.eq(Mux(tfirst,
                    Cat(self.s_axis_tdata[64:96], C(0, 32), tdata_header),
                    Cat(tdata_l, self.s_axis_tdata[0:96]))),
                self.m_axis_tkeep.eq(Mux(tlast_lat, C(0b0001, 4), C(0b1111, 4))),
                self.m_axis_tuser.eq(Cat(
                    Mux(tfirst, Cat(firstbe, lastbe), Cat(firstbe_l, lastbe_l)),
                    upper_user
                )),
            ]
        elif data_width == 256:
            tfirst_ff = Signal(reset=1)
            firstbe_l = Signal(4)
            lastbe_l  = Signal(4)

            self.comb += self.s_axis_tready.eq(self.m_axis_tready)
            self.sync += [
                If(self.s_axis_tvalid & self.m_axis_tready,
                    tfirst_ff.eq(0),
                    If(self.s_axis_tlast,
                        tfirst_ff.eq(1)
                    )
                ),
                If(self.s_axis_tvalid & tfirst_ff,
                    firstbe_l.eq(firstbe),
                    lastbe_l.eq(lastbe)
                )
            ]

            upper_user = Signal(52)
            self.comb += upper_user.eq(_rq_upper_user(self.s_axis_tuser[3]))
            self.comb += [
                self.m_axis_tlast.eq(self.s_axis_tlast),
                self.m_axis_tvalid.eq(self.s_axis_tvalid),
                self.m_axis_tdata.eq(Mux(tfirst_ff,
                    Cat(self.s_axis_tdata[96:128], self.s_axis_tdata[64:96], tdata_header, self.s_axis_tdata[128:256]),
                    self.s_axis_tdata)),
                self.m_axis_tkeep.eq(tkeep_or),
                self.m_axis_tuser.eq(Cat(
                    Mux(tfirst_ff, Cat(firstbe, lastbe), Cat(firstbe_l, lastbe_l)),
                    upper_user
                )),
            ]
        else:
            cnt          = Signal(2)
            tlast_dly_en = Signal()
            tlast_lat    = Signal()
            firstbe_l    = Signal(4)
            lastbe_l     = Signal(4)
            tdata_l      = Signal(32)

            tfirst = Signal()
            read   = Signal()
            write  = Signal()
            self.comb += [
                tfirst.eq((cnt == 0) & ~tlast_lat),
                read.eq(self.s_axis_tdata[30:32] == 0),
                write.eq(~read),
            ]

            ready_ff = Signal()
            self.comb += [
                ready_ff.eq(self.m_axis_tready & ~tlast_lat),
                self.s_axis_tready.eq(ready_ff),
            ]

            self.sync += [
                If(self.s_axis_tvalid & ready_ff,
                    If(self.s_axis_tlast,
                        cnt.eq(0)
                    ).Elif(~cnt[1],
                        cnt.eq(cnt + 1)
                    )
                ),
                If(self.s_axis_tvalid & tfirst & write,
                    tlast_dly_en.eq(self.s_axis_tdata[0:4] == 13)
                ),
                If(tlast_lat & self.m_axis_tready,
                    tlast_lat.eq(0)
                ).Elif(self.s_axis_tvalid & self.s_axis_tlast & self.m_axis_tready,
                    If(tfirst,
                        If(write,
                            tlast_lat.eq(dwlen == 13)
                        ).Else(
                            tlast_lat.eq(0)
                        )
                    ).Else(
                        tlast_lat.eq(tlast_dly_en)
                    )
                ),
                If(self.s_axis_tvalid & tfirst,
                    firstbe_l.eq(firstbe),
                    lastbe_l.eq(lastbe)
                ),
                If(self.s_axis_tvalid & ready_ff,
                    tdata_l.eq(self.s_axis_tdata[480:512])
                )
            ]

            self.comb += [
                self.m_axis_tlast.eq(Mux(tfirst,
                    read | (dwlen < 13),
                    Mux(tlast_dly_en, tlast_lat, self.s_axis_tlast))),
                self.m_axis_tvalid.eq(self.s_axis_tvalid | tlast_lat),
                self.m_axis_tdata.eq(Mux(tfirst,
                    Cat(self.s_axis_tdata[64:96], C(0, 32), tdata_header, self.s_axis_tdata[96:480]),
                    Cat(tdata_l, self.s_axis_tdata[0:480]))),
                self.m_axis_tkeep.eq(Mux(tlast_lat,
                    C(0x0001, 16),
                    Cat(C(1, 1), tkeep_or[0:15]))),
                self.m_axis_tuser.eq(Cat(
                    firstbe,
                    C(0, 4),
                    lastbe,
                    C(0, 4),
                    C(0, 20),
                    self.s_axis_tuser[3],
                    C(0, 100)
                )),
            ]

```

`litepcie/phy/c5pciephy.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2019 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

import os

from migen import *
from migen.genlib.cdc import MultiReg

from litex.gen import *

from litex.soc.interconnect.csr import *
from litex.soc.interconnect.avalon import *

from litepcie.common import *

# --------------------------------------------------------------------------------------------------

class C5PCIEPHY(LiteXModule):
    endianness    = "little"
    qword_aligned = True
    def __init__(self, platform, pads, data_width=64, cd="sys",
        # PCIe hardblock parameters.
        bar0_size = 0x100000,
    ):
        # Streams ---------------------------------------------------------------------------------
        self.sink   = stream.Endpoint(phy_layout(data_width))
        self.source = stream.Endpoint(phy_layout(data_width))
        self.msi    = stream.Endpoint(msi_layout())

        # Parameters/Locals ------------------------------------------------------------------------
        self.pads             = pads
        self.platform         = platform
        self.data_width       = data_width

        self.id               = Signal(16, reset_less=True)
        self.bar0_size        = bar0_size
        self.bar0_mask        = get_bar_mask(bar0_size)
        self.max_request_size = Signal(16, reset_less=True)
        self.max_payload_size = Signal(16, reset_less=True)

        self.external_hard_ip = False

        # # #

        pcie_clk                       = Signal()
        pcie_rst_n                     = Signal(reset=1)
        pcie_reconfig_clk              = Signal()
        pcie_coreclkout_hip_clk        = Signal()
        pcie_pld_clk_clk               = Signal()
        pcie_pld_clk_1_clk             = Signal()

        pcie_config_tl_tl_cfg_add      = Signal(4)
        pcie_o_config_tl_tl_cfg_ctl    = Signal(32)
        pcie_hip_rst_serdes_pll_locked = Signal()
        pcie_o_power_mngt_pme_to_sr    = Signal()

         # Clocking ---------------------------------------------------------------------------------
        pcie_refclk = Signal()
        self.specials += Instance("ALT_INBUF_DIFF",
            i_i    = pads.clk_p,
            i_ibar = pads.clk_n,
            o_o    = pcie_refclk
        )

        self.cd_pcie = ClockDomain()

        # TX CDC (FPGA --> HOST) -------------------------------------------------------------------
        if cd == "pcie":
            tx_st = self.sink
        else:
            tx_buffer = stream.Buffer(phy_layout(data_width))
            tx_buffer = ClockDomainsRenamer(cd)(tx_buffer)
            tx_cdc    = stream.AsyncFIFO(phy_layout(data_width), 32)
            tx_cdc    = ClockDomainsRenamer({"write": cd, "read": "pcie"})(tx_cdc)
            self.submodules += tx_buffer, tx_cdc
            self.comb += [
                self.sink.connect(tx_buffer.sink),
                tx_buffer.source.connect(tx_cdc.sink)
            ]
            tx_st = tx_cdc.source

        # RX CDC (HOST --> FPGA) -------------------------------------------------------------------
        if cd == "pcie":
            rx_st = self.source
        else:
            rx_cdc    = stream.AsyncFIFO(phy_layout(data_width), 32)
            rx_cdc    = ClockDomainsRenamer({"write": "pcie", "read": cd})(rx_cdc)
            rx_buffer = stream.Buffer(phy_layout(data_width))
            rx_buffer = ClockDomainsRenamer(cd)(rx_buffer)
            self.submodules += rx_buffer, rx_cdc
            self.comb += [
                rx_cdc.source.connect(rx_buffer.sink),
                rx_buffer.source.connect(self.source)
            ]
            rx_st = rx_cdc.sink

        # MSI CDC (FPGA --> HOST) ------------------------------------------------------------------
        if cd == "pcie":
            cfg_msi = self.msi
        else:
            msi_cdc = stream.AsyncFIFO(msi_layout(), 4)
            msi_cdc = ClockDomainsRenamer({"write": cd, "read": "pcie"})(msi_cdc)
            self.submodules += msi_cdc
            self.comb += self.msi.connect(msi_cdc.sink)
            cfg_msi = msi_cdc.source

        # Hard IP Configuration --------------------------------------------------------------------
        def convert_size(command, size):
            cases = {}
            value = 128
            for i in range(6):
                cases[i] = size.eq(value)
                value = value*2
            return Case(command, cases)

        bus_number      = Signal(8)
        device_number   = Signal(5)
        function_number = Signal(3)
        dcommand        = Signal(16)

        self.bus_number      = bus_number
        self.device_number   = device_number
        self.function_number = function_number

        tl_cfg_add_reg_lsb    = Signal()
        tl_cfg_add_reg2_lsb   = Signal()
        cfgctl_addr_change    = Signal()
        cfgctl_addr_change2   = Signal()
        cfgctl_addr_strobe    = Signal()
        captured_cfg_addr_reg = Signal(4)
        captured_cfg_data_reg = Signal(32)

        self.sync.pcie += [
            convert_size(dcommand[12:15], self.max_request_size),
            convert_size(dcommand[5:8], self.max_payload_size),
            self.id.eq(Cat(function_number, device_number, bus_number))
        ]

        # To capture configuration space Register, register LSB bit of tl_cfg_add
        self.sync.pcie += [
            tl_cfg_add_reg_lsb.eq(pcie_config_tl_tl_cfg_add[0]),
            tl_cfg_add_reg2_lsb.eq(tl_cfg_add_reg_lsb)
        ]
        # Detect the address change to generate a strobe to sample the input 32-bit data
        self.sync.pcie += [
            cfgctl_addr_change.eq(tl_cfg_add_reg_lsb != tl_cfg_add_reg2_lsb),
            cfgctl_addr_change2.eq(cfgctl_addr_change),
            cfgctl_addr_strobe.eq(cfgctl_addr_change2)
        ]
        self.sync.pcie += [
            captured_cfg_addr_reg.eq(pcie_config_tl_tl_cfg_add),
            captured_cfg_data_reg.eq(pcie_o_config_tl_tl_cfg_ctl)
        ]

        # Get dcommand
        self.sync.pcie += [
            If((cfgctl_addr_strobe == 1) & (captured_cfg_addr_reg == 0),
                dcommand.eq(captured_cfg_data_reg[0:16])
            )
        ]
        # Get device_number and bus_number
        self.sync.pcie += [
            If((cfgctl_addr_strobe == 1) & (captured_cfg_addr_reg == 15),
                device_number.eq(captured_cfg_data_reg[0:5]),
                bus_number.eq(captured_cfg_data_reg[5:13])
            )
        ]

        # tl_cfg_add[6:4] should represent function number whose information is being presented on
        # tl_cfg_ctl, but only one function is enabled on IP core  in this case function_number is
        # always 0
        self.comb += function_number.eq(0)

        # Native stream <--> AvalonST --------------------------------------------------------------
        tx_n2av = Native2AvalonST(phy_layout(data_width), latency=2)
        tx_n2av = ClockDomainsRenamer("pcie")(tx_n2av)
        self.comb += tx_st.connect(tx_n2av.sink)
        self.submodules += tx_n2av

        rx_av2n = AvalonST2Native(phy_layout(data_width), latency=2)
        rx_av2n = ClockDomainsRenamer("pcie")(rx_av2n)
        self.comb += rx_av2n.source.connect(rx_st)
        self.submodules += rx_av2n

        tx_avst = tx_n2av.source
        rx_avst = rx_av2n.sink

        # Hard IP ----------------------------------------------------------------------------------
        self.pcie_phy_params = dict(
            # Clocks
            i_refclk_clk                = pcie_refclk,
            i_pld_clk_clk               = ClockSignal("pcie"),
            o_coreclkout_hip_clk        = ClockSignal("pcie"),

            # Resets
            i_npor_npor                 = 1 if not hasattr(pads, "rst_n") else pads.rst_n,
            i_npor_pin_perst            = 1 if not hasattr(pads, "rst_n") else pads.rst_n,

            # Hard IP Reconfiguration
            i_reconfig_clk_clk          = pcie_reconfig_clk,
            i_reconfig_reset_reset_n    = pcie_rst_n,

            # Power Management
            i_power_mngt_pme_to_cr      = pcie_o_power_mngt_pme_to_sr,
            o_power_mngt_pme_to_sr      = pcie_o_power_mngt_pme_to_sr,

            # Config (Configuration space)
            o_config_tl_tl_cfg_ctl      = pcie_o_config_tl_tl_cfg_ctl,
            o_config_tl_tl_cfg_add      = pcie_config_tl_tl_cfg_add,

            # Control
            o_hip_rst_serdes_pll_locked = pcie_hip_rst_serdes_pll_locked,
            i_hip_rst_pld_core_ready    = pcie_hip_rst_serdes_pll_locked,

            # RX Port
            o_rx_st_valid               = rx_avst.valid,
            o_rx_st_startofpacket       = rx_avst.first,
            o_rx_st_endofpacket         = rx_avst.last,
            i_rx_st_ready               = rx_avst.ready,
            o_rx_st_data                = rx_avst.dat,

            # TX Port
            i_tx_st_valid               = tx_avst.valid,
            i_tx_st_startofpacket       = tx_avst.first,
            i_tx_st_endofpacket         = tx_avst.last,
            o_tx_st_ready               = tx_avst.ready,
            i_tx_st_data                = tx_avst.dat,

            # Serial IF
            i_hip_serial_rx_in0         = pads.rx_p[0],
            i_hip_serial_rx_in1         = pads.rx_p[1],
            i_hip_serial_rx_in2         = pads.rx_p[2],
            i_hip_serial_rx_in3         = pads.rx_p[3],
            o_hip_serial_tx_out0        = pads.tx_p[0],
            o_hip_serial_tx_out1        = pads.tx_p[1],
            o_hip_serial_tx_out2        = pads.tx_p[2],
            o_hip_serial_tx_out3        = pads.tx_p[3],

            # MSI
            i_int_msi_app_msi_num       = 0,
            i_int_msi_app_msi_req       = cfg_msi.valid,
            i_int_msi_app_msi_tc        = 0,
            o_int_msi_app_msi_ack       = cfg_msi.ready,
            i_int_msi_app_int_sts       = 0
        )

    # External Hard IP -----------------------------------------------------------------------------
    def use_external_hard_ip(self, hard_ip_path):
        self.external_hard_ip = True
        self.platform.add_source(
            os.path.join("altera", "cyclone_v", "pcie_phy", "synthesis", "pcie_phy.qip"), "QIP")

    def do_finalize(self):
        if not self.external_hard_ip:
            raise ValueError("User needs to provide Hard IP source path with use_external_hard_ip")
        self.specials += Instance("pcie_phy", **self.pcie_phy_params)

```

`litepcie/phy/common.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2015-2020 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

from migen import *
from migen.genlib.cdc import MultiReg

from litepcie.common import *

# TX Datapath --------------------------------------------------------------------------------------

class PHYTXDatapath(Module):
    def __init__(self, core_data_width, pcie_data_width, clock_domain):
        self.sink   = sink   = stream.Endpoint(phy_layout(core_data_width))
        self.source = source = stream.Endpoint(phy_layout(pcie_data_width))

        # # #

        if (clock_domain == "pcie") and (core_data_width == pcie_data_width):
            self.comb += sink.connect(source)
        else:
            pipe_valid = stream.PipeValid(phy_layout(core_data_width))
            pipe_valid = ClockDomainsRenamer(clock_domain)(pipe_valid)
            cdc        = stream.ClockDomainCrossing(
                layout          = phy_layout(core_data_width),
                cd_from         = clock_domain,
                cd_to           = "pcie",
                with_common_rst = True,
                depth           = 16,
            )
            converter  = stream.StrideConverter(phy_layout(core_data_width), phy_layout(pcie_data_width))
            converter  = ClockDomainsRenamer("pcie")(converter)
            pipe_ready = stream.PipeReady(phy_layout(pcie_data_width))
            pipe_ready = ClockDomainsRenamer("pcie")(pipe_ready)
            self.submodules += pipe_valid, cdc, converter, pipe_ready
            self.comb += [
                sink.connect(pipe_valid.sink),
                pipe_valid.source.connect(cdc.sink),
                cdc.source.connect(converter.sink),
                converter.source.connect(pipe_ready.sink),
                pipe_ready.source.connect(source),
            ]

# PHYRX128BAligner ---------------------------------------------------------------------------------

class PHYRX128BAligner(Module):
    def __init__(self):
        self.sink   = sink   = stream.Endpoint(phy_layout(128))
        self.source = source = stream.Endpoint(phy_layout(128))
        self.first_dword = Signal(2)

        # # #

        dat_last = Signal(64, reset_less=True)
        be_last  = Signal(8,  reset_less=True)
        self.sync += [
            If(sink.valid & sink.ready,
                dat_last.eq(sink.dat[64:]),
                be_last.eq( sink.be[8:]),
            )
        ]

        self.submodules.fsm = fsm = FSM(reset_state="ALIGNED")
        fsm.act("ALIGNED",
            sink.connect(source, omit={"first"}),
            # If "first" on DWORD2 and "last" on the same cycle, switch to UNALIGNED.
            If(sink.valid & sink.last & sink.first & (self.first_dword == 2),
                source.be[8:].eq(0),
                If(source.ready,
                    NextState("UNALIGNED")
                )
            )
        )
        fsm.act("UNALIGNED",
            sink.connect(source, omit={"first", "dat", "be"}),
            source.dat.eq(Cat(dat_last, sink.dat)),
            source.be.eq( Cat(be_last,  sink.be)),
            # If "last" and not "first" on the same cycle, switch to ALIGNED.
            If(sink.valid & sink.last & ~sink.first,
                source.be[8:].eq(0),
                If(source.ready,
                    NextState("ALIGNED")
                )
            )
        )

# RX Datapath --------------------------------------------------------------------------------------

class PHYRXDatapath(Module):
    def __init__(self, core_data_width, pcie_data_width, clock_domain, with_aligner=False):
        self.sink   = sink   = stream.Endpoint(phy_layout(pcie_data_width))
        self.source = source = stream.Endpoint(phy_layout(core_data_width))

        # # #

        if (pcie_data_width == 128) and with_aligner:
            aligner = PHYRX128BAligner()
            aligner = ClockDomainsRenamer("pcie")(aligner)
            self.submodules.aligner = aligner
            self.comb += sink.connect(aligner.sink)
            sink = aligner.source

        if (clock_domain == "pcie") and (core_data_width == pcie_data_width):
            self.comb += sink.connect(source)
        else:
            pipe_ready = stream.PipeReady(phy_layout(core_data_width))
            pipe_ready = ClockDomainsRenamer("pcie")(pipe_ready)
            converter  = stream.StrideConverter(phy_layout(pcie_data_width), phy_layout(core_data_width))
            converter  = ClockDomainsRenamer("pcie")(converter)
            cdc        = stream.ClockDomainCrossing(
                layout          = phy_layout(core_data_width),
                cd_from         = "pcie",
                cd_to           = clock_domain,
                with_common_rst = True,
                depth           = 16,
            )
            pipe_valid = stream.PipeValid(phy_layout(core_data_width))
            pipe_valid = ClockDomainsRenamer(clock_domain)(pipe_valid)
            self.submodules += pipe_ready, converter, cdc, pipe_valid
            self.comb += [
                sink.connect(pipe_ready.sink),
                pipe_ready.source.connect(converter.sink),
                converter.source.connect(cdc.sink),
                cdc.source.connect(pipe_valid.sink),
                pipe_valid.source.connect(source),
            ]

# LTSSMTracer --------------------------------------------------------------------------------------

class LTSSMTracer(Module, AutoCSR):
    def __init__(self, ltssm):
        self._history = CSRStatus(description="History of LTSSM states",
            fields = [
                CSRField("new",   offset= 0, size=6, description="New LTSSM state"),
                CSRField("old",   offset= 6, size=6, description="Old LTSSM state"),
                CSRField("ovfl",  offset=30, size=1, description="Overflow"),
                CSRField("valid", offset=31, size=1, description="Is data valid"),
        ])

        # The ltssm state signal input is sampled in the sys domain just using a MultiReg. This means
        # on change we could have an invalid state during 1 cycle.
        #
        # We also don't use an AsyncFIFO because the pcie clock domain is held in reset most of the
        # LTSSM initial negotiation defeating the point of this module.

        fifo = stream.SyncFIFO([("new", 6), ("old", 6), ("ovfl", 1)], 128)
        self.submodules += fifo

        ltssm_cur = Signal(6)
        ltssm_d1  = Signal(6)
        ltssm_d2  = Signal(6)

        overflow  = Signal()
        change    = Signal()

        self.sync += [
            ltssm_d1.eq(ltssm_cur),
            If(fifo.sink.ready, ltssm_d2.eq(ltssm_d1)),
            change.eq((ltssm_cur != ltssm_d1) & ~change),
            overflow.eq((overflow | change) & ~fifo.sink.ready),
        ]

        self.comb += [
            ltssm_cur.eq(ltssm),
            fifo.sink.new.eq(ltssm_cur),
            fifo.sink.old.eq(ltssm_d2),
            fifo.sink.ovfl.eq(overflow),
            fifo.sink.valid.eq(overflow | change),
            self._history.fields.new.eq(fifo.source.new),
            self._history.fields.old.eq(fifo.source.old),
            self._history.fields.ovfl.eq(fifo.source.ovfl),
            self._history.fields.valid.eq(fifo.source.valid),
            fifo.source.ready.eq(self._history.we),
        ]

```

`litepcie/phy/gw5apciephy.py`:

```py
#
# This file is part of LiteX.
#
# Copyright (c) 2024-2025 Enjoy-Digital <enjoy-digital.fr>
#
# SPDX-License-Identifier: BSD-2-Clause

import os
from shutil import which
import subprocess

from migen import *

from litex.gen import *

from litex.soc.interconnect import axi
from litex.soc.interconnect.csr import *

from litepcie.common import *
from litepcie.phy.common import *

# GW5APCIEPHY --------------------------------------------------------------------------------------

class GW5APCIEPHY(LiteXModule):
    endianness = "big" # CHECKME.

    def __init__(self, platform, pads, nlanes=1, data_width=256, cd="sys", bar0_size=0x100000):
        # Streams ---------------------------------------------------------------------------------
        self.sink   = stream.Endpoint(phy_layout(data_width))
        self.source = stream.Endpoint(phy_layout(data_width))
        self.msi    = stream.Endpoint(msi_layout()) # FIXME: Connect.

        # Registers --------------------------------------------------------------------------------
        self._link_status = CSRStatus(fields=[
            CSRField("status", size=1, values=[
                ("``0b0``", "Link Down."),
                ("``0b1``", "Link Up."),
            ]),
            CSRField("rate", size=1, values=[
                ("``0b0``", "2.5 Gb/s."),
                ("``0b1``", "5.0 Gb/s."),
            ]),
            CSRField("width", size=2, values=[
                ("``0b00``", "1-Lane link."),
                ("``0b01``", "2-Lane link."),
                ("``0b10``", "4-Lane link."),
                ("``0b11``", "8-Lane link."),
            ]),
            CSRField("ltssm", size=5, description="LTSSM State"),
        ])

        self._msi_enable  = CSRStatus(description="MSI Enable Status. ``1``: MSI is enabled.")
        self._msix_enable = CSRStatus(description="MSI-X Enable Status. ``1``: MSI-X is enabled.")

        self._tl_cfg_busdev    = CSRStatus(13,
            description="Bus Number and DeviceNumber information for PCIe devices.")
        self._tl_rx_bardec     = CSRStatus(6, description="Target BAR decoding.")
        self._tl_rx_err        = CSRStatus(8, description="Receive data error signal.")
        self._tl_tx_creditsp   = CSRStatus(32,
            description="Posted TLP controls the number of credits sent.")
        self._tl_tx_creditsnp  = CSRStatus(32,
            description="Non-Posted TLP controls the number of credits sent.")
        self._tl_tx_creditscpl = CSRStatus(32,
            description="Completion TLP controls the number of credits sent.")

        self.comb += [
            self._msi_enable.status.eq(1),
            self._msix_enable.status.eq(0),
        ]

        # Parameters/Locals ------------------------------------------------------------------------
        self.platform         = platform
        pcie_data_width       = data_width
        self.data_width       = data_width
        self.id               = Signal(16, reset_less=True) # FIXME: Todo
        self.bar0_size        = bar0_size
        self.bar0_mask        = get_bar_mask(bar0_size)

        self.max_request_size = Signal(16, reset=256) # FIXME.
        self.max_payload_size = Signal(16, reset=256) # FIXME.

        # # #

        self.nlanes = nlanes

        assert nlanes in [1, 4]

        # Clocking / Reset -------------------------------------------------------------------------
        self.cd_pcie = ClockDomain()
        self.comb += [
            self.cd_pcie.clk.eq(ClockSignal("crg_pcie")),
            self.cd_pcie.rst.eq(~pads.rst_n),
        ]

        if hasattr(pads, "wake_n"):
            self.comb += pads.wake_n.eq(0)

        # TX (FPGA --> HOST) CDC / Data Width Conversion -------------------------------------------
        tl_tx_ready      = Signal()
        tl_tx_valid      = Signal(8)

        self.tx_datapath = PHYTXDatapath(
            core_data_width = data_width,
            pcie_data_width = pcie_data_width,
            clock_domain    = cd)
        s_axis_tx = self.tx_datapath.source
        self.comb += [
            self.sink.connect(self.tx_datapath.sink, omit={"dat"}),
            s_axis_tx.ready.eq(~tl_tx_ready),
        ]
        for i in range(8):
            self.comb += tl_tx_valid[7-i].eq(Reduce("OR", s_axis_tx.be[i*4:(i+1)*4]) & s_axis_tx.valid)

        self.comb += self.swap_dwords(self.sink.dat, self.tx_datapath.sink.dat)

        # RX (HOST --> FPGA) CDC / Data Width Conversion -------------------------------------------
        tl_rx_valid      = Signal(8)

        self.rx_datapath = PHYRXDatapath(
            core_data_width = data_width,
            pcie_data_width = pcie_data_width,
            clock_domain    = cd)
        m_axis_rx = self.rx_datapath.sink
        self.comb += [
            self.rx_datapath.source.connect(self.source, omit={"dat"}),
            m_axis_rx.valid.eq(Reduce("OR", tl_rx_valid)), # FIXME: need something more clever
        ]
        for i in range(8):
            self.comb += m_axis_rx.be[i*4: (i+1)*4].eq(Replicate(tl_rx_valid[7-i], 4))

        self.comb += self.swap_dwords(self.rx_datapath.source.dat, self.source.dat)

        # MSI CDC (FPGA --> HOST) ------------------------------------------------------------------
        msi_int_status = Signal()
        msi_req        = Signal()
        msi_dat        = Signal(5)
        msi_valid_d    = Signal()
        if cd == "pcie":
            cfg_msi = self.msi
        else:
            self.msi_cdc = msi_cdc = stream.ClockDomainCrossing(
                layout          = msi_layout(),
                cd_from         = cd,
                cd_to           = "pcie",
                with_common_rst = True,
            )
            self.comb += self.msi.connect(msi_cdc.sink)
            cfg_msi = msi_cdc.source

        self.comb += msi_int_status.eq(cfg_msi.valid)
        self.comb += msi_req.eq(cfg_msi.valid & ~msi_valid_d)
        self.comb += msi_dat.eq(Cat(msi_req, Constant(0, 4)))
        self.sync.pcie += msi_valid_d.eq(cfg_msi.valid)

        # PCIe hard IP -----------------------------------------------------------------------------

        self.ip_params = dict()
        self.ip_params.update(    
            # PCI Express Interface ----------------------------------------------------------------
            # Clk/Rst
            i_PCIE_Controller_Top_pcie_rstn_i             = ~ResetSignal("pcie"),
            i_PCIE_Controller_Top_pcie_tl_clk_i           = ClockSignal("pcie"),

            # Control
            o_PCIE_Controller_Top_pcie_linkup_o           = self.add_resync(self._link_status.fields.status, "sys"),
            o_PCIE_Controller_Top_pcie_ltssm_o            = self.add_resync(self._link_status.fields.ltssm,  "sys"),
            o_PCIE_Controller_Top_pcie_tl_cfg_busdev_o    = self.add_resync(self._tl_cfg_busdev.status,      "sys"),

            # TLP Receive Interface ----------------------------------------------------------------
            # TLP Receive Interface Ports
            i_PCIE_Controller_Top_pcie_tl_rx_wait_i       = ~m_axis_rx.ready,
            o_PCIE_Controller_Top_pcie_tl_rx_valid_o      = tl_rx_valid,
            o_PCIE_Controller_Top_pcie_tl_rx_bardec_o     = self.add_resync(self._tl_rx_bardec.status, "sys"),
            o_PCIE_Controller_Top_pcie_tl_rx_sop_o        = m_axis_rx.first,
            o_PCIE_Controller_Top_pcie_tl_rx_data_o       = m_axis_rx.dat,
            o_PCIE_Controller_Top_pcie_tl_rx_eop_o        = m_axis_rx.last,
            i_PCIE_Controller_Top_pcie_tl_rx_masknp_i     = Constant(0, 1),
            o_PCIE_Controller_Top_pcie_tl_rx_err_o        = self.add_resync(self._tl_rx_err.status, "sys"),

            # TLP Transmit Interface ---------------------------------------------------------------
            # TLP Transmit Interface Ports
            i_PCIE_Controller_Top_pcie_tl_tx_valid_i      = tl_tx_valid,
            i_PCIE_Controller_Top_pcie_tl_tx_eop_i        = s_axis_tx.last,
            i_PCIE_Controller_Top_pcie_tl_tx_sop_i        = s_axis_tx.first, # CHECKME/FIXME: Verify it's generated by LitePCie.
            i_PCIE_Controller_Top_pcie_tl_tx_data_i       = s_axis_tx.dat,
            o_PCIE_Controller_Top_pcie_tl_tx_wait_o       = tl_tx_ready,
            # TLP Transmit Credit Interface Ports
            o_PCIE_Controller_Top_pcie_tl_tx_creditsp_o   = self.add_resync(self._tl_tx_creditsp.status,   "sys"),
            o_PCIE_Controller_Top_pcie_tl_tx_creditsnp_o  = self.add_resync(self._tl_tx_creditsnp.status,  "sys"),
            o_PCIE_Controller_Top_pcie_tl_tx_creditscpl_o = self.add_resync(self._tl_tx_creditscpl.status, "sys"),

            # DRP ----------------------------------------------------------------------------------
            o_PCIE_Controller_Top_pcie_tl_drp_clk_o       = Open(),
            o_PCIE_Controller_Top_pcie_tl_drp_rddata_o    = Open(32),
            o_PCIE_Controller_Top_pcie_tl_drp_resp_o      = Open(),
            o_PCIE_Controller_Top_pcie_tl_drp_rd_valid_o  = Open(),
            o_PCIE_Controller_Top_pcie_tl_drp_ready_o     = Open(),
            i_PCIE_Controller_Top_pcie_tl_drp_addr_i      = Constant(0, 24),
            i_PCIE_Controller_Top_pcie_tl_drp_wrdata_i    = Constant(0, 32),
            i_PCIE_Controller_Top_pcie_tl_drp_strb_i      = Constant(0,  8),
            i_PCIE_Controller_Top_pcie_tl_drp_wr_i        = Constant(0,  1),
            i_PCIE_Controller_Top_pcie_tl_drp_rd_i        = Constant(0,  1),

            # MSI
            o_PCIE_Controller_Top_pcie_tl_int_ack_o       = cfg_msi.ready,
            i_PCIE_Controller_Top_pcie_tl_int_status_i    = msi_int_status,
            i_PCIE_Controller_Top_pcie_tl_int_req_i       = msi_req,
            i_PCIE_Controller_Top_pcie_tl_int_msinum_i    = msi_dat,
        )

        if nlanes == 1:
            self.ip_params.update(
                # Unused/undocumented
                i_gpio_refclk3_i = Constant(0, 1),
                i_gpio_refclk2_i = Constant(0, 1),
                i_gpio_refclk1_i = Constant(0, 1),
                i_gpio_refclk0_i = Constant(0, 1),
            )

    # Data Ordering Helper -------------------------------------------------------------------------
    def swap_dwords(self, src, dst):
        assert len(src) == len(dst)
        ndwords = len(src)//32
        r = []
        for i in range(ndwords):
            r.append(dst[i*32:(i + 1)*32].eq(src[(ndwords - i - 1)*32:(ndwords - i - 0)*32]))
        return r

    # Resync Helper --------------------------------------------------------------------------------
    def add_resync(self, sig, clk="sys"):
        _sig = Signal.like(sig)
        self.specials += MultiReg(_sig, sig, clk)
        return _sig

    # Finalize -------------------------------------------------------------------------------------
    def do_finalize(self):
        src_dir = os.path.join(self.platform.output_dir, "gw5apciephy")
        src_zip = os.path.join(self.platform.output_dir, "gw5apciephy.zip")
        url     = "https://github.com/user-attachments/files/18846086/gw5apciephy.zip"
        if not os.path.exists(src_dir):
            # If zip archive is not available
            if not os.path.exists(src_zip):
                # Download archive.
                # Build the wget command
                command = ["wget", "-O" , src_zip, url]
                try:
                    print(f"Downloading {url}...")
                    # Execute the wget command
                    result = subprocess.run(command, check=True)
                    print(f"Downloaded {src_zip} successfully!")
                except subprocess.CalledProcessError as e:
                    print(f"Failed to download {url}. Error: {e}")
                except FileNotFoundError:
                    print("The 'wget' command is not available. Please install wget and try again.")

            # Extract archive.
            # Build the wget command
            command = ["unzip", src_zip, "-d" , self.platform.output_dir]
            try:
                print(f"Unzipping {src_zip}...")
                # Execute the wget command
                result = subprocess.run(command, check=True)
                print(f"Unzipped {src_zip} successfully!")
            except subprocess.CalledProcessError as e:
                print(f"Failed to unzip {src_zip}. Error: {e}")
            except FileNotFoundError:
                print("The 'unzip' command is not available. Please install unzip and try again.")

        src_dir = os.path.join(src_dir, f"gw5apciephyx{self.nlanes}")

        self.platform.add_source(os.path.join(src_dir, "gw5apciephy.v"))
        self.platform.add_source(os.path.join(src_dir, "pcie_controller", "pcie_controller.v"))
        self.platform.add_source(os.path.join(src_dir, "upar_arbiter",    "upar_arbiter.v"))

        self.specials += Instance("GW5APCIEPHY_Top", **self.ip_params)

```

`litepcie/phy/lfcpnxpciephy.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2024-2025 Enjoy-Digital <enjoy-digital.fr>
#
# SPDX-License-Identifier: BSD-2-Clause

# Use latticesemi.com_ip_pcie_x4_1.1.0
# FIXME: switch to 2.3.0

import os
from shutil import which
import subprocess

from migen import *

from litex.gen import *

from litex.soc.interconnect import axi
from litex.soc.interconnect.csr import *

from litepcie.common import *
from litepcie.tlp.common import *
from litepcie.phy.common import *

# LFCPNXPCIEPHY ------------------------------------------------------------------------------------

class LFCPNXPCIEPHY(LiteXModule):
    endianness = "big"
    lmmi_layout = [
        ("request",      1),
        ("wr_rdn",       1),
        ("wdata",       32),
        ("offset",      15),
        ("rdata",       64),
        ("rdata_valid",  5),
        ("ready",        5),
    ]

    def __init__(self, platform, pads, data_width=128, cd="pcie", bar0_size=65536):
        # Streams ---------------------------------------------------------------------------------
        self.sink   = stream.Endpoint(phy_layout(data_width))
        self.source = stream.Endpoint(phy_layout(data_width))
        self.msi    = stream.Endpoint(msi_layout()) # FIXME: Connect.

        # Registers --------------------------------------------------------------------------------
        self._link_status = CSRStatus(fields=[
            CSRField("status", size=1, values=[
                ("``0b0``", "Link Down."),
                ("``0b1``", "Link Up."),
            ]),
            CSRField("rate", size=1, values=[
                ("``0b0``", "2.5 Gb/s."),
                ("``0b1``", "5.0 Gb/s."),
            ]),
            CSRField("width", size=2, values=[
                ("``0b00``", "1-Lane link."),
                ("``0b01``", "2-Lane link."),
                ("``0b10``", "4-Lane link."),
                ("``0b11``", "8-Lane link."),
            ]),
            CSRField("ltssm", size=6, description="LTSSM State"),
        ])
        self._msi_enable        = CSRStatus(description="MSI Enable Status. ``1``: MSI is enabled.")
        self._msix_enable       = CSRStatus(description="MSI-X Enable Status. ``1``: MSI-X is enabled.")

        # Parameters/Locals ------------------------------------------------------------------------
        self.platform   = platform
        pcie_data_width = data_width
        self.perst_n_i  = pads.perst
        self.data_width = data_width
        self.id         = Signal(16, reset_less=True) # FIXME: Todo
        self.bar0_size  = bar0_size
        self.bar0_mask  = get_bar_mask(bar0_size)

        self.max_request_size = Signal(16, reset=256) # FIXME.
        self.max_payload_size = Signal(16, reset=256) # FIXME.

        # # #

        nlanes = len(pads.tx_p)

        assert nlanes in [4]

        # Clocking / Reset -------------------------------------------------------------------------
        self.cd_pcie = ClockDomain()
        self.comb += self.cd_pcie.clk.eq(platform.request("clkin125"))

        # Link Status ------------------------------------------------------------------------------
        link_up          = Signal()
        link0_pl_link_up = Signal()
        link0_dl_link_up = Signal()
        link0_tl_link_up = Signal()
        self.comb += [
            link_up.eq(link0_pl_link_up & link0_dl_link_up & link0_tl_link_up),
            self._link_status.fields.status.eq(link_up),
        ]

        # TX (FPGA --> HOST) CDC / Data Width Conversion -------------------------------------------
        tx_data_p = Signal(16)
        self.tx_datapath = PHYTXDatapath(
            core_data_width = data_width,
            pcie_data_width = pcie_data_width,
            clock_domain    = cd,
        )
        self.comb += self.sink.connect(self.tx_datapath.sink, omit={"dat", "be"})
        self.comb += dword_endianness_swap(
            src        = self.sink.dat,
            dst        = self.tx_datapath.sink.dat,
            data_width = data_width,
            endianness = "big",
            mode       = "dat",
        )
        self.comb += dword_endianness_swap(
            src        = self.sink.be,
            dst        = self.tx_datapath.sink.be,
            data_width = data_width,
            endianness = "big",
            mode       = "be",
        )
        self.s_axis_tx = s_axis_tx = self.tx_datapath.source

        for i in range(16):
            self.comb += tx_data_p[i].eq(Reduce("XOR", self.s_axis_tx.dat[i*8:(i+1)*8]))

        # RX (HOST --> FPGA) CDC / Data Width Conversion -------------------------------------------
        self.rx_datapath = PHYRXDatapath(
            core_data_width = data_width,
            pcie_data_width = pcie_data_width,
            clock_domain    = cd,
        )
        self.m_axis_rx = m_axis_rx = self.rx_datapath.sink
        self.comb += self.rx_datapath.source.connect(self.source, omit={"dat", "be"})
        self.comb += dword_endianness_swap(
            src        = self.rx_datapath.source.dat,
            dst        = self.source.dat,
            data_width = data_width,
            endianness = "big",
            mode       = "dat",
        )
        self.comb += dword_endianness_swap(
            src        = self.rx_datapath.source.be, # FIXME: Should be adapted.
            dst        = self.source.be,
            data_width = data_width,
            endianness = "big",
            mode       = "be",
        )
        self.comb += self.source.be.eq(2**len(self.source.be) - 1) # FIXME: Should be adapted.

        # LMMI (Configuration) ---------------------------------------------------------------------
        usr_lmmi         = Record(self.lmmi_layout)
        usr_lmmi_resetn  = Signal(1, reset_less=True)
        self.sync.pcie += If(~pads.perst, usr_lmmi_resetn.eq(0)).Else(usr_lmmi_resetn.eq(1))

        self.ip_params      = dict()
        self.lmmi_ip_params = dict()

        # PCIe hard IP -----------------------------------------------------------------------------

        self.ip_params.update(    
            # PCI Express Interface ----------------------------------------------------------------
            # Clk/Rst
            i_refclkp_i                         = pads.clk_p,
            i_refclkn_i                         = pads.clk_n,

            # TX
            o_link0_txp_o                       = pads.tx_p,
            o_link0_txn_o                       = pads.tx_n,

            # RX
            i_link0_rxp_i                       = pads.rx_p,
            i_link0_rxn_i                       = pads.rx_n,

            i_refret_i                          = pads.refret,
            i_rext_i                            = pads.rext,
            i_sys_clk_i                         = ClockSignal("pcie"),
            i_link0_aux_clk_i                   = ClockSignal("pcie"),
            i_link0_perst_n_i                   = pads.perst,
            i_link0_rst_usr_n_i                 = Constant(1, 1), # FIXME: bit of logic?
            o_link0_clk_usr_o                   = Open(),         # FIXME: must be used as cd_pcie source
            o_link0_pl_link_up_o                = link0_pl_link_up,
            o_link0_dl_link_up_o                = link0_dl_link_up,
            o_link0_tl_link_up_o                = link0_tl_link_up,
                
            i_link0_user_aux_power_detected_i   = Constant(0, 1),
            i_link0_user_transactions_pending_i = Constant(0, 1),

            # TLP Receive Interface ----------------------------------------------------------------
            # TLP Receive Interface Ports
            i_link0_rx_ready_i                  = m_axis_rx.ready,
            o_link0_rx_valid_o                  = m_axis_rx.valid,
            o_link0_rx_sel_o                    = Open(2),
            o_link0_rx_cmd_data_o               = Open(13),
            o_link0_rx_sop_o                    = Open(),
            o_link0_rx_data_o                   = m_axis_rx.dat,
            o_link0_rx_datap_o                  = Open(16),
            o_link0_rx_eop_o                    = m_axis_rx.last,
            o_link0_rx_err_ecrc_o               = Open(),
            o_link0_rx_f_o                      = Open(2),

            # TLP Receive Credit Interface Ports
            i_link0_rx_credit_init_i            = Constant(1, 1),
            i_link0_rx_credit_nh_i              = Constant(0, 12),
            i_link0_rx_credit_nh_inf_i          = Constant(1, 1),
            i_link0_rx_credit_return_i          = Constant(1, 1),
        
            # TLP Transmit Interface ---------------------------------------------------------------
            # TLP Transmit Interface Ports
            i_link0_tx_valid_i                  = s_axis_tx.valid,
            i_link0_tx_eop_i                    = s_axis_tx.last,
            i_link0_tx_eop_n_i                  = Constant(0, 1),
            i_link0_tx_sop_i                    = s_axis_tx.first, # CHECKME/FIXME: Verify it's generated by LitePCie.
            i_link0_tx_data_i                   = s_axis_tx.dat,
            i_link0_tx_datap_i                  = tx_data_p,
            o_link0_tx_ready_o                  = s_axis_tx.ready,

            # TLP Transmit Credit Interface Ports
            o_link0_tx_credit_init_o            = Open(),
            o_link0_tx_credit_return_o          = Open(),
            o_link0_tx_credit_nh_o              = Open(12),

            # Lattice Memory Mapped Interface (LMMI) -----------------------------------------------
            i_usr_lmmi_clk_i                    = ClockSignal("pcie"),
            i_usr_lmmi_resetn_i                 = usr_lmmi_resetn,
            i_usr_lmmi_request_i                = Cat(usr_lmmi.request, Constant(0, 4)),
            i_usr_lmmi_wr_rdn_i                 = usr_lmmi.wr_rdn,
            i_usr_lmmi_wdata_i                  = usr_lmmi.wdata,
            i_usr_lmmi_offset_i                 = Cat(Constant(0, 2), usr_lmmi.offset),
            o_usr_lmmi_rdata_o                  = usr_lmmi.rdata,
            o_usr_lmmi_rdata_valid_o            = usr_lmmi.rdata_valid,
            o_usr_lmmi_ready_o                  = usr_lmmi.ready,
                
            i_ucfg_link_i                       = Constant(0, 1),
            i_ucfg_valid_i                      = Constant(0, 1),
            i_ucfg_wr_rd_n_i                    = Constant(0, 1),
            i_ucfg_addr_i                       = Constant(0, 10),
            i_ucfg_f_i                          = Constant(0, 3),
            i_ucfg_wr_be_i                      = Constant(0, 4),
            i_ucfg_wr_data_i                    = Constant(0, 32),
            o_ucfg_rd_data_o                    = Open(32),
            o_ucfg_rd_done_o                    = Open(2),
            o_ucfg_ready_o                      = Open(),
        )

        self.lmmi_ip_params.update(
            # Clk/Rst
            i_clk                    = ClockSignal("pcie"),
            i_rst_n                  = usr_lmmi_resetn,

            # LMMI interface
            o_usr_lmmi_request_o     = usr_lmmi.request,
            o_usr_lmmi_wr_rdn_o      = usr_lmmi.wr_rdn,
            o_usr_lmmi_wdata_o       = usr_lmmi.wdata,
            o_usr_lmmi_offset_o      = usr_lmmi.offset,
            i_usr_lmmi_rdata_i       = usr_lmmi.rdata[0:32],
            i_usr_lmmi_rdata_valid_i = usr_lmmi.rdata_valid[0],
            i_usr_lmmi_ready_i       = usr_lmmi.ready[0],

            # completer id for tx engine
            o_completer_id_o         = Open(16),
            o_config_done            = Open(),
        )

    # Finalize -------------------------------------------------------------------------------------
    def do_finalize(self):
        src_dir = os.path.join(self.platform.output_dir, "lfcpnxpciephy")
        src_zip = os.path.join(self.platform.output_dir, "lfcpnxpciephy.zip")
        url     = "https://github.com/user-attachments/files/18943678/lfcpnxpciephy.zip"
        if not os.path.exists(src_dir):
            # If zip archive is not available
            if not os.path.exists(src_zip):
                # Download archive.
                # Build the wget command
                command = ["wget", "-O" , src_zip, url]
                try:
                    print(f"Downloading {url}...")
                    # Execute the wget command
                    result = subprocess.run(command, check=True)
                    print(f"Downloaded {src_zip} successfully!")
                except subprocess.CalledProcessError as e:
                    print(f"Failed to download {url}. Error: {e}")
                except FileNotFoundError:
                    print("The 'wget' command is not available. Please install wget and try again.")

            # Extract archive.
            # Build the wget command
            command = ["unzip", src_zip, "-d" , self.platform.output_dir]
            try:
                print(f"Unzipping {src_zip}...")
                # Execute the wget command
                result = subprocess.run(command, check=True)
                print(f"Unzipped {src_zip} successfully!")
            except subprocess.CalledProcessError as e:
                print(f"Failed to unzip {src_zip}. Error: {e}")
            except FileNotFoundError:
                print("The 'unzip' command is not available. Please install unzip and try again.")

        self.platform.add_source(os.path.join(src_dir, "rtl", "lfcpnxpciephy.v"))
        self.platform.add_source(os.path.join(src_dir, "LMMI_app.v"))

        self.specials += [
            Instance("lfcpnxpciephy", **self.ip_params),
            Instance("LMMI_app",      **self.lmmi_ip_params),
            Instance("GSR",
                i_CLK   = ClockSignal("pcie"),
                i_GSR_N = self.perst_n_i,
            )
        ]

```

`litepcie/phy/s7pciephy.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2015-2023 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

import os

from migen import *
from migen.genlib.cdc import MultiReg

from litex.gen import *

from litex.soc.interconnect.csr import *
from litex.soc.cores.clock import S7MMCM

from litepcie.common import *
from litepcie.phy.common import *

# S7PCIEPHY ----------------------------------------------------------------------------------------

class S7PCIEPHY(LiteXModule):
    endianness    = "big"
    qword_aligned = False
    gt_channel_path = {
        "gtp": "gtp_channel.gtpe2_channel_i",
        "gtx": "gtx_channel.gtxe2_channel_i",
    }
    def __init__(self, platform, pads, data_width=64,  cd="sys",
        # PCIe hardblock parameters.
        pcie_data_width               = None,
        refclk_freq                   = 100e6,
        bar0_size                     = 0x100000,
        msi_type                      = "msi",
        with_ptm                      = False,
        mode                          = "Endpoint",
        with_perst_refclk_gating      = False,
        # MMCM parameters.
        mmcm_clk125_buf               = "bufg",
        mmcm_clk250_buf               = "bufg",
    ):
        # Streams ----------------------------------------------------------------------------------
        self.sink   = stream.Endpoint(phy_layout(data_width))
        self.source = stream.Endpoint(phy_layout(data_width))
        self.msi    = stream.Endpoint(msi_layout())

        # Registers --------------------------------------------------------------------------------
        self._link_status = CSRStatus(fields=[
            CSRField("status", size=1, values=[
                ("``0b0``", "Link Down."),
                ("``0b1``", "Link Up."),
            ]),
            CSRField("rate", size=1, values=[
                ("``0b0``", "2.5 Gb/s."),
                ("``0b1``", "5.0 Gb/s."),
            ]),
            CSRField("width", size=2, values=[
                ("``0b00``", "1-Lane link."),
                ("``0b01``", "2-Lane link."),
                ("``0b10``", "4-Lane link."),
                ("``0b11``", "8-Lane link."),
            ]),
            CSRField("ltssm", size=6, description="LTSSM State"),
        ])
        self._msi_enable        = CSRStatus(description="MSI Enable Status. ``1``: MSI is enabled.")
        self._msix_enable       = CSRStatus(description="MSI-X Enable Status. ``1``: MSI-X is enabled.")
        self._bus_master_enable = CSRStatus(description="Bus Mastering Status. ``1``: Bus Mastering enabled.")
        self._max_request_size  = CSRStatus(16, description="Negiotiated Max Request Size (in bytes).")
        self._max_payload_size  = CSRStatus(16, description="Negiotiated Max Payload Size (in bytes).")

        # Parameters/Locals ------------------------------------------------------------------------
        assert mode in ["Endpoint", "RootPort"]
        self.mode = mode

        if pcie_data_width is None: pcie_data_width = data_width
        self.platform         = platform
        self.data_width       = data_width
        self.pcie_data_width  = pcie_data_width
        self.refclk_freq      = refclk_freq
        self.msi_type         = msi_type
        self.with_ptm         = with_ptm

        self.id               = Signal(16, reset_less=True)
        self.bar0_size        = bar0_size
        self.bar0_mask        = get_bar_mask(bar0_size)
        self.max_request_size = Signal(16, reset_less=True)
        self.max_payload_size = Signal(16, reset_less=True)

        self.config           = {}
        self.external_hard_ip = False

        # # #

        self.nlanes = nlanes = len(pads.tx_p)

        assert nlanes          in [1, 2, 4, 8]
        assert data_width      in [64, 128]
        assert pcie_data_width in [64, 128]
        assert refclk_freq     in [100e6, 125e6, 250e6]

        # Clocking / Reset -------------------------------------------------------------------------
        self.pcie_refclk = pcie_refclk = Signal()
        self.pcie_rst_n  = pcie_rst_n  = Signal(reset=1)
        if hasattr(pads, "rst_n"):
            self.comb += If(pads.rst_n == 0, pcie_rst_n.eq(0))
        self.specials += Instance("IBUFDS_GTE2",
            i_CEB = (~pcie_rst_n) if with_perst_refclk_gating else 0,
            i_I   = pads.clk_p,
            i_IB  = pads.clk_n,
            o_O   = pcie_refclk
        )
        platform.add_period_constraint(pads.clk_p, 1e9/refclk_freq)
        self.cd_pcie = ClockDomain()

        # TX (FPGA --> HOST) CDC / Data Width Conversion -------------------------------------------
        self.tx_datapath = PHYTXDatapath(
            core_data_width = data_width,
            pcie_data_width = pcie_data_width,
            clock_domain    = cd)
        self.comb += self.sink.connect(self.tx_datapath.sink)
        s_axis_tx = self.tx_datapath.source

        # RX (HOST --> FPGA) CDC / Data Width Conversion -------------------------------------------
        self.rx_datapath = PHYRXDatapath(
            core_data_width = data_width,
            pcie_data_width = pcie_data_width,
            clock_domain    = cd,
            with_aligner    = True)
        m_axis_rx = self.rx_datapath.sink
        self.comb += self.rx_datapath.source.connect(self.source)

        # MSI CDC ----------------------------------------------------------------------------------
        if self.mode == "Endpoint":
            if cd == "pcie":
                cfg_msi = self.msi
            else:
                self.msi_cdc = msi_cdc = stream.ClockDomainCrossing(
                    layout          = msi_layout(),
                    cd_from         = cd,
                    cd_to           = "pcie",
                    with_common_rst = True,
                )
                self.comb += self.msi.connect(msi_cdc.sink)
                cfg_msi = msi_cdc.source
        else:
            cfg_msi = None

        # Hard IP Configuration --------------------------------------------------------------------

        def convert_size(command, size, max_size):
            cases = {}
            value = 128
            for i in range(6):
                cases[i] = size.eq(value)
                value = min(value*2, max_size)
            return Case(command, cases)

        bus_number      = Signal(8)
        device_number   = Signal(5)
        function_number = Signal(3)
        command         = Signal(16)
        dcommand        = Signal(16)
        self.comb += [
            convert_size(dcommand[12:15], self.max_request_size, max_size=512),
            convert_size(dcommand[5:8],   self.max_payload_size, max_size=512),
            self.id.eq(Cat(function_number, device_number, bus_number)),
        ]
        self.comb += [
            self._bus_master_enable.status.eq(command[2]),
            self._max_request_size.status.eq(self.max_request_size),
            self._max_payload_size.status.eq(self.max_payload_size),
        ]

        # Hard IP Clocking -------------------------------------------------------------------------

        # Signals.
        pipe_txoutclk      = Signal()
        pipe_txoutclk_bufg = Signal()
        pipe_pclk_sel      = Signal(nlanes)

        # Clock Domains.
        self.cd_clk125   = ClockDomain()
        self.cd_clk250   = ClockDomain()
        self.cd_userclk1 = ClockDomain()
        self.cd_userclk2 = ClockDomain()
        self.cd_pclk     = ClockDomain()

        # MMCM.
        userclk1_freq = {1:125e6, 2:125e6, 4:250e6, 8:500e6}[nlanes]
        userclk2_freq = {1:125e6, 2:125e6, 4:125e6, 8:250e6}[nlanes]
        self.mmcm = mmcm = S7MMCM(speedgrade=-2)
        self.specials += Instance("BUFG",
            i_I = pipe_txoutclk,
            o_O = pipe_txoutclk_bufg,
        )
        mmcm.register_clkin(pipe_txoutclk_bufg, refclk_freq)
        mmcm.create_clkout(self.cd_clk125,           125e6, margin=0, buf=mmcm_clk125_buf)
        mmcm.create_clkout(self.cd_clk250,           250e6, margin=0, buf=mmcm_clk250_buf)
        mmcm.create_clkout(self.cd_userclk1, userclk1_freq, margin=0)
        mmcm.create_clkout(self.cd_userclk2, userclk2_freq, margin=0)

        # PClk Selection.
        pipe_pclk_sel_r = Signal(nlanes)
        pclk_sel        = Signal()
        self.specials += MultiReg(pipe_pclk_sel, pipe_pclk_sel_r, "pclk")
        self.sync.pclk += [
            If(pipe_pclk_sel_r == (2**nlanes - 1), pclk_sel.eq(1)),
            If(pipe_pclk_sel_r ==               0, pclk_sel.eq(0)),
        ]
        self.specials += [
            Instance("BUFGCTRL",
                i_CE0 = 0b1,
                i_CE1 = 0b1,
                i_I0  = ClockSignal("clk125"),
                i_I1  = ClockSignal("clk250"),
                i_S0  = (pclk_sel == 0),
                i_S1  = (pclk_sel == 1),
                o_O   = ClockSignal("pclk"),
            )
        ]
        pclk_sel.attr.add("keep")
        platform.add_platform_command("set_false_path -through [get_nets {{*pclk_sel}}]")

        # Hard IP ----------------------------------------------------------------------------------
        m_axis_rx_tlast = Signal()
        m_axis_rx_tuser = Signal(32)

        if self.mode == "Endpoint":
            irq_ports = dict(
                i_cfg_interrupt            = cfg_msi.valid,
                o_cfg_interrupt_rdy        = cfg_msi.ready,
                i_cfg_interrupt_di         = cfg_msi.dat,
                o_cfg_interrupt_msienable  = self.add_resync(self._msi_enable.status,  "sys"),
                o_cfg_interrupt_msixenable = self.add_resync(self._msix_enable.status, "sys"),
            )
        else:
            irq_ports = dict(
                i_cfg_interrupt            = 0,
                o_cfg_interrupt_rdy        = Open(),
                i_cfg_interrupt_di         = 0,
                o_cfg_interrupt_msienable  = Open(),
                o_cfg_interrupt_msixenable = Open(),
            )

        if self.mode == "RootPort":
            cfg_msg_received = Signal()
            cfg_msg_data     = Signal(8)
            cfg_msg_ports = dict(
                o_cfg_msg_received = cfg_msg_received,
                o_cfg_msg_data     = cfg_msg_data,
            )
        else:
            cfg_msg_ports = dict(
                o_cfg_msg_received = Open(),
                o_cfg_msg_data     = Open(),
            )

        self.pcie_phy_params = dict(
            # PCI Express Interface ----------------------------------------------------------------
            # Clk/Rst
            i_sys_clk                                    = pcie_refclk,
            i_sys_rst_n                                  = pcie_rst_n,

            # TX
            o_pci_exp_txp                                = pads.tx_p,
            o_pci_exp_txn                                = pads.tx_n,

            # RX
            i_pci_exp_rxp                                = pads.rx_p,
            i_pci_exp_rxn                                = pads.rx_n,

            # PIPE Clocking Interface --------------------------------------------------------------
            i_pipe_pclk_in                               = ClockSignal("pclk"),
            o_pipe_txoutclk_out                          = pipe_txoutclk,
            o_pipe_rxoutclk_out                          = Open(),
            o_pipe_pclk_sel_out                          = pipe_pclk_sel,
            o_pipe_gen3_out                              = Open(),
            i_pipe_rxusrclk_in                           = ClockSignal("pclk"),
            i_pipe_rxoutclk_in                           = 0,
            i_pipe_dclk_in                               = ClockSignal("clk125"),
            i_pipe_userclk1_in                           = ClockSignal("userclk1"),
            i_pipe_userclk2_in                           = ClockSignal("userclk2"),
            i_pipe_oobclk_in                             = ClockSignal("pclk"),
            i_pipe_mmcm_lock_in                          = mmcm.locked,
            i_pipe_mmcm_rst_n                            = 1,

            # AXI-S Interface ----------------------------------------------------------------------
            # Common
            o_user_clk_out                               = ClockSignal("pcie"),
            o_user_reset_out                             = ResetSignal("pcie"),
            o_user_lnk_up                                = self.add_resync(self._link_status.fields.status, "sys"),
            o_user_app_rdy                               = Open(),

            # TX
            o_tx_buf_av                                  = Open(),
            o_tx_err_drop                                = Open(),
            o_tx_cfg_req                                 = Open(),
            i_tx_cfg_gnt                                 = 1,
            i_s_axis_tx_tvalid                           = s_axis_tx.valid,
            i_s_axis_tx_tlast                            = s_axis_tx.last,
            o_s_axis_tx_tready                           = s_axis_tx.ready,
            i_s_axis_tx_tdata                            = s_axis_tx.dat,
            i_s_axis_tx_tkeep                            = s_axis_tx.be,
            i_s_axis_tx_tuser                            = 0,

            # RX
            i_rx_np_ok                                   = 1,
            i_rx_np_req                                  = 1,
            o_m_axis_rx_tvalid                           = m_axis_rx.valid,
            o_m_axis_rx_tlast                            = m_axis_rx_tlast,
            i_m_axis_rx_tready                           = m_axis_rx.ready,
            o_m_axis_rx_tdata                            = m_axis_rx.dat,
            o_m_axis_rx_tkeep                            = m_axis_rx.be,
            o_m_axis_rx_tuser                            = m_axis_rx_tuser,

            # Flow Control
            o_fc_cpld                                    = Open(),
            o_fc_cplh                                    = Open(),
            o_fc_npd                                     = Open(),
            o_fc_nph                                     = Open(),
            o_fc_pd                                      = Open(),
            o_fc_ph                                      = Open(),
            i_fc_sel                                     = 0,

            # Management Interface -----------------------------------------------------------------
            o_cfg_mgmt_do                                = Open(),
            o_cfg_mgmt_rd_wr_done                        = Open(),
            i_cfg_mgmt_di                                = 0,
            i_cfg_mgmt_byte_en                           = 0,
            i_cfg_mgmt_dwaddr                            = 0,
            i_cfg_mgmt_wr_en                             = 0,
            i_cfg_mgmt_rd_en                             = 0,
            i_cfg_mgmt_wr_readonly                       = 0,
            i_cfg_mgmt_wr_rw1c_as_rw                     = 0,

            # Error Reporting Interface ------------------------------------------------------------
            i_cfg_err_ecrc                               = 0,
            i_cfg_err_ur                                 = 0,
            i_cfg_err_cpl_timeout                        = 0,
            i_cfg_err_cpl_unexpect                       = 0,
            i_cfg_err_cpl_abort                          = 0,
            i_cfg_err_posted                             = 0,
            i_cfg_err_cor                                = 0,
            i_cfg_err_atomic_egress_blocked              = 0,
            i_cfg_err_internal_cor                       = 0,
            i_cfg_err_malformed                          = 0,
            i_cfg_err_mc_blocked                         = 0,
            i_cfg_err_poisoned                           = 0,
            i_cfg_err_norecovery                         = 0,
            i_cfg_err_tlp_cpl_header                     = 0,
            o_cfg_err_cpl_rdy                            = Open(),
            i_cfg_err_locked                             = 0,
            i_cfg_err_acs                                = 0,
            i_cfg_err_internal_uncor                     = 0,

            # AER interface ------------------------------------------------------------------------
            i_cfg_err_aer_headerlog                      = 0,
            i_cfg_aer_interrupt_msgnum                   = 0,
            o_cfg_err_aer_headerlog_set                  = Open(),
            o_cfg_aer_ecrc_check_en                      = Open(),
            o_cfg_aer_ecrc_gen_en                        = Open(),

            i_cfg_turnoff_ok                             = 0,
            i_cfg_trn_pending                            = 0,
            i_cfg_pm_halt_aspm_l0s                       = 0,
            i_cfg_pm_halt_aspm_l1                        = 0,
            i_cfg_pm_force_state_en                      = 0,
            i_cfg_pm_force_state                         = 0,
            i_cfg_dsn                                    = 0,
            i_cfg_pm_send_pme_to                         = 0,
            i_cfg_ds_bus_number                          = 0,
            i_cfg_ds_device_number                       = 0,
            i_cfg_ds_function_number                     = 0,
            i_cfg_pm_wake                                = 0,

            # Interrupt Interface ------------------------------------------------------------------
            i_cfg_interrupt_assert                       = 0,
            o_cfg_interrupt_do                           = Open(),
            o_cfg_interrupt_mmenable                     = Open(),
            o_cfg_interrupt_msixfm                       = Open(),
            i_cfg_interrupt_stat                         = 0,
            i_cfg_pciecap_interrupt_msgnum               = 0,

            # Configuration Interface --------------------------------------------------------------
            o_cfg_status                                 = Open(),
            o_cfg_command                                = self.add_resync(command, "sys"),
            o_cfg_dstatus                                = Open(),
            o_cfg_dcommand                               = self.add_resync(dcommand, "sys"),
            o_cfg_lstatus                                = Open(),
            o_cfg_lcommand                               = Open(),
            o_cfg_dcommand2                              = Open(),
            o_cfg_pcie_link_state                        = Open(),
            o_cfg_to_turnoff                             = Open(),
            o_cfg_bus_number                             = self.add_resync(bus_number,      "sys"),
            o_cfg_device_number                          = self.add_resync(device_number,   "sys"),
            o_cfg_function_number                        = self.add_resync(function_number, "sys"),

            o_cfg_pmcsr_pme_en                           = Open(),
            o_cfg_pmcsr_powerstate                       = Open(),
            o_cfg_pmcsr_pme_status                       = Open(),
            o_cfg_received_func_lvl_rst                  = Open(),
            o_cfg_bridge_serr_en                         = Open(),
            o_cfg_slot_control_electromech_il_ctl_pulse  = Open(),
            o_cfg_root_control_syserr_corr_err_en        = Open(),
            o_cfg_root_control_syserr_non_fatal_err_en   = Open(),
            o_cfg_root_control_syserr_fatal_err_en       = Open(),
            o_cfg_root_control_pme_int_en                = Open(),
            o_cfg_aer_rooterr_corr_err_reporting_en      = Open(),
            o_cfg_aer_rooterr_non_fatal_err_reporting_en = Open(),
            o_cfg_aer_rooterr_fatal_err_reporting_en     = Open(),
            o_cfg_aer_rooterr_corr_err_received          = Open(),
            o_cfg_aer_rooterr_non_fatal_err_received     = Open(),
            o_cfg_aer_rooterr_fatal_err_received         = Open(),

            # VC Interface -------------------------------------------------------------------------
            o_cfg_vc_tcvc_map                            = Open(),

            o_cfg_msg_received_pm_as_nak                 = Open(),
            o_cfg_msg_received_setslotpowerlimit         = Open(),
            o_cfg_msg_received_err_cor                   = Open(),
            o_cfg_msg_received_err_non_fatal             = Open(),
            o_cfg_msg_received_err_fatal                 = Open(),
            o_cfg_msg_received_pm_pme                    = Open(),
            o_cfg_msg_received_pme_to_ack                = Open(),
            o_cfg_msg_received_assert_int_a              = Open(),
            o_cfg_msg_received_assert_int_b              = Open(),
            o_cfg_msg_received_assert_int_c              = Open(),
            o_cfg_msg_received_assert_int_d              = Open(),
            o_cfg_msg_received_deassert_int_a            = Open(),
            o_cfg_msg_received_deassert_int_b            = Open(),
            o_cfg_msg_received_deassert_int_c            = Open(),
            o_cfg_msg_received_deassert_int_d            = Open(),

            # Physical Layer Interface -------------------------------------------------------------
            i_pl_directed_link_change                    = 0,
            i_pl_directed_link_width                     = 0,
            i_pl_directed_link_speed                     = 0,
            i_pl_directed_link_auton                     = 0,
            i_pl_upstream_prefer_deemph                  = 1,
            o_pl_sel_lnk_rate                            = self.add_resync(self._link_status.fields.rate,  "sys"),
            o_pl_sel_lnk_width                           = self.add_resync(self._link_status.fields.width, "sys"),
            o_pl_ltssm_state                             = self.add_resync(self._link_status.fields.ltssm, "sys"),
            o_pl_lane_reversal_mode                      = Open(),
            o_pl_phy_lnk_up                              = Open(),
            o_pl_tx_pm_state                             = Open(),
            o_pl_rx_pm_state                             = Open(),
            o_pl_link_upcfg_cap                          = Open(),
            o_pl_link_gen2_cap                           = Open(),
            o_pl_link_partner_gen2_supported             = Open(),
            o_pl_initial_link_width                      = Open(),
            o_pl_directed_change_done                    = Open(),
            o_pl_received_hot_rst                        = Open(),
            i_pl_transmit_hot_rst                        = 0,
            i_pl_downstream_deemph_source                = 0,

            # PCIe DRP Interface -------------------------------------------------------------------
            i_pcie_drp_clk                               = 1,
            i_pcie_drp_en                                = 0,
            i_pcie_drp_we                                = 0,
            i_pcie_drp_addr                              = 0,
            i_pcie_drp_di                                = 0,
            o_pcie_drp_rdy                               = Open(),
            o_pcie_drp_do                                = Open(),
        )

        self.pcie_phy_params.update(irq_ports)
        self.pcie_phy_params.update(cfg_msg_ports)

        if pcie_data_width == 128:
            rx_is_sof = m_axis_rx_tuser[10:15] # Start of a new packet header in m_axis_rx_tdata.
            rx_is_eof = m_axis_rx_tuser[17:22] # End of a packet in m_axis_rx_tdata.
            self.comb += [
                m_axis_rx.first.eq(rx_is_sof[-1]),
                m_axis_rx.last.eq( rx_is_eof[-1]),
                If(rx_is_sof == 0b11000, self.rx_datapath.aligner.first_dword.eq(2)),
            ]
        else:
            self.comb += [
                m_axis_rx.first.eq(0),
                m_axis_rx.last.eq(m_axis_rx_tlast),
            ]

    # Resync Helper --------------------------------------------------------------------------------
    def add_resync(self, sig, clk="sys"):
        _sig = Signal.like(sig)
        self.specials += MultiReg(_sig, sig, clk)
        return _sig

    # LTSSM Tracer ---------------------------------------------------------------------------------
    def add_ltssm_tracer(self):
        self.ltssm_tracer = LTSSMTracer(self._link_status.fields.ltssm)

    # External QPLL (Sharing) ----------------------------------------------------------------------
    def use_external_qpll(self, qpll_channel):
        self.pcie_phy_params.update(
            # QPLL DRP Interface (not used).
            i_qpll_drp_crscode   = 0,
            i_qpll_drp_fsm       = 0,
            i_qpll_drp_done      = 1,
            i_qpll_drp_reset     = 0,
            o_qpll_drp_clk       = Open(),
            o_qpll_drp_rst_n     = Open(),
            o_qpll_drp_ovrd      = Open(),
            o_qpll_drp_gen3      = Open(),
            o_qpll_drp_start     = Open(),

            # QPLL Clk Interface.
            i_qpll_qplllock      = qpll_channel.lock,
            i_qpll_qplloutclk    = qpll_channel.clk,
            i_qpll_qplloutrefclk = qpll_channel.refclk,
            o_qpll_qplld         = Open(),
            o_qpll_qpllreset     = qpll_channel.reset,
        )
        self.config.update({
            "mode_selection"   : "Advanced",
            "en_ext_gt_common" : True,
        })

    # Hard IP sources ------------------------------------------------------------------------------
    def update_config(self, config):
        self.config.update(config)

    def add_gt_loc_constraints(self, locs, gt_type=None, by_pipe_lane=True):
        if gt_type is None:
            gt_type = "gtp" if self.platform.device.startswith("xc7a") else "gtx"
        gt_channel_path = self.gt_channel_path[gt_type]

        commands = self.platform.toolchain.pre_placement_commands
        commands.append(
            "reset_property LOC "
            "[get_cells -hierarchical -filter "
            f"{{{{NAME=~pcie_s7/*{gt_channel_path}}}}}]"
        )
        if by_pipe_lane:
            for lane, loc in enumerate(locs):
                commands.append(
                    "set_property LOC "
                    f"{loc} "
                    "[get_cells -hierarchical -filter "
                    f"{{{{NAME=~pcie_s7/*pipe_lane[{lane}].gt_wrapper_i/{gt_channel_path}}}}}]"
                )
        else:
            assert len(locs) == 1
            commands.append(
                "set_property LOC "
                f"{locs[0]} "
                f"[get_cells -hierarchical -filter {{{{NAME=~pcie_s7/*{gt_channel_path}}}}}]"
            )

    def add_sources(self, platform, phy_path, phy_filename=None, user_config=None):
        if phy_filename is not None:
            platform.add_ip(os.path.join(phy_path, phy_filename))
        else:
            # Device identification.
            device_id = 7020 + self.nlanes

            # Link / clocks.
            link_speed         = "5.0_GT/s"
            maximum_link_width = f"X{self.nlanes}"
            ref_clk_freq       = f"{int(self.refclk_freq/1e6)}_MHz"
            user_clk_freq      = 125 if self.nlanes != 8 else 250

            # Interface.
            interface_width = f"{self.pcie_data_width}_bit"
            max_payload     = "512_bytes" if self.nlanes != 8 else "256_bytes"

            # BAR0.
            bar0_scale = "Megabytes"
            bar0_size  = max(self.bar0_size/MB, 1)

            # Target link speed.
            trgt_link_speed = "4'h2"

            config = {
                # Core.
                "Device_ID"          : device_id,
                "PCIe_Blk_Locn"      : "X0Y0",

                # Link.
                "Link_Speed"         : link_speed,
                "Maximum_Link_Width" : maximum_link_width,
                "Trgt_Link_Speed"    : trgt_link_speed,

                # Clocks.
                "Ref_Clk_Freq"       : ref_clk_freq,
                "User_Clk_Freq"      : user_clk_freq,

                # Interface.
                "Interface_Width"    : interface_width,
                "Max_Payload_Size"   : max_payload,

                # Buffers.
                "Buf_Opt_BMA"        : True,
                "Trans_Buf_Pipeline" : None,

                # BAR0.
                "Bar0_Scale"         : bar0_scale,
                "Bar0_Size"          : bar0_size,
            }

            # Interrupts parameters.
            assert self.msi_type in ["msi", "msi-multi-vector", "msi-x"]
            config.update({
                "Legacy_Interrupt" : None,
                "IntX_Generation"  : False,
            })
            if self.msi_type in ["msi", "msi-multi-vector"]:
                config.update({
                    "MSI_64b"                  : False,
                    "Multiple_Message_Capable" : "1_vector",  # FIXME for multi-vector.
                })
            if self.msi_type == "msi-x":
                config.update({
                    "mode_selection"    : "Advanced",
                    "MSI_Enabled"       : False,
                    "MSIx_Enabled"      : True,
                    "MSIx_Table_Size"   : "20",   # Hexa.
                    "MSIx_Table_Offset" : "2000", # Hexa, should match CSR_PCIE_MSI_TABLE_BASE.
                    "MSIx_PBA_Offset"   : "1808", # Hexa, should match CSR_PCIE_MSI_PBA_ADDR.
                })

            # Extended Capabilities Registers.
            if self.with_ptm:
                config.update({
                    "EXT_PCI_CFG_Space"      : True,
                    "EXT_PCI_CFG_Space_Addr" : "6B", # 0x1AC.
                })

            # RootPort mode.
            if self.mode == "RootPort":
                config.update({
                    "Device_Port_Type"         : "Root_Port_of_PCI_Express_Root_Complex",
                    "Base_Class_Menu"          : "Bridge_device",
                    "Sub_Class_Interface_Menu" : "Host_bridge",
                    "Class_Code_Base"          : "06",
                    "Class_Code_Sub"           : "00",
                })
                config.setdefault("Bar0_Type", "Memory")

            # User/Custom Config.
            config.update(self.config)

            # Tcl generation.
            ip_tcl = []
            ip_tcl.append("create_ip -vendor xilinx.com -name pcie_7x -module_name pcie_s7")
            ip_tcl.append("set obj [get_ips pcie_s7]")
            ip_tcl.append("set_property -dict [list \\")
            for config, value in config.items():
                ip_tcl.append("CONFIG.{} {} \\".format(config, '{{' + str(value) + '}}'))
            ip_tcl.append(f"] $obj")
            ip_tcl.append("synth_ip $obj")
            platform.toolchain.pre_synthesis_commands += ip_tcl

        # Reset LOC constraints on GTPE2_COMMON and BRAM36 from .xci (keep timing constraints only).
        if "en_ext_gt_common" not in self.config.keys():
            if platform.device.startswith("xc7a"):
                platform.toolchain.pre_placement_commands.append("reset_property LOC [get_cells -hierarchical -filter {{NAME=~pcie_s7/*gtp_common.gtpe2_common_i}}]")
            else:
                platform.toolchain.pre_placement_commands.append("reset_property LOC [get_cells -hierarchical -filter {{NAME=~pcie_s7/*gtx_common.gtxe2_common_i}}]")
        if self.nlanes != 8:
            platform.toolchain.pre_placement_commands.append("reset_property LOC [get_cells -hierarchical -filter {{NAME=~pcie_s7/*genblk*.bram36_tdp_bl.bram36_tdp_bl}}]")

    # External Hard IP -----------------------------------------------------------------------------
    def use_external_hard_ip(self, hard_ip_path, hard_ip_filename):
        self.external_hard_ip = True
        self.add_sources(self.platform, hard_ip_path, hard_ip_filename)

    # Finalize -------------------------------------------------------------------------------------
    def do_finalize(self):
        if not self.external_hard_ip:
            phy_path     = "xilinx_s7_gen2"
            self.add_sources(self.platform,
                phy_path     = os.path.join(os.path.abspath(os.path.dirname(__file__)), phy_path),
            )
        self.specials += Instance("pcie_s7", **self.pcie_phy_params)

```

`litepcie/phy/uspciephy.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2020-2023 Enjoy-Digital <enjoy-digital.fr>
# Copyright (c) 2022 Sylvain Munaut <tnt@246tNt.com>
# SPDX-License-Identifier: BSD-2-Clause

import os

from migen import *
from migen.genlib.cdc import MultiReg

from litex.gen import *

from litex.soc.interconnect.csr import *

from litepcie.common import *
from litepcie.phy.common import *
from litepcie.phy.axis_adapters import MAxisCQAdapter, MAxisRCAdapter, SAxisCCAdapter, SAxisRQAdapter

# USPCIEPHY ----------------------------------------------------------------------------------------

class USPCIEPHY(LiteXModule):
    endianness    = "little"
    qword_aligned = False
    def __init__(self, platform, pads, speed="gen3", data_width=64, cd="sys",
        # PCIe hardblock parameters.
        pcie_data_width = None,
        bar0_size       = 0x100000,
        mode            = "Endpoint",
    ):
        # Streams ----------------------------------------------------------------------------------
        self.req_sink   = stream.Endpoint(phy_layout(data_width))
        self.cmp_sink   = stream.Endpoint(phy_layout(data_width))
        self.req_source = stream.Endpoint(phy_layout(data_width))
        self.cmp_source = stream.Endpoint(phy_layout(data_width))
        self.msi        = stream.Endpoint(msi_layout())

        # Registers --------------------------------------------------------------------------------
        self._link_status = CSRStatus(fields=[
            CSRField("status", size=1, values=[
                ("``0b0``", "Link Down."),
                ("``0b1``", "Link Up."),
            ]),
            CSRField("phy_down", size=1, values=[
                ("``0b0``", "PHY Link Up."),
                ("``0b1``", "PHY Link Down."),
            ]),
            CSRField("phy_status", size=2, values=[
                ("``00b``", "No receivers detected."),
                ("``01b``", "Link training in progress."),
                ("``10b``", "Link up, DL initialization in progress."),
                ("``11b``", "Link up, DL initialization completed."),
            ]),
            CSRField("rate", size=3, values=[
                ("``0b001``", "2.5 GT/s."),
                ("``0b010``", "5.0 GT/s."),
                ("``0b100``", "8.0 GT/s."),
            ]),
            CSRField("width", size=4, values=[
                ("``0b0001``", "1-Lane link."),
                ("``0b0010``", "2-Lane link."),
                ("``0b0100``", "4-Lane link."),
                ("``0b1000``", "8-Lane link."),
            ]),
            CSRField("ltssm", size=6, description="LTSSM State"),
        ])
        self._msi_enable        = CSRStatus(description="MSI Enable Status. ``1``: MSI is enabled.")
        self._bus_master_enable = CSRStatus(description="Bus Mastering Status. ``1``: Bus Mastering enabled.")
        self._max_request_size  = CSRStatus(16, description="Negiotiated Max Request Size (in bytes).")
        self._max_payload_size  = CSRStatus(16, description="Negiotiated Max Payload Size (in bytes).")

        # Parameters/Locals ------------------------------------------------------------------------
        assert mode in ["Endpoint", "RootPort"]
        self.mode = mode

        if pcie_data_width is None: pcie_data_width = data_width
        self.platform         = platform
        self.data_width       = data_width
        self.pcie_data_width  = pcie_data_width

        self.id               = Signal(16)
        self.bar0_size        = bar0_size
        self.bar0_mask        = get_bar_mask(bar0_size)
        self.max_request_size = Signal(16)
        self.max_payload_size = Signal(16)

        self.config           = {}
        self.external_hard_ip = False

        # # #

        self.speed  = speed
        self.nlanes = nlanes = len(pads.tx_p)

        assert speed           in ["gen2", "gen3"]
        assert nlanes          in [1, 2, 4, 8]
        assert data_width      in [64, 128, 256]
        assert pcie_data_width in [64, 128, 256]

        # Clocking / Reset -------------------------------------------------------------------------
        self.pcie_refclk    = pcie_refclk    = Signal()
        self.pcie_refclk_gt = pcie_refclk_gt = Signal()
        self.pcie_rst_n     = pcie_rst_n     = Signal(reset=1)
        if hasattr(pads, "rst_n"):
            self.comb += pcie_rst_n.eq(pads.rst_n)
        self.specials += Instance("IBUFDS_GTE3",
            p_REFCLK_HROW_CK_SEL = 0,
            i_CEB   = 0,
            i_I     = pads.clk_p,
            i_IB    = pads.clk_n,
            o_O     = pcie_refclk_gt,
            o_ODIV2 = pcie_refclk
        )
        platform.add_period_constraint(pads.clk_p, 1e9/100e6)
        self.cd_pcie = ClockDomain()

        # TX (FPGA --> HOST) CDC / Data Width Conversion -------------------------------------------
        self.cc_datapath = PHYTXDatapath(
            core_data_width = data_width,
            pcie_data_width = pcie_data_width,
            clock_domain    = cd)
        self.comb += self.cmp_sink.connect(self.cc_datapath.sink)
        s_axis_cc = self.cc_datapath.source

        self.rq_datapath = PHYTXDatapath(
            core_data_width = data_width,
            pcie_data_width = pcie_data_width,
            clock_domain    = cd)
        self.comb += self.req_sink.connect(self.rq_datapath.sink)
        s_axis_rq = self.rq_datapath.source

        # RX (HOST --> FPGA) CDC / Data Width Conversion -------------------------------------------
        self.cq_datapath = PHYRXDatapath(
            core_data_width = data_width,
            pcie_data_width = pcie_data_width,
            clock_domain    = cd)
        m_axis_cq = self.cq_datapath.sink
        self.comb += self.cq_datapath.source.connect(self.req_source)

        self.rc_datapath = PHYRXDatapath(
            core_data_width = data_width,
            pcie_data_width = pcie_data_width,
            clock_domain    = cd)
        m_axis_rc = self.rc_datapath.sink
        self.comb += self.rc_datapath.source.connect(self.cmp_source)

        # MSI CDC ----------------------------------------------------------------------------------
        if self.mode == "Endpoint":
            if cd == "pcie":
                cfg_msi = self.msi
            else:
                self.msi_cdc = msi_cdc = stream.ClockDomainCrossing(
                    layout          = msi_layout(),
                    cd_from         = cd,
                    cd_to           = "pcie",
                    with_common_rst = True,
                )
                self.comb += self.msi.connect(msi_cdc.sink)
                cfg_msi = msi_cdc.source
        else:
            cfg_msi = None

        # Hard IP Configuration --------------------------------------------------------------------

        def convert_size(command, size, max_size):
            cases = {}
            value = 128
            for i in range(6):
                cases[i] = size.eq(value)
                value = min(value*2, max_size)
            return Case(command, cases)

        serial_number   = Signal(64)
        bus_number      = Signal(8)
        device_number   = Signal(5)
        function_number = Signal(3)

        cfg_function_status  = Signal(16)
        cfg_max_payload_size = Signal(3)
        cfg_max_read_req     = Signal(3)
        link_status_sys      = self.add_resync(self._link_status.fields.status, "sys")
        link_phy_down_sys    = self.add_resync(self._link_status.fields.phy_down, "sys")
        link_phy_status_sys  = self.add_resync(self._link_status.fields.phy_status, "sys")
        link_width_sys       = self.add_resync(self._link_status.fields.width, "sys")
        link_rate_sys        = self.add_resync(self._link_status.fields.rate, "sys")
        link_ltssm_sys       = self.add_resync(self._link_status.fields.ltssm, "sys")
        cfg_max_payload_sys  = self.add_resync(cfg_max_payload_size, "sys")
        cfg_max_read_req_sys = self.add_resync(cfg_max_read_req, "sys")
        cfg_function_status_sys = self.add_resync(cfg_function_status, "sys")
        msi_enable_sys       = self.add_resync(self._msi_enable.status, "sys")

        self.comb += [
            convert_size(cfg_max_read_req,     self.max_request_size, max_size=512),
            convert_size(cfg_max_payload_size, self.max_payload_size, max_size=512),
            self.id.eq(Cat(function_number, device_number, bus_number))
        ]
        self.comb += [
            self._bus_master_enable.status.eq(cfg_function_status),
            self._max_request_size.status.eq(self.max_request_size),
            self._max_payload_size.status.eq(self.max_payload_size),
        ]

        self.m_axis_cq = m_axis_cq
        self.s_axis_cc = s_axis_cc
        self.s_axis_rq = s_axis_rq
        self.m_axis_rc = m_axis_rc

        # Hard IP ----------------------------------------------------------------------------------

        rq_tuser_width = 137 if pcie_data_width == 512 else 60

        m_axis_rc_tuser = Signal(85)
        m_axis_cq_tuser = Signal(85)
        m_axis_rc_tlast = Signal()
        m_axis_cq_tlast = Signal()
        s_axis_rq_tdata_raw  = Signal(pcie_data_width)
        s_axis_rq_tkeep_raw  = Signal(pcie_data_width//32)
        s_axis_rq_tuser_raw  = Signal(rq_tuser_width)
        s_axis_rq_tlast_raw  = Signal()
        s_axis_rq_tvalid_raw = Signal()
        s_axis_rq_tready_raw = Signal(4)
        m_axis_rc_tdata_raw  = Signal(pcie_data_width)
        m_axis_rc_tkeep_raw  = Signal(pcie_data_width//32)
        m_axis_rc_tuser_raw  = Signal(85)
        m_axis_rc_tuser_full = Signal(75)
        m_axis_rc_tlast_raw  = Signal()
        m_axis_rc_tvalid_raw = Signal()
        m_axis_rc_tready_raw = Signal(4)
        m_axis_cq_tdata_raw  = Signal(pcie_data_width)
        m_axis_cq_tkeep_raw  = Signal(pcie_data_width//32)
        m_axis_cq_tuser_raw  = Signal(85)
        m_axis_cq_tuser_full = Signal(88)
        m_axis_cq_tlast_raw  = Signal()
        m_axis_cq_tvalid_raw = Signal()
        m_axis_cq_tready_raw = Signal(4)
        s_axis_cc_tdata_raw  = Signal(pcie_data_width)
        s_axis_cc_tkeep_raw  = Signal(pcie_data_width//32)
        s_axis_cc_tuser_raw  = Signal(33)
        s_axis_cc_tlast_raw  = Signal()
        s_axis_cc_tvalid_raw = Signal()
        s_axis_cc_tready_raw = Signal(4)

        if self.mode == "Endpoint":
            msi_ports = dict(
                o_cfg_interrupt_msi_enable    = msi_enable_sys,
                i_cfg_interrupt_msi_int_valid = cfg_msi.valid,
                i_cfg_interrupt_msi_int       = cfg_msi.dat,
                o_cfg_interrupt_msi_sent      = cfg_msi.ready,
                o_cfg_interrupt_msi_fail      = Open(),
            )
        else:
            msi_ports = dict(
                o_cfg_interrupt_msi_enable    = Open(),
                i_cfg_interrupt_msi_int_valid = 0,
                i_cfg_interrupt_msi_int       = 0,
                o_cfg_interrupt_msi_sent      = Open(),
                o_cfg_interrupt_msi_fail      = Open(),
            )

        if self.mode == "RootPort":
            cfg_msg_received      = Signal()
            cfg_msg_received_type = Signal(5)
            cfg_msg_received_data = Signal(8)
            cfg_msg_ports = dict(
                o_cfg_msg_received      = cfg_msg_received,
                o_cfg_msg_received_data = cfg_msg_received_data,
                o_cfg_msg_received_type = cfg_msg_received_type,
            )
        else:
            cfg_msg_ports = dict(
                o_cfg_msg_received      = Open(),
                o_cfg_msg_received_data = Open(8),
                o_cfg_msg_received_type = Open(5),
            )

        # Direct pcie_us MSI adaptation (equivalent to legacy support wrapper).
        cfg_interrupt_msi_enable_x4 = Signal(4)
        cfg_interrupt_msi_sent      = Signal()
        cfg_interrupt_msi_fail      = Signal()
        cfg_interrupt_msi_mmenable  = Signal(12)
        cfg_interrupt_msi_int_enc   = Signal(32)
        cfg_interrupt_msi_int_valid = Signal()
        cfg_interrupt_msi_int_valid_r = Signal()
        cfg_interrupt_msi_int_valid_sh = Signal(2)
        cfg_interrupt_msi_int_valid_edge = Signal()
        cfg_interrupt_msi_int_valid_edge1 = Signal()
        cfg_interrupt_msi_int_enc_lat = Signal(32)
        cfg_interrupt_msi_int_enc_mux = Signal(32)
        self.comb += cfg_interrupt_msi_int_valid.eq(
            cfg_msi.valid & ~(cfg_interrupt_msi_sent | cfg_interrupt_msi_fail)
            if self.mode == "Endpoint" else 0
        )
        self.sync.pcie += [
            cfg_interrupt_msi_int_valid_r.eq(cfg_interrupt_msi_int_valid),
            cfg_interrupt_msi_int_valid_sh.eq(Cat(cfg_interrupt_msi_int_valid, cfg_interrupt_msi_int_valid_sh[0])),
        ]
        self.comb += cfg_interrupt_msi_int_valid_edge.eq(cfg_interrupt_msi_int_valid_sh == 0b01)
        self.comb += Case(cfg_interrupt_msi_mmenable[0:3], {
            0b000: cfg_interrupt_msi_int_enc.eq(0x00000001),
            0b001: cfg_interrupt_msi_int_enc.eq(0x00000002),
            0b010: cfg_interrupt_msi_int_enc.eq(0x00000010),
            0b011: cfg_interrupt_msi_int_enc.eq(0x00000100),
            0b100: cfg_interrupt_msi_int_enc.eq(0x00010000),
            "default": cfg_interrupt_msi_int_enc.eq(0x80000000),
        })
        self.sync.pcie += [
            If(cfg_interrupt_msi_int_valid_edge,
                cfg_interrupt_msi_int_enc_lat.eq(cfg_interrupt_msi_int_enc)
            ).Elif(cfg_interrupt_msi_sent,
                cfg_interrupt_msi_int_enc_lat.eq(0)
            ),
            If(ResetSignal("pcie"),
                cfg_interrupt_msi_int_valid_edge1.eq(0)
            ).Else(
                cfg_interrupt_msi_int_valid_edge1.eq(cfg_interrupt_msi_int_valid_edge)
            )
        ]
        self.comb += cfg_interrupt_msi_int_enc_mux.eq(Mux(cfg_interrupt_msi_int_valid_edge1, cfg_interrupt_msi_int_enc_lat, 0))
        self.comb += [
            msi_enable_sys.eq(cfg_interrupt_msi_enable_x4[0]),
            m_axis_rc_tuser_raw.eq(Cat(m_axis_rc_tuser_full, C(0, 10))),
            m_axis_cq_tuser_raw.eq(m_axis_cq_tuser_full[:85]),
        ]
        if self.mode == "Endpoint":
            self.comb += cfg_msi.ready.eq(cfg_interrupt_msi_sent)

        self.pcie_phy_params = dict(
            # Parameters ---------------------------------------------------------------------------
            p_LINK_CAP_MAX_LINK_WIDTH          = nlanes,
            p_C_DATA_WIDTH                     = pcie_data_width,
            p_KEEP_WIDTH                       = pcie_data_width//8,
            p_PCIE_GT_DEVICE                   = "GTH",
            p_PCIE_USE_MODE                    = "2.0",

            # PCI Express Interface ----------------------------------------------------------------
            # Clk / Rst
            i_sys_clk                          = pcie_refclk,
            i_sys_clk_gt                       = pcie_refclk_gt,
            i_sys_rst_n                        = pcie_rst_n,

            # TX
            o_pci_exp_txp                      = pads.tx_p,
            o_pci_exp_txn                      = pads.tx_n,
            # RX
            i_pci_exp_rxp                      = pads.rx_p,
            i_pci_exp_rxn                      = pads.rx_n,

            # AXI-S Interface ----------------------------------------------------------------------
            # Common
            o_user_clk_out                     = ClockSignal("pcie"),
            o_user_reset_out                   = ResetSignal("pcie"),
            o_user_lnk_up                      = link_status_sys,
            o_user_app_rdy                     = Open(),

            # (FPGA -> Host) Requester Request
            o_pcie_tfc_nph_av                  = Open(2),
            o_pcie_tfc_npd_av                  = Open(2),
            o_pcie_rq_tag_av                   = Open(2),
            o_pcie_rq_seq_num                  = Open(4),
            o_pcie_rq_seq_num_vld              = Open(),
            o_pcie_rq_tag                      = Open(6),
            o_pcie_rq_tag_vld                  = Open(),
            i_s_axis_rq_tvalid                 = s_axis_rq_tvalid_raw,
            i_s_axis_rq_tlast                  = s_axis_rq_tlast_raw,
            o_s_axis_rq_tready                 = s_axis_rq_tready_raw,
            i_s_axis_rq_tdata                  = s_axis_rq_tdata_raw,
            i_s_axis_rq_tkeep                  = s_axis_rq_tkeep_raw,
            i_s_axis_rq_tuser                  = s_axis_rq_tuser_raw,

            # (Host -> FPGA) Completer Request
            i_pcie_cq_np_req                   = 1,
            o_pcie_cq_np_req_count             = Open(6),
            o_m_axis_cq_tvalid                 = m_axis_cq_tvalid_raw,
            o_m_axis_cq_tlast                  = m_axis_cq_tlast_raw,
            i_m_axis_cq_tready                 = m_axis_cq_tready_raw,
            o_m_axis_cq_tdata                  = m_axis_cq_tdata_raw,
            o_m_axis_cq_tkeep                  = m_axis_cq_tkeep_raw,
            o_m_axis_cq_tuser                  = m_axis_cq_tuser_raw,

            # (Host -> FPGA) Requester Completion
            o_m_axis_rc_tvalid                 = m_axis_rc_tvalid_raw,
            o_m_axis_rc_tlast                  = m_axis_rc_tlast_raw,
            i_m_axis_rc_tready                 = m_axis_rc_tready_raw,
            o_m_axis_rc_tdata                  = m_axis_rc_tdata_raw,
            o_m_axis_rc_tkeep                  = m_axis_rc_tkeep_raw,
            o_m_axis_rc_tuser                  = m_axis_rc_tuser_raw,

            # (FPGA -> Host) Completer Completion
            i_s_axis_cc_tvalid                 = s_axis_cc_tvalid_raw,
            i_s_axis_cc_tlast                  = s_axis_cc_tlast_raw,
            o_s_axis_cc_tready                 = s_axis_cc_tready_raw,
            i_s_axis_cc_tdata                  = s_axis_cc_tdata_raw,
            i_s_axis_cc_tkeep                  = s_axis_cc_tkeep_raw,
            i_s_axis_cc_tuser                  = s_axis_cc_tuser_raw,

            # Management Interface -----------------------------------------------------------------
            o_cfg_mgmt_do                      = Open(32),
            o_cfg_mgmt_rd_wr_done              = Open(),
            i_cfg_mgmt_di                      = 0,
            i_cfg_mgmt_byte_en                 = 0,
            i_cfg_mgmt_dwaddr                  = 0,
            i_cfg_mgmt_wr_en                   = 0,
            i_cfg_mgmt_rd_en                   = 0,

            # Flow Control & Status ----------------------------------------------------------------
            o_cfg_fc_cpld                      = Open(12),
            o_cfg_fc_cplh                      = Open(8),
            o_cfg_fc_npd                       = Open(12),
            o_cfg_fc_nph                       = Open(8),
            o_cfg_fc_pd                        = Open(12),
            o_cfg_fc_ph                        = Open(8),
            i_cfg_fc_sel                       = 0, # Use PF0

            # Configuration Tx/Rx Message ----------------------------------------------------------
            i_cfg_msg_transmit                 = 0,
            i_cfg_msg_transmit_data            = 0,
            i_cfg_msg_transmit_type            = 0,
            o_cfg_msg_transmit_done            = Open(),

            # Configuration Control Interface ------------------------------------------------------
            # Hot config
            o_pl_received_hot_rst              = Open(),
            i_pl_transmit_hot_rst              = 0,

            # Identification & Routing -------------------------------------------------------------
            i_cfg_dsn                          = serial_number,
            i_cfg_ds_bus_number                = bus_number,
            i_cfg_ds_device_number             = device_number,
            i_cfg_ds_function_number           = function_number,
            i_cfg_ds_port_number               = 0,
            i_cfg_subsys_vend_id               = 0x10ee,

            # Power-Down Request TLP ---------------------------------------------------------------
            i_cfg_power_state_change_ack       = 0,
            o_cfg_power_state_change_interrupt = Open(),

            # Interrupt Signals --------------------------------------------------------------------
            i_cfg_interrupt_int                = 0,
            i_cfg_interrupt_pending            = 0,
            o_cfg_interrupt_sent               = Open(),

            o_cfg_interrupt_msi_mmenable       = Open(12),
            o_cfg_interrupt_msi_mask_update    = Open(),
            o_cfg_interrupt_msi_data           = Open(32),
            o_cfg_interrupt_msi_vf_enable      = Open(8),

            # Error Reporting Interface ------------------------------------------------------------
            o_cfg_phy_link_down                = link_phy_down_sys,
            o_cfg_phy_link_status              = link_phy_status_sys,
            o_cfg_negotiated_width             = link_width_sys,
            o_cfg_current_speed                = link_rate_sys,
            o_cfg_max_payload                  = cfg_max_payload_sys,
            o_cfg_max_read_req                 = cfg_max_read_req_sys,
            o_cfg_function_status              = cfg_function_status_sys,
            o_cfg_function_power_state         = Open(12),
            o_cfg_vf_status                    = Open(16),
            o_cfg_vf_power_state               = Open(24),
            o_cfg_link_power_state             = Open(2),

            o_cfg_err_cor_out                  = Open(),
            o_cfg_err_nonfatal_out             = Open(),
            o_cfg_err_fatal_out                = Open(),
            o_cfg_ltr_enable                   = Open(),
            o_cfg_ltssm_state                  = link_ltssm_sys,
            o_cfg_rcb_status                   = Open(4),
            o_cfg_dpa_substate_change          = Open(4),
            o_cfg_obff_enable                  = Open(2),
            o_cfg_pl_status_change             = Open(),

            o_cfg_tph_requester_enable         = Open(4),
            o_cfg_tph_st_mode                  = Open(12),
            o_cfg_vf_tph_requester_enable      = Open(8),
            o_cfg_vf_tph_st_mode               = Open(24),
        )

        self.pcie_phy_params.update(msi_ports)
        self.pcie_phy_params.update(cfg_msg_ports)

        # Direct pcie_us instantiation (US only, wrapper-less path).
        self.pcie_us_phy_params = dict(
            # PCI Express Interface ---------------------------------------------------------------
            i_sys_clk                          = pcie_refclk,
            i_sys_clk_gt                       = pcie_refclk_gt,
            i_sys_reset                        = pcie_rst_n,
            o_pci_exp_txp                      = pads.tx_p,
            o_pci_exp_txn                      = pads.tx_n,
            i_pci_exp_rxp                      = pads.rx_p,
            i_pci_exp_rxn                      = pads.rx_n,
            o_int_qpll1lock_out                = Open(),
            o_int_qpll1outrefclk_out           = Open(),
            o_int_qpll1outclk_out              = Open(),

            # AXI-S ------------------------------------------------------------------------------
            o_user_clk                         = ClockSignal("pcie"),
            o_user_reset                       = ResetSignal("pcie"),
            o_user_lnk_up                      = link_status_sys,
            o_phy_rdy_out                      = Open(),

            i_s_axis_rq_tvalid                 = s_axis_rq_tvalid_raw,
            i_s_axis_rq_tlast                  = s_axis_rq_tlast_raw,
            o_s_axis_rq_tready                 = s_axis_rq_tready_raw,
            i_s_axis_rq_tdata                  = s_axis_rq_tdata_raw,
            i_s_axis_rq_tkeep                  = s_axis_rq_tkeep_raw,
            i_s_axis_rq_tuser                  = s_axis_rq_tuser_raw,

            o_m_axis_rc_tdata                  = m_axis_rc_tdata_raw,
            o_m_axis_rc_tuser                  = m_axis_rc_tuser_full,
            o_m_axis_rc_tlast                  = m_axis_rc_tlast_raw,
            o_m_axis_rc_tkeep                  = m_axis_rc_tkeep_raw,
            o_m_axis_rc_tvalid                 = m_axis_rc_tvalid_raw,
            i_m_axis_rc_tready                 = m_axis_rc_tready_raw,

            o_m_axis_cq_tdata                  = m_axis_cq_tdata_raw,
            o_m_axis_cq_tuser                  = m_axis_cq_tuser_full,
            o_m_axis_cq_tlast                  = m_axis_cq_tlast_raw,
            o_m_axis_cq_tkeep                  = m_axis_cq_tkeep_raw,
            o_m_axis_cq_tvalid                 = m_axis_cq_tvalid_raw,
            i_m_axis_cq_tready                 = m_axis_cq_tready_raw,

            i_s_axis_cc_tdata                  = s_axis_cc_tdata_raw,
            i_s_axis_cc_tuser                  = s_axis_cc_tuser_raw,
            i_s_axis_cc_tlast                  = s_axis_cc_tlast_raw,
            i_s_axis_cc_tkeep                  = s_axis_cc_tkeep_raw,
            i_s_axis_cc_tvalid                 = s_axis_cc_tvalid_raw,
            o_s_axis_cc_tready                 = s_axis_cc_tready_raw,

            # Sequence & Tag ---------------------------------------------------------------------
            i_pcie_cq_np_req                   = 1,
            o_pcie_rq_tag_av                   = Open(4),

            # Error reporting / status -----------------------------------------------------------
            o_cfg_phy_link_down                = link_phy_down_sys,
            o_cfg_phy_link_status              = link_phy_status_sys,
            o_cfg_negotiated_width             = link_width_sys,
            o_cfg_current_speed                = link_rate_sys,
            o_cfg_max_payload                  = cfg_max_payload_sys,
            o_cfg_max_read_req                 = cfg_max_read_req_sys,
            o_cfg_function_status              = cfg_function_status_sys,
            o_cfg_function_power_state         = Open(12),
            o_cfg_link_power_state             = Open(2),
            o_cfg_err_cor_out                  = Open(),
            o_cfg_err_nonfatal_out             = Open(),
            o_cfg_err_fatal_out                = Open(),
            o_cfg_ltr_enable                   = Open(),
            o_cfg_ltssm_state                  = link_ltssm_sys,
            o_cfg_rcb_status                   = Open(4),
            o_cfg_dpa_substate_change          = Open(4),
            o_cfg_obff_enable                  = Open(2),
            o_cfg_pl_status_change             = Open(),
            o_cfg_tph_requester_enable         = Open(4),
            o_cfg_tph_st_mode                  = Open(12),

            # Management -------------------------------------------------------------------------
            i_cfg_mgmt_addr                    = 0,
            i_cfg_mgmt_write                   = 0,
            i_cfg_mgmt_write_data              = 0,
            i_cfg_mgmt_byte_enable             = 0,
            i_cfg_mgmt_read                    = 0,
            o_cfg_mgmt_read_data               = Open(32),
            o_cfg_mgmt_read_write_done         = Open(),
            i_cfg_mgmt_type1_cfg_reg_access    = 0,

            # Flow / messages -------------------------------------------------------------------
            o_pcie_tfc_nph_av                  = Open(4),
            o_pcie_tfc_npd_av                  = Open(4),
            o_cfg_msg_received                 = cfg_msg_ports["o_cfg_msg_received"],
            o_cfg_msg_received_data            = cfg_msg_ports["o_cfg_msg_received_data"],
            o_cfg_msg_received_type            = cfg_msg_ports["o_cfg_msg_received_type"],
            i_cfg_msg_transmit                 = 0,
            i_cfg_msg_transmit_type            = 0,
            i_cfg_msg_transmit_data            = 0,
            o_cfg_msg_transmit_done            = Open(),
            o_cfg_fc_ph                        = Open(8),
            o_cfg_fc_pd                        = Open(12),
            o_cfg_fc_nph                       = Open(8),
            o_cfg_fc_npd                       = Open(12),
            o_cfg_fc_cplh                      = Open(8),
            o_cfg_fc_cpld                      = Open(12),
            i_cfg_fc_sel                       = 0,
            i_cfg_per_func_status_control      = 0,
            o_cfg_per_func_status_data         = Open(16),

            # Control / power -------------------------------------------------------------------
            i_cfg_hot_reset_in                 = 0,
            o_cfg_hot_reset_out                = Open(),
            i_cfg_per_function_number          = 0,
            i_cfg_per_function_output_request  = 0,
            o_cfg_per_function_update_done     = Open(),
            i_cfg_power_state_change_ack       = 0,
            o_cfg_power_state_change_interrupt = Open(),
            i_cfg_err_cor_in                   = 0,
            i_cfg_err_uncor_in                 = 0,
            o_cfg_flr_in_process               = Open(4),
            i_cfg_flr_done                     = 0,
            o_cfg_vf_flr_in_process            = Open(8),
            i_cfg_vf_flr_done                  = 0,
            o_cfg_local_error                  = Open(),
            i_cfg_link_training_enable         = 1,
            i_cfg_config_space_enable          = 1,
            i_cfg_req_pm_transition_l23_ready  = 0,

            # Identification --------------------------------------------------------------------
            i_cfg_dsn                          = serial_number,
            i_cfg_ds_bus_number                = bus_number,
            i_cfg_ds_device_number             = device_number,
            i_cfg_ds_function_number           = function_number,
            i_cfg_ds_port_number               = 0,
            i_cfg_subsys_vend_id               = 0x10ee,

            # Interrupts ------------------------------------------------------------------------
            i_cfg_interrupt_int                              = 0,
            i_cfg_interrupt_pending                          = 0,
            o_cfg_interrupt_sent                             = Open(),
            o_cfg_interrupt_msi_enable                       = cfg_interrupt_msi_enable_x4,
            i_cfg_interrupt_msi_int                          = cfg_interrupt_msi_int_enc_mux,
            o_cfg_interrupt_msi_sent                         = cfg_interrupt_msi_sent,
            o_cfg_interrupt_msi_fail                         = cfg_interrupt_msi_fail,
            o_cfg_interrupt_msi_mmenable                     = cfg_interrupt_msi_mmenable,
            o_cfg_interrupt_msi_mask_update                  = Open(),
            o_cfg_interrupt_msi_data                         = Open(32),
            i_cfg_interrupt_msi_select                       = 0,
            i_cfg_interrupt_msi_pending_status               = cfg_interrupt_msi_int_enc_lat,
            i_cfg_interrupt_msi_attr                         = 0,
            i_cfg_interrupt_msi_tph_present                  = 0,
            i_cfg_interrupt_msi_tph_type                     = 0,
            i_cfg_interrupt_msi_tph_st_tag                   = 0,
            i_cfg_interrupt_msi_pending_status_function_num  = 0,
            i_cfg_interrupt_msi_pending_status_data_enable   = 0,
            i_cfg_interrupt_msi_function_number              = 0,

            # Perst pass-through -----------------------------------------------------------------
            o_pcie_perstn0_out                 = Open(),
            i_pcie_perstn1_in                  = 0,
            o_pcie_perstn1_out                 = Open(),
        )

        self.m_axis_cq_adapt = m_axis_cq_adapt = ClockDomainsRenamer("pcie")(MAxisCQAdapter(pcie_data_width))
        self.comb += [
            m_axis_cq_adapt.s_axis_tdata.eq(m_axis_cq_tdata_raw),
            m_axis_cq_adapt.s_axis_tkeep.eq(m_axis_cq_tkeep_raw),
            m_axis_cq_adapt.s_axis_tuser.eq(m_axis_cq_tuser_raw),
            m_axis_cq_adapt.s_axis_tlast.eq(m_axis_cq_tlast_raw),
            m_axis_cq_adapt.s_axis_tvalid.eq(m_axis_cq_tvalid_raw),
            m_axis_cq_tready_raw.eq(m_axis_cq_adapt.s_axis_tready),

            m_axis_cq.dat.eq(m_axis_cq_adapt.m_axis_tdata),
            m_axis_cq.be.eq(m_axis_cq_adapt.m_axis_tkeep),
            m_axis_cq_tuser.eq(m_axis_cq_adapt.m_axis_tuser),
            m_axis_cq_tlast.eq(m_axis_cq_adapt.m_axis_tlast),
            m_axis_cq.valid.eq(m_axis_cq_adapt.m_axis_tvalid),
            m_axis_cq_adapt.m_axis_tready.eq(m_axis_cq.ready),
            m_axis_cq.first.eq(m_axis_cq_tuser[14]),
            m_axis_cq.last.eq(m_axis_cq_tlast),
        ]

        self.m_axis_rc_adapt = m_axis_rc_adapt = ClockDomainsRenamer("pcie")(MAxisRCAdapter(pcie_data_width))
        self.comb += [
            m_axis_rc_adapt.s_axis_tdata.eq(m_axis_rc_tdata_raw),
            m_axis_rc_adapt.s_axis_tkeep.eq(m_axis_rc_tkeep_raw),
            m_axis_rc_adapt.s_axis_tuser.eq(m_axis_rc_tuser_raw),
            m_axis_rc_adapt.s_axis_tlast.eq(m_axis_rc_tlast_raw),
            m_axis_rc_adapt.s_axis_tvalid.eq(m_axis_rc_tvalid_raw),
            m_axis_rc_tready_raw.eq(m_axis_rc_adapt.s_axis_tready),

            m_axis_rc.dat.eq(m_axis_rc_adapt.m_axis_tdata),
            m_axis_rc.be.eq(m_axis_rc_adapt.m_axis_tkeep),
            m_axis_rc_tuser.eq(m_axis_rc_adapt.m_axis_tuser),
            m_axis_rc_tlast.eq(m_axis_rc_adapt.m_axis_tlast),
            m_axis_rc.valid.eq(m_axis_rc_adapt.m_axis_tvalid),
            m_axis_rc_adapt.m_axis_tready.eq(m_axis_rc.ready),
            m_axis_rc.first.eq(m_axis_rc_adapt.m_axis_sop),
            m_axis_rc.last.eq(m_axis_rc_tlast),
        ]

        self.s_axis_cc_adapt = s_axis_cc_adapt = ClockDomainsRenamer("pcie")(SAxisCCAdapter(pcie_data_width))
        self.comb += [
            s_axis_cc_adapt.s_axis_tdata.eq(s_axis_cc.dat),
            s_axis_cc_adapt.s_axis_tkeep.eq(s_axis_cc.be),
            s_axis_cc_adapt.s_axis_tlast.eq(s_axis_cc.last),
            s_axis_cc_adapt.s_axis_tuser.eq(Constant(0b0000)),
            s_axis_cc_adapt.s_axis_tvalid.eq(s_axis_cc.valid),
            s_axis_cc.ready.eq(s_axis_cc_adapt.s_axis_tready),

            s_axis_cc_tdata_raw.eq(s_axis_cc_adapt.m_axis_tdata),
            s_axis_cc_tkeep_raw.eq(s_axis_cc_adapt.m_axis_tkeep),
            s_axis_cc_tlast_raw.eq(s_axis_cc_adapt.m_axis_tlast),
            s_axis_cc_tuser_raw.eq(s_axis_cc_adapt.m_axis_tuser),
            s_axis_cc_tvalid_raw.eq(s_axis_cc_adapt.m_axis_tvalid),
            s_axis_cc_adapt.m_axis_tready.eq(s_axis_cc_tready_raw[0]),
        ]

        self.s_axis_rq_adapt = s_axis_rq_adapt = ClockDomainsRenamer("pcie")(SAxisRQAdapter(pcie_data_width))
        self.comb += [
            s_axis_rq_adapt.s_axis_tdata.eq(s_axis_rq.dat),
            s_axis_rq_adapt.s_axis_tkeep.eq(s_axis_rq.be),
            s_axis_rq_adapt.s_axis_tlast.eq(s_axis_rq.last),
            s_axis_rq_adapt.s_axis_tuser.eq(Constant(0b0000)),
            s_axis_rq_adapt.s_axis_tvalid.eq(s_axis_rq.valid),
            s_axis_rq.ready.eq(s_axis_rq_adapt.s_axis_tready),

            s_axis_rq_tdata_raw.eq(s_axis_rq_adapt.m_axis_tdata),
            s_axis_rq_tkeep_raw.eq(s_axis_rq_adapt.m_axis_tkeep),
            s_axis_rq_tlast_raw.eq(s_axis_rq_adapt.m_axis_tlast),
            s_axis_rq_tuser_raw.eq(s_axis_rq_adapt.m_axis_tuser),
            s_axis_rq_tvalid_raw.eq(s_axis_rq_adapt.m_axis_tvalid),
            s_axis_rq_adapt.m_axis_tready.eq(s_axis_rq_tready_raw[0]),
        ]

    # Resync Helper --------------------------------------------------------------------------------
    def add_resync(self, sig, clk="sys"):
        _sig = Signal.like(sig)
        self.specials += MultiReg(_sig, sig, clk)
        return _sig

    # LTSSM Tracer ---------------------------------------------------------------------------------
    def add_ltssm_tracer(self):
        self.ltssm_tracer = LTSSMTracer(self._link_status.fields.ltssm)

    # Hard IP sources ------------------------------------------------------------------------------
    def update_config(self, config):
        self.config.update(config)

    def add_sources(self, platform, phy_path=None, phy_filename=None):
        if phy_filename is not None:
            platform.add_ip(os.path.join(phy_path, phy_filename))
        else:
            # Link / clocks (speed-dependent).
            link_speed   = {"gen2": "5.0_GT/s", "gen3": "8.0_GT/s"}[self.speed]
            axisten_freq = {"gen2": 125,        "gen3": 250       }[self.speed]
            coreclk_freq = {"gen2": 250,        "gen3": 500       }[self.speed]

            # Device identification.
            device_id_base = {"gen2": 8020, "gen3": 8030}[self.speed]
            device_id      = device_id_base + self.nlanes

            # Port type / class code (mode-dependent).
            port_type  = "PCI_Express_Endpoint_device"
            class_code = None
            if self.mode == "RootPort":
                port_type  = "Root_Port_of_PCI_Express_Root_Complex"
                class_code = 0x060400

            # BAR0.
            bar0_scale = "Megabytes"
            bar0_size  = max(self.bar0_size/MB, 1)

            # AXI-S / interface.
            axisten_if_width       = f"{self.pcie_data_width}_bit"
            axisten_rc_straddle    = False
            enable_client_tag      = True

            # Power management.
            aspm_support = "No_ASPM"

            # PLL selection.
            plltype = "QPLL1"

            config = {
                # Core.
                "Component_Name"               : "pcie_us",
                "DEVICE_PORT_TYPE"             : port_type,
                "PF0_DEVICE_ID"                : device_id,

                # Link.
                "PL_LINK_CAP_MAX_LINK_WIDTH"   : f"X{self.nlanes}",
                "PL_LINK_CAP_MAX_LINK_SPEED"   : link_speed,

                # AXI-S.
                "axisten_if_width"             : axisten_if_width,
                "AXISTEN_IF_RC_STRADDLE"       : axisten_rc_straddle,
                "axisten_freq"                 : axisten_freq,
                "coreclk_freq"                 : coreclk_freq,
                "axisten_if_enable_client_tag" : enable_client_tag,

                # Power / features.
                "aspm_support"                 : aspm_support,
                "plltype"                      : plltype,

                # BAR0.
                "pf0_bar0_scale"               : bar0_scale,
                "pf0_bar0_size"                : bar0_size,

                # Interrupts.
                "PF0_INTERRUPT_PIN"            : "NONE",
            }

            if class_code is not None:
                config["PF0_CLASS_CODE"] = class_code

            # User/Custom config.
            config.update(self.config)

            # Tcl generation.
            ip_tcl = []
            ip_tcl.append("create_ip -vendor xilinx.com -name pcie3_ultrascale -module_name pcie_us")
            ip_tcl.append("set obj [get_ips pcie_us]")
            ip_tcl.append("set_property -dict [list \\")
            for config, value in config.items():
                ip_tcl.append("CONFIG.{} {} \\".format(config, '{{' + str(value) + '}}'))
            ip_tcl.append(f"] $obj")
            ip_tcl.append("synth_ip $obj")
            platform.toolchain.pre_synthesis_commands += ip_tcl

        verilog_path = os.path.join(os.path.abspath(os.path.dirname(__file__)), "xilinx")

        # No support-wrapper Verilog source required in direct mode.


    # External Hard IP -----------------------------------------------------------------------------
    def use_external_hard_ip(self, hard_ip_path, hard_ip_filename):
        self.external_hard_ip = True
        self.add_sources(self.platform, hard_ip_path, hard_ip_filename)

    # Finalize -------------------------------------------------------------------------------------
    def do_finalize(self):
        if not self.external_hard_ip:
            self.add_sources(self.platform)
        self.specials += Instance("pcie_us", **self.pcie_us_phy_params)

```

`litepcie/phy/usppciephy.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2020-2023 Enjoy-Digital <enjoy-digital.fr>
# Copyright (c) 2022 Sylvain Munaut <tnt@246tNt.com>
# Copyright (c) 2024 John Simons <jammsimons@gmail.com>
# SPDX-License-Identifier: BSD-2-Clause

import os

from migen import *
from migen.genlib.cdc import MultiReg

from litex.gen import *

from litex.soc.interconnect.csr import *

from litepcie.common import *
from litepcie.phy.common import *
from litepcie.phy.axis_adapters import MAxisCQAdapter, MAxisRCAdapter, SAxisCCAdapter, SAxisRQAdapter

# USPPCIEPHY ---------------------------------------------------------------------------------------

class USPPCIEPHY(LiteXModule):
    endianness    = "little"
    qword_aligned = False
    def __init__(self, platform, pads, speed="gen3", data_width=64, cd="sys",
        # PCIe hardblock parameters.
        ip_name         = "pcie4_uscale_plus",
        pcie_data_width = None,
        bar0_size       = 0x100000,
        mode            = "Endpoint",
    ):
        # Streams ----------------------------------------------------------------------------------
        self.req_sink   = stream.Endpoint(phy_layout(data_width))
        self.cmp_sink   = stream.Endpoint(phy_layout(data_width))
        self.req_source = stream.Endpoint(phy_layout(data_width))
        self.cmp_source = stream.Endpoint(phy_layout(data_width))
        self.msi        = stream.Endpoint(msi_layout())

        # Registers --------------------------------------------------------------------------------
        self._link_status = CSRStatus(fields=[
            CSRField("status", size=1, values=[
                ("``0b0``", "Link Down."),
                ("``0b1``", "Link Up."),
            ]),
            CSRField("phy_down", size=1, values=[
                ("``0b0``", "PHY Link Up."),
                ("``0b1``", "PHY Link Down."),
            ]),
            CSRField("phy_status", size=2, values=[
                ("``00b``", "No receivers detected."),
                ("``01b``", "Link training in progress."),
                ("``10b``", "Link up, DL initialization in progress."),
                ("``11b``", "Link up, DL initialization completed."),
            ]),
            CSRField("rate", size=2, values=[
                ("``0b00``", "2.5 GT/s."),
                ("``0b01``", "5.0 GT/s."),
                ("``0b10``", "8.0 GT/s."),
            ]),
            CSRField("width", size=3, values=[
                ("``0b000``", "1-Lane link."),
                ("``0b001``", "2-Lane link."),
                ("``0b010``", "4-Lane link."),
                ("``0b011``", "8-Lane link."),
                ("``0b100``", "16-Lane link."),
            ]),
            CSRField("ltssm", size=6, description="LTSSM State"),
        ])
        self._msi_enable        = CSRStatus(description="MSI Enable Status. ``1``: MSI is enabled.")
        self._bus_master_enable = CSRStatus(description="Bus Mastering Status. ``1``: Bus Mastering enabled.")
        self._max_request_size  = CSRStatus(16, description="Negiotiated Max Request Size (in bytes).")
        self._max_payload_size  = CSRStatus(16, description="Negiotiated Max Payload Size (in bytes).")

        # Parameters/Locals ------------------------------------------------------------------------
        assert mode in ["Endpoint", "RootPort"]
        self.mode = mode

        if pcie_data_width is None: pcie_data_width = data_width
        self.platform         = platform
        self.data_width       = data_width
        self.pcie_data_width  = pcie_data_width
        assert ip_name  in ["pcie4_uscale_plus", "pcie4c_uscale_plus"]
        self.ip_name          = ip_name

        self.id               = Signal(16)
        self.bar0_size        = bar0_size
        self.bar0_mask        = get_bar_mask(bar0_size)
        self.max_request_size = Signal(16)
        self.max_payload_size = Signal(16)

        self.config           = {}
        self.external_hard_ip = False

        # # #

        self.speed  = speed
        self.nlanes = nlanes = len(pads.tx_p)

        assert speed           in ["gen2", "gen3", "gen4"]
        assert nlanes          in [1, 2, 4, 8, 16]
        assert data_width      in [64, 128, 256, 512]
        assert pcie_data_width in [64, 128, 256, 512]

        # Clocking / Reset -------------------------------------------------------------------------
        self.pcie_refclk    = pcie_refclk    = Signal()
        self.pcie_refclk_gt = pcie_refclk_gt = Signal()
        self.pcie_rst_n     = pcie_rst_n     = Signal(reset=1)
        if hasattr(pads, "rst_n"):
            self.comb += pcie_rst_n.eq(pads.rst_n)
        self.specials += Instance("IBUFDS_GTE4",
            p_REFCLK_HROW_CK_SEL = 0,
            i_CEB   = 0,
            i_I     = pads.clk_p,
            i_IB    = pads.clk_n,
            o_O     = pcie_refclk_gt,
            o_ODIV2 = pcie_refclk
        )
        platform.add_period_constraint(pads.clk_p, 1e9/100e6)
        self.cd_pcie = ClockDomain()

        # TX (FPGA --> HOST) CDC / Data Width Conversion -------------------------------------------
        self.cc_datapath = PHYTXDatapath(
            core_data_width = data_width,
            pcie_data_width = pcie_data_width,
            clock_domain    = cd)
        self.comb += self.cmp_sink.connect(self.cc_datapath.sink)
        s_axis_cc = self.cc_datapath.source

        self.rq_datapath = PHYTXDatapath(
            core_data_width = data_width,
            pcie_data_width = pcie_data_width,
            clock_domain    = cd)
        self.comb += self.req_sink.connect(self.rq_datapath.sink)
        s_axis_rq = self.rq_datapath.source

        # RX (HOST --> FPGA) CDC / Data Width Conversion -------------------------------------------
        self.cq_datapath = PHYRXDatapath(
            core_data_width = data_width,
            pcie_data_width = pcie_data_width,
            clock_domain    = cd)
        m_axis_cq = self.cq_datapath.sink
        self.comb += self.cq_datapath.source.connect(self.req_source)

        self.rc_datapath = PHYRXDatapath(
            core_data_width = data_width,
            pcie_data_width = pcie_data_width,
            clock_domain    = cd)
        m_axis_rc = self.rc_datapath.sink
        self.comb += self.rc_datapath.source.connect(self.cmp_source)

        # MSI CDC ----------------------------------------------------------------------------------
        if self.mode == "Endpoint":
            if cd == "pcie":
                cfg_msi = self.msi
            else:
                self.msi_cdc = msi_cdc = stream.ClockDomainCrossing(
                    layout          = msi_layout(),
                    cd_from         = cd,
                    cd_to           = "pcie",
                    with_common_rst = True,
                )
                self.comb += self.msi.connect(msi_cdc.sink)
                cfg_msi = msi_cdc.source
        else:
            cfg_msi = None

        # Hard IP Configuration --------------------------------------------------------------------

        def convert_size(command, size, max_size):
            cases = {}
            value = 128
            for i in range(6):
                cases[i] = size.eq(value)
                value = min(value*2, max_size)
            return Case(command, cases)

        serial_number   = Signal(64)
        bus_number      = Signal(8)
        device_number   = Signal(5)
        function_number = Signal(3)

        cfg_function_status  = Signal(16)
        cfg_max_payload_size = Signal(3)
        cfg_max_read_req     = Signal(3)
        link_status_sys      = self.add_resync(self._link_status.fields.status, "sys")
        link_phy_down_sys    = self.add_resync(self._link_status.fields.phy_down, "sys")
        link_phy_status_sys  = self.add_resync(self._link_status.fields.phy_status, "sys")
        link_width_sys       = self.add_resync(self._link_status.fields.width, "sys")
        link_rate_sys        = self.add_resync(self._link_status.fields.rate, "sys")
        link_ltssm_sys       = self.add_resync(self._link_status.fields.ltssm, "sys")
        cfg_max_payload_sys  = self.add_resync(cfg_max_payload_size, "sys")
        cfg_max_read_req_sys = self.add_resync(cfg_max_read_req, "sys")
        cfg_function_status_sys = self.add_resync(cfg_function_status, "sys")
        msi_enable_sys       = self.add_resync(self._msi_enable.status, "sys")

        self.comb += [
            convert_size(cfg_max_read_req,     self.max_request_size, max_size=512),
            convert_size(cfg_max_payload_size, self.max_payload_size, max_size=512),
            self.id.eq(Cat(function_number, device_number, bus_number))
        ]
        self.comb += [
            self._bus_master_enable.status.eq(cfg_function_status),
            self._max_request_size.status.eq(self.max_request_size),
            self._max_payload_size.status.eq(self.max_payload_size),
        ]

        self.m_axis_cq = m_axis_cq
        self.s_axis_cc = s_axis_cc
        self.s_axis_rq = s_axis_rq
        self.m_axis_rc = m_axis_rc

        # Hard IP ----------------------------------------------------------------------------------

        rq_tuser_width = 137 if pcie_data_width == 512 else 60

        m_axis_rc_tuser = Signal(85)
        m_axis_cq_tuser = Signal(85)
        m_axis_rc_tlast = Signal()
        m_axis_cq_tlast = Signal()
        s_axis_rq_tdata_raw  = Signal(pcie_data_width)
        s_axis_rq_tkeep_raw  = Signal(pcie_data_width//32)
        s_axis_rq_tuser_raw  = Signal(rq_tuser_width)
        s_axis_rq_tlast_raw  = Signal()
        s_axis_rq_tvalid_raw = Signal()
        s_axis_rq_tready_raw = Signal(4)
        m_axis_rc_tdata_raw  = Signal(pcie_data_width)
        m_axis_rc_tkeep_raw  = Signal(pcie_data_width//32)
        m_axis_rc_tuser_raw  = Signal(85)
        m_axis_rc_tuser_full = Signal(75)
        m_axis_rc_tlast_raw  = Signal()
        m_axis_rc_tvalid_raw = Signal()
        m_axis_rc_tready_raw = Signal(4)
        m_axis_cq_tdata_raw  = Signal(pcie_data_width)
        m_axis_cq_tkeep_raw  = Signal(pcie_data_width//32)
        m_axis_cq_tuser_raw  = Signal(85)
        m_axis_cq_tuser_full = Signal(88)
        m_axis_cq_tlast_raw  = Signal()
        m_axis_cq_tvalid_raw = Signal()
        m_axis_cq_tready_raw = Signal(4)
        s_axis_cc_tdata_raw  = Signal(pcie_data_width)
        s_axis_cc_tkeep_raw  = Signal(pcie_data_width//32)
        s_axis_cc_tuser_raw  = Signal(33)
        s_axis_cc_tlast_raw  = Signal()
        s_axis_cc_tvalid_raw = Signal()
        s_axis_cc_tready_raw = Signal(4)

        if self.mode == "Endpoint":
            msi_ports = dict(
                o_cfg_interrupt_msi_enable    = msi_enable_sys,
                i_cfg_interrupt_msi_int_valid = cfg_msi.valid,
                i_cfg_interrupt_msi_int       = cfg_msi.dat,
                o_cfg_interrupt_msi_sent      = cfg_msi.ready,
                o_cfg_interrupt_msi_fail      = Open(),
            )
        else:
            msi_ports = dict(
                o_cfg_interrupt_msi_enable    = Open(),
                i_cfg_interrupt_msi_int_valid = 0,
                i_cfg_interrupt_msi_int       = 0,
                o_cfg_interrupt_msi_sent      = Open(),
                o_cfg_interrupt_msi_fail      = Open(),
            )

        if self.mode == "RootPort":
            cfg_msg_received      = Signal()
            cfg_msg_received_type = Signal(5)
            cfg_msg_received_data = Signal(8)
            cfg_msg_ports = dict(
                o_cfg_msg_received      = cfg_msg_received,
                o_cfg_msg_received_data = cfg_msg_received_data,
                o_cfg_msg_received_type = cfg_msg_received_type,
            )
        else:
            cfg_msg_ports = dict(
                o_cfg_msg_received      = Open(),
                o_cfg_msg_received_data = Open(8),
                o_cfg_msg_received_type = Open(5),
            )

        # Direct pcie_usp MSI adaptation (equivalent to legacy support wrapper).
        cfg_interrupt_msi_enable_x4 = Signal(4)
        cfg_interrupt_msi_sent      = Signal()
        cfg_interrupt_msi_fail      = Signal()
        cfg_interrupt_msi_mmenable  = Signal(12)
        cfg_interrupt_msi_int_enc   = Signal(32)
        cfg_interrupt_msi_int_valid = Signal()
        cfg_interrupt_msi_int_valid_sh = Signal(2)
        cfg_interrupt_msi_int_valid_edge = Signal()
        cfg_interrupt_msi_int_valid_edge1 = Signal()
        cfg_interrupt_msi_int_enc_lat = Signal(32)
        cfg_interrupt_msi_int_enc_mux = Signal(32)
        self.comb += cfg_interrupt_msi_int_valid.eq(
            cfg_msi.valid & ~(cfg_interrupt_msi_sent | cfg_interrupt_msi_fail)
            if self.mode == "Endpoint" else 0
        )
        self.sync.pcie += [
            cfg_interrupt_msi_int_valid_sh.eq(Cat(cfg_interrupt_msi_int_valid, cfg_interrupt_msi_int_valid_sh[0])),
        ]
        self.comb += cfg_interrupt_msi_int_valid_edge.eq(cfg_interrupt_msi_int_valid_sh == 0b01)
        self.comb += Case(cfg_interrupt_msi_mmenable[0:3], {
            0b000: cfg_interrupt_msi_int_enc.eq(0x00000001),
            0b001: cfg_interrupt_msi_int_enc.eq(0x00000002),
            0b010: cfg_interrupt_msi_int_enc.eq(0x00000010),
            0b011: cfg_interrupt_msi_int_enc.eq(0x00000100),
            0b100: cfg_interrupt_msi_int_enc.eq(0x00010000),
            "default": cfg_interrupt_msi_int_enc.eq(0x80000000),
        })
        self.sync.pcie += [
            If(cfg_interrupt_msi_int_valid_edge,
                cfg_interrupt_msi_int_enc_lat.eq(cfg_interrupt_msi_int_enc)
            ).Elif(cfg_interrupt_msi_sent,
                cfg_interrupt_msi_int_enc_lat.eq(0)
            ),
            If(ResetSignal("pcie"),
                cfg_interrupt_msi_int_valid_edge1.eq(0)
            ).Else(
                cfg_interrupt_msi_int_valid_edge1.eq(cfg_interrupt_msi_int_valid_edge)
            )
        ]
        self.comb += cfg_interrupt_msi_int_enc_mux.eq(Mux(cfg_interrupt_msi_int_valid_edge1, cfg_interrupt_msi_int_enc_lat, 0))
        self.comb += [
            msi_enable_sys.eq(cfg_interrupt_msi_enable_x4[0]),
            m_axis_rc_tuser_raw.eq(Cat(m_axis_rc_tuser_full, C(0, 10))),
            m_axis_cq_tuser_raw.eq(m_axis_cq_tuser_full[:85]),
        ]
        if self.mode == "Endpoint":
            self.comb += cfg_msi.ready.eq(cfg_interrupt_msi_sent)

        self.pcie_phy_params = dict(
            # Parameters ---------------------------------------------------------------------------
            p_LINK_CAP_MAX_LINK_WIDTH          = nlanes,
            p_C_DATA_WIDTH                     = pcie_data_width,
            p_KEEP_WIDTH                       = pcie_data_width//8,
            p_PCIE_GT_DEVICE                   = "GTY",
            p_PCIE_USE_MODE                    = "2.0",

            # PCI Express Interface ----------------------------------------------------------------
            # Clk / Rst
            i_sys_clk                          = pcie_refclk,
            i_sys_clk_gt                       = pcie_refclk_gt,
            i_sys_rst_n                        = pcie_rst_n,

            # TX
            o_pci_exp_txp                      = pads.tx_p,
            o_pci_exp_txn                      = pads.tx_n,
            # RX
            i_pci_exp_rxp                      = pads.rx_p,
            i_pci_exp_rxn                      = pads.rx_n,

            # AXI-S Interface ----------------------------------------------------------------------
            # Common
            o_user_clk_out                     = ClockSignal("pcie"),
            o_user_reset_out                   = ResetSignal("pcie"),
            o_user_lnk_up                      = link_status_sys,
            o_user_app_rdy                     = Open(),

            # (FPGA -> Host) Requester Request
            o_pcie_tfc_nph_av                  = Open(2),
            o_pcie_tfc_npd_av                  = Open(2),
            o_pcie_rq_tag_av                   = Open(2),
            o_pcie_rq_seq_num                  = Open(4),
            o_pcie_rq_seq_num_vld              = Open(),
            o_pcie_rq_tag                      = Open(6),
            o_pcie_rq_tag_vld                  = Open(),
            i_s_axis_rq_tvalid                 = s_axis_rq_tvalid_raw,
            i_s_axis_rq_tlast                  = s_axis_rq_tlast_raw,
            o_s_axis_rq_tready                 = s_axis_rq_tready_raw,
            i_s_axis_rq_tdata                  = s_axis_rq_tdata_raw,
            i_s_axis_rq_tkeep                  = s_axis_rq_tkeep_raw,
            i_s_axis_rq_tuser                  = s_axis_rq_tuser_raw,

            # (Host -> FPGA) Completer Request
            i_pcie_cq_np_req                   = 1,
            o_pcie_cq_np_req_count             = Open(6),
            o_m_axis_cq_tvalid                 = m_axis_cq_tvalid_raw,
            o_m_axis_cq_tlast                  = m_axis_cq_tlast_raw,
            i_m_axis_cq_tready                 = m_axis_cq_tready_raw,
            o_m_axis_cq_tdata                  = m_axis_cq_tdata_raw,
            o_m_axis_cq_tkeep                  = m_axis_cq_tkeep_raw,
            o_m_axis_cq_tuser                  = m_axis_cq_tuser_raw,

            # (Host -> FPGA) Requester Completion
            o_m_axis_rc_tvalid                 = m_axis_rc_tvalid_raw,
            o_m_axis_rc_tlast                  = m_axis_rc_tlast_raw,
            i_m_axis_rc_tready                 = m_axis_rc_tready_raw,
            o_m_axis_rc_tdata                  = m_axis_rc_tdata_raw,
            o_m_axis_rc_tkeep                  = m_axis_rc_tkeep_raw,
            o_m_axis_rc_tuser                  = m_axis_rc_tuser_raw,

            # (FPGA -> Host) Completer Completion
            i_s_axis_cc_tvalid                 = s_axis_cc_tvalid_raw,
            i_s_axis_cc_tlast                  = s_axis_cc_tlast_raw,
            o_s_axis_cc_tready                 = s_axis_cc_tready_raw,
            i_s_axis_cc_tdata                  = s_axis_cc_tdata_raw,
            i_s_axis_cc_tkeep                  = s_axis_cc_tkeep_raw,
            i_s_axis_cc_tuser                  = s_axis_cc_tuser_raw,

            # Management Interface -----------------------------------------------------------------
            o_cfg_mgmt_do                      = Open(32),
            o_cfg_mgmt_rd_wr_done              = Open(),
            i_cfg_mgmt_di                      = 0,
            i_cfg_mgmt_byte_en                 = 0,
            i_cfg_mgmt_dwaddr                  = 0,
            i_cfg_mgmt_wr_en                   = 0,
            i_cfg_mgmt_rd_en                   = 0,

            # Flow Control & Status ----------------------------------------------------------------
            o_cfg_fc_cpld                      = Open(12),
            o_cfg_fc_cplh                      = Open(8),
            o_cfg_fc_npd                       = Open(12),
            o_cfg_fc_nph                       = Open(8),
            o_cfg_fc_pd                        = Open(12),
            o_cfg_fc_ph                        = Open(8),
            i_cfg_fc_sel                       = 0, # Use PF0

            # Configuration Tx/Rx Message ----------------------------------------------------------
            i_cfg_msg_transmit                 = 0,
            i_cfg_msg_transmit_data            = 0,
            i_cfg_msg_transmit_type            = 0,
            o_cfg_msg_transmit_done            = Open(),

            # Configuration Control Interface ------------------------------------------------------
            # Hot config
            o_pl_received_hot_rst              = Open(),
            i_pl_transmit_hot_rst              = 0,

            # Identification & Routing -------------------------------------------------------------
            i_cfg_dsn                          = serial_number,
            i_cfg_ds_bus_number                = bus_number,
            i_cfg_ds_device_number             = device_number,
            i_cfg_ds_function_number           = function_number,
            i_cfg_ds_port_number               = 0,
            i_cfg_subsys_vend_id               = 0x10ee,

            # Power-Down Request TLP ---------------------------------------------------------------
            i_cfg_power_state_change_ack       = 0,
            o_cfg_power_state_change_interrupt = Open(),

            # Interrupt Signals --------------------------------------------------------------------
            i_cfg_interrupt_int                = 0,
            i_cfg_interrupt_pending            = 0,
            o_cfg_interrupt_sent               = Open(),

            # Error Reporting Interface ------------------------------------------------------------
            o_cfg_phy_link_down                = link_phy_down_sys,
            o_cfg_phy_link_status              = link_phy_status_sys,
            o_cfg_negotiated_width             = link_width_sys,
            o_cfg_current_speed                = link_rate_sys,
            o_cfg_max_payload                  = cfg_max_payload_sys,
            o_cfg_max_read_req                 = cfg_max_read_req_sys,
            o_cfg_function_status              = cfg_function_status_sys,
            o_cfg_function_power_state         = Open(12),
            o_cfg_vf_status                    = Open(16),
            o_cfg_vf_power_state               = Open(24),
            o_cfg_link_power_state             = Open(2),

            o_cfg_err_cor_out                  = Open(),
            o_cfg_err_nonfatal_out             = Open(),
            o_cfg_err_fatal_out                = Open(),
            o_cfg_ltr_enable                   = Open(),
            o_cfg_ltssm_state                  = link_ltssm_sys,
            o_cfg_rcb_status                   = Open(4),
            o_cfg_dpa_substate_change          = Open(4),
            o_cfg_obff_enable                  = Open(2),
            o_cfg_pl_status_change             = Open(),

            o_cfg_tph_requester_enable         = Open(4),
            o_cfg_tph_st_mode                  = Open(12),
            o_cfg_vf_tph_requester_enable      = Open(8),
            o_cfg_vf_tph_st_mode               = Open(24),
        )

        self.pcie_phy_params.update(msi_ports)
        self.pcie_phy_params.update(cfg_msg_ports)

        # Direct pcie_usp instantiation (wrapper-less path).
        self.pcie_usp_phy_params = dict(
            i_sys_clk                           = pcie_refclk,
            i_sys_clk_gt                        = pcie_refclk_gt,
            i_sys_reset                         = pcie_rst_n,

            o_pci_exp_txp                       = pads.tx_p,
            o_pci_exp_txn                       = pads.tx_n,
            i_pci_exp_rxp                       = pads.rx_p,
            i_pci_exp_rxn                       = pads.rx_n,

            o_user_clk                          = ClockSignal("pcie"),
            o_user_reset                        = ResetSignal("pcie"),
            o_user_lnk_up                       = link_status_sys,
            o_phy_rdy_out                       = Open(),

            i_s_axis_rq_tvalid                  = s_axis_rq_tvalid_raw,
            i_s_axis_rq_tlast                   = s_axis_rq_tlast_raw,
            o_s_axis_rq_tready                  = s_axis_rq_tready_raw,
            i_s_axis_rq_tdata                   = s_axis_rq_tdata_raw,
            i_s_axis_rq_tkeep                   = s_axis_rq_tkeep_raw,
            i_s_axis_rq_tuser                   = s_axis_rq_tuser_raw,

            o_m_axis_rc_tdata                   = m_axis_rc_tdata_raw,
            o_m_axis_rc_tuser                   = m_axis_rc_tuser_full,
            o_m_axis_rc_tlast                   = m_axis_rc_tlast_raw,
            o_m_axis_rc_tkeep                   = m_axis_rc_tkeep_raw,
            o_m_axis_rc_tvalid                  = m_axis_rc_tvalid_raw,
            i_m_axis_rc_tready                  = m_axis_rc_tready_raw,

            o_m_axis_cq_tdata                   = m_axis_cq_tdata_raw,
            o_m_axis_cq_tuser                   = m_axis_cq_tuser_full,
            o_m_axis_cq_tlast                   = m_axis_cq_tlast_raw,
            o_m_axis_cq_tkeep                   = m_axis_cq_tkeep_raw,
            o_m_axis_cq_tvalid                  = m_axis_cq_tvalid_raw,
            i_m_axis_cq_tready                  = m_axis_cq_tready_raw,

            i_s_axis_cc_tdata                   = s_axis_cc_tdata_raw,
            i_s_axis_cc_tuser                   = s_axis_cc_tuser_raw,
            i_s_axis_cc_tlast                   = s_axis_cc_tlast_raw,
            i_s_axis_cc_tkeep                   = s_axis_cc_tkeep_raw,
            i_s_axis_cc_tvalid                  = s_axis_cc_tvalid_raw,
            o_s_axis_cc_tready                  = s_axis_cc_tready_raw,

            i_pcie_cq_np_req                    = 1,
            o_pcie_tfc_nph_av                   = Open(4),
            o_pcie_tfc_npd_av                   = Open(4),
            o_pcie_rq_tag_av                    = Open(4),

            o_cfg_phy_link_down                 = link_phy_down_sys,
            o_cfg_phy_link_status               = link_phy_status_sys,
            o_cfg_negotiated_width              = link_width_sys,
            o_cfg_current_speed                 = link_rate_sys,
            o_cfg_max_payload                   = cfg_max_payload_sys,
            o_cfg_max_read_req                  = cfg_max_read_req_sys,
            o_cfg_function_status               = cfg_function_status_sys,
            o_cfg_function_power_state          = Open(12),
            o_cfg_link_power_state              = Open(2),
            o_cfg_err_cor_out                   = Open(),
            o_cfg_err_nonfatal_out              = Open(),
            o_cfg_err_fatal_out                 = Open(),
            o_cfg_ltssm_state                   = link_ltssm_sys,
            o_cfg_rcb_status                    = Open(4),
            o_cfg_obff_enable                   = Open(2),
            o_cfg_pl_status_change              = Open(),
            o_cfg_tph_requester_enable          = Open(4),
            o_cfg_tph_st_mode                   = Open(12),

            i_cfg_mgmt_addr                     = 0,
            i_cfg_mgmt_write                    = 0,
            i_cfg_mgmt_write_data               = 0,
            i_cfg_mgmt_byte_enable              = 0,
            i_cfg_mgmt_read                     = 0,
            o_cfg_mgmt_read_data                = Open(32),
            o_cfg_mgmt_read_write_done          = Open(),
            i_cfg_mgmt_function_number          = 0,
            i_cfg_mgmt_debug_access             = 0,

            o_cfg_msg_received                  = cfg_msg_ports["o_cfg_msg_received"],
            o_cfg_msg_received_data             = cfg_msg_ports["o_cfg_msg_received_data"],
            o_cfg_msg_received_type             = cfg_msg_ports["o_cfg_msg_received_type"],
            i_cfg_msg_transmit                  = 0,
            i_cfg_msg_transmit_type             = 0,
            i_cfg_msg_transmit_data             = 0,
            o_cfg_msg_transmit_done             = Open(),

            o_cfg_fc_ph                         = Open(8),
            o_cfg_fc_pd                         = Open(12),
            o_cfg_fc_nph                        = Open(8),
            o_cfg_fc_npd                        = Open(12),
            o_cfg_fc_cplh                       = Open(8),
            o_cfg_fc_cpld                       = Open(12),
            i_cfg_fc_sel                        = 0,

            i_cfg_hot_reset_in                  = 0,
            o_cfg_hot_reset_out                 = Open(),
            i_cfg_power_state_change_ack        = 0,
            o_cfg_power_state_change_interrupt  = Open(),
            i_cfg_err_cor_in                    = 0,
            i_cfg_err_uncor_in                  = 0,
            o_cfg_flr_in_process                = Open(4),
            i_cfg_flr_done                      = 0,
            o_cfg_vf_flr_in_process             = Open(8),
            i_cfg_vf_flr_done                   = 0,
            i_cfg_vf_flr_func_num               = 0,
            i_cfg_link_training_enable          = 1,
            i_cfg_pm_aspm_l1_entry_reject       = 0,
            i_cfg_pm_aspm_tx_l0s_entry_disable  = 0,
            i_cfg_config_space_enable           = 1,
            i_cfg_req_pm_transition_l23_ready   = 0,

            i_cfg_dsn                           = serial_number,
            i_cfg_ds_bus_number                 = bus_number,
            i_cfg_ds_device_number              = device_number,
            i_cfg_ds_port_number                = 0,

            i_cfg_interrupt_int                               = 0,
            i_cfg_interrupt_pending                           = 0,
            o_cfg_interrupt_sent                              = Open(),
            o_cfg_interrupt_msi_enable                        = cfg_interrupt_msi_enable_x4,
            i_cfg_interrupt_msi_int                           = cfg_interrupt_msi_int_enc_mux,
            o_cfg_interrupt_msi_sent                          = cfg_interrupt_msi_sent,
            o_cfg_interrupt_msi_fail                          = cfg_interrupt_msi_fail,
            o_cfg_interrupt_msi_mmenable                      = cfg_interrupt_msi_mmenable,
            o_cfg_interrupt_msi_mask_update                   = Open(),
            o_cfg_interrupt_msi_data                          = Open(32),
            i_cfg_interrupt_msi_select                        = 0,
            i_cfg_interrupt_msi_pending_status                = cfg_interrupt_msi_int_enc_lat,
            i_cfg_interrupt_msi_attr                          = 0,
            i_cfg_interrupt_msi_tph_present                   = 0,
            i_cfg_interrupt_msi_tph_type                      = 0,
            i_cfg_interrupt_msi_tph_st_tag                    = 0,
            i_cfg_interrupt_msi_pending_status_function_num   = 0,
            i_cfg_interrupt_msi_pending_status_data_enable    = 0,
            i_cfg_interrupt_msi_function_number               = 0,
        )

        self.m_axis_cq_adapt = m_axis_cq_adapt = ClockDomainsRenamer("pcie")(MAxisCQAdapter(pcie_data_width))
        self.comb += [
            m_axis_cq_adapt.s_axis_tdata.eq(m_axis_cq_tdata_raw),
            m_axis_cq_adapt.s_axis_tkeep.eq(m_axis_cq_tkeep_raw),
            m_axis_cq_adapt.s_axis_tuser.eq(m_axis_cq_tuser_raw),
            m_axis_cq_adapt.s_axis_tlast.eq(m_axis_cq_tlast_raw),
            m_axis_cq_adapt.s_axis_tvalid.eq(m_axis_cq_tvalid_raw),
            m_axis_cq_tready_raw.eq(m_axis_cq_adapt.s_axis_tready),

            m_axis_cq.dat.eq(m_axis_cq_adapt.m_axis_tdata),
            m_axis_cq.be.eq(m_axis_cq_adapt.m_axis_tkeep),
            m_axis_cq_tuser.eq(m_axis_cq_adapt.m_axis_tuser),
            m_axis_cq_tlast.eq(m_axis_cq_adapt.m_axis_tlast),
            m_axis_cq.valid.eq(m_axis_cq_adapt.m_axis_tvalid),
            m_axis_cq_adapt.m_axis_tready.eq(m_axis_cq.ready),
            m_axis_cq.first.eq(m_axis_cq_tuser[14]),
            m_axis_cq.last.eq(m_axis_cq_tlast),
        ]

        self.m_axis_rc_adapt = m_axis_rc_adapt = ClockDomainsRenamer("pcie")(MAxisRCAdapter(pcie_data_width))
        self.comb += [
            m_axis_rc_adapt.s_axis_tdata.eq(m_axis_rc_tdata_raw),
            m_axis_rc_adapt.s_axis_tkeep.eq(m_axis_rc_tkeep_raw),
            m_axis_rc_adapt.s_axis_tuser.eq(m_axis_rc_tuser_raw),
            m_axis_rc_adapt.s_axis_tlast.eq(m_axis_rc_tlast_raw),
            m_axis_rc_adapt.s_axis_tvalid.eq(m_axis_rc_tvalid_raw),
            m_axis_rc_tready_raw.eq(m_axis_rc_adapt.s_axis_tready),

            m_axis_rc.dat.eq(m_axis_rc_adapt.m_axis_tdata),
            m_axis_rc.be.eq(m_axis_rc_adapt.m_axis_tkeep),
            m_axis_rc_tuser.eq(m_axis_rc_adapt.m_axis_tuser),
            m_axis_rc_tlast.eq(m_axis_rc_adapt.m_axis_tlast),
            m_axis_rc.valid.eq(m_axis_rc_adapt.m_axis_tvalid),
            m_axis_rc_adapt.m_axis_tready.eq(m_axis_rc.ready),
            m_axis_rc.first.eq(m_axis_rc_adapt.m_axis_sop),
            m_axis_rc.last.eq(m_axis_rc_tlast),
        ]

        self.s_axis_cc_adapt = s_axis_cc_adapt = ClockDomainsRenamer("pcie")(SAxisCCAdapter(pcie_data_width))
        self.comb += [
            s_axis_cc_adapt.s_axis_tdata.eq(s_axis_cc.dat),
            s_axis_cc_adapt.s_axis_tkeep.eq(s_axis_cc.be),
            s_axis_cc_adapt.s_axis_tlast.eq(s_axis_cc.last),
            s_axis_cc_adapt.s_axis_tuser.eq(Constant(0b0000)),
            s_axis_cc_adapt.s_axis_tvalid.eq(s_axis_cc.valid),
            s_axis_cc.ready.eq(s_axis_cc_adapt.s_axis_tready),

            s_axis_cc_tdata_raw.eq(s_axis_cc_adapt.m_axis_tdata),
            s_axis_cc_tkeep_raw.eq(s_axis_cc_adapt.m_axis_tkeep),
            s_axis_cc_tlast_raw.eq(s_axis_cc_adapt.m_axis_tlast),
            s_axis_cc_tuser_raw.eq(s_axis_cc_adapt.m_axis_tuser),
            s_axis_cc_tvalid_raw.eq(s_axis_cc_adapt.m_axis_tvalid),
            s_axis_cc_adapt.m_axis_tready.eq(s_axis_cc_tready_raw[0]),
        ]

        self.s_axis_rq_adapt = s_axis_rq_adapt = ClockDomainsRenamer("pcie")(SAxisRQAdapter(pcie_data_width))
        self.comb += [
            s_axis_rq_adapt.s_axis_tdata.eq(s_axis_rq.dat),
            s_axis_rq_adapt.s_axis_tkeep.eq(s_axis_rq.be),
            s_axis_rq_adapt.s_axis_tlast.eq(s_axis_rq.last),
            s_axis_rq_adapt.s_axis_tuser.eq(Constant(0b0000)),
            s_axis_rq_adapt.s_axis_tvalid.eq(s_axis_rq.valid),
            s_axis_rq.ready.eq(s_axis_rq_adapt.s_axis_tready),

            s_axis_rq_tdata_raw.eq(s_axis_rq_adapt.m_axis_tdata),
            s_axis_rq_tkeep_raw.eq(s_axis_rq_adapt.m_axis_tkeep),
            s_axis_rq_tlast_raw.eq(s_axis_rq_adapt.m_axis_tlast),
            s_axis_rq_tuser_raw.eq(s_axis_rq_adapt.m_axis_tuser),
            s_axis_rq_tvalid_raw.eq(s_axis_rq_adapt.m_axis_tvalid),
            s_axis_rq_adapt.m_axis_tready.eq(s_axis_rq_tready_raw[0]),
        ]

    # Resync Helper --------------------------------------------------------------------------------
    def add_resync(self, sig, clk="sys"):
        _sig = Signal.like(sig)
        self.specials += MultiReg(_sig, sig, clk)
        return _sig

    # LTSSM Tracer ---------------------------------------------------------------------------------
    def add_ltssm_tracer(self):
        self.ltssm_tracer = LTSSMTracer(self._link_status.fields.ltssm)

    # Hard IP sources ------------------------------------------------------------------------------
    def update_config(self, config):
        self.config.update(config)

    def add_sources(self, platform, phy_path=None, phy_filename=None):
        if phy_filename is not None:
            platform.add_ip(os.path.join(phy_path, phy_filename))
        else:
            # Link / clocks (speed-dependent).
            link_speed   = {"gen2": "5.0_GT/s", "gen3": "8.0_GT/s",  "gen4": "16.0_GT/s"}[self.speed]
            axisten_freq = {"gen2": 125,        "gen3": 250,         "gen4": 250        }[self.speed]
            coreclk_freq = {"gen2": 250,        "gen3": 500,         "gen4": 500        }[self.speed]

            # Device identification.
            device_id_base = {"gen2": 9020, "gen3": 9030, "gen4": 9040}[self.speed]
            device_id      = device_id_base + self.nlanes

            # Port type / class code (mode-dependent).
            port_type  = "PCI_Express_Endpoint_device"
            class_code = None
            if self.mode == "RootPort":
                port_type  = "Root_Port_of_PCI_Express_Root_Complex"
                class_code = 0x060400

            # BAR0.
            bar0_scale = "Megabytes"
            bar0_size  = max(self.bar0_size/MB, 1)

            # AXI-S / interface.
            axisten_if_width    = f"{self.pcie_data_width}_bit"
            axisten_rc_straddle = False
            enable_client_tag   = True

            # Power management.
            aspm_support = "No_ASPM"

            # PLL selection.
            plltype = "QPLL0"

            config = {
                # Core.
                "Component_Name"               : "pcie_usp",
                "DEVICE_PORT_TYPE"             : port_type,
                "PF0_DEVICE_ID"                : device_id,

                # Link.
                "PL_LINK_CAP_MAX_LINK_WIDTH"   : f"X{self.nlanes}",
                "PL_LINK_CAP_MAX_LINK_SPEED"   : link_speed,

                # AXI-S.
                "axisten_if_width"             : axisten_if_width,
                "AXISTEN_IF_RC_STRADDLE"       : axisten_rc_straddle,
                "axisten_freq"                 : axisten_freq,
                "coreclk_freq"                 : coreclk_freq,
                "axisten_if_enable_client_tag" : enable_client_tag,

                # Power / features.
                "aspm_support"                 : aspm_support,
                "plltype"                      : plltype,

                # BAR0.
                "pf0_bar0_scale"               : bar0_scale,
                "pf0_bar0_size"                : bar0_size,

                # Interrupts.
                "PF0_INTERRUPT_PIN"            : "NONE",
            }

            if class_code is not None:
                config["PF0_CLASS_CODE"] = class_code

            # User/Custom config.
            config.update(self.config)

            # Tcl generation.
            ip_tcl  = []
            ip_tcl.append(f"create_ip -vendor xilinx.com -name {self.ip_name} -module_name pcie_usp")
            ip_tcl.append("set obj [get_ips pcie_usp]")
            ip_tcl.append("set_property -dict [list \\")
            for config, value in config.items():
                ip_tcl.append("CONFIG.{} {} \\".format(config, '{{' + str(value) + '}}'))
            ip_tcl.append(f"] $obj")
            ip_tcl.append("synth_ip $obj")
            platform.toolchain.pre_synthesis_commands += ip_tcl

        verilog_path = os.path.join(os.path.abspath(os.path.dirname(__file__)), "xilinx")

        # No support-wrapper Verilog source required in direct mode.


    # External Hard IP -----------------------------------------------------------------------------
    def use_external_hard_ip(self, hard_ip_path, hard_ip_filename):
        self.external_hard_ip = True
        self.add_sources(self.platform, hard_ip_path, hard_ip_filename)

    # Finalize -------------------------------------------------------------------------------------
    def do_finalize(self):
        if not self.external_hard_ip:
            self.add_sources(self.platform)
        self.specials += Instance("pcie_usp", **self.pcie_usp_phy_params)

# USPHBMPCIEPHY ------------------------------------------------------------------------------------

class USPHBMPCIEPHY(USPPCIEPHY):
    def __init__(self, *args, **kwargs):
        USPPCIEPHY.__init__(self, *args, **kwargs, ip_name="pcie4c_uscale_plus")

```

`litepcie/software/__init__.py`:

```py
import os
from shutil import copytree

from litex.build import tools

from litex.soc.integration.export import get_csr_header, get_soc_header, get_mem_header


def copy_litepcie_software(dst):
    src = os.path.abspath(os.path.dirname(__file__))
    copytree(src, dst, dirs_exist_ok=True)

def generate_litepcie_software_headers(soc, dst):
    csr_header = get_csr_header(soc.csr_regions, soc.constants, with_access_functions=False)
    tools.write_to_file(os.path.join(dst, "csr.h"), csr_header)
    soc_header = get_soc_header(soc.constants, with_access_functions=False)
    tools.write_to_file(os.path.join(dst, "soc.h"), soc_header)
    mem_header = get_mem_header(soc.mem_regions)
    tools.write_to_file(os.path.join(dst, "mem.h"), mem_header)

def generate_litepcie_software(soc, dst):
    copy_litepcie_software(dst)
    generate_litepcie_software_headers(soc, os.path.join(dst, "kernel"))

```

`litepcie/software/kernel/Makefile`:

```
# Makefile for kernel module
KERNEL_VERSION:=$(shell uname -r)
KERNEL_PATH?=/lib/modules/$(KERNEL_VERSION)/build
ARCH?=$(shell uname -m)

obj-m = litepcie.o liteuart.o
litepcie-objs = main.o
#liteuart-objs = liteuart.o


all: litepcie.ko liteuart.ko

litepcie.ko: main.c
	make -C $(KERNEL_PATH) ARCH=$(ARCH) CROSS_COMPILE=$(CROSS_COMPILE) M=$(shell pwd) modules

litepcie.ko: litepcie.h config.h flags.h csr.h soc.h

liteuart.ko: liteuart.c
	make -C $(KERNEL_PATH) ARCH=$(ARCH) CROSS_COMPILE=$(CROSS_COMPILE) M=$(shell pwd) modules

clean:
	make -C $(KERNEL_PATH) ARCH=$(ARCH) CROSS_COMPILE=$(CROSS_COMPILE) M=$(shell pwd) clean
	rm -f *~

```

`litepcie/software/kernel/README`:

```
- Use 'make' to build the driver

- Install the driver and create the device with :

  ./init.sh

- Remove driver with

  rmmod litepcie

```

`litepcie/software/kernel/config.h`:

```h
/* SPDX-License-Identifier: BSD-2-Clause
 *
 * LitePCIe driver
 *
 * This file is part of LitePCIe.
 *
 * Copyright (C) 2018-2024 / EnjoyDigital  / florent@enjoy-digital.fr
 *
 */

#ifndef __HW_CONFIG_H
#define __HW_CONFIG_H
#include "soc.h"

/* PCIe PHY Vendor IDs */

#define PCIE_XILINX_VENDOR_ID  0x10ee
#define PCIE_LATTICE_VENDOR_ID 0x1204
#define PCIE_GOWIN_VENDOR_ID   0x22c2

/* PCIe PHY Device IDs */

/* Xilinx */
#define PCIE_XILINX_DEVICE_ID_S7_GEN2_X1   0x7021
#define PCIE_XILINX_DEVICE_ID_S7_GEN2_X2   0x7022
#define PCIE_XILINX_DEVICE_ID_S7_GEN2_X4   0x7024
#define PCIE_XILINX_DEVICE_ID_S7_GEN2_X8   0x7028

#define PCIE_XILINX_DEVICE_ID_US_GEN2_X1   0x8021
#define PCIE_XILINX_DEVICE_ID_US_GEN2_X2   0x8022
#define PCIE_XILINX_DEVICE_ID_US_GEN2_X4   0x8024
#define PCIE_XILINX_DEVICE_ID_US_GEN2_X8   0x8028

#define PCIE_XILINX_DEVICE_ID_US_GEN3_X1   0x8031
#define PCIE_XILINX_DEVICE_ID_US_GEN3_X2   0x8032
#define PCIE_XILINX_DEVICE_ID_US_GEN3_X4   0x8034
#define PCIE_XILINX_DEVICE_ID_US_GEN3_X8   0x8038

#define PCIE_XILINX_DEVICE_ID_USP_GEN2_X1  0x9021
#define PCIE_XILINX_DEVICE_ID_USP_GEN2_X2  0x9022
#define PCIE_XILINX_DEVICE_ID_USP_GEN2_X4  0x9024
#define PCIE_XILINX_DEVICE_ID_USP_GEN2_X8  0x9028
#define PCIE_XILINX_DEVICE_ID_USP_GEN2_X16 0x902f

#define PCIE_XILINX_DEVICE_ID_USP_GEN2_X1  0x9021
#define PCIE_XILINX_DEVICE_ID_USP_GEN2_X2  0x9022
#define PCIE_XILINX_DEVICE_ID_USP_GEN2_X4  0x9024
#define PCIE_XILINX_DEVICE_ID_USP_GEN2_X8  0x9028
#define PCIE_XILINX_DEVICE_ID_USP_GEN2_X16 0x902f

#define PCIE_XILINX_DEVICE_ID_USP_GEN3_X1  0x9031
#define PCIE_XILINX_DEVICE_ID_USP_GEN3_X2  0x9032
#define PCIE_XILINX_DEVICE_ID_USP_GEN3_X4  0x9034
#define PCIE_XILINX_DEVICE_ID_USP_GEN3_X8  0x9038
#define PCIE_XILINX_DEVICE_ID_USP_GEN3_X16 0x903f

#define PCIE_XILINX_DEVICE_ID_USP_GEN4_X1  0x9041
#define PCIE_XILINX_DEVICE_ID_USP_GEN4_X2  0x9042
#define PCIE_XILINX_DEVICE_ID_USP_GEN4_X4  0x9044
#define PCIE_XILINX_DEVICE_ID_USP_GEN4_X8  0x9048

/* Lattice */

#define PCIE_LATTICE_DEVICE_ID_CPNX_GEN3_X4 0x9c25

/* Gowin */

#define PCIE_GOWIN_DEVICE_ID_GW5AT_GEN2_X4 0x1100

/* /!\ Keep in sync with csr.h  /!\ */

/* DMA Flags */
#define DMA_IRQ_DISABLE  (1<<24)
#define DMA_LAST_DISABLE (1<<25)

#define DMA_CHANNEL_COUNT      DMA_CHANNELS
#define DMA_BUFFER_PER_IRQ     32
#define DMA_BUFFER_COUNT       256
#define DMA_BUFFER_SIZE        8192
#define DMA_BUFFER_TOTAL_SIZE (DMA_BUFFER_COUNT*DMA_BUFFER_SIZE)
//#define DMA_BUFFER_ALIGNED

/* DMA Offsets */
#define PCIE_DMA_WRITER_ENABLE_OFFSET             0x0000
#define PCIE_DMA_WRITER_TABLE_VALUE_OFFSET        0x0004
#define PCIE_DMA_WRITER_TABLE_WE_OFFSET           0x000c
#define PCIE_DMA_WRITER_TABLE_LOOP_PROG_N_OFFSET  0x0010
#define PCIE_DMA_WRITER_TABLE_LOOP_STATUS_OFFSET  0x0014
#define PCIE_DMA_WRITER_TABLE_LEVEL_OFFSET        0x0018
#define PCIE_DMA_WRITER_TABLE_FLUSH_OFFSET        0x001c
#define PCIE_DMA_READER_ENABLE_OFFSET             0x0020
#define PCIE_DMA_READER_TABLE_VALUE_OFFSET        0x0024
#define PCIE_DMA_READER_TABLE_WE_OFFSET           0x002c
#define PCIE_DMA_READER_TABLE_LOOP_PROG_N_OFFSET  0x0030
#define PCIE_DMA_READER_TABLE_LOOP_STATUS_OFFSET  0x0034
#define PCIE_DMA_READER_TABLE_LEVEL_OFFSET        0x0038
#define PCIE_DMA_READER_TABLE_FLUSH_OFFSET        0x003c
#define PCIE_DMA_LOOPBACK_ENABLE_OFFSET           0x0040
#define PCIE_DMA_BUFFERING_READER_FIFO_DEPTH_ADDR 0x0044
#define PCIE_DMA_BUFFERING_READER_FIFO_LEVEL_ADDR 0x0048
#define PCIE_DMA_BUFFERING_WRITER_FIFO_DEPTH_ADDR 0x004c
#define PCIE_DMA_BUFFERING_WRITER_FIFO_LEVEL_ADDR 0x0050

/* /!\ Keep in sync with csr.h  /!\ */

#endif /* __HW_CONFIG_H */

```

`litepcie/software/kernel/flags.h`:

```h
/* SPDX-License-Identifier: BSD-2-Clause
 *
 * LitePCIe driver
 *
 * This file is part of LitePCIe.
 *
 * Copyright (C) 2018-2024 / EnjoyDigital  / florent@enjoy-digital.fr
 *
 */

#ifndef __HW_FLAGS_H
#define __HW_FLAGS_H

/* SPI */
#define SPI_CTRL_START  (1 << 0)
#define SPI_CTRL_LENGTH (1 << 8)
#define SPI_STATUS_DONE (1 << 0)

/* PCIe */
#define DMA_TABLE_LOOP_INDEX (1 <<  0)
#define DMA_TABLE_LOOP_COUNT (1 << 16)

/* ICAP */
#define ICAP_CMD_REG   0b00100
#define ICAP_CMD_IPROG 0b01111

#define ICAP_IDCODE_REG   0b01100

#define ICAP_BOOTSTS_REG  0b10110
#define ICAP_BOOTSTS_VALID    (1 << 0)
#define ICAP_BOOTSTS_FALLBACK (1 << 1)


#endif /* __HW_FLAGS_H */

```

`litepcie/software/kernel/init.sh`:

```sh
#!/bin/sh
# TODO: use udev instead

# Check if litepcie module is already installed.
FOUND=$(lsmod | grep litepcie)
if [ "$FOUND" != "" ] ; then
    echo "litepcie module already installed."
    exit 0
fi

# Automatically remove liteuart module if installed.
FOUND=$(lsmod | grep liteuart)
if [ "$FOUND" != "" ] ; then
    rmmod liteuart.ko
fi

# Install litepcie module.
INS=$(insmod litepcie.ko 2>&1)
if [ "$?" != "0" ] ; then
    ERR=$(echo $INS | sed -s "s/.*litepcie.ko: //")
    case $ERR in
    'Invalid module format')
        set -e
        echo "Kernel may have changed, try to rebuild module"
        make -s clean
        make -s
        insmod litepcie.ko
        set +e
        ;;
    'No such file or directory')
        set -e
        echo "Module not compiled"
        make -s
        insmod litepcie.ko
        set +e
        ;;
    'Required key not available')
        echo "Can't insert kernel module, secure boot is probably enabled"
        echo "Please disable it from BIOS"
        exit 1
        ;;
    *)
        >&2 echo $INS
        exit 1
    esac
fi

# Install liteuart module.
insmod liteuart.ko

# Change permissions on litepcie created devices.
for i in `seq 0 16` ; do
    chmod 666 /dev/litepcie$i > /dev/null 2>&1
done


```

`litepcie/software/kernel/litepcie.h`:

```h
/* SPDX-License-Identifier: BSD-2-Clause
 *
 * LitePCIe driver
 *
 * This file is part of LitePCIe.
 *
 * Copyright (C) 2018-2024 / EnjoyDigital  / florent@enjoy-digital.fr
 *
 */

#ifndef _LINUX_LITEPCIE_H
#define _LINUX_LITEPCIE_H

#include <linux/types.h>

#include "csr.h"
#include "config.h"

struct litepcie_ioctl_reg {
	uint32_t addr;
	uint32_t val;
	uint8_t is_write;
};

struct litepcie_ioctl_flash {
	int tx_len; /* 8 to 40 */
	__u64 tx_data; /* 8 to 40 bits */
	__u64 rx_data; /* 40 bits */
};

struct litepcie_ioctl_icap {
	uint8_t addr;
	uint32_t data;
};

struct litepcie_ioctl_dma {
	uint8_t loopback_enable;
};

struct litepcie_ioctl_dma_writer {
	uint8_t enable;
	int64_t hw_count;
	int64_t sw_count;
};

struct litepcie_ioctl_dma_reader {
	uint8_t enable;
	int64_t hw_count;
	int64_t sw_count;
};

struct litepcie_ioctl_lock {
	uint8_t dma_reader_request;
	uint8_t dma_writer_request;
	uint8_t dma_reader_release;
	uint8_t dma_writer_release;
	uint8_t dma_reader_status;
	uint8_t dma_writer_status;
};

struct litepcie_ioctl_mmap_dma_info {
	uint64_t dma_tx_buf_offset;
	uint64_t dma_tx_buf_size;
	uint64_t dma_tx_buf_count;

	uint64_t dma_rx_buf_offset;
	uint64_t dma_rx_buf_size;
	uint64_t dma_rx_buf_count;
};

struct litepcie_ioctl_mmap_dma_update {
	int64_t sw_count;
};

#define LITEPCIE_IOCTL 'S'

#define LITEPCIE_IOCTL_REG               _IOWR(LITEPCIE_IOCTL,  0, struct litepcie_ioctl_reg)
#define LITEPCIE_IOCTL_FLASH             _IOWR(LITEPCIE_IOCTL,  1, struct litepcie_ioctl_flash)
#define LITEPCIE_IOCTL_ICAP              _IOWR(LITEPCIE_IOCTL,  2, struct litepcie_ioctl_icap)

#define LITEPCIE_IOCTL_DMA                       _IOW(LITEPCIE_IOCTL,  20, struct litepcie_ioctl_dma)
#define LITEPCIE_IOCTL_DMA_WRITER                _IOWR(LITEPCIE_IOCTL, 21, struct litepcie_ioctl_dma_writer)
#define LITEPCIE_IOCTL_DMA_READER                _IOWR(LITEPCIE_IOCTL, 22, struct litepcie_ioctl_dma_reader)
#define LITEPCIE_IOCTL_MMAP_DMA_INFO             _IOR(LITEPCIE_IOCTL,  24, struct litepcie_ioctl_mmap_dma_info)
#define LITEPCIE_IOCTL_LOCK                      _IOWR(LITEPCIE_IOCTL, 25, struct litepcie_ioctl_lock)
#define LITEPCIE_IOCTL_MMAP_DMA_WRITER_UPDATE    _IOW(LITEPCIE_IOCTL,  26, struct litepcie_ioctl_mmap_dma_update)
#define LITEPCIE_IOCTL_MMAP_DMA_READER_UPDATE    _IOW(LITEPCIE_IOCTL,  27, struct litepcie_ioctl_mmap_dma_update)

#endif /* _LINUX_LITEPCIE_H */

```

`litepcie/software/kernel/liteuart.c`:

```c
/* SPDX-License-Identifier: GPL-2.0
 *
 * LiteUART serial controller (LiteX) Driver
 *
 * Copyright (C) 2019-2020 Antmicro <www.antmicro.com>
 */

#include <linux/console.h>
//#include <linux/litex.h> FIXME: Too early to use litex.h directly from kernel, use a local version for now.
#include <linux/module.h>
#include <linux/of.h>
#include <linux/of_address.h>
#include <linux/of_platform.h>
#include <linux/platform_device.h>
#include <linux/serial.h>
#include <linux/serial_core.h>
#include <linux/slab.h>
#include <linux/timer.h>
#include <linux/tty_flip.h>
#include <linux/version.h>
#include <linux/xarray.h>

#include "litex.h"

// FIXME: Too early to use  platform_get_mem_or_io directly from kernel, use a local version for now.

static struct resource *local_platform_get_mem_or_io(struct platform_device *dev,
					unsigned int num)
{
	u32 i;

	for (i = 0; i < dev->num_resources; i++) {
		struct resource *r = &dev->resource[i];

		if ((resource_type(r) & (IORESOURCE_MEM|IORESOURCE_IO)) && num-- == 0)
			return r;
	}
	return NULL;
}

/*
 * CSRs definitions (base address offsets + width)
 *
 * The definitions below are true for LiteX SoC configured for 8-bit CSR Bus,
 * 32-bit aligned.
 *
 * Supporting other configurations might require new definitions or a more
 * generic way of indexing the LiteX CSRs.
 *
 * For more details on how CSRs are defined and handled in LiteX, see comments
 * in the LiteX SoC Driver: drivers/soc/litex/litex_soc_ctrl.c
 */
#define OFF_RXTX	0x00
#define OFF_TXFULL	0x04
#define OFF_RXEMPTY	0x08
#define OFF_EV_STATUS	0x0c
#define OFF_EV_PENDING	0x10
#define OFF_EV_ENABLE	0x14

/* events */
#define EV_TX		0x1
#define EV_RX		0x2

struct liteuart_port {
	struct uart_port port;
	struct timer_list timer;
	u32 id;
	struct workqueue_struct *workqueue;
	struct work_struct work;
};

#define to_liteuart_port(port)	container_of(port, struct liteuart_port, port)

static DEFINE_XARRAY_FLAGS(liteuart_array, XA_FLAGS_ALLOC);

#ifdef CONFIG_SERIAL_LITEUART_CONSOLE
static struct console liteuart_console;
#endif

#ifndef CONFIG_SERIAL_LITEUART_MAX_PORTS
#define CONFIG_SERIAL_LITEUART_MAX_PORTS 16
#endif

static struct uart_driver liteuart_driver = {
	.owner = THIS_MODULE,
	.driver_name = "liteuart",
	.dev_name = "ttyLXU",
	.major = 0,
	.minor = 0,
	.nr = CONFIG_SERIAL_LITEUART_MAX_PORTS,
#ifdef CONFIG_SERIAL_LITEUART_CONSOLE
	.cons = &liteuart_console,
#endif
};

static void liteuart_work(struct work_struct *w)
{
	struct liteuart_port *uart = container_of(w, struct liteuart_port, work);
	struct uart_port *port = &uart->port;
	unsigned char __iomem *membase = port->membase;
	unsigned int flg = TTY_NORMAL;
	int ch;
	unsigned long status;

	while ((status = !litex_read8(membase + OFF_RXEMPTY)) == 1) {
		ch = litex_read8(membase + OFF_RXTX);
		port->icount.rx++;

		/* no overflow bits in status */
		if (!(uart_handle_sysrq_char(port, ch)))
			uart_insert_char(port, status, 0, ch, flg);

		tty_flip_buffer_push(&port->state->port);
	}
}

static void liteuart_timer(struct timer_list *t)
{
#if LINUX_VERSION_CODE < KERNEL_VERSION(6, 16, 0)
	struct liteuart_port *uart = from_timer(uart, t, timer);
#else
	struct liteuart_port *uart = timer_container_of(uart, t, timer);
#endif
	struct uart_port *port = &uart->port;
	unsigned char __iomem *membase = port->membase;
	unsigned int flg = TTY_NORMAL;
	int ch;
	unsigned long status;
	uint16_t length = 0;

	while ((status = !litex_read8(membase + OFF_RXEMPTY)) == 1) {
		/* stop blocking this callback: delegate to a workqueue */
		if (length > 256) {
			queue_work(uart->workqueue, &uart->work);
			break;
		}
		length++;
		ch = litex_read8(membase + OFF_RXTX);
		port->icount.rx++;

		/* no overflow bits in status */
		if (!(uart_handle_sysrq_char(port, ch)))
			uart_insert_char(port, status, 0, ch, flg);

		tty_flip_buffer_push(&port->state->port);
	}

	mod_timer(&uart->timer, jiffies + uart_poll_timeout(port));
}

static void liteuart_putchar(struct uart_port *port, int ch)
{
	while (litex_read8(port->membase + OFF_TXFULL))
		cpu_relax();

	litex_write8(port->membase + OFF_RXTX, ch);
}

static unsigned int liteuart_tx_empty(struct uart_port *port)
{
	/* not really tx empty, just checking if tx is not full */
	if (!litex_read8(port->membase + OFF_TXFULL))
		return TIOCSER_TEMT;

	return 0;
}

static void liteuart_set_mctrl(struct uart_port *port, unsigned int mctrl)
{
	/* modem control register is not present in LiteUART */
}

static unsigned int liteuart_get_mctrl(struct uart_port *port)
{
	return TIOCM_CTS | TIOCM_DSR | TIOCM_CAR;
}

static void liteuart_stop_tx(struct uart_port *port)
{
}

static void liteuart_start_tx(struct uart_port *port)
{
#if LINUX_VERSION_CODE < KERNEL_VERSION(6, 10, 0)
	struct circ_buf *xmit = &port->state->xmit;
#else
	struct tty_port *tport = &port->state->port;
#endif
	unsigned char ch;

	if (unlikely(port->x_char)) {
		litex_write8(port->membase + OFF_RXTX, port->x_char);
		port->icount.tx++;
		port->x_char = 0;
#if LINUX_VERSION_CODE < KERNEL_VERSION(6, 10, 0)
	} else if (!uart_circ_empty(xmit)) {
		while (xmit->head != xmit->tail) {
			ch = xmit->buf[xmit->tail];
			xmit->tail = (xmit->tail + 1) & (UART_XMIT_SIZE - 1);
			port->icount.tx++;
#else
	} else if (!kfifo_is_empty(&tport->xmit_fifo)) {
		while(1) {
			if (!uart_fifo_get(port, &ch))
				break;
#endif
			liteuart_putchar(port, ch);
		}
	}

#if LINUX_VERSION_CODE < KERNEL_VERSION(6, 10, 0)
	if (uart_circ_chars_pending(xmit) < WAKEUP_CHARS)
#else
	if (kfifo_len(&tport->xmit_fifo) < WAKEUP_CHARS)
#endif
		uart_write_wakeup(port);
}

static void liteuart_stop_rx(struct uart_port *port)
{
	struct liteuart_port *uart = to_liteuart_port(port);

	/* just delete timer */
#if LINUX_VERSION_CODE < KERNEL_VERSION(6, 16, 0)
	del_timer(&uart->timer);
#else
	timer_shutdown(&uart->timer);
#endif
}

static void liteuart_break_ctl(struct uart_port *port, int break_state)
{
	/* LiteUART doesn't support sending break signal */
}

static int liteuart_startup(struct uart_port *port)
{
	struct liteuart_port *uart = to_liteuart_port(port);
	char b[12];

	/* disable events */
	litex_write8(port->membase + OFF_EV_ENABLE, 0);

	sprintf(b, "liteuart%d", uart->id);
	uart->workqueue = create_freezable_workqueue(b);
	if (!uart->workqueue) {
		printk("cannot create workqueue\n");
		return -EBUSY;
	}
	INIT_WORK(&uart->work, liteuart_work);

	/* prepare timer for polling */
	timer_setup(&uart->timer, liteuart_timer, 0);
	mod_timer(&uart->timer, jiffies + uart_poll_timeout(port));

	return 0;
}

static void liteuart_shutdown(struct uart_port *port)
{
	struct liteuart_port *uart = to_liteuart_port(port);
	if (uart->workqueue) {
		destroy_workqueue(uart->workqueue);
		uart->workqueue = NULL;
	}
}

static void liteuart_set_termios(struct uart_port *port, struct ktermios *new,
#if LINUX_VERSION_CODE < KERNEL_VERSION(6, 1, 0)
				 struct ktermios *old)
#else
				 const struct ktermios *old)
#endif
{
	unsigned int baud;
	unsigned long flags;

	spin_lock_irqsave(&port->lock, flags);

	/* update baudrate */
	baud = uart_get_baud_rate(port, new, old, 0, 460800);
	uart_update_timeout(port, new->c_cflag, baud);

	spin_unlock_irqrestore(&port->lock, flags);
}

static const char *liteuart_type(struct uart_port *port)
{
	return "liteuart";
}

static void liteuart_release_port(struct uart_port *port)
{
}

static int liteuart_request_port(struct uart_port *port)
{
	return 0;
}

static void liteuart_config_port(struct uart_port *port, int flags)
{
	/*
	 * Driver core for serial ports forces a non-zero value for port type.
	 * Write an arbitrary value here to accommodate the serial core driver,
	 * as ID part of UAPI is redundant.
	 */
	port->type = 1;
}

static int liteuart_verify_port(struct uart_port *port,
				struct serial_struct *ser)
{
	if (port->type != PORT_UNKNOWN && ser->type != 1)
		return -EINVAL;

	return 0;
}

static const struct uart_ops liteuart_ops = {
	.tx_empty	= liteuart_tx_empty,
	.set_mctrl	= liteuart_set_mctrl,
	.get_mctrl	= liteuart_get_mctrl,
	.stop_tx	= liteuart_stop_tx,
	.start_tx	= liteuart_start_tx,
	.stop_rx	= liteuart_stop_rx,
	.break_ctl	= liteuart_break_ctl,
	.startup	= liteuart_startup,
	.shutdown	= liteuart_shutdown,
	.set_termios	= liteuart_set_termios,
	.type		= liteuart_type,
	.release_port	= liteuart_release_port,
	.request_port	= liteuart_request_port,
	.config_port	= liteuart_config_port,
	.verify_port	= liteuart_verify_port,
};

static int liteuart_probe(struct platform_device *pdev)
{
	struct liteuart_port *uart;
	struct uart_port *port;
	struct xa_limit limit;
	struct resource *res;
	int dev_id, ret;

	/* look for aliases; auto-enumerate for free index if not found */
	dev_id = of_alias_get_id(pdev->dev.of_node, "serial");
	if (dev_id < 0)
		limit = XA_LIMIT(0, CONFIG_SERIAL_LITEUART_MAX_PORTS);
	else
		limit = XA_LIMIT(dev_id, dev_id);

	uart = devm_kzalloc(&pdev->dev, sizeof(struct liteuart_port), GFP_KERNEL);
	if (!uart)
		return -ENOMEM;

	ret = xa_alloc(&liteuart_array, &dev_id, uart, limit, GFP_KERNEL);
	if (ret)
		return ret;

	uart->id = dev_id;
	port = &uart->port;

	/* get membase */
	res = local_platform_get_mem_or_io(pdev, 0);
	if (!res) {
		ret = -EINVAL;
		goto err_erase_id;
	}

	if (res->flags & IORESOURCE_REG)
		port->membase = (unsigned char __iomem	*) res->start;
	else {
		port->membase = devm_ioremap_resource(&pdev->dev, res);
		if (IS_ERR(port->membase)) {
			ret = PTR_ERR(port->membase);
			goto err_erase_id;
		}
	}

	/* values not from device tree */
	port->dev = &pdev->dev;
	port->iotype = UPIO_MEM;
	port->flags = UPF_BOOT_AUTOCONF;
	port->ops = &liteuart_ops;
	port->regshift = 2;
	port->fifosize = 16;
	port->iobase = 1;
	port->type = PORT_UNKNOWN;
	port->line = dev_id;
	spin_lock_init(&port->lock);

	platform_set_drvdata(pdev, port);

	ret = uart_add_one_port(&liteuart_driver, &uart->port);
	if (ret)
		goto err_erase_id;

	return 0;

err_erase_id:
	xa_erase(&liteuart_array, uart->id);

	return ret;
}

#if LINUX_VERSION_CODE < KERNEL_VERSION(6, 11, 0)
static int liteuart_remove(struct platform_device *pdev)
#else
static void liteuart_remove(struct platform_device *pdev)
#endif
{
	struct uart_port *port = platform_get_drvdata(pdev);
	struct liteuart_port *uart = to_liteuart_port(port);

	uart_remove_one_port(&liteuart_driver, port);
	xa_erase(&liteuart_array, uart->id);

#if LINUX_VERSION_CODE < KERNEL_VERSION(6, 11, 0)
	return 0;
#endif
}

static const struct of_device_id liteuart_of_match[] = {
	{ .compatible = "litex,liteuart" },
	{}
};
MODULE_DEVICE_TABLE(of, liteuart_of_match);

static struct platform_driver liteuart_platform_driver = {
	.probe = liteuart_probe,
	.remove = liteuart_remove,
	.driver = {
		.name = "liteuart",
		.of_match_table = liteuart_of_match,
	},
};

#ifdef CONFIG_SERIAL_LITEUART_CONSOLE

static void liteuart_console_write(struct console *co, const char *s,
	unsigned int count)
{
	struct liteuart_port *uart;
	struct uart_port *port;
	unsigned long flags;

	uart = (struct liteuart_port *)xa_load(&liteuart_array, co->index);
	port = &uart->port;

	spin_lock_irqsave(&port->lock, flags);
	uart_console_write(port, s, count, liteuart_putchar);
	spin_unlock_irqrestore(&port->lock, flags);
}

static int liteuart_console_setup(struct console *co, char *options)
{
	struct liteuart_port *uart;
	struct uart_port *port;
	int baud = 115200;
	int bits = 8;
	int parity = 'n';
	int flow = 'n';

	uart = (struct liteuart_port *)xa_load(&liteuart_array, co->index);
	if (!uart)
		return -ENODEV;

	port = &uart->port;
	if (!port->membase)
		return -ENODEV;

	if (options)
		uart_parse_options(options, &baud, &parity, &bits, &flow);

	return uart_set_options(port, co, baud, parity, bits, flow);
}

static struct console liteuart_console = {
	.name = "liteuart",
	.write = liteuart_console_write,
	.device = uart_console_device,
	.setup = liteuart_console_setup,
	.flags = CON_PRINTBUFFER,
	.index = -1,
	.data = &liteuart_driver,
};

static int __init liteuart_console_init(void)
{
	register_console(&liteuart_console);

	return 0;
}
console_initcall(liteuart_console_init);

static void early_liteuart_write(struct console *console, const char *s,
				    unsigned int count)
{
	struct earlycon_device *device = console->data;
	struct uart_port *port = &device->port;

	uart_console_write(port, s, count, liteuart_putchar);
}

static int __init early_liteuart_setup(struct earlycon_device *device,
				       const char *options)
{
	if (!device->port.membase)
		return -ENODEV;

	device->con->write = early_liteuart_write;
	return 0;
}

OF_EARLYCON_DECLARE(liteuart, "litex,liteuart", early_liteuart_setup);
#endif /* CONFIG_SERIAL_LITEUART_CONSOLE */

static int __init liteuart_init(void)
{
	int res;

	res = uart_register_driver(&liteuart_driver);
	if (res)
		return res;

	res = platform_driver_register(&liteuart_platform_driver);
	if (res) {
		uart_unregister_driver(&liteuart_driver);
		return res;
	}

	return 0;
}

static void __exit liteuart_exit(void)
{
	platform_driver_unregister(&liteuart_platform_driver);
	uart_unregister_driver(&liteuart_driver);
}

module_init(liteuart_init);
module_exit(liteuart_exit);

MODULE_AUTHOR("Antmicro <www.antmicro.com>");
MODULE_DESCRIPTION("LiteUART serial driver");
MODULE_LICENSE("GPL v2");
MODULE_ALIAS("platform: liteuart");

```

`litepcie/software/kernel/litex.h`:

```h
/* SPDX-License-Identifier: GPL-2.0
 *
 * Common LiteX header providing
 * helper functions for accessing CSRs.
 *
 * Copyright (C) 2019-2020 Antmicro <www.antmicro.com>
 */

#ifndef _LINUX_LITEX_H
#define _LINUX_LITEX_H

#include <linux/io.h>

static inline void _write_litex_subregister(u32 val, void __iomem *addr)
{
	writel((u32 __force)cpu_to_le32(val), addr);
}

static inline u32 _read_litex_subregister(void __iomem *addr)
{
	return le32_to_cpu((__le32 __force)readl(addr));
}

/*
 * LiteX SoC Generator, depending on the configuration, can split a single
 * logical CSR (Control&Status Register) into a series of consecutive physical
 * registers.
 *
 * For example, in the configuration with 8-bit CSR Bus, a 32-bit aligned,
 * 32-bit wide logical CSR will be laid out as four 32-bit physical
 * subregisters, each one containing one byte of meaningful data.
 *
 * For Linux support, upstream LiteX enforces a 32-bit wide CSR bus, which
 * means that only larger-than-32-bit CSRs will be split across multiple
 * subregisters (e.g., a 64-bit CSR will be spread across two consecutive
 * 32-bit subregisters).
 *
 * For details see: https://github.com/enjoy-digital/litex/wiki/CSR-Bus
 */

static inline void litex_write8(void __iomem *reg, u8 val)
{
	_write_litex_subregister(val, reg);
}

static inline void litex_write16(void __iomem *reg, u16 val)
{
	_write_litex_subregister(val, reg);
}

static inline void litex_write32(void __iomem *reg, u32 val)
{
	_write_litex_subregister(val, reg);
}

static inline void litex_write64(void __iomem *reg, u64 val)
{
	_write_litex_subregister(val >> 32, reg);
	_write_litex_subregister(val, reg + 4);
}

static inline u8 litex_read8(void __iomem *reg)
{
	return _read_litex_subregister(reg);
}

static inline u16 litex_read16(void __iomem *reg)
{
	return _read_litex_subregister(reg);
}

static inline u32 litex_read32(void __iomem *reg)
{
	return _read_litex_subregister(reg);
}

static inline u64 litex_read64(void __iomem *reg)
{
	return ((u64)_read_litex_subregister(reg) << 32) |
		_read_litex_subregister(reg + 4);
}

#endif /* _LINUX_LITEX_H */

```

`litepcie/software/kernel/main.c`:

```c
/* SPDX-License-Identifier: BSD-2-Clause
 *
 * LitePCIe driver
 *
 * This file is part of LitePCIe.
 *
 * Copyright (C) 2018-2024 / EnjoyDigital  / florent@enjoy-digital.fr
 *
 */

#include <linux/kernel.h>
#include <linux/module.h>
#include <linux/types.h>
#include <linux/ioctl.h>
#include <linux/init.h>
#include <linux/errno.h>
#include <linux/mm.h>
#include <linux/fs.h>
#include <linux/mmtimer.h>
#include <linux/miscdevice.h>
#include <linux/posix-timers.h>
#include <linux/interrupt.h>
#include <linux/time.h>
#include <linux/math64.h>
#include <linux/mutex.h>
#include <linux/slab.h>
#include <linux/pci.h>
#include <linux/pci_regs.h>
#include <linux/delay.h>
#include <linux/wait.h>
#include <linux/log2.h>
#include <linux/poll.h>
#include <linux/cdev.h>
#include <linux/platform_device.h>
#include <linux/version.h>

#if defined(__arm__) || defined(__aarch64__)
#include <linux/dma-direct.h>
#endif

#include "litepcie.h"
#include "csr.h"
#include "config.h"
#include "flags.h"
#include "soc.h"

//#define DEBUG_CSR
//#define DEBUG_MSI
//#define DEBUG_POLL
//#define DEBUG_READ
//#define DEBUG_WRITE

#define LITEPCIE_NAME "litepcie"
#define LITEPCIE_MINOR_COUNT 32

#ifndef CSR_BASE
#define CSR_BASE 0x00000000
#endif

struct litepcie_dma_chan {
	uint32_t base;
	uint32_t writer_interrupt;
	uint32_t reader_interrupt;
	dma_addr_t reader_handle[DMA_BUFFER_COUNT];
	dma_addr_t writer_handle[DMA_BUFFER_COUNT];
	uint32_t *reader_addr[DMA_BUFFER_COUNT];
	uint32_t *writer_addr[DMA_BUFFER_COUNT];
	int64_t reader_hw_count;
	int64_t reader_hw_count_last;
	int64_t reader_sw_count;
	int64_t writer_hw_count;
	int64_t writer_hw_count_last;
	int64_t writer_sw_count;
	uint8_t writer_enable;
	uint8_t reader_enable;
	uint8_t writer_lock;
	uint8_t reader_lock;
};

struct litepcie_chan {
	struct litepcie_device *litepcie_dev;
	struct litepcie_dma_chan dma;
	struct cdev cdev;
	uint32_t block_size;
	uint32_t core_base;
	wait_queue_head_t wait_rd; /* to wait for an ongoing read */
	wait_queue_head_t wait_wr; /* to wait for an ongoing write */

	int index;
	int minor;
};

/* Structure to hold the LitePCIe device information */
struct litepcie_device {
	struct pci_dev *dev;                          /* PCI device */
	struct platform_device *uart;                 /* UART platform device */
	resource_size_t bar0_size;                    /* Size of BAR0 */
	phys_addr_t bar0_phys_addr;                   /* Physical address of BAR0 */
	uint8_t *bar0_addr;                           /* Virtual address of BAR0 */
	struct litepcie_chan chan[DMA_CHANNEL_COUNT]; /* DMA channel information */
	spinlock_t lock;                              /* Spinlock for synchronization */
	int minor_base;                               /* Base minor number for the device */
	int irqs;                                     /* Number of IRQs */
	int channels;                                 /* Number of DMA channels */
};

struct litepcie_chan_priv {
	struct litepcie_chan *chan;
	bool reader;
	bool writer;
};

static int litepcie_major;
static int litepcie_minor_idx;
static struct class *litepcie_class;
static dev_t litepcie_dev_t;

/* Function to read a 32-bit value from a LitePCIe device register */
static inline uint32_t litepcie_readl(struct litepcie_device *s, uint32_t addr)
{
	uint32_t val;

	val = readl(s->bar0_addr + addr - CSR_BASE);
#ifdef DEBUG_CSR
	dev_dbg(&s->dev->dev, "csr_read: 0x%08x @ 0x%08x", val, addr);
#endif
	return val;
}

/* Function to write a 32-bit value to a LitePCIe device register */
static inline void litepcie_writel(struct litepcie_device *s, uint32_t addr, uint32_t val)
{
#ifdef DEBUG_CSR
	dev_dbg(&s->dev->dev, "csr_write: 0x%08x @ 0x%08x", val, addr);
#endif
	return writel(val, s->bar0_addr + addr - CSR_BASE);
}

/* Function to enable a specific interrupt on a LitePCIe device */
static void litepcie_enable_interrupt(struct litepcie_device *s, int irq_num)
{
	uint32_t v;

	/* Read the current interrupt enable register value */
	v = litepcie_readl(s, CSR_PCIE_MSI_ENABLE_ADDR);

	/* Set the bit corresponding to the given interrupt number */
	v |= (1 << irq_num);

	/* Write the updated value back to the register */
	litepcie_writel(s, CSR_PCIE_MSI_ENABLE_ADDR, v);
}

/* Function to disable a specific interrupt on a LitePCIe device */
static void litepcie_disable_interrupt(struct litepcie_device *s, int irq_num)
{
	uint32_t v;

	/* Read the current interrupt enable register value */
	v = litepcie_readl(s, CSR_PCIE_MSI_ENABLE_ADDR);

	/* Clear the bit corresponding to the given interrupt number */
	v &= ~(1 << irq_num);

	/* Write the updated value back to the register */
	litepcie_writel(s, CSR_PCIE_MSI_ENABLE_ADDR, v);
}

static int litepcie_dma_init(struct litepcie_device *s)
{

	int i, j;
	struct litepcie_dma_chan *dmachan;

	if (!s)
		return -ENODEV;

	/* for each dma channel */
	for (i = 0; i < s->channels; i++) {
		dmachan = &s->chan[i].dma;
		/* for each dma buffer */
		for (j = 0; j < DMA_BUFFER_COUNT; j++) {
			/* allocate rd */
			dmachan->reader_addr[j] = dmam_alloc_coherent(
				&s->dev->dev,
				DMA_BUFFER_SIZE,
				&dmachan->reader_handle[j],
				GFP_KERNEL);
			/* allocate wr */
			dmachan->writer_addr[j] = dmam_alloc_coherent(
				&s->dev->dev,
				DMA_BUFFER_SIZE,
				&dmachan->writer_handle[j],
				GFP_KERNEL);
			/* check */
			if (!dmachan->writer_addr[j]
				|| !dmachan->reader_addr[j]) {
				dev_err(&s->dev->dev, "Failed to allocate dma buffers\n");
				return -ENOMEM;
			}
		}
	}

	return 0;
}

static void litepcie_dma_writer_start(struct litepcie_device *s, int chan_num)
{
	struct litepcie_dma_chan *dmachan;
	int i;

	dmachan = &s->chan[chan_num].dma;

	/* Fill DMA Writer descriptors. */
	litepcie_writel(s, dmachan->base + PCIE_DMA_WRITER_ENABLE_OFFSET, 0);
	litepcie_writel(s, dmachan->base + PCIE_DMA_WRITER_TABLE_FLUSH_OFFSET, 1);
	litepcie_writel(s, dmachan->base + PCIE_DMA_WRITER_TABLE_LOOP_PROG_N_OFFSET, 0);
	for (i = 0; i < DMA_BUFFER_COUNT; i++) {
		/* Fill buffer size + parameters. */
		litepcie_writel(s, dmachan->base + PCIE_DMA_WRITER_TABLE_VALUE_OFFSET,
#ifndef DMA_BUFFER_ALIGNED
			DMA_LAST_DISABLE |
#endif
			(!(i%DMA_BUFFER_PER_IRQ == 0)) * DMA_IRQ_DISABLE | /* generate an msi */
			DMA_BUFFER_SIZE);                                  /* every n buffers */
		/* Fill 32-bit Address LSB. */
		litepcie_writel(s, dmachan->base + PCIE_DMA_WRITER_TABLE_VALUE_OFFSET + 4, (dmachan->writer_handle[i] >>  0) & 0xffffffff);
		/* Write descriptor (and fill 32-bit Address MSB for 64-bit mode). */
		litepcie_writel(s, dmachan->base + PCIE_DMA_WRITER_TABLE_WE_OFFSET,        (dmachan->writer_handle[i] >> 32) & 0xffffffff);
	}
	litepcie_writel(s, dmachan->base + PCIE_DMA_WRITER_TABLE_LOOP_PROG_N_OFFSET, 1);

	/* Clear counters. */
	dmachan->writer_hw_count = 0;
	dmachan->writer_hw_count_last = 0;
	dmachan->writer_sw_count = 0;

	/* Start DMA Writer. */
	litepcie_writel(s, dmachan->base + PCIE_DMA_WRITER_ENABLE_OFFSET, 1);
}

static void litepcie_dma_writer_stop(struct litepcie_device *s, int chan_num)
{
	struct litepcie_dma_chan *dmachan;

	dmachan = &s->chan[chan_num].dma;

	/* Flush and stop DMA Writer. */
	litepcie_writel(s, dmachan->base + PCIE_DMA_WRITER_TABLE_LOOP_PROG_N_OFFSET, 0);
	litepcie_writel(s, dmachan->base + PCIE_DMA_WRITER_TABLE_FLUSH_OFFSET, 1);
	udelay(1000);
	litepcie_writel(s, dmachan->base + PCIE_DMA_WRITER_ENABLE_OFFSET, 0);
	litepcie_writel(s, dmachan->base + PCIE_DMA_WRITER_TABLE_FLUSH_OFFSET, 1);

	/* Clear counters. */
	dmachan->writer_hw_count = 0;
	dmachan->writer_hw_count_last = 0;
	dmachan->writer_sw_count = 0;
}

static void litepcie_dma_reader_start(struct litepcie_device *s, int chan_num)
{
	struct litepcie_dma_chan *dmachan;
	int i;

	dmachan = &s->chan[chan_num].dma;

	/* Fill DMA Reader descriptors. */
	litepcie_writel(s, dmachan->base + PCIE_DMA_READER_ENABLE_OFFSET, 0);
	litepcie_writel(s, dmachan->base + PCIE_DMA_READER_TABLE_FLUSH_OFFSET, 1);
	litepcie_writel(s, dmachan->base + PCIE_DMA_READER_TABLE_LOOP_PROG_N_OFFSET, 0);
	for (i = 0; i < DMA_BUFFER_COUNT; i++) {
		/* Fill buffer size + parameters. */
		litepcie_writel(s, dmachan->base + PCIE_DMA_READER_TABLE_VALUE_OFFSET,
#ifndef DMA_BUFFER_ALIGNED
			DMA_LAST_DISABLE |
#endif
			(!(i%DMA_BUFFER_PER_IRQ == 0)) * DMA_IRQ_DISABLE | /* generate an msi */
			DMA_BUFFER_SIZE);                                  /* every n buffers */
		/* Fill 32-bit Address LSB. */
		litepcie_writel(s, dmachan->base + PCIE_DMA_READER_TABLE_VALUE_OFFSET + 4, (dmachan->reader_handle[i] >>  0) & 0xffffffff);
		/* Write descriptor (and fill 32-bit Address MSB for 64-bit mode). */
		litepcie_writel(s, dmachan->base + PCIE_DMA_READER_TABLE_WE_OFFSET, (dmachan->reader_handle[i] >> 32) & 0xffffffff);
	}
	litepcie_writel(s, dmachan->base + PCIE_DMA_READER_TABLE_LOOP_PROG_N_OFFSET, 1);

	/* Clear counters */
	dmachan->reader_hw_count = 0;
	dmachan->reader_hw_count_last = 0;
	dmachan->reader_sw_count = 0;

	/* Start dma reader */
	litepcie_writel(s, dmachan->base + PCIE_DMA_READER_ENABLE_OFFSET, 1);
}

static void litepcie_dma_reader_stop(struct litepcie_device *s, int chan_num)
{
	struct litepcie_dma_chan *dmachan;

	dmachan = &s->chan[chan_num].dma;

	/* flush and stop dma reader */
	litepcie_writel(s, dmachan->base + PCIE_DMA_READER_TABLE_LOOP_PROG_N_OFFSET, 0);
	litepcie_writel(s, dmachan->base + PCIE_DMA_READER_TABLE_FLUSH_OFFSET, 1);
	udelay(1000);
	litepcie_writel(s, dmachan->base + PCIE_DMA_READER_ENABLE_OFFSET, 0);
	litepcie_writel(s, dmachan->base + PCIE_DMA_READER_TABLE_FLUSH_OFFSET, 1);

	/* clear counters */
	dmachan->reader_hw_count = 0;
	dmachan->reader_hw_count_last = 0;
	dmachan->reader_sw_count = 0;
}

static void litepcie_stop_dma(struct litepcie_device *s)
{
	struct litepcie_dma_chan *dmachan;
	int i;

	for (i = 0; i < s->channels; i++) {
		dmachan = &s->chan[i].dma;
		litepcie_writel(s, dmachan->base + PCIE_DMA_WRITER_ENABLE_OFFSET, 0b0);
		litepcie_writel(s, dmachan->base + PCIE_DMA_READER_ENABLE_OFFSET, 0b0);
	}
}

static irqreturn_t litepcie_interrupt(int irq, void *data)
{
	struct litepcie_device *s = (struct litepcie_device *) data;
	struct litepcie_chan *chan;
	uint32_t loop_status;
	uint32_t clear_mask, irq_vector, irq_enable;
	int i;

/* Single MSI */
#ifdef CSR_PCIE_MSI_CLEAR_ADDR
	irq_vector = litepcie_readl(s, CSR_PCIE_MSI_VECTOR_ADDR);
	irq_enable = litepcie_readl(s, CSR_PCIE_MSI_ENABLE_ADDR);
/* MSI MultiVector / MSI-X */
#else
	irq_vector = 0;
	for (i = 0; i < s->irqs; i++) {
		if (irq == pci_irq_vector(s->dev, i)) {
			irq_vector = (1 << i);
			break;
		}
	}
	irq_enable = litepcie_readl(s, CSR_PCIE_MSI_ENABLE_ADDR);
#endif

#ifdef DEBUG_MSI
	dev_dbg(&s->dev->dev, "MSI: 0x%x 0x%x\n", irq_vector, irq_enable);
#endif
	irq_vector &= irq_enable;
	clear_mask = 0;

	for (i = 0; i < s->channels; i++) {
		chan = &s->chan[i];
		/* dma reader interrupt handling */
		if (irq_vector & (1 << chan->dma.reader_interrupt)) {
			loop_status = litepcie_readl(s, chan->dma.base +
				PCIE_DMA_READER_TABLE_LOOP_STATUS_OFFSET);
			chan->dma.reader_hw_count &= ((~(DMA_BUFFER_COUNT - 1) << 16) & 0xffffffffffff0000);
			chan->dma.reader_hw_count |= (loop_status >> 16) * DMA_BUFFER_COUNT + (loop_status & 0xffff);
			if (chan->dma.reader_hw_count_last > chan->dma.reader_hw_count)
				chan->dma.reader_hw_count += (1 << (ilog2(DMA_BUFFER_COUNT) + 16));
			chan->dma.reader_hw_count_last = chan->dma.reader_hw_count;
#ifdef DEBUG_MSI
			dev_dbg(&s->dev->dev, "MSI DMA%d Reader buf: %lld\n", i,
				chan->dma.reader_hw_count);
#endif
			wake_up_interruptible(&chan->wait_wr);
			clear_mask |= (1 << chan->dma.reader_interrupt);
		}
		/* dma writer interrupt handling */
		if (irq_vector & (1 << chan->dma.writer_interrupt)) {
			loop_status = litepcie_readl(s, chan->dma.base +
				PCIE_DMA_WRITER_TABLE_LOOP_STATUS_OFFSET);
			chan->dma.writer_hw_count &= ((~(DMA_BUFFER_COUNT - 1) << 16) & 0xffffffffffff0000);
			chan->dma.writer_hw_count |= (loop_status >> 16) * DMA_BUFFER_COUNT + (loop_status & 0xffff);
			if (chan->dma.writer_hw_count_last > chan->dma.writer_hw_count)
				chan->dma.writer_hw_count += (1 << (ilog2(DMA_BUFFER_COUNT) + 16));
			chan->dma.writer_hw_count_last = chan->dma.writer_hw_count;
#ifdef DEBUG_MSI
			dev_dbg(&s->dev->dev, "MSI DMA%d Writer buf: %lld\n", i,
				chan->dma.writer_hw_count);
#endif
			wake_up_interruptible(&chan->wait_rd);
			clear_mask |= (1 << chan->dma.writer_interrupt);
		}
	}

#ifdef CSR_PCIE_MSI_CLEAR_ADDR
	litepcie_writel(s, CSR_PCIE_MSI_CLEAR_ADDR, clear_mask);
#endif

	return IRQ_HANDLED;
}

static int litepcie_open(struct inode *inode, struct file *file)
{
	struct litepcie_chan *chan = container_of(inode->i_cdev, struct litepcie_chan, cdev);
	struct litepcie_chan_priv *chan_priv = kzalloc(sizeof(*chan_priv), GFP_KERNEL);

	if (!chan_priv)
		return -ENOMEM;

	chan_priv->chan = chan;
	file->private_data = chan_priv;

	if (chan->dma.reader_enable == 0) { /* clear only if disabled */
		chan->dma.reader_hw_count = 0;
		chan->dma.reader_hw_count_last = 0;
		chan->dma.reader_sw_count = 0;
	}

	if (chan->dma.writer_enable == 0) { /* clear only if disabled */
		chan->dma.writer_hw_count = 0;
		chan->dma.writer_hw_count_last = 0;
		chan->dma.writer_sw_count = 0;
	}

	return 0;
}

static int litepcie_release(struct inode *inode, struct file *file)
{
	struct litepcie_chan_priv *chan_priv = file->private_data;
	struct litepcie_chan *chan = chan_priv->chan;

	if (chan_priv->reader) {
		/* disable interrupt */
		litepcie_disable_interrupt(chan->litepcie_dev, chan->dma.reader_interrupt);
		/* disable DMA */
		litepcie_dma_reader_stop(chan->litepcie_dev, chan->index);
		chan->dma.reader_lock = 0;
		chan->dma.reader_enable = 0;
	}

	if (chan_priv->writer) {
		/* disable interrupt */
		litepcie_disable_interrupt(chan->litepcie_dev, chan->dma.writer_interrupt);
		/* disable DMA */
		litepcie_dma_writer_stop(chan->litepcie_dev, chan->index);
		chan->dma.writer_lock = 0;
		chan->dma.writer_enable = 0;
	}

	kfree(chan_priv);

	return 0;
}

static ssize_t litepcie_read(struct file *file, char __user *data, size_t size, loff_t *offset)
{
	size_t len;
	int i, ret;
	int overflows;

	struct litepcie_chan_priv *chan_priv = file->private_data;
	struct litepcie_chan *chan = chan_priv->chan;
	struct litepcie_device *s = chan->litepcie_dev;

	if (file->f_flags & O_NONBLOCK) {
		if (chan->dma.writer_hw_count == chan->dma.writer_sw_count)
			ret = -EAGAIN;
		else
			ret = 0;
	} else {
		ret = wait_event_interruptible(chan->wait_rd,
					       (chan->dma.writer_hw_count - chan->dma.writer_sw_count) > 0);
	}

	if (ret < 0)
		return ret;

	i = 0;
	overflows = 0;
	len = size;
	while (len >= DMA_BUFFER_SIZE) {
		if ((chan->dma.writer_hw_count - chan->dma.writer_sw_count) > 0) {
			if ((chan->dma.writer_hw_count - chan->dma.writer_sw_count) > DMA_BUFFER_COUNT/2) {
				overflows++;
			} else {
				ret = copy_to_user(data + (chan->block_size * i),
						   chan->dma.writer_addr[chan->dma.writer_sw_count%DMA_BUFFER_COUNT],
						   DMA_BUFFER_SIZE);
				if (ret)
					return -EFAULT;
			}
			len -= DMA_BUFFER_SIZE;
			chan->dma.writer_sw_count += 1;
			i++;
		} else {
			break;
		}
	}

	if (overflows)
		dev_err(&s->dev->dev, "Reading too late, %d buffers lost\n", overflows);

#ifdef DEBUG_READ
	dev_dbg(&s->dev->dev, "read: read %ld bytes out of %ld\n", size - len, size);
#endif

	return size - len;
}

static ssize_t litepcie_write(struct file *file, const char __user *data, size_t size, loff_t *offset)
{
	size_t len;
	int i, ret;
	int underflows;

	struct litepcie_chan_priv *chan_priv = file->private_data;
	struct litepcie_chan *chan = chan_priv->chan;
	struct litepcie_device *s = chan->litepcie_dev;

	if (file->f_flags & O_NONBLOCK) {
		if (chan->dma.reader_hw_count == chan->dma.reader_sw_count)
			ret = -EAGAIN;
		else
			ret = 0;
	} else {
		ret = wait_event_interruptible(chan->wait_wr,
					       (chan->dma.reader_sw_count - chan->dma.reader_hw_count) < DMA_BUFFER_COUNT/2);
	}

	if (ret < 0)
		return ret;

	i = 0;
	underflows = 0;
	len = size;
	while (len >= DMA_BUFFER_SIZE) {
		if ((chan->dma.reader_sw_count - chan->dma.reader_hw_count) < DMA_BUFFER_COUNT/2) {
			if ((chan->dma.reader_sw_count - chan->dma.reader_hw_count) < 0) {
				underflows++;
			} else {
				ret = copy_from_user(chan->dma.reader_addr[chan->dma.reader_sw_count%DMA_BUFFER_COUNT],
						     data + (chan->block_size * i), DMA_BUFFER_SIZE);
				if (ret)
					return -EFAULT;
			}
			len -= DMA_BUFFER_SIZE;
			chan->dma.reader_sw_count += 1;
			i++;
		} else {
			break;
		}
	}

	if (underflows)
		dev_err(&s->dev->dev, "Writing too late, %d buffers lost\n", underflows);

#ifdef DEBUG_WRITE
	dev_dbg(&s->dev->dev, "write: write %ld bytes out of %ld\n", size - len, size);
#endif

	return size - len;
}

static int litepcie_mmap(struct file *file, struct vm_area_struct *vma)
{
	struct litepcie_chan_priv *chan_priv = file->private_data;
	struct litepcie_chan *chan = chan_priv->chan;
	struct litepcie_device *s = chan->litepcie_dev;
	unsigned long pfn;
	int is_tx, i;

	if (vma->vm_end - vma->vm_start != DMA_BUFFER_TOTAL_SIZE)
		return -EINVAL;

	if (vma->vm_pgoff == 0)
		is_tx = 1;
	else if (vma->vm_pgoff == (DMA_BUFFER_TOTAL_SIZE >> PAGE_SHIFT))
		is_tx = 0;
	else
		return -EINVAL;

	for (i = 0; i < DMA_BUFFER_COUNT; i++) {
#if defined(__arm__) || defined(__aarch64__)
		void *va;
		if (is_tx)
			va = phys_to_virt(dma_to_phys(&s->dev->dev, chan->dma.reader_handle[i]));
		else
			va = phys_to_virt(dma_to_phys(&s->dev->dev, chan->dma.writer_handle[i]));
		pfn = page_to_pfn(virt_to_page(va));
#else
		if (is_tx)
			pfn = __pa(chan->dma.reader_addr[i]) >> PAGE_SHIFT;
		else
			pfn = __pa(chan->dma.writer_addr[i]) >> PAGE_SHIFT;
#endif
		/*
		 * Note: the memory is cached, so the user must explicitly
		 * flush the CPU caches on architectures which require it.
		 */
		if (remap_pfn_range(vma, vma->vm_start + i * DMA_BUFFER_SIZE, pfn,
				    DMA_BUFFER_SIZE, vma->vm_page_prot)) {
			dev_err(&s->dev->dev, "mmap remap_pfn_range failed\n");
			return -EAGAIN;
		}
	}

	return 0;
}

static unsigned int litepcie_poll(struct file *file, poll_table *wait)
{
	unsigned int mask = 0;

	struct litepcie_chan_priv *chan_priv = file->private_data;
	struct litepcie_chan *chan = chan_priv->chan;
#ifdef DEBUG_POLL
	struct litepcie_device *s = chan->litepcie_dev;
#endif

	poll_wait(file, &chan->wait_rd, wait);
	poll_wait(file, &chan->wait_wr, wait);

#ifdef DEBUG_POLL
	dev_dbg(&s->dev->dev, "poll: writer hw_count: %10lld / sw_count %10lld\n",
	chan->dma.writer_hw_count, chan->dma.writer_sw_count);
	dev_dbg(&s->dev->dev, "poll: reader hw_count: %10lld / sw_count %10lld\n",
	chan->dma.reader_hw_count, chan->dma.reader_sw_count);
#endif

	if ((chan->dma.writer_hw_count - chan->dma.writer_sw_count) > 2)
		mask |= POLLIN | POLLRDNORM;

	if ((chan->dma.reader_sw_count - chan->dma.reader_hw_count) < DMA_BUFFER_COUNT/2)
		mask |= POLLOUT | POLLWRNORM;

	return mask;
}

#ifdef CSR_FLASH_BASE
/* SPI */

#define SPI_TIMEOUT 100000 /* in us */

static int litepcie_flash_spi(struct litepcie_device *s, struct litepcie_ioctl_flash *m)
{
	int i;

	if (m->tx_len < 8 || m->tx_len > 40)
		return -EINVAL;

	litepcie_writel(s, CSR_FLASH_SPI_MOSI_ADDR, m->tx_data >> 32);
	litepcie_writel(s, CSR_FLASH_SPI_MOSI_ADDR + 4, m->tx_data);
	litepcie_writel(s, CSR_FLASH_SPI_CONTROL_ADDR,
		SPI_CTRL_START | (m->tx_len * SPI_CTRL_LENGTH));
	udelay(16);
	for (i = 0; i < SPI_TIMEOUT; i++) {
		if (litepcie_readl(s, CSR_FLASH_SPI_STATUS_ADDR) & SPI_STATUS_DONE)
			break;
		udelay(1);
	}
	m->rx_data = ((uint64_t)litepcie_readl(s, CSR_FLASH_SPI_MISO_ADDR) << 32) |
		litepcie_readl(s, CSR_FLASH_SPI_MISO_ADDR + 4);
	return 0;
}
#endif

static long litepcie_ioctl(struct file *file, unsigned int cmd,
			   unsigned long arg)
{
	long ret = 0;

	struct litepcie_chan_priv *chan_priv = file->private_data;
	struct litepcie_chan *chan = chan_priv->chan;
	struct litepcie_device *dev = chan->litepcie_dev;

	switch (cmd) {
	case LITEPCIE_IOCTL_REG:
	{
		struct litepcie_ioctl_reg m;

		if (copy_from_user(&m, (void *)arg, sizeof(m))) {
			ret = -EFAULT;
			break;
		}
		if (m.is_write)
			litepcie_writel(dev, m.addr, m.val);
		else
			m.val = litepcie_readl(dev, m.addr);

		if (copy_to_user((void *)arg, &m, sizeof(m))) {
			ret = -EFAULT;
			break;
		}
	}
	break;
#ifdef CSR_FLASH_BASE
	case LITEPCIE_IOCTL_FLASH:
	{
		struct litepcie_ioctl_flash m;

		if (copy_from_user(&m, (void *)arg, sizeof(m))) {
			ret = -EFAULT;
			break;
		}
		ret = litepcie_flash_spi(dev, &m);
		if (ret == 0) {
			if (copy_to_user((void *)arg, &m, sizeof(m))) {
				ret = -EFAULT;
				break;
			}
		}
	}
	break;
#endif
#ifdef CSR_ICAP_BASE
	case LITEPCIE_IOCTL_ICAP:
	{
		struct litepcie_ioctl_icap m;

		if (copy_from_user(&m, (void *)arg, sizeof(m))) {
			ret = -EFAULT;
			break;
		}

		litepcie_writel(dev, CSR_ICAP_ADDR_ADDR, m.addr);
		litepcie_writel(dev, CSR_ICAP_DATA_ADDR, m.data);
		litepcie_writel(dev, CSR_ICAP_WRITE_ADDR, 1);
	}
	break;
#endif
	case LITEPCIE_IOCTL_DMA:
	{
		struct litepcie_ioctl_dma m;

		if (copy_from_user(&m, (void *)arg, sizeof(m))) {
			ret = -EFAULT;
			break;
		}

		/* loopback */
		litepcie_writel(chan->litepcie_dev, chan->dma.base + PCIE_DMA_LOOPBACK_ENABLE_OFFSET, m.loopback_enable);
	}
	break;
	case LITEPCIE_IOCTL_DMA_WRITER:
	{
		struct litepcie_ioctl_dma_writer m;

		if (copy_from_user(&m, (void *)arg, sizeof(m))) {
			ret = -EFAULT;
			break;
		}

		if (m.enable != chan->dma.writer_enable) {
			/* enable / disable DMA */
			if (m.enable) {
				litepcie_dma_writer_start(chan->litepcie_dev, chan->index);
				litepcie_enable_interrupt(chan->litepcie_dev, chan->dma.writer_interrupt);
			} else {
				litepcie_disable_interrupt(chan->litepcie_dev, chan->dma.writer_interrupt);
				litepcie_dma_writer_stop(chan->litepcie_dev, chan->index);
			}

		}

		chan->dma.writer_enable = m.enable;

		m.hw_count = chan->dma.writer_hw_count;
		m.sw_count = chan->dma.writer_sw_count;

		if (copy_to_user((void *)arg, &m, sizeof(m))) {
			ret = -EFAULT;
			break;
		}

	}
	break;
	case LITEPCIE_IOCTL_DMA_READER:
	{
		struct litepcie_ioctl_dma_reader m;

		if (copy_from_user(&m, (void *)arg, sizeof(m))) {
			ret = -EFAULT;
			break;
		}

		if (m.enable != chan->dma.reader_enable) {
			/* enable / disable DMA */
			if (m.enable) {
				litepcie_dma_reader_start(chan->litepcie_dev, chan->index);
				litepcie_enable_interrupt(chan->litepcie_dev, chan->dma.reader_interrupt);
			} else {
				litepcie_disable_interrupt(chan->litepcie_dev, chan->dma.reader_interrupt);
				litepcie_dma_reader_stop(chan->litepcie_dev, chan->index);
			}
		}

		chan->dma.reader_enable = m.enable;

		m.hw_count = chan->dma.reader_hw_count;
		m.sw_count = chan->dma.reader_sw_count;

		if (copy_to_user((void *)arg, &m, sizeof(m))) {
			ret = -EFAULT;
			break;
		}

	}
	break;
	case LITEPCIE_IOCTL_MMAP_DMA_INFO:
	{
		struct litepcie_ioctl_mmap_dma_info m;

		m.dma_tx_buf_offset = 0;
		m.dma_tx_buf_size = DMA_BUFFER_SIZE;
		m.dma_tx_buf_count = DMA_BUFFER_COUNT;

		m.dma_rx_buf_offset = DMA_BUFFER_TOTAL_SIZE;
		m.dma_rx_buf_size = DMA_BUFFER_SIZE;
		m.dma_rx_buf_count = DMA_BUFFER_COUNT;

		if (copy_to_user((void *)arg, &m, sizeof(m))) {
			ret = -EFAULT;
			break;
		}
	}
	break;
	case LITEPCIE_IOCTL_MMAP_DMA_WRITER_UPDATE:
	{
		struct litepcie_ioctl_mmap_dma_update m;

		if (copy_from_user(&m, (void *)arg, sizeof(m))) {
			ret = -EFAULT;
			break;
		}

		chan->dma.writer_sw_count = m.sw_count;
	}
	break;
	case LITEPCIE_IOCTL_MMAP_DMA_READER_UPDATE:
	{
		struct litepcie_ioctl_mmap_dma_update m;

		if (copy_from_user(&m, (void *)arg, sizeof(m))) {
			ret = -EFAULT;
			break;
		}

		chan->dma.reader_sw_count = m.sw_count;
	}
	break;
	case LITEPCIE_IOCTL_LOCK:
	{
		struct litepcie_ioctl_lock m;


		if (copy_from_user(&m, (void *)arg, sizeof(m))) {
			ret = -EFAULT;
			break;
		}

		m.dma_reader_status = 1;
		if (m.dma_reader_request) {
			if (chan->dma.reader_lock) {
				m.dma_reader_status = 0;
			} else {
				chan->dma.reader_lock = 1;
				chan_priv->reader = 1;
			}
		}
		if (m.dma_reader_release) {
			chan->dma.reader_lock = 0;
			chan_priv->reader = 0;
		}

		m.dma_writer_status = 1;
		if (m.dma_writer_request) {
			if (chan->dma.writer_lock) {
				m.dma_writer_status = 0;
			} else {
				chan->dma.writer_lock = 1;
				chan_priv->writer = 1;
			}
		}
		if (m.dma_writer_release) {
			chan->dma.writer_lock = 0;
			chan_priv->writer = 0;
		}

		if (copy_to_user((void *)arg, &m, sizeof(m))) {
			ret = -EFAULT;
			break;
		}

	}
	break;
	default:
		ret = -ENOIOCTLCMD;
		break;
	}
	return ret;
}

static const struct file_operations litepcie_fops = {
	.owner = THIS_MODULE,
	.unlocked_ioctl = litepcie_ioctl,
	.open = litepcie_open,
	.release = litepcie_release,
	.read = litepcie_read,
	.poll = litepcie_poll,
	.write = litepcie_write,
	.mmap = litepcie_mmap,
};

static int litepcie_alloc_chdev(struct litepcie_device *s)
{
	int i, j;
	int ret;
	int index;

	index = litepcie_minor_idx;
	s->minor_base = litepcie_minor_idx;
	for (i = 0; i < s->channels; i++) {
		cdev_init(&s->chan[i].cdev, &litepcie_fops);
		ret = cdev_add(&s->chan[i].cdev, MKDEV(litepcie_major, index), 1);
		if (ret < 0) {
			dev_err(&s->dev->dev, "Failed to allocate cdev\n");
			goto fail_alloc;
		}
		index++;
	}

	index = litepcie_minor_idx;
	for (i = 0; i < s->channels; i++) {
		dev_info(&s->dev->dev, "Creating /dev/litepcie%d\n", index);
		if (!device_create(litepcie_class, NULL, MKDEV(litepcie_major, index), NULL, "litepcie%d", index)) {
			ret = -EINVAL;
			dev_err(&s->dev->dev, "Failed to create device\n");
			goto fail_create;
		}
		index++;

	}

	litepcie_minor_idx = index;
	return 0;

fail_create:
	index = litepcie_minor_idx;
	for (j = 0; j < i; j++)
		device_destroy(litepcie_class, MKDEV(litepcie_major, index++));

fail_alloc:
	for (i = 0; i < s->channels; i++)
		cdev_del(&s->chan[i].cdev);

	return ret;
}

static void litepcie_free_chdev(struct litepcie_device *s)
{
	int i;

	for (i = 0; i < s->channels; i++) {
		device_destroy(litepcie_class, MKDEV(litepcie_major, s->minor_base + i));
		cdev_del(&s->chan[i].cdev);
	}
}

/* Function to probe the LitePCIe PCI device */
static int litepcie_pci_probe(struct pci_dev *dev, const struct pci_device_id *id)
{
	int ret = 0;
	int irqs = 0;
	uint8_t rev_id;
	int i;
	char fpga_identifier[256];
	struct litepcie_device *litepcie_dev = NULL;
#ifdef CSR_UART_XOVER_RXTX_ADDR
	struct resource *tty_res = NULL;
#endif

	dev_info(&dev->dev, "\e[1m[Probing device]\e[0m\n");

	/* Allocate memory for the LitePCIe device structure */
	litepcie_dev = devm_kzalloc(&dev->dev, sizeof(struct litepcie_device), GFP_KERNEL);
	if (!litepcie_dev) {
		ret = -ENOMEM;
		goto fail1;
	}

	pci_set_drvdata(dev, litepcie_dev);
	litepcie_dev->dev = dev;
	spin_lock_init(&litepcie_dev->lock);

	/* Enable the PCI device */
	ret = pcim_enable_device(dev);
	if (ret != 0) {
		dev_err(&dev->dev, "Cannot enable device\n");
		goto fail1;
	}

	ret = -EIO;

	/* Check the device version */
	pci_read_config_byte(dev, PCI_REVISION_ID, &rev_id);
	if (rev_id != 0) {
		dev_err(&dev->dev, "Unsupported device version %d\n", rev_id);
		goto fail1;
	}

	/* Check the BAR0 configuration */
	if (!(pci_resource_flags(dev, 0) & IORESOURCE_MEM)) {
		dev_err(&dev->dev, "Invalid BAR0 configuration\n");
		goto fail1;
	}

	/* Request and map BAR0 */
	if (pcim_iomap_regions(dev, BIT(0), LITEPCIE_NAME) < 0) {
		dev_err(&dev->dev, "Could not request regions\n");
		goto fail1;
	}

	litepcie_dev->bar0_addr = pcim_iomap_table(dev)[0];
	if (!litepcie_dev->bar0_addr) {
		dev_err(&dev->dev, "Could not map BAR0\n");
		goto fail1;
	}

	/* Reset LitePCIe core */
#ifdef CSR_CTRL_RESET_ADDR
	litepcie_writel(litepcie_dev, CSR_CTRL_RESET_ADDR, 1);
	msleep(10);
#endif

	/* Read and display the FPGA identifier */
	for (i = 0; i < 256; i++)
		fpga_identifier[i] = litepcie_readl(litepcie_dev, CSR_IDENTIFIER_MEM_BASE + i * 4);
	dev_info(&dev->dev, "Version %s\n", fpga_identifier);

	pci_set_master(dev);
#if LINUX_VERSION_CODE < KERNEL_VERSION(5, 18, 0)
	ret = pci_set_dma_mask(dev, DMA_BIT_MASK(DMA_ADDR_WIDTH));
#else
	ret = dma_set_mask(&dev->dev, DMA_BIT_MASK(DMA_ADDR_WIDTH));
#endif
	if (ret) {
		dev_err(&dev->dev, "Failed to set DMA mask\n");
		goto fail1;
	}


/* MSI-X */
#ifdef CSR_PCIE_MSI_PBA_ADDR
	irqs = pci_alloc_irq_vectors(dev, 1, 32, PCI_IRQ_MSIX);
/* MSI Single / MultiVector */
#else
	irqs = pci_alloc_irq_vectors(dev, 1, 32, PCI_IRQ_MSI);
#endif
	if (irqs < 0) {
		dev_err(&dev->dev, "Failed to enable MSI\n");
		ret = irqs;
		goto fail1;
	}
/* MSI-X */
#ifdef CSR_PCIE_MSI_PBA_ADDR
	dev_info(&dev->dev, "%d MSI-X IRQs allocated.\n", irqs);
/* MSI Single / MultiVector */
#else
	dev_info(&dev->dev, "%d MSI IRQs allocated.\n", irqs);
#endif

	litepcie_dev->irqs = 0;
	for (i = 0; i < irqs; i++) {
		int irq = pci_irq_vector(dev, i);

		/* Request IRQ */
		ret = request_irq(irq, litepcie_interrupt, 0, LITEPCIE_NAME, litepcie_dev);
		if (ret < 0) {
			dev_err(&dev->dev, " Failed to allocate IRQ %d\n", dev->irq);
			while (--i >= 0) {
				irq = pci_irq_vector(dev, i);
				free_irq(irq, dev);
			}
			goto fail2;
		}
		litepcie_dev->irqs += 1;
	}

	litepcie_dev->channels = DMA_CHANNELS;

	/* create all chardev in /dev */
	ret = litepcie_alloc_chdev(litepcie_dev);
	if (ret) {
		dev_err(&dev->dev, "Failed to allocate character device\n");
		goto fail2;
	}

	for (i = 0; i < litepcie_dev->channels; i++) {
		litepcie_dev->chan[i].index = i;
		litepcie_dev->chan[i].block_size = DMA_BUFFER_SIZE;
		litepcie_dev->chan[i].minor = litepcie_dev->minor_base + i;
		litepcie_dev->chan[i].litepcie_dev = litepcie_dev;
		litepcie_dev->chan[i].dma.writer_lock = 0;
		litepcie_dev->chan[i].dma.reader_lock = 0;
		init_waitqueue_head(&litepcie_dev->chan[i].wait_rd);
		init_waitqueue_head(&litepcie_dev->chan[i].wait_wr);
		switch (i) {
#ifdef CSR_PCIE_DMA7_BASE
		case 7: {
		litepcie_dev->chan[i].dma.base = CSR_PCIE_DMA7_BASE;
		litepcie_dev->chan[i].dma.writer_interrupt = PCIE_DMA7_WRITER_INTERRUPT;
		litepcie_dev->chan[i].dma.reader_interrupt = PCIE_DMA7_READER_INTERRUPT;
	}
	break;
#endif
#ifdef CSR_PCIE_DMA6_BASE
		case 6: {
		litepcie_dev->chan[i].dma.base = CSR_PCIE_DMA6_BASE;
		litepcie_dev->chan[i].dma.writer_interrupt = PCIE_DMA6_WRITER_INTERRUPT;
		litepcie_dev->chan[i].dma.reader_interrupt = PCIE_DMA6_READER_INTERRUPT;
	}
	break;
#endif
#ifdef CSR_PCIE_DMA5_BASE
		case 5: {
		litepcie_dev->chan[i].dma.base = CSR_PCIE_DMA5_BASE;
		litepcie_dev->chan[i].dma.writer_interrupt = PCIE_DMA5_WRITER_INTERRUPT;
		litepcie_dev->chan[i].dma.reader_interrupt = PCIE_DMA5_READER_INTERRUPT;
	}
	break;
#endif
#ifdef CSR_PCIE_DMA4_BASE
		case 4: {
		litepcie_dev->chan[i].dma.base = CSR_PCIE_DMA4_BASE;
		litepcie_dev->chan[i].dma.writer_interrupt = PCIE_DMA4_WRITER_INTERRUPT;
		litepcie_dev->chan[i].dma.reader_interrupt = PCIE_DMA4_READER_INTERRUPT;
	}
	break;
#endif
#ifdef CSR_PCIE_DMA3_BASE
		case 3: {
		litepcie_dev->chan[i].dma.base = CSR_PCIE_DMA3_BASE;
		litepcie_dev->chan[i].dma.writer_interrupt = PCIE_DMA3_WRITER_INTERRUPT;
		litepcie_dev->chan[i].dma.reader_interrupt = PCIE_DMA3_READER_INTERRUPT;
	}
	break;
#endif
#ifdef CSR_PCIE_DMA2_BASE
		case 2: {
		litepcie_dev->chan[i].dma.base = CSR_PCIE_DMA2_BASE;
		litepcie_dev->chan[i].dma.writer_interrupt = PCIE_DMA2_WRITER_INTERRUPT;
		litepcie_dev->chan[i].dma.reader_interrupt = PCIE_DMA2_READER_INTERRUPT;
	}
	break;
#endif
#ifdef CSR_PCIE_DMA1_BASE
		case 1: {
		litepcie_dev->chan[i].dma.base = CSR_PCIE_DMA1_BASE;
		litepcie_dev->chan[i].dma.writer_interrupt = PCIE_DMA1_WRITER_INTERRUPT;
		litepcie_dev->chan[i].dma.reader_interrupt = PCIE_DMA1_READER_INTERRUPT;
	}
	break;
#endif
		default:
			{
				litepcie_dev->chan[i].dma.base = CSR_PCIE_DMA0_BASE;
				litepcie_dev->chan[i].dma.writer_interrupt = PCIE_DMA0_WRITER_INTERRUPT;
				litepcie_dev->chan[i].dma.reader_interrupt = PCIE_DMA0_READER_INTERRUPT;
			}
			break;
		}
	}

	/* allocate all dma buffers */
	ret = litepcie_dma_init(litepcie_dev);
	if (ret) {
		dev_err(&dev->dev, "Failed to allocate DMA\n");
		goto fail3;
	}

#ifdef CSR_UART_XOVER_RXTX_ADDR
	tty_res = devm_kzalloc(&dev->dev, sizeof(struct resource), GFP_KERNEL);
	if (!tty_res)
		return -ENOMEM;
	tty_res->start =
		(resource_size_t) litepcie_dev->bar0_addr +
		CSR_UART_XOVER_RXTX_ADDR - CSR_BASE;
	tty_res->flags = IORESOURCE_REG;
	litepcie_dev->uart = platform_device_register_simple("liteuart", litepcie_minor_idx, tty_res, 1);
	if (IS_ERR(litepcie_dev->uart)) {
		ret = PTR_ERR(litepcie_dev->uart);
		goto fail3;
	}
#endif

	return 0;

fail3:
	litepcie_free_chdev(litepcie_dev);
fail2:
	pci_free_irq_vectors(dev);
fail1:
	return ret;
}

/* Function to remove the LitePCIe PCI device */
static void litepcie_pci_remove(struct pci_dev *dev)
{
	int i, irq;
	struct litepcie_device *litepcie_dev;

	litepcie_dev = pci_get_drvdata(dev);

	dev_info(&dev->dev, "\e[1m[Removing device]\e[0m\n");

	/* Stop the DMAs */
	litepcie_stop_dma(litepcie_dev);

	/* Disable all interrupts */
	litepcie_writel(litepcie_dev, CSR_PCIE_MSI_ENABLE_ADDR, 0);

	/* Free all IRQs */
	for (i = 0; i < litepcie_dev->irqs; i++) {
		irq = pci_irq_vector(dev, i);
		free_irq(irq, litepcie_dev);
	}

	platform_device_unregister(litepcie_dev->uart);

	litepcie_free_chdev(litepcie_dev);

	pci_free_irq_vectors(dev);
}

/* PCI device ID table */
static const struct pci_device_id litepcie_pci_ids[] = {
	/* Xilinx */
	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_S7_GEN2_X1), },
	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_S7_GEN2_X2), },
	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_S7_GEN2_X4), },
	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_S7_GEN2_X8), },

	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_US_GEN2_X1), },
	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_US_GEN2_X2), },
	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_US_GEN2_X4), },
	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_US_GEN2_X8), },

	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_US_GEN3_X1), },
	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_US_GEN3_X2), },
	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_US_GEN3_X4), },
	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_US_GEN3_X8), },

	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_USP_GEN2_X1),  },
	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_USP_GEN2_X2),  },
	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_USP_GEN2_X4),  },
	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_USP_GEN2_X8),  },
	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_USP_GEN2_X16), },

	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_USP_GEN3_X1),  },
	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_USP_GEN3_X2),  },
	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_USP_GEN3_X4),  },
	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_USP_GEN3_X8),  },
	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_USP_GEN3_X16), },

	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_USP_GEN4_X1),  },
	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_USP_GEN4_X2),  },
	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_USP_GEN4_X4),  },
	{ PCI_DEVICE(PCIE_XILINX_VENDOR_ID, PCIE_XILINX_DEVICE_ID_USP_GEN4_X8),  },

	/* Lattice */
	{ PCI_DEVICE(PCIE_LATTICE_VENDOR_ID, PCIE_LATTICE_DEVICE_ID_CPNX_GEN3_X4),  },

	/* Gowin */
	{ PCI_DEVICE(PCIE_GOWIN_VENDOR_ID, PCIE_GOWIN_DEVICE_ID_GW5AT_GEN2_X4),  },

	{ 0, }
};
MODULE_DEVICE_TABLE(pci, litepcie_pci_ids);

/* PCI driver structure */
static struct pci_driver litepcie_pci_driver = {
	.name = LITEPCIE_NAME,
	.id_table = litepcie_pci_ids,
	.probe = litepcie_pci_probe,
	.remove = litepcie_pci_remove,
};

/* Module initialization function */
static int __init litepcie_module_init(void)
{
	int ret;

	#if LINUX_VERSION_CODE < KERNEL_VERSION(6, 4, 0)
		litepcie_class = class_create(THIS_MODULE, LITEPCIE_NAME);
	#else
		litepcie_class = class_create(LITEPCIE_NAME);
	#endif
	if (!litepcie_class) {
		ret = -EEXIST;
		pr_err(" Failed to create class\n");
		goto fail_create_class;
	}

	ret = alloc_chrdev_region(&litepcie_dev_t, 0, LITEPCIE_MINOR_COUNT, LITEPCIE_NAME);
	if (ret < 0) {
		pr_err(" Could not allocate char device\n");
		goto fail_alloc_chrdev_region;
	}
	litepcie_major = MAJOR(litepcie_dev_t);
	litepcie_minor_idx = MINOR(litepcie_dev_t);

	ret = pci_register_driver(&litepcie_pci_driver);
	if (ret < 0) {
		pr_err(" Error while registering PCI driver\n");
		goto fail_register;
	}

	return 0;

fail_register:
	unregister_chrdev_region(litepcie_dev_t, LITEPCIE_MINOR_COUNT);
fail_alloc_chrdev_region:
	class_destroy(litepcie_class);
fail_create_class:
	return ret;
}

/* Module exit function */
static void __exit litepcie_module_exit(void)
{
	pci_unregister_driver(&litepcie_pci_driver);
	unregister_chrdev_region(litepcie_dev_t, LITEPCIE_MINOR_COUNT);
	class_destroy(litepcie_class);
}

module_init(litepcie_module_init);
module_exit(litepcie_module_exit);

MODULE_LICENSE("GPL");

```

`litepcie/software/user/Makefile`:

```
CFLAGS=-O2 -Wall -g -I../kernel -Iliblitepcie -MMD -fPIC
LDFLAGS=-g
CC=$(CROSS_COMPILE)gcc
AR=ar

PROGS=litepcie_util litepcie_test

all: $(PROGS)

liblitepcie/liblitepcie.a: liblitepcie/litepcie_dma.o liblitepcie/litepcie_flash.o liblitepcie/litepcie_helpers.o
	ar rcs $@ $+
	ranlib $@

litepcie_util: liblitepcie/liblitepcie.a litepcie_util.o
	$(CC) $(LDFLAGS) -o $@ $^ -Lliblitepcie -llitepcie

litepcie_test: liblitepcie/liblitepcie.a litepcie_test.o
	$(CC) $(LDFLAGS) -o $@ $^ -Lliblitepcie -lm -llitepcie

clean:
	rm -f $(PROGS) *.o *.a *.d *~ liblitepcie/*.a liblitepcie/*.o liblitepcie/*.d

%.o: %.c
	$(CC) -c $(CFLAGS) -o $@ $<

liblitepcie/%.o: liblitepcie/%.c
	$(CC) -c $(CFLAGS) -o $@ $<

-include $(wildcard *.d)

```

`litepcie/software/user/liblitepcie/liblitepcie.h`:

```h
/* SPDX-License-Identifier: BSD-2-Clause
 *
 * LitePCIe library
 *
 * This file is part of LitePCIe.
 *
 * Copyright (C) 2018-2023 / EnjoyDigital  / florent@enjoy-digital.fr
 *
 */

#ifndef LITEPCIE_LIB_H
#define LITEPCIE_LIB_H

#ifdef __cplusplus
extern "C" {
#endif

#include "litepcie_dma.h"
#include "litepcie_flash.h"
#include "litepcie_helpers.h"
#include "litepcie.h"

#ifdef __cplusplus
}
#endif

#endif /* LITEPCIE_LIB_H */

```

`litepcie/software/user/liblitepcie/litepcie_dma.c`:

```c
/* SPDX-License-Identifier: BSD-2-Clause
 *
 * LitePCIe library
 *
 * This file is part of LitePCIe.
 *
 * Copyright (C) 2018-2023 / EnjoyDigital  / florent@enjoy-digital.fr
 *
 */

#include <stdio.h>
#include <stdlib.h>
#include <fcntl.h>
#include <unistd.h>
#include <sys/mman.h>
#include "litepcie_dma.h"
#include "litepcie_helpers.h"


void litepcie_dma_set_loopback(int fd, uint8_t loopback_enable) {
    struct litepcie_ioctl_dma m;
    m.loopback_enable = loopback_enable;
    checked_ioctl(fd, LITEPCIE_IOCTL_DMA, &m);
}

void litepcie_dma_writer(int fd, uint8_t enable, int64_t *hw_count, int64_t *sw_count) {
    struct litepcie_ioctl_dma_writer m;
    m.enable = enable;
    checked_ioctl(fd, LITEPCIE_IOCTL_DMA_WRITER, &m);
    *hw_count = m.hw_count;
    *sw_count = m.sw_count;
}

void litepcie_dma_reader(int fd, uint8_t enable, int64_t *hw_count, int64_t *sw_count) {
    struct litepcie_ioctl_dma_reader m;
    m.enable = enable;
    checked_ioctl(fd, LITEPCIE_IOCTL_DMA_READER, &m);
    *hw_count = m.hw_count;
    *sw_count = m.sw_count;
}

/* lock */

uint8_t litepcie_request_dma(int fd, uint8_t reader, uint8_t writer) {
    struct litepcie_ioctl_lock m;
    m.dma_reader_request = reader > 0;
    m.dma_writer_request = writer > 0;
    m.dma_reader_release = 0;
    m.dma_writer_release = 0;
    checked_ioctl(fd, LITEPCIE_IOCTL_LOCK, &m);
    return m.dma_reader_status;
}

void litepcie_release_dma(int fd, uint8_t reader, uint8_t writer) {
    struct litepcie_ioctl_lock m;
    m.dma_reader_request = 0;
    m.dma_writer_request = 0;
    m.dma_reader_release = reader > 0;
    m.dma_writer_release = writer > 0;
    checked_ioctl(fd, LITEPCIE_IOCTL_LOCK, &m);
}

int litepcie_dma_init(struct litepcie_dma_ctrl *dma, const char *device_name, uint8_t zero_copy)
{
    dma->reader_hw_count = 0;
    dma->reader_sw_count = 0;
    dma->writer_hw_count = 0;
    dma->writer_sw_count = 0;

    dma->zero_copy = zero_copy;

    if (dma->use_reader)
        dma->fds.events |= POLLOUT;
    if (dma->use_writer)
        dma->fds.events |= POLLIN;

    dma->fds.fd = open(device_name, O_RDWR | O_CLOEXEC);
    if (dma->fds.fd < 0) {
        fprintf(stderr, "Could not open device\n");
        return -1;
    }

    /* request dma reader and writer */
    if ((litepcie_request_dma(dma->fds.fd, dma->use_reader, dma->use_writer) == 0)) {
        fprintf(stderr, "DMA not available\n");
        return -1;
    }

    litepcie_dma_set_loopback(dma->fds.fd, dma->loopback);

    if (dma->zero_copy) {
        /* if mmap: get it from the kernel */
        checked_ioctl(dma->fds.fd, LITEPCIE_IOCTL_MMAP_DMA_INFO, &dma->mmap_dma_info);
        if (dma->use_writer) {
            dma->buf_rd = mmap(NULL, DMA_BUFFER_TOTAL_SIZE, PROT_READ | PROT_WRITE, MAP_SHARED,
                               dma->fds.fd, dma->mmap_dma_info.dma_rx_buf_offset);
            if (dma->buf_rd == MAP_FAILED) {
                fprintf(stderr, "MMAP failed\n");
                return -1;
            }
        }
        if (dma->use_reader) {
            dma->buf_wr = mmap(NULL, DMA_BUFFER_TOTAL_SIZE, PROT_WRITE, MAP_SHARED,
                               dma->fds.fd, dma->mmap_dma_info.dma_tx_buf_offset);
            if (dma->buf_wr == MAP_FAILED) {
                fprintf(stderr, "MMAP failed\n");
                return -1;
            }
        }
    } else {
        /* else: allocate it */
        if (dma->use_writer) {
            dma->buf_rd = calloc(1, DMA_BUFFER_TOTAL_SIZE);
            if (!dma->buf_rd) {
                fprintf(stderr, "%d: alloc failed\n", __LINE__);
                return -1;
            }
        }
        if (dma->use_reader) {
            dma->buf_wr = calloc(1, DMA_BUFFER_TOTAL_SIZE);
            if (!dma->buf_wr) {
                free(dma->buf_rd);
                fprintf(stderr, "%d: alloc failed\n", __LINE__);
                return -1;
            }
        }
    }

    return 0;
}

void litepcie_dma_cleanup(struct litepcie_dma_ctrl *dma)
{
    if (dma->use_reader)
        litepcie_dma_reader(dma->fds.fd, 0, &dma->reader_hw_count, &dma->reader_sw_count);
    if (dma->use_writer)
        litepcie_dma_writer(dma->fds.fd, 0, &dma->writer_hw_count, &dma->writer_sw_count);

    litepcie_release_dma(dma->fds.fd, dma->use_reader, dma->use_writer);

    if (dma->zero_copy) {
        if (dma->use_reader)
            munmap(dma->buf_wr, dma->mmap_dma_info.dma_tx_buf_size * dma->mmap_dma_info.dma_tx_buf_count);
        if (dma->use_writer)
            munmap(dma->buf_rd, dma->mmap_dma_info.dma_tx_buf_size * dma->mmap_dma_info.dma_tx_buf_count);
    } else {
        free(dma->buf_rd);
        free(dma->buf_wr);
    }

    close(dma->fds.fd);
}

void litepcie_dma_process(struct litepcie_dma_ctrl *dma)
{
    ssize_t len;
    int ret;

    /* set / get dma */
    if (dma->use_writer)
        litepcie_dma_writer(dma->fds.fd, dma->writer_enable, &dma->writer_hw_count, &dma->writer_sw_count);
    if (dma->use_reader)
        litepcie_dma_reader(dma->fds.fd, dma->reader_enable, &dma->reader_hw_count, &dma->reader_sw_count);

    /* polling */
    ret = poll(&dma->fds, 1, 100);
    if (poll < 0) {
        perror("poll");
        return;
    } else if (ret == 0) {
        /* timeout */
        return;
    }

    /* read event */
    if (dma->fds.revents & POLLIN) {
        if (dma->zero_copy) {
            /* count available buffers */
            dma->buffers_available_read = dma->writer_hw_count - dma->writer_sw_count;
            dma->usr_read_buf_offset = dma->writer_sw_count % DMA_BUFFER_COUNT;

            /* update dma sw_count*/
            dma->mmap_dma_update.sw_count = dma->writer_sw_count + dma->buffers_available_read;
            checked_ioctl(dma->fds.fd, LITEPCIE_IOCTL_MMAP_DMA_WRITER_UPDATE, &dma->mmap_dma_update);
        } else {
            len = read(dma->fds.fd, dma->buf_rd, DMA_BUFFER_TOTAL_SIZE);
            if (len < 0) {
                perror("read");
                abort();
            }
            dma->buffers_available_read = len / DMA_BUFFER_SIZE;
            dma->usr_read_buf_offset = 0;
        }
    } else {
        dma->buffers_available_read = 0;
    }

    /* write event */
    if (dma->fds.revents & POLLOUT) {
        if (dma->zero_copy) {
            /* count available buffers */
            dma->buffers_available_write = DMA_BUFFER_COUNT / 2 - (dma->reader_sw_count - dma->reader_hw_count);
            dma->usr_write_buf_offset = dma->reader_sw_count % DMA_BUFFER_COUNT;

            /* update dma sw_count */
            dma->mmap_dma_update.sw_count = dma->reader_sw_count + dma->buffers_available_write;
            checked_ioctl(dma->fds.fd, LITEPCIE_IOCTL_MMAP_DMA_READER_UPDATE, &dma->mmap_dma_update);

        } else {
            len = write(dma->fds.fd, dma->buf_wr, DMA_BUFFER_TOTAL_SIZE);
            if (len < 0) {
                perror("write");
                abort();
            }
            dma->buffers_available_write = len / DMA_BUFFER_SIZE;
            dma->usr_write_buf_offset = 0;
        }
    } else {
        dma->buffers_available_write = 0;
    }
}

char *litepcie_dma_next_read_buffer(struct litepcie_dma_ctrl *dma)
{
    if (!dma->buffers_available_read)
        return NULL;
    dma->buffers_available_read --;
    char *ret = dma->buf_rd + dma->usr_read_buf_offset * DMA_BUFFER_SIZE;
    dma->usr_read_buf_offset = (dma->usr_read_buf_offset + 1) % DMA_BUFFER_COUNT;
    return ret;
}

char *litepcie_dma_next_write_buffer(struct litepcie_dma_ctrl *dma)
{
    if (!dma->buffers_available_write)
        return NULL;
    dma->buffers_available_write --;
    char *ret = dma->buf_wr + dma->usr_write_buf_offset * DMA_BUFFER_SIZE;
    dma->usr_write_buf_offset = (dma->usr_write_buf_offset + 1) % DMA_BUFFER_COUNT;
    return ret;
}

```

`litepcie/software/user/liblitepcie/litepcie_dma.h`:

```h
/* SPDX-License-Identifier: BSD-2-Clause
 *
 * LitePCIe library
 *
 * This file is part of LitePCIe.
 *
 * Copyright (C) 2018-2023 / EnjoyDigital  / florent@enjoy-digital.fr
 *
 */

#ifndef LITEPCIE_LIB_DMA_H
#define LITEPCIE_LIB_DMA_H

#include <stdint.h>
#include <poll.h>
#include "litepcie.h"

struct litepcie_dma_ctrl {
    uint8_t use_reader, use_writer, loopback, zero_copy;
    struct pollfd fds;
    char *buf_rd, *buf_wr;
    uint8_t reader_enable;
    uint8_t writer_enable;
    int64_t reader_hw_count, reader_sw_count;
    int64_t writer_hw_count, writer_sw_count;
    unsigned buffers_available_read, buffers_available_write;
    unsigned usr_read_buf_offset, usr_write_buf_offset;
    struct litepcie_ioctl_mmap_dma_info mmap_dma_info;
    struct litepcie_ioctl_mmap_dma_update mmap_dma_update;
};

void litepcie_dma_set_loopback(int fd, uint8_t loopback_enable);
void litepcie_dma_reader(int fd, uint8_t enable, int64_t *hw_count, int64_t *sw_count);
void litepcie_dma_writer(int fd, uint8_t enable, int64_t *hw_count, int64_t *sw_count);

uint8_t litepcie_request_dma(int fd, uint8_t reader, uint8_t writer);
void litepcie_release_dma(int fd, uint8_t reader, uint8_t writer);

int litepcie_dma_init(struct litepcie_dma_ctrl *dma, const char *device_name, uint8_t zero_copy);
void litepcie_dma_cleanup(struct litepcie_dma_ctrl *dma);
void litepcie_dma_process(struct litepcie_dma_ctrl *dma);
char *litepcie_dma_next_read_buffer(struct litepcie_dma_ctrl *dma);
char *litepcie_dma_next_write_buffer(struct litepcie_dma_ctrl *dma);

#endif /* LITEPCIE_LIB_DMA_H */

```

`litepcie/software/user/liblitepcie/litepcie_flash.c`:

```c
/* SPDX-License-Identifier: BSD-2-Clause
 *
 * LitePCIe library
 *
 * This file is part of LitePCIe.
 *
 * Copyright (C) 2018-2023 / EnjoyDigital  / florent@enjoy-digital.fr
 *
 */

#include <sys/ioctl.h>
#include <stdio.h>
#include <unistd.h>
#include <string.h>
#include "litepcie_flash.h"
#include "litepcie_helpers.h"
#include "litepcie.h"

#ifdef CSR_FLASH_BASE

//#define FLASH_FULL_ERASE
#define FLASH_RETRIES 16

static void flash_spi_cs(int fd, uint8_t cs_n)
{
    litepcie_writel(fd, CSR_FLASH_CS_N_OUT_ADDR, cs_n);
}

static uint64_t flash_spi(int fd, int tx_len, uint8_t cmd,
                          uint32_t tx_data)
{
    struct litepcie_ioctl_flash m;
    flash_spi_cs(fd, 0);
    m.tx_len = tx_len;
    m.tx_data = tx_data | ((uint64_t)cmd << 32);
    checked_ioctl(fd, LITEPCIE_IOCTL_FLASH, &m);
    flash_spi_cs(fd, 1);
    return m.rx_data;
}

uint32_t flash_read_id(int fd, int reg)
{
    return flash_spi(fd, 32, reg, 0) & 0xffffff;
}

static void flash_write_enable(int fd)
{
    flash_spi(fd, 8, FLASH_WREN, 0);
}

static void flash_write_disable(int fd)
{
    flash_spi(fd, 8, FLASH_WRDI, 0);
}

static uint8_t flash_read_status(int fd)
{
    return flash_spi(fd, 16, FLASH_RDSR, 0) & 0xff;
}

static __attribute__((unused)) void flash_write_status(int fd, uint8_t value)
{
    flash_spi(fd, 16, FLASH_WRSR, value << 24);
}

static __attribute__((unused)) void flash_erase_sector(int fd, uint32_t addr)
{
    flash_spi(fd, 32, FLASH_SE, addr << 8);
}

static __attribute__((unused)) uint8_t flash_read_sector_lock(int fd, uint32_t addr)
{
    return flash_spi(fd, 40, FLASH_WRSR, addr << 8) & 0xff;
}

static __attribute__((unused)) void flash_write_sector_lock(int fd, uint32_t addr, uint8_t byte)
{
    flash_spi(fd, 40, FLASH_WRSR, (addr << 8) | byte);
}

static void flash_write(int fd, uint32_t addr, uint8_t byte)
{
    flash_spi(fd, 40, FLASH_PP, (addr << 8) | byte);
}

static void flash_write_buffer(int fd, uint32_t addr, uint8_t *buf, uint16_t size)
{
    if (size == 1) {
        flash_write(fd, addr, buf[0]);
    } else {
        int i;
        struct litepcie_ioctl_flash m;

        /* set cs_n */
        flash_spi_cs(fd, 0);

        /* send cmd */
        m.tx_len = 32;
        m.tx_data = ((uint64_t)FLASH_PP << 32) | ((uint64_t)addr << 8);
        checked_ioctl(fd, LITEPCIE_IOCTL_FLASH, &m);

        /* send bytes */
        for (i=0; i<size; i+=4) {
            m.tx_len = 32;
            m.tx_data = (
                ((uint64_t)buf[i+0] << 32) |
                ((uint64_t)buf[i+1] << 24) |
                ((uint64_t)buf[i+2] << 16) |
                ((uint64_t)buf[i+3] << 8));
            checked_ioctl(fd, LITEPCIE_IOCTL_FLASH, &m);
        }

        /* release cs_n */
        flash_spi_cs(fd, 1);
    }
}

uint8_t litepcie_flash_read(int fd, uint32_t addr)
{
    return flash_spi(fd, 40, FLASH_READ, addr << 8) & 0xff;
}

static void litepcie_flash_read_buffer(int fd, uint32_t addr, uint8_t *buf, uint16_t size)
{
    int i;

    struct litepcie_ioctl_flash m;

    if (size == 1) {
        buf[0] = litepcie_flash_read(fd, addr);

    } else {
        /* set cs_n */
        flash_spi_cs(fd, 0);

        /* send cmd */
        m.tx_len = 32;
        m.tx_data = ((uint64_t)FLASH_READ << 32) | ((uint64_t)addr << 8);
        checked_ioctl(fd, LITEPCIE_IOCTL_FLASH, &m);

        /* read bytes */
        for (i=0; i<size; i+=4) {
            m.tx_len = 32;
            checked_ioctl(fd, LITEPCIE_IOCTL_FLASH, &m);
            buf[i+0] = (m.rx_data >> 24 & 0xff);
            buf[i+1] = (m.rx_data >> 16 & 0xff);
            buf[i+2] = (m.rx_data >>  8 & 0xff);
            buf[i+3] = (m.rx_data >>  0 & 0xff);
        }

        /* release cs_n */
        flash_spi_cs(fd, 1);
    }
}

int litepcie_flash_get_erase_block_size(int fd)
{
    return FLASH_SECTOR_SIZE;
}

static int litepcie_flash_get_flash_program_size(int fd)
{
    int software_cs = 1;
    /* if software cs control, program in blocks to speed up update */
    litepcie_writel(fd, CSR_FLASH_CS_N_OUT_ADDR, 0);
    software_cs &= ((litepcie_readl(fd, CSR_FLASH_CS_N_OUT_ADDR) & 0x1) == 0);
    litepcie_writel(fd, CSR_FLASH_CS_N_OUT_ADDR, 1);
    software_cs &= ((litepcie_readl(fd, CSR_FLASH_CS_N_OUT_ADDR) & 0x1) == 1);
    if (software_cs)
        return 256;
    else
        return 1;
}

int litepcie_flash_write(int fd,
                     uint8_t *buf, uint32_t base, uint32_t size,
                     void (*progress_cb)(void *opaque, const char *fmt, ...),
                     void *opaque)
{
    int i;
    int retries;
    uint16_t flash_program_size;

    flash_program_size = litepcie_flash_get_flash_program_size(fd);
    printf("flash_program_size: %d\n", flash_program_size);

    uint8_t cmp_buf[256];

    /* dummy command because in some case the first erase does not
       work. */
    flash_read_id(fd, 0);

    /* disable write protection */
     flash_write_enable(fd);

#ifndef FLASH_FULL_ERASE
    /* erase */
    for(i = 0; i < size; i += FLASH_SECTOR_SIZE) {
        if (progress_cb) {
            progress_cb(opaque, "Erasing @%08x\r", base + i);
        }
        flash_write_enable(fd);
        flash_erase_sector(fd, base + i);
        while (flash_read_status(fd) & FLASH_WIP) {
            usleep(1000);
        }
    }
    if (progress_cb) {
        progress_cb(opaque, "\n");
    }
#else
    /* erase full flash */
    printf("Erasing...\n");
    flash_write_enable(fd);
    flash_spi(fd, 8, 0xC7, 0);
    while (flash_read_status(fd) & FLASH_WIP) {
        usleep(1000);
    }
#endif
    flash_write_disable(fd);

    i = 0;
    retries = 0;
    while (i < size) {
        if (progress_cb && (i % FLASH_SECTOR_SIZE) == 0) {
            progress_cb(opaque, "Writing @%08x\r", base + i);
        }

        /* wait flash to be ready */
        while (flash_read_status(fd) & FLASH_WIP)
            usleep(100);

        /* write flash page */
        flash_write_enable(fd);
        flash_write_buffer(fd, base + i, buf + i, flash_program_size);
        flash_write_disable(fd);

        /* wait flash to be ready*/
        while (flash_read_status(fd) & FLASH_WIP)
            usleep(100);

        /* verify flash page */
        litepcie_flash_read_buffer(fd, base + i, cmp_buf, flash_program_size);
        if (memcmp(buf + i, cmp_buf, flash_program_size) != 0) {
            retries += 1;
        } else {
            i += flash_program_size;
            retries = 0;
        }

        if (retries > FLASH_RETRIES) {
            printf("Not able to write page\n");
            return 1;
        }
    }

    if (progress_cb) {
        progress_cb(opaque, "\n");
    }

    return 0;
}

#endif

```

`litepcie/software/user/liblitepcie/litepcie_flash.h`:

```h
/* SPDX-License-Identifier: BSD-2-Clause
 *
 * LitePCIe library
 *
 * This file is part of LitePCIe.
 *
 * Copyright (C) 2018-2023 / EnjoyDigital  / florent@enjoy-digital.fr
 *
 */

#ifndef LITEPCIE_LIB_FLASH_H
#define LITEPCIE_LIB_FLASH_H

#include <stdint.h>

#define FLASH_READ_ID_REG 0x9F

#define FLASH_READ    0x03
#define FLASH_WREN    0x06
#define FLASH_WRDI    0x04
#define FLASH_PP      0x02
#define FLASH_SE      0xD8
#define FLASH_BE      0xC7
#define FLASH_RDSR    0x05
#define FLASH_WRSR    0x01
/* status */
#define FLASH_WIP     0x01

#define FLASH_SECTOR_SIZE (1 << 16)

uint8_t litepcie_flash_read(int fd, uint32_t addr);
int litepcie_flash_get_erase_block_size(int fd);
int litepcie_flash_write(int fd,
                         uint8_t *buf, uint32_t base, uint32_t size,
                         void (*progress_cb)(void *opaque, const char *fmt, ...),
                         void *opaque);

#endif //LITEPCIE_LIB_FLASH_H

```

`litepcie/software/user/liblitepcie/litepcie_helpers.c`:

```c
/* SPDX-License-Identifier: BSD-2-Clause
 *
 * LitePCIe library
 *
 * This file is part of LitePCIe.
 *
 * Copyright (C) 2018-2023 / EnjoyDigital  / florent@enjoy-digital.fr
 *
 */

#include <time.h>
#include <sys/ioctl.h>
#include <stdio.h>
#include <errno.h>
#include <string.h>
#include <stdlib.h>
#include "litepcie_helpers.h"
#include "litepcie.h"

int64_t get_time_ms(void)
{
    struct timespec ts;
    clock_gettime(CLOCK_MONOTONIC, &ts);
    return (int64_t)ts.tv_sec * 1000 + (ts.tv_nsec / 1000000U);
}

uint32_t litepcie_readl(int fd, uint32_t addr) {
    struct litepcie_ioctl_reg m;
    m.is_write = 0;
    m.addr = addr;
    checked_ioctl(fd, LITEPCIE_IOCTL_REG, &m);
    return m.val;
}

void litepcie_writel(int fd, uint32_t addr, uint32_t val) {
    struct litepcie_ioctl_reg m;
    m.is_write = 1;
    m.addr = addr;
    m.val = val;
    checked_ioctl(fd, LITEPCIE_IOCTL_REG, &m);
}

void litepcie_reload(int fd) {
    struct litepcie_ioctl_icap m;
    m.addr = 0x4;
    m.data = 0xf;
    checked_ioctl(fd, LITEPCIE_IOCTL_ICAP, &m);
}

void _check_ioctl(int status, const char *file, int line) {
    if (status) {
        fprintf(stderr, "Failed ioctl at %s:%d: %s\n", file, line, strerror(errno));
        abort();
    }
}

```

`litepcie/software/user/liblitepcie/litepcie_helpers.h`:

```h
/* SPDX-License-Identifier: BSD-2-Clause
 *
 * LitePCIe library
 *
 * This file is part of LitePCIe.
 *
 * Copyright (C) 2018-2023 / EnjoyDigital  / florent@enjoy-digital.fr
 *
 */

#ifndef LITEPCIE_LIB_HELPERS_H
#define LITEPCIE_LIB_HELPERS_H

#include <stdint.h>
#include <sys/ioctl.h>

int64_t get_time_ms(void);

uint32_t litepcie_readl(int fd, uint32_t addr);
void litepcie_writel(int fd, uint32_t addr, uint32_t val);
void litepcie_reload(int fd);

#define checked_ioctl(...) _check_ioctl(ioctl(__VA_ARGS__), __FILE__, __LINE__)
void _check_ioctl(int status, const char *file, int line);

#endif /* LITEPCIE_LIB_HELPERS_H */

```

`litepcie/software/user/litepcie_test.c`:

```c
/* SPDX-License-Identifier: BSD-2-Clause
 *
 * LitePCIe test
 *
 * This file is part of LitePCIe.
 *
 * Copyright (C) 2018-2023 / EnjoyDigital  / florent@enjoy-digital.fr
 *
 */

#include <stdlib.h>
#include <stdio.h>
#include <string.h>
#include <inttypes.h>
#include <unistd.h>
#include <fcntl.h>
#include <math.h>
#include <signal.h>
#include "liblitepcie.h"

/* Variables */
/*-----------*/

sig_atomic_t keep_running = 1;

void intHandler(int dummy) {
    keep_running = 0;
}

/* Record (DMA RX) */
/*-----------------*/

static void litepcie_record(const char *device_name, const char *filename, uint32_t size, uint8_t zero_copy)
{
    static struct litepcie_dma_ctrl dma = {.use_writer = 1};

    FILE * fo = NULL;
    int i = 0;
    size_t len;
    size_t total_len = 0;
    int64_t last_time;
    int64_t writer_sw_count_last = 0;

    /* Open File to write to. */
    if (filename != NULL) {
        fo = fopen(filename, "wb");
        if (!fo) {
            perror(filename);
            exit(1);
        }
    }

    /* Initialize DMA. */
    if (litepcie_dma_init(&dma, device_name, zero_copy))
        exit(1);

    dma.writer_enable = 1;

    /* Test Loop. */
    last_time = get_time_ms();
    for (;;) {
        /* Exit loop on CTRL+C. */
        if (!keep_running)
            break;

        /* Update DMA status. */
        litepcie_dma_process(&dma);

        /* Read from DMA. */
        while (1) {
            /* Get Read buffer. */
            char *buf_rd = litepcie_dma_next_read_buffer(&dma);
            /* Break when no buffer available for Read. */
            if (!buf_rd)
                break;
            /* Copy Read data to File. */
            if (filename != NULL) {
                len = fwrite(buf_rd, 1, fmin(size - total_len, DMA_BUFFER_SIZE), fo);
                total_len += len;
            }
            /* Stop when specified size is reached */
            if (size > 0 && total_len >= size)
                keep_running = 0;
        }

        /* Statistics every 200ms. */
        int64_t duration = get_time_ms() - last_time;
        if (duration > 200) {
            /* Print banner every 10 lines. */
            if (i % 10 == 0)
                printf("\e[1mSPEED(Gbps)    BUFFERS SIZE(MB)\e[0m\n");
            i++;
            /* Print statistics. */
            printf("%10.2f %10" PRIu64 "  %8" PRIu64"\n",
                    (double)(dma.writer_sw_count - writer_sw_count_last) * DMA_BUFFER_SIZE * 8 / ((double)duration * 1e6),
                    dma.writer_sw_count,
                    (size > 0) ? ((dma.writer_sw_count) * DMA_BUFFER_SIZE) / 1024 / 1024 : 0);
            /* Update time/count. */
            last_time = get_time_ms();
            writer_sw_count_last = dma.writer_sw_count;
        }
    }

    /* Cleanup DMA. */
    litepcie_dma_cleanup(&dma);

    /* Close File. */
    if (filename != NULL)
        fclose(fo);
}

/* Play (DMA TX) */
/*---------------*/

static void litepcie_play(const char *device_name, const char *filename, uint32_t loops, uint8_t zero_copy)
{
    static struct litepcie_dma_ctrl dma = {.use_reader = 1};

    FILE * fo;
    int i = 0;
    size_t len;
    int64_t reader_sw_count_last = 0;
    int64_t last_time;
    uint32_t current_loop = 0;
    uint64_t sw_underflows = 0;

    /* Open File to read from. */
    fo = fopen(filename, "rb");
    if (!fo) {
        perror(filename);
        exit(1);
    }

    /* Initialize DMA. */
    if (litepcie_dma_init(&dma, device_name, zero_copy))
        exit(1);

    dma.reader_enable = 1;

    /* Test Loop. */
    last_time = get_time_ms();
    for (;;) {
        /* Exit loop on CTRL+C. */
        if (!(keep_running))
            break;

        /* Update DMA status. */
        litepcie_dma_process(&dma);

        /* Write to DMA. */
        while (1) {
            /* Get Write buffer. */
            char *buf_wr = litepcie_dma_next_write_buffer(&dma);
            /* Break when no buffer available for Write. */
            if (!buf_wr)
                break;
            /* Detect DMA underflows. */
            if (dma.reader_sw_count - dma.reader_hw_count < 0)
                sw_underflows += (dma.reader_hw_count - dma.reader_sw_count);
            /* Read data from File and fill Write buffer */
            len = fread(buf_wr, 1, DMA_BUFFER_SIZE, fo);
            if (feof(fo)) {
                /* Rewind on end of file. */
                current_loop += 1;
                if (current_loop >= loops)
                    keep_running = 0;
                rewind(fo);
                len += fread(buf_wr + len, 1, DMA_BUFFER_SIZE - len, fo);
            }
        }

        /* Statistics every 200ms. */
        int64_t duration = get_time_ms() - last_time;
        if (duration > 200) {
             /* Print banner every 10 lines. */
            if (i % 10 == 0)
                printf("\e[1mSPEED(Gbps)   BUFFERS   SIZE(MB)   LOOP UNDERFLOWS\e[0m\n");
            i++;
            /* Print statistics. */
            printf("%10.2f %10" PRIu64 " %10" PRIu64 " %6d %10ld\n",
                   (double)(dma.reader_sw_count - reader_sw_count_last) * DMA_BUFFER_SIZE * 8 / ((double)duration * 1e6),
                   dma.reader_sw_count,
                   (dma.reader_sw_count * DMA_BUFFER_SIZE) / 1024 / 1024,
                   current_loop,
                   sw_underflows);
           /* Update time/count/underflows. */
            last_time = get_time_ms();
            reader_sw_count_last = dma.reader_hw_count;
            sw_underflows = 0;
        }
    }

    /* Cleanup DMA. */
    litepcie_dma_cleanup(&dma);

    /* Close File. */
    fclose(fo);
}

/* Help */
/*------*/

static void help(void)
{
    printf("LitePCIe testing utilities\n"
           "usage: litepcie_test [options] cmd [args...]\n"
           "\n"
           "options:\n"
           "-h                               Help.\n"
           "-c device_num                    Select the device (default = 0).\n"
           "-z                               Enable zero-copy DMA mode.\n"
           "\n"
           "record [filename] [size]         Record DMA stream to file.\n"
           "play filename [loops]            Play DMA stream from file.\n"
           );
    exit(1);
}

/* Main */
/*------*/

int main(int argc, char **argv)
{
    const char *cmd;
    int c;
    static char litepcie_device[1024];
    static int litepcie_device_num;
    static uint8_t litepcie_device_zero_copy;

    litepcie_device_num = 0;
    litepcie_device_zero_copy = 0;

    signal(SIGINT, intHandler);

    /* Parameters. */
    for (;;) {
        c = getopt(argc, argv, "hc:z");
        if (c == -1)
            break;
        switch(c) {
        case 'h':
            help();
            break;
        case 'c':
            litepcie_device_num = atoi(optarg);
            break;
        case 'z':
            litepcie_device_zero_copy = 1;
            break;
        default:
            exit(1);
        }
    }

    /* Show help when too much args. */
    if (optind >= argc)
        help();

    /* Select device. */
    snprintf(litepcie_device, sizeof(litepcie_device), "/dev/litepcie%d", litepcie_device_num);

    cmd = argv[optind++];

    /* Record cmd. */
    if (!strcmp(cmd, "record")) {
        const char *filename = NULL;
        uint32_t size = 0;
        if (optind != argc) {
            if (optind + 2 > argc)
                goto show_help;
            filename = argv[optind++];
            size = strtoul(argv[optind++], NULL, 0);
        }
        litepcie_record(litepcie_device, filename, size, litepcie_device_zero_copy);
    /* Play cmd. */
    } else if (!strcmp(cmd, "play")) {
        const char *filename;
        uint32_t loops = 1;
        if (optind + 1 > argc)
            goto show_help;
        filename = argv[optind++];
        if (optind < argc)
            loops = strtoul(argv[optind++], NULL, 0);
        litepcie_play(litepcie_device, filename, loops, litepcie_device_zero_copy);
    /* Show help otherwise. */
    } else
show_help:
        help();

    return 0;
}

```

`litepcie/software/user/litepcie_util.c`:

```c
/* SPDX-License-Identifier: BSD-2-Clause
 *
 * LitePCIe util
 *
 * This file is part of LitePCIe.
 *
 * Copyright (C) 2018-2023 / EnjoyDigital  / florent@enjoy-digital.fr
 *
 */

#include <stdlib.h>
#include <stdio.h>
#include <string.h>
#include <stdarg.h>
#include <inttypes.h>
#include <unistd.h>
#include <fcntl.h>
#include <signal.h>
#include "liblitepcie.h"

/* Parameters */
/*------------*/

#define DMA_CHECK_DATA   /* Un-comment to disable data check */
#define DMA_RANDOM_DATA  /* Un-comment to disable data random */

/* Variables */
/*-----------*/

static char litepcie_device[1024];
static int litepcie_device_num;

sig_atomic_t keep_running = 1;

void intHandler(int dummy) {
    keep_running = 0;
}

/* Info */
/*------*/

static void info(void)
{
    int fd;
    int i;
    unsigned char fpga_identifier[256];

    fd = open(litepcie_device, O_RDWR);
    if (fd < 0) {
        fprintf(stderr, "Could not init driver\n");
        exit(1);
    }


    printf("\e[1m[> FPGA/SoC Info:\e[0m\n");
    printf("-----------------\n");

    for (i = 0; i < 256; i ++)
        fpga_identifier[i] = litepcie_readl(fd, CSR_IDENTIFIER_MEM_BASE + 4 * i);
    printf("SoC Identifier   : %s.\n", fpga_identifier);
#ifdef CSR_DNA_BASE
    printf("FPGA DNA         : 0x%08x%08x\n",
        litepcie_readl(fd, CSR_DNA_ID_ADDR + 4 * 0),
        litepcie_readl(fd, CSR_DNA_ID_ADDR + 4 * 1)
    );
#endif
#ifdef CSR_XADC_BASE
    printf("FPGA Temperature : %0.1f °C\n",
           (double)litepcie_readl(fd, CSR_XADC_TEMPERATURE_ADDR) * 503.975/4096 - 273.15);
    printf("FPGA VCC-INT     : %0.2f V\n",
           (double)litepcie_readl(fd, CSR_XADC_VCCINT_ADDR) / 4096 * 3);
    printf("FPGA VCC-AUX     : %0.2f V\n",
           (double)litepcie_readl(fd, CSR_XADC_VCCAUX_ADDR) / 4096 * 3);
    printf("FPGA VCC-BRAM    : %0.2f V\n",
           (double)litepcie_readl(fd, CSR_XADC_VCCBRAM_ADDR) / 4096 * 3);
#endif
    close(fd);
}

/* Scratch */
/*---------*/

void scratch_test(void)
{
    int fd;

    printf("\e[1m[> Scratch register test:\e[0m\n");
    printf("-------------------------\n");

    /* Open LitePCIe device. */
    fd = open(litepcie_device, O_RDWR);
    if (fd < 0) {
        fprintf(stderr, "Could not init driver\n");
        exit(1);
    }

    /* Write to scratch register. */
    printf("Write 0x12345678 to Scratch register:\n");
    litepcie_writel(fd, CSR_CTRL_SCRATCH_ADDR, 0x12345678);
    printf("Read: 0x%08x\n", litepcie_readl(fd, CSR_CTRL_SCRATCH_ADDR));

    /* Read from scratch register. */
    printf("Write 0xdeadbeef to Scratch register:\n");
    litepcie_writel(fd, CSR_CTRL_SCRATCH_ADDR, 0xdeadbeef);
    printf("Read: 0x%08x\n", litepcie_readl(fd, CSR_CTRL_SCRATCH_ADDR));

    /* Close LitePCIe device. */
    close(fd);
}

/* SPI Flash */
/*-----------*/

#ifdef CSR_FLASH_BASE

static void flash_progress(void *opaque, const char *fmt, ...)
{
    va_list ap;
    va_start(ap, fmt);
    vprintf(fmt, ap);
    fflush(stdout);
    va_end(ap);
}

static void flash_program(uint32_t base, const uint8_t *buf1, int size1)
{
    int fd;

    uint32_t size;
    uint8_t *buf;
    int sector_size;
    int errors;

    /* Open LitePCIe device. */
    fd = open(litepcie_device, O_RDWR);
    if (fd < 0) {
        fprintf(stderr, "Could not init driver\n");
        exit(1);
    }

    /* Get flash sector size and pad size to it. */
    sector_size = litepcie_flash_get_erase_block_size(fd);
    size = ((size1 + sector_size - 1) / sector_size) * sector_size;

    /* Alloc buffer and copy data to it. */
    buf = calloc(1, size);
    if (!buf) {
        fprintf(stderr, "%d: alloc failed\n", __LINE__);
        exit(1);
    }
    memcpy(buf, buf1, size1);

    /* Program flash. */
    printf("Programming (%d bytes at 0x%08x)...\n", size, base);
    errors = litepcie_flash_write(fd, buf, base, size, flash_progress, NULL);
    if (errors) {
        printf("Failed %d errors.\n", errors);
        exit(1);
    } else {
        printf("Success.\n");
    }

    /* Free buffer and close LitePCIe device. */
    free(buf);
    close(fd);
}

static void flash_write(const char *filename, uint32_t offset)
{
    uint8_t *data;
    int size;
    FILE * f;

    /* Open data source file. */
    f = fopen(filename, "rb");
    if (!f) {
        perror(filename);
        exit(1);
    }

    /* Get size, alloc buffer and copy data to it. */
    fseek(f, 0L, SEEK_END);
    size = ftell(f);
    fseek(f, 0L, SEEK_SET);
    data = malloc(size);
    if (!data) {
        fprintf(stderr, "%d: malloc failed\n", __LINE__);
        exit(1);
    }
    ssize_t ret = fread(data, size, 1, f);
    fclose(f);

    /* Program file to flash */
    if (ret != 1)
        perror(filename);
    else
        flash_program(offset, data, size);

    /* Free buffer */
    free(data);
}

static void flash_read(const char *filename, uint32_t size, uint32_t offset)
{
    int fd;
    FILE * f;
    uint32_t base;
    uint32_t sector_size;
    uint8_t byte;
    int i;

    /* Open data destination file. */
    f = fopen(filename, "wb");
    if (!f) {
        perror(filename);
        exit(1);
    }

    /* Open LitePCIe device. */
    fd = open(litepcie_device, O_RDWR);
    if (fd < 0) {
        fprintf(stderr, "Could not init driver\n");
        exit(1);
    }

    /* Get flash sector size. */
    sector_size = litepcie_flash_get_erase_block_size(fd);

    /* Read flash and write to destination file. */
    base = offset;
    for (i = 0; i < size; i++) {
        if ((i % sector_size) == 0) {
            printf("Reading 0x%08x\r", base + i);
            fflush(stdout);
        }
        byte = litepcie_flash_read(fd, base + i);
        fwrite(&byte, 1, 1, f);
    }

    /* Close destination file and LitePCIe device. */
    fclose(f);
    close(fd);
}

static void flash_reload(void)
{
    int fd;

    /* Open LitePCIe device. */
    fd = open(litepcie_device, O_RDWR);
    if (fd < 0) {
        fprintf(stderr, "Could not init driver\n");
        exit(1);
    }

    /* Reload FPGA through ICAP.*/
    litepcie_reload(fd);

    /* Notice user to reboot/rescan the hardware.*/
    printf("===========================================================================\n");
    printf("= PLEASE REBOOT YOUR HARDWARE OR RESCAN PCIe BUS TO USE NEW FPGA GATEWARE =\n");
    printf("===========================================================================\n");

    /* Close LitePCIe device. */
    close(fd);
}
#endif

/* DMA */
/*-----*/

static inline int64_t add_mod_int(int64_t a, int64_t b, int64_t m)
{
    a += b;
    if (a >= m)
        a -= m;
    return a;
}

static int get_next_pow2(int data_width)
{
    int x = 1;
    while (x < data_width)
        x <<= 1;
    return x;
}

#ifdef DMA_CHECK_DATA

static inline uint32_t seed_to_data(uint32_t seed)
{
#ifdef DMA_RANDOM_DATA
    /* Return pseudo random data from seed. */
    return seed * 69069 + 1;
#else
    /* Return seed. */
    return seed;
#endif
}

static uint32_t get_data_mask(int data_width)
{
    int i;
    uint32_t mask;
    mask = 0;
    for (i = 0; i < 32/get_next_pow2(data_width); i++) {
        mask <<= get_next_pow2(data_width);
        mask |= ((uint64_t) 1 << data_width) - 1;
    }
    return mask;
}

static void write_pn_data(uint32_t *buf, int count, uint32_t *pseed, int data_width)
{
    int i;
    uint32_t seed;
    uint32_t mask = get_data_mask(data_width);

    seed = *pseed;
    for(i = 0; i < count; i++) {
        buf[i] = (seed_to_data(seed) & mask);
        seed = add_mod_int(seed, 1, DMA_BUFFER_SIZE / sizeof(uint32_t));
    }
    *pseed = seed;
}

static int check_pn_data(const uint32_t *buf, int count, uint32_t *pseed, int data_width)
{
    int i, errors;
    uint32_t seed;
    uint32_t mask = get_data_mask(data_width);

    errors = 0;
    seed = *pseed;
    for (i = 0; i < count; i++) {
        if ((buf[i] & mask) != (seed_to_data(seed) & mask)) {
            errors ++;
        }
        seed = add_mod_int(seed, 1, DMA_BUFFER_SIZE / sizeof(uint32_t));
    }
    *pseed = seed;
    return errors;
}
#endif

static void dma_test(uint8_t zero_copy, uint8_t external_loopback, int data_width, int auto_rx_delay, int duration)
{
    static struct litepcie_dma_ctrl dma = {.use_reader = 1, .use_writer = 1};
    dma.loopback = external_loopback ? 0 : 1;

    if (data_width > 32 || data_width < 1) {
        fprintf(stderr, "Invalid data width %d\n", data_width);
        exit(1);
    }

    /* Statistics */
    int i = 0;
    int64_t reader_sw_count_last = 0;
    int64_t last_time;
    uint32_t errors = 0;
    int64_t end_time = (duration > 0) ? get_time_ms() + duration * 1000 : 0;

#ifdef DMA_CHECK_DATA
    uint32_t seed_wr = 0;
    uint32_t seed_rd = 0;
    uint8_t  run = (auto_rx_delay == 0);
#else
    uint8_t run = 1;
#endif

    signal(SIGINT, intHandler);

    printf("\e[1m[> DMA loopback test:\e[0m\n");
    printf("---------------------\n");

    if (litepcie_dma_init(&dma, litepcie_device, zero_copy))
        exit(1);

    dma.reader_enable = 1;
    dma.writer_enable = 1;

    /* Test loop. */
    last_time = get_time_ms();
    for (;;) {
        /* Exit loop on CTRL+C or when the duration is over. */
        if (!keep_running || (duration > 0 && get_time_ms() >= end_time))
            break;

        /* Update DMA status. */
        litepcie_dma_process(&dma);

#ifdef DMA_CHECK_DATA
        char *buf_wr;
        char *buf_rd;

        /* DMA-TX Write. */
        while (1) {
            /* Get Write buffer. */
            buf_wr = litepcie_dma_next_write_buffer(&dma);
            /* Break when no buffer available for Write. */
            if (!buf_wr)
                break;
            /* Write data to buffer. */
            write_pn_data((uint32_t *) buf_wr, DMA_BUFFER_SIZE / sizeof(uint32_t), &seed_wr, data_width);
        }

        /* DMA-RX Read/Check */
        while (1) {
            /* Get Read buffer. */
            buf_rd = litepcie_dma_next_read_buffer(&dma);
            /* Break when no buffer available for Read. */
            if (!buf_rd)
                break;
            /* Skip the first 128 DMA loops. */
            if (dma.writer_hw_count < 128*DMA_BUFFER_COUNT)
                break;
            /* When running... */
            if (run) {
                /* Check data in Read buffer. */
                errors += check_pn_data((uint32_t *) buf_rd, DMA_BUFFER_SIZE / sizeof(uint32_t), &seed_rd, data_width);
                /* Clear Read buffer */
                memset(buf_rd, 0, DMA_BUFFER_SIZE);
            } else {
                /* Find initial Delay/Seed (Useful when loopback is introducing delay). */
                uint32_t errors_min = 0xffffffff;
                for (int delay = 0; delay < DMA_BUFFER_SIZE / sizeof(uint32_t); delay++) {
                    seed_rd = delay;
                    errors = check_pn_data((uint32_t *) buf_rd, DMA_BUFFER_SIZE / sizeof(uint32_t), &seed_rd, data_width);
                    //printf("delay: %d / errors: %d\n", delay, errors);
                    if (errors < errors_min)
                        errors_min = errors;
                    if (errors < (DMA_BUFFER_SIZE / sizeof(uint32_t)) / 2) {
                        printf("RX_DELAY: %d (errors: %d)\n", delay, errors);
                        run = 1;
                        break;
                    }
                }
                if (!run) {
                    printf("Unable to find DMA RX_DELAY (min errors: %d/%ld), exiting.\n",
                        errors_min,
                        DMA_BUFFER_SIZE / sizeof(uint32_t));
                    goto end;
                }
            }

        }
#endif

        /* Statistics every 200ms. */
        int64_t duration_ms = get_time_ms() - last_time;
        if (run & (duration_ms > 200)) {
            /* Print banner every 10 lines. */
            if (i % 10 == 0)
                printf("\e[1mDMA_SPEED(Gbps)\tTX_BUFFERS\tRX_BUFFERS\tDIFF\tERRORS\e[0m\n");
            i++;
            /* Print statistics. */
            printf("%14.2f\t%10" PRIu64 "\t%10" PRIu64 "\t%4" PRIu64 "\t%6u\n",
                   (double)(dma.reader_sw_count - reader_sw_count_last) * DMA_BUFFER_SIZE * 8 * data_width / (get_next_pow2(data_width) * (double)duration_ms * 1e6),
                   dma.reader_sw_count,
                   dma.writer_sw_count,
                   (uint64_t) abs(dma.reader_sw_count - dma.writer_sw_count),
                   errors);
            /* Update errors/time/count. */
            errors = 0;
            last_time = get_time_ms();
            reader_sw_count_last = dma.reader_sw_count;
        }
    }

    /* Cleanup DMA. */
#ifdef DMA_CHECK_DATA
end:
#endif
    litepcie_dma_cleanup(&dma);
}

/* Help */
/*------*/

static void help(void)
{
    printf("LitePCIe utilities\n"
           "usage: litepcie_util [options] cmd [args...]\n"
           "\n"
           "options:\n"
           "-h                                Help.\n"
           "-c device_num                     Select the device (default = 0).\n"
           "-z                                Enable zero-copy DMA mode.\n"
           "-e                                Use external loopback (default = internal).\n"
           "-w data_width                     Width of data bus (default = 16).\n"
           "-a                                Automatic DMA RX-Delay calibration.\n"
           "-t duration                       Duration of the test in seconds (default = 0, infinite).\n"
           "\n"
           "available commands:\n"
           "info                              Get Board information.\n"
           "\n"
           "dma_test                          Test DMA.\n"
           "scratch_test                      Test Scratch register.\n"
           "\n"
#ifdef CSR_FLASH_BASE
           "flash_write filename [offset]     Write file contents to SPI Flash.\n"
           "flash_read filename size [offset] Read from SPI Flash and write contents to file.\n"
           "flash_reload                      Reload FPGA Image.\n"
#endif
           );
    exit(1);
}

/* Main */
/*------*/

int main(int argc, char **argv)
{
    const char *cmd;
    int c;
    static uint8_t litepcie_device_zero_copy;
    static uint8_t litepcie_device_external_loopback;
    static int litepcie_data_width;
    static int litepcie_auto_rx_delay;
    static int test_duration = 0; /* Default to 0 for infinite duration.*/

    litepcie_device_num = 0;
    litepcie_data_width = 16;
    litepcie_auto_rx_delay = 0;
    litepcie_device_zero_copy = 0;
    litepcie_device_external_loopback = 0;

    /* Parameters. */
    for (;;) {
        c = getopt(argc, argv, "hc:w:zeat:");
        if (c == -1)
            break;
        switch(c) {
        case 'h':
            help();
            break;
        case 'c':
            litepcie_device_num = atoi(optarg);
            break;
        case 'w':
            litepcie_data_width = atoi(optarg);
            break;
        case 'z':
            litepcie_device_zero_copy = 1;
            break;
        case 'e':
            litepcie_device_external_loopback = 1;
            break;
        case 'a':
            litepcie_auto_rx_delay = 1;
            break;
        case 't':
            test_duration = atoi(optarg);
            break;
        default:
            exit(1);
        }
    }

    /* Show help when too much args. */
    if (optind >= argc)
        help();

    /* Select device. */
    snprintf(litepcie_device, sizeof(litepcie_device), "/dev/litepcie%d", litepcie_device_num);

    cmd = argv[optind++];

    /* Info cmds. */
    if (!strcmp(cmd, "info"))
        info();
    /* Scratch cmds. */
    else if (!strcmp(cmd, "scratch_test"))
        scratch_test();
    /* SPI Flash cmds. */
#if CSR_FLASH_BASE
    else if (!strcmp(cmd, "flash_write")) {
        const char *filename;
        uint32_t offset = 0;
        if (optind + 1 > argc)
            goto show_help;
        filename = argv[optind++];
        if (optind < argc)
            offset = strtoul(argv[optind++], NULL, 0);
        flash_write(filename, offset);
    }
    else if (!strcmp(cmd, "flash_read")) {
        const char *filename;
        uint32_t size = 0;
        uint32_t offset = 0;
        if (optind + 2 > argc)
            goto show_help;
        filename = argv[optind++];
        size = strtoul(argv[optind++], NULL, 0);
        if (optind < argc)
            offset = strtoul(argv[optind++], NULL, 0);
        flash_read(filename, size, offset);
    }
    else if (!strcmp(cmd, "flash_reload"))
        flash_reload();
#endif

    /* DMA cmds. */
    else if (!strcmp(cmd, "dma_test"))
        dma_test(
            litepcie_device_zero_copy,
            litepcie_device_external_loopback,
            litepcie_data_width,
            litepcie_auto_rx_delay,
            test_duration);

    /* Show help otherwise. */
    else
        goto show_help;

    return 0;

show_help:
        help();

    return 0;
}

```

`litepcie/tlp/common.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2015-2023 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

from migen import *

from litepcie.common import *

# Constants ----------------------------------------------------------------------------------------

# Maximum payload size and request size (in bytes).
max_payload_size = 512
max_request_size = 512

# Format (fmt) field of different types of TLPs.
fmt_dict = {
    "mem_rd32" : 0b00, # Memory Read Request  (32-bit).
    "mem_rd64" : 0b01, # Memory Read Request  (64-bit).
    "mem_wr32" : 0b10, # Memory Write Request (32-bit).
    "mem_wr64" : 0b11, # Memory Write Request (64-bit).
    "cpld"     : 0b10, # Completion with Data.
    "cpl"      : 0b00, # Completion without Data.
    "cfg_rd0"  : 0b00, # Configuration Read Request (Type 0).
    "cfg_wr0"  : 0b10, # Configuration Write Request (Type 0).
    "ptm_req"  : 0b01, # PTM Request.
    "ptm_res"  : 0b11, # PTM Response.
}

# Type (type) field of different types of TLPs.
type_dict = {
    "mem_rd32" : 0b00000, # Memory Read Request  (32-bit).
    "mem_rd64" : 0b00000, # Memory Read Request  (64-bit).
    "mem_wr32" : 0b00000, # Memory Write Request (32-bit).
    "mem_wr64" : 0b00000, # Memory Write Request (64-bit).
    "cpld"     : 0b01010, # Completion with Data.
    "cpl"      : 0b01010, # Completion without Data.
    "cfg_rd0"  : 0b00100, # Configuration Read Request (Type 0).
    "cfg_wr0"  : 0b00100, # Configuration Write Request (Type 0).
    "ptm_req"  : 0b10100, # PTM Request.
    "ptm_res"  : 0b10100, # PTM Response.
}

# Format and Type fields for different types of TLPs.
fmt_type_dict = {
    "mem_rd32" : 0b00_00000, # Memory Read Request  (32-bit).
    "mem_rd64" : 0b01_00000, # Memory Read Request  (64-bit).
    "mem_wr32" : 0b10_00000, # Memory Write Request (32-bit).
    "mem_wr64" : 0b11_00000, # Memory Write Request (64-bit).
    "cpld"     : 0b10_01010, # Completion with Data.
    "cpl"      : 0b00_01010, # Completion without Data.
    "cfg_rd0"  : 0b00_00100, # Configuration Read Request (Type 0).
    "cfg_wr0"  : 0b10_00100, # Configuration Write Request (Type 0).
    "ptm_req"  : 0b01_10100, # PTM Request.
    "ptm_res"  : 0b11_10100, # PTM Response.
}

# Completion Status (cpl) field of Completion TLPs.
cpl_dict = {
    "sc"  : 0b000, # Successful Completion.
    "ur"  : 0b001, # Unsupported Request.
    "crs" : 0b010, # Configuration Request Retry Status.
    "ca"  : 0b011, # Completer Abort.
}

# Headers ------------------------------------------------------------------------------------------

# Length of the TLP common header (in bytes).
tlp_common_header_length = 16
# Define TLP common header fields.
tlp_common_header_fields = {
    "fmt"  : HeaderField(byte=0*4, offset=29, width=2), # Format.
    "type" : HeaderField(byte=0*4, offset=24, width=5), # Type.
}
# Define TLP common header
tlp_common_header = Header(
    fields           = tlp_common_header_fields,
    length           = tlp_common_header_length,
    swap_field_bytes = False # No byte swapping required.
)

# Length of the TLP configuration header (in bytes).
tlp_configuration_header_length = 16
# Define TLP configuration header fields.
tlp_configuration_header_fields = {
    "fmt"          : HeaderField(byte=0*4, offset=29, width= 2), # Format.
    "type"         : HeaderField(byte=0*4, offset=24, width= 5), # Type.
    "tc"           : HeaderField(byte=0*4, offset=20, width= 3), # Traffic Class.
    "td"           : HeaderField(byte=0*4, offset=15, width= 1), # TLP Digest.
    "ep"           : HeaderField(byte=0*4, offset=14, width= 1), # Poisoned TLP.
    "attr"         : HeaderField(byte=0*4, offset=12, width= 2), # Attributes.
    "length"       : HeaderField(byte=0*4, offset= 0, width=10), # Length.

    "requester_id" : HeaderField(byte=1*4, offset=16, width=16), # Requester ID.
    "tag"          : HeaderField(byte=1*4, offset= 8, width= 8), # Tag.
    "last_be"      : HeaderField(byte=1*4, offset= 4, width= 4), # Last Byte Enable.
    "first_be"     : HeaderField(byte=1*4, offset= 0, width= 4), # First Byte Enable.

    "bus_number"   : HeaderField(byte=2*4, offset=24, width= 8), # Bus number.
    "device_no"    : HeaderField(byte=2*4, offset=19, width= 5), # Device number.
    "func"         : HeaderField(byte=2*4, offset=16, width= 3), # Function number.
    "ext_reg"      : HeaderField(byte=2*4, offset= 8, width= 3), # Extended Register.
    "register_no"  : HeaderField(byte=2*4, offset= 2, width= 6), # Register number.
}
# Define TLP configuration header.
tlp_configuration_header = Header(
    fields           = tlp_configuration_header_fields,
    length           = tlp_configuration_header_length,
    swap_field_bytes = False # No byte swapping required.
)

# Length of the TLP request header (in bytes).
tlp_request_header_length = 16
# Define TLP request header fields.
tlp_request_header_fields = {
    "fmt"          : HeaderField(byte=0*4, offset=29, width= 2), # Format.
    "type"         : HeaderField(byte=0*4, offset=24, width= 5), # Type.
    "tc"           : HeaderField(byte=0*4, offset=20, width= 3), # Traffic Class.
    "td"           : HeaderField(byte=0*4, offset=15, width= 1), # TLP Digest.
    "ep"           : HeaderField(byte=0*4, offset=14, width= 1), # Poisoned TLP.
    "attr"         : HeaderField(byte=0*4, offset=12, width= 2), # Attributes.
    "length"       : HeaderField(byte=0*4, offset= 0, width=10), # Length.

    "requester_id" : HeaderField(byte=1*4, offset=16, width=16), # Requester ID.
    "tag"          : HeaderField(byte=1*4, offset= 8, width= 8), # Tag.
    "last_be"      : HeaderField(byte=1*4, offset= 4, width= 4), # Last Byte Enable.
    "first_be"     : HeaderField(byte=1*4, offset= 0, width= 4), # First Byte Enable.

    "address"      : HeaderField(byte=2*4, offset= 0, width=64), # Address.
}
# Define TLP request header.
tlp_request_header = Header(
    fields           = tlp_request_header_fields,
    length           = tlp_request_header_length,
    swap_field_bytes = False # No byte swapping required.
)

# Length of the TLP completion header (in bytes).
tlp_completion_header_length = 16
# Define TLP completion header fields.
tlp_completion_header_fields = {
    "fmt"           : HeaderField(byte=0*4, offset=29, width= 2), # Format.
    "type"          : HeaderField(byte=0*4, offset=24, width= 5), # Type.
    "tc"            : HeaderField(byte=0*4, offset=20, width= 3), # Traffic Class.
    "td"            : HeaderField(byte=0*4, offset=15, width= 1), # TLP Digest.
    "ep"            : HeaderField(byte=0*4, offset=14, width= 1), # Poisoned TLP.
    "attr"          : HeaderField(byte=0*4, offset=12, width= 2), # Attributes.
    "length"        : HeaderField(byte=0*4, offset= 0, width=10), # Length.

    "completer_id"  : HeaderField(byte=1*4, offset=16, width=16), # Completer ID.
    "status"        : HeaderField(byte=1*4, offset=13, width= 3), # Completion Status.
    "bcm"           : HeaderField(byte=1*4, offset=12, width= 1), # Byte Count Mismatch.
    "byte_count"    : HeaderField(byte=1*4, offset= 0, width=12), # Byte Count.

    "requester_id"  : HeaderField(byte=2*4, offset=16, width=16), # Requester ID.
    "tag"           : HeaderField(byte=2*4, offset= 8, width= 8), # Tag.
    "lower_address" : HeaderField(byte=2*4, offset= 0, width= 7), # Lower Address.
}
# Define TLP completion header.
tlp_completion_header = Header(
    fields           = tlp_completion_header_fields,
    length           = tlp_completion_header_length,
    swap_field_bytes = False # No byte swapping required.
)

# Length of the TLP PTM header (in bytes).
tlp_ptm_header_length = 16
# Define TLP request header fields.
tlp_ptm_header_fields = {
    "fmt"          : HeaderField(byte=0*4, offset=29, width= 2), # Format.
    "type"         : HeaderField(byte=0*4, offset=24, width= 5), # Type.
    "tc"           : HeaderField(byte=0*4, offset=20, width= 3), # Traffic Class.
    "ln"           : HeaderField(byte=0*4, offset=17, width= 1), # ?.
    "th"           : HeaderField(byte=0*4, offset=16, width= 1), # ?.
    "td"           : HeaderField(byte=0*4, offset=15, width= 1), # TLP Digest.
    "ep"           : HeaderField(byte=0*4, offset=14, width= 1), # Poisoned TLP.
    "attr"         : HeaderField(byte=0*4, offset=12, width= 2), # Attributes.
    "length"       : HeaderField(byte=0*4, offset= 0, width=10), # Length.

    "requester_id" : HeaderField(byte=1*4, offset=16, width=16), # Requester ID.
    "message_code" : HeaderField(byte=1*4, offset=0,  width= 8), # Message Code.
    "master_time"  : HeaderField(byte=2*4, offset=0,  width=64), # Master Time.
}
# Define TLP PTM header.
tlp_ptm_header = Header(
    fields           = tlp_ptm_header_fields,
    length           = tlp_ptm_header_length,
    swap_field_bytes = False # No byte swapping required.
)

# Helpers ------------------------------------------------------------------------------------------

def dword_endianness_swap(src, dst, data_width, endianness, mode="dat", ndwords=None):
    """
    Perform an endianness swap on Migen signals.

    Parameters:
        src (Signal)           : Source signal.
        dst (Signal)           : Destination signal.
        data_width (int)       : Width of the data (in bits).
        endianness (str)       : Endianness ("little" or "big").
        mode (str, optional)   : Mode of operation ("dat" for data or "be" for Byte Enable). Defaults to "dat".
        ndwords (int, optional): Number of DWORDs. Defaults to data_width//32.

    Returns:
        list: List of assignments after endianness swap.
    """
    # Validate inputs
    assert len(src) == len(dst)
    assert data_width%32 == 0
    assert mode in ["dat", "be"]
    r = []
    # Select number of bits to swap based on the mode.
    nbits       = {"dat":            32, "be":            4}[mode]
    # Default number of dwords to data_width//32 if not provided.
    ndwords     = data_width//32 if ndwords is None else ndwords
    # Select reversing function based on the mode.
    reverse_cls = {"dat": reverse_bytes, "be": reverse_bits}[mode]

    # Iterate through each dword.
    for n in range(ndwords):
        low  = (n + 0)*nbits
        high = (n + 1)*nbits
         # Add swapped dword to result list.
        r += {
            "little" : [dst[low:high].eq(            src[low:high])],  # If little-endian, no need for reversal.
            "big"    : [dst[low:high].eq(reverse_cls(src[low:high]))], # If big-endian, reverse the bytes/bits.
        }[endianness]
    return r

# Layouts ------------------------------------------------------------------------------------------

def tlp_raw_layout(data_width):
    """
    Generate a raw TLP endpoint description.
    """
    layout = [
        ("fmt",    2),            # Format field.
        ("header", 4*32),         # Header field.
        ("dat",    data_width),   # Data field.
        ("be",     data_width//8) # Byte Enable field.
    ]
    return EndpointDescription(layout)


def tlp_common_layout(data_width):
    """
    Generate a common TLP endpoint description.
    """
    layout = tlp_common_header.get_layout() + [
        ("dat", data_width),   # Data field.
        ("be",  data_width//8) # Byte Enable field.
    ]
    return EndpointDescription(layout)


def tlp_configuration_layout(data_width):
    """
    Generate a configuration TLP endpoint description.
    """
    layout = tlp_configuration_header.get_layout() + [
        ("dat", data_width),   # Data field.
        ("be",  data_width//8) # Byte Enable field.
    ]
    return EndpointDescription(layout)


def tlp_request_layout(data_width):
    """
    Generate a request TLP endpoint description.
    """
    layout = tlp_request_header.get_layout() + [
        ("dat", data_width),   # Data field.
        ("be",  data_width//8) # Byte Enable field.
    ]
    return EndpointDescription(layout)


def tlp_completion_layout(data_width):
    """
    Generate a completion TLP endpoint description.
    """
    layout = tlp_completion_header.get_layout() + [
        ("dat", data_width),   # Data field.
        ("be",  data_width//8) # Byte Enable field.
    ]
    return EndpointDescription(layout)

def tlp_ptm_layout(data_width):
    """
    Generate a PTM TLP endpoint description.

    Parameters:
        data_width (int): Width of the data (in bits).

    Returns:
        EndpointDescription: PTM TLP endpoint description.
    """
    layout = tlp_ptm_header.get_layout() + [
        ("dat", data_width),   # Data field.
        ("be",  data_width//8) # Byte Enable field.
    ]
    return EndpointDescription(layout)

```

`litepcie/tlp/controller.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2015-2023 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

from migen import *

from litex.gen import *

from litepcie.common      import *
from litepcie.core.common import *
from litepcie.tlp.common  import *

# LitePCIe TLP Controller --------------------------------------------------------------------------

class LitePCIeTLPController(LiteXModule):
    """LitePCIe TLP requests/completions controller.

    Arbitrate/throttle TLP requests and reorder/assemble/redirect completions.
    """
    def __init__(self, data_width, address_width, max_pending_requests, cmp_bufs_buffered=True, with_configuration=False):
        self.ctrl_rst  = Signal()
        self.master_in  = LitePCIeMasterInternalPort(data_width, address_width, with_configuration=with_configuration)
        self.master_out = LitePCIeMasterInternalPort(data_width, address_width, with_configuration=with_configuration)

        # # #

        req_sink, req_source = self.master_in.sink,    self.master_out.sink
        cmp_sink, cmp_source = self.master_out.source, self.master_in.source

        # Parameters.
        tag_bits = log2_int(max_pending_requests)

        # Tag queue --------------------------------------------------------------------------------
        # The tag queue is filled initially with the tags that will be used to issue read requests
        # to the host. A tag is dequeued when a read requests is issued to the host and queued when
        # a readcomplementation is received from the host.
        self.tag_queue = tag_queue = ResetInserter()(SyncFIFO(
            layout   = [("tag", tag_bits)],
            depth    = max_pending_requests,
            buffered = True,
        ))

        # Requests queue ---------------------------------------------------------------------------
        # Store the read requests tags as emitted to the host, datas will be dequeued in this order
        self.req_queue = req_queue = ResetInserter()(SyncFIFO(
            layout   =  [("tag", tag_bits), ("channel", 8), ("user_id", 8)],
            depth    = max_pending_requests,
            buffered = True,
        ))

        # Requests Management ----------------------------------------------------------------------

        # Connect Data-Path.
        self.comb += req_sink.connect(req_source, omit={"valid", "ready", "tag"})

        # FSM.
        self.req_fsm = req_fsm = ResetInserter()(FSM(reset_state="WAIT-REQ"))
        self.comb += [
            tag_queue.reset.eq(self.ctrl_rst),
            req_queue.reset.eq(self.ctrl_rst),
            req_fsm.reset.eq(self.ctrl_rst),
        ]
        req_fsm.act("WAIT-REQ",
            # Wait for a TLP Request...
            If(req_sink.valid & req_sink.first,
                # TLP Write: We can send the request directly.
                If(req_sink.we,
                   NextState("SEND-WRITE-REQ")
                # TLP Read:  We can send the request when one tag available and space in req_queue.
                ).Elif(tag_queue.source.valid & req_queue.sink.ready,
                   NextState("SEND-READ-REQ")
                )
            )
        )
        req_fsm.act("SEND-WRITE-REQ",
            # Connect Control-Path.
            req_sink.connect(req_source, keep={"valid", "ready"}),
            req_source.tag.eq(32),
            # End Request and return to Wait on last valid cycle.
            If(req_source.valid & req_source.ready & req_source.last,
                NextState("WAIT-REQ")
            )
        )
        self.comb += [
            req_queue.sink.tag.eq(tag_queue.source.tag),
            req_sink.connect(req_queue.sink, keep={"channel", "user_id"}),
        ]
        req_fsm.act("SEND-READ-REQ",
            # Connect Control-Path.
            req_sink.connect(req_source, keep={"valid", "ready"}),
            req_source.tag.eq(tag_queue.source.tag),
            # End Request and return to Wait on last valid cycle.
            If(req_source.valid & req_source.ready & req_source.last,
                # Pop Tag from tag_queue.
                tag_queue.source.ready.eq(1),
                # Push Req to req_queue.
                req_queue.sink.valid.eq(1),
                NextState("WAIT-REQ")
            )
        )

        # Completions Data Buffers (Reordering) ----------------------------------------------------
        #                          ┌───────────────┐
        #   Read Requests'Tags ────►   Req Queue   ├───┐
        #                          └───────────────┘   │
        #                                              │
        #                                              ▼
        #                 ┌─► Demux                   Mux
        #             Tag │   ┌──┐    ┌──────────┐   ┌───┐
        #                 │   │  ├────► Buffer 0 ├───►   │
        #                 │   │  │    └──────────┘   │   │
        #                 │   │  │                   │   │
        #                 │   │  │    ┌──────────┐   │   │
        #        Cmp In ──┴───►  ├────► Buffer . ├───►   ├─────► Cmp Out
        #                     │  │    └──────────┘   │   │
        #                     │  │                   │   │
        #                     │  │    ┌──────────┐   │   │
        #                     │  ├────► Buffer N ├───►   │
        #                     └──┘    └──────────┘   └───┘
        #
        #

        cmp_reorder = stream.Endpoint(completion_layout(data_width))
        cmp_bufs    = []

        # Create Buffers.
        for i in range(max_pending_requests):
            cmp_buf_depth = 4*max_request_size//(data_width//8)
            cmp_buf       = ResetInserter()(SyncFIFO(completion_layout(data_width), cmp_buf_depth, buffered=cmp_bufs_buffered))
            cmp_bufs.append(cmp_buf)
        self.submodules += cmp_bufs
        self.comb += [cmp_buf.reset.eq(self.ctrl_rst) for cmp_buf in cmp_bufs]

        # Connect Cmp Input to Buffers (based on incoming Tag).
        cases = {i: [cmp_reorder.connect(cmp_bufs[i].sink)] for i in range(len(cmp_bufs))}
        cases["default"] = [cmp_reorder.ready.eq(1)]
        self.comb += Case(cmp_reorder.tag, cases)

        # Connect Buffers to Cmp Output (based on Tag from req_queue).
        self.comb += Case(req_queue.source.tag,
            {i: cmp_bufs[i].source.connect(cmp_source) for i in range(len(cmp_bufs))})
        self.comb += [
            # Pop Req from req_queue when Req is fully received.
            If(cmp_source.valid & cmp_source.last & cmp_source.end,
                req_queue.source.ready.eq(cmp_source.ready)
            ),
            req_queue.source.connect(cmp_source, keep={"channel", "user_id"}),
        ]

        # Completions Management -------------------------------------------------------------------

        fill_tag = Signal(tag_bits)
        self.sync += If(self.ctrl_rst, fill_tag.eq(0))

        # Connect Data-Path.
        self.comb += cmp_sink.connect(cmp_reorder, omit={"valid", "ready"})

        # FSM
        self.cmp_fsm = cmp_fsm = ResetInserter()(FSM(reset_state="FILL-TAG-QUEUE"))
        self.comb += cmp_fsm.reset.eq(self.ctrl_rst)
        cmp_fsm.act("FILL-TAG-QUEUE",
            # Pre-fill Tags.
            tag_queue.sink.valid.eq(1),
            tag_queue.sink.tag.eq(fill_tag),
            NextValue(fill_tag, fill_tag + 1),
            If(fill_tag == (max_pending_requests - 1),
                NextState("WAIT")
            )
        )
        cmp_fsm.act("WAIT",
            # Wait for a TLP Completion...
            If(cmp_sink.valid & cmp_sink.first,
                NextState("RUN")
            ).Else(
                cmp_sink.ready.eq(1)
            )
        )
        cmp_fsm.act("RUN",
            # Connect Control-Path.
            cmp_sink.connect(cmp_reorder, keep={"valid", "ready"}),
            # Push incoming Tag to tag_queue when Cmp is fully received.
            If(cmp_sink.valid & cmp_sink.ready & cmp_sink.last,
                If(cmp_sink.end,
                    tag_queue.sink.valid.eq(1),
                    tag_queue.sink.tag.eq(cmp_sink.tag)
                ),
                NextState("WAIT")
            )
        )

```

`litepcie/tlp/depacketizer.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2015-2022 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

from migen import *

from litex.gen import *

from litepcie.tlp.common import *

# LitePCIeTLPHeaderExtracter64b --------------------------------------------------------------------

class LitePCIeTLPHeaderExtracter64b(LiteXModule):
    def __init__(self):
        self.sink   = sink   = stream.Endpoint(phy_layout(64))
        self.source = source = stream.Endpoint(tlp_raw_layout(64))

        # # #

        first = Signal()
        last  = Signal()
        count = Signal()
        dat   = Signal(64,    reset_less=True)
        be    = Signal(64//8, reset_less=True)
        self.sync += \
            If(sink.valid & sink.ready,
                dat.eq(sink.dat),
                be.eq(sink.be)
            )

        self.fsm = fsm = FSM(reset_state="IDLE")
        fsm.act("IDLE",
            NextValue(first, 1),
            NextValue(last,  0),
            NextValue(count, 0),
            If(sink.valid, NextState("HEADER"))
        )
        fsm.act("HEADER",
            sink.ready.eq(1),
            If(sink.valid,
                NextValue(count, count + 1),
                NextValue(source.header[32*0:32*1], source.header[32*2:32*3]),
                NextValue(source.header[32*1:32*2], source.header[32*3:32*4]),
                NextValue(source.header[32*2:32*3],      sink.dat[32*0:32*1]),
                NextValue(source.header[32*3:32*4],      sink.dat[32*1:32*2]),
                If(count,
                    If(sink.last, NextValue(last, 1)),
                    NextState("COPY")
                )
            )
        )
        fsm.act("COPY",
            source.valid.eq(sink.valid | last),
            source.first.eq(first),
            source.last.eq(sink.last | last),
            If(source.valid & source.ready,
                NextValue(first, 0),
                sink.ready.eq(1 & ~last), # already acked when last is 1
                If(source.last, NextState("IDLE"))
            )
        )
        self.comb += [
            source.dat[32*0:32*1].eq(     dat[32*1:32*2]),
            source.dat[32*1:32*2].eq(sink.dat[32*0:32*1]),
            source.be[  4*0: 4*1].eq(     be[4*1:4*2]),
            source.be[  4*1: 4*2].eq(sink.be[4*0:4*1])
        ]

# LitePCIeTLPHeaderExtracter128b -------------------------------------------------------------------

class LitePCIeTLPHeaderExtracter128b(LiteXModule):
    def __init__(self):
        self.sink   = sink   = stream.Endpoint(phy_layout(128))
        self.source = source = stream.Endpoint(tlp_raw_layout(128))

        # # #

        first = Signal()
        last  = Signal()
        dat   = Signal(128,    reset_less=True)
        be    = Signal(128//8, reset_less=True)
        self.sync += \
            If(sink.valid & sink.ready,
                dat.eq(sink.dat),
                be.eq(sink.be)
            )

        self.fsm = fsm = FSM(reset_state="IDLE")
        fsm.act("IDLE",
            NextValue(first, 1),
            NextValue(last,  0),
            If(sink.valid,
                NextState("HEADER")
            )
        )
        fsm.act("HEADER",
            sink.ready.eq(1),
            If(sink.valid,
                NextValue(source.header[32*0:32*1], sink.dat[32*0:32*1]),
                NextValue(source.header[32*1:32*2], sink.dat[32*1:32*2]),
                NextValue(source.header[32*2:32*3], sink.dat[32*2:32*3]),
                NextValue(source.header[32*3:32*4], sink.dat[32*3:32*4]),
                If(sink.last,
                    NextValue(last, 1)
                ),
                NextState("COPY")
            )
        )
        fsm.act("COPY",
            source.valid.eq(sink.valid | last),
            source.first.eq(first),
            source.last.eq(sink.last | last),
            If(source.valid & source.ready,
                NextValue(first, 0),
                sink.ready.eq(1 & ~last), # already acked when last is 1
                If(source.last,
                    NextState("IDLE")
                )
            )
        )
        self.comb += [
            source.dat[32*0:32*1].eq(     dat[32*3:32*4]),
            source.dat[32*1:32*2].eq(sink.dat[32*0:32*1]),
            source.dat[32*2:32*3].eq(sink.dat[32*1:32*2]),
            source.dat[32*3:32*4].eq(sink.dat[32*2:32*3]),
            source.be[  4*0: 4*1].eq(        be[4*3:4*4]),
            source.be[  4*1: 4*2].eq(   sink.be[4*0:4*1]),
            source.be[  4*2: 4*3].eq(   sink.be[4*1:4*2]),
            source.be[  4*1: 4*2].eq(   sink.be[4*2:4*3]),
        ]

# LitePCIeTLPHeaderExtracter256b -------------------------------------------------------------------

class LitePCIeTLPHeaderExtracter256b(LiteXModule):
    def __init__(self):
        self.sink   = sink   = stream.Endpoint(phy_layout(256))
        self.source = source = stream.Endpoint(tlp_raw_layout(256))

        # # #

        first = Signal()
        last  = Signal()
        dat   = Signal(256,    reset_less=True)
        be    = Signal(256//8, reset_less=True)
        self.sync += \
            If(sink.valid & sink.ready,
                dat.eq(sink.dat),
                be.eq(sink.be)
            )

        self.fsm = fsm = FSM(reset_state="IDLE")
        fsm.act("IDLE",
            NextValue(first, 1),
            NextValue(last,  0),
            If(sink.valid,
                NextState("HEADER")
            )
        )
        fsm.act("HEADER",
            sink.ready.eq(1),
            If(sink.valid,
                NextValue(source.header[32*0:32*1], sink.dat[32*0:32*1]),
                NextValue(source.header[32*1:32*2], sink.dat[32*1:32*2]),
                NextValue(source.header[32*2:32*3], sink.dat[32*2:32*3]),
                NextValue(source.header[32*3:32*4], sink.dat[32*3:32*4]),
                If(sink.last,
                    NextValue(last, 1)
                ),
                NextState("COPY")
            )
        )
        fsm.act("COPY",
            source.valid.eq(sink.valid | last),
            source.first.eq(first),
            source.last.eq(sink.last | last),
            If(source.valid & source.ready,
                NextValue(first, 0),
                sink.ready.eq(1 & ~last), # already acked when last is 1
                If(source.last,
                    NextState("IDLE")
                )
            )
        )
        self.comb += [
            source.dat[32*0:32*1].eq(     dat[32*3:32*4]),
            source.dat[32*1:32*2].eq(     dat[32*4:32*5]),
            source.dat[32*2:32*3].eq(     dat[32*5:32*6]),
            source.dat[32*3:32*4].eq(     dat[32*6:32*7]),
            source.dat[32*4:32*5].eq(     dat[32*7:32*8]),
            source.dat[32*5:32*6].eq(sink.dat[32*0:32*1]),
            source.dat[32*6:32*7].eq(sink.dat[32*1:32*2]),
            source.dat[32*7:32*8].eq(sink.dat[32*2:32*3]),

            source.be[4*0:4*1].eq(     be[4*3:4*4]),
            source.be[4*1:4*2].eq(     be[4*4:4*5]),
            source.be[4*2:4*3].eq(     be[4*5:4*6]),
            source.be[4*3:4*4].eq(     be[4*6:4*7]),
            source.be[4*4:4*5].eq(     be[4*7:4*8]),
            source.be[4*5:4*6].eq(sink.be[4*0:4*1]),
            source.be[4*6:4*7].eq(sink.be[4*1:4*2]),
            source.be[4*7:4*8].eq(sink.be[4*2:4*3])
        ]

# LitePCIeTLPHeaderExtracter512b -------------------------------------------------------------------

class LitePCIeTLPHeaderExtracter512b(LiteXModule):
    def __init__(self):
        self.sink   = sink   = stream.Endpoint(phy_layout(512))
        self.source = source = stream.Endpoint(tlp_raw_layout(512))

        # # #

        first = Signal()
        last  = Signal()
        dat   = Signal(512,    reset_less=True)
        be    = Signal(512//8, reset_less=True)
        self.sync += \
            If(sink.valid & sink.ready,
                dat.eq(sink.dat),
                be.eq(sink.be)
            )

        self.fsm = fsm = FSM(reset_state="IDLE")
        fsm.act("IDLE",
            NextValue(first, 1),
            NextValue(last,  0),
            If(sink.valid,
                NextState("HEADER")
            )
        )
        fsm.act("HEADER",
            sink.ready.eq(1),
            If(sink.valid,
                NextValue(source.header[32*0:32*1], sink.dat[32*0:32*1]),
                NextValue(source.header[32*1:32*2], sink.dat[32*1:32*2]),
                NextValue(source.header[32*2:32*3], sink.dat[32*2:32*3]),
                NextValue(source.header[32*3:32*4], sink.dat[32*3:32*4]),
                If(sink.last,
                    NextValue(last, 1)
                ),
                NextState("COPY")
            )
        )
        fsm.act("COPY",
            source.valid.eq(sink.valid | last),
            source.first.eq(first),
            source.last.eq(sink.last | last),
            If(source.valid & source.ready,
                NextValue(first, 0),
                sink.ready.eq(1 & ~last), # already acked when last is 1
                If(source.last,
                    NextState("IDLE")
                )
            )
        )
        self.comb += [
            source.dat[ 32*0: 32*1].eq(     dat[ 32*3: 32*4]),
            source.dat[ 32*1: 32*2].eq(     dat[ 32*4: 32*5]),
            source.dat[ 32*2: 32*3].eq(     dat[ 32*5: 32*6]),
            source.dat[ 32*3: 32*4].eq(     dat[ 32*6: 32*7]),
            source.dat[ 32*4: 32*5].eq(     dat[ 32*7: 32*8]),
            source.dat[ 32*5: 32*6].eq(     dat[ 32*8: 32*9]),
            source.dat[ 32*6: 32*7].eq(     dat[ 32*9:32*10]),
            source.dat[ 32*7: 32*8].eq(     dat[32*10:32*11]),
            source.dat[ 32*8: 32*9].eq(     dat[32*11:32*12]),
            source.dat[ 32*9:32*10].eq(     dat[32*12:32*13]),
            source.dat[32*10:32*11].eq(     dat[32*13:32*14]),
            source.dat[32*11:32*12].eq(     dat[32*14:32*15]),
            source.dat[32*12:32*13].eq(     dat[32*15:32*16]),
            source.dat[32*13:32*14].eq(sink.dat[ 32*0: 32*1]),
            source.dat[32*14:32*15].eq(sink.dat[ 32*1: 32*2]),
            source.dat[32*15:32*16].eq(sink.dat[ 32*2: 32*3]),


            source.be[ 4*0: 4*1].eq(     be[ 4*3: 4*4]),
            source.be[ 4*1: 4*2].eq(     be[ 4*4: 4*5]),
            source.be[ 4*2: 4*3].eq(     be[ 4*5: 4*6]),
            source.be[ 4*3: 4*4].eq(     be[ 4*6: 4*7]),
            source.be[ 4*4: 4*5].eq(     be[ 4*7: 4*8]),
            source.be[ 4*5: 4*6].eq(     be[ 4*8: 4*9]),
            source.be[ 4*6: 4*7].eq(     be[ 4*9:4*10]),
            source.be[ 4*7: 4*8].eq(     be[4*10:4*11]),
            source.be[ 4*8: 4*9].eq(     be[4*11:4*12]),
            source.be[ 4*9:4*10].eq(     be[4*12:4*13]),
            source.be[4*10:4*11].eq(     be[4*13:4*14]),
            source.be[4*11:4*12].eq(     be[4*14:4*15]),
            source.be[4*12:4*13].eq(     be[4*15:4*16]),
            source.be[4*13:4*14].eq(sink.be[ 4*0: 4*1]),
            source.be[4*14:4*15].eq(sink.be[ 4*1: 4*2]),
            source.be[4*15:4*16].eq(sink.be[ 4*2: 4*3]),
        ]

# LitePCIeTLPDepacketizer --------------------------------------------------------------------------

class LitePCIeTLPDepacketizer(LiteXModule):
    def __init__(self, data_width, endianness, address_mask=0, capabilities=["REQUEST", "COMPLETION"]):
        # Sink Endpoint.
        self.sink = stream.Endpoint(phy_layout(data_width))

        # Source Endpoints.
        for c in capabilities:
            assert c in ["REQUEST", "COMPLETION", "CONFIGURATION", "PTM"]
        if "REQUEST" in capabilities:
            self.req_source  = req_source  = stream.Endpoint(request_layout(data_width))
        if "COMPLETION" in capabilities:
            self.cmp_source  = cmp_source  = stream.Endpoint(completion_layout(data_width))
        if "CONFIGURATION" in capabilities:
            self.conf_source = conf_source = stream.Endpoint(configuration_layout(data_width))
        if "PTM" in capabilities:
            self.ptm_source = ptm_source = stream.Endpoint(ptm_layout(data_width))

        # # #

        # Extract RAW Header from Sink -------------------------------------------------------------

        header_extracter_cls = {
             64 : LitePCIeTLPHeaderExtracter64b,
            128 : LitePCIeTLPHeaderExtracter128b,
            256 : LitePCIeTLPHeaderExtracter256b,
            512 : LitePCIeTLPHeaderExtracter512b,
        }
        self.header_extracter = header_extracter = header_extracter_cls[data_width]()
        self.comb += self.sink.connect(header_extracter.sink)
        header = header_extracter.source.header

        # Create Dispatcher ------------------------------------------------------------------------

        # Dispatch Sources
        self.dispatch_sources = dispatch_sources = {"DISCARD" : stream.Endpoint(tlp_common_layout(data_width))}
        for source in capabilities:
            dispatch_sources[source] = stream.Endpoint(tlp_common_layout(data_width))

        def dispatch_source_sel(name):
            for n, k in enumerate(dispatch_sources.keys()):
                if k == name:
                    return n
            return None

        # Dispatch Sink.
        self.dispatch_sink = dispatch_sink = stream.Endpoint(tlp_common_layout(data_width))

        # Dispatcher
        self.dispatcher = Dispatcher(
            master = dispatch_sink,
            slaves = dispatch_sources.values()
        )

        # Ensure DISCARD source is always ready.
        self.comb += dispatch_sources["DISCARD"].ready.eq(1)

        # Connect Header Extracter to Dispatch Sink.
        self.comb += [
            header_extracter.source.connect(dispatch_sink, keep={"valid", "ready", "first", "last"}),
            tlp_common_header.decode(header, dispatch_sink)
        ]
        self.comb += dword_endianness_swap(
            src        = header_extracter.source.dat,
            dst        = dispatch_sink.dat,
            data_width = data_width,
            endianness = endianness,
            mode       = "dat",
        )
        self.comb += dword_endianness_swap(
            src        = header_extracter.source.be,
            dst        = dispatch_sink.be,
            data_width = data_width,
            endianness = endianness,
            mode       = "be",
        )

        # Create fmt_type for destination decoding.
        self.fmt_type = fmt_type = Cat(dispatch_sink.type, dispatch_sink.fmt)

        # Set default Dispatcher select to DISCARD Sink.
        self.comb += self.dispatcher.sel.eq(dispatch_source_sel("DISCARD"))

        # Decode/Dispatch TLP Requests -------------------------------------------------------------

        if "REQUEST" in capabilities:
            self.comb += [
                If((fmt_type == fmt_type_dict["mem_rd32"]) |
                   (fmt_type == fmt_type_dict["mem_wr32"]),
                    self.dispatcher.sel.eq(dispatch_source_sel("REQUEST")),
                )
            ]

            self.tlp_req = tlp_req = stream.Endpoint(tlp_request_layout(data_width))
            self.comb += dispatch_sources["REQUEST"].connect(tlp_req)
            self.comb += tlp_request_header.decode(header, tlp_req)

            req_type = Cat(tlp_req.type, tlp_req.fmt)
            self.comb += [
                req_source.valid.eq(tlp_req.valid),
                req_source.we.eq(tlp_req.valid & (req_type == fmt_type_dict["mem_wr32"])),
                tlp_req.ready.eq(req_source.ready),
                req_source.first.eq(tlp_req.first),
                req_source.last.eq(tlp_req.last),
                req_source.adr.eq(tlp_req.address & (~address_mask)),
                req_source.len.eq(tlp_req.length),
                req_source.req_id.eq(tlp_req.requester_id),
                req_source.tag.eq(tlp_req.tag),
                req_source.dat.eq(tlp_req.dat)
            ]

        # Decode/Dispatch TLP Completions ----------------------------------------------------------

        if "COMPLETION" in capabilities:
            self.comb += [
                If((fmt_type == fmt_type_dict["cpld"]) |
                   (fmt_type == fmt_type_dict["cpl"]),
                    self.dispatcher.sel.eq(dispatch_source_sel("COMPLETION")),
                )
            ]

            self.tlp_cmp = tlp_cmp = stream.Endpoint(tlp_completion_layout(data_width))
            self.comb += dispatch_sources["COMPLETION"].connect(tlp_cmp)
            self.comb += tlp_completion_header.decode(header, tlp_cmp)

            self.comb += [
                cmp_source.valid.eq(tlp_cmp.valid),
                tlp_cmp.ready.eq(cmp_source.ready),
                cmp_source.first.eq(tlp_cmp.first),
                cmp_source.last.eq(tlp_cmp.last),
                cmp_source.len.eq(tlp_cmp.length),
                cmp_source.end.eq(tlp_cmp.length == (tlp_cmp.byte_count[2:])),
                cmp_source.adr.eq(tlp_cmp.lower_address),
                cmp_source.req_id.eq(tlp_cmp.requester_id),
                cmp_source.cmp_id.eq(tlp_cmp.completer_id),
                cmp_source.err.eq(tlp_cmp.status != 0),
                cmp_source.tag.eq(tlp_cmp.tag),
                cmp_source.dat.eq(tlp_cmp.dat)
            ]


        # Decode/Dispatch TLP Configurations -------------------------------------------------------

        if "CONFIGURATION" in capabilities:
            self.comb += [
                If((fmt_type == fmt_type_dict["cfg_rd0"]) |
                   (fmt_type == fmt_type_dict["cfg_wr0"]),
                    self.dispatcher.sel.eq(dispatch_source_sel("CONFIGURATION")),
                )
            ]

            self.tlp_conf = tlp_conf = stream.Endpoint(tlp_configuration_layout(data_width))
            self.comb += dispatch_sources["CONFIGURATION"].connect(tlp_conf)
            self.comb += tlp_configuration_header.decode(header, tlp_conf)

            self.comb += [
                conf_source.valid.eq(tlp_conf.valid),
                tlp_conf.ready.eq(conf_source.ready),
                conf_source.first.eq(tlp_conf.first),
                conf_source.last.eq(tlp_conf.last),
                If(fmt_type == fmt_type_dict["cfg_rd0"],
                    conf_source.we.eq(0)
                ),
                If(fmt_type == fmt_type_dict["cfg_wr0"],
                    conf_source.we.eq(1)
                ),
                conf_source.req_id.eq(tlp_conf.requester_id),
                conf_source.bus_number.eq(tlp_conf.bus_number),
                conf_source.device_no.eq(tlp_conf.device_no),
                conf_source.func.eq(tlp_conf.func),
                conf_source.ext_reg.eq(tlp_conf.ext_reg),
                conf_source.register_no.eq(tlp_conf.register_no),
                conf_source.tag.eq(tlp_conf.tag),
                conf_source.dat.eq(tlp_conf.dat)
            ]

        # Decode/Dispatch TLP PTM Requests/Responses -----------------------------------------------

        if "PTM" in capabilities:
            self.comb += [
                If((fmt_type == fmt_type_dict["ptm_req"]) |
                   (fmt_type == fmt_type_dict["ptm_res"]),
                    self.dispatcher.sel.eq(dispatch_source_sel("PTM")),
                )
            ]

            self.tlp_ptm = tlp_ptm = stream.Endpoint(tlp_ptm_layout(data_width))
            self.comb += dispatch_sources["PTM"].connect(tlp_ptm)
            self.comb += tlp_ptm_header.decode(header, tlp_ptm)

            self.comb += [
                ptm_source.valid.eq(tlp_ptm.valid),
                tlp_ptm.ready.eq(ptm_source.ready),
                ptm_source.first.eq(tlp_ptm.first),
                ptm_source.last.eq(tlp_ptm.last),
                ptm_source.requester_id.eq(tlp_ptm.requester_id),
                ptm_source.length.eq(tlp_ptm.length),
                ptm_source.message_code.eq(tlp_ptm.message_code),
                ptm_source.master_time.eq(tlp_ptm.master_time),
                ptm_source.dat.eq(tlp_ptm.dat)
            ]

```

`litepcie/tlp/packetizer.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2015-2023 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

from migen import *

from litex.gen import *

from litepcie.tlp.common import *

# LitePCIeTLPHeaderInserter ------------------------------------------------------------------------

class LitePCIeTLPHeaderInserter3DWs4DWs(LiteXModule):
    def __init__(self, data_width, header_inserter_3dws_cls, header_inserter_4dws_cls, fmt):
        self.sink   = sink   = stream.Endpoint(tlp_raw_layout(data_width))
        self.source = source = stream.Endpoint(phy_layout(data_width))

        # # #

        # Header Inserters Modules.
        header_inserter_3dws = header_inserter_3dws_cls()
        header_inserter_4dws = header_inserter_4dws_cls()
        self.submodules += header_inserter_3dws, header_inserter_4dws

        # Header Inserters Sel.
        _3DWS_SEL = 0b0
        _4DWS_SEL = 0b1
        header_sel = Signal()
        self.comb += Case(fmt, {
            fmt_dict["mem_rd32"] : header_sel.eq(_3DWS_SEL),
            fmt_dict["mem_rd64"] : header_sel.eq(_4DWS_SEL),
            fmt_dict["mem_wr32"] : header_sel.eq(_3DWS_SEL),
            fmt_dict["mem_wr64"] : header_sel.eq(_4DWS_SEL),
            fmt_dict[ "cfg_rd0"] : header_sel.eq(_3DWS_SEL),
            fmt_dict[ "cfg_wr0"] : header_sel.eq(_3DWS_SEL),
            fmt_dict[    "cpld"] : header_sel.eq(_3DWS_SEL),
            fmt_dict[     "cpl"] : header_sel.eq(_3DWS_SEL),
            fmt_dict[ "ptm_req"] : header_sel.eq(_4DWS_SEL),
            fmt_dict[ "ptm_res"] : header_sel.eq(_4DWS_SEL),
        })

        # Header Inserters Mux.
        self.comb += Case(header_sel, {
            _3DWS_SEL : [
                sink.connect(header_inserter_3dws.sink),
                header_inserter_3dws.source.connect(source),
            ],
            _4DWS_SEL : [
                sink.connect(header_inserter_4dws.sink),
                header_inserter_4dws.source.connect(source),
            ],
        })

# LitePCIeTLPHeaderInserter64b ---------------------------------------------------------------------

class LitePCIeTLPHeaderInserter64b3DWs(LiteXModule):
    def __init__(self):
        self.sink   = sink   = stream.Endpoint(tlp_raw_layout(64))
        self.source = source = stream.Endpoint(phy_layout(64))

        # # #

        count = Signal()
        dat   = Signal(64,    reset_less=True)
        be    = Signal(64//8, reset_less=True)
        last  = Signal(       reset_less=True)
        self.sync += [
            If(sink.valid & sink.ready,
                dat.eq(sink.dat),
                be.eq(sink.be),
                last.eq(sink.last)
            )
        ]

        self.fsm = fsm = FSM(reset_state="HEADER")
        fsm.act("HEADER",
            sink.ready.eq(1),
            If(sink.valid & sink.first,
                sink.ready.eq(0),
                source.valid.eq(1),
                source.first.eq((count == 0) & sink.first),
                source.last.eq( (count == 1) & sink.last & (sink.be[4*1:] == 0)),
                If(count == 0,
                    source.dat[32*0:32*1].eq(sink.header[32*0:]),
                    source.dat[32*1:32*2].eq(sink.header[32*1:]),
                    source.be[4*0:4*1].eq(0xf),
                    source.be[4*1:4*2].eq(0xf),
                ),
                If(count == 1,
                    source.dat[32*0:32*1].eq(sink.header[32*2:]),
                    source.dat[32*1:32*2].eq(sink.dat[32*0:]),
                    source.be[4*0:4*1].eq(0xf),
                    source.be[4*1:4*2].eq(sink.be[4*0:]),
                ),
                If(source.valid & source.ready,
                    NextValue(count, count + 1),
                    If(count == 1,
                        sink.ready.eq(1),
                        If(~source.last,
                            NextState("DATA")
                        )
                    )
                )
            )
        )
        fsm.act("DATA",
            source.valid.eq(sink.valid | last),
            source.last.eq(last),

            source.dat[32*0:32*1].eq(dat[32*1:]),
            source.dat[32*1:32*2].eq(sink.dat[32*0:]),

            source.be[4*0:4*1].eq(be[4*0:]),
            If(last,
                source.be[4*1:4*2].eq(0x0)
            ).Else(
                source.be[4*1:4*2].eq(sink.be[4*0:])
            ),

            If(source.valid & source.ready,
                sink.ready.eq(~last),
                If(source.last,
                    NextState("HEADER")
                )
            )
        )

class LitePCIeTLPHeaderInserter64b4DWs(LiteXModule):
    def __init__(self):
        self.sink   = sink   = stream.Endpoint(tlp_raw_layout(64))
        self.source = source = stream.Endpoint(phy_layout(64))

        # # #

        count = Signal()
        self.fsm = fsm = FSM(reset_state="HEADER")
        fsm.act("HEADER",
            sink.ready.eq(1),
            If(sink.valid & sink.first,
                sink.ready.eq(0),
                source.valid.eq(1),
                source.first.eq((count == 0) & sink.first),
                source.last.eq( (count == 1) & sink.last & (sink.be == 0)),
                If(count == 0,
                    source.dat[32*0:32*1].eq(sink.header[32*0:]),
                    source.dat[32*1:32*2].eq(sink.header[32*1:]),
                    source.be[4*0:4*1].eq(0xf),
                    source.be[4*1:4*2].eq(0xf),
                ),
                If(count == 1,
                    source.dat[32*0:32*1].eq(sink.header[32*2:]),
                    source.dat[32*1:32*2].eq(sink.header[32*3:]),
                    source.be[4*0:4*1].eq(0xf),
                    source.be[4*1:4*2].eq(0xf),
                ),
                If(source.valid & source.ready,
                    NextValue(count, count + 1),
                    If(count == 1,
                        sink.ready.eq(1),
                        If(~source.last,
                            sink.ready.eq(0),
                            NextState("DATA")
                        )
                    )
                )
            )
        )
        fsm.act("DATA",
            source.valid.eq(sink.valid),
            source.last.eq(sink.last),

            source.dat[32*0:32*1].eq(sink.dat[32*0:]),
            source.dat[32*1:32*2].eq(sink.dat[32*1:]),
            source.be[4*0:4*1].eq(sink.be[4*0:]),
            source.be[4*1:4*2].eq(sink.be[4*1:]),

            If(source.valid & source.ready,
                sink.ready.eq(1),
                If(source.last,
                    NextState("HEADER")
                )
            )
        )

class LitePCIeTLPHeaderInserter64b(LitePCIeTLPHeaderInserter3DWs4DWs):
    def __init__(self, fmt):
        LitePCIeTLPHeaderInserter3DWs4DWs.__init__(self,
            data_width               = 64,
            header_inserter_3dws_cls = LitePCIeTLPHeaderInserter64b3DWs,
            header_inserter_4dws_cls = LitePCIeTLPHeaderInserter64b4DWs,
            fmt                      = fmt,
        )

# LitePCIeTLPHeaderInserter128b --------------------------------------------------------------------

class LitePCIeTLPHeaderInserter128b3DWs(LiteXModule):
    def __init__(self):
        self.sink   = sink   = stream.Endpoint(tlp_raw_layout(128))
        self.source = source = stream.Endpoint(phy_layout(128))

        # # #

        dat  = Signal(128,    reset_less=True)
        be   = Signal(128//8, reset_less=True)
        last = Signal(        reset_less=True)
        self.sync += [
            If(sink.valid & sink.ready,
                dat.eq(sink.dat),
                be.eq(sink.be),
                last.eq(sink.last)
            )
        ]

        self.fsm = fsm = FSM(reset_state="HEADER")
        fsm.act("HEADER",
            sink.ready.eq(1),
            If(sink.valid & sink.first,
                sink.ready.eq(0),
                source.valid.eq(1),
                source.first.eq(1),
                source.last.eq(sink.last & (sink.be[4*1:] == 0)),

                source.dat[32*0:32*1].eq(sink.header[32*0:]),
                source.dat[32*1:32*2].eq(sink.header[32*1:]),
                source.dat[32*2:32*3].eq(sink.header[32*2:]),
                source.dat[32*3:32*4].eq(sink.dat[32*0:]),

                source.be[4*0:4*1].eq(0xf),
                source.be[4*1:4*2].eq(0xf),
                source.be[4*2:4*3].eq(0xf),
                source.be[4*3:4*4].eq(sink.be[0:]),

                If(source.valid & source.ready,
                    sink.ready.eq(1),
                    If(~source.last,
                        NextState("DATA"),
                    )
                )
            )
        )
        fsm.act("DATA",
            source.valid.eq(sink.valid | last),
            source.last.eq(last),

            source.dat[32*0:32*1].eq(dat[32*1:]),
            source.dat[32*1:32*2].eq(dat[32*2:]),
            source.dat[32*2:32*3].eq(dat[32*3:]),
            source.dat[32*3:32*4].eq(sink.dat[32*0:]),

            source.be[4*0:4*1].eq(be[1:]),
            source.be[4*1:4*2].eq(be[2:]),
            source.be[4*2:4*3].eq(be[3:]),
            If(last,
                source.be[4*3:4*4].eq(0x0)
            ).Else(
                source.be[4*3:4*4].eq(sink.be[0:])
            ),

            If(source.valid & source.ready,
                sink.ready.eq(~last),
                If(source.last,
                    NextState("HEADER")
                )
            )
        )

class LitePCIeTLPHeaderInserter128b4DWs(LiteXModule):
    def __init__(self):
        self.sink   = sink   = stream.Endpoint(tlp_raw_layout(128))
        self.source = source = stream.Endpoint(phy_layout(128))

        # # #

        self.fsm = fsm = FSM(reset_state="HEADER")
        fsm.act("HEADER",
            sink.ready.eq(1),
            If(sink.valid & sink.first,
                sink.ready.eq(0),
                source.valid.eq(1),
                source.first.eq(1),
                source.last.eq(sink.last & (sink.be == 0)),

                source.dat[32*0:32*1].eq(sink.header[32*0:]),
                source.dat[32*1:32*2].eq(sink.header[32*1:]),
                source.dat[32*2:32*3].eq(sink.header[32*2:]),
                source.dat[32*3:32*4].eq(sink.header[32*3:]),

                source.be[4*0:4*1].eq(0xf),
                source.be[4*1:4*2].eq(0xf),
                source.be[4*2:4*3].eq(0xf),
                source.be[4*3:4*4].eq(0xf),

                If(source.valid & source.ready,
                    sink.ready.eq(1),
                    If(~source.last,
                        sink.ready.eq(0),
                        NextState("DATA"),
                    )
                )
            )
        )
        fsm.act("DATA",
            source.valid.eq(sink.valid),
            source.last.eq(sink.last),

            source.dat[32*0:32*1].eq(sink.dat[32*0:]),
            source.dat[32*1:32*2].eq(sink.dat[32*1:]),
            source.dat[32*2:32*3].eq(sink.dat[32*2:]),
            source.dat[32*3:32*4].eq(sink.dat[32*3:]),

            source.be[4*0:4*1].eq(sink.be[4*0:]),
            source.be[4*1:4*2].eq(sink.be[4*1:]),
            source.be[4*2:4*3].eq(sink.be[4*2:]),
            source.be[4*3:4*4].eq(sink.be[4*3:]),

            If(source.valid & source.ready,
                sink.ready.eq(1),
                If(source.last,
                    NextState("HEADER")
                )
            )
        )

class LitePCIeTLPHeaderInserter128b(LitePCIeTLPHeaderInserter3DWs4DWs):
    def __init__(self, fmt):
        LitePCIeTLPHeaderInserter3DWs4DWs.__init__(self,
            data_width               = 128,
            header_inserter_3dws_cls = LitePCIeTLPHeaderInserter128b3DWs,
            header_inserter_4dws_cls = LitePCIeTLPHeaderInserter128b4DWs,
            fmt                      = fmt,
        )

# LitePCIeTLPHeaderInserter256b --------------------------------------------------------------------

class LitePCIeTLPHeaderInserter256b3DWs(LiteXModule):
    def __init__(self):
        self.sink   = sink   = stream.Endpoint(tlp_raw_layout(256))
        self.source = source = stream.Endpoint(phy_layout(256))

        # # #

        dat  = Signal(256,    reset_less=True)
        be   = Signal(256//8, reset_less=True)
        last = Signal(        reset_less=True)
        self.sync += [
            If(sink.valid & sink.ready,
                dat.eq(sink.dat),
                be.eq(sink.be),
                last.eq(sink.last)
            )
        ]

        self.fsm = fsm = FSM(reset_state="HEADER")
        fsm.act("HEADER",
            sink.ready.eq(1),
            If(sink.valid & sink.first,
                sink.ready.eq(0),
                source.valid.eq(1),
                source.first.eq(1),
                source.last.eq(sink.last & (sink.be[4*5:] == 0)),

                source.dat[32*0:32*1].eq(sink.header[32*0:]),
                source.dat[32*1:32*2].eq(sink.header[32*1:]),
                source.dat[32*2:32*3].eq(sink.header[32*2:]),
                source.dat[32*3:32*4].eq(sink.dat[32*0:]),
                source.dat[32*4:32*5].eq(sink.dat[32*1:]),
                source.dat[32*5:32*6].eq(sink.dat[32*2:]),
                source.dat[32*6:32*7].eq(sink.dat[32*3:]),
                source.dat[32*7:32*8].eq(sink.dat[32*4:]),

                source.be[4*0:4*1].eq(0xf),
                source.be[4*1:4*2].eq(0xf),
                source.be[4*2:4*3].eq(0xf),
                source.be[4*3:4*4].eq(sink.be[4*0:]),
                source.be[4*4:4*5].eq(sink.be[4*1:]),
                source.be[4*5:4*6].eq(sink.be[4*2:]),
                source.be[4*6:4*7].eq(sink.be[4*3:]),
                source.be[4*7:4*8].eq(sink.be[4*4:]),

                If(source.valid & source.ready,
                    sink.ready.eq(1),
                    If(~source.last,
                        NextState("DATA"),
                    )
                )
            )
        )
        fsm.act("DATA",
            source.valid.eq(sink.valid | last),
            source.last.eq(last),

            source.dat[32*0:32*1].eq(dat[32*5:]),
            source.dat[32*1:32*2].eq(dat[32*6:]),
            source.dat[32*2:32*3].eq(dat[32*7:]),
            source.dat[32*3:32*4].eq(sink.dat[32*0:]),
            source.dat[32*4:32*5].eq(sink.dat[32*1:]),
            source.dat[32*5:32*6].eq(sink.dat[32*2:]),
            source.dat[32*6:32*7].eq(sink.dat[32*3:]),
            source.dat[32*7:32*8].eq(sink.dat[32*4:]),

            source.be[4*0:4*1].eq(be[4*5:]),
            source.be[4*1:4*2].eq(be[4*6:]),
            source.be[4*2:4*3].eq(be[4*7:]),
            If(last,
                source.be[4*3:4*8].eq(0x0)
            ).Else(
                source.be[4*3:4*4].eq(sink.be[4*0:]),
                source.be[4*4:4*5].eq(sink.be[4*1:]),
                source.be[4*5:4*6].eq(sink.be[4*2:]),
                source.be[4*6:4*7].eq(sink.be[4*3:]),
                source.be[4*7:4*8].eq(sink.be[4*4:]),
            ),
            If(source.valid & source.ready,
                sink.ready.eq(~last),
                If(source.last,
                    NextState("HEADER")
                )
            )
        )

class LitePCIeTLPHeaderInserter256b4DWs(LiteXModule):
    def __init__(self):
        self.sink   = sink   = stream.Endpoint(tlp_raw_layout(256))
        self.source = source = stream.Endpoint(phy_layout(256))

        # # #

        dat  = Signal(256,    reset_less=True)
        be   = Signal(256//8, reset_less=True)
        last = Signal(        reset_less=True)
        self.sync += [
            If(sink.valid & sink.ready,
                dat.eq(sink.dat),
                be.eq(sink.be),
                last.eq(sink.last)
            )
        ]

        self.fsm = fsm = FSM(reset_state="HEADER")
        fsm.act("HEADER",
            sink.ready.eq(1),
            If(sink.valid & sink.first,
                sink.ready.eq(0),
                source.valid.eq(1),
                source.first.eq(1),
                source.last.eq(sink.last & (sink.be[4*4:] == 0)),

                source.dat[32*0:32*1].eq(sink.header[32*0:]),
                source.dat[32*1:32*2].eq(sink.header[32*1:]),
                source.dat[32*2:32*3].eq(sink.header[32*2:]),
                source.dat[32*3:32*4].eq(sink.header[32*3:]),
                source.dat[32*4:32*5].eq(sink.dat[32*0:]),
                source.dat[32*5:32*6].eq(sink.dat[32*1:]),
                source.dat[32*6:32*7].eq(sink.dat[32*2:]),
                source.dat[32*7:32*8].eq(sink.dat[32*3:]),

                source.be[4*0:4*1].eq(0xf),
                source.be[4*1:4*2].eq(0xf),
                source.be[4*2:4*3].eq(0xf),
                source.be[4*3:4*4].eq(0xf),
                source.be[4*4:4*5].eq(sink.be[4*0:]),
                source.be[4*5:4*6].eq(sink.be[4*1:]),
                source.be[4*6:4*7].eq(sink.be[4*2:]),
                source.be[4*7:4*8].eq(sink.be[4*3:]),

                If(source.valid & source.ready,
                    sink.ready.eq(1),
                    If(~source.last,
                        NextState("DATA"),
                    )
                )
            )
        )
        fsm.act("DATA",
            source.valid.eq(sink.valid | last),
            source.last.eq(last),

            source.dat[32*0:32*1].eq(dat[32*4:]),
            source.dat[32*1:32*2].eq(dat[32*5:]),
            source.dat[32*2:32*3].eq(dat[32*6:]),
            source.dat[32*3:32*4].eq(dat[32*7:]),
            source.dat[32*4:32*5].eq(sink.dat[32*0:]),
            source.dat[32*5:32*6].eq(sink.dat[32*1:]),
            source.dat[32*6:32*7].eq(sink.dat[32*2:]),
            source.dat[32*7:32*8].eq(sink.dat[32*3:]),

            source.be[4*0:4*1].eq(be[4*4:]),
            source.be[4*1:4*2].eq(be[4*5:]),
            source.be[4*2:4*3].eq(be[4*6:]),
            source.be[4*3:4*4].eq(be[4*7:]),
            If(last,
                source.be[4*4:4*8].eq(0x0)
            ).Else(
                source.be[4*4:4*5].eq(sink.be[4*0:]),
                source.be[4*5:4*6].eq(sink.be[4*1:]),
                source.be[4*6:4*7].eq(sink.be[4*2:]),
                source.be[4*7:4*8].eq(sink.be[4*3:]),
            ),
            If(source.valid & source.ready,
                sink.ready.eq(~last),
                If(source.last,
                    NextState("HEADER")
                )
            )
        )

class LitePCIeTLPHeaderInserter256b(LitePCIeTLPHeaderInserter3DWs4DWs):
    def __init__(self, fmt):
        LitePCIeTLPHeaderInserter3DWs4DWs.__init__(self,
            data_width               = 256,
            header_inserter_3dws_cls = LitePCIeTLPHeaderInserter256b3DWs,
            header_inserter_4dws_cls = LitePCIeTLPHeaderInserter256b4DWs,
            fmt                      = fmt,
        )

# LitePCIeTLPHeaderInserter512b --------------------------------------------------------------------

class LitePCIeTLPHeaderInserter512b3DWs(LiteXModule):
    def __init__(self):
        self.sink   = sink   = stream.Endpoint(tlp_raw_layout(512))
        self.source = source = stream.Endpoint(phy_layout(512))

        # # #

        dat  = Signal(512,    reset_less=True)
        be   = Signal(512//8, reset_less=True)
        last = Signal(        reset_less=True)
        self.sync += [
            If(sink.valid & sink.ready,
                dat.eq(sink.dat),
                be.eq(sink.be),
                last.eq(sink.last)
            )
        ]

        self.fsm = fsm = FSM(reset_state="HEADER")
        fsm.act("HEADER",
            sink.ready.eq(1),
            If(sink.valid & sink.first,
                sink.ready.eq(0),
                source.valid.eq(1),
                source.first.eq(1),
                source.last.eq(sink.last & (sink.be[4*13:] == 0)),

                source.dat[32* 0:32* 1].eq(sink.header[32*0:]),
                source.dat[32* 1:32* 2].eq(sink.header[32*1:]),
                source.dat[32* 2:32* 3].eq(sink.header[32*2:]),
                source.dat[32* 3:32* 4].eq(sink.dat[32* 0:]),
                source.dat[32* 4:32* 5].eq(sink.dat[32* 1:]),
                source.dat[32* 5:32* 6].eq(sink.dat[32* 2:]),
                source.dat[32* 6:32* 7].eq(sink.dat[32* 3:]),
                source.dat[32* 7:32* 8].eq(sink.dat[32* 4:]),
                source.dat[32* 8:32* 9].eq(sink.dat[32* 5:]),
                source.dat[32* 9:32*10].eq(sink.dat[32* 6:]),
                source.dat[32*10:32*11].eq(sink.dat[32* 7:]),
                source.dat[32*11:32*12].eq(sink.dat[32* 8:]),
                source.dat[32*12:32*13].eq(sink.dat[32* 9:]),
                source.dat[32*13:32*14].eq(sink.dat[32*10:]),
                source.dat[32*14:32*15].eq(sink.dat[32*11:]),
                source.dat[32*15:32*16].eq(sink.dat[32*12:]),

                source.be[4* 0:4* 1].eq(0xf),
                source.be[4* 1:4* 2].eq(0xf),
                source.be[4* 2:4* 3].eq(0xf),
                source.be[4* 3:4* 4].eq(sink.be[4* 0:]),
                source.be[4* 4:4* 5].eq(sink.be[4* 1:]),
                source.be[4* 5:4* 6].eq(sink.be[4* 2:]),
                source.be[4* 6:4* 7].eq(sink.be[4* 3:]),
                source.be[4* 7:4* 8].eq(sink.be[4* 4:]),
                source.be[4* 8:4* 9].eq(sink.be[4* 5:]),
                source.be[4* 9:4*10].eq(sink.be[4* 6:]),
                source.be[4*10:4*11].eq(sink.be[4* 7:]),
                source.be[4*11:4*12].eq(sink.be[4* 8:]),
                source.be[4*12:4*13].eq(sink.be[4* 9:]),
                source.be[4*13:4*14].eq(sink.be[4*10:]),
                source.be[4*14:4*15].eq(sink.be[4*11:]),
                source.be[4*15:4*16].eq(sink.be[4*12:]),

                If(source.valid & source.ready,
                    sink.ready.eq(1),
                    If(~source.last,
                        NextState("DATA"),
                    )
                )
            )
        )
        fsm.act("DATA",
            source.valid.eq(sink.valid | last),
            source.last.eq(last),

            source.dat[32* 0:32* 1].eq(     dat[32*13:]),
            source.dat[32* 1:32* 2].eq(     dat[32*14:]),
            source.dat[32* 2:32* 3].eq(     dat[32*15:]),
            source.dat[32* 3:32* 4].eq(sink.dat[32* 0:]),
            source.dat[32* 4:32* 5].eq(sink.dat[32* 1:]),
            source.dat[32* 5:32* 6].eq(sink.dat[32* 2:]),
            source.dat[32* 6:32* 7].eq(sink.dat[32* 3:]),
            source.dat[32* 7:32* 8].eq(sink.dat[32* 4:]),
            source.dat[32* 8:32* 9].eq(sink.dat[32* 5:]),
            source.dat[32* 9:32*10].eq(sink.dat[32* 6:]),
            source.dat[32*10:32*11].eq(sink.dat[32* 7:]),
            source.dat[32*11:32*12].eq(sink.dat[32* 8:]),
            source.dat[32*12:32*13].eq(sink.dat[32* 9:]),
            source.dat[32*13:32*14].eq(sink.dat[32*10:]),
            source.dat[32*14:32*15].eq(sink.dat[32*11:]),
            source.dat[32*15:32*16].eq(sink.dat[32*12:]),

            source.be[4*0:4*1].eq(be[4*13:]),
            source.be[4*1:4*2].eq(be[4*14:]),
            source.be[4*2:4*3].eq(be[4*15:]),
            If(last,
                source.be[4*3:4*16].eq(0x0)
            ).Else(
                source.be[4* 3:4* 4].eq(sink.be[4* 0:]),
                source.be[4* 4:4* 5].eq(sink.be[4* 1:]),
                source.be[4* 5:4* 6].eq(sink.be[4* 2:]),
                source.be[4* 6:4* 7].eq(sink.be[4* 3:]),
                source.be[4* 7:4* 8].eq(sink.be[4* 4:]),
                source.be[4* 8:4* 9].eq(sink.be[4* 5:]),
                source.be[4* 9:4*10].eq(sink.be[4* 6:]),
                source.be[4*10:4*11].eq(sink.be[4* 7:]),
                source.be[4*11:4*12].eq(sink.be[4* 8:]),
                source.be[4*12:4*13].eq(sink.be[4* 9:]),
                source.be[4*13:4*14].eq(sink.be[4*10:]),
                source.be[4*14:4*15].eq(sink.be[4*11:]),
                source.be[4*15:4*16].eq(sink.be[4*12:]),
            ),
            If(source.valid & source.ready,
                sink.ready.eq(~last),
                If(source.last,
                    NextState("HEADER")
                )
            )
        )

class LitePCIeTLPHeaderInserter512b4DWs(LiteXModule):
    def __init__(self):
        self.sink   = sink   = stream.Endpoint(tlp_raw_layout(512))
        self.source = source = stream.Endpoint(phy_layout(512))

        # # #

        dat  = Signal(512,    reset_less=True)
        be   = Signal(512//8, reset_less=True)
        last = Signal(        reset_less=True)
        self.sync += [
            If(sink.valid & sink.ready,
                dat.eq(sink.dat),
                be.eq(sink.be),
                last.eq(sink.last)
            )
        ]

        self.fsm = fsm = FSM(reset_state="HEADER")
        fsm.act("HEADER",
            sink.ready.eq(1),
            If(sink.valid & sink.first,
                sink.ready.eq(0),
                source.valid.eq(1),
                source.first.eq(1),
                source.last.eq(sink.last & (sink.be[4*12:] == 0)),

                source.dat[32* 0:32* 1].eq(sink.header[32*0:]),
                source.dat[32* 1:32* 2].eq(sink.header[32*1:]),
                source.dat[32* 2:32* 3].eq(sink.header[32*2:]),
                source.dat[32* 3:32* 4].eq(sink.header[32*3:]),
                source.dat[32* 4:32* 5].eq(sink.dat[32* 0:]),
                source.dat[32* 5:32* 6].eq(sink.dat[32* 1:]),
                source.dat[32* 6:32* 7].eq(sink.dat[32* 2:]),
                source.dat[32* 7:32* 8].eq(sink.dat[32* 3:]),
                source.dat[32* 8:32* 9].eq(sink.dat[32* 4:]),
                source.dat[32* 9:32*10].eq(sink.dat[32* 5:]),
                source.dat[32*10:32*11].eq(sink.dat[32* 6:]),
                source.dat[32*11:32*12].eq(sink.dat[32* 7:]),
                source.dat[32*12:32*13].eq(sink.dat[32* 8:]),
                source.dat[32*13:32*14].eq(sink.dat[32* 9:]),
                source.dat[32*14:32*15].eq(sink.dat[32*10:]),
                source.dat[32*15:32*16].eq(sink.dat[32*11:]),

                source.be[4* 0:4* 1].eq(0xf),
                source.be[4* 1:4* 2].eq(0xf),
                source.be[4* 2:4* 3].eq(0xf),
                source.be[4* 3:4* 4].eq(0xf),
                source.be[4* 4:4* 5].eq(sink.be[4* 0:]),
                source.be[4* 5:4* 6].eq(sink.be[4* 1:]),
                source.be[4* 6:4* 7].eq(sink.be[4* 2:]),
                source.be[4* 7:4* 8].eq(sink.be[4* 3:]),
                source.be[4* 8:4* 9].eq(sink.be[4* 4:]),
                source.be[4* 9:4*10].eq(sink.be[4* 5:]),
                source.be[4*10:4*11].eq(sink.be[4* 6:]),
                source.be[4*11:4*12].eq(sink.be[4* 7:]),
                source.be[4*12:4*13].eq(sink.be[4* 8:]),
                source.be[4*13:4*14].eq(sink.be[4* 9:]),
                source.be[4*14:4*15].eq(sink.be[4*10:]),
                source.be[4*15:4*16].eq(sink.be[4*11:]),

                If(source.valid & source.ready,
                    sink.ready.eq(1),
                    If(~source.last,
                        NextState("DATA"),
                    )
                )
            )
        )
        fsm.act("DATA",
            source.valid.eq(sink.valid | last),
            source.last.eq(last),

            source.dat[32* 0:32* 1].eq(     dat[32*12:]),
            source.dat[32* 1:32* 2].eq(     dat[32*13:]),
            source.dat[32* 2:32* 3].eq(     dat[32*14:]),
            source.dat[32* 3:32* 4].eq(     dat[32*15:]),
            source.dat[32* 4:32* 5].eq(sink.dat[32* 0:]),
            source.dat[32* 5:32* 6].eq(sink.dat[32* 1:]),
            source.dat[32* 6:32* 7].eq(sink.dat[32* 2:]),
            source.dat[32* 7:32* 8].eq(sink.dat[32* 3:]),
            source.dat[32* 8:32* 9].eq(sink.dat[32* 4:]),
            source.dat[32* 9:32*10].eq(sink.dat[32* 5:]),
            source.dat[32*10:32*11].eq(sink.dat[32* 6:]),
            source.dat[32*11:32*12].eq(sink.dat[32* 7:]),
            source.dat[32*12:32*13].eq(sink.dat[32* 8:]),
            source.dat[32*13:32*14].eq(sink.dat[32* 9:]),
            source.dat[32*14:32*15].eq(sink.dat[32*10:]),
            source.dat[32*15:32*16].eq(sink.dat[32*11:]),

            source.be[4*0:4*1].eq(be[4*12:]),
            source.be[4*1:4*2].eq(be[4*13:]),
            source.be[4*2:4*3].eq(be[4*14:]),
            source.be[4*3:4*4].eq(be[4*15:]),

            If(last,
                source.be[4*4:4*16].eq(0x0)
            ).Else(
                source.be[ 4*4: 4*5].eq(sink.be[4* 0:]),
                source.be[ 4*5: 4*6].eq(sink.be[4* 1:]),
                source.be[ 4*6: 4*7].eq(sink.be[4* 2:]),
                source.be[ 4*7: 4*8].eq(sink.be[4* 3:]),
                source.be[ 4*8: 4*9].eq(sink.be[4* 4:]),
                source.be[ 4*9:4*10].eq(sink.be[4* 5:]),
                source.be[4*10:4*11].eq(sink.be[4* 6:]),
                source.be[4*11:4*12].eq(sink.be[4* 7:]),
                source.be[4*12:4*13].eq(sink.be[4* 8:]),
                source.be[4*13:4*14].eq(sink.be[4* 9:]),
                source.be[4*14:4*15].eq(sink.be[4*10:]),
                source.be[4*15:4*16].eq(sink.be[4*11:]),
            ),
            If(source.valid & source.ready,
                sink.ready.eq(~last),
                If(source.last,
                    NextState("HEADER")
                )
            )
        )

class LitePCIeTLPHeaderInserter512b(LitePCIeTLPHeaderInserter3DWs4DWs):
    def __init__(self, fmt):
        LitePCIeTLPHeaderInserter3DWs4DWs.__init__(self,
            data_width               = 512,
            header_inserter_3dws_cls = LitePCIeTLPHeaderInserter512b3DWs,
            header_inserter_4dws_cls = LitePCIeTLPHeaderInserter512b4DWs,
            fmt                      = fmt,
        )

# LitePCIeTLPPacketizer ----------------------------------------------------------------------------

class LitePCIeTLPPacketizer(LiteXModule):
    def __init__(self, data_width, endianness, address_width=32, capabilities=["REQUEST", "COMPLETION"]):
        assert data_width%32 == 0
        assert address_width in [32, 64]
        if address_width == 64:
            assert data_width in [64, 128, 256, 512]
        for c in capabilities:
            assert c in ["REQUEST", "COMPLETION", "CONFIGURATION", "PTM"]
        # Sink Endpoints.
        with_configuration = ("CONFIGURATION" in capabilities)
        if "REQUEST" in capabilities:
            self.req_sink = req_sink = stream.Endpoint(request_layout(data_width, address_width, with_configuration=with_configuration))
        if "COMPLETION" in capabilities:
            self.cmp_sink = cmp_sink = stream.Endpoint(completion_layout(data_width))
        if "PTM" in capabilities:
            self.ptm_sink = ptm_sink = stream.Endpoint(ptm_layout(data_width))

        # Source Endpoints.
        self.source   = stream.Endpoint(phy_layout(data_width))

        # # #

        req_is_cfg = Signal()
        if with_configuration:
            self.comb += req_is_cfg.eq(req_sink.is_cfg)

        # Format and Encode TLP Requests -----------------------------------------------------------

        if "REQUEST" in capabilities:
            self.tlp_req = tlp_req = stream.Endpoint(tlp_request_layout(data_width))
            self.comb += [
                If(~req_is_cfg,
                    tlp_req.valid.eq(req_sink.valid),
                    req_sink.ready.eq(tlp_req.ready)
                ),
                tlp_req.first.eq(req_sink.first),
                tlp_req.last.eq(req_sink.last),

                tlp_req.type.eq(0b00000),
                If(req_sink.we,
                    tlp_req.fmt.eq(fmt_dict["mem_wr32"]),
                ).Else(
                    tlp_req.fmt.eq(fmt_dict["mem_rd32"]),
                ),
                tlp_req.address.eq(req_sink.adr),
            ]

            # On Ultrascale(+) / 256/512-bit, force to 64-bit (for 4DWs format).
            try:
                force_64b = (LiteXContext.platform.device[:4] in ["xcku", "xcvu", "xczu", 'xcau']) and (data_width in [256, 512])
            except:
                force_64b = False

            if address_width == 64:
                self.comb += [
                    # Use WR64/RD64 only when 64-bit Address's MSB != 0, else use WR32/RD32.
                    If((req_sink.adr[32:] != 0) | force_64b,
                        # Address's MSB on DW2, LSB on DW3 with 64-bit addressing: Requires swap due to
                        # Packetizer's behavior.
                        tlp_req.address[:32].eq(req_sink.adr[32:]),
                        tlp_req.address[32:].eq(req_sink.adr[:32]),
                        If(req_sink.we,
                            tlp_req.fmt.eq(fmt_dict["mem_wr64"]),
                        ).Else(
                            tlp_req.fmt.eq(fmt_dict["mem_rd64"]),
                        ),
                    )
                ]
            elif force_64b:
                # Address width is 32 bits but we force issuing 4DWs TLP
                self.comb += [
                    tlp_req.address[:32].eq(Constant(0, 32)),
                    tlp_req.address[32:].eq(req_sink.adr[:32]),
                    If(req_sink.we,
                        tlp_req.fmt.eq(fmt_dict["mem_wr64"]),
                    ).Else(
                        tlp_req.fmt.eq(fmt_dict["mem_rd64"]),
                    ),
                ]

            self.comb += [
                tlp_req.tc.eq(0),
                tlp_req.td.eq(0),
                tlp_req.ep.eq(0),
                tlp_req.attr.eq(0),
                tlp_req.length.eq(req_sink.len),

                tlp_req.requester_id.eq(req_sink.req_id),
                tlp_req.tag.eq(req_sink.tag),
                If(req_sink.len > 1,
                    tlp_req.last_be.eq(0xf)
                ).Else(
                    tlp_req.last_be.eq(0x0)
                ),
                tlp_req.first_be.eq(0xf),
                tlp_req.dat.eq(req_sink.dat),
                If(req_sink.we,
                    If(req_sink.len == 1,
                        tlp_req.be.eq(0xf)
                    ).Else(
                        tlp_req.be.eq(2**(data_width//8)-1)
                    )
                ).Else(
                    tlp_req.be.eq(0x00)
                )
            ]

            tlp_raw_req        = stream.Endpoint(tlp_raw_layout(data_width))
            tlp_raw_req_header = Signal(len(tlp_raw_req.header))
            self.comb += [
                tlp_req.connect(tlp_raw_req, omit={*tlp_request_header_fields.keys()}),
                tlp_raw_req.fmt.eq(tlp_req.fmt),
                tlp_request_header.encode(tlp_req, tlp_raw_req_header),
            ]
            self.comb += dword_endianness_swap(
                src        = tlp_raw_req_header,
                dst        = tlp_raw_req.header,
                data_width = data_width,
                endianness = endianness,
                mode       = "dat",
                ndwords    = 4
            )

        # Format and Encode TLP Completions --------------------------------------------------------

        if "COMPLETION" in capabilities:
            self.tlp_cmp = tlp_cmp = stream.Endpoint(tlp_completion_layout(data_width))
            self.comb += [
                tlp_cmp.valid.eq(cmp_sink.valid),
                cmp_sink.ready.eq(tlp_cmp.ready),
                tlp_cmp.first.eq(cmp_sink.first),
                tlp_cmp.last.eq(cmp_sink.last),

                tlp_cmp.tc.eq(0),
                tlp_cmp.td.eq(0),
                tlp_cmp.ep.eq(0),
                tlp_cmp.attr.eq(0),
                tlp_cmp.length.eq(cmp_sink.len),

                tlp_cmp.completer_id.eq(cmp_sink.cmp_id),
                If(cmp_sink.err,
                    tlp_cmp.type.eq(type_dict["cpl"]),
                    tlp_cmp.fmt.eq( fmt_dict["cpl"]),
                    tlp_cmp.status.eq(cpl_dict["ur"])
                ).Else(
                    tlp_cmp.type.eq(type_dict["cpld"]),
                    tlp_cmp.fmt.eq( fmt_dict["cpld"]),
                    tlp_cmp.status.eq(cpl_dict["sc"])
                ),
                tlp_cmp.bcm.eq(0),
                tlp_cmp.byte_count.eq(cmp_sink.len*4),

                tlp_cmp.requester_id.eq(cmp_sink.req_id),
                tlp_cmp.tag.eq(cmp_sink.tag),
                tlp_cmp.lower_address.eq(cmp_sink.adr),

                tlp_cmp.dat.eq(cmp_sink.dat),
                If(cmp_sink.last & cmp_sink.first,
                    tlp_cmp.be.eq(0xf)
                ).Else(
                    tlp_cmp.be.eq(2**(data_width//8)-1)
                ),
            ]

            tlp_raw_cmp        = stream.Endpoint(tlp_raw_layout(data_width))
            tlp_raw_cmp_header = Signal(len(tlp_raw_cmp.header))
            self.comb += [
                tlp_cmp.connect(tlp_raw_cmp, omit={*tlp_completion_header_fields.keys()}),
                tlp_raw_cmp.fmt.eq(tlp_cmp.fmt),
                tlp_completion_header.encode(tlp_cmp, tlp_raw_cmp_header),
            ]
            self.comb += dword_endianness_swap(
                src        = tlp_raw_cmp_header,
                dst        = tlp_raw_cmp.header,
                data_width = data_width,
                endianness = endianness,
                mode       = "dat",
                ndwords    = 4
            )

        # Format and Encode TLP PTM ----------------------------------------------------------------

        if "PTM" in capabilities:
            self.tlp_ptm = tlp_ptm = stream.Endpoint(tlp_ptm_layout(data_width))
            self.comb += [
                tlp_ptm.valid.eq(ptm_sink.valid),
                ptm_sink.ready.eq(tlp_ptm.ready),
                tlp_ptm.first.eq(ptm_sink.first),
                tlp_ptm.last.eq(ptm_sink.last),

                tlp_ptm.tc.eq(0),
                tlp_ptm.ln.eq(0),
                tlp_ptm.th.eq(0),
                tlp_ptm.td.eq(0),
                tlp_ptm.ep.eq(0),
                tlp_ptm.attr.eq(0),
                tlp_ptm.length.eq(ptm_sink.length),

                tlp_ptm.requester_id.eq(ptm_sink.requester_id),
                tlp_ptm.message_code.eq(ptm_sink.message_code),
                tlp_ptm.master_time.eq(ptm_sink.master_time),

                If(ptm_sink.request,
                    tlp_ptm.type.eq(type_dict["ptm_req"]),
                    tlp_ptm.fmt.eq( fmt_dict["ptm_req"]),
                ),
                If(ptm_sink.response,
                    tlp_ptm.type.eq(type_dict["ptm_res"]),
                    tlp_ptm.fmt.eq( fmt_dict["ptm_res"]),
                    tlp_ptm.dat.eq(ptm_sink.dat),
                    tlp_ptm.be.eq(2**(data_width//8)-1), # CHECKME.
                ),
            ]

            tlp_raw_ptm        = stream.Endpoint(tlp_raw_layout(data_width))
            tlp_raw_ptm_header = Signal(len(tlp_raw_ptm.header))
            self.comb += [
                tlp_ptm.connect(tlp_raw_ptm, omit={*tlp_ptm_header_fields.keys()}),
                tlp_raw_ptm.fmt.eq(tlp_ptm.fmt),
                tlp_ptm_header.encode(tlp_ptm, tlp_raw_ptm_header),
            ]
            self.comb += dword_endianness_swap(
                src        = tlp_raw_ptm_header,
                dst        = tlp_raw_ptm.header,
                data_width = data_width,
                endianness = endianness,
                mode       = "dat",
                ndwords    = 4
            )


        # Format and Encode TLP Configuration ------------------------------------------------------

        if "CONFIGURATION" in capabilities:
            self.tlp_cfg = tlp_cfg = stream.Endpoint(tlp_configuration_layout(data_width))
            self.comb += [
                If(req_is_cfg,
                    tlp_cfg.valid.eq(req_sink.valid),
                    req_sink.ready.eq(tlp_cfg.ready)
                ),

                # first/last.
                tlp_cfg.first.eq(req_sink.first),
                tlp_cfg.last.eq(req_sink.last),

                # Common fields.
                tlp_cfg.tc.eq(0),
                tlp_cfg.td.eq(0),
                tlp_cfg.ep.eq(0),
                tlp_cfg.attr.eq(0),
                tlp_cfg.length.eq(1),   # CFG accesses are 1 DW.

                # Routing/identity.
                tlp_cfg.requester_id.eq(req_sink.req_id),
                tlp_cfg.tag.eq(req_sink.tag),

                # Byte enables.
                tlp_cfg.first_be.eq(0xf),
                tlp_cfg.last_be.eq(0x0),

                # Target BDF + register.
                tlp_cfg.bus_number.eq(req_sink.bus_number),
                tlp_cfg.device_no.eq(req_sink.device_no),
                tlp_cfg.func.eq(req_sink.func),
                tlp_cfg.ext_reg.eq(req_sink.ext_reg),
                tlp_cfg.register_no.eq(req_sink.register_no),

                # Data + BE policy.
                tlp_cfg.dat.eq(req_sink.dat),
                If(req_sink.we,
                    tlp_cfg.be.eq(0xf)
                ).Else(
                    tlp_cfg.be.eq(0x00)
                ),

                # CFG0.
                If(req_sink.we,
                    tlp_cfg.type.eq(type_dict["cfg_wr0"]),
                    tlp_cfg.fmt.eq(fmt_dict["cfg_wr0"]),
                ).Else(
                    tlp_cfg.type.eq(type_dict["cfg_rd0"]),
                    tlp_cfg.fmt.eq(fmt_dict["cfg_rd0"]),
                ),
            ]

            tlp_raw_conf        = stream.Endpoint(tlp_raw_layout(data_width))
            tlp_raw_conf_header = Signal(len(tlp_raw_conf.header))
            self.comb += [
                tlp_cfg.connect(tlp_raw_conf, omit={*tlp_configuration_header_fields.keys()}),
                tlp_raw_conf.fmt.eq(tlp_cfg.fmt),
                tlp_configuration_header.encode(tlp_cfg, tlp_raw_conf_header),
            ]
            self.comb += dword_endianness_swap(
                src        = tlp_raw_conf_header,
                dst        = tlp_raw_conf.header,
                data_width = data_width,
                endianness = endianness,
                mode       = "dat",
                ndwords    = 4
            )

        # Arbitrate --------------------------------------------------------------------------------

        tlp_raws = []
        if "REQUEST" in capabilities:
            tlp_raws.append(tlp_raw_req)
        if "COMPLETION" in capabilities:
            tlp_raws.append(tlp_raw_cmp)
        if "CONFIGURATION" in capabilities:
            tlp_raws.append(tlp_raw_conf)
        if "PTM" in capabilities:
            tlp_raws.append(tlp_raw_ptm)
        tlp_raw = stream.Endpoint(tlp_raw_layout(data_width))
        self.arbitrer = Arbiter(
            masters = tlp_raws,
            slave   = tlp_raw
        )

        # Buffer -----------------------------------------------------------------------------------

        tlp_raw_d   = stream.Endpoint(tlp_raw_layout(data_width))
        tlp_raw_buf = stream.Buffer(tlp_raw_layout(data_width))
        self.submodules += tlp_raw_buf
        self.comb += [
            tlp_raw.connect(tlp_raw_buf.sink),
            tlp_raw_buf.source.connect(tlp_raw_d),
        ]

        # Insert header ----------------------------------------------------------------------------
        header_inserter_cls = {
            64 : LitePCIeTLPHeaderInserter64b,
           128 : LitePCIeTLPHeaderInserter128b,
           256 : LitePCIeTLPHeaderInserter256b,
           512 : LitePCIeTLPHeaderInserter512b,
        }
        header_inserter = header_inserter_cls[data_width](fmt=tlp_raw_d.fmt)
        self.submodules += header_inserter
        self.comb += tlp_raw_d.connect(header_inserter.sink)
        self.comb += header_inserter.source.connect(self.source, omit={"data", "be"})
        for name in ["dat", "be"]:
            self.comb += dword_endianness_swap(
                src        = getattr(header_inserter.source, name),
                dst        = getattr(self.source, name),
                data_width = data_width,
                endianness = endianness,
                mode       = name,
            )

```

`setup.py`:

```py
#!/usr/bin/env python3

from setuptools import setup
from setuptools import find_packages


with open("README.md", "r", encoding="utf-8") as fp:
    long_description = fp.read()


setup(
    name                          = "litepcie",
    version = "2025.12",
    description                   = "Small footprint and configurable PCIe core",
    long_description              = long_description,
    long_description_content_type = "text/markdown",
    author                        = "Florent Kermarrec",
    author_email                  = "florent@enjoy-digital.fr",
    url                           = "http://enjoy-digital.fr",
    download_url                  = "https://github.com/enjoy-digital/litepcie",
    test_suite                    = "test",
    license                       = "BSD",
    python_requires               = "~=3.8",
    install_requires              = ["pyyaml", "litex"],
    extras_require                = {
        "develop": [
          "meson"
          "pexpect"
          "setuptools"
          "requests"
        ]
    },
    packages                      = find_packages(exclude=("test*", "sim*", "doc*", "examples*")),
    include_package_data          = True,
    keywords                      = "HDL ASIC FPGA hardware design",
    classifiers                   = [
        "Topic :: Scientific/Engineering :: Electronic Design Automation (EDA)",
        "Environment :: Console",
        "Development Status :: 3 - Alpha",
        "Intended Audience :: Developers",
        "License :: OSI Approved :: BSD License",
        "Operating System :: OS Independent",
        "Programming Language :: Python",
    ],
    entry_points = {
        "console_scripts": [
            "litepcie_gen=litepcie.gen:main",
        ],
    },
)

```

`test/common.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2015-2022 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause


def seed_to_data(seed, random=True):
    if random:
        return (seed * 0x31415979 + 1) & 0xffffffff
    else:
        return seed

```

`test/model/chipset.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2015-2024 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

import random

from litex.gen import *

from litepcie.common import *
from litepcie.tlp.common import *

from test.model.tlp import *

# Helpers ------------------------------------------------------------------------------------------

def print_chipset(s):
    print("[CHIPSET] {}".format(s))


def find_cmp_tags(queue):
    tags = []
    for tag, dwords in queue:
        if tag not in tags:
            tags.append(tag)
    return tags


def find_first_cmp_msg(queue, msg_tag):
    for i, (tag, dwords) in enumerate(queue):
        if tag == msg_tag:
            return i

# Chipset model ------------------------------------------------------------------------------------

class Chipset(LiteXModule):
    def __init__(self, phy, root_id, debug=False, with_reordering=False):
        self.phy     = phy
        self.root_id = root_id
        self.debug   = debug
        self.with_reordering = with_reordering

        # # #

        self.rd_data   = []
        self.cmp_queue = []
        self.en = False

    def set_host_callback(self, callback):
        self.host_callback = callback

    def enable(self):
        self.en = True

    def disable(self):
        self.en = False

    def wr(self, wr_cls, adr, data):
        wr = wr_cls()
        wr.fmt          = 0b10 if isinstance(wr, WR32) else 0b11
        wr.type         = 0b00000
        wr.length       = len(data)
        wr.first_be     = 0xf
        wr.address      = (adr << 2)
        wr.requester_id = self.root_id
        dwords = wr.encode_dwords(data)
        if self.debug:
            print_chipset(">>>>>>>>")
            print_chipset(parse_dwords(dwords))
        yield from self.phy.send_blocking(dwords)

    def wr32(self, adr, data):
        return self.wr(wr_cls=WR32, adr=adr, data=data)

    def wr64(self, adr, data):
        return self.wr(wr_cls=WR64, adr=adr, data=data)

    def rd(self, rd_cls, adr, length=1):
        rd = rd_cls()
        rd.fmt          = 0b00 if isinstance(rd, RD32) else 0b01
        rd.type         = 0b00000
        rd.length       = length
        rd.first_be     = 0xf
        rd.address      = (adr << 2)
        rd.requester_id = self.root_id
        dwords = rd.encode_dwords()
        if self.debug:
            print_chipset(">>>>>>>>")
            print_chipset(parse_dwords(dwords))
        yield from self.phy.send_blocking(dwords)
        dwords = None
        while dwords is None:
            dwords = self.phy.receive()
            yield
        cpld = CPLD(dwords)
        self.rd_data = cpld.data
        if self.debug:
            print_chipset("<<<<<<<<")
            print_chipset(cpld)

    def rd32(self, adr, length=1):
        return self.rd(rd_cls=RD32, adr=adr, length=length)

    def rd64(self, adr, length=1):
        return self.rd(rd_cls=RD64, adr=adr, length=length)

    def cmp(self, req_id, data, byte_count=None, lower_address=0, tag=0, with_split=False):
        if with_split:
            d = random.choice([64, 128, 256])
            n = byte_count//d
            if n == 0:
                self.cmp(req_id, data, byte_count=byte_count, tag=tag)
            else:
                for i in range(n):
                    cmp_data = data[i*byte_count//(4*n):(i+1)*byte_count//(4*n)]
                    self.cmp(req_id, cmp_data,
                        byte_count=byte_count-i*byte_count//n, tag=tag)
        else:
            if len(data) == 0:
                fmt = 0b00
                cpl = CPL()
            else:
                fmt = 0b10
                cpl = CPLD()
            cpl.fmt           = fmt
            cpl.type          = 0b01010
            cpl.length        = len(data)
            cpl.lower_address = lower_address
            cpl.requester_id  = req_id
            cpl.completer_id  = self.root_id
            if byte_count is None:
                cpl.byte_count = len(data)*4
            else:
                cpl.byte_count = byte_count
            cpl.tag = tag
            if len(data) == 0:
                dwords = cpl.encode_dwords()
            else:
                dwords = cpl.encode_dwords(data)
            self.cmp_queue.append((tag, dwords))

    def cmp_callback(self):
        if len(self.cmp_queue):
            if self.with_reordering:
                tags = find_cmp_tags(self.cmp_queue)
                tag  = random.choice(tags)
                n    = find_first_cmp_msg(self.cmp_queue, tag)
                tag, dwords = self.cmp_queue.pop(n)
            else:
                tag, dwords = self.cmp_queue.pop(0)
            if self.debug:
                print_chipset(">>>>>>>>")
                print_chipset(parse_dwords(dwords))
            self.phy.send(dwords)

    @passive
    def generator(self):
        while True:
            if self.en:
                dwords = self.phy.receive()
                if dwords is not None:
                    msg = parse_dwords(dwords)
                    if self.debug:
                        print_chipset("<<<<<<<< (Callback)")
                        print_chipset(msg)
                    self.host_callback(msg)
                self.cmp_callback()
            yield

```

`test/model/host.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2015-2024 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

from litex.gen import *

from litepcie.common import *
from litepcie.tlp.common import *

from test.model.phy import PHY
from test.model.tlp import *
from test.model.chipset import Chipset

# Helpers ------------------------------------------------------------------------------------------

def print_host(s):
    print("[HOST] {}".format(s))


# Host model ---------------------------------------------------------------------------------------

class Host(LiteXModule):
    def __init__(self, data_width, root_id, endpoint_id,
        bar0_size          = 1*MB,
        phy_debug          = False,
        chipset_debug      = False,
        chipset_split      = False,
        chipset_reordering = False,
        host_debug         = False):
        self.debug         = host_debug
        self.chipset_split = chipset_split

        # # #

        self.phy     = PHY(data_width, endpoint_id, bar0_size, phy_debug)
        self.chipset = Chipset(self.phy, root_id, chipset_debug, chipset_reordering)
        self.chipset.set_host_callback(self.callback)

        self.rd_queue = []

    def malloc(self, base, length):
        self.base   = base
        self.buffer = [0]*(length//4)

    def write_mem(self, adr, data):
        if self.debug:
            print_host("Writing {} bytes @0x{:08x}".format(len(data)*4, adr))
        current_adr = (adr-self.base)//4
        for i in range(len(data)):
            self.buffer[current_adr+i] = data[i]

    def read_mem(self, adr, length=1):
        if self.debug:
            print_host("Reading {} bytes @0x{:08x}".format(length, adr))
        current_adr = (adr-self.base)//4
        data        = []
        for i in range(length//4):
            data.append(self.buffer[current_adr+i])
        return data

    def callback(self, msg):
        if isinstance(msg, WR32):
            self.write_mem(msg.address, msg.data)
        elif isinstance(msg, RD32):
            self.rd_queue.append(msg)
        elif isinstance(msg, WR64):
            self.write_mem(msg.address, msg.data)
        elif isinstance(msg, RD64):
            self.rd_queue.append(msg)

    @passive
    def generator(self):
        while True:
            if len(self.rd_queue):
                msg     = self.rd_queue.pop(0)
                address = msg.address
                length  = msg.length*4
                data    = self.read_mem(address, length)
                self.chipset.cmp(msg.requester_id, data,
                    byte_count = length,
                    tag        = msg.tag,
                    with_split = self.chipset_split
                )
            yield

```

`test/model/phy.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2015-2024 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

import math

from litex.gen import *

from litepcie.common import *
from litepcie.tlp.common import *

# Helpers ------------------------------------------------------------------------------------------

def print_phy(s):
    print("[PHY] {}".format(s))

# PHY Packet model ---------------------------------------------------------------------------------

class PHYPacket:
    def __init__(self, dat=[], be=[]):
        self.dat   = dat
        self.be    = be
        self.start = 1
        self.done  = 0

# PHY Source model ---------------------------------------------------------------------------------

class PHYSource(LiteXModule):
    def __init__(self, data_width):
        self.source = stream.Endpoint(phy_layout(data_width))

        # # #

        self.packets = []
        self.packet  = PHYPacket()
        self.packet.done = 1

    def send(self, packet):
        self.packets.append(packet)

    def send_blocking(self, packet):
        self.send(packet)
        while packet.done == 0:
            yield

    @passive
    def generator(self):
        while True:
            if len(self.packets) and self.packet.done:
                self.packet = self.packets.pop(0)
            if self.packet.start and not self.packet.done:
                yield self.source.valid.eq(1)
                yield self.source.last.eq(len(self.packet.dat) == 1)
                yield self.source.dat.eq(self.packet.dat.pop(0))
                yield self.source.be.eq(self.packet.be.pop(0))
                self.packet.start = 0
            elif ((yield self.source.valid) == 1 and
                  (yield self.source.ready) == 1):
                yield self.source.last.eq(len(self.packet.dat) == 1)
                if len(self.packet.dat) > 0:
                    yield self.source.valid.eq(1)
                    yield self.source.dat.eq(self.packet.dat.pop(0))
                    yield self.source.be.eq(self.packet.be.pop(0))
                else:
                    self.packet.done = 1
                    yield self.source.valid.eq(0)
            yield

# PHY Sink model -----------------------------------------------------------------------------------

class PHYSink(Module):
    def __init__(self, data_width):
        self.sink = stream.Endpoint(phy_layout(data_width))

        # # #

        self.packet = PHYPacket()
        self.first  = True

    def receive(self):
        self.packet.done = 0
        while self.packet.done == 0:
            yield

    @passive
    def generator(self):
        while True:
            self.packet.done = 0
            yield self.sink.ready.eq(1)
            if (yield self.sink.valid) == 1 and self.first:
                self.packet.start = 1
                self.packet.dat = [(yield self.sink.dat)]
                self.packet.be = [(yield self.sink.be)]
                self.first = False
            elif (yield self.sink.valid):
                self.packet.start = 0
                self.packet.dat.append((yield self.sink.dat))
                self.packet.be.append((yield self.sink.be))
            if (yield self.sink.valid) == 1 and (yield self.sink.last) == 1:
                self.packet.done = 1
                self.first = True
            yield

# PHY Layer model ----------------------------------------------------------------------------------

class PHY(LiteXModule):
    def __init__(self, data_width, id, bar0_size, debug):
        self.data_width = data_width

        self.id = id

        self.bar0_size = bar0_size
        self.bar0_mask = get_bar_mask(bar0_size)

        self.max_request_size = Signal(10, reset=512)
        self.max_payload_size = Signal(8,  reset=128)

        self.phy_source = PHYSource(data_width)
        self.phy_sink   = PHYSink(data_width)

        self.source = self.phy_source.source
        self.sink   = self.phy_sink.sink

    def dwords2packet(self, dwords):
            ratio  = self.data_width//32
            length = math.ceil(len(dwords)/ratio)
            dat    = [0]*length
            be     = [0]*length
            for n in range(length):
                for i in reversed(range(ratio)):
                    dat[n] = dat[n] << 32
                    be[n]  = be[n] << 4
                    try:
                        dat[n] |= dwords[2*n+i]
                        be[n]  |= 0xF
                    except:
                        pass
            return dat, be

    def send(self, dwords):
        dat, be = self.dwords2packet(dwords)
        packet  = PHYPacket(dat, be)
        self.phy_source.send(packet)

    def send_blocking(self, dwords):
        dat, be = self.dwords2packet(dwords)
        packet  = PHYPacket(dat, be)
        yield from self.phy_source.send_blocking(packet)

    def packet2dwords(self, p_dat, p_be):
            ratio  = self.data_width//32
            dwords = []
            for dat, be in zip(p_dat, p_be):
                for i in range(ratio):
                    dword_be  = (be >> (4*i)) & 0xf
                    dword_dat = (dat >> (32*i)) & 0xffffffff
                    if dword_be == 0xf:
                        dwords.append(dword_dat)
            return dwords

    def receive(self):
        if self.phy_sink.packet.done:
            self.phy_sink.packet.done = 0
            return self.packet2dwords(self.phy_sink.packet.dat, self.phy_sink.packet.be)
        else:
            return None


```

`test/model/tlp.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2015-2024 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

from litepcie.common import *
from litepcie.tlp.common import *


# Helpers/Definitions ------------------------------------------------------------------------------

def get_field_data(field, dwords):
    return (dwords[field.byte//4] >> field.offset) & (2**field.width-1)

tlp_headers_dict = {
    "RD32": tlp_request_header,
    "WR32": tlp_request_header,
    "RD64": tlp_request_header,
    "WR64": tlp_request_header,
    "CPLD": tlp_completion_header,
    "CPL":  tlp_completion_header
}

# TLP Layer model ----------------------------------------------------------------------------------

class TLP:
    def __init__(self, name, dwords, header_dwords=3):
        assert header_dwords in [3, 4]
        self.name   = name
        self.header = dwords[:header_dwords]
        self.data   = dwords[header_dwords:]
        self.dwords = self.header + self.data
        self.header_dwords = header_dwords
        self.decode_dwords()

    def decode_dwords(self):
        for k, v in tlp_headers_dict[self.name].fields.items():
            setattr(self, k, get_field_data(v, self.header))

    def encode_dwords(self, data=[]):
        self.header = [0]*self.header_dwords
        for k, v in tlp_headers_dict[self.name].fields.items():
            field = tlp_headers_dict[self.name].fields[k]
            self.header[field.byte//4] |= (getattr(self, k) << field.offset)
        self.data   = data
        self.dwords = self.header + self.data
        return self.dwords

    def __repr__(self):
        r = self.name + "\n"
        r += "--------\n"
        for k in sorted(tlp_headers_dict[self.name].fields.keys()):
            r += k + " : 0x{:x}".format(getattr(self, k)) + "\n"
        if len(self.data) != 0:
            r += "data:\n"
            for d in self.data:
                r += "{:08x}\n".format(d)
        return r

# RD32 ---------------------------------------------------------------------------------------------

class RD32(TLP):
    def __init__(self, dwords=[0, 0, 0]):
        TLP.__init__(self, "RD32", dwords)

# WR32 ---------------------------------------------------------------------------------------------

class WR32(TLP):
    def __init__(self, dwords=[0, 0, 0]):
        TLP.__init__(self, "WR32", dwords)

# RD64 ---------------------------------------------------------------------------------------------

class RD64(TLP):
    def __init__(self, dwords=[0, 0, 0, 0]):
        _dwords = [d for d in dwords]
        _dwords[2] = dwords[3] # FIXME: Swap Address LSB/MSB.
        _dwords[3] = dwords[2] # FIXME: Swap Address LSB/MSB.
        TLP.__init__(self, "RD64", _dwords, header_dwords=4)

# WR64 ---------------------------------------------------------------------------------------------

class WR64(TLP):
    def __init__(self, dwords=[0, 0, 0, 0]):
        _dwords = [d for d in dwords]
        _dwords[2] = dwords[3] # FIXME: Swap Address LSB/MSB.
        _dwords[3] = dwords[2] # FIXME: Swap Address LSB/MSB.
        TLP.__init__(self, "WR64", _dwords, header_dwords=4)

# CPLD ---------------------------------------------------------------------------------------------

class CPLD(TLP):
    def __init__(self, dwords=[0, 0, 0]):
        TLP.__init__(self, "CPLD", dwords)

# CPL ----------------------------------------------------------------------------------------------

class CPL(TLP):
    def __init__(self, dwords=[0, 0, 0]):
        TLP.__init__(self, "CPL", dwords)

# Unknown ------------------------------------------------------------------------------------------

class Unknown:
    def __repr__(self):
        r = "UNKNOWN\n"
        return r

# --------------------------------------------------------------------------------------------------

fmt_type_dict = {
    fmt_type_dict["mem_rd32"]: (RD32, 3),
    fmt_type_dict["mem_wr32"]: (WR32, 4),
    fmt_type_dict["mem_rd64"]: (RD64, 4),
    fmt_type_dict["mem_wr64"]: (WR64, 5),
    fmt_type_dict["cpld"]:     (CPLD, 4),
    fmt_type_dict["cpl"]:      ( CPL, 3),
}


def parse_dwords(dwords):
    f = get_field_data(tlp_common_header.fields["fmt"], dwords)
    t = get_field_data(tlp_common_header.fields["type"], dwords)
    fmt_type = (f << 5) | t
    try:
        tlp, min_len = fmt_type_dict[fmt_type]
        if len(dwords) >= min_len:
            return tlp(dwords)
        else:
            return Unknown()
    except:
        return Unknown()

```

`test/test_axis_adapter_cross_width_properties.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2026 Enjoy-Digital <enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

import unittest

from litex.gen import *

from litepcie.phy.axis_adapters import MAxisCQAdapter, MAxisRCAdapter, SAxisRQAdapter


def _rq_run_single(width, data, tkeep, tuser):
    dut = SAxisRQAdapter(width)
    beats = []

    @passive
    def monitor():
        for _ in range(10):
            if (yield dut.m_axis_tvalid):
                beats.append({
                    "data": (yield dut.m_axis_tdata),
                    "user": (yield dut.m_axis_tuser),
                    "last": (yield dut.m_axis_tlast),
                })
            yield

    def stim():
        yield dut.m_axis_tready.eq(1)
        yield
        yield dut.s_axis_tvalid.eq(1)
        yield dut.s_axis_tlast.eq(1)
        yield dut.s_axis_tdata.eq(data)
        yield dut.s_axis_tkeep.eq(tkeep)
        yield dut.s_axis_tuser.eq(tuser)
        yield
        yield dut.s_axis_tvalid.eq(0)
        yield

    run_simulation(dut, [stim(), monitor()], vcd_name=None)
    return beats


def _cq_run_packet(width, data0, data1, user0, user1):
    dut = MAxisCQAdapter(width)
    beats = []

    @passive
    def monitor():
        for _ in range(16):
            if (yield dut.m_axis_tvalid):
                beats.append({
                    "data": (yield dut.m_axis_tdata),
                    "user": (yield dut.m_axis_tuser),
                    "last": (yield dut.m_axis_tlast),
                })
            yield

    def stim():
        yield dut.m_axis_tready.eq(1)
        yield
        yield dut.s_axis_tvalid.eq(1)
        yield dut.s_axis_tlast.eq(0)
        yield dut.s_axis_tdata.eq(data0)
        yield dut.s_axis_tuser.eq(user0)
        yield dut.s_axis_tkeep.eq(0)
        yield
        yield dut.s_axis_tvalid.eq(1)
        yield dut.s_axis_tlast.eq(1)
        yield dut.s_axis_tdata.eq(data1)
        yield dut.s_axis_tuser.eq(user1)
        yield dut.s_axis_tkeep.eq(0)
        yield
        yield dut.s_axis_tvalid.eq(0)
        yield

    run_simulation(dut, [stim(), monitor()], vcd_name=None)
    return beats


def _rc_run_packet(width, data0, data1, user0, user1):
    dut = MAxisRCAdapter(width)
    beats = []

    @passive
    def monitor():
        for _ in range(16):
            if (yield dut.m_axis_tvalid):
                beats.append({
                    "data": (yield dut.m_axis_tdata),
                    "user": (yield dut.m_axis_tuser),
                    "last": (yield dut.m_axis_tlast),
                    "sop": (yield dut.m_axis_sop),
                })
            yield

    def stim():
        yield dut.m_axis_tready.eq(1)
        yield
        yield dut.s_axis_tvalid.eq(1)
        yield dut.s_axis_tlast.eq(0)
        yield dut.s_axis_tdata.eq(data0)
        yield dut.s_axis_tuser.eq(user0)
        yield dut.s_axis_tkeep.eq(0)
        yield
        yield dut.s_axis_tvalid.eq(1)
        yield dut.s_axis_tlast.eq(1)
        yield dut.s_axis_tdata.eq(data1)
        yield dut.s_axis_tuser.eq(user1)
        yield dut.s_axis_tkeep.eq(0)
        yield
        yield dut.s_axis_tvalid.eq(0)
        yield

    run_simulation(dut, [stim(), monitor()], vcd_name=None)
    return beats


def _decode_cq_reqtype(fmt, typ):
    inv = {
        (0b000, 0b00000): 0b0000,
        (0b000, 0b00001): 0b0111,
        (0b010, 0b00000): 0b0001,
        (0b000, 0b00010): 0b0010,
        (0b010, 0b00010): 0b0011,
        (0b000, 0b00100): 0b1000,
        (0b010, 0b00100): 0b1010,
        (0b000, 0b00101): 0b1001,
        (0b010, 0b00101): 0b1011,
    }
    return inv[(fmt, typ)]


class TestAxisAdapterCrossWidthProperties(unittest.TestCase):
    def test_s_axis_rq_cross_width_invariants(self):
        # One logical memory-read request payload, same intent across widths.
        firstbe = 0x5
        lastbe = 0xA
        tuser = 0b0011  # ecrc/poison sideband contributions.

        ref = None
        for width in [128, 256, 512]:
            data = int("0123456789abcdeffedcba9876543210" * (width // 128), 16)
            data &= ~0x3FF
            data |= 0x11
            data &= ~(0xFF << 24)  # reqtype class -> mem read (0000)
            data &= ~((0xFF) << 32)
            data |= (firstbe << 32) | (lastbe << 36)
            tkeep = (1 << (width // 8)) - 1

            out = _rq_run_single(width=width, data=data, tkeep=tkeep, tuser=tuser)
            self.assertGreaterEqual(len(out), 1)
            self.assertEqual(out[0]["last"], 1)

            header = (out[0]["data"] >> 64) & ((1 << 64) - 1)
            reqtype = (header >> 11) & 0xF

            if width in [128, 256]:
                out_firstbe = out[0]["user"] & 0xF
                out_lastbe = (out[0]["user"] >> 4) & 0xF
            else:
                out_firstbe = out[0]["user"] & 0xF
                out_lastbe = (out[0]["user"] >> 8) & 0xF

            norm = {
                "header": header,
                "reqtype": reqtype,
                "firstbe": out_firstbe,
                "lastbe": out_lastbe,
            }
            if ref is None:
                ref = norm
            self.assertEqual(norm, ref)
            self.assertEqual(reqtype, 0b0000)
            self.assertEqual(out_firstbe, firstbe)
            self.assertEqual(out_lastbe, lastbe)

    def test_m_axis_cq_cross_width_invariants(self):
        # One logical memory-write request as seen on CQ.
        reqtype_in = 0b0011
        firstbe = 0x9
        lastbe = 0x6
        be_byte = (lastbe << 4) | firstbe
        barhit_expected = (0 << 7) | (0b101 << 4) | reqtype_in

        ref = None
        for width in [128, 256, 512]:
            data0 = int("00112233445566778899aabbccddeeff" * (width // 128), 16)
            data1 = int("ffeeddccbbaa99887766554433221100" * (width // 128), 16)

            hdr = 0
            hdr |= 0x2A              # dwlen
            hdr |= 0b01 << 60        # attr
            hdr |= 0b101 << 57       # tc
            hdr |= 0xAB << 32        # tag
            hdr |= 0xCDEF << 16      # requesterid
            hdr |= reqtype_in << 11  # reqtype
            hdr |= 0b101 << 48       # bar
            data0 &= ~(((1 << 64) - 1) << 64)
            data0 |= hdr << 64

            if width == 512:
                user0 = (firstbe & 0xF) | ((lastbe & 0xF) << 8)
                user1 = 1 << 96
            else:
                user0 = be_byte
                user1 = 1 << 41

            out = _cq_run_packet(width=width, data0=data0, data1=data1, user0=user0, user1=user1)
            self.assertGreaterEqual(len(out), 1)

            header = out[0]["data"] & ((1 << 64) - 1)
            fmt = (header >> 29) & 0x7
            typ = (header >> 24) & 0x1F
            reqtype = _decode_cq_reqtype(fmt, typ)
            be = (header >> 32) & 0xFF
            barhit = (out[0]["user"] >> 2) & 0xFF

            norm = {
                "header": header,
                "reqtype": reqtype,
                "barhit": barhit,
                "firstbe": be & 0xF,
                "lastbe": (be >> 4) & 0xF,
            }
            if ref is None:
                ref = norm
            self.assertEqual(norm, ref)
            self.assertEqual(reqtype, reqtype_in)
            self.assertEqual(barhit, barhit_expected)
            self.assertEqual(be, be_byte)

    def test_m_axis_rc_cross_width_invariants(self):
        # One logical RC completion packet over two beats.
        # Keep bytecnt!=0 and bcm=0 so fmt/type are deterministic.
        ecrc = 1
        poison = 1

        ref = None
        for width in [128, 256, 512]:
            data0 = int("123456789abcdef0fedcba9876543210" * (width // 128), 16)
            data1 = int("0f1e2d3c4b5a69788796a5b4c3d2e1f0" * (width // 128), 16)
            user0 = (ecrc << 42) & ((1 << 85) - 1)
            user1 = 0  # second-beat ECRC source.

            # Program RC header source fields (in incoming RC stream layout).
            data0 &= ~((0x3FF) << 32)
            data0 |= 0x155 << 32      # dwlen
            data0 &= ~((0x3) << 92)
            data0 |= 0b10 << 92       # attr
            data0 &= ~((0x7) << 89)
            data0 |= 0b101 << 89      # tc
            data0 &= ~((0xFFF) << 16)
            data0 |= 0x2A5 << 16      # bytecnt
            data0 &= ~((0x7) << 43)
            data0 |= 0b011 << 43      # cmpstatus
            data0 &= ~((0xFFFF) << 72)
            data0 |= 0x4567 << 72     # completerid
            data0 &= ~((0x7F) << 0)
            data0 |= 0x35             # lowaddr
            data0 &= ~((0xFF) << 64)
            data0 |= 0xAB << 64       # tag
            data0 &= ~((0xFFFF) << 48)
            data0 |= 0xCDEF << 48     # requesterid
            data0 &= ~(1 << 29)       # bcm=0 path
            data0 &= ~(1 << 46)
            data0 |= poison << 46

            out = _rc_run_packet(width=width, data0=data0, data1=data1, user0=user0, user1=user1)
            self.assertEqual(len(out), 2)
            self.assertEqual(out[0]["sop"], 1)
            self.assertEqual(out[1]["sop"], 0)
            self.assertEqual(out[0]["last"], 0)
            self.assertEqual(out[1]["last"], 1)

            header0 = out[0]["data"] & ((1 << 64) - 1)
            header1 = (out[0]["data"] >> 64) & ((1 << 64) - 1)
            typ = (header0 >> 24) & 0x1F
            fmt = (header0 >> 29) & 0x7
            user_first = out[0]["user"] & 0x3
            user_second = out[1]["user"] & 0x3

            norm = {
                "header0": header0,
                "header1": header1,
                "fmt": fmt,
                "typ": typ,
                "user_first": user_first,
                "user_second": user_second,
            }
            if ref is None:
                ref = norm
            self.assertEqual(norm, ref)
            self.assertEqual((fmt, typ), (0b010, 0b01010))
            self.assertEqual(user_first, (ecrc << 0) | (poison << 1))
            self.assertEqual(user_second, (0 << 0) | (poison << 1))

```

`test/test_dma.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2015-2024 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

# In this high level test, LitePCIeEndpoint is connected to LitePCIeDMAReader and LitePCIeDMAWriter
# frontends with Reader's source connected to Writer's sink. Our Host model is used to emulate a Host
# memory with the Reader and Writer are reading/writing data from/to this memory.
#
#                                       ┌───────────┐
#                                       │           │
#                                       │   HOST    │
#                                       │  (Model)  │
#                                       │           │
#                                       └─┬───────▲─┘
#                                         │       │
#                                   ┌─────▼───────┴─────┐
#                                   │                   │
#                                   │                   │
#                                ┌──►  LitePCIeEndpoint ├─┐
#                                │  │                   │ │
#                                │  │                   │ │
#                                │  └───────────────────┘ │
#                                │                        │
#                       ┌────────┴──────────┐   ┌─────────▼─────────┐
#                       │                   │   │                   │
#                       │ LitePCIeDMAWriter │   │ LitePCIeDMAReader │
#                       │                   │   │                   │
#                       └────────▲──────────┘   └─────────┬─────────┘
#                                │                        │
#                                │                        │
#                                └────────────────────────┘
#
# The Host memory  is initially filled with random data, that are read by the Reader, re-directed
# to the Writer and then re-written in another memory location of the Host. The test then checks
# that the initial data and re-written data are identical.

import unittest

from litex.gen import *

from litepcie.common import *
from litepcie.core import LitePCIeEndpoint
from litepcie.core.msi import LitePCIeMSI
from litepcie.frontend.dma import LitePCIeDMAWriter, LitePCIeDMAReader

from test.common import seed_to_data
from test.model.host import *

# Parameters ---------------------------------------------------------------------------------------

root_id     = 0x100
endpoint_id = 0x400

# DMA Driver ---------------------------------------------------------------------------------------

class DMADriver:
    """DMA Driver model

    Provides methods to control/program LitePCIeDMAReader/LitePCIeDMAWriter.
    """
    def __init__(self, dma, dut):
        self.dma = getattr(dut, dma)
        self.dut = dut

    def set_prog_mode(self):
        yield from self.dma.table.loop_prog_n.write(0)

    def set_loop_mode(self):
        yield from self.dma.table.loop_prog_n.write(1)

    def flush(self):
        yield from self.dma.table.reset.write(1)

    def program_descriptor(self, address, length):
        address_lsb = (address >>  0) & 0xffff_ffff
        address_msb = (address >> 32) & 0xffff_ffff
        value = address_lsb
        value |= (length << 32)
        yield from self.dma.table.value.write(value)
        yield from self.dma.table.we.write(address_msb)

    def enable(self):
        yield from self.dma._enable.write(1)

    def disable(self):
        yield from self.dma._enable.write(0)

# MSI Handler --------------------------------------------------------------------------------------

DMA_READER_IRQ = 1
DMA_WRITER_IRQ = 2

class MSIHandler(LiteXModule):
    """MSI Handled model

    Handles the MSI IRQs generated by LitePCIeDMAReader/LitePCIeDMAWriter.
    """
    def __init__(self, debug=False):
        self.debug = debug
        self.sink  = stream.Endpoint(msi_layout())

        self.dma_reader_irq_count = 0
        self.dma_writer_irq_count = 0

    def clear_dma_reader_irq_count(self):
        self.dma_reader_irq_count = 0

    def clear_dma_writer_irq_count(self):
        self.dma_writer_irq_count = 0

    @passive
    def generator(self, dut):
        while True:
            yield self.sink.ready.eq(1)
            if (yield self.sink.valid):
                # Get IRQs.
                irq_vector = (yield dut.msi.vector.status)
                irq_clear  = 0

                # Handle IRQs.
                if irq_vector & DMA_READER_IRQ:
                    self.dma_reader_irq_count += 1
                    if self.debug:
                        print("[MSI] dma_reader_irq (n: {:d})".format(self.dma_reader_irq_count))
                    irq_clear |= DMA_READER_IRQ

                if irq_vector & DMA_WRITER_IRQ:
                    self.dma_writer_irq_count += 1
                    if self.debug:
                        print("[MSI] dma_writer_irq (n: {:d})".format(self.dma_writer_irq_count))
                    irq_clear |= DMA_WRITER_IRQ
                # Clear IRQs.
                yield from dut.msi.clear.write((yield from dut.msi.clear.read()) | irq_clear)
            yield

# Test DMA -----------------------------------------------------------------------------------------

class TestDMA(unittest.TestCase):
    def dma_test(self, data_width, address_width, test_size=1024):
        host_data     = [seed_to_data(i, True) for i in range(test_size//4)]
        loopback_data = []

        def main_generator(dut, nreads=8, nwrites=8):
            # Allocate Host's Memory.
            dut.host.malloc(0x00000000, test_size*2)

            # Enable Chipset
            dut.host.chipset.enable()

            # Fill initial Host's Memory.
            dut.host.write_mem(0x00000000, host_data)

            # DMA Reader/Writer control models.
            dma_reader_driver = DMADriver("dma_reader", dut)
            dma_writer_driver = DMADriver("dma_writer", dut)

            # Program DMA Reader descriptors.
            yield from dma_reader_driver.set_prog_mode()
            yield from dma_reader_driver.flush()
            for i in range(nreads):
                yield from dma_reader_driver.program_descriptor((test_size//8)*i, test_size//8)

            # Program DMA Writer descriptors.
            yield from dma_writer_driver.set_prog_mode()
            yield from dma_writer_driver.flush()
            for i in range(nwrites):
                yield from dma_writer_driver.program_descriptor(test_size + (test_size//8)*i, test_size//8)

            # Enable MSI.
            yield dut.msi.enable.storage.eq(DMA_READER_IRQ | DMA_WRITER_IRQ)

            # Enable DMA Reader & Writer.
            yield from dma_reader_driver.enable()
            yield from dma_writer_driver.enable()

            # Wait for all writes.
            while dut.msi_handler.dma_writer_irq_count != nwrites:
                yield

            # Delay to ensure all the data has been written.
            for i in range(1024):
                yield

            for data in dut.host.read_mem(test_size, test_size):
                loopback_data.append(data)


        class DUT(LiteXModule):
            def __init__(self, data_width, address_width):
                self.data_width    = data_width
                self.address_width = address_width

                # Host -----------------------------------------------------------------------------
                self.host = Host(data_width, root_id, endpoint_id,
                    phy_debug          = False,
                    chipset_debug      = False,
                    chipset_split      = True,
                    chipset_reordering = True,
                    host_debug         = True)

                # Endpoint -------------------------------------------------------------------------
                self.endpoint = LitePCIeEndpoint(self.host.phy,
                    address_width        = address_width,
                    max_pending_requests = 8
                )

                # DMA Reader/Writer ----------------------------------------------------------------
                dma_reader_port = self.endpoint.crossbar.get_master_port(read_only=True)
                dma_writer_port = self.endpoint.crossbar.get_master_port(write_only=True)
                self.dma_reader = LitePCIeDMAReader(self.endpoint, dma_reader_port, address_width=address_width)
                self.dma_writer = LitePCIeDMAWriter(self.endpoint, dma_writer_port, address_width=address_width)
                self.comb += self.dma_reader.source.connect(self.dma_writer.sink)

                # MSI ------------------------------------------------------------------------------
                self.msi = LitePCIeMSI(2)
                self.comb += [
                    self.msi.irqs[log2_int(DMA_READER_IRQ)].eq(self.dma_reader.irq),
                    self.msi.irqs[log2_int(DMA_WRITER_IRQ)].eq(self.dma_writer.irq)
                ]
                self.msi_handler = MSIHandler(debug=False)
                self.comb += self.msi.source.connect(self.msi_handler.sink)

        dut = DUT(data_width, address_width)
        generators = {
            "sys" : [
                main_generator(dut),
                dut.msi_handler.generator(dut),
                dut.host.generator(),
                dut.host.chipset.generator(),
                dut.host.phy.phy_sink.generator(),
                dut.host.phy.phy_source.generator()
            ]
        }
        clocks = {"sys": 10}
        run_simulation(dut, generators, clocks, vcd_name="test_dma.vcd")
        self.assertEqual(host_data, loopback_data)

    def test_dma_64b_data_width_32b_address_width(self):
        self.dma_test(data_width=64, address_width=32)

    def test_dma_64b_data_width_64b_address_width(self):
        self.dma_test(data_width=64, address_width=64)
```

`test/test_examples.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2019-2022 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

import unittest
import os

# Test Examples ------------------------------------------------------------------------------------

class TestExamples(unittest.TestCase):
    def target_test(self, target):
        os.system("rm -rf bench/build")
        os.system("cd bench && python3 {}.py".format(target))
        self.assertEqual(os.path.isfile("bench/build/{}/gateware/{}.v".format(target, target)), True)
        self.assertEqual(os.path.isfile("bench/build/{}/software/include/generated/csr.h".format(target)), True)
        self.assertEqual(os.path.isfile("bench/build/{}/software/include/generated/soc.h".format(target)), True)
        self.assertEqual(os.path.isfile("bench/build/{}/software/include/generated/mem.h".format(target)), True)

    def test_kc705_target(self):
        self.target_test("kc705")

    def test_kcu105_target(self):
        self.target_test("kcu105")

    def test_fk33_target(self):
        self.target_test("fk33")

    def test_xcu1525_target(self):
        self.target_test("xcu1525")

    def gen_test(self, name):
        os.system("rm -rf examples/build")
        os.system("cd examples && python3 ../litepcie/gen.py {}.yml".format(name))
        errors = not os.path.isfile("examples/build/gateware/litepcie_core.v")
        os.system("rm -rf examples/build")
        return errors

    def test_ac701_gen(self):
        errors = self.gen_test("ac701")
        self.assertEqual(errors, 0)

```

`test/test_m_axis_cq_adapter.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2026 Enjoy-Digital <enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

import unittest
import random

from litex.gen import *

from litepcie.phy.axis_adapters import MAxisCQAdapter


def _field(value, msb, lsb):
    return (value >> lsb) & ((1 << (msb - lsb + 1)) - 1)


def _cq_fmt_type(reqtype):
    mapping = {
        0b0000: (0b000, 0b00000),
        0b0111: (0b000, 0b00001),
        0b0001: (0b010, 0b00000),
        0b0010: (0b000, 0b00010),
        0b0011: (0b010, 0b00010),
        0b1000: (0b000, 0b00100),
        0b1010: (0b010, 0b00100),
        0b1001: (0b000, 0b00101),
        0b1011: (0b010, 0b00101),
    }
    return mapping.get(reqtype, (0, 0))


def _cq_header(data0, be):
    hdr = _field(data0, 127, 64)
    dwlen = _field(hdr, 9, 0)
    attr = _field(hdr, 61, 60)
    tc = _field(hdr, 59, 57)
    reqtype = _field(hdr, 14, 11)
    tag = _field(hdr, 39, 32)
    requesterid = _field(hdr, 31, 16)
    fmt, typ = _cq_fmt_type(reqtype)

    out = 0
    out |= dwlen
    out |= attr << 12
    out |= tc << 20
    out |= typ << 24
    out |= fmt << 29
    out |= be << 32
    out |= tag << 40
    out |= requesterid << 48
    return out


class TestMAxisCQAdapter(unittest.TestCase):
    def _run_case(self, data_width):
        keep_width = data_width // 8
        dut = MAxisCQAdapter(data_width)

        data0 = int("1122334455667788aabbccddeeff0011" * (data_width // 128), 16)
        data1 = int("0102030405060708f0e0d0c0b0a09080" * (data_width // 128), 16)

        # reqtype=0001 (write), bar=0b101.
        hdr = 0
        dwlen = {128: 1, 256: 5, 512: 13}[data_width]
        hdr |= dwlen
        hdr |= 0b10 << 60
        hdr |= 0b011 << 57
        hdr |= 0x34 << 32
        hdr |= 0x5678 << 16
        hdr |= 0b0001 << 11
        hdr |= 0b101 << 48
        data0 &= ~(((1 << 64) - 1) << 64)
        data0 |= hdr << 64

        user0 = 0
        user1 = 0
        user0 |= 1 << 41
        user1 |= 1 << 41
        if data_width == 512:
            user0 |= 1 << 96
            user1 |= 1 << 96
            be = ((user0 >> 8) & 0xF) << 4 | (user0 & 0xF)
        else:
            be = user0 & 0xFF

        expected_header = _cq_header(data0, be)

        beats = []

        @passive
        def monitor():
            while len(beats) < 1:
                if (yield dut.m_axis_tvalid):
                    beats.append({
                        "data": (yield dut.m_axis_tdata),
                        "keep": (yield dut.m_axis_tkeep),
                        "last": (yield dut.m_axis_tlast),
                        "user": (yield dut.m_axis_tuser),
                        "ready": (yield dut.s_axis_tready),
                    })
                yield

        def stim():
            yield dut.m_axis_tready.eq(1)
            yield

            yield dut.s_axis_tvalid.eq(1)
            yield dut.s_axis_tlast.eq(0)
            yield dut.s_axis_tdata.eq(data0)
            yield dut.s_axis_tuser.eq(user0)
            yield dut.s_axis_tkeep.eq(0)
            yield

            yield dut.s_axis_tlast.eq(1)
            yield dut.s_axis_tdata.eq(data1)
            yield dut.s_axis_tuser.eq(user1)
            yield

            yield dut.s_axis_tvalid.eq(0)
            yield dut.s_axis_tlast.eq(0)
            yield

        run_simulation(dut, [stim(), monitor()], vcd_name=None)

        self.assertEqual(len(beats), 1)
        out = beats[0]
        self.assertEqual(out["ready"], 0b1111)
        self.assertEqual(out["last"], 1)

        if data_width == 128:
            expected_data = (data1 & 0xFFFF_FFFF) << 96
            expected_data |= (data0 & 0xFFFF_FFFF) << 64
            expected_data |= expected_header
        elif data_width == 256:
            expected_data = (data1 & 0xFFFF_FFFF) << 224
            expected_data |= ((data0 >> 128) & ((1 << 128) - 1)) << 96
            expected_data |= (data0 & 0xFFFF_FFFF) << 64
            expected_data |= expected_header
        else:
            expected_data = (data1 & 0xFFFF_FFFF) << (data_width - 32)
            expected_data |= ((data0 >> 128) & ((1 << (data_width - 128)) - 1)) << 96
            expected_data |= (data0 & 0xFFFF_FFFF) << 64
            expected_data |= expected_header

        self.assertEqual(out["data"], expected_data)
        self.assertEqual(out["keep"], (1 << keep_width) - 1)

        barhit = (0 << 7) | (0b101 << 4) | 0b0001
        ecrc_bit = 96 if data_width == 512 else 41
        expected_user = ((user1 >> ecrc_bit) & 0x1) | (barhit << 2)
        self.assertEqual(out["user"] & ((1 << 22) - 1), expected_user)

    def test_m_axis_cq_adapter_128(self):
        self._run_case(data_width=128)

    def test_m_axis_cq_adapter_256(self):
        self._run_case(data_width=256)

    def test_m_axis_cq_adapter_512(self):
        self._run_case(data_width=512)

    def test_m_axis_cq_adapter_256_delayed_last(self):
        dut = MAxisCQAdapter(256)

        # Force SOP with tlast_a=1 so the adapter must emit a delayed extra beat.
        data0 = int("00112233445566778899aabbccddeeff" * 2, 16)
        hdr = 0
        hdr |= 1            # dwlen != 5
        hdr |= 0b0001 << 11 # write reqtype
        data0 &= ~(((1 << 64) - 1) << 64)
        data0 |= hdr << 64
        user0 = 0
        user0 |= 1 << 41
        user0 |= 0xA5A5_5A5A << 8  # last-be source

        beats = []

        @passive
        def monitor():
            for _ in range(8):
                if (yield dut.m_axis_tvalid):
                    beats.append({
                        "last": (yield dut.m_axis_tlast),
                        "keep": (yield dut.m_axis_tkeep),
                    })
                yield

        def stim():
            yield dut.m_axis_tready.eq(1)
            yield
            yield dut.s_axis_tvalid.eq(1)
            yield dut.s_axis_tlast.eq(1)
            yield dut.s_axis_tdata.eq(data0)
            yield dut.s_axis_tuser.eq(user0)
            yield
            yield dut.s_axis_tvalid.eq(0)
            yield
            yield

        run_simulation(dut, [stim(), monitor()], vcd_name=None)
        self.assertEqual(len(beats), 1)
        self.assertEqual(beats[0]["last"], 1)
        expected_keep = ((user0 >> 24) & 0xFFFF) << 12 | 0xFFF
        self.assertEqual(beats[0]["keep"], expected_keep)

    def test_m_axis_cq_adapter_128_read_keep(self):
        dut = MAxisCQAdapter(128)

        data0 = int("89abcdef012345670011223344556677", 16)
        hdr = 0
        hdr |= 1              # dwlen
        hdr |= 0b0000 << 11   # read reqtype
        data0 &= ~(((1 << 64) - 1) << 64)
        data0 |= hdr << 64

        beats = []

        @passive
        def monitor():
            for _ in range(6):
                if (yield dut.m_axis_tvalid):
                    beats.append({
                        "keep": (yield dut.m_axis_tkeep),
                        "last": (yield dut.m_axis_tlast),
                    })
                yield

        def stim():
            yield dut.m_axis_tready.eq(1)
            yield
            yield dut.s_axis_tvalid.eq(1)
            yield dut.s_axis_tlast.eq(0)
            yield dut.s_axis_tdata.eq(data0)
            yield dut.s_axis_tuser.eq(0)
            yield
            yield dut.s_axis_tvalid.eq(1)
            yield dut.s_axis_tlast.eq(1)
            yield dut.s_axis_tdata.eq(0)
            yield dut.s_axis_tuser.eq(0)
            yield
            yield dut.s_axis_tvalid.eq(0)
            yield

        run_simulation(dut, [stim(), monitor()], vcd_name=None)
        self.assertGreaterEqual(len(beats), 1)
        self.assertEqual(beats[0]["keep"], 0x0FFF)

    def test_m_axis_cq_adapter_256_backpressure(self):
        data0 = int("1122334455667788aabbccddeeff0011" * 2, 16)
        data1 = int("0102030405060708f0e0d0c0b0a09080" * 2, 16)
        hdr = 0
        hdr |= 5
        hdr |= 0b0001 << 11
        data0 &= ~(((1 << 64) - 1) << 64)
        data0 |= hdr << 64
        user0 = 1 << 41
        user1 = 1 << 41

        in_beats = [
            dict(data=data0, user=user0, last=0),
            dict(data=data1, user=user1, last=1),
        ]

        def run(ready_pattern):
            dut = MAxisCQAdapter(256)
            out_beats = []

            @passive
            def monitor():
                while len(out_beats) < 1:
                    if (yield dut.m_axis_tvalid) and (yield dut.m_axis_tready):
                        out_beats.append((
                            (yield dut.m_axis_tdata),
                            (yield dut.m_axis_tkeep),
                            (yield dut.m_axis_tlast),
                            (yield dut.m_axis_tuser),
                        ))
                    yield

            def stim():
                yield dut.s_axis_tvalid.eq(0)
                yield
                cyc = 0
                i = 0
                while i < len(in_beats):
                    yield dut.m_axis_tready.eq(1 if ready_pattern[cyc % len(ready_pattern)] else 0)
                    beat = in_beats[i]
                    yield dut.s_axis_tvalid.eq(1)
                    yield dut.s_axis_tdata.eq(beat["data"])
                    yield dut.s_axis_tuser.eq(beat["user"])
                    yield dut.s_axis_tlast.eq(beat["last"])
                    if (yield dut.s_axis_tready[0]):
                        i += 1
                    cyc += 1
                    yield
                yield dut.s_axis_tvalid.eq(0)
                for _ in range(32):
                    yield dut.m_axis_tready.eq(1 if ready_pattern[cyc % len(ready_pattern)] else 0)
                    cyc += 1
                    yield

            run_simulation(dut, [stim(), monitor()], vcd_name=None)
            return out_beats

        ready_all_ones = [1] * 128
        ready_bursty = [1 if ((i * 13 + 1) % 9) not in [0, 1, 2] else 0 for i in range(128)]
        self.assertEqual(run(ready_bursty), run(ready_all_ones))

    def test_m_axis_cq_adapter_256_multi_packet_continuity_dwlen(self):
        dut = MAxisCQAdapter(256)

        def make_sop(dwlen):
            d = int("112233445566778899aabbccddeeff00" * 2, 16)
            hdr = 0
            hdr |= dwlen & 0x3FF
            hdr |= 0b0001 << 11  # write reqtype
            d &= ~(((1 << 64) - 1) << 64)
            d |= hdr << 64
            return d

        stream = [
            # Packet 1: dwlen=5 (threshold), 2-beat packet.
            dict(data=make_sop(5),  user=(1 << 41), last=0),
            dict(data=int("00112233445566778899aabbccddeeff" * 2, 16), user=(1 << 41), last=1),
            # Packet 2: dwlen=4, back-to-back no idle (this one creates delayed-last behavior).
            dict(data=make_sop(4),  user=(1 << 41), last=0),
            dict(data=int("ffeeddccbbaa99887766554433221100" * 2, 16), user=(1 << 41), last=1),
        ]

        out_beats = []

        @passive
        def monitor():
            for _ in range(32):
                if (yield dut.m_axis_tvalid) and (yield dut.m_axis_tready):
                    out_beats.append({
                        "data": (yield dut.m_axis_tdata),
                        "last": (yield dut.m_axis_tlast),
                    })
                yield

        def stim():
            yield dut.m_axis_tready.eq(1)
            yield
            i = 0
            while i < len(stream):
                beat = stream[i]
                yield dut.s_axis_tvalid.eq(1)
                yield dut.s_axis_tdata.eq(beat["data"])
                yield dut.s_axis_tuser.eq(beat["user"])
                yield dut.s_axis_tlast.eq(beat["last"])
                yield dut.s_axis_tkeep.eq(0)
                if (yield dut.s_axis_tready[0]):
                    i += 1
                yield
            yield dut.s_axis_tvalid.eq(0)
            for _ in range(16):
                yield

        run_simulation(dut, [stim(), monitor()], vcd_name=None)

        # No boundary loss across back-to-back packets:
        # pkt1 -> 1 beat, pkt2 -> 2 beats (delayed last), total 3.
        self.assertEqual(len(out_beats), 3)
        self.assertEqual([b["last"] for b in out_beats], [1, 0, 1])
        # Header is in low 64b of first output beat for each packet.
        self.assertEqual((out_beats[0]["data"] >> 0) & 0x3FF, 5)
        self.assertEqual((out_beats[1]["data"] >> 0) & 0x3FF, 4)

    def _run_ecrc_matrix_case(self, data_width, ecrc):
        dut = MAxisCQAdapter(data_width)
        beats = []

        data0 = int("1122334455667788aabbccddeeff0011" * (data_width // 128), 16)
        data1 = int("0102030405060708f0e0d0c0b0a09080" * (data_width // 128), 16)

        hdr = 0
        hdr |= {128: 1, 256: 5, 512: 13}[data_width]
        hdr |= 0b0001 << 11
        hdr |= 0b101 << 48
        data0 &= ~(((1 << 64) - 1) << 64)
        data0 |= hdr << 64

        user0 = 0
        user1 = 0
        if data_width == 512:
            user0 |= (ecrc & 0x1) << 96
            user1 |= (ecrc & 0x1) << 96
        else:
            user0 |= (ecrc & 0x1) << 41
            user1 |= (ecrc & 0x1) << 41

        @passive
        def monitor():
            for _ in range(12):
                if (yield dut.m_axis_tvalid):
                    beats.append((yield dut.m_axis_tuser))
                yield

        def stim():
            yield dut.m_axis_tready.eq(1)
            yield
            yield dut.s_axis_tvalid.eq(1)
            yield dut.s_axis_tlast.eq(0)
            yield dut.s_axis_tdata.eq(data0)
            yield dut.s_axis_tuser.eq(user0)
            yield dut.s_axis_tkeep.eq(0)
            yield
            yield dut.s_axis_tvalid.eq(1)
            yield dut.s_axis_tlast.eq(1)
            yield dut.s_axis_tdata.eq(data1)
            yield dut.s_axis_tuser.eq(user1)
            yield
            yield dut.s_axis_tvalid.eq(0)
            yield

        run_simulation(dut, [stim(), monitor()], vcd_name=None)
        self.assertGreaterEqual(len(beats), 1)
        return beats[0]

    def test_ecrc_matrix_all_widths(self):
        for data_width in [128, 256, 512]:
            for ecrc in [0, 1]:
                out_user = self._run_ecrc_matrix_case(data_width=data_width, ecrc=ecrc)
                self.assertEqual(out_user & 0x1, ecrc)

    def test_be_unpack_fuzz_all_widths(self):
        rng = random.Random(0x5A17C0)
        for data_width in [128, 256, 512]:
            for _ in range(40):
                dut = MAxisCQAdapter(data_width)
                beats = []

                data0 = rng.getrandbits(data_width)
                data1 = rng.getrandbits(data_width)
                hdr = 0
                hdr |= {128: 1, 256: 5, 512: 13}[data_width]
                hdr |= 0b0001 << 11  # write
                data0 &= ~(((1 << 64) - 1) << 64)
                data0 |= hdr << 64

                if data_width == 512:
                    lo = rng.getrandbits(4)
                    hi = rng.getrandbits(4)
                    user0 = lo | (hi << 8)
                    expected_be = (hi << 4) | lo
                else:
                    expected_be = rng.getrandbits(8)
                    user0 = expected_be
                user1 = 0

                @passive
                def monitor():
                    for _ in range(10):
                        if (yield dut.m_axis_tvalid):
                            beats.append((yield dut.m_axis_tdata))
                        yield

                def stim():
                    yield dut.m_axis_tready.eq(1)
                    yield
                    yield dut.s_axis_tvalid.eq(1)
                    yield dut.s_axis_tlast.eq(0)
                    yield dut.s_axis_tdata.eq(data0)
                    yield dut.s_axis_tuser.eq(user0)
                    yield dut.s_axis_tkeep.eq(0)
                    yield
                    yield dut.s_axis_tvalid.eq(1)
                    yield dut.s_axis_tlast.eq(1)
                    yield dut.s_axis_tdata.eq(data1)
                    yield dut.s_axis_tuser.eq(user1)
                    yield
                    yield dut.s_axis_tvalid.eq(0)
                    yield

                run_simulation(dut, [stim(), monitor()], vcd_name=None)
                self.assertGreaterEqual(len(beats), 1)
                self.assertEqual((beats[0] >> 32) & 0xFF, expected_be)

    def test_last_keep_fuzz_256_512(self):
        rng = random.Random(0x5A17C1)
        for data_width in [256, 512]:
            keep_width = data_width // 8
            for _ in range(40):
                dut = MAxisCQAdapter(data_width)
                beats = []

                data0 = rng.getrandbits(data_width)
                hdr = 0
                hdr |= rng.randrange(0, 1024)  # dwlen
                hdr |= 0b0001 << 11            # write
                data0 &= ~(((1 << 64) - 1) << 64)
                data0 |= hdr << 64

                if data_width == 256:
                    tail = rng.getrandbits(16)
                    user0 = tail << 24
                    expected_keep = (tail << 12) | 0xFFF
                else:
                    tail = rng.getrandbits(48)
                    user0 = tail << 32
                    expected_keep = (tail << 12) | 0xFFF
                    expected_keep &= (1 << keep_width) - 1

                @passive
                def monitor():
                    for _ in range(8):
                        if (yield dut.m_axis_tvalid):
                            beats.append({
                                "keep": (yield dut.m_axis_tkeep),
                                "last": (yield dut.m_axis_tlast),
                            })
                        yield

                def stim():
                    yield dut.m_axis_tready.eq(1)
                    yield
                    yield dut.s_axis_tvalid.eq(1)
                    yield dut.s_axis_tlast.eq(1)
                    yield dut.s_axis_tdata.eq(data0)
                    yield dut.s_axis_tuser.eq(user0)
                    yield dut.s_axis_tkeep.eq(0)
                    yield
                    yield dut.s_axis_tvalid.eq(0)
                    yield

                run_simulation(dut, [stim(), monitor()], vcd_name=None)
                self.assertGreaterEqual(len(beats), 1)
                self.assertEqual(beats[0]["last"], 1)
                self.assertEqual(beats[0]["keep"], expected_keep)

```

`test/test_m_axis_rc_adapter.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2026 Enjoy-Digital <enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

import unittest

from litex.gen import *

from litepcie.phy.axis_adapters import MAxisRCAdapter


def _field(value, msb, lsb):
    return (value >> lsb) & ((1 << (msb - lsb + 1)) - 1)


def _rc_headers(data):
    dwlen       = _field(data, 41, 32)
    attr        = _field(data, 93, 92)
    tc          = _field(data, 91, 89)
    bytecnt     = _field(data, 27, 16)
    cmpstatus   = _field(data, 45, 43)
    completerid = _field(data, 87, 72)
    lowaddr     = _field(data, 6, 0)
    tag         = _field(data, 71, 64)
    requesterid = _field(data, 63, 48)

    if _field(data, 29, 29):
        fmt = 0b000 if bytecnt == 0 else 0b010
        typ = 0b01011
    else:
        fmt = 0b000 if bytecnt == 0 else 0b010
        typ = 0b01010

    header0 = 0
    header0 |= dwlen
    header0 |= attr << 12
    header0 |= tc << 20
    header0 |= typ << 24
    header0 |= fmt << 29
    header0 |= bytecnt << 32
    header0 |= cmpstatus << 45
    header0 |= completerid << 48

    header1 = 0
    header1 |= lowaddr
    header1 |= tag << 8
    header1 |= requesterid << 16
    header1 |= _field(data, 127, 96) << 32
    return header0, header1


class TestMAxisRCAdapter(unittest.TestCase):
    def _run_case(self, data_width):
        keep_width = data_width // 8
        dut = MAxisRCAdapter(data_width)

        data0 = int("123456789abcdef0fedcba9876543210" * (data_width // 128), 16)
        data1 = int("0f1e2d3c4b5a69788796a5b4c3d2e1f0" * (data_width // 128), 16)
        user0 = (1 << 42) | 0x1555_aa55_1234
        user1 = 0x0f0f_aaaa_55aa
        user0 &= (1 << 85) - 1
        user1 &= (1 << 85) - 1

        beats = []

        @passive
        def monitor():
            while len(beats) < 2:
                if (yield dut.m_axis_tvalid):
                    beats.append({
                        "data":  (yield dut.m_axis_tdata),
                        "keep":  (yield dut.m_axis_tkeep),
                        "last":  (yield dut.m_axis_tlast),
                        "user":  (yield dut.m_axis_tuser),
                        "sop":   (yield dut.m_axis_sop),
                        "ready": (yield dut.s_axis_tready),
                    })
                yield

        def stim():
            yield dut.m_axis_tready.eq(1)
            yield

            yield dut.s_axis_tvalid.eq(1)
            yield dut.s_axis_tlast.eq(0)
            yield dut.s_axis_tdata.eq(data0)
            yield dut.s_axis_tuser.eq(user0)
            yield dut.s_axis_tkeep.eq(0)
            yield

            yield dut.s_axis_tlast.eq(1)
            yield dut.s_axis_tdata.eq(data1)
            yield dut.s_axis_tuser.eq(user1)
            yield

            yield dut.s_axis_tvalid.eq(0)
            yield dut.s_axis_tlast.eq(0)
            yield

        run_simulation(dut, [stim(), monitor()], vcd_name=None)

        self.assertEqual(len(beats), 2)
        self.assertEqual(beats[0]["ready"], 0b1111)
        self.assertEqual(beats[1]["ready"], 0b1111)

        header0, header1 = _rc_headers(data0)
        if data_width == 128:
            exp_data0 = (header1 << 64) | header0
            exp_keep0 = (1 << keep_width) - 1
            exp_user0 = ((user0 >> 42) & 0x1) | (((data0 >> 46) & 0x1) << 1) | (1 << 14)
        else:
            exp_data0 = ((data0 >> 128) << 128) | (header1 << 64) | header0
            exp_keep0 = ((((user0 >> 12) << 12) | 0xFFF) & ((1 << keep_width) - 1))
            exp_user0 = ((user0 >> 42) & 0x1) | (((data0 >> 46) & 0x1) << 1)

        exp_data1 = data1
        exp_keep1 = user1 & ((1 << keep_width) - 1)
        exp_user1 = ((user1 >> 42) & 0x1) | (((data0 >> 46) & 0x1) << 1)

        self.assertEqual(beats[0]["sop"], 1)
        self.assertEqual(beats[1]["sop"], 0)
        self.assertEqual(beats[0]["data"], exp_data0)
        self.assertEqual(beats[0]["keep"], exp_keep0)
        self.assertEqual(beats[0]["last"], 0)
        self.assertEqual(beats[0]["user"] & ((1 << 22) - 1), exp_user0)
        self.assertEqual(beats[1]["data"], exp_data1)
        self.assertEqual(beats[1]["keep"], exp_keep1)
        self.assertEqual(beats[1]["last"], 1)
        self.assertEqual(beats[1]["user"] & ((1 << 22) - 1), exp_user1)

    def test_m_axis_rc_adapter_128(self):
        self._run_case(data_width=128)

    def test_m_axis_rc_adapter_256(self):
        self._run_case(data_width=256)

    def test_m_axis_rc_adapter_512(self):
        self._run_case(data_width=512)

    def test_m_axis_rc_adapter_256_backpressure(self):
        in_beats = [
            dict(
                data=int("123456789abcdef0fedcba9876543210" * 2, 16),
                user=((1 << 42) | 0x1234_5678_9abc) & ((1 << 85) - 1),
                last=0,
            ),
            dict(
                data=int("0f1e2d3c4b5a69788796a5b4c3d2e1f0" * 2, 16),
                user=(0x0f0f_aaaa_55aa) & ((1 << 85) - 1),
                last=1,
            ),
        ]

        def run(ready_pattern):
            dut = MAxisRCAdapter(256)
            out_beats = []

            @passive
            def monitor():
                while len(out_beats) < 2:
                    if (yield dut.m_axis_tvalid) and (yield dut.m_axis_tready):
                        out_beats.append((
                            (yield dut.m_axis_tdata),
                            (yield dut.m_axis_tkeep),
                            (yield dut.m_axis_tlast),
                            (yield dut.m_axis_tuser),
                            (yield dut.m_axis_sop),
                        ))
                    yield

            def stim():
                yield dut.s_axis_tvalid.eq(0)
                yield dut.s_axis_tlast.eq(0)
                yield
                cyc = 0
                i = 0
                while i < len(in_beats):
                    yield dut.m_axis_tready.eq(1 if ready_pattern[cyc % len(ready_pattern)] else 0)
                    beat = in_beats[i]
                    yield dut.s_axis_tvalid.eq(1)
                    yield dut.s_axis_tdata.eq(beat["data"])
                    yield dut.s_axis_tuser.eq(beat["user"])
                    yield dut.s_axis_tlast.eq(beat["last"])
                    if (yield dut.s_axis_tready[0]):
                        i += 1
                    cyc += 1
                    yield
                yield dut.s_axis_tvalid.eq(0)
                for _ in range(32):
                    yield dut.m_axis_tready.eq(1 if ready_pattern[cyc % len(ready_pattern)] else 0)
                    cyc += 1
                    yield

            run_simulation(dut, [stim(), monitor()], vcd_name=None)
            return out_beats

        ready_all_ones = [1] * 128
        ready_bursty = [1 if ((i * 17 + 3) % 7) not in [0, 1] else 0 for i in range(128)]
        ref = run(ready_all_ones)
        got = run(ready_bursty)
        self.assertEqual(got, ref)

    def _run_poison_ecrc_matrix_case(self, data_width, poison_data, ecrc_user):
        dut = MAxisRCAdapter(data_width)
        beats = []

        data = int("123456789abcdef0fedcba9876543210" * (data_width // 128), 16)
        data &= ~(1 << 46)
        data |= (poison_data & 0x1) << 46
        user = (ecrc_user & 0x1) << 42

        @passive
        def monitor():
            for _ in range(8):
                if (yield dut.m_axis_tvalid):
                    beats.append((yield dut.m_axis_tuser))
                yield

        def stim():
            yield dut.m_axis_tready.eq(1)
            yield
            yield dut.s_axis_tvalid.eq(1)
            yield dut.s_axis_tlast.eq(1)
            yield dut.s_axis_tdata.eq(data)
            yield dut.s_axis_tuser.eq(user)
            yield dut.s_axis_tkeep.eq(0)
            yield
            yield dut.s_axis_tvalid.eq(0)
            yield

        run_simulation(dut, [stim(), monitor()], vcd_name=None)
        self.assertGreaterEqual(len(beats), 1)
        return beats[0]

    def test_poison_ecrc_matrix_all_widths(self):
        for data_width in [128, 256, 512]:
            for poison_data in [0, 1]:
                for ecrc_user in [0, 1]:
                    out_user = self._run_poison_ecrc_matrix_case(
                        data_width=data_width,
                        poison_data=poison_data,
                        ecrc_user=ecrc_user,
                    )
                    self.assertEqual(out_user & 0x1, ecrc_user)
                    self.assertEqual((out_user >> 1) & 0x1, poison_data)

```

`test/test_s_axis_cc_adapter.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2026 Enjoy-Digital <enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

import unittest
import random

from litex.gen import *

from litepcie.phy.axis_adapters import SAxisCCAdapter


def _field(value, msb, lsb):
    return (value >> lsb) & ((1 << (msb - lsb + 1)) - 1)


def _header_words(data, tuser):
    lowaddr = _field(data, 70, 64)
    bytecnt = _field(data, 43, 32)
    lockedrdcmp = 1 if _field(data, 29, 24) == 0b001011 else 0
    dwordcnt = _field(data, 9, 0)
    cmpstatus = _field(data, 47, 45)
    poison = _field(data, 14, 14)
    requesterid = _field(data, 95, 80)
    tag = _field(data, 79, 72)
    completerid = _field(data, 63, 48)
    tc = _field(data, 22, 20)
    attr = _field(data, 13, 12)
    td = _field(data, 15, 15) | (tuser & 0x1)

    header0 = 0
    header0 |= lowaddr
    header0 |= bytecnt << 16
    header0 |= lockedrdcmp << 29
    header0 |= dwordcnt << 32
    header0 |= cmpstatus << 42
    header0 |= poison << 45
    header0 |= requesterid << 48

    header1 = 0
    header1 |= tag
    header1 |= completerid << 8
    header1 |= tc << 25
    header1 |= attr << 28
    header1 |= td << 31
    header1 |= _field(data, 127, 96) << 32
    return header0, header1


class TestSAxisCCAdapter(unittest.TestCase):
    def _expected_keep(self, data_width, keep):
        if data_width == 128:
            return sum(((1 if ((keep >> (4*i)) & 0xF) else 0) << i) for i in range(4))
        if data_width == 256:
            return sum(((1 if ((keep >> (4*i)) & 0xF) else 0) << i) for i in range(8))
        return sum((((keep >> (4*i)) & 0x1) << i) for i in range(16))

    def _run_case(self, data_width):
        dut = SAxisCCAdapter(data_width)
        keep_width = data_width // 8

        data = int("ffeeddccbbaa99887766554433221100" * (data_width // 128), 16)
        # Force meaningful header fields.
        data &= ~((1 << 128) - 1)
        data |= 0x89ABCDEF << 96
        data |= 0x1357 << 80
        data |= 0x42 << 72
        data |= 0x2468 << 48
        data |= 0b101 << 45
        data |= 0x155 << 32
        data |= 0b001011 << 24
        data |= 0b110 << 20
        data |= 0b10 << 12
        data |= 0x2AA
        data |= 0x3F << 64

        if data_width == 128:
            keep = 0xF0F3
        elif data_width == 256:
            keep = 0x00FF_0F0F
        else:
            keep = int("1111000011110000", 2)  # nibble-lsb pattern.
            keep = sum((((keep >> i) & 0x1) << (4*i)) for i in range(16))

        tuser = 0b1001  # td contribution + discontinue.
        beats = []

        @passive
        def monitor():
            while len(beats) < 1:
                if (yield dut.m_axis_tvalid):
                    beats.append({
                        "data": (yield dut.m_axis_tdata),
                        "keep": (yield dut.m_axis_tkeep),
                        "last": (yield dut.m_axis_tlast),
                        "user": (yield dut.m_axis_tuser),
                        "ready": (yield dut.s_axis_tready),
                    })
                yield

        def stim():
            yield dut.m_axis_tready.eq(1)
            yield
            yield dut.s_axis_tvalid.eq(1)
            yield dut.s_axis_tlast.eq(1)
            yield dut.s_axis_tdata.eq(data)
            yield dut.s_axis_tkeep.eq(keep)
            yield dut.s_axis_tuser.eq(tuser)
            yield
            yield dut.s_axis_tvalid.eq(0)
            yield

        run_simulation(dut, [stim(), monitor()], vcd_name=None)

        self.assertEqual(len(beats), 1)
        out = beats[0]

        header0, header1 = _header_words(data, tuser)
        if data_width == 128:
            expected_data = (header1 << 64) | header0
        else:
            expected_data = ((data >> 128) << 128) | (header1 << 64) | header0

        self.assertEqual(out["ready"], 1)
        self.assertEqual(out["last"], 1)
        self.assertEqual(out["user"], 1)  # only discontinue bit is propagated.
        self.assertEqual(out["keep"], self._expected_keep(data_width, keep))
        self.assertEqual(out["data"], expected_data)

    def test_s_axis_cc_adapter_128(self):
        self._run_case(data_width=128)

    def test_s_axis_cc_adapter_256(self):
        self._run_case(data_width=256)

    def test_s_axis_cc_adapter_512(self):
        self._run_case(data_width=512)

    def test_s_axis_cc_adapter_256_backpressure(self):
        data = int("ffeeddccbbaa99887766554433221100" * 2, 16)
        keep = 0x00FF_0F0F
        user = 0b1001

        in_beats = [dict(data=data, keep=keep, user=user, last=1)]

        def run(ready_pattern):
            dut = SAxisCCAdapter(256)
            out_beats = []

            @passive
            def monitor():
                while len(out_beats) < 1:
                    if (yield dut.m_axis_tvalid) and (yield dut.m_axis_tready):
                        out_beats.append((
                            (yield dut.m_axis_tdata),
                            (yield dut.m_axis_tkeep),
                            (yield dut.m_axis_tlast),
                            (yield dut.m_axis_tuser),
                        ))
                    yield

            def stim():
                yield dut.s_axis_tvalid.eq(0)
                yield
                cyc = 0
                i = 0
                while i < len(in_beats):
                    yield dut.m_axis_tready.eq(1 if ready_pattern[cyc % len(ready_pattern)] else 0)
                    beat = in_beats[i]
                    yield dut.s_axis_tvalid.eq(1)
                    yield dut.s_axis_tdata.eq(beat["data"])
                    yield dut.s_axis_tkeep.eq(beat["keep"])
                    yield dut.s_axis_tuser.eq(beat["user"])
                    yield dut.s_axis_tlast.eq(beat["last"])
                    if (yield dut.s_axis_tready):
                        i += 1
                    cyc += 1
                    yield
                yield dut.s_axis_tvalid.eq(0)
                for _ in range(16):
                    yield dut.m_axis_tready.eq(1 if ready_pattern[cyc % len(ready_pattern)] else 0)
                    cyc += 1
                    yield

            run_simulation(dut, [stim(), monitor()], vcd_name=None)
            return out_beats

        ready_all_ones = [1] * 64
        ready_bursty = [1 if ((i * 11 + 5) % 8) not in [0, 1] else 0 for i in range(64)]
        self.assertEqual(run(ready_bursty), run(ready_all_ones))

    def _run_poison_ecrc_matrix_case(self, data_width, poison_data, td_data, td_user):
        dut = SAxisCCAdapter(data_width)
        beats = []

        data = int("ffeeddccbbaa99887766554433221100" * (data_width // 128), 16)
        data &= ~(1 << 14)
        data &= ~(1 << 15)
        data |= (poison_data & 0x1) << 14
        data |= (td_data & 0x1) << 15
        keep = (1 << (data_width // 8)) - 1
        tuser = td_user & 0x1

        @passive
        def monitor():
            for _ in range(8):
                if (yield dut.m_axis_tvalid):
                    beats.append((yield dut.m_axis_tdata))
                yield

        def stim():
            yield dut.m_axis_tready.eq(1)
            yield
            yield dut.s_axis_tvalid.eq(1)
            yield dut.s_axis_tlast.eq(1)
            yield dut.s_axis_tdata.eq(data)
            yield dut.s_axis_tkeep.eq(keep)
            yield dut.s_axis_tuser.eq(tuser)
            yield
            yield dut.s_axis_tvalid.eq(0)
            yield

        run_simulation(dut, [stim(), monitor()], vcd_name=None)
        self.assertGreaterEqual(len(beats), 1)
        return beats[0]

    def test_poison_ecrc_matrix_all_widths(self):
        for data_width in [128, 256, 512]:
            for poison_data in [0, 1]:
                for td_data in [0, 1]:
                    for td_user in [0, 1]:
                        out_data = self._run_poison_ecrc_matrix_case(
                            data_width=data_width,
                            poison_data=poison_data,
                            td_data=td_data,
                            td_user=td_user,
                        )
                        expected_poison = poison_data
                        expected_td = td_data | td_user
                        self.assertEqual((out_data >> 45) & 0x1, expected_poison)
                        self.assertEqual((out_data >> 95) & 0x1, expected_td)

    def test_keep_fuzz_all_widths(self):
        rng = random.Random(0x5A17CC)
        for data_width in [128, 256, 512]:
            keep_width = data_width // 8
            for _ in range(40):
                dut = SAxisCCAdapter(data_width)
                beats = []

                data = rng.getrandbits(data_width)
                keep = rng.getrandbits(keep_width)
                tuser = rng.getrandbits(4)

                @passive
                def monitor():
                    for _ in range(6):
                        if (yield dut.m_axis_tvalid):
                            beats.append((yield dut.m_axis_tkeep))
                        yield

                def stim():
                    yield dut.m_axis_tready.eq(1)
                    yield
                    yield dut.s_axis_tvalid.eq(1)
                    yield dut.s_axis_tlast.eq(1)
                    yield dut.s_axis_tdata.eq(data)
                    yield dut.s_axis_tkeep.eq(keep)
                    yield dut.s_axis_tuser.eq(tuser)
                    yield
                    yield dut.s_axis_tvalid.eq(0)
                    yield

                run_simulation(dut, [stim(), monitor()], vcd_name=None)
                self.assertEqual(len(beats), 1)
                self.assertEqual(beats[0], self._expected_keep(data_width, keep))

```

`test/test_s_axis_rq_adapter.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2026 Enjoy-Digital <enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

import unittest
import random

from litex.gen import *

from litepcie.phy.axis_adapters import SAxisRQAdapter


def _rq_header(data, tuser):
    dwlen = data & 0x3FF
    req_class = (((data >> 30) & 0x3) << 5) | ((data >> 24) & 0x1F)
    if req_class == 0b0000000:
        reqtype = 0b0000
    elif req_class == 0b0000001:
        reqtype = 0b0111
    elif req_class == 0b0100000:
        reqtype = 0b0001
    elif ((data >> 24) & 0xFF) == 0b00000010:
        reqtype = 0b0010
    elif ((data >> 24) & 0xFF) == 0b01000010:
        reqtype = 0b0011
    elif ((data >> 24) & 0xFF) == 0b00000100:
        reqtype = 0b1000
    elif ((data >> 24) & 0xFF) == 0b01000100:
        reqtype = 0b1010
    elif ((data >> 24) & 0xFF) == 0b00000101:
        reqtype = 0b1001
    elif ((data >> 24) & 0xFF) == 0b01000101:
        reqtype = 0b1011
    else:
        reqtype = 0b1111

    poisoning = ((data >> 14) & 1) | ((tuser >> 1) & 1)
    requesterid = (data >> 48) & 0xFFFF
    tag = (data >> 40) & 0xFF
    tc = (data >> 20) & 0x7
    attr = (data >> 12) & 0x3
    ecrc = ((data >> 15) & 1) | (tuser & 1)

    header = 0
    header |= dwlen
    header |= reqtype << 11
    header |= poisoning << 15
    header |= requesterid << 16
    header |= tag << 32
    header |= tc << 57
    header |= attr << 60
    header |= ecrc << 63
    return header


class TestSAxisRQAdapter(unittest.TestCase):
    def _run_poison_ecrc_matrix_case(self, data_width, poison_data, poison_user, ecrc_data, ecrc_user):
        dut = SAxisRQAdapter(data_width)
        beats = []

        data = int("0123456789abcdeffedcba9876543210" * (data_width // 128), 16)
        data &= ~(0x3 << 30)  # read request class to keep single-beat behavior
        data &= ~(1 << 14)
        data &= ~(1 << 15)
        data |= (poison_data & 0x1) << 14
        data |= (ecrc_data & 0x1) << 15
        data &= ~0x3FF
        data |= 1

        tuser = ((poison_user & 0x1) << 1) | (ecrc_user & 0x1)
        tkeep = (1 << (data_width // 8)) - 1

        @passive
        def monitor():
            for _ in range(8):
                if (yield dut.m_axis_tvalid):
                    beats.append((yield dut.m_axis_tdata))
                yield

        def stim():
            yield dut.m_axis_tready.eq(1)
            yield
            yield dut.s_axis_tvalid.eq(1)
            yield dut.s_axis_tlast.eq(1)
            yield dut.s_axis_tdata.eq(data)
            yield dut.s_axis_tkeep.eq(tkeep)
            yield dut.s_axis_tuser.eq(tuser)
            yield
            yield dut.s_axis_tvalid.eq(0)
            yield

        run_simulation(dut, [stim(), monitor()], vcd_name=None)
        self.assertGreaterEqual(len(beats), 1)
        return beats[0]

    def test_128_read_single_beat(self):
        dut = SAxisRQAdapter(128)
        data = 0x0123456789ABCDEFFEDCBA9876543210
        data &= ~(0x3 << 30)  # read
        data &= ~0x3FF
        data |= 0x010  # dwlen
        tuser = 0b1000

        beats = []

        @passive
        def monitor():
            for _ in range(8):
                if (yield dut.m_axis_tvalid):
                    beats.append(((yield dut.m_axis_tdata), (yield dut.m_axis_tkeep), (yield dut.m_axis_tlast), (yield dut.m_axis_tuser)))
                yield

        def stim():
            yield dut.m_axis_tready.eq(1)
            yield
            yield dut.s_axis_tvalid.eq(1)
            yield dut.s_axis_tlast.eq(1)
            yield dut.s_axis_tdata.eq(data)
            yield dut.s_axis_tkeep.eq(0xFFFF)
            yield dut.s_axis_tuser.eq(tuser)
            yield
            yield dut.s_axis_tvalid.eq(0)
            yield

        run_simulation(dut, [stim(), monitor()], vcd_name=None)
        self.assertEqual(len(beats), 1)
        out_data, out_keep, out_last, out_user = beats[0]
        expected_data = ((data >> 64) & 0xFFFFFFFF)
        expected_data |= _rq_header(data, tuser) << 64
        self.assertEqual(out_data, expected_data)
        self.assertEqual(out_keep, 0xF)
        self.assertEqual(out_last, 1)
        self.assertEqual(out_user & 0xFF, (((data >> 36) & 0xF) << 4) | ((data >> 32) & 0xF))

    def test_128_write_single_beat_delayed_last(self):
        dut = SAxisRQAdapter(128)
        data = 0x0F1E2D3C4B5A69788796A5B4C3D2E1F1
        data &= ~(0x3 << 30)
        data |= (0x1 << 30)  # write
        data &= ~0x3
        data |= 0x1          # trigger delayed-last path

        beats = []

        @passive
        def monitor():
            for _ in range(10):
                if (yield dut.m_axis_tvalid):
                    beats.append(((yield dut.m_axis_tkeep), (yield dut.m_axis_tlast)))
                yield

        def stim():
            yield dut.m_axis_tready.eq(1)
            yield
            yield dut.s_axis_tvalid.eq(1)
            yield dut.s_axis_tlast.eq(1)
            yield dut.s_axis_tdata.eq(data)
            yield dut.s_axis_tkeep.eq(0xFFFF)
            yield dut.s_axis_tuser.eq(0)
            yield
            yield dut.s_axis_tvalid.eq(0)
            yield
            yield

        run_simulation(dut, [stim(), monitor()], vcd_name=None)
        self.assertEqual(len(beats), 2)
        self.assertEqual(beats[0], (0xF, 0))
        self.assertEqual(beats[1], (0x1, 1))

    def test_256_first_beat_rewrite(self):
        dut = SAxisRQAdapter(256)
        data = int("112233445566778899aabbccddeeff00" * 2, 16)
        data &= ~0x3FF
        data |= 0x055
        tuser = 0b1000

        beats = []

        @passive
        def monitor():
            for _ in range(6):
                if (yield dut.m_axis_tvalid):
                    beats.append(((yield dut.m_axis_tdata), (yield dut.m_axis_tkeep), (yield dut.m_axis_tlast), (yield dut.m_axis_tuser)))
                yield

        def stim():
            yield dut.m_axis_tready.eq(1)
            yield
            yield dut.s_axis_tvalid.eq(1)
            yield dut.s_axis_tlast.eq(1)
            yield dut.s_axis_tdata.eq(data)
            yield dut.s_axis_tkeep.eq((1 << 32) - 1)
            yield dut.s_axis_tuser.eq(tuser)
            yield
            yield dut.s_axis_tvalid.eq(0)
            yield

        run_simulation(dut, [stim(), monitor()], vcd_name=None)
        self.assertEqual(len(beats), 1)
        out_data, out_keep, out_last, out_user = beats[0]
        expected_data = ((data >> 128) << 128)
        expected_data |= (_rq_header(data, tuser) << 64)
        expected_data |= ((data >> 64) & 0xFFFFFFFF) << 32
        expected_data |= ((data >> 96) & 0xFFFFFFFF)
        self.assertEqual(out_data, expected_data)
        self.assertEqual(out_keep, 0xFF)
        self.assertEqual(out_last, 1)
        self.assertEqual(out_user & 0xFF, (((data >> 36) & 0xF) << 4) | ((data >> 32) & 0xF))

    def test_512_read_short_single_beat(self):
        dut = SAxisRQAdapter(512)
        data = int("00112233445566778899aabbccddeeff" * 4, 16)
        data &= ~(0x3 << 30)  # read
        data &= ~0x3FF
        data |= 0x005         # < 13, should end on first beat
        tkeep = (1 << 64) - 1

        beats = []

        @passive
        def monitor():
            for _ in range(8):
                if (yield dut.m_axis_tvalid):
                    beats.append(((yield dut.m_axis_tkeep), (yield dut.m_axis_tlast), (yield dut.m_axis_tuser)))
                yield

        def stim():
            yield dut.m_axis_tready.eq(1)
            yield
            yield dut.s_axis_tvalid.eq(1)
            yield dut.s_axis_tlast.eq(1)
            yield dut.s_axis_tdata.eq(data)
            yield dut.s_axis_tkeep.eq(tkeep)
            yield dut.s_axis_tuser.eq(0b1000)
            yield
            yield dut.s_axis_tvalid.eq(0)
            yield

        run_simulation(dut, [stim(), monitor()], vcd_name=None)
        self.assertEqual(len(beats), 1)
        out_keep, out_last, out_user = beats[0]
        self.assertEqual(out_last, 1)
        self.assertEqual(out_keep, 0xFFFF)
        self.assertEqual((out_user >> 36) & 0x1, 1)

    def test_256_be_latched_on_second_beat(self):
        dut = SAxisRQAdapter(256)
        data0 = int("00112233445566778899aabbccddeeff" * 2, 16)
        data1 = int("ffeeddccbbaa99887766554433221100" * 2, 16)

        # First beat BE values that must be reused on second beat.
        data0 &= ~((0xFF) << 32)
        data0 |= (0xA << 36) | (0x5 << 32)

        beats = []

        @passive
        def monitor():
            for _ in range(8):
                if (yield dut.m_axis_tvalid):
                    beats.append((yield dut.m_axis_tuser) & 0xFF)
                yield

        def stim():
            yield dut.m_axis_tready.eq(1)
            yield
            yield dut.s_axis_tvalid.eq(1)
            yield dut.s_axis_tlast.eq(0)
            yield dut.s_axis_tdata.eq(data0)
            yield dut.s_axis_tkeep.eq((1 << 32) - 1)
            yield dut.s_axis_tuser.eq(0)
            yield
            yield dut.s_axis_tlast.eq(1)
            yield dut.s_axis_tdata.eq(data1)
            yield
            yield dut.s_axis_tvalid.eq(0)
            yield

        run_simulation(dut, [stim(), monitor()], vcd_name=None)
        self.assertEqual(len(beats), 2)
        self.assertEqual(beats[0], 0xA5)
        self.assertEqual(beats[1], 0xA5)

    def test_512_write_dwlen_13_delayed_last(self):
        dut = SAxisRQAdapter(512)
        data = int("89abcdef01234567fedcba9876543210" * 4, 16)
        data |= (0x1 << 30)      # write
        data &= ~0x3FF
        data |= 13               # dwlen == 13 triggers delayed-last path

        beats = []

        @passive
        def monitor():
            for _ in range(10):
                if (yield dut.m_axis_tvalid):
                    beats.append(((yield dut.m_axis_tkeep), (yield dut.m_axis_tlast)))
                yield

        def stim():
            yield dut.m_axis_tready.eq(1)
            yield
            yield dut.s_axis_tvalid.eq(1)
            yield dut.s_axis_tlast.eq(1)
            yield dut.s_axis_tdata.eq(data)
            yield dut.s_axis_tkeep.eq((1 << 64) - 1)
            yield dut.s_axis_tuser.eq(0)
            yield
            yield dut.s_axis_tvalid.eq(0)
            yield
            yield

        run_simulation(dut, [stim(), monitor()], vcd_name=None)
        self.assertEqual(len(beats), 2)
        self.assertEqual(beats[0], (0xFFFF, 0))
        self.assertEqual(beats[1], (0x0001, 1))

    def test_256_backpressure_equivalence(self):
        beat0 = int("00112233445566778899aabbccddeeff" * 2, 16)
        beat1 = int("ffeeddccbbaa99887766554433221100" * 2, 16)
        beat0 &= ~0x3FF
        beat0 |= 0x055

        in_beats = [
            dict(data=beat0, keep=(1 << 32) - 1, user=0, last=0),
            dict(data=beat1, keep=(1 << 32) - 1, user=0, last=1),
        ]

        def run(ready_pattern):
            dut = SAxisRQAdapter(256)
            out_beats = []

            @passive
            def monitor():
                while len(out_beats) < 2:
                    if (yield dut.m_axis_tvalid) and (yield dut.m_axis_tready):
                        out_beats.append((
                            (yield dut.m_axis_tdata),
                            (yield dut.m_axis_tkeep),
                            (yield dut.m_axis_tlast),
                            (yield dut.m_axis_tuser),
                        ))
                    yield

            def stim():
                yield dut.s_axis_tvalid.eq(0)
                yield
                cyc = 0
                i = 0
                while i < len(in_beats):
                    yield dut.m_axis_tready.eq(1 if ready_pattern[cyc % len(ready_pattern)] else 0)
                    beat = in_beats[i]
                    yield dut.s_axis_tvalid.eq(1)
                    yield dut.s_axis_tdata.eq(beat["data"])
                    yield dut.s_axis_tkeep.eq(beat["keep"])
                    yield dut.s_axis_tuser.eq(beat["user"])
                    yield dut.s_axis_tlast.eq(beat["last"])
                    if (yield dut.s_axis_tready):
                        i += 1
                    cyc += 1
                    yield
                yield dut.s_axis_tvalid.eq(0)
                for _ in range(24):
                    yield dut.m_axis_tready.eq(1 if ready_pattern[cyc % len(ready_pattern)] else 0)
                    cyc += 1
                    yield

            run_simulation(dut, [stim(), monitor()], vcd_name=None)
            return out_beats

        ready_all_ones = [1] * 128
        ready_bursty = [1 if ((i * 19 + 7) % 10) not in [0, 1, 2, 3] else 0 for i in range(128)]
        self.assertEqual(run(ready_bursty), run(ready_all_ones))

    def test_512_multi_packet_continuity_dwlen_thresholds(self):
        dut = SAxisRQAdapter(512)

        def make_first_beat(dwlen, is_write, be_code):
            d = int("0123456789abcdeffedcba9876543210" * 4, 16)
            # Req type class bits.
            d &= ~(0x3 << 30)
            if is_write:
                d |= (0x1 << 30)
            # DLen.
            d &= ~0x3FF
            d |= dwlen & 0x3FF
            # Distinct BE nibble pair.
            d &= ~((0xFF) << 32)
            d |= ((be_code & 0xF) << 36) | (((be_code + 1) & 0xF) << 32)
            return d

        beat_stream = [
            # Packet A: write dwlen=1 (single output beat, last=1).
            dict(data=make_first_beat(1,  True, 0x1), last=1),
            # Packet B: write dwlen=13 (delayed-last: two output beats).
            dict(data=make_first_beat(13, True, 0x2), last=1),
            # Packet C: read dwlen=14 (single output beat, last=1).
            dict(data=make_first_beat(14, False, 0x3), last=1),
            # Packet D: read dwlen=0 (single output beat, last=1).
            dict(data=make_first_beat(0,  False, 0x4), last=1),
        ]

        out_beats = []

        @passive
        def monitor():
            for _ in range(64):
                if (yield dut.m_axis_tvalid) and (yield dut.m_axis_tready):
                    out_beats.append({
                        "data": (yield dut.m_axis_tdata),
                        "last": (yield dut.m_axis_tlast),
                        "user": (yield dut.m_axis_tuser),
                    })
                yield

        def stim():
            yield dut.m_axis_tready.eq(1)
            yield
            i = 0
            # Keep valid asserted while feeding consecutive packets.
            while i < len(beat_stream):
                beat = beat_stream[i]
                yield dut.s_axis_tvalid.eq(1)
                yield dut.s_axis_tdata.eq(beat["data"])
                yield dut.s_axis_tkeep.eq((1 << 64) - 1)
                yield dut.s_axis_tuser.eq(0)
                yield dut.s_axis_tlast.eq(beat["last"])
                if (yield dut.s_axis_tready):
                    i += 1
                yield
            yield dut.s_axis_tvalid.eq(0)
            for _ in range(24):
                yield

        run_simulation(dut, [stim(), monitor()], vcd_name=None)

        # Expected output beat boundaries across A/B/C/D with no-idle packet transition.
        # A: 1 beat, B: 2 beats (delayed last), C: 1 beat, D: 1 beat.
        self.assertEqual(len(out_beats), 5)
        self.assertEqual([b["last"] for b in out_beats], [1, 0, 1, 1, 1])

        # Check SOP boundaries on threshold packets via header dwlen.
        first_indices = [0, 1, 3, 4]
        dlen_seen = [((out_beats[i]["data"] >> 64) & 0x3FF) for i in first_indices[:2]]
        self.assertEqual(dlen_seen, [1, 13])

    def test_poison_ecrc_matrix_all_widths(self):
        for data_width in [128, 256, 512]:
            header_lsb = 64
            for poison_data in [0, 1]:
                for poison_user in [0, 1]:
                    for ecrc_data in [0, 1]:
                        for ecrc_user in [0, 1]:
                            out_data = self._run_poison_ecrc_matrix_case(
                                data_width=data_width,
                                poison_data=poison_data,
                                poison_user=poison_user,
                                ecrc_data=ecrc_data,
                                ecrc_user=ecrc_user,
                            )
                            expected_poison = poison_data | poison_user
                            expected_ecrc = ecrc_data | ecrc_user
                            self.assertEqual((out_data >> (header_lsb + 15)) & 0x1, expected_poison)
                            self.assertEqual((out_data >> (header_lsb + 63)) & 0x1, expected_ecrc)

    def test_keep_be_fuzz_all_widths(self):
        rng = random.Random(0x5A1700)

        def expected_keep(width, keep):
            if width == 128:
                return 0xF
            if width == 256:
                return sum((((keep >> (4*i)) & 0x1) << i) for i in range(8))
            return 1 | sum((((keep >> (4*i)) & 0x1) << (i + 1)) for i in range(15))

        for data_width in [128, 256, 512]:
            keep_width = data_width // 8
            for _ in range(40):
                dut = SAxisRQAdapter(data_width)
                beats = []

                firstbe = rng.getrandbits(4)
                lastbe = rng.getrandbits(4)

                data = rng.getrandbits(data_width)
                data &= ~(0xFF << 32)
                data |= (firstbe << 32) | (lastbe << 36)
                data &= ~(0x3 << 30)  # read request to force single output beat
                data &= ~0x3FF
                data |= 1
                keep = rng.getrandbits(keep_width)
                tuser = rng.getrandbits(4)

                @passive
                def monitor():
                    for _ in range(8):
                        if (yield dut.m_axis_tvalid):
                            beats.append({
                                "keep": (yield dut.m_axis_tkeep),
                                "user": (yield dut.m_axis_tuser),
                                "last": (yield dut.m_axis_tlast),
                            })
                        yield

                def stim():
                    yield dut.m_axis_tready.eq(1)
                    yield
                    yield dut.s_axis_tvalid.eq(1)
                    yield dut.s_axis_tlast.eq(1)
                    yield dut.s_axis_tdata.eq(data)
                    yield dut.s_axis_tkeep.eq(keep)
                    yield dut.s_axis_tuser.eq(tuser)
                    yield
                    yield dut.s_axis_tvalid.eq(0)
                    yield

                run_simulation(dut, [stim(), monitor()], vcd_name=None)
                self.assertEqual(len(beats), 1)
                self.assertEqual(beats[0]["last"], 1)
                self.assertEqual(beats[0]["keep"], expected_keep(data_width, keep))
                if data_width in [128, 256]:
                    self.assertEqual(beats[0]["user"] & 0xFF, (lastbe << 4) | firstbe)
                else:
                    self.assertEqual(beats[0]["user"] & 0xF, firstbe)
                    self.assertEqual((beats[0]["user"] >> 8) & 0xF, lastbe)

```

`test/test_wishbone.py`:

```py
#
# This file is part of LitePCIe.
#
# Copyright (c) 2015-2024 Florent Kermarrec <florent@enjoy-digital.fr>
# SPDX-License-Identifier: BSD-2-Clause

import unittest

from litex.gen import *

from litex.soc.interconnect import wishbone

from litepcie.core import LitePCIeEndpoint
from litepcie.frontend.wishbone import LitePCIeWishboneMaster, LitePCIeWishboneSlave

from test.common import seed_to_data
from test.model.host import *

# Parameters ---------------------------------------------------------------------------------------

root_id     = 0x100
endpoint_id = 0x400

# Test Wishbone Master -----------------------------------------------------------------------------

# In this high level test, LitePCIeEndpoint is connected to LitePCIeWishboneMaster frontend, itself
# connected to a Wishbone SRAM and the Host software model is used to generate Write/Read TLPs:
#
#                                    ┌───────────┐
#                                    │           │
#                                    │   HOST    │
#                                    │  (Model)  │
#                                    │           │
#                                    └─┬───────▲─┘
#                                      │  TLPs │
#                                ┌─────▼───────┴─────┐
#                                │                   │
#                                │                   │
#                                │  LitePCIeEndpoint │
#                                │                   │
#                                │                   │
#                                └──┬──────────────▲─┘
#                                   │   Req/Cmp    │
#                              ┌────▼──────────────┴────┐
#                              │                        │
#                              │                        │
#                              │ LitePCIeWishboneMaster │
#                              │                        │
#                              │                        │
#                              └────────┬──────▲────────┘
#                                       │      │
#                                   ┌───▼──────┴───┐
#                                   │   Wishbone   │
#                                   │     SRAM     │
#                                   └──────────────┘
#
# The test verifies that the Host model is able to access the wishbone SRAM correctly through the
# LitePCIeEndpoint.

class TestWishboneMaster(unittest.TestCase):
    def wishbone_test(self, data_width, nwords=64):
        wr_datas = [seed_to_data(i, True) for i in range(nwords)]
        rd_datas = []

        def main_generator(dut):
            # Write ndatas to the Wishbone SRAM.
            for i in range(nwords):
                yield from dut.host.chipset.wr32(i, [wr_datas[i]])
            # Read ndatas from the Wishbone SRAM.
            for i in range(nwords):
                yield from dut.host.chipset.rd32(i)
                rd_datas.append(dut.host.chipset.rd_data[0])

        class DUT(LiteXModule):
            def __init__(self, data_width):
                self.host     = Host(data_width, root_id, endpoint_id)
                self.endpoint = LitePCIeEndpoint(self.host.phy)
                self.master   = LitePCIeWishboneMaster(self.endpoint)
                self.sram     = wishbone.SRAM(nwords*4, bus=self.master.wishbone)

        dut = DUT(data_width)
        generators = {
            "sys" : [
                main_generator(dut),
                dut.host.chipset.phy.phy_sink.generator(),
                dut.host.chipset.phy.phy_source.generator(),
            ]
        }
        clocks = {"sys": 10}
        run_simulation(dut, generators, clocks)
        # Verify Write/Read datas match.
        self.assertEqual(wr_datas, rd_datas)

    def test_wishbone_64b(self):
        self.wishbone_test(data_width=64)

    def test_wishbone_128b(self):
        self.wishbone_test(data_width=128)

    def test_wishbone_256b(self):
        self.wishbone_test(data_width=256)

    def test_wishbone_512b(self):
        self.wishbone_test(data_width=512)


# Test Wishbone Slave ------------------------------------------------------------------------------

# In this high level test, LitePCIeEndpoint is connected to LitePCIeWishboneSlave frontend. Wishbone
# accesses are done to Host Memory through LitePCIeWishbone and the Host software model is used to 
# handle Write/Read TLPs:
#
#                                    ┌───────────┐
#                                    │           │
#                                    │   HOST    │
#                                    │  (Model)  │
#                                    │           │
#                                    └─┬───────▲─┘
#                                      │  TLPs │
#                                ┌─────▼───────┴─────┐
#                                │                   │
#                                │                   │
#                                │  LitePCIeEndpoint │
#                                │                   │
#                                │                   │
#                                └──┬──────────────▲─┘
#                                   │   Req/Cmp    │
#                              ┌────▼──────────────┴────┐
#                              │                        │
#                              │                        │
#                              │ LitePCIeWishboneSlave  │
#                              │                        │
#                              │                        │
#                              └────────┬──────▲────────┘
#                                       │      │
#                                   ┌───▼──────┴───┐
#                                   │   Wishbone   │
#                                   │   Accesses   │
#                                   └──────────────┘
#
# The test verifies that the LitePCIeWishboneSlave is able to access Host Memory.

class TestWishboneSlave(unittest.TestCase):
    def wishbone_test(self, data_width, nwords=8):
        wr_datas = [seed_to_data(i, True) for i in range(nwords)]
        rd_datas = []

        #@passive
        def main_generator(dut):
            # Allocate Host's Memory.
            dut.host.malloc(0x00000000, 1024)

            # Enable Chipset
            dut.host.chipset.enable()

            # Write ndatas to Host Memory.
            for i in range(nwords):
                yield from dut.slave.wishbone.write(i, wr_datas[i])

           # Read ndatas from Host Memory.
            for i in range(nwords):
                rd_datas.append((yield from dut.slave.wishbone.read(i)))

        def fake_generator(dut):
            for i in range(1024):
                yield

        class DUT(LiteXModule):
            def __init__(self, data_width):
                self.host     = Host(data_width, root_id, endpoint_id, phy_debug=True, host_debug=True)
                self.endpoint = LitePCIeEndpoint(self.host.phy)
                self.slave    = LitePCIeWishboneSlave(self.endpoint)

        dut = DUT(data_width)
        generators = {
            "sys" : [
                main_generator(dut),
                #fake_generator(dut),
                dut.host.generator(),
                dut.host.chipset.generator(),
                dut.host.chipset.phy.phy_sink.generator(),
                dut.host.chipset.phy.phy_source.generator(),
            ]
        }
        clocks = {"sys": 10}
        run_simulation(dut, generators, clocks, vcd_name="sim.vcd")

    def test_wishbone_64b(self):
        self.wishbone_test(64)

```