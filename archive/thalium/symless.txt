Project Path: arc_thalium_symless_y23z6t5j

Source Tree:

```txt
arc_thalium_symless_y23z6t5j
├── LICENCE
├── README.md
├── img
│   ├── plugin_builder_form.png
│   ├── plugin_built_structure.png
│   └── plugin_context_menu.png
├── plugin
│   ├── install.py
│   └── symless_plugin.py
├── run_script.py
├── scripts
│   ├── ctors.py
│   ├── dump.py
│   ├── entries.py
│   └── vtables.py
├── symless
│   ├── __init__.py
│   ├── allocators.py
│   ├── config
│   │   ├── __init__.py
│   │   ├── config.json
│   │   └── imports.csv
│   ├── conflict.py
│   ├── cpustate
│   │   ├── __init__.py
│   │   ├── arch.py
│   │   └── cpustate.py
│   ├── existing.py
│   ├── generation
│   │   ├── __init__.py
│   │   ├── generate.py
│   │   └── structures.py
│   ├── main.py
│   ├── model
│   │   ├── __init__.py
│   │   ├── entrypoints.py
│   │   └── model.py
│   ├── plugins
│   │   ├── __init__.py
│   │   └── builder.py
│   ├── resources
│   │   ├── bigger_champi.png
│   │   ├── champi.png
│   │   ├── cross.png
│   │   └── propag.png
│   ├── symbols
│   │   ├── __init__.py
│   │   └── rename.py
│   └── utils
│       ├── ida_utils.py
│       ├── utils.py
│       └── vtables.py
└── symless.py

```

`LICENCE`:

```
    MIT License

    Copyright (c) 2023 Thalium Team

    Permission is hereby granted, free of charge, to any person obtaining a copy
    of this software and associated documentation files (the "Software"), to deal
    in the Software without restriction, including without limitation the rights
    to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
    copies of the Software, and to permit persons to whom the Software is
    furnished to do so, subject to the following conditions:

    The above copyright notice and this permission notice shall be included in all
    copies or substantial portions of the Software.

    THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
    IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
    FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
    AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
    LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
    OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
    SOFTWARE.

```

`README.md`:

```md
# Symless

An **IDA Pro plugin** that assists with **structure reconstruction**. Using static data-flow analysis to gather information, Symless automates most of the structure creation workflow. Its key features are:

* Inferring and creating structure fields based on access patterns
* Identifying and creating C++ virtual function tables
* Placing cross-references to link each structure field with the code that uses it

## Installation

```bash
$ python3 plugin/install.py [-u]
```

Or install manually: copy the [symless](symless/) directory and [symless_plugin.py](plugin/symless_plugin.py) file into your IDA plugins folder.

## Usage

The **interactive plugin** helps reconstruct a chosen structure. In the Disassembly or Pseudocode view, right-click a line that uses the structure you want to rebuild and select **Propagate structure** from the context menu:

<p align="center">
    <kbd>
        <img src="img/plugin_context_menu.png"/>
    </kbd>
</p>

A form will appear prompting for:

* The **name of the new structure** to create, or an existing structure to extend.
* An **entry point** for the data-flow analysis, which is performed on the microcode. This entry point is a microcode operand that holds a pointer to the structure.

> [!NOTE]
> The microcode is IDA's intermediate representation (IR), generated from the CPU-specific assembly. Because of its similarity with the assembly, it is not difficult to read.

<p align="center">
    <kbd>
        <img src="img/plugin_builder_form.png" width="448"/>
    </kbd>
</p>

Additional options are:

* **Shifted by**, the shift to apply to the structure pointer
* **Spread in callees**, whether the analysis should extend into called functions and discovered virtual methods

Clicking **Propagate** starts the analysis. The structure pointer is tracked from the selected entry, and observed accesses are used to infer structure fields.

> [!TIP]
> To get a more complete structure, run the analysis from the code that initializes the structure (for example, right after an allocation or inside a constructor).

The new structure is added to the Local Types view. Cross-references are added on assembly operands for each field access:

<p align="center">
    <kbd>
        <img src="img/plugin_built_structure.png"/>
    </kbd>
</p>

You can then edit field types directly from the pseudocode. The plugin reduces the amount of back-and-forth navigation between disassembly, pseudocode and local types, required when creating structures and placing cross-references.

## CLI mode

An **automatic command-line** mode also exists, able to identify and automatically reconstruct most of the structures used in a binary. Symless uses two sources to discover structures:

* Dynamic memory allocations
* C++ virtual function tables and constructors

This automatic mode is intended as a pre-analysis step, to create structures and improve decompilation before manual work.

First, add the memory allocators used in your executable in [imports.csv](symless/config/imports.csv). This allows Symless to rebuild structures from dynamic allocations. If you don't, only C++ classes with virtual tables will be reconstructed.

The pre-analysis is ran using:

```bash
    $ python3 symless.py [-c config.csv] <target>
```

* ```config.csv``` - configuration file to use (defaults to [imports.csv](symless/config/imports.csv))
* ```target``` - a binary or an IDA database

if target is an executable, a new IDA database will be created. When the analysis finishes, the database is populated with the reconstructed structures.

### Limitations

The main challenge for the automatic analysis is resolving conflicts between structures. This can cause functions to be incorrectly typed, or duplicated structures to be created. In some cases it is better to use the interactive plugin, which is less prone to errors.

## Support

All architectures supported by your IDA decompiler are supported.

Supported IDA versions are **IDA 8.4 and later**.

## Credits

Thalium Team, and Célian Debéthune for working on the architecture-agnostic version during his internship at Thalium.

```

`plugin/install.py`:

```py
#!/usr/bin/python3

import os
import shutil
import sys

"""
    Installs the symless plugin into your IDA plugins user directory :
    On Windows: %APPDATA%/Hex-Rays/IDA Pro
    On Linux and Mac: $HOME/.idapro


    Install: $ python3 install.py
    Uninstall: $ python3 install.py -u
"""


def usage():
    print(f"Usage: python {sys.argv[0]} [-u] [--dev]")
    print("-u => uninstall plugin")
    print("--dev => use symlinks to sync with git repo folder")


ROOT_DIR = os.path.abspath(os.path.dirname(__file__))
TO_COPY = [("symless_plugin.py", False), ("../symless", True)]


def install(where: str, symlink: bool) -> int:
    # check no installation is present
    for file, is_dir in TO_COPY:
        filepath = os.path.join(where, os.path.basename(file))
        if os.path.exists(filepath):
            print(f"Replacing existing {'directory' if is_dir else 'file'} \"{filepath}\"")
            if is_dir:
                shutil.rmtree(filepath)
            else:
                os.remove(filepath)

    # install
    for file, is_dir in TO_COPY:
        src = os.path.abspath(os.path.join(ROOT_DIR, file))
        dst = os.path.join(where, os.path.basename(file))

        if symlink:
            print(f'Linking "{dst}"')
            os.symlink(src, dst)
        else:
            print(f'Creating "{dst}"')
            if is_dir:
                shutil.copytree(src, dst, dirs_exist_ok=True)
            else:
                shutil.copy(src, dst)

    return 0


def uninstall(where: str) -> int:
    for file, is_dir in TO_COPY:
        path = os.path.join(where, os.path.basename(file))

        print(f"Deleting {path}")
        try:
            if is_dir and not os.path.islink(path):
                shutil.rmtree(path)
            else:
                os.unlink(path)
        except FileNotFoundError:
            pass

    return 0


if __name__ == "__main__":
    # find IDA installation
    if os.name == "posix":
        ida_plugins_dir = os.path.expandvars("/$HOME/.idapro/plugins")
    elif os.name == "nt":
        ida_plugins_dir = os.path.expandvars("%APPDATA%/Hex-Rays/IDA Pro/plugins")
    else:
        print(f"Could not retrieve IDA install folder on OS {os.name}")
        exit(1)

    # make sure the "plugins" dir exists
    os.makedirs(ida_plugins_dir, exist_ok=True)

    # args parsing
    do_install = True
    symlink = False
    for arg in sys.argv[1:]:
        if arg == "-u":
            do_install = False
        elif arg == "--dev":
            symlink = True
        else:
            usage()
            exit(1)

    ok = install(ida_plugins_dir, symlink) if do_install else uninstall(ida_plugins_dir)
    if ok == 0:
        print("Done")

```

`plugin/symless_plugin.py`:

```py
import base64
import collections
import importlib
import os
import pkgutil
import sys
import traceback
from typing import Collection

import idaapi

import symless
import symless.plugins as plugins
import symless.utils.utils as utils


class fixedBtn(idaapi.Form.ButtonInput):
    def __init__(self, plugin: "SymlessPlugin", form: "SymlessInfoForm"):
        super().__init__(self.reload, "0")
        self.plugin = plugin
        self.form = form

    def reload(self, code):
        idaapi.show_wait_box("Reloading Symless..")

        try:
            # terminate all extensions
            self.plugin.term()

            remove_old_modules()

            # rebind all extensions
            self.plugin.find_extensions(reload=True)

        except Exception as e:
            idaapi.hide_wait_box()
            utils.g_logger.critical(repr(e) + "\n" + traceback.format_exc())
        else:
            idaapi.hide_wait_box()
            self.form.Close(1)

    def get_tag(self):
        return "<Reload:%s%d:%s%s:%s:%s>" % (
            self.tp,
            self.id,
            "+" if self.is_relative_offset else "",
            self.width,
            self.swidth,
            ":" if self.hlp is None else self.hlp,
        )


class SymlessInfoForm(idaapi.Form):
    def __init__(self, plugin: "SymlessPlugin"):
        icon_path = os.path.join(os.path.abspath(symless.__path__[0]), "resources", "bigger_champi.png")
        with open(icon_path, "rb") as file:
            icon_b64 = base64.b64encode(file.read()).decode()

        img_html = "<img src='data:image/png;base64,%s'>" % icon_b64
        info_html = """
            <div style='text-align: center; margin: 6px; font-size: 16px;'>
                <pre style='font-size: 72px;'>Symless</pre>
                <pre style='font-size: 16px; text-align: left;'>%s<br><br>Version: <b>%.1f</b></pre>
            </div>
        """ % (
            symless.PLUGIN_DESC,
            symless.PLUGIN_VERSION,
        )

        super().__init__(
            "BUTTON YES NONE\nBUTTON CANCEL NONE\nSymless plugin\n{img}<|>{info}\n{reload}",
            {
                "img": idaapi.Form.StringLabel(img_html, tp=idaapi.Form.FT_HTML_LABEL, size=None),
                "info": idaapi.Form.StringLabel(info_html, tp=idaapi.Form.FT_HTML_LABEL, size=None),
                "reload": fixedBtn(plugin, self),
            },
        )


# Symless plugin
class SymlessPlugin(idaapi.plugin_t):
    flags = idaapi.PLUGIN_MOD | idaapi.PLUGIN_PROC  # | idaapi.PLUGIN_HIDE
    comment = "Symless interactive plugin"
    wanted_name = "Symless"
    help = ""  # not used, IDA < 7.6 compatibility
    wanted_hotkey = ""  # not used, IDA < 7.6 compatibility

    # find & initialize all extensions
    def init(self) -> idaapi.plugmod_t:
        self.ext: Collection[plugins.plugin_t] = collections.deque()
        self.find_extensions()
        return idaapi.PLUGIN_KEEP

    # find and load extensions from symless plugins folder
    def find_extensions(self, reload: bool = False):
        for mod_info in pkgutil.walk_packages(plugins.__path__, prefix="symless.plugins."):
            if mod_info.ispkg:
                continue

            spec = mod_info.module_finder.find_spec(mod_info.name)
            module = importlib.util.module_from_spec(spec)

            # module is already loaded
            if module.__name__ in sys.modules:
                module = sys.modules[module.__name__]

            # load the module
            else:
                sys.modules[module.__name__] = module
                try:
                    spec.loader.exec_module(module)
                except BaseException as e:
                    sys.modules.pop(module.__name__)
                    utils.g_logger.error(f"Error while loading extension {mod_info.name}:")
                    utils.g_logger.error(repr(e) + "\n" + traceback.format_exc())
                    continue

            # module defines an extension
            if not hasattr(module, "get_plugin"):
                continue
            ext: plugins.plugin_t = module.get_plugin()

            # notify the extension that it has been reloaded
            if reload:
                ext.reload()

            self.ext.append(ext)

    # display info panel
    def run(self, args):
        info = SymlessInfoForm(self)
        info.Compile()
        info.Execute()
        info.Free()

    # term all extensions
    def term(self):
        while len(self.ext) > 0:
            ext = self.ext.pop()
            ext.term()


def PLUGIN_ENTRY() -> idaapi.plugin_t:
    return SymlessPlugin()


# remove old symless modules from loaded modules
def remove_old_modules():
    to_remove = set()
    for k in sys.modules.keys():
        if k.startswith("symless"):
            to_remove.add(k)

    for r in to_remove:
        print(f"Removing old {r} ..")
        del sys.modules[r]

```

`run_script.py`:

```py
import os
import platform
import random
import string
import subprocess
import sys
import tempfile
from typing import List, Optional, Tuple

# max & min supported majors
MIN_MAJOR = 8
MAX_MAJOR = 9


def stderr_print(line: str):
    sys.stderr.write(line + "\n")


# remove quote from start & end of a path
# quotes can appear in env var when setting them from windows cmd
def unquote(path: str) -> str:
    if path[0] == '"' and path[-1] == '"':
        return path[1:-1]
    return path


# find IDA install on Windows
def find_ida_win() -> Optional[str]:
    # TODO : Run all over USER PATH in Windows, not only Program Files
    for major in range(MAX_MAJOR, MIN_MAJOR - 1, -1):
        for minor in range(9, 0, -1):
            current = f"C:\\Program Files\\IDA Pro {major}.{minor}"
            if os.path.exists(current):
                return current
    return None


# find IDA install on Linux
def find_ida_Linux() -> Optional[str]:
    # find in PATH
    if "PATH" in os.environ:
        for path in os.environ["PATH"].split(":"):
            if os.path.exists(os.path.join(path, "idat64")) or os.path.exists(os.path.join(path, "idat")):
                return path

    # find in default location
    for major in range(MAX_MAJOR, MIN_MAJOR - 1, -1):
        for minor in range(9, -1, -1):
            p1 = "%s/idapro-%d.%d" % (os.environ["HOME"], major, minor)
            p2 = "%s/ida-pro-%d.%d" % (os.environ["HOME"], major, minor)
            if os.path.exists(p1):
                return p1
            if os.path.exists(p2):
                return p2
    return None


# find idat executables
def find_idat() -> Tuple[Optional[str], str]:
    ida_dir = None

    # user defined IDA path
    if "IDA_DIR" in os.environ.keys():
        ida_dir = os.path.abspath(unquote(os.environ["IDA_DIR"]))
    else:
        if sys.platform == "win32":
            ida_dir = find_ida_win()
        else:
            ida_dir = find_ida_Linux()

    if ida_dir is None:
        stderr_print("Please specify an IDA installation location using IDA_DIR env or add IDA to PATH")
        return None

    else:
        print(f'Using IDA installation: "{ida_dir}"')

    suffix = ".exe" if sys.platform == "win32" else ""
    idat = os.path.join(ida_dir, "idat" + suffix)
    idat64 = os.path.join(ida_dir, "idat64" + suffix)

    if not (os.path.isfile(idat) or os.path.isfile(idat64)):
        stderr_print('Missing idat%s in "%s"' % (suffix, ida_dir))
        return None

    # earliest IDA 9 version - only idat64
    if not os.path.isfile(idat):
        return (None, idat64)

    # IDA 9 + - only idat
    if not os.path.isfile(idat64):
        return (None, idat)

    # IDA 8 or earlier
    return (idat, idat64)


# craft IDA batch command
def craft_ida_command(idat: str, idb: str, script: str, script_args: List[str]) -> Tuple[str, str]:
    exec_name = os.path.basename(idb).split(".")[0]
    log_file = tempfile.mktemp(prefix=f"{exec_name}_", suffix=".log")

    if len(script_args) == 0:
        quoted_args = ""
    else:
        quoted_args = ' \\"' + '\\" \\"'.join(script_args) + '\\"'

    cmd = f'"{idat}" -A -L"{log_file}" -S"\\"{script}\\"{quoted_args}" "{idb}"'

    return (cmd, log_file)


# run ida -B filepath
def run_ida_batchmode(idat: str, filepath: str) -> int:
    args = f'"{idat}" -B "{filepath}"'
    process = subprocess.Popen(args, shell=(platform.system() != "Windows"))

    code = process.wait()
    if code != 0:
        return code

    # remove assembler file generated by analysis.idc
    os.remove(filepath + ".asm")

    return 0


# Create .idb from 32 bits executable or .i64 from 64 bits exe
def make_idb(ida_install: tuple, filepath: str) -> Tuple[str, int]:
    if ida_install[0] and run_ida_batchmode(ida_install[0], filepath) == 0:
        return (f"{filepath}.idb", 0)

    # 32 bits analysis failed, try 64 bits mode
    code = run_ida_batchmode(ida_install[1], filepath)
    if code == 0:
        return (f"{filepath}.i64", 0)

    return (None, code)


# random string prefix to retrieve script output in IDA logs
def get_random_string(size: int) -> str:
    letters = string.ascii_lowercase
    return "".join(random.choice(letters) for i in range(size))


def is_idb(filename: str) -> bool:
    return filename.split(".")[-1] in ("i64", "idb")


def run_ida(ida_install: tuple, input_file: str, script: str, script_args: List[str]) -> bool:
    if not is_idb(input_file):
        print("Creating IDA database from binary %s" % input_file)
        (idb_file, ret_code) = make_idb(ida_install, input_file)
        if ret_code != 0:
            stderr_print(f"Could not create initial database, IDA batchmode returned {ret_code}")
            return False
    else:
        idb_file = input_file

    # no script, just generate idb
    if len(script) == 0:
        return True

    prefix = get_random_string(6)
    script_args += ["--prefix", prefix]

    idat = ida_install[1] if idb_file.endswith(".i64") else ida_install[0]
    cmd, log_file = craft_ida_command(idat, idb_file, script, script_args)

    # TODO: stderr is a dirty hack, find a better solution
    # used here to ignore these information when piping script output
    stderr_print("Running IDA script..")
    stderr_print("* IDAT  : %s" % idat)
    stderr_print("* Script: %s%s" % (script, "" if len(script_args) == 0 else ' ("%s")' % '", "'.join(script_args)))
    stderr_print("* Base  : %s" % idb_file)
    stderr_print("* Logs  : %s" % log_file)

    process = subprocess.Popen(cmd, shell=(platform.system() != "Windows"))
    code = process.wait()

    try:
        output = open(log_file, "r")
    except FileNotFoundError:
        stderr_print("[-] IDA script did not produce logs, return code: %d" % code)
        return False

    if code == 0:
        stderr_print("IDA script terminated successfully.")

        line = True
        while line:
            line = output.readline()
            if not line.startswith(prefix):
                continue

            print(line.strip()[len(prefix) :])
    else:
        stderr_print("Trace:")
        stderr_print(output.read())
        stderr_print(f"[-] Status code:\t{hex(code)}")

    output.close()

    return code == 0


def run_script(script: str, input_file: str, args: List[str] = None) -> int:
    ida_install = find_idat()
    if ida_install is None:
        return 1

    if args is None:
        args = []  # new args array, do not used the same default one between multiple calls

    return int(not run_ida(ida_install, input_file, script, args))


def usage():
    print("Usage: run_script.py <script.py> <input.i64> [args]")


def main() -> int:
    if len(sys.argv) < 3:
        usage()
        return 1

    return run_script(sys.argv[1], sys.argv[2], sys.argv[3:])


if __name__ == "__main__":
    exit(main())

```

`scripts/ctors.py`:

```py
import argparse
import inspect
import os
import re
import sys

import idaapi
import idc

# add symless dir to search path
symless_dir = os.path.abspath(os.path.join(os.path.dirname(os.path.abspath(inspect.getsourcefile(lambda: 0))), ".."))
sys.path.append(symless_dir)

import symless.model.entrypoints as entrypoints
import symless.utils.ida_utils as ida_utils

re_ctors = re.compile(r"\b((?:[\w_]+::)*)([\S ]+)::(~?)\2(?:\(|$)")


""" Debug script - Find ctors/dtors in binary """

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--prefix", type=str, default="")
    args = parser.parse_args(idc.ARGV[1:])

    # wait for autoanalysis, we'll need its results
    idaapi.auto_wait()

    families = entrypoints.get_ctors()

    i = 0
    for vtbl in families:
        print("%sFamily 0x%x:" % (args.prefix, vtbl))

        for ctor in families[vtbl]:
            fea = ctor.func.start_ea
            name = ida_utils.demangle_ea(fea)

            match = re_ctors.match(name)
            if match is None:
                if "vector deleting destructor" in name:
                    typ = "[V-DESTRUCTOR]"
                elif "scalar deleting destructor" in name:
                    typ = "[S-DESTRUCTOR]"
                else:
                    typ = "[UNKNOWN]"
            elif len(match.group(3)):
                typ = "[DESTRUCTOR]"
            else:
                typ = "[CONSTRUCTOR]"

            print("%s  %s 0x%x -> %s" % (args.prefix, typ, fea, name))
        print(args.prefix)

        i += 1

idc.qexit(0)

```

`scripts/dump.py`:

```py
import argparse

import idaapi
import idautils
import idc

""" Dump all informations found in one database (types, functions, ..) """


def report(output: str = ""):
    if len(output) == 0:
        print(g_prefix)
        return

    for i in output.splitlines():
        print("%s%s" % (g_prefix, i))


def dump_functions() -> dict:
    out = {"total": 0}

    all_fcts = [fea for fea in idautils.Functions()]
    all_fcts.sort()

    for fea in all_fcts:
        # only print user defined function types
        if not idaapi.is_userti(fea):
            continue

        name = idaapi.print_type(fea, idaapi.PRTYPE_CPP)
        if name and len(name):
            report(name)
        else:
            report("VOID[0x%x]" % fea)

        out["total"] += 1

    return out


def get_xref_type(xref: int):
    func = idaapi.get_func(xref)
    if func is not None:
        name = "%s%s" % (
            idaapi.get_short_name(func.start_ea),
            "" if xref == func.start_ea else (" + 0x%x" % (xref - func.start_ea)),
        )
        return (name, 1)

    if idaapi.is_member_id(xref):
        return (idaapi.get_member_fullname(xref), 2)

    if idaapi.get_struc(xref) is not None:
        return (idaapi.get_struc_name(xref), 4)

    name = idaapi.get_short_name(xref)

    return (name, 8)


def dump_xrefs_to(ea: int, shift: str = "", mask: int = 0xFF) -> int:
    count = 0
    for xref in idautils.XrefsTo(ea):
        name, type = get_xref_type(xref.frm)
        if (type & mask) != 0:
            count += 1
            report("%sxref: 0x%x%s" % (shift, xref.frm, (" (%s)" % name) if name else ""))

    return count


def dump_structures() -> dict:
    out = {
        "total vtables": 0,
        "total structures": 0,
        "total members": 0,
        "typed members": 0,
        "xrefs on members": 0,
        "xrefs on structs": 0,
        "xrefs on vtables": 0,
    }

    # sort structures by name
    structures = list()
    for idx, sid, name in idautils.Structs():
        structures.append((name, sid))
    structures.sort()

    for name, sid in structures:
        struc = idaapi.get_struc(sid)

        # do not dump hidden structs
        # if struc.props & idaapi.SF_HIDDEN:
        #    continue

        is_vtable = "_vtbl" in name

        if is_vtable:
            out["total vtables"] += 1
        else:
            out["total structures"] += 1

        report("struc %s:" % name)
        report("\tprops: 0x%x" % struc.props)
        report("\tsize : 0x%x" % idaapi.get_struc_size(sid))
        xref_count = dump_xrefs_to(sid, "\t", 8)
        report("\tmembers: %d" % struc.memqty)

        if is_vtable:
            out["xrefs on vtables"] += xref_count
        else:
            out["xrefs on structs"] += xref_count

        for m in struc.members:
            out["total members"] += 1

            m_name = idaapi.get_member_name(m.id)
            m_size = idaapi.get_member_size(m)

            m_type = idaapi.tinfo_t()
            if idaapi.get_member_tinfo(m_type, m):
                m_type_str = str(m_type)
            else:
                m_type_str = None

            report("\t0x%x: %s" % (m.soff, m_name))
            report("\t\tsize: 0x%x" % m_size)
            if m_type_str:
                report("\t\ttype: %s" % m_type_str)
                out["typed members"] += 1

            out["xrefs on members"] += dump_xrefs_to(m.id, "\t\t", 9)

        report()

    return out


def dump_local_types() -> dict:
    out = {"total": 0}

    idati = idaapi.get_idati()

    count = idaapi.get_ordinal_count(idati)
    if count == 0 or count == 0xFFFFFFFF:
        return

    # get all struct types
    types = list()
    for i in range(count):
        tinfo = idaapi.tinfo_t()
        if tinfo.get_numbered_type(idati, i) and tinfo.is_struct():
            types.append((i, tinfo))

    # sort by name
    types.sort(key=lambda k: str(k[1]))

    for _, tinfo in types:
        # do not print types imported as structures
        name = str(tinfo)
        if idaapi.get_struc_id(name) != idaapi.BADADDR:
            continue

        out["total"] += 1

        flags = idaapi.PRTYPE_MULTI | idaapi.PRTYPE_CPP | idaapi.PRTYPE_DEF | idaapi.PRTYPE_TYPE
        report(idaapi.print_tinfo("", 0, 0, flags, tinfo, name, ""))
        report()

    return out


if __name__ == "__main__":
    global g_prefix

    parser = argparse.ArgumentParser()
    parser.add_argument("--prefix", type=str, default="")
    args = parser.parse_args(idc.ARGV[1:])

    g_prefix = args.prefix

    seq = (
        ("Functions", dump_functions),
        ("Local types", dump_local_types),
        ("Structures", dump_structures),
    )

    report()
    for name, fct in seq:
        report("##### %s #####" % name)
        ret = fct()

        report("\n##### Statistics for %s #####" % name)
        for key, val in ret.items():
            report("%s: %d" % (key, val))
        report()

    idc.qexit(0)

```

`scripts/entries.py`:

```py
import argparse
import inspect
import os
import sys

import idaapi
import idc

# add symless dir to search path
symless_dir = os.path.abspath(os.path.join(os.path.dirname(os.path.abspath(inspect.getsourcefile(lambda: 0))), ".."))
sys.path.append(symless_dir)

import symless.allocators as allocators
import symless.model.entrypoints as entrypoints

# import symless.model.model as model

""" Debug script - Get all entrypoints (structures creations) identified in one binary """

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--prefix", type=str, default="")
    args = parser.parse_args(idc.ARGV[1:])

    idaapi.auto_wait()

    config_path = os.path.abspath(os.path.join(symless_dir, "symless", "config", "imports.csv"))

    imports = allocators.get_allocators(config_path)
    if not len(imports):
        print("%sNo allocators identified" % args.prefix)
        idc.qexit(0)

    # get initial entrypoints
    ctx = entrypoints.retrieve_entrypoints(imports)

    # build entries tree
    # model.analyze_entrypoints(ctx)

    entries = ctx.get_entrypoints()
    allocs = ctx.get_allocators()

    e_str = str(entries)
    print("%sEntrypoints:" % args.prefix)
    for line in e_str.splitlines():
        print("%s%s" % (args.prefix, line))

    print(args.prefix)

    print("%sAllocators:" % args.prefix)
    for i in allocs:
        print("%s%s" % (args.prefix, i))

idc.qexit(0)

```

`scripts/vtables.py`:

```py
import argparse
import inspect
import os
import sys

import idaapi
import idc

# add symless dir to search path
symless_dir = os.path.abspath(os.path.join(os.path.dirname(os.path.abspath(inspect.getsourcefile(lambda: 0))), ".."))
sys.path.append(symless_dir)

import symless.utils.ida_utils as ida_utils
import symless.utils.vtables as vtables

""" Debug script - Scans binary for vtables """

if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    parser.add_argument("--prefix", type=str, default="")
    args = parser.parse_args(idc.ARGV[1:])

    idaapi.auto_wait()

    stats = [0, 0]

    for vtbl in vtables.get_all_vtables():
        name = ida_utils.demangle_ea(vtbl.ea)
        print("%s0x%x (size: 0x%x) -> %s" % (args.prefix, vtbl.ea, vtbl.size(), name))

        for x in vtbl.get_loads():
            print("%s\tload @ 0x%x" % (args.prefix, x))

        stats[1] += 1
        stats[0] += 1 if "vftable" in name else 0

    print("%sTotal: %d, corrects (from symbols): %d" % (args.prefix, stats[1], stats[0]))

idc.qexit(0)

```

`symless.py`:

```py
#!/usr/bin/python3

import argparse
import os
import sys

import symless.config as config

""" IDA main """


def ida_main():
    # parse arguments
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", type=str, help="config file")
    parser.add_argument("--prefix", type=str, default="", help="log prefix")
    args = parser.parse_args(idc.ARGV[1:])
    start_analysis(args.config)


""" Command line main """


def cmd_usage():
    print(f"Usage: python {sys.argv[0]} [-c config.csv] <file(s)>")


def cmd_main():
    files = []
    root_dir = os.path.realpath(os.path.join(config.g_settings.root, ".."))
    config_path = os.path.join(root_dir, "symless", "config", "imports.csv")

    # parse arguments
    i, length = 1, len(sys.argv)
    while i < length:
        if sys.argv[i] == "-c":
            i += 1
            if i == length:
                cmd_usage()
                return
            config_path = sys.argv[i]
        else:
            files.append(sys.argv[i])
        i += 1

    if len(files) == 0:
        cmd_usage()
        return

    args = ["--config", config_path]

    runner = os.path.join(root_dir, "symless.py")
    for file in files:
        run_script(runner, os.path.abspath(file), args)


""" Symless main """

if __name__ == "__main__":
    try:
        # flake8: noqa: F401
        import idc

    except ModuleNotFoundError:
        from run_script import run_script

        cmd_main()  # script run from command line

    else:
        from symless.main import start_analysis

        ida_main()  # script run from IDA

        idc.qexit(0)

```

`symless/__init__.py`:

```py
# plugin info
PLUGIN_VERSION = 1.1
PLUGIN_DESC = "Structure reconstruction assistant"

```

`symless/allocators.py`:

```py
import enum
import re
from typing import Any, List, Tuple

import idaapi

import symless.cpustate.cpustate as cpustate
import symless.utils.ida_utils as ida_utils
import symless.utils.utils as utils

# do not consider alloc bigger than this to be object allocs
g_max_alloc = 0x4000


def valid_size(size: int):
    return size > 0 and size < g_max_alloc


class alloc_action_t(enum.Enum):  # allocator action
    STATIC_ALLOCATION = 0  # malloc(n)
    WRAPPED_ALLOCATOR = 1  # func(x) -> return malloc(x)
    UNDEFINED = 2


# a heap allocation function
class allocator_t:
    index = dict()

    def __init__(self, ea: int, type: str):
        self.ea = ea
        self.type = type
        self.index = self.next_index()

    def next_index(self) -> int:
        try:
            allocator_t.index[self.type] += 1
            return allocator_t.index[self.type]
        except KeyError:
            allocator_t.index[self.type] = 0
            return 0

    def get_name(self) -> str:
        return f"{self.type}_like_{self.index:x}"

    def get_child(self, ea: int, args: tuple) -> "allocator_t":
        child = self.__class__.__new__(self.__class__)  # is there a nicer way to do this ?
        child.__init__(ea, *args)
        return child

    # how to type the allocator once identified
    def make_type(self, func_data: idaapi.func_type_data_t):
        pass

    # what type of allocation for given state + allocation size for STATIC_ALLOCATION
    def on_call(self, state: cpustate.state_t) -> Tuple[alloc_action_t, Any]:
        return (alloc_action_t.UNDEFINED, 0)

    # for WRAPPED_ALLOCATOR action, does wrapper return value confirms it is a wrapper
    def on_wrapper_ret(self, state: cpustate.state_t, call_ea: int) -> bool:
        if isinstance(state.ret, cpustate.call_t) and state.ret.where == call_ea:
            return True

        return False

    def __hash__(self):
        return self.ea

    def __eq__(self, other):
        return isinstance(other, allocator_t) and self.ea == other.ea

    def __repr__(self):
        return f"[0x{self.ea:x}] - {ida_utils.demangle_ea(self.ea)} ({self.get_name()})"


# malloc like function, takes one size parameter and returns memory space
class malloc_like_t(allocator_t):
    def __init__(self, ea: int, size_index: int = 0):
        allocator_t.__init__(self, ea, "malloc")
        self.size_index = size_index

    def on_call(self, state: cpustate.state_t) -> Tuple[alloc_action_t, Any]:
        if len(state.call_args) <= self.size_index:
            return (alloc_action_t.UNDEFINED, 0)

        arg = state.call_args[self.size_index]
        if isinstance(arg, cpustate.arg_t):
            index = arg.idx
            return (alloc_action_t.WRAPPED_ALLOCATOR, (index,))
        elif isinstance(arg, cpustate.int_t) and valid_size(arg.get_uval()):
            return (alloc_action_t.STATIC_ALLOCATION, arg.get_uval())

        return (alloc_action_t.UNDEFINED, 0)

    def make_type(self, func_data: idaapi.func_type_data_t):
        func_data.rettype = ida_utils.void_ptr()

        tinfo = ida_utils.get_local_type("size_t")
        if tinfo.get_decltype() == idaapi.BT_UNK:
            tinfo = ida_utils.get_basic_type(idaapi.BT_INT)

        ida_utils.set_function_argument(func_data, self.size_index, tinfo, name="size")

    def __repr__(self):
        return f"malloc_like_t : [0x{self.ea:x}] - {ida_utils.demangle_ea(self.ea)} ({self.get_name()}) index : ({self.size_index})"


# calloc like allocator, takes two parameters: count & unit size
class calloc_like_t(allocator_t):
    def __init__(self, ea: int, count_index: int = 0, size_index: int = 1):
        allocator_t.__init__(self, ea, "calloc")
        self.count_index = count_index
        self.size_index = size_index

    def on_call(self, state: cpustate.state_t) -> Tuple[alloc_action_t, Any]:
        if len(state.call_args) <= max(self.size_index, self.count_index):
            return (alloc_action_t.UNDEFINED, 0)

        count_arg = state.call_args[self.count_index]
        size_arg = state.call_args[self.size_index]
        if isinstance(count_arg, cpustate.arg_t) and isinstance(size_arg, cpustate.arg_t):
            count_index = count_arg.idx
            size_index = size_arg.idx
            return (alloc_action_t.WRAPPED_ALLOCATOR, (count_index, size_index))
        elif (
            isinstance(count_arg, cpustate.int_t)
            and valid_size(count_arg.get_uval())
            and isinstance(size_arg, cpustate.int_t)
            and valid_size(size_arg.get_uval())
        ):
            size = count_arg.get_uval() * size_arg.get_uval()
            return (alloc_action_t.STATIC_ALLOCATION, size)

        return (alloc_action_t.UNDEFINED, 0)

    def make_type(self, func_data: idaapi.func_type_data_t):
        func_data.rettype = ida_utils.void_ptr()

        tinfo = ida_utils.get_local_type("size_t")
        if tinfo.get_decltype() == idaapi.BT_UNK:
            tinfo = ida_utils.get_basic_type(idaapi.BT_INT)

        ida_utils.set_function_argument(func_data, self.count_index, tinfo, name="nmemb")
        ida_utils.set_function_argument(func_data, self.size_index, tinfo, name="size")

    def __repr__(self):
        return f"calloc_like_t : [0x{self.ea:x}] - {ida_utils.demangle_ea(self.ea)} ({self.get_name()}) index : ({self.size_index})"


# realloc is just a malloc with the size parameter at index 1
class realloc_t(malloc_like_t):
    def __init__(self, ea: int, size_index: int = 1):
        allocator_t.__init__(self, ea, "realloc")
        self.size_index = size_index

    def __repr__(self):
        return f"realloc_like_t : [0x{self.ea:x}] - {ida_utils.demangle_ea(self.ea)} ({self.get_name()}) index : ({self.size_index})"


available_allocators = {"malloc": malloc_like_t, "calloc": calloc_like_t, "realloc": realloc_t}


# parse calloc(0, 1) into (calloc_like_t, [0,1])
def parse_allocator(declaration: str) -> Tuple[allocator_t, list]:
    pattern = re.compile(r"^([a-zA-Z]+)(?:\((\s*[0-9]+\s*(?:\|\s*[0-9]+\s*)*)?\))?$")
    match = pattern.match(declaration)
    if match is None:
        return (None, None)

    try:
        allocator = available_allocators[match.group(1)]
    except KeyError:
        return (None, None)

    args = list()
    if match.group(2) is not None:
        for index in match.group(2).split("|"):
            if len(index) == 0:
                continue

            try:
                args.append(int(index))
            except ValueError:
                return (None, None)

    return (allocator, args)


# reads config.csv data to find memory allocators in the binary, used as entry points
def get_allocators(config_path: str) -> List[allocator_t]:
    imports = []

    try:
        config = open(config_path)
    except FileNotFoundError as e:
        utils.g_logger.error("Can not retrieve config file (%s)" % str(e))
        return None

    i = 1
    current = config.readline()
    while current:
        current = current.strip().split("#")[0]

        if len(current) == 0 or current[0] == "#":
            pass
        else:
            keys = current.split(",")
            length = len(keys)
            if length > 3 or length < 2:
                utils.g_logger.error("%s bad syntax at line %d" % (config_path, i))
                return None

            import_type, args = parse_allocator(keys[-1].strip())
            if import_type is None:
                utils.g_logger.error(
                    '%s bad syntax for allocator type "%s" at line %d' % (config_path, keys[-1].strip(), i)
                )
                return None

            # entry point from lib import
            if length == 3:
                module_name = keys[0].strip()
                import_name = keys[1].strip()

                module = ida_utils.get_import_module_index(module_name)

                if module is None:
                    utils.g_logger.debug(
                        "import %s from module %s absent from binary (module not imported)" % (import_name, module_name)
                    )
                    pass
                else:
                    ea = ida_utils.get_import_from_module(module, import_name)
                    if ea is None:
                        utils.g_logger.debug("import %s from module %s absent from binary" % (import_name, module_name))
                    else:
                        utils.g_logger.info("retrieved entry point %s from module %s" % (import_name, module_name))

                        imports.append(import_type(ea, *args))

            # entry point as function from binary
            elif length == 2:
                func_name = keys[0].strip()

                try:
                    func_ea = int(func_name, 16)
                except ValueError:
                    func_ea = idaapi.get_name_ea(idaapi.BADADDR, func_name)

                func = idaapi.get_func(func_ea)
                if func is None or func.start_ea != func_ea:
                    utils.g_logger.error('Unable to located entry point "%s"' % func_name)
                else:
                    utils.g_logger.info('Retrieved entry point "%s"' % func_name)

                    imports.append(import_type(func.start_ea, *args))

        current = config.readline()
        i += 1

    config.close()

    return imports

```

`symless/config/__init__.py`:

```py
import inspect
import json
import os

# different log levels
LOG_LEVEL_CRITICAL = 50
LOG_LEVEL_ERROR = 40
LOG_LEVEL_WARNING = 30
LOG_LEVEL_INFO = 20
LOG_LEVEL_DEBUG = 10
LOG_LEVEL_VERBOSE_DEBUG = 5

LOG_LEVEL_DEFAULT = LOG_LEVEL_WARNING


# symless global settings
class Settings:
    def __init__(self):
        self.log_level = LOG_LEVEL_DEFAULT
        self.debug = False
        self.rebase_db = True  # set imagebase to 0 before generating structures (& names)

        # symless folder path
        self.root = os.path.realpath(os.path.join(os.path.dirname(inspect.getsourcefile(lambda: 0)), ".."))

        config_file = os.path.join(self.root, "config", "config.json")
        self.initialize(config_file)

    # initialize global config with config file
    def initialize(self, config_file: str):
        with open(config_file, "rb") as config:
            settings = json.load(config)
            for key, value in settings.items():
                self.__setattr__(key, value)
        self.debug = self.log_level <= LOG_LEVEL_DEBUG


# global settings variable
g_settings = Settings()

```

`symless/config/config.json`:

```json
{
    "log_level": 30,
    "rebase_db" : true
}

```

`symless/config/imports.csv`:

```csv
CSV Schema (1 sample row):
Headers: # List of imports / functions used as entry points for the analysis
Sample: "# format #1: module_name", " impot_name", " type"
... [53 more rows omitted]

```

`symless/conflict.py`:

```py
import collections
from typing import Collection, Dict, List, Set, Tuple

import symless.generation as generation
import symless.model as model
import symless.utils.ida_utils as ida_utils
import symless.utils.utils as utils


# when two possible fields are overlapping in a structure, select which to keep
def fields_conflicts_solver(field: generation.field_t, old_field: generation.field_t) -> bool:
    if old_field.has_type():
        if not field.has_type():
            return False

        return old_field.replace(field)

    # default: keep smallest
    return field.size <= old_field.size


# when converting from var field to field
# which field size to use, between all possibilities
def field_size_solver(field: model.field_t) -> int:
    # default policy: minimum size
    return min(field.get_size())


# define less derived structure between multiple structs
# the less derived should be the nearest from their common base
def less_derived(candidates: List[Tuple[generation.structure_t, int]]) -> Tuple[generation.structure_t, int]:
    # search for smallest struc with smallest shift applied
    candidates.sort(key=lambda i: (i[1], i[0].get_size()))
    chosen = candidates[0]

    __vftable = chosen[0].get_field(0)
    if not isinstance(__vftable, generation.vtbl_ptr_field_t):
        return chosen

    # if we still have multiple candidates left, and they are cpp classes
    # find the one with the less derived associated vtable
    for struc, shift in filter(lambda c: c[1] == chosen[1] and c[0].get_size() == chosen[0].get_size(), candidates[1:]):
        __vftable_2 = struc.get_field(0)
        if not isinstance(__vftable_2, generation.vtbl_ptr_field_t):
            continue

        if __vftable.value.get_most_derived(__vftable_2.value) == __vftable.value:
            chosen = (struc, shift)

    return chosen


# find which class a vtable belongs to
# among multiple structures referencing this vtable
def vtable_owner_solver(candidates: List[Tuple[generation.structure_t, int]]) -> Tuple[generation.structure_t, int]:
    # find less derived candidate (smallest shift and smallest size)
    candidates.sort(key=lambda i: (i[1], i[0].get_size()))
    return candidates[0]


# get groups of structures that are conflicting
# i.e they flow through the same entries (with same shift) and can be duplicated
def get_conflicting_structures(
    entries: model.entry_record_t,
) -> Collection[Set[generation.structure_t]]:
    # list of every conflict by belligerent (structure & shift)
    conflict_per_struc: Dict[Tuple[int, generation.structure_t], Set[Tuple[int, generation.structure_t]]] = dict()

    # get conflicts for each entry
    for entry in entries.get_entries():
        # do not consider ep that may not represent a structure
        lower, upper = entry.get_boundaries()
        if lower == 0 and upper <= ida_utils.get_ptr_size():
            continue

        # get conflicting strucs & shift for entry
        flow = entry.get_flow()
        shifts = set([shift for shift, _ in flow])
        conflicts = [set([j for j in filter(lambda k: k[0] == i, flow)]) for i in shifts]

        # update conflicts record
        for conflict in conflicts:
            if len(conflict) <= 1:  # no conflict
                continue

            utils.g_logger.debug(
                f"conflicting strucs for {entry.entry_id()}: ({', '.join(['[%s:0x%x]' % (struc.get_name(), shift) for shift, struc in conflict])})"
            )

            # update conflict_per_struc record
            # regroup structures conflicting on same shift as potential duplicates
            cqueue = collections.deque(conflict)
            while len(cqueue) > 0:
                current = cqueue.pop()

                if current in conflict_per_struc:
                    previous = conflict_per_struc[current]
                    cqueue.extend(previous.difference(conflict))
                    conflict.update(previous)

                conflict_per_struc[current] = conflict

    # build conflict record
    out: Collection[Set[generation.structure_t]] = collections.deque()
    for conflict in conflict_per_struc.values():
        conflicts_strucs = set([struc for _, struc in conflict])  # conflicting strucs set

        # if conflict subset exists, update it
        no_subset = True
        for existing in out:
            if conflicts_strucs.issubset(existing):  # conflict already recorded
                pass
            elif existing.issubset(conflicts_strucs):  # update conflict
                existing.update(conflicts_strucs)
            else:
                continue

            no_subset = False
            break

        # else add conflict group to record
        if no_subset:
            out.append(conflicts_strucs)

    return out


# can we consider two structures to be duplicates & merge them
def are_structures_identical(one: generation.structure_t, other: generation.structure_t) -> bool:
    i, j = 0, 0
    while i < len(one.range) and j < len(other.range):
        off_one, size_one = one.range[i][0], one.range[i][1]
        off_other, size_other = other.range[j][0], other.range[j][1]

        if off_one < off_other:
            # overlapping fields
            if off_one + size_one < off_other:
                return False

            i += 1

        elif off_one > off_other:
            # overlapping fields
            if off_other + size_other < off_one:
                return False

            j += 1

        else:
            f_field = one.get_field(off_one)
            s_field = other.get_field(off_other)

            # find most basic field
            if isinstance(f_field, s_field.__class__):
                base, oth = s_field, f_field

            elif isinstance(s_field, f_field.__class__):
                base, oth = f_field, s_field

            # the two fields have unrelated types
            else:
                return False

            # two fields types do not match
            if not base.match(oth):
                return False

            i += 1
            j += 1

    # if not at the end of both structures, they are different
    if i < len(one.range) or j < len(other.range):
        return False

    return True


# merge src struc into dst
def merge_structures(src: generation.structure_t, dst: generation.structure_t, entries: model.entry_record_t):
    utils.g_logger.info("Merging duplicated structures %s & %s" % (src.get_name(), dst.get_name()))

    # merge fields
    for field in src.get_fields():
        dst.set_field(field, fields_conflicts_solver)

    # merge root entries
    for shift, entry in src.associated_root():
        dst.associate_root(entry, shift)

    # replace associated structures in entries
    for entry in entries.get_entries():
        shift, struc = entry.get_structure()
        if struc == src:
            entry.set_structure(shift, dst)


# try to find & merge duplicated structures
def remove_dupes(entries: model.entry_record_t, structures: generation.structure_record_t):
    # find conflicting structures
    dupe_conflicts = get_conflicting_structures(entries)

    # merge duplicates
    for c in dupe_conflicts:
        conflict = list(c)

        utils.g_logger.debug("Found conflict between structures (%s)" % ", ".join([struc.get_name() for struc in c]))

        i = 0
        while i < len(conflict) - 1:
            dst = structures.get_structure(conflict[i])

            j = i + 1
            while j < len(conflict):
                src = structures.get_structure(conflict[j])

                # different strucs, to be merged
                if dst != src and are_structures_identical(src, dst):
                    merge_structures(src, dst, entries)
                    structures.replace_by(src, dst)
                    del conflict[j]
                    continue

                j += 1

            i += 1

```

`symless/cpustate/__init__.py`:

```py
import copy
import enum
from typing import Collection, Dict, Generator, List, Optional

import ida_hexrays
import idaapi

import symless.utils.ida_utils as ida_utils
import symless.utils.utils as utils

########################
# CPU state definition #
########################


# abstract operand - define a micro-operand type & possible value
# use to track values propagation between variables
class absop_t:
    # should this operand value be transfered from a caller to a callee as an arg
    def should_dive(self) -> bool:
        return True

    def __eq__(self, other) -> bool:
        raise Exception('Class "%s" should implement __eq__()' % self.__class__.__name__)

    def __hash__(self) -> int:
        raise Exception('Class "%s" should implement __hash__()' % self.__class__.__name__)


# return value of an unknown call
class call_t(absop_t):
    def __init__(self, arg: int, where: int):
        self.arg = arg
        self.where = where

    def __eq__(self, other) -> bool:
        return isinstance(other, call_t) and self.where == other.where and self.arg == other.arg

    def __hash__(self) -> int:
        return self.where

    def __repr__(self):
        return f"call:0x{self.arg:x}@0x{self.where:x}"


# (unknown) function argument operand
class arg_t(absop_t):
    def __init__(self, idx: int):
        self.idx = idx

    def should_dive(self) -> bool:
        return False  # one caller arg is not a callee arg

    def __eq__(self, other) -> bool:
        return isinstance(other, arg_t) and self.idx == other.idx

    def __hash__(self) -> int:
        return self.idx

    def __repr__(self):
        return "arg%d" % self.idx


# shifted buffer
class buff_t(absop_t):
    def __init__(self, shift: int = 0):
        self.shift = shift

    def shift_by(self, add: int, size: int) -> "buff_t":
        out = copy.copy(self)
        out.shift = utils.to_c_integer(out.shift + add, size)
        return out


# a pointer dereference (ex: access to an object's field)
class deref_t(absop_t):
    def __init__(self, ptr: Optional[absop_t], size: int):
        self.ptr = ptr  # pointer beeing dereferenced
        self.size = size

    def __eq__(self, other) -> bool:
        return isinstance(other, deref_t) and self.ptr == other.ptr and self.size == other.size

    def __hash__(self) -> int:
        return hash((self.ptr, self.size))

    def __repr__(self):
        return f"[{self.ptr}:{self.size:#x}]"


# structure pointer
class sid_t(buff_t):
    def __init__(self, sid, shift=0):
        super().__init__(shift)
        self.sid = sid

    def should_dive(self) -> bool:
        return False  # sid represents an entrypoint -> local to a function

    def __eq__(self, other) -> bool:
        return isinstance(other, sid_t) and self.sid == other.sid and self.shift == other.shift

    def __hash__(self) -> int:
        return hash((self.sid, self.shift))

    def __repr__(self):
        return f"sid{self.sid:x}+0x{self.shift:x}"


# immediate operand, applies to the same operation than buff_t
class int_t(buff_t):
    def __init__(self, val: int, sizeof: int):
        super().__init__(val)

        self.size = sizeof
        self.shift = utils.to_c_integer(self.shift, self.size)

    def get_val(self) -> int:
        return self.shift

    def get_uval(self) -> int:  # unsigned value
        return utils.to_c_integer(self.shift, self.size, False)

    def __eq__(self, other) -> bool:
        return isinstance(other, int_t) and self.shift == other.shift and self.size == other.size

    def __hash__(self) -> int:
        return hash((self.shift, self.size))

    def __repr__(self):
        return f"int{self.size*8}:0x{self.get_uval():x}"


# a memory address or a value read @ addr
class mem_t(int_t):
    def __init__(self, value: int, addr: int, sizeof: int):
        super().__init__(value, sizeof)
        self.addr = addr

    def __repr__(self):
        return f"mem:0x{self.addr:x}:0x{self.get_uval():x}"


# memory write
class write_t:
    def __init__(self, ea: int, target: Optional[absop_t], size: int, value: Optional[absop_t]):
        self.ea = ea  # ea of the write
        self.target = target  # write dst
        self.size = size  # write size
        self.value = value  # written value

    def __repr__(self):
        return f"{self.ea:#x} u{self.size*8}[{self.target}]={self.value}"


# memory read
class read_t:
    def __init__(self, ea: int, target: Optional[absop_t], size: int, dst: ida_hexrays.mop_t):
        self.ea = ea  # ea of the read
        self.target = target  # read src
        self.size = size  # read size
        self.dst = dst  # dst operand of the read, no copy

    def __repr__(self):
        dstname = (
            ida_hexrays.get_mreg_name(self.dst.r, self.size)
            if self.dst.t == ida_hexrays.mop_r
            else f"stk:{self.dst.s.off:x}"
        )
        return f"{self.ea:#x} {dstname}=u{self.size*8}[{self.target}]"


# memory access
class access_t:
    def __init__(self, ea: int, target: Optional[absop_t], loc: idaapi.mop_t, size: int):
        self.ea = ea  # ea for the access
        self.target = target  # target beeing accessed
        self.size = size  # access size
        self.loc = loc  # target operand, no copy it should not get freed

    def __repr__(self):
        return f"{self.ea:#x} u{self.size*8}[{self.target}]"


# a visited function
class function_t:
    def __init__(self, mba: ida_hexrays.mba_t):
        self.ea = mba.entry_ea

        # location of function's ret code
        self.retloc: Optional[ida_hexrays.vdloc_t] = None

        # location of function's arguments
        self.argloc: Collection[ida_hexrays.vdloc_t] = list()

        # tinfo for function, force decompile for accurate arguments count
        finfo = ida_utils.get_fct_type(self.ea, True)
        if not finfo:
            return

        fdata = idaapi.func_type_data_t()
        if not finfo.get_func_details(fdata):
            utils.g_logger.warning(f"No func_details for fea {self.ea:#x}")
            return

        # update retloc & arglocs
        if fdata.retloc.atype() != idaapi.ALOC_NONE:
            self.retloc = mba.idaloc2vd(fdata.retloc, ida_utils.get_ptr_size())

        for arg in fdata:
            self.argloc.append(mba.idaloc2vd(arg.argloc, ida_utils.get_ptr_size()))

    def get_args_count(self) -> int:
        return len(self.argloc)

    def get_retloc(self) -> Optional[ida_hexrays.vdloc_t]:
        return self.retloc

    def get_argloc(self, idx: int) -> Optional[ida_hexrays.vdloc_t]:
        if idx < self.get_args_count():
            return self.argloc[idx]
        return None

    def __repr__(self):
        return f"fct {hex(self.ea)} ({self.get_args_count()} args)"


# types for state last processed instruction
class last_insn_type_t(enum.Enum):
    LAST_INSN_ANY = 0
    LAST_INSN_RET = 1
    LAST_INSN_CALL = 2


# a cpu state (stack, registers (variables), ..)
class state_t:
    def __init__(self, mba: ida_hexrays.mba_t, fct: Optional[function_t]):
        self.mba = mba  # microcode where the propagation takes place
        self.fct = fct  # owning function's model

        # type of the last processed instruction
        # we mostly care about function calls & ret
        self.last_insn_type: last_insn_type_t = last_insn_type_t.LAST_INSN_ANY

        # record current micro registers values (mreg_t: value)
        self.registers: Dict[int, absop_t] = {}

        # record current stack variables values (index: value)
        self.locals: Dict[int, absop_t] = {}

        self.writes: List[write_t] = []  # writes performed by last insn
        self.reads: List[read_t] = []  # reads performed by last insn
        self.accesses: List[access_t] = []  # memory accesses performed by last insn

        self.call_to: Optional[idaapi.func_t] = None  # current call target
        self.call_args: List[Optional[absop_t]] = []  # arguments for current call insn

        self.ret: Optional[absop_t] = None  # current ret value

    # start ea for function in which we propagate
    def get_fea(self) -> int:
        return self.fct.ea

    # get value for given mreg_t
    def get_register(self, mreg: int) -> Optional[absop_t]:
        return self.registers.get(mreg)

    # set value for mreg_t
    def set_register(self, mreg: int, value: Optional[absop_t]):
        if value is not None:
            self.registers[mreg] = value
        else:
            self.drop_register(mreg)

    # drop recorded value for mreg_t
    def drop_register(self, mreg: int):
        self.registers.pop(mreg, None)

    # get value for given stack variable
    def get_local(self, idx: int) -> Optional[absop_t]:
        return self.locals.get(idx)

    # set value for stack variable
    def set_local(self, idx: int, value: Optional[absop_t]):
        if value is not None:
            self.locals[idx] = value
        else:
            self.drop_local(idx)

    # drop recorded stack variable
    def drop_local(self, idx: int):
        self.locals.pop(idx, None)

    # get value for given micro operand
    def get_var_from_mop(self, mop: ida_hexrays.mop_t) -> Optional[absop_t]:
        if mop.t == ida_hexrays.mop_r:
            return self.get_register(mop.r)
        if mop.t == ida_hexrays.mop_S:
            return self.get_local(mop.s.off)
        utils.g_logger.warning(f"{ida_utils.g_mopt_name[mop.t]} operands not handled")
        return None

    # set value for given micro operand
    def set_var_from_mop(self, mop: ida_hexrays.mop_t, value: Optional[absop_t]):
        if mop.t == ida_hexrays.mop_r:
            self.set_register(mop.r, value)
        elif mop.t == ida_hexrays.mop_S:
            self.set_local(mop.s.off, value)
        else:
            utils.g_logger.error(f"{ida_utils.g_mopt_name[mop.t]} operands not handled")

    # drop var from given micro operand
    def drop_var_from_mop(self, mop: ida_hexrays.mop_t):
        if mop.t == ida_hexrays.mop_r:
            self.drop_register(mop.r)
        elif mop.t == ida_hexrays.mop_S:
            self.drop_local(mop.s.off)
        else:
            utils.g_logger.info(f"{ida_utils.g_mopt_name[mop.t]} operands not handled")

    # get value at the specified vd location (stack or register)
    def get_var_from_loc(self, loc: ida_hexrays.vdloc_t) -> Optional[absop_t]:
        if loc.is_reg1():
            return self.get_register(loc.reg1())
        if loc.is_stkoff():
            return self.get_local(loc.stkoff())
        return None

    # set value at the specified vd location (stack or register)
    def set_var_from_loc(self, loc: ida_hexrays.vdloc_t, value: Optional[absop_t]):
        if loc.is_reg1():
            self.set_register(loc.reg1(), value)
        elif loc.is_stkoff():
            self.set_local(loc.stkoff(), value)

    # drop recorded values for kregs used to pass results between inlined minsns
    def drop_kregs(self):
        for kreg in self.mba.tmp_result_kregs:
            self.drop_register(kreg)
        self.drop_register(self.mba.call_result_kreg)

    def get_vars(self) -> Generator[absop_t, None, None]:
        for var in self.registers.values():
            yield var
        for var in self.locals.values():
            yield var

    def get_nb_types(self, wanted_type) -> int:
        ret = 0
        for var in self.get_vars():
            ret += int(isinstance(var, wanted_type))
        return ret

    # reset information about current insn
    def reset(self):
        self.last_insn_type = last_insn_type_t.LAST_INSN_ANY
        self.writes.clear()
        self.reads.clear()
        self.accesses.clear()
        self.call_to = None
        self.call_args.clear()
        self.ret = None

    # copy persistent content into another state
    def copy(self) -> "state_t":
        out = state_t(self.mba, self.fct)
        out.registers = copy.copy(self.registers)
        out.locals = copy.copy(self.locals)
        return out

    # save write
    def write_to(self, ea: int, target: Optional[absop_t], loc: idaapi.mop_t, size: int, value: Optional[absop_t]):
        self.access_to(ea, target, loc, size)
        self.writes.append(write_t(ea, target, size, value))

    # save read
    def read_from(self, ea: int, target: Optional[absop_t], loc: idaapi.mop_t, size: int, dst: ida_hexrays.mop_t):
        self.access_to(ea, target, loc, size)
        self.reads.append(read_t(ea, target, size, dst))

    # save access
    def access_to(self, ea: int, target: Optional[absop_t], loc: idaapi.mop_t, size: int):
        self.accesses.append(access_t(ea, target, loc, size))

    # state contains call info from last call instruction
    def has_call_info(self) -> bool:
        return self.last_insn_type == last_insn_type_t.LAST_INSN_CALL

    # state contains ret info from last function ret
    def has_ret_info(self) -> bool:
        return self.last_insn_type == last_insn_type_t.LAST_INSN_RET

    # cpu state representation
    def __repr__(self) -> str:
        regs = ", ".join([f"{idaapi.get_mreg_name(r, 8)}({v})" for r, v in self.registers.items()])
        lcls = ", ".join([f"{loc:#x}({val})" for loc, val in sorted(self.locals.items(), key=lambda k: k[0])])
        return f"[regs: {regs}], [stack: {lcls}]"

```

`symless/cpustate/arch.py`:

```py
import idaapi


def is_arch_supported() -> bool:
    return is_proc_supported()


def is_proc_supported() -> bool:
    # name = idaapi.inf_get_procname()
    return True  # every arch should be supported by microcode


def get_proc_name() -> str:
    return idaapi.inf_get_procname()

```

`symless/cpustate/cpustate.py`:

```py
from collections import deque
from collections.abc import Callable
from typing import Collection, Dict, Generator, List, Set, Tuple

import ida_hexrays
import idaapi

import symless.config as config
import symless.utils.ida_utils as ida_utils
import symless.utils.utils as utils
from symless.cpustate import *

# max functions depth to propagate a structure
MAX_PROPAGATION_RECURSION = 100


# handles mov (mop_r | mop_S), (mop_r | mop_S)
def handle_mov_var_var(state: state_t, insn: ida_hexrays.minsn_t):
    v = state.get_var_from_mop(insn.l)
    state.set_var_from_mop(insn.d, v)


# handles mov mop_n, (mop_r | mop_S)
def handle_mov_imm_var(state: state_t, insn: ida_hexrays.minsn_t):
    v = int_t(insn.l.nnn.value, insn.d.size)
    state.set_var_from_mop(insn.d, v)


# handles mov mop_v, (mop_r | mop_S)
def handle_mov_gbl_var(state: state_t, insn: ida_hexrays.minsn_t):
    gvalue = ida_utils.get_nb_bytes(insn.l.g, insn.d.size)
    if gvalue is None:
        return state.drop_var_from_mop(insn.d)
    v = mem_t(gvalue, insn.l.g, insn.d.size)
    state.set_var_from_mop(insn.d, v)


# handles mov mop_a, (mop_r | mop_S)
def handle_mov_addr_var(state: state_t, insn: ida_hexrays.minsn_t):
    if insn.l.a.t != ida_hexrays.mop_v:  # mop_l, mop_S or mop_r
        return state.drop_var_from_mop(insn.d)
    v = mem_t(insn.l.a.g, insn.l.a.g, insn.d.size)
    state.set_var_from_mop(insn.d, v)


# handles stx (mop_r | mop_S), mop_r, (mop_r | mop_S)
# note: sel register is ignored
def handle_stx_var_var(state: state_t, insn: ida_hexrays.minsn_t):
    dst = state.get_var_from_mop(insn.d)
    # if not isinstance(dst, buff_t):  # stx to unknown
    #     return

    v = state.get_var_from_mop(insn.l)
    state.write_to(insn.ea, dst, insn.d, insn.l.size, v)


# handles stx mop_n, mop_r, (mop_r | mop_S)
# note: sel register is ignored
def handle_stx_imm_var(state: state_t, insn: ida_hexrays.minsn_t):
    dst = state.get_var_from_mop(insn.d)
    # if not isinstance(dst, buff_t):  # stx to unknown
    #     return

    v = int_t(insn.l.nnn.value, insn.l.size)
    state.write_to(insn.ea, dst, insn.d, insn.l.size, v)


# handles stx mop_v, mop_r, (mop_r | mop_S)
# note: sel register is ignored
def handle_stx_gbl_var(state: state_t, insn: ida_hexrays.minsn_t):
    dst = state.get_var_from_mop(insn.d)
    # if not isinstance(dst, buff_t):  # stx to unknown
    #     return

    gvalue = ida_utils.get_nb_bytes(insn.l.g, insn.l.size)
    if gvalue is not None:
        v = mem_t(gvalue, insn.l.g, insn.l.size)
        state.write_to(insn.ea, dst, insn.d, insn.l.size, v)


# handles stx mop_a, mop_r, (mop_r | mop_S)
# note: sel register is ignored
def handle_stx_addr_var(state: state_t, insn: ida_hexrays.minsn_t):
    dst = state.get_var_from_mop(insn.d)
    # if not isinstance(dst, buff_t):  # stx to unknown
    #     return

    if insn.l.a.t != ida_hexrays.mop_v:  # mop_l, mop_S or mop_r
        return
    v = mem_t(insn.l.a.g, insn.l.a.g, insn.l.size)
    state.write_to(insn.ea, dst, insn.d, insn.l.size, v)


# handles ldx mop_r, (mop_r | mop_S), (mop_r | mop_S)
# note: sel register is ignored
def handle_ldx_var_var(state: state_t, insn: ida_hexrays.minsn_t):
    src = state.get_var_from_mop(insn.r)
    state.read_from(insn.ea, src, insn.r, insn.d.size, insn.d)  # record read

    # set dst mop value
    deref = deref_t(src, insn.d.size)  # default : unknown access
    if isinstance(src, mem_t):
        v = ida_utils.get_nb_bytes(src.get_uval(), insn.d.size)  # try getting read value from memory
        deref = mem_t(v, src.get_uval(), insn.d.size) if v is not None else deref
    state.set_var_from_mop(insn.d, deref)


# handles xdu (mop_r | mop_S), (mop_r | mop_S)
def handle_xdu_var_var(state: state_t, insn: ida_hexrays.minsn_t):
    assert insn.l.size < insn.d.size

    src = state.get_var_from_mop(insn.l)
    if not isinstance(src, int_t):  # only makes sense to extend int
        return state.drop_var_from_mop(insn.d)

    v = copy.copy(src)
    v.size = insn.d.size
    state.set_var_from_mop(insn.d, v)


# handles xdu mop_n, (mop_r | mop_S)
def handle_xdu_imm_var(state: state_t, insn: ida_hexrays.minsn_t):
    handle_mov_imm_var(state, insn)


# handles xds (mop_r | mop_S), (mop_r | mop_S)
def handle_xds_var_var(state: state_t, insn: ida_hexrays.minsn_t):
    handle_xdu_var_var(state, insn)  # we do not differenciate signed / unsigned (should we ?)


# handles xds mop_n, (mop_r | mop_S)
def handle_xds_imm_var(state: state_t, insn: ida_hexrays.minsn_t):
    handle_xdu_imm_var(state, insn)


# handles call mop_v, (mop_f | mop_z)
def handle_call(state: state_t, insn: ida_hexrays.minsn_t):
    state.last_insn_type = last_insn_type_t.LAST_INSN_CALL

    # resolve call arguments
    if insn.d.t == ida_hexrays.mop_f:
        # assert(insn.l.g == insn.d.f.callee)  # insn.d.f.callee is not always resolved

        # we should not have non-flattened mop_d in the args list
        assert not any([i.t == ida_hexrays.mop_d for i in insn.d.f.args])

        state.call_args.extend([state.get_var_from_mop(i) for i in insn.d.f.args])
        utils.g_logger.debug(f"call site {insn.ea:#x} : {len(state.call_args)} argument(s)")

    # try to resolve callee
    callee = idaapi.get_func(insn.l.g)
    if callee is None or callee.start_ea != insn.l.g:
        return

    utils.g_logger.debug(f"call @ {insn.ea:#x} resolved to function {callee.start_ea:#x}")
    state.call_to = callee


# handles icall mop_r, mop_r, (mop_f | mop_z)
# note: sel register is ignored
def handle_icall(state: state_t, insn: ida_hexrays.minsn_t):
    state.last_insn_type = last_insn_type_t.LAST_INSN_CALL

    # resolve call arguments
    if insn.d.t == ida_hexrays.mop_f:
        assert not any([i.t == ida_hexrays.mop_d for i in insn.d.f.args])

        state.call_args.extend([state.get_var_from_mop(i) for i in insn.d.f.args])
        utils.g_logger.debug(f"icall site {insn.ea:#x} : {len(state.call_args)} argument(s)")

    # try to resolve callee
    off = state.get_var_from_mop(insn.r)
    if not isinstance(off, mem_t):
        return

    callee = idaapi.get_func(off.get_uval())
    if callee is None or callee.start_ea != off.get_uval():
        return

    utils.g_logger.debug(f"icall @ {insn.ea:#x} resolved to function {callee.start_ea:#x}")
    state.call_to = callee


# special case for ret handling
# there are no micro-insn for a ret
def handle_ret(state: state_t) -> state_t:
    state.reset()

    state.last_insn_type = last_insn_type_t.LAST_INSN_RET

    retloc = state.fct.get_retloc()
    if retloc is None:
        return state

    state.ret = state.get_var_from_loc(retloc)

    return state


# handles add (mop_r | mop_S), mop_n, (mop_r | mop_S)
def handle_add_var_imm(state: state_t, insn: ida_hexrays.minsn_t, sign: int = 1):
    v = state.get_var_from_mop(insn.l)
    if not isinstance(v, buff_t):
        return state.drop_var_from_mop(insn.d)

    shifted_v = v.shift_by(sign * insn.r.nnn.value, insn.r.size)
    state.set_var_from_mop(insn.d, shifted_v)

    # this add can be a lea we need to type
    # register an access for a field of size 0 (size is unknown)
    state.access_to(insn.ea, shifted_v, insn.l, 0)


# handles add (mop_r | mop_S), (mop_r | mop_S), (mop_r | mop_S)
def handle_add_var_var(state: state_t, insn: ida_hexrays.minsn_t, sign: int = 1):
    v = state.get_var_from_mop(insn.l)
    v2 = state.get_var_from_mop(insn.r)
    if not isinstance(v, buff_t) or not isinstance(v2, int_t):
        return state.drop_var_from_mop(insn.d)

    shifted_v = v.shift_by(sign * v2.get_val(), insn.r.size)
    state.set_var_from_mop(insn.d, shifted_v)

    state.access_to(insn.ea, shifted_v, insn.l, 0)  # dummy access


# handles sub (mop_r | mop_S), mop_n, (mop_r | mop_S)
def handle_sub_var_imm(state: state_t, insn: ida_hexrays.minsn_t):
    handle_add_var_imm(state, insn, -1)


# handles sub (mop_r | mop_S), (mop_r | mop_S), (mop_r | mop_S)
def handle_sub_var_var(state: state_t, insn: ida_hexrays.minsn_t):
    handle_add_var_var(state, insn, -1)


# handlers per instructions types
g_per_minsn_handlers = {
    ida_hexrays.m_mov: (
        # mov rax, rcx
        (
            (ida_hexrays.mop_r, ida_hexrays.mop_S),
            (ida_hexrays.mop_z,),
            (ida_hexrays.mop_r, ida_hexrays.mop_S),
            handle_mov_var_var,
        ),
        # mov #0, rax
        ((ida_hexrays.mop_n,), (ida_hexrays.mop_z,), (ida_hexrays.mop_r, ida_hexrays.mop_S), handle_mov_imm_var),
        # mov dword_0, rax
        ((ida_hexrays.mop_v,), (ida_hexrays.mop_z,), (ida_hexrays.mop_r, ida_hexrays.mop_S), handle_mov_gbl_var),
        # mov &dword_0, rax
        ((ida_hexrays.mop_a,), (ida_hexrays.mop_z,), (ida_hexrays.mop_r, ida_hexrays.mop_S), handle_mov_addr_var),
    ),
    ida_hexrays.m_stx: (
        # stx rax, ds, rcx
        (
            (ida_hexrays.mop_r, ida_hexrays.mop_S),
            (ida_hexrays.mop_r,),
            (ida_hexrays.mop_r, ida_hexrays.mop_S),
            handle_stx_var_var,
        ),
        # stx #0, ds, rcx
        ((ida_hexrays.mop_n,), (ida_hexrays.mop_r,), (ida_hexrays.mop_r, ida_hexrays.mop_S), handle_stx_imm_var),
        # stx dword_0, ds, rcx
        ((ida_hexrays.mop_v,), (ida_hexrays.mop_r,), (ida_hexrays.mop_r, ida_hexrays.mop_S), handle_stx_gbl_var),
        # stx &dword_0, ds, rcx
        ((ida_hexrays.mop_a,), (ida_hexrays.mop_r,), (ida_hexrays.mop_r, ida_hexrays.mop_S), handle_stx_addr_var),
    ),
    ida_hexrays.m_ldx: (
        # ldx ds, rax, rcx
        (
            (ida_hexrays.mop_r,),
            (ida_hexrays.mop_r, ida_hexrays.mop_S),
            (ida_hexrays.mop_r, ida_hexrays.mop_S),
            handle_ldx_var_var,
        ),
    ),
    ida_hexrays.m_xdu: (
        # xdu esi, rsi
        (
            (ida_hexrays.mop_r, ida_hexrays.mop_S),
            (ida_hexrays.mop_z,),
            (ida_hexrays.mop_r, ida_hexrays.mop_S),
            handle_xdu_var_var,
        ),
        # xdu #0, rsi
        ((ida_hexrays.mop_n,), (ida_hexrays.mop_z,), (ida_hexrays.mop_r, ida_hexrays.mop_S), handle_xdu_imm_var),
    ),
    ida_hexrays.m_xds: (
        # xds esi, rsi
        (
            (ida_hexrays.mop_r, ida_hexrays.mop_S),
            (ida_hexrays.mop_z,),
            (ida_hexrays.mop_r, ida_hexrays.mop_S),
            handle_xds_var_var,
        ),
        # xds #0, rsi
        ((ida_hexrays.mop_n,), (ida_hexrays.mop_z,), (ida_hexrays.mop_r, ida_hexrays.mop_S), handle_xds_imm_var),
    ),
    ida_hexrays.m_call: (
        # call sub_0, (arg1, arg2, ..)
        ((ida_hexrays.mop_v,), (ida_hexrays.mop_z,), (ida_hexrays.mop_f, ida_hexrays.mop_z), handle_call),
    ),
    ida_hexrays.m_icall: (
        # icall cs, x16, (arg1, arg2, ..)
        ((ida_hexrays.mop_r,), (ida_hexrays.mop_r,), (ida_hexrays.mop_f, ida_hexrays.mop_z), handle_icall),
    ),
    ida_hexrays.m_add: (
        # add rax, #0, rax
        (
            (ida_hexrays.mop_r, ida_hexrays.mop_S),
            (ida_hexrays.mop_n,),
            (ida_hexrays.mop_r, ida_hexrays.mop_S),
            handle_add_var_imm,
        ),
        # add rax, rcx, rax
        (
            (ida_hexrays.mop_r, ida_hexrays.mop_S),
            (ida_hexrays.mop_r, ida_hexrays.mop_S),
            (ida_hexrays.mop_r, ida_hexrays.mop_S),
            handle_add_var_var,
        ),
    ),
    ida_hexrays.m_sub: (
        # sub rax, #0, rax
        (
            (ida_hexrays.mop_r, ida_hexrays.mop_S),
            (ida_hexrays.mop_n,),
            (ida_hexrays.mop_r, ida_hexrays.mop_S),
            handle_sub_var_imm,
        ),
        # sub rax, rcx, rax
        (
            (ida_hexrays.mop_r, ida_hexrays.mop_S),
            (ida_hexrays.mop_r, ida_hexrays.mop_S),
            (ida_hexrays.mop_r, ida_hexrays.mop_S),
            handle_sub_var_var,
        ),
    ),
}


def get_handler_for_insn(insn: ida_hexrays.minsn_t) -> Optional[Callable[[state_t, ida_hexrays.minsn_t], None]]:
    family = g_per_minsn_handlers.get(insn.opcode, tuple())

    for lft, rgt, dst, handler in family:
        if insn.l.t in lft and insn.r.t in rgt and insn.d.t in dst:
            return handler

    return None


# debug: pretty print current state and insn
def dbg_dump_state_insn(insn: ida_hexrays.minsn_t, state: state_t):
    if utils.g_logger.level > config.LOG_LEVEL_VERBOSE_DEBUG:
        return

    utils.g_logger.log(config.LOG_LEVEL_VERBOSE_DEBUG, f"<----- insn & state @ {insn.ea:#x} ----->")
    utils.g_logger.log(config.LOG_LEVEL_VERBOSE_DEBUG, f"insn: {ida_utils.insn_str_full(insn)}")
    utils.g_logger.log(config.LOG_LEVEL_VERBOSE_DEBUG, f"state: {state}")


# divide a microinstruction into the subinstructions composing it
# returned instructions are ordered from first to last executed
# + patch instructions to use special kreg to transfer results
# note: this does not handle mop_d in mop_f arguments list
def flatten_minsn(minsn: ida_hexrays.minsn_t, mba: ida_hexrays.mba_t) -> Collection[ida_hexrays.minsn_t]:
    subs = deque()
    used_kregs = deque()

    # always copy, minsn in IDA Python 8.4 have a tendency to get freed prematurely. TODO: why ?
    # mk_copy &= any([(op.t == ida_hexrays.mop_d) for op in (minsn.l, minsn.r, minsn.d)])
    to_patch = ida_hexrays.minsn_t(minsn)

    # search operands for sub instructions
    for num_op in ("l", "r", "d"):
        op = getattr(to_patch, num_op)
        if op.t != ida_hexrays.mop_d:  # is op a subinsn
            continue

        # sub ret value is used as insn operand
        if op.d.d.t == ida_hexrays.mop_z:
            sub = ida_hexrays.minsn_t(op.d)  # copy to patch

            # kreg to use for transfering sub ret to insn
            kreg = mba.tmp_result_kregs.pop()
            used_kregs.append(kreg)
            krop = ida_hexrays.mop_t(kreg, op.size)  # make mop_r

            # sub ret to kreg
            sub.d = krop

            # sub may also contain sub instructions
            subs.extend(flatten_minsn(sub, mba))

        # sub-insn does not return a value (m_call)
        else:
            # insn should read call ret from call_result_kreg
            # call_result_kreg is set by flow_in_callee
            krop = ida_hexrays.mop_t(mba.call_result_kreg, op.size)

            subs.extend(flatten_minsn(op.d, mba))

        # replace minsn original operand with kreg
        setattr(to_patch, num_op, krop)

    # release used kregs
    mba.tmp_result_kregs.extend(used_kregs)

    subs.append(to_patch)
    return subs


# process one instruction & update current state
def process_instruction(state: state_t, insn: ida_hexrays.minsn_t):
    # reset previous instruction state
    state.reset()

    # modify the current state according to the insn
    handler = get_handler_for_insn(insn)
    if handler is None:
        utils.g_logger.log(config.LOG_LEVEL_VERBOSE_DEBUG, f"unsupported insn @ {insn.ea:#x}")
        state.drop_var_from_mop(insn.d)
    else:
        handler(state, insn)

    # dump the new state
    dbg_dump_state_insn(insn, state)


# select most interesting state (most sid_t, call_t)
def select_state(states: List[state_t]) -> state_t:
    states.sort(key=lambda e: (e.get_nb_types(sid_t), e.get_nb_types(call_t)), reverse=True)
    return states[0]


# get the starting state for a basic block
# if many states are possible, select the one with the most info in it
def get_previous_state(block: ida_hexrays.mblock_t, prev_states: Dict[int, state_t]) -> state_t:
    npred = block.npred()
    initial = prev_states[idaapi.BADADDR]

    # get all candidates for previous state
    states = []
    for i in range(npred):
        prev = block.pred(i)
        if prev in prev_states:
            states.append(prev_states[prev])

    if len(states) == 0:
        return state_t(initial.mba, initial.fct)

    return select_state(states).copy()


# next node to visit from given list
def pop_node(nodes: Collection[Tuple[int, Set[int]]], visited: Set[int]) -> int:
    # default: next node in graph flow
    idx = 0

    # find a block with all its predecessor visited
    sel = [i for i, (_, preds) in enumerate(nodes) if len(preds.difference(visited)) == 0]

    if len(sel):
        idx = sel[0]

    # find first node in nodes with a visited pred
    else:
        sel = [i for i, (_, preds) in enumerate(nodes) if len(visited.intersection(preds)) > 0]

        if len(sel):
            idx = sel[0]

    node = nodes[idx][0]
    visited.add(node)  # update visited
    del nodes[idx]  # remove node from list

    return node


def walk_topological(mba: ida_hexrays.mba_t) -> Generator[int, None, None]:
    # generate a list of nodes with predecessors
    nodes: Collection[Tuple[int, Set[int]]] = list()

    cur: ida_hexrays.mblock_t = mba.blocks
    while cur:
        # avoid empty blocks (head, tail & other purged blocks)
        if not cur.empty():
            preds = set(cur.pred(i) for i in range(cur.npred()) if not mba.get_mblock(cur.pred(i)).empty())
            nodes.append((cur.serial, preds))
        cur = cur.nextb

    visited: Set[int] = set()
    while len(nodes):
        yield pop_node(nodes, visited)


# Injector into state_t
class injector_t:
    def __init__(self, callback=None, when: int = 0):
        self.callback = callback  # callback(state: state_t, ea: int, sub_ea: int, before_update: bool)
        self.when = when  # when & 1 -> inject before, when & 2 -> inject after

    # inject value before processing current instruction
    def inject_before(self, state: state_t, ea: int, sub_ea: int):
        if self.when & 1:
            self.callback(state, ea, sub_ea, True)

    # inject value after the current instruction has been processed
    def inject_after(self, state: state_t, ea: int, sub_ea: int):
        if self.when & 2:
            self.callback(state, ea, sub_ea, False)


# should_propagate default callback
def always_propagate(fct: function_t, state: state_t) -> bool:
    return True


# data flow control parameters
# used to control propagation & retrieve information
class dflow_ctrl_t:
    def __init__(
        self,
        injector: injector_t = injector_t(),
        dive_cb=always_propagate,
        depth: int = MAX_PROPAGATION_RECURSION,
    ):
        self.injector = injector  # state injector
        self.visited: Dict[int, function_t] = dict()  # visited functions

        self.depth = depth  # current (reverse) depth
        self.max_depth = depth  # maximum depth to reach

        self.dive_cb = dive_cb  # callback deciding whether or not to dive into callee

    # is there a potential new state we need to visit
    def should_propagate(self, fct: function_t, state: state_t) -> bool:
        if self.depth < 0:  # max depth has been reached
            return False

        return self.dive_cb(fct, state)

    # has propagation passed by function
    def has_function(self, ea: int) -> bool:
        return ea in self.visited

    # get or create function
    def get_function_for_mba(self, mba: ida_hexrays.mba_t) -> function_t:
        if not self.has_function(mba.entry_ea):
            self.visited[mba.entry_ea] = function_t(mba)
        return self.visited[mba.entry_ea]

    # get or create function model for ea
    def get_function(self, fct: idaapi.func_t) -> Optional[function_t]:
        mba = ida_utils.get_func_microcode(fct)
        if mba is None:
            return None

        return self.get_function_for_mba(mba)


# copy callee's arguments from caller's state and propagate in callee
def flow_in_callee(
    call_ea: int, state: state_t, params: dflow_ctrl_t
) -> Generator[Tuple[int, int, state_t], None, None]:
    ret_value = call_t(idaapi.BADADDR if state.call_to is None else state.call_to.start_ea, call_ea)

    if state.call_to is not None:  # callee was resolved
        # microcode for callee
        mba = ida_utils.get_func_microcode(state.call_to)
        if mba is None:
            utils.g_logger.warning(f"No mba for callee {state.call_to.start_ea:#x}")
        else:
            # callee initial state
            cistate = state_t(mba, params.get_function_for_mba(mba))
            populate_arguments(cistate, state)

            params.depth -= 1

            # propagate in callee
            # peep at intermediate states to catch return values
            for ea, sea, cstate in function_data_flow(cistate, params):
                if isinstance(cstate.ret, absop_t) and cstate.ret.should_dive() and cstate.fct == cistate.fct:
                    ret_value = cstate.ret

                yield ea, sea, cstate

            params.depth += 1

    # set last call return value
    utils.g_logger.debug(f"ret value for call @ {call_ea:#x} set to {ret_value}")
    state.set_register(state.mba.call_result_kreg, ret_value)


# propagate in a function, using given initial state and parameters
def function_data_flow(initial_state: state_t, params: dflow_ctrl_t) -> Generator[Tuple[int, int, state_t], None, None]:
    mba = initial_state.mba

    # apply entry injection before deciding if we should continue
    # note: function's ea may differ from first insn.ea
    params.injector.inject_before(initial_state, mba.entry_ea, -1)

    # check if we can get new info by propagating there
    if not params.should_propagate(initial_state.fct, initial_state):
        return

    # record initial states for every node
    prev_states = dict()  # bb index -> state
    prev_states[idaapi.BADADDR] = initial_state

    # analyze calls & resolve callees arguments
    # this takes decompilation, do it after we are sure to analyze the function
    ida_utils.mba_analyze_calls(mba)

    # get nodes flooding order
    nodes = walk_topological(mba)

    # get entry basic block
    try:
        block = mba.get_mblock(next(nodes))
    except StopIteration:  # function has no block
        utils.g_logger.error(f"No entry block for function 0x{mba.entry_ea}")
        return

    insn = block.head  # first instruction
    state = initial_state  # first state

    # two minsn may have the same ea, use sub_ea to distinguish them
    sub_ea = 0

    # for every basic block
    while True:
        # for every instruction
        while insn:
            # for every subinstruction forming the instruction
            for subinsn in flatten_minsn(insn, mba):
                params.injector.inject_before(state, subinsn.ea, sub_ea)

                process_instruction(state, subinsn)

                # yield state after processing the insn
                yield subinsn.ea, sub_ea, state

                # we need to go deeper
                if state.has_call_info():
                    yield from flow_in_callee(subinsn.ea, state, params)

                params.injector.inject_after(state, subinsn.ea, sub_ea)
                sub_ea += 1

            # forget intermediate results
            state.drop_kregs()

            sub_ea = sub_ea if (insn.next and insn.ea == insn.next.ea) else 0
            insn = insn.next

        # tail basic block (ending with a ret)
        # there are no specific minsn for ret, a tail bb is only followed by the special BLT_STOP bb
        # note: a call to a noreturn function creates a special bb without any successor
        if block.nsucc() == 1 and mba.get_mblock(block.succ(0)).type == idaapi.BLT_STOP:
            yield block.end, -1, handle_ret(state)

        # add updated state to previous states
        prev_states[block.serial] = state

        # next block to process
        try:
            block = mba.get_mblock(next(nodes))
        except StopIteration:
            break

        insn = block.head
        state = get_previous_state(block, prev_states)


# copy arguments from caller state to callee state
def populate_arguments(callee_state: state_t, caller_state: Optional[state_t] = None):
    # make sure the number of arguments of the call site VS function's prototype are the same
    if caller_state and callee_state.fct.get_args_count() != len(caller_state.call_args):
        utils.g_logger.warning(
            f"fct {callee_state.get_fea():#x} mismatch between fct nargs ({callee_state.fct.get_args_count()}) and call site args {len(caller_state.call_args)}"
        )

    for i in range(callee_state.fct.get_args_count()):
        val = (
            caller_state.call_args[i] if (caller_state and i < len(caller_state.call_args)) else None
        )  # get caller value for the arg
        val = val if isinstance(val, absop_t) and val.should_dive() else arg_t(i)  # use default arg when required

        callee_state.set_var_from_loc(callee_state.fct.get_argloc(i), val)


# generate cpu state for given function
def generate_state(
    func: idaapi.func_t, params: Optional[dflow_ctrl_t] = None
) -> Generator[Tuple[int, int, state_t], None, None]:
    mba = ida_utils.get_func_microcode(func)
    if mba is None:
        utils.g_logger.error(f"no microcode for {func.start_ea}, no states generated")
        return

    params = params or dflow_ctrl_t()
    starting_state = state_t(mba, params.get_function_for_mba(mba))
    populate_arguments(starting_state)

    yield from function_data_flow(starting_state, params)

```

`symless/existing.py`:

```py
from collections import deque
from typing import Collection, Tuple

import idaapi

import symless.generation as generation
import symless.utils.ida_utils as ida_utils
import symless.utils.utils as utils


# add special gap field to structure
def make_gap(struc: idaapi.tinfo_t, off: int, size: int):
    udm = idaapi.udm_t()
    udm.offset = off * 8
    udm.size = size * 8
    udm.name = f"gap{off:X}"
    udm.tafld_bits |= idaapi.TAFLD_GAP  # is_gap

    # set type to _BYTE[size]
    arr = idaapi.array_type_data_t(0, size)
    arr.elem_type = ida_utils.get_basic_type(idaapi.BT_VOID | idaapi.BTMT_SIZE12)
    udm.type = idaapi.tinfo_t()
    udm.type.create_array(arr)

    tcode = struc.add_udm(udm, idaapi.ETF_MAY_DESTROY)
    if tcode != idaapi.TERR_OK:
        utils.g_logger.error(
            f'Failed to gap {struc.get_type_name()} with {udm.name} (size {size:#x}, type "{udm.type}"): "{idaapi.tinfo_errstr(tcode)}" ({tcode:#x})'
        )


# remove padding fields from structure
def remove_padd_fields(struc: idaapi.tinfo_t):
    details = idaapi.udt_type_data_t()
    struc.get_udt_details(details)

    # search for gaps
    gaps: Collection[Tuple[int, int]] = deque()
    for udm in details:
        if udm.name == f"gap{(udm.offset // 8):X}":  # gap identified by name
            # we do not want consecutive gaps latter, merge them
            if len(gaps) and gaps[0][1] == udm.offset:
                gaps[0] = (gaps[0][0], udm.offset + udm.size)
            else:
                gaps.appendleft((udm.offset, udm.offset + udm.size))

    # merge all gaps into real gaps fields
    for off, end in gaps:
        make_gap(struc, off // 8, (end // 8) - (off // 8))


# remove gap flag from padd fields
# + padd to reach at least min_size bytes
def add_padd_fields(struc: idaapi.tinfo_t, min_size: int):
    csize = struc.get_size()
    if csize < min_size:  # padd to final size
        make_gap(struc, csize, min_size - csize)

    # remove gap flags from gaps - collapse padding
    details = idaapi.udt_type_data_t()
    struc.get_udt_details(details)
    for udm in details:
        udm.tafld_bits &= ~idaapi.TAFLD_GAP
    struc.create_udt(details)  # removes tid & ordinal info


# get the structure path assigned to given operand
def get_op_stroff(ea: int, n: int):
    delta, path = idaapi.sval_pointer(), idaapi.tid_array(idaapi.MAXSTRUCPATH)
    if idaapi.get_stroff_path(path.cast(), delta.cast(), ea, n) == 0:
        return idaapi.BADADDR
    return path[0]


# find existing vtable structure from vtable ea
def find_existing_vtable(ea: int) -> int:
    tinfo = idaapi.tinfo_t()
    if not (idaapi.get_tinfo(tinfo, ea) and tinfo.is_udt()):
        return idaapi.BADADDR
    return tinfo.get_tid()


# find existing structure with given name
def find_existing_structure(name: str) -> int:
    tinfo = ida_utils.get_local_type(name)
    if tinfo is None:
        return idaapi.BADADDR

    if tinfo.is_forward_struct():
        ida_utils.replace_forward_ref(tinfo)
    elif not tinfo.is_udt():
        return idaapi.BADADDR

    return tinfo.get_tid()


# should we replace an existing type in the idb by our struc ptr
# types we think it's ok to replace are void, scalars and scalars pointers
def should_arg_type_be_replaced(tinfo: idaapi.tinfo_t) -> bool:
    if tinfo.is_ptr():
        ptr_data = idaapi.ptr_type_data_t()
        if not tinfo.get_ptr_details(ptr_data) or ptr_data.parent.get_realtype() != idaapi.BT_UNK:
            return False
        tinfo = ptr_data.obj_type  # decide on pointee type

    # void, ints, floats, bools
    return idaapi.get_base_type(tinfo.get_realtype()) < idaapi.BT_PTR


# should we replace an existing struc field type
# only replace integers and void pointer
def should_field_type_be_replaced(tinfo: idaapi.tinfo_t) -> bool:
    if tinfo.is_ptr():
        ptr_data = idaapi.ptr_type_data_t()
        if not tinfo.get_ptr_details(ptr_data) or ptr_data.parent.get_realtype() != idaapi.BT_UNK:
            return False

        # void*
        return idaapi.get_base_type(ptr_data.obj_type.get_realtype()) == idaapi.BT_VOID

    # integers
    rt = idaapi.get_base_type(tinfo.get_realtype())
    return rt >= idaapi.BT_INT8 and rt <= idaapi.BT_INT


# should we rename a field, avoid renaming user-provided fields
def should_field_name_be_replaced(offset: int, old_name: str, new_name: str) -> bool:
    default_names = {  # record of preferred default names
        "": -1,
        generation.unk_data_field_t.get_default_name(offset): 0,
        generation.field_t.get_default_name(offset): 1,
        generation.ptr_field_t.get_default_name(offset): 2,
        generation.fct_ptr_field_t.get_default_name(offset): 3,
        generation.struc_ptr_field_t.get_default_name(offset): 3,
        generation.vtbl_ptr_field_t.get_default_name(offset): 4,
    }

    old_name_score = default_names.get(old_name, 5)
    new_name_score = default_names.get(new_name, 5)
    return new_name_score > old_name_score

```

`symless/generation/__init__.py`:

```py
import collections
from math import log2
from typing import Any, Collection, Generator, List, Optional, Set, Tuple, Union

import idaapi

import symless.config as config
import symless.existing as existing
import symless.model as model
import symless.symbols as symbols
import symless.utils.ida_utils as ida_utils
import symless.utils.utils as utils


# a structure's field
class field_t:
    def __init__(
        self,
        offset: int,
        size: int,
        flow: model.entry_t,
        block: model.block_t,
    ):
        self.offset = offset
        self.size = size
        self.flow: model.entry_t = flow  # root of the flow this field comes from
        self.block: model.block_t = block  # block where this field was set
        self.name: Optional[str] = None  # field's name
        self.owner: Optional[structure_t] = None  # structure this field belongs to

    # default name for the fields of this class, at given offset
    def get_default_name(off: int) -> str:
        return f"field_{off:08x}"

    # get field's name
    def get_name(self) -> str:
        if self.name is None:
            return self.__class__.get_default_name(self.offset)
        return self.name

    # compute wished field's name using symbols
    # does not handle conflicts
    def preferred_name(self) -> Optional[str]:
        return None

    # compute field's name
    def set_name(self, taken: Set[str]):
        self.name = self.preferred_name()
        if self.name is None:
            return

        if self.name in taken:
            self.name = f"{self.name}_0x{self.offset:x}"

        taken.add(self.name)

    # comment associated to the field
    def get_comment(self) -> Optional[str]:
        return None

    # get field's type
    def get_type(self) -> idaapi.tinfo_t:
        if self.size not in (1, 2, 4, 8, 16):
            raise RuntimeError(f"Unexpected {self} size")

        # try the cool kids types
        bt = ("uint8_t", "uint16_t", "uint32_t", "uint64_t", "uint128_t")[int(log2(self.size))]
        t = ida_utils.get_local_type(bt)
        if t is not None:
            return t

        # resort to verbose types
        bt = (idaapi.BT_INT8, idaapi.BT_INT16, idaapi.BT_INT32, idaapi.BT_INT64, idaapi.BT_INT128)[int(log2(self.size))]
        return ida_utils.get_basic_type(bt | idaapi.BTMT_USIGNED)

    # do we have information on this field's type
    def has_type(self) -> bool:
        return False

    # set the structure this fields belongs to
    def set_owner(self, struc: "structure_t"):
        self.owner = struc

    # are self & other types compatible
    def match(self, other: "field_t") -> bool:
        return self.size == other.size

    # should we replace the field by given other field
    def replace(self, other: "field_t") -> bool:
        # other has a more derived type, use it
        if isinstance(other, self.__class__) and not isinstance(self, other.__class__):
            return True

        # replacement class is less derived, keep current value
        if isinstance(self, other.__class__) and not isinstance(other, self.__class__):
            return False

        # try to keep the type set in the constructor / init function
        # i.e nearest function from the root of the data flow
        distance_new = other.flow.distance_to(other.block.get_owner())
        distance_old = self.flow.distance_to(self.block.get_owner())
        if distance_new < distance_old:
            return True
        if distance_new > distance_old:
            return False

        utils.g_logger.warning(
            f"Can not decide between fields set in {self.block.get_owner().entry_id()} and {other.block.get_owner().entry_id()} for structure {self.owner.get_name()}"
        )
        return False

    def __str__(self) -> str:
        return f"{self.get_name()}[{self.offset:#x}:{self.size:x}]"


# class for fields of unknown size
# i.e we know the address of the field was used, no idea what's in there
class unk_data_field_t(field_t):
    def __init__(self, offset, block: model.block_t):
        super().__init__(offset, 1, None, block)

    def get_default_name(off: int) -> str:
        return f"buff_{off:08x}"

    def replace(self, other: "field_t") -> bool:
        return True

    # char[1]
    def get_type(self) -> idaapi.tinfo_t:
        t = idaapi.tinfo_t()
        a = idaapi.array_type_data_t()
        a.elem_type = ida_utils.get_basic_type(idaapi.BT_INT8 | idaapi.BTMT_CHAR)
        a.nelems = 1
        t.create_array(a)
        return t


# field typed with an unknown pointer
class ptr_field_t(field_t):
    def __init__(self, value: Any, offset: int, flow: model.entry_t, block: model.block_t):
        super().__init__(offset, ida_utils.get_ptr_size(), flow, block)
        self.value = value  # for base ptr_field_t, an integer value

    def get_default_name(off: int) -> str:
        return f"ptr_{off:08x}"

    def has_type(self) -> bool:
        return True

    # guess type from pointed data type
    def get_type(self) -> idaapi.tinfo_t:
        if not idaapi.is_mapped(self.value):
            return ida_utils.void_ptr()

        tinfo = idaapi.tinfo_t()
        if not idaapi.get_tinfo(tinfo, self.value):
            return ida_utils.void_ptr()

        tinfo.create_ptr(tinfo)
        return tinfo


# field typed with a function pointer
class fct_ptr_field_t(ptr_field_t):
    def __init__(
        self,
        fct_ea: int,
        offset: int,
        flow: model.entry_t,
        block: model.block_t,
    ):
        super().__init__(fct_ea, offset, flow, block)

    def get_default_name(off: int) -> str:
        return f"method_{off:08x}"

    def preferred_name(self) -> Optional[str]:
        signature = ida_utils.demangle_ea(self.value)
        if len(signature) == 0:
            return None

        simple = symbols.method_name_from_signature(signature)

        # as much as we would love to use '~' in dtor names, IDA does not really support it
        # it can cause problems when applying stroff & xrefs
        if simple[0] == "~":
            simple = "%s_dtor%s" % (simple[1:], "" if self.offset == 0 else f"_{(self.offset//self.size):x}")

        return simple.strip("~")

    def get_comment(self) -> str:
        return f"{self.value:#x}"

    def get_type(self) -> idaapi.tinfo_t:
        func_tinfo, func_data = ida_utils.get_or_create_fct_type(self.value)

        # owner is a vtable, make sure to type method's 'this' argument
        if isinstance(self.owner, vtable_struc_t):
            this, shift = self.owner.get_class()
            this_tinfo = this.find_ptr_tinfo()
            ida_utils.set_function_argument(func_data, 0, this_tinfo, shift, this_tinfo, "this")
            func_tinfo.create_func(func_data)

        if func_tinfo.create_ptr(func_tinfo):
            return func_tinfo
        return ida_utils.void_ptr()  # default to void*

    def match(self, other: "fct_ptr_field_t") -> bool:
        return self.value == other.value


# field typed with a structure pointer
class struc_ptr_field_t(ptr_field_t):
    def __init__(
        self,
        ep: model.entry_t,
        offset: int,
        flow: model.entry_t,
        block: model.block_t,
    ):
        super().__init__(ep, offset, flow, block)

    def get_default_name(off: int) -> str:
        return f"struc_{off:08x}"

    # get structure this field points to
    def get_structure(self) -> Tuple[int, "structure_t"]:
        return self.value.get_structure()

    def get_type(self) -> idaapi.tinfo_t:
        shift, struc = self.get_structure()

        tinfo = struc.find_ptr_tinfo()
        if tinfo is None:
            utils.g_logger.error('Could not retrieve local type with name "%s" for field typing' % struc.get_name())
            return None

        ida_utils.shift_ptr(tinfo, tinfo, shift)
        return tinfo

    def match(self, other: "struc_ptr_field_t") -> bool:
        self_shift, self_struc = self.get_structure()
        other_shift, other_struc = other.get_structure()

        return self_shift == other_shift and self_struc == other_struc


# field typed with a vtable pointer
class vtbl_ptr_field_t(struc_ptr_field_t):
    def __init__(
        self,
        types: Collection[model.ftype_t],
        offset: int,
        flow: model.entry_t,
        block: model.block_t,
    ):
        super().__init__(None, offset, flow, block)

        # all vtables that went in this field
        self.values: Collection[model.vtbl_entry_t] = collections.deque()

        # are we sure the list of vtables set are in the ctor order
        self.in_order = not isinstance(flow, model.arg_entry_t)

        # fill types
        for type in filter(
            lambda t: isinstance(t, model.ftype_struc_t) and isinstance(t.entry, model.vtbl_entry_t),
            types[::-1],
        ):
            self.add_vtable(type.entry, self.in_order)

    def get_default_name(off: int) -> str:
        return "%s%s" % (idaapi.VTBL_MEMNAME, "" if off == 0 else f"_{off:08x}")

    def get_comment(self) -> str:
        _, vtbl = self.get_structure()
        return vtbl.get_name()

    # add given vtable to vtables values list
    # if as_latest is set, consider it to be effective field's value
    # else use less derived vtable between first & last added
    def add_vtable(self, vtbl: model.vtbl_entry_t, as_latest: bool):
        if vtbl in self.values:  # already encountered
            return

        self.values.append(vtbl)
        self.value = vtbl if as_latest else vtbl.get_most_derived(self.values[0])

    def replace(self, other: "field_t") -> bool:
        if not isinstance(other, vtbl_ptr_field_t):
            return False

        # from same data flow, take latest vtable into account
        if other.flow == self.flow:
            old_vtbl = self.value
            new_vtbl = other.value

            # keep all info into new field
            other.values = self.values
            other.value = self.value
            other.add_vtable(new_vtbl, other.in_order)

            utils.g_logger.debug(
                f"__vftable_{self.offset:#x} selecting vtbl {other.value.ea:#x} between ({old_vtbl.ea:#x}, {new_vtbl.ea:#x}) (in order {other.in_order})"
            )
            return True

        # else: different data flow not taken into account
        # effective vtable should have been found in this flow

        return False


# model of a structure
class structure_t:
    def __init__(self, sid: int):
        self.sid = sid  # model sid
        self.size = -1  # structure size, if known
        self.ea = idaapi.BADADDR
        self.ida_tid = idaapi.BADADDR  # associated IDA struc tid

        self.fields: dict[int, field_t] = dict()  # structure's members
        self.range: Collection[tuple[int, int]] = list()  # structure's ranges occupied by fields (offset, size)

        self.name: Optional[str] = None  # struc's name

        # set of structure's entries in the data flow
        # records (shift, entry), shift is used when entry is a shift ptr on our strucs
        self.root_eps: Set[Tuple[int, model.entry_t]] = set()

        # is the structure associated with some xrefs
        # if not, no need to generate it
        self.has_xrefs = False

        # force this struc generation into IDA database
        self.force_generation = False

    def set_size(self, size: int):
        self.size = size

    # structure size from its last field
    def get_size_from_fields(self) -> int:
        if len(self.range) == 0:
            return 0
        last = self.range[-1]
        return last[0] + last[1]

    # structure size, known (malloc) or from the fields we found
    def get_size(self) -> int:
        if self.size >= 0:
            return self.size
        return self.get_size_from_fields()

    # add a field to the structure
    # solver_cb callback used to resolve overlapping fields
    def set_field(self, field: field_t, solver_cb) -> bool:
        offset = field.offset
        field_end = offset + field.size

        # check boundaries
        if offset < 0 or (self.size >= 0 and field_end > self.size):
            utils.g_logger.warning(
                f"Could not add field (0x{offset:x}:0x{field.size:x}) to {self.get_name()} of size {self.size:x}"
            )
            return False

        # compute overlapping fields
        i = 0
        replaced = collections.deque()
        while i < len(self.range) and self.range[i][0] < field_end:
            other_end = self.range[i][0] + self.range[i][1]

            # overlapping fields
            if other_end > offset:
                replace = solver_cb(field, self.fields[self.range[i][0]])
                if replace:
                    replaced.appendleft(i)
                else:  # do not insert new field
                    utils.g_logger.debug(
                        "Could not add %s (set in %s) to %s because of conflicts with existing (0x%x:0x%x)"
                        % (
                            field.get_name(),
                            field.block.get_owner().entry_id(),
                            self.get_name(),
                            self.range[i][0],
                            self.range[i][1],
                        )
                    )
                    return False

            i += 1

        # remove conflicting fields
        for j in replaced:
            old = self.fields[self.range[j][0]]
            utils.g_logger.debug(
                "Discarding %s (set in %s) from %s, replacing with %s (set in %s)"
                % (
                    old.get_name(),
                    old.block.get_owner().entry_id(),
                    self.get_name(),
                    field.get_name(),
                    field.block.get_owner().entry_id(),
                )
            )
            del self.fields[self.range[j][0]]
            del self.range[j]

        # add new field
        idx = i - len(replaced)
        self.range.insert(idx, (offset, field.size))
        self.fields[offset] = field
        field.set_owner(self)

        utils.g_logger.debug(f"Adding {field} to {self.get_name()}")

        return True

    # get the field that occupies given offset
    def has_field_at(self, offset: int) -> Optional[field_t]:
        i = 0
        while i < len(self.range) and self.range[i][0] <= offset:
            if self.range[i][0] + self.range[i][1] > offset:
                return self.fields[self.range[i][0]]
            i += 1
        return None

    # get field starting at given offset
    def get_field(self, offset: int) -> Optional[field_t]:
        try:
            return self.fields[offset]
        except KeyError:
            return None

    def get_fields(self) -> Generator[field_t, None, None]:
        for field in self.fields.values():
            yield field

    # add one root entrypoint
    # defining a data flow this structure follows
    def associate_root(self, entry: model.entry_t, shift: int):
        # struc's default name is based on ea, on assign it once
        if self.ea == idaapi.BADADDR:
            self.ea = entry.ea

        self.root_eps.add((shift, entry))
        entry.set_structure(shift, self)

    # get structure's entries in the data flow
    def associated_root(self) -> Generator[Tuple[int, model.entry_t], None, None]:
        for shift, root in self.root_eps:
            yield shift, root

    # get the flow of nodes traveled by the structure
    # yields (root node, current shift, current block)
    def node_flow(self, all_roots: bool = True) -> Generator[Tuple[model.entry_t, model.block_t, int], None, None]:
        for initial_shift, initial_root in self.associated_root():
            for root, node, shift in model.flow_from_root(initial_root, all_roots):
                yield (root, node, shift + initial_shift)

    # find existing IDA structure that this model represents
    def find_existing(self) -> int:
        self.ida_tid = existing.find_existing_structure(self.get_name())
        return self.ida_tid

    # set existing IDA struc represented by this model
    def set_existing(self, tid: int):
        self.ida_tid = tid

    # get IDA tinfo_t representing our structure
    # the structure must have been created before
    def find_tinfo(self) -> idaapi.tinfo_t:
        if self.ida_tid == idaapi.BADADDR:
            raise Exception(f"find_tinfo on {self.get_name()} failed, no IDA structure associated")

        tif = idaapi.tinfo_t()
        tif.get_type_by_tid(self.ida_tid)  # should return True
        return tif

    # get a struc pointer tinfo
    def find_ptr_tinfo(self) -> idaapi.tinfo_t:
        t = self.find_tinfo()
        t.create_ptr(t)
        return t

    def get_name(self) -> str:
        if self.name is not None:
            return self.name
        return self.default_name()

    def set_name(self, name: str):
        self.name = name

    def default_name(self) -> str:
        return f"struc_0x{self.ea:x}"

    # define fields names
    def compute_names(self):
        taken = set()  # used names set, avoid conflicts
        for field in self.fields.values():
            field.set_name(taken)

    # comment associated to structure
    def get_comment(self) -> Optional[str]:
        if not config.g_settings.debug:
            return None

        eas = set([(shift, root.ea) for shift, root in self.associated_root()])
        return "Root nodes:\n%s" % "\n".join(
            [("%s, shift: 0x%x" % (ida_utils.addr_friendly_name(ea), shift)) for shift, ea in eas]
        )

    # do we generate this structure in IDA
    def relevant(self) -> bool:
        return self.force_generation or (
            self.has_xrefs
            and len(self.fields) > 0
            and (  # a struc without xref is useless
                len(self.fields) > 1
                or self.get_size_from_fields() > ida_utils.get_ptr_size()  # more than 1 field - not a buffer
                or self.fields[  # unique field not at off 0 - not a buffer
                    self.range[0][0]
                ].has_type()  # unique field has a relevant type
            )
        )

    # do we need to apply the __cppobj flag
    def is_cppobj(self) -> bool:
        return isinstance(self.get_field(0), vtbl_ptr_field_t)

    # do we need to apply the VFT flag
    def is_vtable(self) -> bool:
        return False

    def __eq__(self, other) -> bool:
        return isinstance(other, structure_t) and self.sid == other.sid

    def __hash__(self) -> int:
        return self.sid


# model of a vtable
class vtable_struc_t(structure_t):
    def __init__(self, sid: int):
        super().__init__(sid)
        self.owning_class: Optional[Tuple[structure_t, int]] = None  # class owning this vtable, with associated offset

    def default_name(self) -> str:
        return f"loc_{self.ea:x}{idaapi.VTBL_SUFFIX}"

    def get_comment(self) -> str:
        out = (
            f"Vtable at 0x{self.ea:x}\nOwned by {self.owning_class[0].get_name()} at offset 0x{self.owning_class[1]:x}"
        )
        return out

    # find existing vtable structure from typed vtable
    def find_existing(self) -> int:
        self.ida_tid = existing.find_existing_vtable(self.ea)
        if self.ida_tid != idaapi.BADADDR:
            return self.ida_tid

        return super().find_existing()

    def set_class(self, owner: structure_t, offset: int):
        self.owning_class = (owner, offset)

    def get_class(self) -> Tuple[structure_t, int]:
        return self.owning_class

    # no need to build unlinked vtables
    def relevant(self) -> bool:
        return self.owning_class is not None

    def is_vtable(self) -> bool:
        return True


# empty structure model from associated entry
def empty_model_from_ep(entry: model.entry_t) -> structure_t:
    if isinstance(entry, model.vtbl_entry_t):
        return vtable_struc_t(entry.struc_id)

    struc = structure_t(entry.struc_id)
    if isinstance(entry, model.alloc_entry_t):  # known size structure
        struc.set_size(entry.size)

    return struc


# defines a structure that has been merged into another
# identify the new structure
class merge_t:
    def __init__(self, merge: structure_t):
        self.merge_id = merge.sid


# record of all structures to be built
class structure_record_t:
    def __init__(self, entries: model.entry_record_t):
        self.structures: List[Union[structure_t, merge_t]] = [None for _ in range(entries.structures_count())]

        # fill structures array
        for entry in entries.get_entries():
            if not entry.is_root():
                continue

            # make empty structure model from entry point
            if self.structures[entry.struc_id] is None:
                self.structures[entry.struc_id] = empty_model_from_ep(entry)

            # associate structure with its entries in the data flow
            self.structures[entry.struc_id].associate_root(entry, entry.struc_shift)

    # define a structure to have been merged into another
    def replace_by(self, struc: structure_t, merge: structure_t):
        self.structures[struc.sid] = merge_t(merge)

    def _get_structure(self, sid: int) -> Union[structure_t, merge_t]:
        return self.structures[sid]

    # get effective structure
    # if given structure has been merged, return merge result
    def get_structure(self, struc: structure_t) -> structure_t:
        st = self._get_structure(struc.sid)
        while isinstance(st, merge_t):
            st = self._get_structure(st.merge_id)
        return st

    def get_structures(
        self, cls: type = structure_t, include_discarded: bool = True
    ) -> Generator[structure_t, None, None]:
        for struc in self.structures:
            if isinstance(struc, cls) and (include_discarded or struc.relevant()):
                yield struc

```

`symless/generation/generate.py`:

```py
from typing import Dict, Tuple

import idaapi
import idautils
import idc

import symless.allocators as allocators
import symless.existing as existing
import symless.model.entrypoints as entrypoints
import symless.symbols as symbols
import symless.utils.ida_utils as ida_utils
from symless.generation import *

# folder in local types listing, to store symless generated types
STRUC_DIR = "Symless"


# make symless structures directory
def make_structures_dir():
    root = ida_utils.get_local_types_folder()
    if root is None:
        return

    err = root.mkdir(STRUC_DIR)
    if err not in (idaapi.DTE_OK, idaapi.DTE_ALREADY_EXISTS):
        utils.g_logger.error(f'Could not create {STRUC_DIR} local types folder: "{root.errstr(err)}"')


# create an empty IDA structure used to contain given struc
def make_IDA_structure(struc: structure_t):
    if struc.ida_tid != idaapi.BADADDR:
        return

    name = struc.get_name()

    # check for existing struc
    ida_tid = struc.find_existing()
    if ida_tid != idaapi.BADADDR:
        utils.g_logger.info(f'Re-using existing structure (tid {ida_tid:#x}) for model "{name}"')
        return

    # create new structure
    struc.set_existing(idc.add_struc(idaapi.BADADDR, name, False))
    if struc.ida_tid == idaapi.BADADDR:
        utils.g_logger.error(f'Could not create empty structure "{name}"')
        return

    # move it to symless folder
    root = ida_utils.get_local_types_folder()
    if root is None:
        return

    err = root.rename(name, f"{STRUC_DIR}/{name}")
    if err != idaapi.DTE_OK:
        utils.g_logger.warning(f'Could not move structure "{name}" into {STRUC_DIR} directory: "{root.errstr(err)}"')


# do we want to type IDA base with given entry data
def should_type_entry(entry: entrypoints.entry_t, ctx: entrypoints.context_t) -> bool:
    # root is always right
    if entry.is_root():
        return True

    shift, struc = entry.get_structure()
    if not struc.relevant():
        return False  # structure will not be generated

    struc_tif = struc.find_tinfo()

    # do not overwrite typing set by user on operands
    # TODO we should only check the operand we will type
    # for now check all operands on the instructions about to be typed
    # assume only one operand per instruction can be typed with a struc path (not sure if always true)
    for ea, _, _ in entry.get_operands():
        for n in range(idaapi.UA_MAXOP):
            # operand was typed with a different structure than ours, stop
            if existing.get_op_stroff(ea, n) not in (idaapi.BADADDR, struc_tif.get_tid()):
                return False

    # always type with vtbl, no matter its size
    if isinstance(struc, vtable_struc_t):
        return True

    # arguments entries special case
    if isinstance(entry, entrypoints.arg_entry_t):
        # always type virtual functions
        fct = ctx.get_function(entry.ea)
        if fct.is_virtual():
            return True

        # avoid other shifted ptr arguments
        if shift != 0:
            return False

        # TODO: do not type when arg is already typed with different struc

    # do not type entries that do not represent a structure
    lower, upper = entry.get_boundaries()
    if lower == 0 and upper <= ida_utils.get_ptr_size():
        return False

    return True


# update given function's returned type with the given entry
def type_function_return(fct: entrypoints.prototype_t, entry: entrypoints.entry_t):
    # entry is not returned, exit
    if fct.get_ret() != entry:
        return

    shift, struc = entry.get_structure()

    # avoid prone to error shifted pointers
    if shift != 0:
        return

    func_tinfo, func_data = ida_utils.get_or_create_fct_type(fct.ea)
    if not existing.should_arg_type_be_replaced(func_data.rettype):
        return

    tinfo = struc.find_ptr_tinfo()
    func_data.rettype = tinfo

    if func_tinfo.create_func(func_data):
        idaapi.apply_tinfo(fct.ea, func_tinfo, idaapi.TINFO_DEFINITE)

        utils.g_logger.info(f"Typing return of fct_0x{fct.ea:x} with {tinfo}")


# update function's type with given arg entrypoint
def type_function_argument(fct: entrypoints.prototype_t, arg: entrypoints.entry_t):
    if not isinstance(arg, entrypoints.arg_entry_t):
        return

    idx = arg.index

    func_tinfo, func_data = ida_utils.get_or_create_fct_type(fct.ea)
    if idx >= func_data.size():
        return

    # do not replace existing (complex) type
    if not existing.should_arg_type_be_replaced(func_data[idx].type):
        return

    shift, struc = arg.get_structure()
    ida_utils.set_function_argument(
        func_data,
        idx,
        struc.find_ptr_tinfo(),
        shift,
        struc.find_tinfo(),
        "this" if idx == 0 else None,
    )

    if not func_tinfo.create_func(func_data):
        utils.g_logger.error(f"Could not type arg_{idx} of fct_0x{fct.ea:x} with {arg.entry_id()}")
        return

    idaapi.apply_tinfo(fct.ea, func_tinfo, idaapi.TINFO_DEFINITE)

    utils.g_logger.info(f"Typing fct_0x{fct.ea:x} arg_{idx} with {struc.get_name()} shifted by 0x{shift:x}")


# which op of the given insn should we type with a structure path
# for given reg and given field offset
# returns op and shift to apply
def find_op_for_stroff(insn: idaapi.insn_t, regid: int, off: int) -> Tuple[Optional[idaapi.op_t], int]:
    for op in ida_utils.get_insn_ops(insn):
        # disp/phrase with regid for base register, this is what we want to type
        # we assume they should not be more than one disp/phrase op per insn
        if op.type in (idaapi.o_phrase, idaapi.o_displ) and op.phrase == regid:
            # compute shift to apply to type with member at given offset
            displ = op.addr if op.type == idaapi.o_displ else 0  # signed int32
            shift = utils.to_c_integer(off - displ, 4)

            return (op, shift)

        # immediate operand, preceded regid
        # this must be an arithmetic operation on our struc ptr, we must type the immediate value
        # this assumes the src reg is before the immediate, which is the case on IDA disass for arm and x64
        if (
            op.type == idaapi.o_imm
            and op.n > 0
            and insn.ops[op.n - 1].type == idaapi.o_reg
            and insn.ops[op.n - 1].reg == regid
        ):
            imm_size = idaapi.get_dtype_size(op.dtype)

            displ = op.value
            shift = utils.to_c_integer(off - displ, imm_size)

            return (op, shift)

    return (None, 0)


# type operand with the given "struct offset"
def apply_stroff_to_op(ea: int, regid: int, struc: idaapi.tinfo_t, off: int):
    insn = idaapi.insn_t()
    if idaapi.decode_insn(insn, ea) == 0:
        return

    udm = idaapi.udm_t()
    udm.offset = off * 8
    mid = struc.get_udm_tid(ida_utils.find_udm_wrap(struc, udm))
    path = idaapi.tid_array(idaapi.MAXSTRUCPATH)

    op, shift = find_op_for_stroff(insn, regid, off)
    if op is None:
        utils.g_logger.warning(f"No op to apply stroff for {ea:#x} {idaapi.get_reg_name(regid,8)}({regid:#x})")
        return

    # type operand with struc path
    path[0] = struc.get_tid()
    path[1] = mid
    idaapi.op_stroff(ea, op.n, path.cast(), 2, shift)

    idaapi.auto_wait()  # let IDA digest

    # IDA 8.4: in some cases op_stroff does not set the right struc path
    # instead of '[#struc.field_0]' we end up with '[#struc]'
    # thus missing an xref on field_0 for the instruction
    # this "fix" should force the xref
    if mid not in idautils.DataRefsFrom(ea):
        path[0] = mid
        idaapi.op_stroff(ea, op.n, path.cast(), 1, shift)  # type op
        idaapi.add_dref(ea, mid, idaapi.dr_I | idaapi.XREF_USER)  # force xref

    utils.g_logger.debug(f"Typing op {ea:#x} {op.n} with stroff {path[0]:#x}:{shift:#x}")


# type IDA base with data from given entrypoint
def type_entry(entry: entrypoints.entry_t, ctx: entrypoints.context_t):
    if not should_type_entry(entry, ctx):
        utils.g_logger.debug(f"Not typing database with {entry.entry_id()} data")
        return

    # make sure the associated structure exists in IDA
    shift, struc = entry.get_structure()
    if struc.ida_tid == idaapi.BADADDR:
        utils.g_logger.warning(
            f'Structure "{struc.get_name()}" was not generated, preventing from typing {entry.entry_id()}'
        )
        return

    struc_tif = struc.find_tinfo()

    utils.g_logger.debug(f"Typing database with {entry.entry_id()} data")

    # type disassembly operands
    for ea, regid, offs in entry.get_operands():
        apply_stroff_to_op(ea, regid, struc_tif, shift + offs[0])

        # multiple fields referenced by one instruction, add xrefs on additional fields
        for i in range(1, len(offs)):
            udm = idaapi.udm_t()
            udm.offset = (shift + offs[i]) * 8
            mid = struc_tif.get_udm_tid(ida_utils.find_udm_wrap(struc_tif, udm))
            idaapi.add_dref(ea, mid, idaapi.dr_I | idaapi.XREF_USER)
            utils.g_logger.debug(f"Adding xref for field {struc_tif.get_tid():#x}:{(shift + offs[i]):#x} on {ea:#x}")

    # type containing function
    fct_ea = entry.get_function()
    if fct_ea != idaapi.BADADDR:
        fct = ctx.get_function(fct_ea)

        # type function's arguments
        type_function_argument(fct, entry)

        # type function's return
        type_function_return(fct, entry)


# set type & rename memory allocators if needed
def type_allocator(alloc: allocators.allocator_t):
    # give a default name
    if not symbols.has_relevant_name(alloc.ea):
        idaapi.set_name(alloc.ea, alloc.get_name())

    # set function type
    func_tinfo, func_data = ida_utils.get_or_create_fct_type(alloc.ea)
    if func_tinfo.is_ptr():  # avoid function pointers
        return

    alloc.make_type(func_data)

    if func_tinfo.create_func(func_data):
        idaapi.apply_tinfo(alloc.ea, func_tinfo, idaapi.TINFO_DEFINITE)

        utils.g_logger.info(f"Typing allocator_{alloc.ea:x} ({alloc.get_name()})")


# apply __cppobj & VFT flags
def apply_udt_flags(struc: structure_t, tinfo: idaapi.tinfo_t):
    taudt = idaapi.TAUDT_CPPOBJ if struc.is_cppobj() else 0
    taudt |= idaapi.TAUDT_VFTABLE if struc.is_vtable() else 0
    if taudt == 0:
        return

    # apply flags to tinfo
    details = idaapi.udt_type_data_t()
    tinfo.get_udt_details(details)
    details.taudt_bits |= taudt
    tinfo.create_udt(details)


# add given field to given IDA structure
def add_field_to_IDA_struc(struc: idaapi.tinfo_t, field: field_t, updated: Dict[int, Tuple[idaapi.tinfo_t, int]]):
    bits_offset = field.offset * 8
    bits_size = field.size * 8

    t_ord = struc.get_ordinal()
    if t_ord == 0:  # ordinal number was lost
        pass

    elif t_ord not in updated:
        updated[t_ord] = (struc.copy(), struc.get_size())  # copy or pray
        existing.remove_padd_fields(struc)  # reset gapX fields as padding
    else:
        struc, _ = updated[t_ord]  # use our updated tinfo, not IDA's

    # search for existing field
    udm = idaapi.udm_t()
    udm.offset = bits_offset
    if ida_utils.find_udm_wrap(struc, udm) == idaapi.BADADDR:
        pass

    elif udm.is_gap():  # no STRMEM_SKIP_GAPS on IDA 8
        # we want to add a field beyond the gap, without knowing what's after - abort
        # a gap should not be followed by another gap
        if bits_offset + bits_size > udm.offset + udm.size:
            utils.g_logger.warning(
                f"Abort making {field} into {struc.get_type_name()}: bigger than gap[{udm.offset//8:#x}:{udm.size//8:x}]"
            )
            return

        udm = idaapi.udm_t()  # ignore gap

    # field is within an embedded structure
    elif udm.type.is_udt() and (udm.offset + udm.size) >= (bits_offset + bits_size):
        field.offset = (bits_offset - udm.offset) // 8  # update field_t directly, it is not re-used after
        return add_field_to_IDA_struc(udm.type, field, updated)

    # existing field with different boundaries
    elif udm.offset != bits_offset or udm.size != bits_size:
        utils.g_logger.warning(
            f"Abort making {field} into {struc.get_type_name()}: conflict with {udm.name}[{udm.offset//8:#x}:{udm.size//8:x}]"
        )
        return

    # replace field type if ok to do so
    ftif = field.get_type()
    if udm.type.get_realtype() == idaapi.BT_UNK or (
        existing.should_field_type_be_replaced(udm.type) and not existing.should_field_type_be_replaced(ftif)
    ):
        udm.type = ftif

    # set field comment if no existing
    fcomm = field.get_comment()
    if fcomm and len(udm.cmt) == 0:
        udm.cmt = fcomm

    # replace field name if needed
    fname = field.get_name()
    if existing.should_field_name_be_replaced(field.offset, udm.name, fname):
        udm.name = fname

    # add field to struc tinfo
    udm.offset = bits_offset
    udm.size = bits_size
    tcode = struc.add_udm(udm, idaapi.ETF_MAY_DESTROY)
    if tcode != idaapi.TERR_OK:
        utils.g_logger.error(
            f'Failed making {udm.name} (off {udm.offset//8:#x}, size {udm.size//8:#x}, type "{udm.type}") to {struc.get_type_name()}: "{idaapi.tinfo_errstr(tcode)}" ({tcode:#x})'
        )


# fill IDA structure with given model info
# does not overwrite fields of already existing IDA structure
def fill_IDA_structure(struc: structure_t):
    if struc.ida_tid == idaapi.BADADDR:
        utils.g_logger.error(f'Could not generate structure "{struc.get_name()}"')
        return

    struc_tif = struc.find_tinfo()

    # record of structures to update (current struc and its embedded strucs)
    updated: Dict[int, Tuple[idaapi.tinfo_t, int]] = dict()
    updated[struc_tif.get_ordinal()] = (struc_tif, struc_tif.get_size())
    existing.remove_padd_fields(struc_tif)

    # set udt attr
    apply_udt_flags(struc, struc_tif)

    # add fields
    for field in struc.fields.values():
        add_field_to_IDA_struc(struc_tif, field, updated)

    # set structure's comment
    scomm = struc.get_comment()
    if scomm and struc_tif.get_type_cmt() is None:
        tcode = struc_tif.set_type_cmt(scomm)
        if tcode != idaapi.TERR_OK:
            utils.g_logger.error(
                f'Failed to set comment for {struc.get_name()}: "{idaapi.tinfo_errstr(tcode)}" ({tcode:#x})'
            )

    # reset gapX fields on all updated structures + save to IDA
    while len(updated):
        t_ord, (tinfo, min_size) = updated.popitem()
        existing.add_padd_fields(tinfo, min_size)
        tinfo.set_numbered_type(None, t_ord, idaapi.NTF_REPLACE)


# imports all structures defined into given record into IDA
def import_structures(record: structure_record_t):
    # prepare symless structures directory
    make_structures_dir()

    # create empty structures
    for struc in record.get_structures(include_discarded=False):
        make_IDA_structure(struc)

    # fill the structures
    for struc in record.get_structures(include_discarded=False):
        fill_IDA_structure(struc)

    # type vtables with vtables structures
    for vtbl in record.get_structures(cls=vtable_struc_t, include_discarded=False):
        tinfo = vtbl.find_tinfo()
        if not idaapi.apply_tinfo(vtbl.ea, tinfo, idaapi.TINFO_DEFINITE):
            utils.g_logger.warning(f"Could not apply type {tinfo} to vtable 0x{vtbl.ea:x}")


# apply structures types to IDA base
def import_context(context: entrypoints.context_t):
    entries = context.get_entrypoints()

    # type entries
    for entry in entries.get_entries():
        type_entry(entry, context)

    # type allocators
    for allocator in context.get_allocators():
        type_allocator(allocator)

```

`symless/generation/structures.py`:

```py
from collections import defaultdict
from typing import Dict, List, Tuple

import symless.conflict as conflict
import symless.model.entrypoints as entrypoints
import symless.symbols.rename as rename
import symless.utils.utils as utils
from symless.generation import *


# create a structure's field (fixed) from an entrypoint's field (ambiguous)
# size_solver_cb is used to choose prefered field's size
def make_field(
    var_field: model.field_t, shift: int, flow: model.entry_t, block: model.block_t, size_solver_cb
) -> "field_t":
    var_type = var_field.get_type()
    offset = shift + var_field.offset

    # unknown pointer
    if isinstance(var_type, model.ftype_ptr_t):
        v = var_type.value.get_uval()  # value size is assumed to be ptr_size
        return ptr_field_t(v, offset, flow, block)

    # structure pointer
    if isinstance(var_type, model.ftype_struc_t):
        # vtable pointer
        if isinstance(var_type.entry, model.vtbl_entry_t):
            return vtbl_ptr_field_t(list(var_field.type), offset, flow, block)

        else:
            return struc_ptr_field_t(var_type.entry, offset, flow, block)

    # function pointer
    if isinstance(var_type, model.ftype_fct_t):
        fea = var_type.value.get_uval()
        return fct_ptr_field_t(fea, offset, flow, block)

    size = size_solver_cb(var_field)
    return field_t(offset, size, flow, block)


# fill structures models
def define_structure(struc: structure_t):
    visited: Set[Tuple[model.entry_t, model.block_t, int]] = set()

    # get structures fields from associated entries fields
    for root, node, shift in struc.node_flow():
        # do not visit the same node twice, with the same shift
        path_id = (node.get_owner(), node, shift)
        if path_id in visited:
            continue
        visited.add(path_id)

        # add all fields from node
        for vfield in node.get_fields():
            # structure field from entrypoint field
            field = make_field(vfield, shift, root, node, conflict.field_size_solver)
            struc.set_field(field, conflict.fields_conflicts_solver)

    # search for xrefs on paddings and create dummy fields for it
    # this happens when the address of a field is used, without its content beeing accessed
    for entry, node, shift in visited:
        for _, _, offs in entry.get_operands():
            for off in offs:
                eoff = shift + off
                if struc.has_field_at(eoff) is None and eoff < struc.get_size():
                    struc.set_field(unk_data_field_t(eoff, node), None)


# define which structure an entry is associated to
def associate_entry(
    entry: entrypoints.entry_t, entries: entrypoints.entry_record_t
) -> Optional[Tuple[int, structure_t]]:
    if not entry.has_structure():
        # read entries special case
        if isinstance(entry, model.read_entry_t):
            # get the read field
            src_shift, src_struc = associate_entry(entry.src, entries)
            field = src_struc.get_field(entry.src_off + src_shift)
            if not isinstance(field, struc_ptr_field_t):
                entries.remove_entry(entry)
                return None

            eff_shift, eff_struc = associate_entry(field.value, entries)
            utils.g_logger.debug(
                f"{entry.entry_id()} associated with struc {eff_struc.get_name()} (shift {eff_shift:#x})"
            )

            entry.set_structure(eff_shift, eff_struc)

        else:
            # select less derived structure that flew through this ep
            candidates: List[Tuple[structure_t, int] | None] = list()
            for shift, parent in entry.get_parents():
                pshift, pstruc = associate_entry(parent, entries)
                candidates.append((pstruc, shift + pshift))

            selected = conflict.less_derived(candidates)
            entry.set_structure(selected[1], selected[0])

    return entry.get_structure()


# find best structure to associate to each entrypoint
def associate_entries(entries: model.entry_record_t):
    for entry in entries.get_entries():
        associate_entry(entry, entries)


# compute the owner of each defined vtable
def select_vtables_owners(record: structure_record_t):
    owners: Dict[vtable_struc_t, List[Tuple[structure_t, int]]] = defaultdict(list)

    # find all conflicts on owners
    for struc in record.get_structures(include_discarded=False):
        for field in struc.fields.values():
            if not isinstance(field, vtbl_ptr_field_t):
                continue

            _, vtbl = field.get_structure()
            owners[vtbl].append((struc, field.offset))

    # select owner among candidates for each vtable
    for vtbl in owners:
        owner, shift = conflict.vtable_owner_solver(owners[vtbl])
        vtbl.set_class(owner, shift)


# generate structures models from entrypoints
def define_structures(ctx: entrypoints.context_t) -> structure_record_t:
    entries = ctx.get_entrypoints()
    record = structure_record_t(entries)

    # make strucs models and generate empty structures
    for struc in record.get_structures():
        define_structure(struc)

    # define which structure to be associated to each entry
    associate_entries(entries)

    # find & merge duplicated structures
    conflict.remove_dupes(entries, record)

    # associate vtables to their owners
    select_vtables_owners(record)

    # rename structure models using symbols
    rename.define_structures_names(record)

    return record

```

`symless/main.py`:

```py
import time

import idaapi

import symless.allocators as allocators
import symless.config as config
import symless.cpustate.arch as arch
import symless.generation.generate as generate
import symless.generation.structures as structures
import symless.model.entrypoints as entrypoints
import symless.model.model as model
import symless.utils.utils as utils


def start_analysis(config_path):
    # check binary type
    if not arch.is_arch_supported():
        utils.g_logger.error("Unsupported arch (%s) or filetype" % arch.get_proc_name())
        return

    # check that the decompiler exists
    if not idaapi.init_hexrays_plugin():
        utils.g_logger.error("You do not have the decompiler for this architecture")
        return

    # rebase if required
    if config.g_settings.rebase_db:
        err = idaapi.rebase_program(-idaapi.get_imagebase(), idaapi.MSF_FIXONCE)
        if err != idaapi.MOVE_SEGM_OK:
            utils.g_logger.error(f"Unable to rebase program: {err}")

    # initial ida autoanalysis
    start = time.time()
    idaapi.auto_wait()
    utils.print_delay("Initial IDA autoanalysis", start, time.time())

    # retrieve allocators
    imports = allocators.get_allocators(config_path)
    if imports is None:
        utils.g_logger.error("No allocators identified")
        imports = list()

    # retrieve first entrypoints
    start = time.time()
    ctx = entrypoints.retrieve_entrypoints(imports)
    utils.print_delay("Initial entrypoints retrieved", start, time.time())

    # build entrypoints graph
    start = time.time()
    model.analyze_entrypoints(ctx)
    utils.print_delay("Entrypoints graph built", start, time.time())

    # build structures
    start = time.time()
    strucs = structures.define_structures(ctx)
    utils.print_delay("Structures defined", start, time.time())

    # import structures in IDA
    start = time.time()
    generate.import_structures(strucs)
    generate.import_context(ctx)
    utils.print_delay("IDA database typed", start, time.time())

    # finalize operations
    start = time.time()
    idaapi.auto_wait()
    utils.print_delay("Final IDA autoanalysis", start, time.time())

```

`symless/model/__init__.py`:

```py
from collections import defaultdict, deque
from typing import (
    Any,
    Collection,
    Dict,
    Generator,
    Iterator,
    List,
    Optional,
    Set,
    Tuple,
)

import ida_hexrays
import idaapi

import symless.allocators as allocators
import symless.cpustate.cpustate as cpustate
import symless.generation as generation
import symless.symbols as symbols
import symless.utils.ida_utils as ida_utils
import symless.utils.utils as utils
import symless.utils.vtables as vtables


# a field's type & potential value
class ftype_t:
    def __init__(self, value: cpustate.absop_t):
        self.value = value

    # should we propagate the field value when read
    def should_propagate(self) -> bool:
        return False

    # get value to use when propagating with cpustate
    def get_propagated_value(self) -> cpustate.absop_t:
        if self.should_propagate():
            return self.value
        return None

    def __eq__(self, other) -> bool:
        return isinstance(other, self.__class__) and self.value == other.value

    def __hash__(self) -> int:
        return hash((self.__class__, self.value))

    def __str__(self) -> str:
        return f"{self.__class__.__name__}:({self.value})"


# structure pointer type
class ftype_struc_t(ftype_t):
    def __init__(self, entry: "entry_t"):
        super().__init__(cpustate.sid_t(entry.id))
        self.entry = entry  # entry this field points to


# function pointer type
class ftype_fct_t(ftype_t):
    def __init__(self, value: cpustate.mem_t):
        super().__init__(value)

    def should_propagate(self) -> bool:
        return True


# default pointer type
class ftype_ptr_t(ftype_t):
    def __init__(self, value: cpustate.mem_t):
        super().__init__(value)

    def should_propagate(self) -> bool:
        return True


# entry point field
class field_t:
    def __init__(self, offset: int):
        self.offset = offset
        self.size: int = 0  # bitfield of possible sizes
        self.type: deque[ftype_t] = deque()  # list of affected types, in propagation's order

    # add a type to the field's possible types list
    def set_type(self, type: ftype_t):
        self.type.appendleft(type)  # record types in propagation order

    # get last affected type
    def get_type(self) -> Optional[ftype_t]:
        if len(self.type) == 0:
            return None
        return self.type[0]

    # add possible size
    def set_size(self, size: int):
        self.size |= size

    # get all possible field's sizes
    def get_size(self) -> Collection[int]:
        out = deque()
        for i in range(8):
            if self.size & (1 << i):
                out.append(pow(2, i))
        return out

    def __str__(self) -> str:
        return f"field_{self.offset:#x}:{self.size:#x}"


# records the data flow of a structure in a basic block
# since our data flow is flattened, loops & conditions are not taken into account
# then a basic block is an execution flow ended by a call or a ret
class block_t:
    def __init__(self, owner: "entry_t", id: int = 0):
        self.owner = owner
        self.fields: Dict[int, field_t] = dict()  # fields defined in the block & their types

        # block index in owner's blocks list
        self.id = id

        # structure's boundaries, from accessed fields
        self.max = 0
        self.min = 0

        # called ep following this block in the data flow
        self.callee: Optional[Tuple[int, "entry_t"]] = None

        # following & preceding block in the entrypoint flow
        self.next: Optional[block_t] = None
        self.previous: Optional[block_t] = None

    def has_callee(self) -> bool:
        return self.callee is not None

    def get_callee(self) -> Optional[Tuple[int, "entry_t"]]:
        return self.callee

    # set the called ep following this block & shift applied
    def set_callee(self, callee: "entry_t", shift: int):
        self.callee = (shift, callee)

    def get_owner(self) -> "entry_t":
        return self.owner

    # returns following block in the entrypoint
    def get_next(self) -> "block_t":
        if self.next is None:
            self.next = block_t(self.owner, self.id + 1)
            self.next.previous = self
        return self.next

    def has_field(self, offset: int) -> bool:
        return offset in self.fields

    # get field defined by this block
    def get_field(self, offset: int) -> field_t:
        return self.fields[offset]

    # get all fields
    def get_fields(self) -> Iterator[field_t]:
        return self.fields.values()

    # add / get existing field
    def add_field(self, offset: int, size: int) -> field_t:
        # accept negative offset, a field can be retrieved with a CONTAINING_RECORD()

        if offset not in self.fields:
            self.fields[offset] = field_t(offset)
        self.fields[offset].set_size(size)

        # change size upper boundary
        end = offset + size
        if end > self.max:
            self.max = end

        # change size lower boundary
        if offset < self.min:
            self.min = offset

        return self.fields[offset]

    # get the latest type for a field
    # scope: current block + following (called) entry
    def get_field_type(self, offset: int) -> Optional[ftype_t]:
        ftype = None
        if self.has_callee():
            shift, callee = self.get_callee()
            ftype = callee.get_field_type(offset - shift)

        return self.get_field(offset).get_type() if (ftype is None and self.has_field(offset)) else ftype

    def __eq__(self, other) -> bool:
        return isinstance(other, block_t) and other.id == self.id

    def __hash__(self) -> int:
        return self.id


# data flow entrypoints
# defines a structure's entry into the data flow
# records information defining a structure propagated from the given entrypoint
class entry_t:
    # this kind of ep is to be injected before or after state updates
    inject_before = False

    # this type of ep can have children
    can_ramificate = True

    def __init__(self, ea: int, sub_ea: int = 0):
        self.ea = ea  # entry address
        self.sub_ea = sub_ea  # index of the sub minsn the entry is for
        self.id = -1  # entry identifier

        # for entrypoints defining a structure (root ep)
        self.struc_id = -1

        # structure associated with this entrypoint
        # the structure we will use to type this ep
        self.struc: Optional[generation.structure_t] = None
        self.struc_shift = 0

        # data flow injection parameters
        self.to_analyze = True  # yet to analyze

        # list of operands accessing this ep fields
        # a single op might reference multiple fields (offsets), like in STP, STM arm insns
        self.operands: Dict[Tuple[int, int], Collection[int]] = defaultdict(list)  # (ea, reg_id) -> [offsets]

        # list of the entries that can precede this one in a data flow
        self.parents: Collection[Tuple[int, entry_t]] = deque()

        # list of entries we want to analyze following this one
        self.children: Collection[Tuple[int, entry_t]] = deque()

        # entrypoint size
        self.bounds: Optional[Tuple[int, int]] = None

        self.blocks: Optional[block_t] = None  # list of blocks composing this ep
        self.cblock: Optional[block_t] = None  # current active block

    # does the entry point defines a structure to be generated
    def is_root(self) -> bool:
        return self.struc_id >= 0

    def set_root(self, sid: int):
        self.struc_id = sid

    def has_structure(self) -> bool:
        return self.struc is not None

    def set_structure(self, shift: int, struc: "generation.structure_t"):
        self.struc = struc
        self.struc_shift = shift
        struc.has_xrefs |= self.has_operands()

    # get the structure associated with the entry
    def get_structure(self) -> Tuple[int, "generation.structure_t"]:
        return (self.struc_shift, self.struc)

    # return the function containing this ep
    def get_function(self) -> int:
        return idaapi.BADADDR

    # get all the structures that flow through this ep
    def get_flow(self) -> Collection[Tuple[int, "generation.structure_t"]]:
        flow = set()
        if self.is_root():
            flow.add(self.get_structure())
        for shift, parent in self.get_parents():
            flow.update([(shift + s_shift, s) for s_shift, s in parent.get_flow()])
        return flow

    def add_field(self, offset: int, size: int) -> field_t:
        return self.cblock.add_field(offset, size)

    # get field at given offset
    def get_field(self, offset: int) -> Optional[field_t]:
        return self.cblock.get_field(offset)

    # get the latest type for a field
    # scope: current entry (previous block & callees), at current state (not done analyzing)
    def get_field_type(self, offset: int) -> Optional[ftype_t]:
        ftype = None
        current = self.cblock
        while ftype is None and current is not None:
            ftype = current.get_field_type(offset)
            current = current.previous

        return ftype

    # get ep boundaries, min & max access on ep
    def get_boundaries(self) -> Tuple[int, int]:
        if self.bounds is None:
            lower, upper = 0, 0

            # ep own boundaries
            current = self.blocks
            while current is not None:
                lower = min(lower, current.min)
                upper = max(upper, current.max)
                current = current.next

            # boundaries from ep children
            for off, child in self.get_children(True):
                ci, ca = child.get_boundaries()
                lower = min(lower, ci + off)
                upper = max(upper, ca + off)

            self.bounds = (lower, upper)

        return self.bounds

    # associated accessed operand with this ep
    def add_operand(self, ea: int, off: int, regid: int):
        self.operands[(ea, regid)].append(off)

    def get_operands(self) -> Generator[Tuple[int, int, Collection[int]], None, None]:
        for (ea, regid), offs in self.operands.items():
            yield (ea, regid, offs)

    def has_operands(self) -> bool:
        return len(self.operands) > 0

    # does the given node precede this node in the data flow
    def has_parent(self, parent: "entry_t") -> bool:
        return self == parent or any([p.has_parent(parent) for _, p in self.get_parents()])

    # add parent with given shift
    def add_parent(self, parent: "entry_t", shift: int) -> bool:
        if parent.has_parent(self):  # loop check
            return False

        if (shift, parent) not in self.parents:  # duplicate check
            self.parents.append((shift, parent))
        return True

    # add an entrypoint following this one in the data flow
    def add_child(self, child: "entry_t", shift: int) -> bool:
        if not child.add_parent(self, shift):
            return False

        if (shift, child) not in self.children:
            self.children.append((shift, child))
        return True

    # end the current block, with a call
    # the callee represents an ep to be processed after the current block and before the next one
    def end_block(self, callee: "entry_t", shift: int) -> bool:
        if not callee.add_parent(self, shift):
            return False

        self.cblock.set_callee(callee, shift)
        self.cblock = self.cblock.get_next()
        return True

    # get node's parents
    # yields (shift, parent)
    def get_parents(self) -> Generator[Tuple[int, "entry_t"], None, None]:
        for off, p in self.parents:
            yield (off, p)

    # get node's children
    # if all is set, returns following children + end blocks callee children
    # else only returns following children
    def get_children(self, all: bool = False) -> Generator[Tuple[int, "entry_t"], None, None]:
        if all:
            assert self.blocks is not None

            current = self.blocks
            while current.next is not None:
                yield current.get_callee()
                current = current.next

        for off, c in self.children:
            yield (off, c)

    # get distance to given child
    # assume self is parent of child
    def distance_to(self, child: "entry_t") -> int:
        q = deque()

        q.append((child, 0))
        while len(q) > 0:
            current, distance = q.popleft()
            if current == self:
                return distance

            for _, p in current.get_parents():
                q.append((p, distance + 1))

        raise Exception(f"{self.entry_id()} is not a parent of {child.entry_id()}")

    # inject entrypoint on given state
    # return True if the ep had to be analyzed
    def inject(self, state: cpustate.state_t, reset: bool = True) -> bool:
        if reset:
            self.reset()
        had_to = self.to_analyze
        self.to_analyze = False  # is beeing analyzed
        return had_to

    # reset non-cumulative states when re-propagating
    def reset(self):
        # reset blocks
        self.blocks = block_t(self)
        self.cblock = self.blocks
        utils.g_logger.debug(f"Resetting entry {self.entry_id()}")

    # get unique key identifying the ep from others
    # to be implemented by heirs
    def get_key(self) -> Any:
        raise Exception(f"{self.__class__} does not implement method get_key")

    # find name of the structure associated to this entry point
    # using symbols information
    # returns name, relevance (the least, the more relevant)
    def find_name(self) -> Tuple[Optional[str], int]:
        return None, 0

    def entry_header(self) -> str:
        return "Entry[sid=%d], ea: 0x%x, [%s]" % (
            self.id,
            self.ea,
            ("TO_ANALYZE" if self.to_analyze else "ANALYZED"),
        )

    def entry_id(self) -> str:
        return f"ep_0x{self.ea:x}"

    def __eq__(self, other) -> bool:
        return isinstance(other, entry_t) and other.id == self.id

    def __hash__(self) -> int:
        return self.id

    def __str__(self) -> str:
        out = "%s\n" % self.entry_header()
        out += f"\t| Parents: ({', '.join([str(i.id) for i in self.get_parents()])})\n"

        if len(self.operands) > 0:
            out += "\t| Operands:\n"
            for ea, regid, offs in self.get_operands():
                for off in offs:
                    out += f"\t\t{ida_utils.addr_friendly_name(ea)}, ea: 0x{ea:x}, reg {idaapi.get_reg_name(regid,8)}({regid:#x}), off {off:#x}\n"

        if len(self.children) > 0:
            out += "\t| Children:\n"
            for offset, child in self.children:
                out += f"\t\tentry[sid={child.id}], off: 0x{offset:x}, ea: 0x{child.ea:x}\n"

        return out


# travel the flows of nodes from given entrypoint
# yields (flow root, node, shift)
def flow_from_root(entry: entry_t, all_roots: bool = True) -> Generator[Tuple[entry_t, block_t, int], None, None]:
    roots: Collection[Tuple[int, entry_t]] = deque()
    roots.append((0, entry))

    while len(roots) > 0:
        rshift, root = roots.pop()
        if all_roots:
            roots.extend([(i + rshift, j) for i, j in root.get_children()])

        blocks: Collection[int, block_t] = deque()
        blocks.append((rshift, root.blocks))

        while len(blocks) > 0:
            bshift, node = blocks.pop()
            yield root, node, bshift

            # record next block for latter
            if node.next is not None:
                blocks.append((bshift, node.next))

            # process blocks from direct function call before
            if node.has_callee():
                cshift, callee = node.get_callee()
                blocks.append((bshift + cshift, callee.blocks))

                # childrens are not in this direct flow (ex: virtual method recorded from vtable load)
                # process them as differents roots
                if all_roots:
                    roots.extend([(bshift + cshift + i, j) for i, j in callee.get_children()])


# entrypoint as a method's argument
class arg_entry_t(entry_t):
    inject_before = True

    def __init__(self, ea: int, index: int):
        super().__init__(ea, -1)
        self.index = index

    def get_function(self) -> int:
        return self.ea

    def find_name(self) -> Tuple[Optional[str], int]:
        if self.index != 0:  # TODO use fct arguments types to find names of arguments that are not 'this'
            return None, 0

        fct_name = ida_utils.demangle_ea(self.ea)
        return symbols.get_classname_from_ctor(fct_name), 1

    def inject(self, state: cpustate.state_t) -> bool:
        had_to = super().inject(state, False)

        vdloc = state.fct.get_argloc(self.index)
        state.set_var_from_loc(vdloc, cpustate.sid_t(self.id))

        return had_to

    def get_key(self) -> int:
        return self.index

    def entry_id(self) -> str:
        return f"ep_0x{self.ea:x}_arg{self.index}"

    def entry_header(self) -> str:
        return "Entry[sid=%d], arg %d of %s (0x%x), [%s]" % (
            self.id,
            self.index,
            ida_utils.addr_friendly_name(self.ea),
            self.ea,
            ("TO_ANALYZE" if self.to_analyze else "ANALYZED"),
        )


# entry point in a variable (a micro operand)
# for destination operands (inject_before == False)
class dst_var_entry_t(entry_t):
    def __init__(self, ea: int, sub_ea: int, fct_ea: int, mop: ida_hexrays.mop_t):
        super().__init__(ea, sub_ea)
        self.mop = ida_hexrays.mop_t(mop)  # copy or it gets freed
        assert self.mop.t in (ida_hexrays.mop_r, ida_hexrays.mop_S)

        if self.mop.t == ida_hexrays.mop_r:
            self.key = ida_hexrays.get_mreg_name(self.mop.r, ida_utils.get_ptr_size())
        else:
            self.key = f"stk:#{self.mop.s.off:x}"

        self.fct_ea = fct_ea

    def get_function(self) -> int:
        return self.fct_ea

    def inject(self, state: cpustate.state_t) -> bool:
        had_to = super().inject(state)
        state.set_var_from_mop(self.mop, cpustate.sid_t(self.id))
        return had_to

    def get_key(self) -> str:
        return self.key

    def entry_id(self) -> str:
        return f"ep_0x{self.ea:x}_{self.get_key()}"

    def entry_header(self) -> str:
        return "Entry[sid=%d], %s at ea: 0x%x(%s), [%s]" % (
            self.id,
            self.get_key(),
            self.ea,
            ida_utils.addr_friendly_name(self.ea),
            ("TO_ANALYZE" if self.to_analyze else "ANALYZED"),
        )


# entry point in a register
# as a src operand (inject_before == True)
class src_reg_entry_t(dst_var_entry_t):
    # inject_before needs to be a static member
    # because of its use in get_entry_by_key()
    # thus two reg_entry_t classes are required
    inject_before = True


# entry point as a value read from a structure
# can be used to propagate a structure ptr written & read from a structure
class read_entry_t(dst_var_entry_t):
    can_ramificate = False

    def __init__(self, ea: int, sub_ea: int, fct_ea: int, mop: ida_hexrays.mop_t, source: entry_t, off: int):
        super().__init__(ea, sub_ea, fct_ea, mop)

        # source ep & offset this ep was read from
        self.src = source
        self.src_off = off

    def entry_id(self) -> str:
        return f"ep_rd_0x{self.ea:x}_{self.get_key()}"

    def add_parent(self, parent: "entry_t", shift: int) -> bool:
        raise Exception("read_entry_t are not meant to be linked with parents")


# entry point as an allocation with known size
class alloc_entry_t(dst_var_entry_t):
    def __init__(self, ea: int, sub_ea: int, size: int, mba: ida_hexrays.mba_t):
        super().__init__(ea, sub_ea, mba.entry_ea, ida_hexrays.mop_t(mba.call_result_kreg, ida_utils.get_ptr_size()))
        self.size = size

    # retrieve name from factory function
    # this is not an accurate name for a structure, and is to be used as a last chance name
    def find_name(self) -> Tuple[Optional[str], int]:
        fct = idaapi.get_func(self.ea)
        if fct is None:
            utils.g_logger.error(f"No function for entry {self.entry_id()}, this should not happen")
            return None, 0

        # do not use 'sub_' function names
        if not symbols.has_relevant_name(fct.start_ea):
            return None, 0

        fct_name = symbols.method_name_from_signature(ida_utils.demangle_ea(fct.start_ea))
        return f"struc_{fct_name}", 3

    def add_field(self, offset: int, size: int) -> field_t:
        if offset < 0 or offset + size > self.size:
            return False

        return super().add_field(offset, size)


# constant root entry
# define a known structure we do not need to build on the way
class cst_entry_t(entry_t):
    def __init__(self, ea: int):
        super().__init__(ea)

        self.to_analyze = False

    # do not record accessed fields
    def add_field(self, offset: int, size: int) -> None:
        return None

    # a root has no parents
    def has_parent(self, parent: entry_t) -> bool:
        return False

    def add_parent(self, parent: entry_t, shift: int) -> bool:
        return False

    def end_block(self, callee: entry_t, shift: int) -> bool:
        return False

    def inject(self, state: cpustate.state_t) -> bool:
        raise Exception(f"{self.entry_id()} is not to be injected in the data flow")


# vtable root entry
class vtbl_entry_t(cst_entry_t):
    def __init__(self, vtbl: vtables.vtable_t):
        super().__init__(vtbl.ea)
        self.vtbl = vtbl
        self.reset()  # add default block

        # make fields
        ptr_size = ida_utils.get_ptr_size()
        for i, (fea, _) in enumerate(vtbl.get_members()):
            field = entry_t.add_field(self, i * ptr_size, ptr_size)
            field.set_type(ftype_fct_t(cpustate.mem_t(fea, fea, ptr_size)))

    # get most derived between self and other
    def get_most_derived(self, other: "vtbl_entry_t") -> "vtbl_entry_t":
        if self.vtbl.get_most_derived(other.vtbl) == self.vtbl:
            return self
        return other

    def get_key(self) -> Any:  # ea is enough to discriminate vtables
        return None

    def find_name(self) -> Tuple[Optional[str], int]:
        return symbols.get_vtable_name_from_ctor(self.ea), 0

    def entry_id(self) -> str:
        return f"ep_0x{self.ea:x}_vtbl"

    def entry_header(self) -> str:
        return f"vftable {ida_utils.demangle_ea(self.ea)}"


# records all entrypoints
class entry_record_t:
    g_next_sid = -1

    def __init__(self):
        self.entries_per_sid: List[entry_t] = list()  # entry per sid

        # sorted entries, by ea for quick access
        # & by inject_before / inject_after
        self.entries_per_ea: dict[Tuple[int, int, bool], Collection[entry_t]] = defaultdict(deque)

    # next entry point id
    def next_id(self) -> int:
        return len(self.entries_per_sid)

    def structures_count(self) -> int:
        return entry_record_t.g_next_sid + 1

    # add an entrypoint to the graph
    def add_entry(self, entry: entry_t, as_root: bool = False, inc_sid: bool = True) -> entry_t:
        existing = self.get_entry_by_key(entry.ea, entry.sub_ea, entry.__class__, entry.get_key())
        if existing is not None:
            return existing

        key = (entry.ea, entry.sub_ea, entry.__class__.inject_before)
        self.entries_per_ea[key].append(entry)

        entry.id = self.next_id()
        self.entries_per_sid.append(entry)

        if as_root:
            entry_record_t.g_next_sid += int(inc_sid)
            entry.set_root(entry_record_t.g_next_sid)

        return entry

    # add an entry to the graph, as a child of another entry
    def add_entry_as_child(self, parent: entry_t, child: entry_t, shift: int, block_end: bool) -> Optional[entry_t]:
        # check if parent can have children
        if not parent.__class__.can_ramificate:
            return None

        effective = self.add_entry(child)

        if block_end:
            parent.end_block(effective, shift)
        else:
            parent.add_child(effective, shift)

        return effective

    # remove an entry from the graph, and its successors
    def remove_entry(self, entry: entry_t):
        # entry should not have any parents
        assert len(entry.parents) == 0

        for shift, child in entry.get_children(True):
            child.parents.remove((shift, entry))
            if len(child.parents) == 0:
                self.remove_entry(child)

        self.entries_per_ea[(entry.ea, entry.sub_ea, entry.__class__.inject_before)].remove(entry)
        self.entries_per_sid[entry.id] = None

    # all entries to inject at given ea
    def get_entries_at(self, ea: int, sub_ea: int, inject_before: bool) -> Collection[entry_t]:
        return self.entries_per_ea.get((ea, sub_ea, inject_before), tuple())

    # entry by sid
    def get_entry_by_id(self, sid: int) -> Optional[entry_t]:
        if sid < 0 or sid >= len(self.entries_per_sid):
            return None
        return self.entries_per_sid[sid]

    # entry by ea, class & unique key identifier
    def get_entry_by_key(self, ea: int, sub_ea: int, cls: type, key: Any = None) -> Optional[entry_t]:
        eakey = (ea, sub_ea, cls.inject_before)
        if eakey not in self.entries_per_ea:
            return None

        c = filter(
            lambda e: isinstance(e, cls) and e.get_key() == key,
            self.entries_per_ea[eakey],
        )

        try:
            return next(c)
        except StopIteration:
            return None

    def get_entries(self, analyzed: bool = True) -> Generator[entry_t, None, None]:
        for entry in self.entries_per_sid:
            if entry is not None and not (analyzed and entry.to_analyze):
                yield entry

    # yield all unexplored entrypoints
    # TODO: yield from most interesting function to less (fct having the most entrypoints)
    def next_to_analyze(self) -> Generator[entry_t, None, None]:
        current_len = len(self.entries_per_sid)
        for i in range(current_len):
            if self.entries_per_sid[i].to_analyze:
                yield self.entries_per_sid[i]

    def __str__(self) -> str:
        out = ""
        for entry in self.entries_per_sid:
            out += f"{str(entry)}\n"
        return out


# information about a function's prototype
class prototype_t:
    def __init__(self, ea: int):
        self.ea = ea

        # structure returned by function
        self.ret: Optional[entry_t] = None

        # is a virtual method
        self.virtual = False

    def set_ret(self, ret: entry_t):
        self.ret = ret

    def get_ret(self) -> Optional[entry_t]:
        return self.ret

    def set_virtual(self):
        self.virtual = True

    def is_virtual(self) -> bool:
        return self.virtual

    def __eq__(self, other: object) -> bool:
        return isinstance(other, prototype_t) and self.ea == other.ea


# global model
# groups information gathered by the analysis
class context_t:
    # init from a list of entrypoints and propagation context
    def __init__(self, entries: entry_record_t, allocators: Set[allocators.allocator_t]):
        self.allocators = allocators  # all registered allocators
        self.functions: Dict[int, prototype_t] = dict()  # ea -> prototype_t
        self.graph = entries  # entrypoints tree hierarchy

        # information gathered by data flow
        # is to be deleted once propagation is done
        self.dflow_info: Optional[cpustate.dflow_ctrl_t]

        # propagation context depth
        self.follow_calls = True

        # dive into callee decision
        self.dive_in: bool = False

    def get_function(self, ea: int) -> prototype_t:
        if ea not in self.functions:
            self.functions[ea] = prototype_t(ea)
        return self.functions[ea]

    def get_functions(self) -> Collection[prototype_t]:
        return self.functions.values()

    def get_entrypoints(self) -> entry_record_t:
        return self.graph

    def get_allocators(self) -> Set[allocators.allocator_t]:
        return self.allocators

    def can_follow_calls(self) -> bool:
        return self.follow_calls

    def set_follow_calls(self, follow: bool):
        self.follow_calls = follow

```

`symless/model/entrypoints.py`:

```py
import enum
from collections import defaultdict, deque
from typing import Collection, Dict, Iterable, Set, Tuple, Union

import ida_hexrays
import idaapi

import symless.allocators as allocators
import symless.cpustate.cpustate as cpustate
import symless.utils.ida_utils as ida_utils
import symless.utils.vtables as vtables
from symless.model import *

""" Entry points from memory allocations """


# Type of a memory allocation
class allocation_type(enum.Enum):
    WRAPPED_ALLOCATION = 0  # allocator is just a wrap calling another allocator
    STATIC_SIZE = 1  # static size allocation
    UNKNOWN = 2  # any other case we do not handle


# Analyze a given call to a memory allocator
# defines if the caller is an allocator wrapper, or if the call is a static allocation (known size)
def analyze_allocation(
    caller: idaapi.func_t, allocator: allocators.allocator_t, call_ea: int
) -> Tuple[allocation_type, Union[allocators.allocator_t, alloc_entry_t, None]]:
    action, wrapper_args = None, None

    params = cpustate.dflow_ctrl_t(depth=0)
    for ea, sub_ea, state in cpustate.generate_state(caller, params):
        if ea == call_ea and state.has_call_info() and action is None:
            action, wrapper_args = allocator.on_call(state)

            # caller calls allocator, with size argument passed through
            if action == allocators.alloc_action_t.WRAPPED_ALLOCATOR:
                pass

            # known size allocation
            elif action == allocators.alloc_action_t.STATIC_ALLOCATION:
                return (allocation_type.STATIC_SIZE, alloc_entry_t(ea, sub_ea, wrapper_args, state.mba))

            # unknown size allocation
            elif action == allocators.alloc_action_t.UNDEFINED:
                return (allocation_type.UNKNOWN, None)

        # allocator wrapper returns the allocation
        elif action and state.has_ret_info() and allocator.on_wrapper_ret(state, call_ea):
            return (allocation_type.WRAPPED_ALLOCATION, allocator.get_child(caller.start_ea, wrapper_args))

    return (allocation_type.UNKNOWN, None)


# Analyze all calls to a memory allocator and its wrappers
# returns a set of entrypoints (static allocations) made with this allocator
def analyze_allocator_heirs(
    allocator: allocators.allocator_t,
    allocs: Set[allocators.allocator_t],
    entries: entry_record_t,
):
    if allocator in allocs:  # avoid infinite recursion if crossed xrefs
        return
    allocs.add(allocator)

    # for all xrefs to allocator
    for allocation_ea in ida_utils.get_all_references(allocator.ea):
        # function referencing the allocator
        caller = idaapi.get_func(allocation_ea)
        if caller is None:
            continue

        # instruction referencing the allocator
        call_insn = ida_utils.get_ins_microcode(allocation_ea)
        if call_insn is None:
            continue

        utils.g_logger.debug(f"Analyzing xref {allocation_ea:#x}: {call_insn.dstr()} to allocator {allocator}")

        # verify this is a call / jmp instruction
        if call_insn.opcode not in (ida_hexrays.m_call, ida_hexrays.m_icall, ida_hexrays.m_goto, ida_hexrays.m_ijmp):
            continue

        type, alloc = analyze_allocation(caller, allocator, allocation_ea)

        if type == allocation_type.WRAPPED_ALLOCATION:
            utils.g_logger.debug(f"{allocation_ea:#x} is a wrap around {allocator}")
            analyze_allocator_heirs(alloc, allocs, entries)

        elif type == allocation_type.STATIC_SIZE:
            utils.g_logger.debug(f"{allocation_ea:#x} is a static allocation of {alloc.size:#x}")
            entries.add_entry(alloc, True)


# get all entrypoints from defined allocators
def get_allocations_entrypoints(
    imports: Iterable[allocators.allocator_t], entries: entry_record_t
) -> Set[allocators.allocator_t]:
    allocators = set()

    for i in imports:
        analyze_allocator_heirs(i, allocators, entries)

    return allocators


""" Entry points from ctors & dtors """


# a constructor / destructor and the vtables it loads into the 'this' object
class ctor_t:
    def __init__(self, func: idaapi.func_t):
        self.func = func

        # vtables loaded into the 'this' object by this ctor
        self.vtables: Dict[vtables.vtable_t, Optional[int]] = dict()  # vtbl_ea -> load_offset

    # get what we think is the right vtable for the class associated with this ctor
    def get_associated_vtable(self) -> Tuple[vtables.vtable_t, int]:
        candidates = [(vtbl, off) for (vtbl, off) in self.vtables.items() if off is not None]
        candidates.sort(key=lambda k: k[1], reverse=True)

        vtbl, off = candidates.pop()  # at least one candidate should be present
        while len(candidates) > 0:
            vtbl2, off2 = candidates.pop()
            if off2 != off:
                break
            vtbl = vtbl.get_most_derived(vtbl2)  # conflict, try to find the inheriting vtable

        return (vtbl, off)


# analyse given ctor, returns True if it really is a ctor
def analyze_ctor(ctor: ctor_t) -> bool:
    ptr_size = ida_utils.get_ptr_size()
    yet_to_see = set(ctor.vtables.keys())

    mba = ida_utils.get_func_microcode(ctor.func)
    if mba is None:
        return False

    params = cpustate.dflow_ctrl_t(depth=0)
    state = cpustate.state_t(mba, params.get_function_for_mba(mba))

    if state.fct.get_args_count() == 0:  # function does not take a 'this' argument
        return False
    state.set_var_from_loc(state.fct.get_argloc(0), cpustate.sid_t(0))

    ret = False
    for _, _, state in cpustate.function_data_flow(state, params):
        if len(yet_to_see) == 0:  # nothing more to see
            return ret

        for write in state.writes:
            if write.size != ptr_size or not isinstance(write.value, cpustate.mem_t):
                continue

            val = write.value.get_uval()
            if val not in yet_to_see:  # written value is one of our vtables ea
                continue
            yet_to_see.remove(val)

            # value is written in our 'this' object
            if not isinstance(write.target, cpustate.sid_t):
                continue

            # update shift for vtable
            utils.g_logger.debug(f"Load for vtbl {val:#x} into this:{write.target.shift:x}")
            ctor.vtables[val] = write.target.shift
            ret = True

    return ret


# get ctors & dtors families
def get_ctors() -> Dict[int, Collection[ctor_t]]:
    all_ctors: Dict[int, ctor_t] = dict()
    ctors_for_family: Dict[int, Collection[ctor_t]] = defaultdict(deque)

    # make record of candidates ctors & the vtables they load
    for vtbl in vtables.get_all_vtables():
        for xref in vtbl.get_loads():
            fct = idaapi.get_func(xref)  # can not return None
            if fct.start_ea not in all_ctors:
                all_ctors[fct.start_ea] = ctor_t(fct)
            all_ctors[fct.start_ea].vtables[vtbl] = None

    # analyze all ctors, find the base vtable for their class
    for ctor in all_ctors.values():
        utils.g_logger.debug(
            f"Analyzing fct {ctor.func.start_ea:#x} for {len(ctor.vtables.keys())} vtables loads into 'this'"
        )
        if not analyze_ctor(ctor):
            continue

        vtbl, offset = ctor.get_associated_vtable()
        utils.g_logger.info(f"Found one ctor/dtor @ {ctor.func.start_ea:#x} for vtbl {vtbl.ea:#x} (off {offset:#x})")

        if offset != 0:  # we are only interested in vtables loaded at off:0
            continue

        ctors_for_family[vtbl.ea].append(ctor)

    return ctors_for_family


# get all entrypoints from identified ctors / dtors
def get_ctors_entrypoints(entries: entry_record_t):
    for fam in get_ctors().values():
        for i, ctor in enumerate(fam):
            entries.add_entry(arg_entry_t(ctor.func.start_ea, 0), True, i == 0)


# find root entrypoints, from classes & allocators found in the base
def retrieve_entrypoints(imports: Iterable[allocators.allocator_t]) -> context_t:
    entries = entry_record_t()

    allocators = get_allocations_entrypoints(imports, entries)

    get_ctors_entrypoints(entries)

    return context_t(entries, allocators)

```

`symless/model/model.py`:

```py
import idaapi

import symless.cpustate.cpustate as cpustate
import symless.utils.ida_utils as ida_utils
import symless.utils.vtables as vtables
from symless.model import *
from symless.utils.utils import g_logger as logger

""" Propagation actions handlers """


# handle function ret, record ret type for function typing
def handle_ret(state: cpustate.state_t, ctx: context_t):
    if state.ret is None:
        return

    # only record struct pointer returned without shift
    if not isinstance(state.ret, cpustate.sid_t) or state.ret.shift != 0:
        return

    prot = ctx.get_function(state.get_fea())
    prot.set_ret(ctx.graph.get_entry_by_id(state.ret.sid))


# Build model members from state access
def handle_access(ea: int, sub_ea: int, state: cpustate.state_t, ctx: context_t):
    for access in state.accesses:
        struc = access.target

        # a structure is accessed
        if not isinstance(struc, cpustate.sid_t):
            continue

        offset = access.target.shift
        size = access.size

        # record field beeing accessed
        # do not make field for access of unknown (0) size
        entry = ctx.graph.get_entry_by_id(struc.sid)
        if size != 0:
            f = entry.add_field(offset, size)
            logger.debug(f"{ea:#x}.{sub_ea:x}: adding {f} to {entry.entry_id()}")

        # record operand for the access, to type later
        # we only care about regs operands
        if access.loc.t == ida_hexrays.mop_r:
            regid = ida_hexrays.mreg2reg(access.loc.r, access.loc.size)
            if regid == -1:  # special kreg, nothing to type
                return

            logger.debug(f"{ea:#x}.{sub_ea:x}: add operand to {entry.entry_id()} at offset 0x{offset:x}")
            entry.add_operand(ea, offset, regid)


# add arg_0 entry for each virtual method
# assuming every virtual method takes 'this' as first argument
# we are aware that in some cases this is not right ('this' unused by virtual method + optimization)
def analyze_virtual_methods(vtbl: vtables.vtable_t, current: entry_t, offset: int, ctx: context_t):
    if not ctx.can_follow_calls():
        return

    for fea, _ in vtbl.get_members():
        fct = idaapi.get_func(fea)
        if fct is None:  # no body for virtual method, it may be an import
            continue

        model = ctx.dflow_info.get_function(fct)

        # virtual method should have at least one argument (this)
        # if not we have no interest in analysing it
        if model is None or model.get_args_count() == 0:
            continue

        # add entry to analyse
        child = ctx.graph.add_entry_as_child(current, arg_entry_t(fea, 0), offset, False)
        if child is not None:
            logger.debug(f"Add virtual method 0x{fea:x}, {child.entry_id()}, as child of {current.entry_id()}")

        # mark function as virtual
        prot = ctx.get_function(fea)
        prot.set_virtual()


# Handle writes to struc members
def handle_write(ea: int, sub_ea: int, state: cpustate.state_t, ctx: context_t):
    ptr_size = ida_utils.get_ptr_size()

    for write in state.writes:
        struc = write.target
        size = write.size

        # mov [sid + offset], mem -> ptr loaded
        if not (isinstance(struc, cpustate.sid_t) and isinstance(write.value, cpustate.mem_t) and size == ptr_size):
            continue

        offset = struc.shift

        value = write.value.get_uval()
        entry = ctx.graph.get_entry_by_id(struc.sid)

        # check if addr is a vtable
        vtbl = vtables.vtable_t(value)

        # value is not a vtable address
        if not vtbl.valid():
            type = ftype_ptr_t(write.value)
            logger.debug(f'{ea:#x}.{sub_ea:x}: add type "{type}" to field 0x{offset:x} of {entry.entry_id()}')

        else:
            # record vtable loading sites
            # used later in conflicts to differentiate a base vtable from an inherinting one
            vtbl.search_loads()

            # get / create vtable entry point
            vtbl_entry = ctx.graph.add_entry(vtbl_entry_t(vtbl), True)
            type = ftype_struc_t(vtbl_entry)

            logger.debug(
                f"{ea:#x}.{sub_ea:x} associate {vtbl_entry.entry_id()} to field 0x{offset:x} of {entry.entry_id()}"
            )

            # add entrypoints to analyze virtual methods
            analyze_virtual_methods(vtbl, entry, offset, ctx)

        # type structure field with retrieved type
        entry.get_field(offset).set_type(type)


# Handle read of struct members
def handle_read(ea: int, sub_ea: int, state: cpustate.state_t, ctx: context_t):
    ptr_size = ida_utils.get_ptr_size()

    for read in state.reads:
        struc = read.target
        size = read.size

        # mov reg, [sid + offset]
        if not isinstance(struc, cpustate.sid_t):
            continue

        offset = struc.shift

        entry = ctx.graph.get_entry_by_id(struc.sid)

        # do not expand entries graph too much from read_entry_t leaves
        if isinstance(entry, read_entry_t):
            logger.debug(f"Ignoring read from {entry.entry_id()}")
            continue

        # no fixed value, propagate read entrypoint
        rtype = entry.get_field_type(offset)
        if rtype is None and size == ptr_size:
            r_entry = ctx.graph.add_entry(read_entry_t(ea, sub_ea, state.get_fea(), read.dst, entry, offset))
            logger.debug(f"{ea:#x}.{sub_ea:x}: type not known, propagating {r_entry.entry_id()}")

        elif rtype is None:
            pass

        # a struc ptr is read
        elif isinstance(rtype, ftype_struc_t):
            r_entry = ctx.graph.add_entry_as_child(
                rtype.entry, dst_var_entry_t(ea, sub_ea, state.get_fea(), read.dst), 0, False
            )
            if r_entry is not None:
                logger.debug(f"{ea:#x}.{sub_ea:x} from {rtype.entry.entry_id()}, propagating {r_entry.entry_id()}")

        # propagate any field
        else:
            state.set_var_from_mop(read.dst, rtype.get_propagated_value())
            logger.debug(f"{ea:#x}.{sub_ea:x}: propagating read type {rtype}")


# handle call, add entrypoints in callee
def handle_call(ea: int, sub_ea: int, state: cpustate.state_t, ctx: context_t):
    if not ctx.can_follow_calls():
        return

    if state.call_to is not None:
        ctx.dive_in = False  # default: do not dive in every callee
        call_ea = state.call_to.start_ea

        callee_model = ctx.dflow_info.get_function(state.call_to)
        if callee_model is None:
            return  # function mba could not be generated, analysis is not possible

        # callsite nargs can differ from callee nargs
        callee_nargs = min(len(state.call_args), callee_model.get_args_count())

        # look for entries to be propagated as callee's arguments
        epc = 0
        for i in range(callee_nargs):
            arg = state.call_args[i]

            if not isinstance(arg, cpustate.sid_t):
                continue

            entry = ctx.graph.get_entry_by_id(arg.sid)  # current entry as caller-to-callee arg

            # create new arg entry point
            # one entry point is restricted to be propagated in only one function
            epc += int(ctx.graph.add_entry_as_child(entry, arg_entry_t(call_ea, i), arg.shift, True) is not None)

        logger.debug(f"{ea:#x}.{sub_ea:x}, {epc} entrypoints recorded")


# handle new cpu state
def handle_state(ea: int, sub_ea: int, state: cpustate.state_t, ctx: context_t):
    handle_access(ea, sub_ea, state, ctx)
    handle_write(ea, sub_ea, state, ctx)
    handle_read(ea, sub_ea, state, ctx)
    handle_call(ea, sub_ea, state, ctx)
    handle_ret(state, ctx)


""" Entrypoints analysis & entries graph building """


# diving decision callback - dive if we have sid to propagate
def dive_in(callee: cpustate.function_t, state: cpustate.state_t, ctx: context_t) -> bool:
    dive = ctx.dive_in  # get context dive_in decision

    # root function, propagate
    if ctx.dflow_info.depth == ctx.dflow_info.max_depth:
        dive = True

    if dive:
        # arguments entries are to be built (again ?), reset their states
        for ep in ctx.graph.get_entries_at(callee.ea, -1, arg_entry_t.inject_before):
            ep.reset()
    utils.g_logger.debug("Diving into fct 0x%x: %s" % (callee.ea, "YES" if dive else "NO"))
    return dive


# injector callback, inject entrypoints into cpustate
def model_injector(state: cpustate.state_t, ea: int, sub_ea: int, before_update: bool, ctx: context_t):
    for ep in ctx.graph.get_entries_at(ea, sub_ea, before_update):
        utils.g_logger.debug(f"Injecting {ep.entry_id()} at {ea:#x}.{sub_ea:x}")
        ctx.dive_in |= ep.inject(state)  # dive in callee if new eps are to be analyzed


# entrypoints graph builder
# from original entrypoints, builds a propagation graph
# that can later be used to build structures
def analyze_entrypoints(ctx: context_t):
    entries = ctx.get_entrypoints()

    # injector callback
    def inject_cb(state: cpustate.state_t, ea: int, sub_ea: int, before_update: bool):
        model_injector(state, ea, sub_ea, before_update, ctx)

    inject = cpustate.injector_t(inject_cb, 3)

    # follow callees, use dive_in() decisions
    if ctx.can_follow_calls():
        ctx.dflow_info = cpustate.dflow_ctrl_t(inject, lambda callee, state: dive_in(callee, state, ctx))

    # only propagate in root function
    else:
        ctx.dflow_info = cpustate.dflow_ctrl_t(inject, lambda callee, state: dive_in(callee, state, ctx), depth=0)

    # analyse entrypoints by waves
    current_count = 1
    current_wave = 0
    while current_count > 0:
        current_count = 0
        for entry in entries.next_to_analyze():
            current_count += 1

            logger.debug(f"Analyzing entry {entry.entry_header()} ..")

            func = idaapi.get_func(entry.ea)
            for ea, sub_ea, state in cpustate.generate_state(func, ctx.dflow_info):
                handle_state(ea, sub_ea, state, ctx)

            # entrypoint was not injected
            # this happens when the user selects an entrypoint that gets deleted from the mba after call analysis
            # solution for now: let the user select another entrypoint, or update the mba
            if entry.to_analyze:
                logger.error(
                    f"Entry {entry.entry_header()} was not injected because it is unvalid - Redo the analysis."
                )
                current_count = 0
                break

        logger.debug(f"Entrypoints wave {current_wave} has been analyzed (total: {current_count})")
        current_wave += 1

    # remove propagation data from model
    del ctx.dflow_info

```

`symless/plugins/__init__.py`:

```py
# a plugin extension to be incorporated into symless plugin
class plugin_t:
    # load the plugin
    def __init__(self):
        pass

    # the extension has been reloaded
    def reload(self):
        pass

    # terminate & clean the extension
    def term(self):
        pass


# entry function to be defined by every additional plugin
def get_plugin() -> plugin_t:
    return None

```

`symless/plugins/builder.py`:

```py
import os
from collections import deque
from dataclasses import dataclass
from typing import Collection, Optional, Tuple

import ida_hexrays
import idaapi
from PyQt5 import QtCore, QtGui, QtWidgets

import symless
import symless.cpustate.arch as arch
import symless.generation.generate as generate
import symless.generation.structures as structures
import symless.model.model as model
import symless.utils.ida_utils as ida_utils
import symless.utils.utils as utils
from symless.plugins import *

# builder window title
WINDOW_TITLE = "Symless structure builder"

# fictive color_t used for tagging elements in our microcode view
COLOR_TARGET = idaapi.COLOR_OPND1
SCOLOR_TARGET = chr(COLOR_TARGET)


# Structure builder plugin extension
class BuilderPlugin(plugin_t):
    def __init__(self):
        self.uihook = PopUpHook()
        self.uihook.hook()

    def reload(self):
        self.uihook.init_action()

    def term(self):
        self.uihook.unhook()
        if self.uihook.loaded:
            self.uihook.term()


# retrieve the extension
def get_plugin() -> plugin_t:
    return BuilderPlugin()


# a selected micro-operand for data flow entrypoint
@dataclass
class mop_sel_t:
    ea: int  # insn ea
    sub_idx: int  # sub insn idx
    mop: ida_hexrays.mop_t  # selected mop
    as_dst: bool  # is dst operand

    def __str__(self) -> str:
        if self.mop.t == ida_hexrays.mop_r:
            name = ida_hexrays.get_mreg_name(self.mop.r, self.mop.size)
        elif self.mop.t == ida_hexrays.mop_S:
            name = f"stk:#{self.mop.s.off:x}"
        return f"{name} @ {self.ea:#x}.{self.sub_idx:x} ({'DST' if self.as_dst else 'SRC'})"


# context for parsing microinstruction and extracting operands
class minsn_parse_ctx_t:
    def __init__(self, mba: ida_hexrays.mba_t, ea: int):
        self.mba = mba
        self.ea = ea
        self.sub_idx = 0
        self.targets: Collection[mop_sel_t] = deque()

    def add_mop(self, mop: ida_hexrays.mop_t, as_dst: bool):
        self.targets.append(mop_sel_t(self.ea, self.sub_idx, ida_hexrays.mop_t(mop), as_dst))

    def next_subinsn(self):
        self.sub_idx += 1


# get simplified name for global at ea
# to be displayed in microcode view
def get_simplified_gbl_name(ea: int) -> str:
    d = ida_utils.demangle_ea(ea)
    if not len(d):
        return f"off_{ea:#x}"
    if "(" in d:
        return d.split("(")[0]
    return d


# parse a microcode operand
# returns its str representation & update the contained micro-operands in the context
# as_dst: operand value gets updated by the instruction
def parse_mop(ctx: minsn_parse_ctx_t, op: ida_hexrays.mop_t, as_dst: bool = False) -> Optional[str]:  # noqa: C901
    if op.t == ida_hexrays.mop_z:  # none
        return None

    if op.t == ida_hexrays.mop_r:  # micro register
        ctx.add_mop(op, as_dst)  # add as target variable
        return idaapi.COLSTR(idaapi.COLSTR(ida_hexrays.get_mreg_name(op.r, op.size), SCOLOR_TARGET), idaapi.SCOLOR_REG)

    if op.t == ida_hexrays.mop_n:  # immediate (number)
        return f"#{idaapi.COLSTR(hex(op.signed_value()), idaapi.SCOLOR_NUMBER)}"

    if op.t == ida_hexrays.mop_str:  # immediate (string)
        return f'"{idaapi.COLSTR(op.cstr, idaapi.SCOLOR_STRING)}"'

    if op.t == ida_hexrays.mop_d:  # result of another instruction
        in_repr = parse_minsn(ctx, op.d, True)
        ctx.next_subinsn()
        return in_repr

    if op.t == ida_hexrays.mop_S:  # local stack variable
        member = op.s.get_stkvar(None)
        if member in (None, -1):  # happens
            return idaapi.COLSTR(f"stk:#{op.s.off:x}", idaapi.SCOLOR_LOCNAME)
        ctx.add_mop(op, as_dst)

        if isinstance(member, int):  # IDA 9 API changed get_stkvar() prototype
            m = idaapi.udm_t()
            op.s.get_stkvar(m)
            varname = m.name

        # IDA 8 case
        else:
            varname = idaapi.get_member_name(member.id)

        return idaapi.COLSTR(idaapi.COLSTR(varname, SCOLOR_TARGET), idaapi.SCOLOR_LOCNAME)

    if op.t == ida_hexrays.mop_v:  # global variable
        color = idaapi.SCOLOR_DNAME
        if idaapi.get_func(op.g) is not None:
            color = idaapi.SCOLOR_CNAME
        return idaapi.COLSTR(get_simplified_gbl_name(op.g), color)

    if op.t == ida_hexrays.mop_b:  # micro basic block
        b = ctx.mba.get_mblock(op.b)
        assert b.serial == op.b
        return f"{b.start:#x}"  # type == BLT_STOP -> ret

    if op.t == ida_hexrays.mop_f:  # args list
        return f"({', '.join([parse_mop(ctx, i) for i in op.f.args])})"

    if op.t == ida_hexrays.mop_l:  # local variable
        return idaapi.COLSTR("?", idaapi.SCOLOR_LOCNAME)  # should only exist at MMAT_LVARS maturity

    if op.t == ida_hexrays.mop_a:  # address of operand
        return f"&({parse_mop(ctx, op.a)})"

    if op.t == ida_hexrays.mop_h:  # helper function
        return idaapi.COLSTR(op.helper, idaapi.SCOLOR_MACRO)

    if op.t == ida_hexrays.mop_c:  # mcases
        return idaapi.tag_remove(op.c._print())  # TODO test me

    if op.t == ida_hexrays.mop_fn:  # floating constant
        return idaapi.COLSTR(idaapi.tag_remove(op.fpc._print()), idaapi.SCOLOR_NUMBER)  # TODO test me

    if op.t == ida_hexrays.mop_p:  # operands pair
        return f"({parse_mop(ctx, op.pair.lop, as_dst)}, {parse_mop(ctx, op.pair.hop, as_dst)})"

    if op.t == ida_hexrays.mop_sc:  # scattered
        return op.scif.name  # TODO test me

    return "?"


# parse microcode instruction
# returns a str representation of the instruction + the variable it contains
# provides a simpler representation than the one given by insn._print()
def parse_minsn(ctx: minsn_parse_ctx_t, insn: ida_hexrays.minsn_t, inlined: bool = False) -> str:
    ops_repr = filter(
        lambda k: k is not None,
        [parse_mop(ctx, i, j) for (i, j) in ((insn.l, False), (insn.r, False), (insn.d, insn.modifies_d()))],
    )

    repr_ = None  # out string representation
    par_ = ("(", ")") if inlined else ("", "")
    padd = 0 if inlined else 9

    # call special format
    if insn.opcode == ida_hexrays.m_call:
        repr_ = f"{idaapi.COLSTR(ida_utils.g_mcode_name[insn.opcode], idaapi.SCOLOR_INSN):{' '}<{padd}} {next(ops_repr)}{next(ops_repr, '()')}"

    # special "ret" goto
    elif (
        insn.opcode == ida_hexrays.m_goto
        and insn.l.t == ida_hexrays.mop_b
        and ctx.mba.get_mblock(insn.l.b).type == ida_hexrays.BLT_STOP
    ):
        repr_ = idaapi.COLSTR("ret", idaapi.SCOLOR_INSN)

    # special embedded operations
    elif inlined and insn.d.t == ida_hexrays.mop_z:
        if insn.opcode == ida_hexrays.m_add:
            repr_ = f"{next(ops_repr)}+{next(ops_repr)}"
        elif insn.opcode == ida_hexrays.m_sub:
            repr_ = f"{next(ops_repr)}-{next(ops_repr)}"
        elif insn.opcode == ida_hexrays.m_mul:
            repr_ = f"{next(ops_repr)}*{next(ops_repr)}"
        elif insn.opcode == ida_hexrays.m_shl:
            repr_ = f"{next(ops_repr)}<<{next(ops_repr)}"
        elif insn.opcode == ida_hexrays.m_shr:
            repr_ = f"{next(ops_repr)}>>{next(ops_repr)}"
        elif insn.opcode == ida_hexrays.m_or:
            repr_ = f"{next(ops_repr)}|{next(ops_repr)}"
        elif insn.opcode == ida_hexrays.m_and:
            repr_ = f"{next(ops_repr)}&{next(ops_repr)}"
        elif insn.opcode == ida_hexrays.m_xor:
            repr_ = f"{next(ops_repr)}^{next(ops_repr)}"
        elif insn.opcode == ida_hexrays.m_ldx:
            repr_ = f"{next(ops_repr)}:{next(ops_repr)}"
            par_ = ("[", "]")

    # default repr
    if repr_ is None:
        repr_ = f"{idaapi.COLSTR(ida_utils.g_mcode_name[insn.opcode], idaapi.SCOLOR_INSN):{' '}<{padd}} {', '.join(ops_repr)}"

    # return insn representation within appropriate parentheses
    return f"{par_[0]}{repr_}{par_[1]}"


def find_in_line_wrapper(
    range: idaapi.tagged_line_section_t, line: idaapi.tagged_line_sections_t, tag: int
) -> idaapi.tagged_line_section_t:
    if hasattr(line, "find_in"):
        return line.find_in(range, tag)  # IDA 8
    return line.nearest_after(range, range.start, tag)  # IDA 9


# view of the current function (simplified) microcode
# for the user to select the propagation entry variable
class MicrocodeViewer(idaapi.simplecustviewer_t):
    def __init__(self, mba: ida_hexrays.mba_t, current_ea: int, hint: Tuple[int, int]):
        super().__init__()
        self.mba = mba
        guess_mreg, guess_size = hint  # guess for target variable

        # chosen target (insn ea, operand, is a dst operand ?)
        self.chosen: Optional[mop_sel_t] = None

        # list of valid target operands for each line
        self.ops_per_line: Collection[Optional[Collection[mop_sel_t]]] = list()

        self.Create("Symless microcode view")

        # fill view with microinstructions
        block = self.mba.blocks
        _jump = True
        while block:
            insn = block.head
            while insn:
                # print(idaapi.tag_remove(insn._print()))

                ctx = minsn_parse_ctx_t(self.mba, insn.ea)
                insn_repr = parse_minsn(ctx, insn)
                self.ops_per_line.append(ctx.targets)

                # set line in listing
                if _jump and insn.ea >= current_ea:
                    self.AddLine(f"{idaapi.COLSTR(hex(insn.ea), idaapi.SCOLOR_INSN)}  {insn_repr}")
                    self.Jump(self.Count() - 1)
                    _jump = False
                else:
                    self.AddLine(f"{idaapi.COLSTR(hex(insn.ea), idaapi.SCOLOR_PREFIX)}  {insn_repr}")

                # find target mvar from hint
                # if multiple mvar match hint, the last one is selected
                if insn.ea == current_ea and self.chosen is None:
                    for i, mvar in enumerate(ctx.targets):
                        if mvar.mop.t == ida_hexrays.mop_r and mvar.mop.r == guess_mreg and mvar.mop.size == guess_size:
                            self.set_chosen(self.Count() - 1, i)
                            break

                insn = insn.next
            block = block.nextb
            if block:  # basic block boundaries
                self.ops_per_line.append(None)  # account for empty lines
                self.AddLine("")

        # remove IDA status bar
        qwidget = idaapi.PluginForm.TWidgetToPyQtWidget(self.GetWidget())
        for child in qwidget.children():
            if isinstance(child, QtWidgets.QStatusBar):
                child.setMaximumHeight(0)

        qwidget.setMinimumWidth(512)

    # get index of given section in given line
    # use improper method because tagged_line_sections_t are not iterable in IDA python
    def index_of_sect_in_line(self, section: idaapi.tagged_line_section_t, line: idaapi.tagged_line_sections_t) -> int:
        range = idaapi.tagged_line_section_t()
        range.start = 0
        range.length = 0xFFFF

        # loop over the tagged sections of the line
        i = 0
        current = find_in_line_wrapper(range, line, COLOR_TARGET)
        while current and current.valid():
            if section.start == current.start and section.length == current.length:
                break
            i += 1
            range.start = current.start + current.length
            current = find_in_line_wrapper(range, line, COLOR_TARGET)
        return i

    # resfresh the view & try to disable (again) the default highlighting
    def OnCursorPosChanged(self):
        self.Refresh()
        idaapi.set_highlight(self.GetWidget(), None, idaapi.HIF_LOCKED)
        self.Close()

    # set chosen target variable to given (line, idx) variable
    def set_chosen(self, line: int, idx: int):
        # highligth selected var
        old_line = self.GetLine(line)[0]
        pat_off, pat_end = 0, 0
        for _ in range(idx + 1):
            pat_off = old_line.find(idaapi.SCOLOR_ON + SCOLOR_TARGET, pat_end, len(old_line))
            pat_end = old_line.find(idaapi.SCOLOR_OFF + SCOLOR_TARGET, pat_off, len(old_line)) + 2
        self.EditLine(
            line,
            old_line[:pat_off]
            + old_line[pat_off:pat_end].replace(SCOLOR_TARGET, idaapi.SCOLOR_ERROR)
            + old_line[pat_end:],
        )

        # set appropriate chosen
        self.chosen = self.ops_per_line[line][idx]
        utils.g_logger.debug(f"selected variable is {self.chosen}")

    # forget current selection
    def forget_chosen(self):
        for i in range(self.Count()):
            line = self.GetLine(i)[0]
            if idaapi.SCOLOR_ERROR in line:
                self.EditLine(i, line.replace(idaapi.SCOLOR_ERROR, SCOLOR_TARGET))
        self.Refresh()

        self.chosen = None

    # the user clicked (hopefully) a target variable
    def OnClick(self, shift):
        self.forget_chosen()  # clear any previous selection

        # click location
        loc = idaapi.listing_location_t()
        if not idaapi.get_custom_viewer_location(loc, self.GetWidget(), idaapi.CVLF_USE_MOUSE):
            return False

        # click location as coords
        y, x, _ = self.GetPos()

        # get clicked variable
        nearest = loc.tagged_sections.nearest_at(x, COLOR_TARGET)
        if nearest is None or not nearest.valid():
            return False

        # get variable idx in line
        var_idx = self.index_of_sect_in_line(nearest, loc.tagged_sections)

        self.set_chosen(y, var_idx)
        return True


"""
class StackViewer(idaapi.simplecustviewer_t):
    def __init__(self, fea: int):
        super().__init__()
        self.Create("Symless stack view")
        self.selected = None
        func = idaapi.get_func(fea)
        frame = idaapi.get_frame(func)
        if not frame:
            utils.g_logger.warning("No frame found")
            return
        self.items = []
        for offset, name, size in idautils.StructMembers(frame.id):
            # Get the member ID and type
            mptr: idaapi.member_t = idaapi.get_member_by_name(frame, name)
            tif = idaapi.tinfo_t()
            idaapi.get_member_tinfo(tif, mptr)
            mtype = idaapi.print_tinfo("", 0, 0, idaapi.PRTYPE_1LINE, tif, "", "")
            if mtype is None:
                mtype = "unknown"

            # Add the details to the items list
            self.items.append([hex(offset), name, hex(size), mtype])
            self.AddLine(
                f"{idaapi.COLSTR('rsp+0x{:04x}'.format(offset), idaapi.SCOLOR_KEYWORD)} "
                f"{idaapi.COLSTR(name.ljust(10), idaapi.SCOLOR_DNAME)} "
                f"{idaapi.COLSTR(mtype, idaapi.SCOLOR_NUMBER)}"
            )

        # remove status bar
        qwidget = idaapi.PluginForm.TWidgetToPyQtWidget(self.GetWidget())
        for child in qwidget.children():
            if isinstance(child, QtWidgets.QStatusBar):
                child.setMaximumHeight(0)
        qwidget.setMinimumWidth(384)

    def OnClick(self, shift):
        if self.selected is not None:
            line, _, _ = self.GetLine(self.selected)
            self.EditLine(self.selected, line[2:])

        line_no, x, y = self.GetPos()
        if line_no != self.selected:
            self.EditLine(line_no, f"> {self.GetCurrentLine()}")
            self.selected = line_no
            self.Refresh()
"""


# a line in the structures list
class StrucSelItem(QtWidgets.QListWidgetItem):
    def __init__(self, struc_name: str, size: int = 0):
        super().__init__(struc_name)
        self.name = struc_name
        self.size = size

    def get_name(self) -> str:
        return self.name

    def get_size(self) -> int:
        return self.size


# default option for structure selector
class StrucSelDefaultItem(QtWidgets.QListWidgetItem):
    def __init__(self):
        super().__init__("New structure")
        icon = QtGui.QIcon(os.path.join(os.path.abspath(symless.__path__[0]), "resources", "cross.png"))
        self.setIcon(icon)
        ft = QtGui.QFont()
        ft.setBold(True)
        self.setData(QtCore.Qt.FontRole, ft)

    def get_size(self) -> int:
        return 0


# structure selector (list)
class StrucSelWid(QtWidgets.QListWidget):
    def __init__(self, parent: QtWidgets.QWidget = None):
        super().__init__(parent)

        self.setWhatsThis("Select a structure to propagate.")

        # Get structures from local types
        tif = idaapi.tinfo_t()
        for id in range(1, idaapi.get_ordinal_count(None)):
            if tif.get_numbered_type(None, id) and (tif.is_struct() or tif.is_forward_struct()):
                local_type_name = idaapi.idc_get_local_type_name(id)
                self.addItem(StrucSelItem(local_type_name, 0 if tif.is_forward_struct() else tif.get_size()))
        self.sortItems()

        # default option
        default = StrucSelDefaultItem()
        self.insertItem(0, default)
        self.setCurrentItem(default)

    def sizeHint(self) -> QtCore.QSize:
        size = super().sizeHint()
        size.setHeight(256)
        return size


# base class for a tab in our plugin's UI
class BuilderTabBase(QtWidgets.QWidget):
    def __init__(self, window: "BuilderMainWid", parent: QtWidgets.QWidget = None):
        super().__init__(parent)
        self.window = window

    # get form error, None if well filled
    def get_error(self) -> Optional[str]:
        return None


"""
# tab - propagate structure in stack
class BuilderFromStkTab(BuilderTabBase):
    def __init__(self, fea: int, window: "BuilderMainWid", parent: QtWidgets.QWidget = None):
        super().__init__(window, parent)

        # title
        layout = QtWidgets.QVBoxLayout()
        title = QtWidgets.QLabel(self)
        title.setText("<h3>Select a stack offset</h3>")
        layout.addWidget(title)

        self.stack = StackViewer(fea)
        stackQTW = idaapi.PluginForm.TWidgetToPyQtWidget(self.stack.GetWidget())
        stackQTW.setWhatsThis("Choose the offset of your structure in the stack")
        layout.addWidget(stackQTW, QtCore.Qt.AlignLeft)

        # size selector
        self.size = QtWidgets.QLineEdit(self)
        self.size.setText("0x0")
        self.size.setMaxLength(16)
        self.size.setValidator(QtGui.QRegularExpressionValidator(QtCore.QRegularExpression("^([0-9]+)|(0x[0-9a-fA-F]+)$"), self.size))
        self.size.setWhatsThis("Size of the in-stack structure.")
        lsize = QtWidgets.QLabel(self)
        lsize.setText("Structure size")
        lsize.setWhatsThis("Size of the in-stack structure.")
        lsize.setBuddy(self.size)

        # deep dive checkbox
        self.chk = QtWidgets.QCheckBox("Spread in callees", self)
        self.chk.setWhatsThis("Should propagation follow functions calls.")
        self.chk.setChecked(True)

        lcenter = QtWidgets.QHBoxLayout()
        lcenter.addWidget(lsize)
        lcenter.addWidget(self.size)
        lcenter.addStretch()
        lcenter.addWidget(self.chk)
        layout.addLayout(lcenter)

        self.setLayout(layout)

    def get_error(self) -> Optional[str]:
        if self.get_stack_offset() is None:
            return "Please select the offset of the structure in the stack."

        if self.get_structure_size() <= 0:
            return "Please provide a valid structure size."

        return None

    def get_stack_offset(self) -> Optional[int]:
        line_no = self.stack.selected
        if line_no is not None and line_no < len(self.stack.items):
            return int(self.stack.items[line_no][0], 16)
        return None

    def get_structure_size(self) -> int:
        sval = self.size.text()
        try:
            return int(sval, 16 if sval.startswith("0x") else 10)
        except ValueError:
            return -1

    def set_structure_size(self, size: int):
        self.size.setText(hex(size))
"""


# tab - propagate structure pointer
class BuilderFromPtrTab(BuilderTabBase):
    def __init__(
        self,
        mba: ida_hexrays.mba_t,
        ea: int,
        hint: Tuple[int, int],
        window: "BuilderMainWid",
        parent: QtWidgets.QWidget = None,
    ):
        super().__init__(window, parent)

        # title
        layout = QtWidgets.QVBoxLayout()
        title = QtWidgets.QLabel(self)
        title.setText("<h3>Select an entry variable</h3>")
        title.setAlignment(QtCore.Qt.AlignCenter)
        layout.addWidget(title)

        # microcode view
        self.microcodeViewer = MicrocodeViewer(mba, ea, hint)
        microQTW = idaapi.PluginForm.TWidgetToPyQtWidget(self.microcodeViewer.GetWidget())
        microQTW.setWhatsThis(
            "Select an entry point for the propagation. The entry point should be a variable having for value a pointer to the structure to propagate."
        )
        layout.addWidget(microQTW, QtCore.Qt.AlignLeft)

        # shift selector
        self.shift = QtWidgets.QLineEdit(self)
        self.shift.setText("0x0")
        self.shift.setMaxLength(16)
        self.shift.setValidator(
            QtGui.QRegularExpressionValidator(QtCore.QRegularExpression("^([0-9]+)|(0x[0-9a-fA-F]+)$"), self.shift)
        )
        self.shift.setWhatsThis("Shift to apply to the propagated structure pointer.")
        lshift = QtWidgets.QLabel(self)
        lshift.setText("Shifted by")
        lshift.setWhatsThis("Shift to apply to the propagated structure pointer.")
        lshift.setBuddy(self.shift)

        # deep dive checkbox
        self.chk = QtWidgets.QCheckBox("Spread in callees", self)
        self.chk.setWhatsThis("Should propagation follow functions calls.")
        self.chk.setChecked(True)

        lcenter = QtWidgets.QHBoxLayout()
        lcenter.addWidget(lshift)
        lcenter.addWidget(self.shift)
        lcenter.addStretch()
        lcenter.addWidget(self.chk)
        layout.addLayout(lcenter)

        self.setLayout(layout)

    def get_error(self) -> Optional[str]:
        if self.get_entry_variable() is None:
            return "Please provide a variable as an entry point for the propagation."

        if self.get_shift() < 0:
            return "Please provide a valid shift (negative values not supported)."

        return None

    def get_entry_variable(self) -> Optional[ida_hexrays.mop_t]:
        if self.microcodeViewer.chosen is None:
            return None
        return self.microcodeViewer.chosen.mop  # chosen op

    def get_shift(self) -> int:
        sval = self.shift.text()
        try:
            return int(sval, 16 if sval.startswith("0x") else 10)
        except ValueError:
            return -1


# plugin's main UI
class BuilderMainWid(QtWidgets.QDialog):
    def __init__(self, mba: ida_hexrays.mba_t, ea: int, hint: Tuple[int, int], parent: QtWidgets.QWidget = None):
        super().__init__(parent)
        self.mba = mba

        # main layout
        layout = QtWidgets.QVBoxLayout()

        # window's title
        whint = QtWidgets.QLabel(self)
        whint.setText("<h3>Select a structure</h3>")
        whint.setAlignment(QtCore.Qt.AlignCenter)
        layout.addWidget(whint)
        layout.setAlignment(whint, QtCore.Qt.AlignTop)

        # structure selector
        self.struct_selector = StrucSelWid(self)
        layout.addWidget(self.struct_selector, QtCore.Qt.AlignLeft)
        layout.setStretch(1, 1)

        # structure selector search bar
        self.search_bar = QtWidgets.QLineEdit(self)
        self.search_bar.setPlaceholderText("Structure name")
        self.search_bar.setWhatsThis("Name of the structure (new or existing) to propagate.")
        self.search_bar.textChanged.connect(self.search_for_structure)
        layout.addWidget(self.search_bar)
        self.search_bar.setFocus()

        # ctrl+f action
        saction = QtWidgets.QAction(self)
        saction.setShortcut(QtGui.QKeySequence.Find)
        saction.triggered.connect(self.search_for)
        self.addAction(saction)

        # tabs
        self.tabs = QtWidgets.QTabWidget(self)
        self.tabs.setMovable(False)
        self.tabs.setTabsClosable(False)
        self.tab0 = BuilderFromPtrTab(self.mba, ea, hint, self, self.tabs)
        self.tabs.addTab(self.tab0, "From pointer")
        # self.tab1 = BuilderFromStkTab(self.mba.entry_ea, self, self.tabs)
        # self.tabs.addTab(self.tab1, "From stack")
        layout.addWidget(self.tabs)
        layout.setStretch(3, 2)

        # Cancel & Propagate buttons
        lbottom = QtWidgets.QGridLayout()
        cancel_btn = QtWidgets.QPushButton("Cancel", self)
        cancel_btn.clicked.connect(self.reject)
        ok_btn = QtWidgets.QPushButton("Propagate", self)
        ok_btn.setDefault(True)
        ok_btn.clicked.connect(self.execute)
        lbottom.addWidget(cancel_btn, 0, 0)
        lbottom.addWidget(ok_btn, 0, 1)

        layout.addLayout(lbottom)
        layout.setAlignment(lbottom, QtCore.Qt.AlignBottom)
        self.setLayout(layout)

        # window's properties
        self.setWindowTitle(WINDOW_TITLE)

        # window's icon
        icon = QtGui.QIcon(os.path.join(os.path.abspath(symless.__path__[0]), "resources", "champi.png"))
        self.setWindowIcon(icon)

        # closing handler
        self.finished.connect(self.on_finish)

    def get_error(self) -> Optional[str]:
        struc = self.struct_selector.currentItem()

        if isinstance(struc, StrucSelDefaultItem) and len(self.search_bar.text()) == 0:
            return "Please provide a name for the new structure."

        return None

    # 'propagate' was clicked
    def execute(self):
        tab = self.tabs.currentWidget()
        error = self.get_error() or tab.get_error()

        if error is not None:
            idaapi.warning(error)
            return

        self.accept()

    # search for structure in list
    def search_for_structure(self, key: str):
        lkey = key.lower()
        for i in range(self.struct_selector.count()):
            current = self.struct_selector.item(i)
            current.setHidden(
                False if (not isinstance(current, StrucSelItem) or lkey in current.text().lower()) else True
            )

    # Ctrl+F action
    def search_for(self):
        self.search_bar.setFocus()

    # get structures (name) selected by user
    def get_structure(self) -> str:
        selected = self.struct_selector.currentItem()
        if isinstance(selected, StrucSelDefaultItem):
            return self.search_bar.text()

        return selected.get_name()

    # spread in callees checked by user
    def get_dive(self) -> bool:
        return self.tabs.currentWidget().chk.isChecked()

    # struc ptr shift specified by user
    def get_shift(self) -> int:
        tab = self.tabs.currentWidget()
        return tab.get_shift() if isinstance(tab, BuilderFromPtrTab) else 0

    # get the microcode variable the user selected as entry point
    def get_entry_variable(self) -> Optional[ida_hexrays.mop_t]:
        tab = self.tabs.currentWidget()
        return tab.get_entry_variable()

    # ea of the selected entry point
    def get_entry_ea(self) -> Tuple[int, int]:
        tab = self.tabs.currentWidget()
        return (
            (tab.microcodeViewer.chosen.ea, tab.microcodeViewer.chosen.sub_idx)
            if isinstance(tab, BuilderFromPtrTab)
            else (self.mba.entry_ea, 0)
        )

    # selected entry operand is a destination operand
    def entry_is_dst_op(self) -> bool:
        tab = self.tabs.currentWidget()
        return tab.microcodeViewer.chosen.as_dst if isinstance(tab, BuilderFromPtrTab) else False

    # close custom viewers when window is close
    # otherwise they will haunt IDA forever
    def on_finish(self, result):
        # TODO this does not seem to work
        # old views still appears in "Synchronize with"
        self.tab0.microcodeViewer.Close()
        # self.tab1.stack.Close()


# Hook to attach new action to popup menu
class PopUpHook(idaapi.UI_Hooks):
    loaded = False

    # triggered when all UI elements have been initialized
    def ready_to_run(self):
        self.init_action()

    def init_action(self):
        if self.loaded:
            return

        # check that the decompiler exists
        if not idaapi.init_hexrays_plugin():
            utils.g_logger.error("You do not have the decompiler for this architecture, symless will not load")
            self.unhook()
            return

        icon_path = os.path.join(utils.get_resources_path(), "propag.png")
        self.icon = idaapi.load_custom_icon(icon_path)

        self.action = idaapi.action_desc_t(
            "symless:live",
            "Propagate structure",
            BuildHandler(),
            "Shift+t",
            "Build structure from selected variable",
            self.icon,
            idaapi.ADF_OWN_HANDLER,
        )
        idaapi.register_action(self.action)
        self.loaded = True

    def term(self):
        idaapi.unregister_action(self.action.name)
        idaapi.free_custom_icon(self.icon)

    # triggered on right click menu popup
    def finish_populating_widget_popup(self, widget, popup, ctx: idaapi.action_ctx_base_t):
        # window is (DISASM or PSEUDOCODE) & no selection
        if ctx.widget_type not in (idaapi.BWN_DISASM, idaapi.BWN_PSEUDOCODE) or ctx.has_flag(idaapi.ACF_HAS_SELECTION):
            return

        # we are inside a function
        if ctx.cur_func is None:
            return

        idaapi.attach_action_to_popup(widget, popup, self.action.name)


# context menu structure builder action
class BuildHandler(idaapi.action_handler_t):
    def activate(self, ctx: idaapi.action_ctx_base_t) -> int:
        hint_mreg = ida_hexrays.mr_none
        hint_size = 0

        if not arch.is_arch_supported():
            utils.g_logger.error("Unsupported arch (%s) or filetype" % arch.get_proc_name())
            return 0

        mba = ida_utils.get_func_microcode(ctx.cur_func, True)
        if not mba:
            utils.g_logger.error(f"Could not generate microcode for function {ctx.cur_func.start_ea:#x}")
            return 0

        # guess the micro operand associated to user selection
        if ctx.widget_type == idaapi.BWN_DISASM:
            hint_mreg, hint_size = self.guess_selected_mop_from_assembly()
        else:  # idaapi.BWN_PSEUDOCODE
            # TODO implement guessing for pseudocode view
            pass

        # display plugin's UI
        form = BuilderMainWid(mba, ctx.cur_ea, (hint_mreg, hint_size))
        code = form.exec()

        # cancel button was hit
        if code == QtWidgets.QDialog.Rejected:
            return 0

        propagate_structure(
            form.get_entry_ea(),
            form.get_entry_variable(),
            form.entry_is_dst_op(),
            form.get_structure(),
            form.get_shift(),
            form.get_dive(),
        )

        return 1  # all IDA windows will be refreshed

    def update(self, ctx):
        return idaapi.AST_ENABLE_ALWAYS

    # use the currently selected assembly operand to guess the corresponding microcode operand
    # returns (mreg_t, size)
    def guess_selected_mop_from_assembly(self) -> Tuple[int, int]:
        mreg = ida_hexrays.mr_none
        mreg_size = 0

        cur_ea = idaapi.get_screen_ea()  # current address
        cur_op = idaapi.get_opnum()  # current op idx
        cur_insn = idaapi.insn_t()  # current instruction
        insn_len = idaapi.decode_insn(cur_insn, cur_ea)

        if insn_len == 0 or cur_op < 0 or cur_op > ida_utils.get_len_insn_ops(cur_insn):
            return (mreg, mreg_size)

        op = cur_insn.ops[cur_op]
        if op.type == idaapi.o_reg:
            mreg = ida_hexrays.reg2mreg(op.reg)  # mr_none if none
            mreg_size = idaapi.get_dtype_size(op.dtype)

        elif op.type in [idaapi.o_phrase, idaapi.o_displ]:
            mreg = ida_hexrays.reg2mreg(op.phrase)
            mreg_size = ida_utils.get_ptr_size()

        if mreg_size:
            utils.g_logger.debug(f"Guess for target mreg: {ida_hexrays.get_mreg_name(mreg, mreg_size)}")

        return (mreg, mreg_size)


# do the propagation & build the structure
def propagate_structure(
    ea_couple: Tuple[int, int], mop: ida_hexrays.mop_t, dst_op: bool, strucname: str, shift: int, dive: bool
):
    idaapi.show_wait_box("HIDECANCEL\nPropagating struct info..")

    ea, subea = ea_couple

    try:
        # get containing function
        fct = idaapi.get_func(ea)

        # entry is to be injected after minsn is processed
        if dst_op:
            entry = model.dst_var_entry_t(ea, subea, fct.start_ea, mop)

        # entry is to be injected before
        else:
            entry = model.src_reg_entry_t(ea, subea, fct.start_ea, mop)

        entry.struc_shift = shift  # shift for associated structure

        # set root entries
        entries = model.entry_record_t()
        entries.add_entry(entry, True)

        # build entrypoints graph
        ctx = model.context_t(entries, set())
        ctx.set_follow_calls(dive)
        model.analyze_entrypoints(ctx)

        # define structures
        strucs = structures.define_structures(ctx)

        # associate generated model with chosen structure
        _, struc_model = entry.get_structure()
        if struc_model is None:
            pass  # previous steps have failed (hopefully with an error msg)

        else:
            struc_model.set_name(strucname)
            struc_model.force_generation = True  # generate even if empty

            # make sure not to reduce existing structure size by removing padding
            struc = ida_utils.get_local_type(strucname)
            if struc and not struc.is_forward_decl() and struc.get_size() > struc_model.get_size():
                struc_model.set_size(struc.get_size())

            # import structures into IDA
            generate.import_structures(strucs)

            # type operands with structures
            generate.import_context(ctx)

    except Exception as e:
        import traceback

        utils.g_logger.critical(repr(e) + "\n" + traceback.format_exc())

    finally:
        # no need to keep all mbas
        ida_utils.g_microcode_cache.clear()

        idaapi.hide_wait_box()

```

`symless/symbols/__init__.py`:

```py
import re
from typing import Optional, Tuple

import idaapi

import symless.utils.ida_utils as ida_utils
import symless.utils.utils as utils

# global expressions for symbol selection
re_ctors = re.compile(r"\b((?:[\w_]+::)*)([\S ]+)::\2(?:\(|$)")
re_vtable_single_msvc = re.compile(r"^const (.+)::`vftable'$")
re_vtable_single_gcc = re.compile(r"^`vtable for'([\s\S]+)$")
re_tinfo_gcc = re.compile(r"^`typeinfo for'([\s\S]+)$")
re_vtable_for_msvc = re.compile(r"^const (.+)::`vftable'{for `(.+)'}")

# invalid structure names exps & replacements
re_invalid_struc_name = (
    (re.compile(r"[\s\*&]"), ""),
    (re.compile(r"[,\-+]"), "_"),
    (re.compile(r"[<>]"), "__"),
)

# invalid method field names exps & replacements
re_invalid_method_name = ((re.compile(r"[\s]+"), "_"), (re.compile(r"[^0-9a-zA-Z~_-]"), ""))


# full method name from method signature
# i.e get Class::Initialize from Class::Initialize(Class*)
def full_method_name_from_signature(signature: str) -> str:
    fct = signature.split("(")[0]
    return fct


# method name from method signature
# i.e get Initialize from Class::Initialize(Class*)
def method_name_from_signature(signature: str) -> str:
    full = full_method_name_from_signature(signature)
    name = full.split("::")[-1]
    for exp, repl in re_invalid_method_name:
        name = exp.sub(repl, name)
    return name.strip("_")


# replace unvalid characters from structure's name
def struc_name_cleanup(original: str) -> str:
    out = original
    for exp, repl in re_invalid_struc_name:
        out = exp.sub(repl, out)
    return out


# ea was given a (non-dummy) name
def has_relevant_name(ea: int):
    flags = idaapi.get_flags(ea)
    return idaapi.has_any_name(flags) and not idaapi.has_dummy_name(flags)


# get class name from its constructor signature
def get_classname_from_ctor(fct_name: str) -> Optional[str]:
    if fct_name is None or "::" not in fct_name:
        return None

    m = re_ctors.search(fct_name)
    if m is None:
        return None

    return m.group(1) + m.group(2)


# get vtable structure's name from its symbol
def get_vtable_name_from_ctor(vtable_ea: int) -> Optional[str]:
    derived, parent = get_classnames_from_vtable(vtable_ea)

    if derived is None:
        utils.g_logger.debug(f"No name found for vtable 0x{vtable_ea:x}")
        return None

    if parent is None:
        return f"{derived}{idaapi.VTBL_SUFFIX}"

    return f"{derived}_{parent}{idaapi.VTBL_SUFFIX}"


# get child & parent classes names from vtable symbol
def get_classnames_from_vtable(vtable_ea: int) -> Tuple[Optional[str], Optional[str]]:
    for f in (get_classnames_from_vtable_gcc, get_classnames_from_vtable_msvc):
        derived, parent = f(vtable_ea)
        if derived is not None:
            return derived, parent

    return None, None


# get child & parent classes names from vtable symbol for gcc compiled binaries
def get_classnames_from_vtable_gcc(vtable_ea: int) -> Tuple[Optional[str], Optional[str]]:
    ptr_size = ida_utils.get_ptr_size()

    # use vtable symbol
    label_ea = vtable_ea - (2 * ptr_size)
    vtbl_name = ida_utils.demangle_ea(label_ea)

    m = re_vtable_single_gcc.search(vtbl_name)
    if m is not None:
        return (m.group(1), None)

    # fallback - use typeinfo symbol
    tinfo_ea = ida_utils.__dereference_pointer(vtable_ea - ptr_size, ptr_size)
    tinfo = ida_utils.demangle_ea(tinfo_ea)

    m = re_tinfo_gcc.search(tinfo)
    if m is not None:
        return (m.group(1), None)

    return (None, None)


# get child & parent classes names from vtable symbol for msvc compiled binaries
def get_classnames_from_vtable_msvc(vtable_ea: int) -> Tuple[Optional[str], Optional[str]]:
    vtbl_name = ida_utils.demangle_ea(vtable_ea)

    if vtbl_name is None or "::" not in vtbl_name:
        return (None, None)

    m = re_vtable_single_msvc.search(vtbl_name)
    if m is not None:
        return (m.group(1), None)

    m = re_vtable_for_msvc.search(vtbl_name)
    if m is not None:
        return (m.group(1), m.group(2))

    return (None, None)

```

`symless/symbols/rename.py`:

```py
from typing import Collection, List, Tuple

import symless.generation as generation
from symless.symbols import *


# update list of potential names with given candidate
def add_candidate_name(names: List[Tuple[int, str]], candidate: Tuple[int, str]):
    relevance, name = candidate

    seeker = (i for i, (_, n) in enumerate(names) if (n == name))
    try:
        idx = next(seeker)  # name exists, update relevance
        old_rel, _ = names[idx]
        if old_rel > relevance:
            names[idx] = (relevance, name)
    except StopIteration:
        names.append((relevance, name))


# get a list of possible names for a structure
# ordered by preferences
def find_structure_name(struc: generation.structure_t) -> Collection[str]:
    names: List[Tuple[int, str]] = list()
    current_root, depth = None, 0

    # loop over all nodes associated to the structure
    # get names from the associated nodes
    for root, block, shift in struc.node_flow(False):
        if root != current_root:
            current_root, depth = root, 0

        if shift == 0 and depth <= 2:
            name, relevance = block.get_owner().find_name()
            if name is not None:  # add possible name to the list
                name = struc_name_cleanup(name)
                relevance *= depth + 1
                add_candidate_name(names, (relevance, name))

        depth += 1

    # add name from associated vtable to the list
    field = struc.get_field(0)

    # first field is a vtable pointer
    if isinstance(field, generation.vtbl_ptr_field_t):
        _, vtable = field.get_structure()
        derived, _ = get_classnames_from_vtable(vtable.ea)
        if derived is not None:
            # names from first vtable are more accurate than names from ctors
            # set best preference (0)
            add_candidate_name(names, (0, struc_name_cleanup(derived)))

    names.sort(key=lambda k: k[0])
    return [n for _, n in names]


# name all structures from given record
# use symbols for naming
# TODO: select less derived when conflict on name
def define_structures_names(record: generation.structure_record_t):
    all_names = set()  # all given names record

    for struc in record.get_structures(include_discarded=False):
        # define structure's fields names
        struc.compute_names()

        # define structure's name
        names = find_structure_name(struc)
        if len(names) == 0:
            continue

        # name conflict, make it unique
        name = names[0]
        if name in all_names:
            name = f"{name}_0x{struc.ea:x}"

        all_names.add(name)
        struc.set_name(name)

```

`symless/utils/ida_utils.py`:

```py
from collections import deque
from typing import Generator, List, Optional, Tuple

import ida_hexrays
import idaapi
import idautils
import idc

import symless.symbols as symbols
import symless.utils.utils as utils

""" Imports utilities """


def get_import_module_index(name: str) -> int:
    for i in range(idaapi.get_import_module_qty()):
        if idaapi.get_import_module_name(i) == name:
            return i
    return None


# Get ea of given import, from given module
def get_import_from_module(module: int, import_name: str) -> int:
    import_ea = None

    def iterator(ea, name, ord):
        nonlocal import_ea, import_name
        if name.startswith(import_name):
            import_ea = ea
            return False
        return True

    idaapi.enum_import_names(module, iterator)
    return import_ea


""" Names utilities """


def demangle(name: str, inf_attr=idc.INF_SHORT_DN) -> str:
    demangled = idaapi.demangle_name(name, idc.get_inf_attr(inf_attr))
    if demangled:
        return demangled

    return name


def demangle_ea(ea: int, inf_attr=idc.INF_SHORT_DN) -> str:
    return demangle(idaapi.get_name(ea), inf_attr)


# retrieve a name in the form "fct+offset"
def addr_friendly_name(ea: int) -> str:
    fct = idaapi.get_func(ea)
    if fct is None:
        return f"ea[0x{ea:x}]"

    offset = ea - fct.start_ea
    fct_name = symbols.full_method_name_from_signature(demangle(idaapi.get_short_name(fct.start_ea)))
    return "%s%s" % (fct_name, f"+{offset:x}" if offset != 0 else "")


""" Xrefs utilities """

# The following functions can be time-consuming when an address has numerous xref
# every xref has to be fetch using an API call


def get_references(address: int) -> List[int]:
    return [ref for ref in idautils.CodeRefsTo(address, 0)]


def get_data_references(address: int) -> List[int]:
    return [ref for ref in idautils.DataRefsTo(address)]


def get_all_references(address: int) -> set:
    crefs = get_references(address)
    drefs = get_data_references(address)
    return set(crefs + drefs)


""" Pointers utilities """


g_ptr_size = None


def get_ptr_size() -> int:
    global g_ptr_size
    g_ptr_size = (
        g_ptr_size if g_ptr_size else (8 if idaapi.inf_is_64bit() else (4 if idaapi.inf_is_32bit_or_higher else 2))
    )
    return g_ptr_size


def __dereference_pointer(addr: int, ptr_size: int) -> int:
    return idaapi.get_qword(addr) if ptr_size == 8 else idaapi.get_dword(addr)


def dereference_pointer(addr: int) -> int:
    return __dereference_pointer(addr, get_ptr_size())


# get size bytes from given ea, if ea is initialized with a value
def get_nb_bytes(ea: int, size: int) -> int:
    if not idaapi.is_loaded(ea):
        return None

    if size == 8:
        return idaapi.get_qword(ea)
    if size == 4:
        return idaapi.get_dword(ea)
    if size == 2:
        return idaapi.get_word(ea)

    return idaapi.get_byte(ea)


""" Type utilities """


# get basic type
def get_basic_type(type: int) -> idaapi.tinfo_t:
    tinfo = idaapi.tinfo_t()
    tinfo.create_simple_type(type)
    return tinfo


# returns void* tinfo_t
def void_ptr() -> idaapi.tinfo_t:
    tinfo = get_basic_type(idaapi.BT_VOID)
    tinfo.create_ptr(tinfo)
    return tinfo


# local type by name
def get_local_type(name: str) -> Optional[idaapi.tinfo_t]:
    tinfo = idaapi.tinfo_t()
    if tinfo.get_named_type(idaapi.get_idati(), name):
        return tinfo
    return None


# convert a local variable forward ref into a real struct
def replace_forward_ref(tif: idaapi.tinfo_t):
    ord, tname = tif.get_ordinal(), tif.get_type_name()
    mudt = idaapi.udt_type_data_t()
    tif.create_udt(mudt)
    err = tif.set_numbered_type(None, ord, idaapi.NTF_REPLACE)
    if err != idaapi.TERR_OK:
        utils.g_logger.error(f'Could not convert forward ref to "{tname}" : {idaapi.tinfo_errstr(err)} ({err})')


# just a wrap around find_udm that returns BADADDR instead of -1
def find_udm_wrap(struc: idaapi.tinfo_t, udm: idaapi.udm_t) -> int:
    rc = struc.find_udm(udm, idaapi.STRMEM_OFFSET)
    return idaapi.BADADDR if rc in (-1, idaapi.BADADDR) else rc


""" Function utilities """


# creates funcarg_t type
def make_function_argument(typ: idaapi.tinfo_t, name: str = "") -> idaapi.funcarg_t:
    farg = idaapi.funcarg_t()
    farg.type = typ
    farg.name = name
    return farg


# shift pointer
def shift_ptr(ptr: idaapi.tinfo_t, parent: idaapi.tinfo_t, shift: int):
    if shift == 0:
        return

    ptr_data = idaapi.ptr_type_data_t()
    if ptr.get_ptr_details(ptr_data):
        ptr_data.taptr_bits |= idaapi.TAPTR_SHIFTED
        ptr_data.delta = shift
        ptr_data.parent = parent
        ptr.create_ptr(ptr_data, idaapi.BT_PTR)


# add argument to function + shift ptr argument
def set_function_argument(
    func_data: idaapi.func_type_data_t,
    index: int,
    typ: idaapi.tinfo_t,
    shift: int = 0,
    parent: Optional[idaapi.tinfo_t] = None,
    name: Optional[str] = None,
):
    while index > func_data.size():
        func_data.grow(make_function_argument(void_ptr(), f"arg_{func_data.size()}"))

    # apply __shifted
    shift_ptr(typ, parent, shift)

    if name is None:
        name = f"arg_{index}"

    arg = make_function_argument(typ, name)
    if index == func_data.size():
        func_data.grow(arg)
    else:
        func_data[index] = arg


# creates a new valid func_type_data_t object
def new_func_data() -> idaapi.func_type_data_t:
    func_data = idaapi.func_type_data_t()

    # ret type to void
    ret_tinfo = idaapi.tinfo_t()
    ret_tinfo.create_simple_type(idaapi.BT_VOID)
    func_data.rettype = ret_tinfo

    # fastcall as default cc
    func_data.cc = idaapi.CM_CC_FASTCALL

    return func_data


# get the tinfo for a given function
def get_fct_type(fea: int, force_decompile: bool = False) -> Optional[idaapi.tinfo_t]:
    tinfo = idaapi.tinfo_t()
    hf = ida_hexrays.hexrays_failure_t()

    if (not force_decompile) and idaapi.get_tinfo(tinfo, fea):
        return tinfo

    utils.g_logger.info(f"Forcing decompilation of fct {fea:#x}")
    cfunc = ida_hexrays.decompile_func(idaapi.get_func(fea), hf, ida_hexrays.DECOMP_NO_WAIT)
    if cfunc is None:
        utils.g_logger.warning(f"Could not decompile fct {fea:#x}: {hf.str} ({hf.code})")
        return None

    if cfunc.get_func_type(tinfo):
        return tinfo

    utils.g_logger.error(f"No tinfo_t for fea {fea:#x}")
    return None


# get function type, create default one if none
def get_or_create_fct_type(fea: int) -> Tuple[idaapi.tinfo_t, idaapi.func_type_data_t]:
    func_tinfo = get_fct_type(fea)
    if func_tinfo is None:
        return (idaapi.tinfo_t(), new_func_data())

    func_data = idaapi.func_type_data_t()
    if func_tinfo.get_func_details(func_data):
        return (func_tinfo, func_data)

    return (func_tinfo, new_func_data())


# yields one instruction operands
def get_insn_ops(insn: idaapi.insn_t) -> Generator[idaapi.op_t, None, None]:
    i = 0
    while i < idaapi.UA_MAXOP and insn.ops[i].type != idaapi.o_void:
        yield insn.ops[i]
        i += 1


# get instruction's operands count
def get_len_insn_ops(insn: idaapi.insn_t) -> int:
    return len([i for i in get_insn_ops(insn)])


# cache our mbas with their special kregs
g_microcode_cache = dict()


# get the microcode for a given function
def get_func_microcode(func: idaapi.func_t, analyze_calls: bool = False) -> Optional[ida_hexrays.mba_t]:
    global g_microcode_cache
    if func.start_ea in g_microcode_cache:
        return g_microcode_cache[func.start_ea]

    # generate the function microcode
    mbr = ida_hexrays.mba_ranges_t(func)
    hf = ida_hexrays.hexrays_failure_t()
    mba: ida_hexrays.mba_t = ida_hexrays.gen_microcode(
        mbr, hf, None, ida_hexrays.DECOMP_NO_WAIT, ida_hexrays.MMAT_PREOPTIMIZED
    )

    if not mba:
        utils.g_logger.error(f"Could generate mba for fct {func.start_ea:#x}: {hf.str} ({hf.code})")
        return None

    # build cfg and define blocks relations
    mba.build_graph()

    # resolve calls arguments and returns
    if analyze_calls:
        mba.analyze_calls(ida_hexrays.ACFL_GUESS)

    # only cache mba used by cpustate (without initial call analysis)
    else:
        g_microcode_cache[mba.entry_ea] = mba

    # allocate special kregs
    # used to pass result of inline minsns to parent minsn
    setattr(mba, "tmp_result_kregs", deque())
    for _ in range(8):
        mba.tmp_result_kregs.append(mba.alloc_kreg(get_ptr_size()))
    setattr(mba, "call_result_kreg", mba.alloc_kreg(get_ptr_size()))

    return mba


# analyze calls of given mba, make sure to have the correct args count for each
def mba_analyze_calls(mba: ida_hexrays.mba_t):
    global g_microcode_cache

    if mba.callinfo_built():  # already done
        return

    hf = ida_hexrays.hexrays_failure_t()

    # find all calls, decompile callees for accurate arguments count
    for i in range(mba.qty):
        mblock = mba.get_mblock(i)
        minsn = mblock.head

        while minsn:
            if minsn.is_unknown_call() and minsn.l.t == ida_hexrays.mop_v:
                fct = idaapi.get_func(minsn.l.g)
                if fct:
                    utils.g_logger.info(f"decompiling callee {fct.start_ea:#x} for accurate call info")
                    ida_hexrays.decompile_func(fct, hf, ida_hexrays.DECOMP_NO_WAIT)

            minsn = minsn.next

    # resolve call arguments (and ret) in mba
    mba.analyze_calls(ida_hexrays.ACFL_GUESS)


# get the microcode block containing the specified ea
def get_block_microcode(fct: idaapi.func_t, ea: int) -> Optional[Tuple[ida_hexrays.mblock_t, ida_hexrays.mba_t]]:
    # function microcode
    mba = get_func_microcode(fct)
    if not mba:
        return None

    # return containing block
    try:
        return (
            next(
                filter(
                    lambda b: (not (b.flags & ida_hexrays.MBL_FAKE)) and ea >= b.start and ea < b.end,
                    [mba.get_mblock(i) for i in range(mba.qty)],
                )
            ),
            mba,
        )
    except StopIteration:  # yes this can happen
        return None


# lift the instruction at ea into a micro instruction
# returns a MMAT_PREOPTIMIZED minsn
def get_ins_microcode(ea: int) -> Optional[ida_hexrays.minsn_t]:
    insn = idaapi.insn_t()
    rvec = idaapi.rangevec_t()
    hf = ida_hexrays.hexrays_failure_t()

    # get the instruction size
    insn_size = idaapi.decode_insn(insn, ea)
    if not insn_size:
        utils.g_logger.warning(f"no instruction found at {ea:#x}")
        return None

    # generate the mba
    rvec.push_back(idaapi.range_t(insn.ea, insn.ea + insn_size))
    mbr = ida_hexrays.mba_ranges_t(rvec)
    mba = ida_hexrays.gen_microcode(
        mbr, hf, None, ida_hexrays.DECOMP_NO_WAIT | ida_hexrays.DECOMP_NO_FRAME, ida_hexrays.MMAT_PREOPTIMIZED
    )
    if not mba:
        utils.g_logger.error(f"Could not get minsn for ea {ea:#x}: {hf.str} ({hf.code})")
        return None

    # find the minsn in the mba
    # it should be the first instruction of the first non-fake block
    minsn = next(
        filter(lambda b: not (b.flags & ida_hexrays.MBL_FAKE), [mba.get_mblock(i) for i in range(mba.qty)])
    ).head

    return ida_hexrays.minsn_t(minsn)  # original is freed with mba


""" Misc """


# get root folder for local types, if supported
def get_local_types_folder() -> Optional[idaapi.dirtree_t]:
    try:
        return idaapi.get_std_dirtree(idaapi.DIRTREE_LOCAL_TYPES)
    except AttributeError:
        return None


# mcode_t values to microinstruction names
g_mcode_name = {
    getattr(ida_hexrays, mcode): mcode[2:] for mcode in filter(lambda y: y.startswith("m_"), dir(ida_hexrays))
}


# mopt_t values to operand type as str
g_mopt_name = [
    "mop_z",
    "mop_r",
    "mop_n",
    "mop_str",
    "mop_d",
    "mop_S",
    "mop_v",
    "mop_b",
    "mop_f",
    "mop_l",
    "mop_a",
    "mop_h",
    "mop_c",
    "mop_fn",
    "mop_p",
    "mop_sc",
]


# get instruction + operands representation
def insn_str_full(insn: ida_hexrays.minsn_t) -> str:
    return f"[{insn.dstr()}] = [{g_mcode_name[insn.opcode]} {', '.join([g_mopt_name[i.t] for i in (insn.l, insn.r, insn.d)])}]"

```

`symless/utils/utils.py`:

```py
import logging
import os

import symless
import symless.config as config


def get_logger(level: int = config.g_settings.log_level):
    logger = logging.getLogger("symless")
    logger.setLevel(level)
    logger.propagate = False

    # do not recreate handler when reloading utils module
    if logger.hasHandlers():
        return logger

    # create console handler and set level to debug
    ch = logging.StreamHandler()
    ch.setLevel(level)

    # log format
    formatter = logging.Formatter(
        "{asctime} - {name} - {levelname:<8s} {filename:>15s}:{lineno:05} - {funcName:<30s} - {message}",
        style="{",
    )

    # add formatter to ch
    ch.setFormatter(formatter)

    # add ch to logger
    logger.addHandler(ch)

    return logger


# initialize global logger
g_logger = get_logger()


# where to look for resources
def get_resources_path() -> str:
    return os.path.join(symless.__path__[0], "resources")


# print completed action & time it took
def print_delay(prefix: str, start: float, end: float):
    delay = int(end - start)
    min = int(delay / 60)
    sec = delay - (min * 60)
    g_logger.info("%s in %s%s" % (prefix, "%d minutes and " % min if min > 0 else "", "%d seconds" % sec))


# convert integer to given sign & size
def to_c_integer(value: int, sizeof: int, signed: bool = True) -> int:
    mask = 1 << (sizeof * 8)
    out = value & (mask - 1)
    if signed and (out & (mask >> 1)):
        out -= mask
    return out

```

`symless/utils/vtables.py`:

```py
from collections import deque
from typing import Collection, Generator, Optional, Tuple

import idaapi

import symless.cpustate.cpustate as cpustate
import symless.utils.ida_utils as ida_utils
import symless.utils.utils as utils

""" Utilities for identifying virtual tables """


# model for a virtual table
class vtable_t:
    def __init__(self, ea: int):
        self.ea = ea
        self.total_xrefs = 0  # total of xrefs on virtual methods

        # all virtual methods (fea, is_imported)
        self.members: Collection[Tuple[int, bool]] = deque()

        for fea, is_import in vtable_members(ea):
            self.members.append((fea, is_import))
            self.total_xrefs += len(ida_utils.get_data_references(fea))

        # list of ea where the vtable is loaded
        self.load_xrefs: Collection[int] = deque()

    def size(self) -> int:
        return len(self.members) * ida_utils.get_ptr_size()

    def add_load(self, xref: int):
        self.load_xrefs.append(xref)

    def get_loads(self) -> Collection[int]:
        return self.load_xrefs

    # search for places where this vtable is loaded into a structure
    def search_loads(self):
        for x in search_xrefs_for_vtable_load(self.ea, self.ea):
            self.add_load(x)

        # special RTTI case, vtable symbol may not point directly to the array of fct ptrs
        # ctor loads the vtable in the object like this:
        #   lea   rax, `vtable for'FooBar
        #   add   rax, 10h
        #   mov   [rbx], rax
        if len(self.get_loads()) == 0:
            for x in search_xrefs_for_vtable_load(self.ea - 2 * ida_utils.get_ptr_size(), self.ea):
                self.add_load(x)

    def get_members(self) -> Collection[Tuple[int, bool]]:
        return self.members

    def members_count(self) -> int:
        return len(self.members)

    # only contain imported functions
    def all_imports(self) -> bool:
        return all([is_import for _, is_import in self.members])

    # we think this really is a vtable
    def valid(self) -> bool:
        return self.members_count() > 0 and not self.all_imports()

    # get most derived vtable between self and other
    # decision based on some not-so-accurate heuristics
    def get_most_derived(self, other: "vtable_t") -> "vtable_t":
        # biggest vtable is the most derived
        if other.members_count() > self.members_count():
            return other
        if other.members_count() < self.members_count():
            return self

        # vtable with the most referenced methods is the base one
        # why ? its methods may be referenced from all inheriting vtables
        if self.total_xrefs > other.total_xrefs:
            return other
        if other.total_xrefs > self.total_xrefs:
            return self

        # most referenced vtable is the base one
        # as it is more loaded (also loaded in child classes ctors/dtors)
        if len(self.load_xrefs) > len(other.load_xrefs):
            return other

        return self

    def __hash__(self):
        return self.ea

    def __eq__(self, value):
        return (isinstance(value, int) and self.ea == value) or (isinstance(value, vtable_t) and self.ea == value.ea)


# returns the next member for the given vftable, None if we reached the end
def next_vtable_member(vtbl_ea: int, member_ea: int, ptr_size: int) -> Optional[Tuple[int, bool]]:
    fea = ida_utils.__dereference_pointer(member_ea, ptr_size) & ~1  # in case of thumb mode
    func = idaapi.get_func(fea)

    # addr is a function entry point
    if func and func.start_ea == fea:
        imported = False

    # addr points to an import
    elif idaapi.is_mapped(fea) and idaapi.getseg(fea).type == idaapi.SEG_XTRN:
        imported = True

    else:
        return None

    # if a reference is found on the member, consider it is not part of the current vtable
    if vtbl_ea != member_ea and (
        idaapi.get_first_dref_to(member_ea) != idaapi.BADADDR or idaapi.get_first_cref_to(member_ea) != idaapi.BADADDR
    ):
        return None

    return fea, imported


# yield all members of given vtable
def vtable_members(vtbl_ea: int) -> Generator[Tuple[int, bool], None, None]:
    ptr_size = ida_utils.get_ptr_size()

    current = vtbl_ea
    r = next_vtable_member(vtbl_ea, current, ptr_size)
    while r is not None:
        yield r
        current += ptr_size
        r = next_vtable_member(vtbl_ea, current, ptr_size)


# does the given xref points to a loading of vtbl_ea into a struct
def is_vtable_loaded_at(fct: idaapi.func_t, xref_ea: int, vtbl_ea: int) -> bool:
    block = ida_utils.get_block_microcode(fct, xref_ea)
    if not block:
        return False
    mbb, mba = block

    # flow in xref basic block, see if vtable is loaded & stored to a struct
    minsn = mbb.head
    state = cpustate.state_t(mba, None)

    utils.g_logger.debug(f"Looking for a load of vtable {vtbl_ea:#x} at {xref_ea:#x}")

    while minsn:  # for every bb's instructions
        for subinsn in cpustate.flatten_minsn(minsn, mba):  # for every sub instruction
            cpustate.process_instruction(state, subinsn)

            # check for vtable ea to be stored
            for write in state.writes:
                if (
                    write.size == ida_utils.get_ptr_size()
                    and isinstance(write.value, cpustate.mem_t)
                    and write.value.get_uval() == vtbl_ea
                ):
                    return True

        minsn = minsn.next

    return False


# search the xrefs of given ea for loads of vtbl_ea
def search_xrefs_for_vtable_load(ea: int, vtbl_ea: int) -> Generator[int, None, None]:
    for xref in ida_utils.get_data_references(ea):
        fct = idaapi.get_func(xref)

        # referenced from other data
        if fct is None and ida_utils.dereference_pointer(xref) == ea:
            yield from search_xrefs_for_vtable_load(xref, vtbl_ea)

        elif fct and is_vtable_loaded_at(fct, xref, vtbl_ea):
            yield xref


# get a model for the vtable at given address
# None if no vtable found at that address
def next_vtable(ea: int, end_ea: int) -> Tuple[Optional[vtable_t], int]:
    if not idaapi.is_loaded(ea):
        return None, idaapi.next_head(ea, end_ea)

    vtbl = vtable_t(ea)
    if vtbl.members_count() == 0:  # not an array of fct ptrs
        return None, idaapi.next_head(ea, end_ea)

    if vtbl.all_imports():  # we are not sure any of these are fct ptrs
        return None, ea + vtbl.size()

    # find vtable loading sites
    vtbl.search_loads()

    # vtable only if it is loaded by code
    if len(vtbl.get_loads()) != 0:
        return vtbl, ea + vtbl.size()

    return None, ea + vtbl.size()


# scans given segment for vtables
def get_all_vtables_in(seg: idaapi.segment_t) -> Generator[vtable_t, None, None]:
    utils.g_logger.info(
        "scanning segment %s[%x, %x] for vtables" % (idaapi.get_segm_name(seg), seg.start_ea, seg.end_ea)
    )

    current = seg.start_ea
    while current != idaapi.BADADDR and current < seg.end_ea:
        # do not cross functions
        chunk = idaapi.get_fchunk(current)
        if chunk is not None:
            current = chunk.end_ea
            continue

        # is a vtable ?
        vtbl, current = next_vtable(current, seg.end_ea)
        if vtbl:
            yield vtbl


# scans code segments for vtables
def get_all_vtables() -> Generator[vtable_t, None, None]:
    seg = idaapi.get_first_seg()
    while seg is not None:
        # search for vtables in .data and .text segments
        if seg.type == idaapi.SEG_CODE or seg.type == idaapi.SEG_DATA:
            yield from get_all_vtables_in(seg)

        seg = idaapi.get_next_seg(seg.start_ea)

```