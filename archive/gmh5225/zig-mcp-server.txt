Project Path: arc_gmh5225_zig-mcp-server_hlzwi1qp

Source Tree:

```txt
arc_gmh5225_zig-mcp-server_hlzwi1qp
├── LICENSE
├── Makefile
├── README.md
├── build.zig
├── build.zig.zon
├── examples
│   ├── build.zig
│   ├── lib_example.zig
│   └── mcp_client.py
├── src
│   ├── bin
│   │   └── server.zig
│   ├── jsonrpc.zig
│   ├── lib.zig
│   ├── main.zig
│   ├── mcp.zig
│   ├── mcp_test.zig
│   ├── net.zig
│   └── tools.zig
└── test_client.js

```

`LICENSE`:

```
MIT License

Copyright (c) 2025 Frank Denis

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

```

`Makefile`:

```
.PHONY: all build test run run-http clean bench docs

all: build

build:
	zig build

test:
	zig build test

run:
	./zig-out/bin/mcp_server

run-http:
	./zig-out/bin/mcp_server --transport http

bench:
	zig build bench

docs:
	zig build docs

clean:
	rm -rf zig-out/ zig-cache/

```

`README.md`:

```md
# Zig MCP Server

<div align="center">
<h3>A high-performance implementation of the MCP protocol in Zig</h3>

[![License: MIT](https://img.shields.io/badge/License-MIT-blue.svg)](https://opensource.org/licenses/MIT)
</div>

---

The Zig MCP Server is a memory-efficient implementation of the [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) specification. It provides both a standalone server executable and a library that can be embedded into your Zig applications.

## Features

- **Built-in HTTP Server**:
  - Threaded connection handling with configurable thread pool
  - Connection limiting to prevent resource exhaustion
  - Graceful shutdown support
  - Connection timeout management
  - Server metrics collection
  - Health check endpoint
- **Memory Efficient**: Uses arena allocators and stack buffers for optimized memory usage
- **Multiple Transports**: Supports both stdio and HTTP transports
- **Tool System**: Easy API to implement and add custom tools
- **MCP 0.4.0 Compatible**: Fully compatible with the latest MCP specification
- **Pure Zig**: No external dependencies required
- **Reusable Module**: Can be used as a library in other Zig applications
- **WebAssembly Support**: Runs on function-as-a-service cloud services based on WebAssembly, such as Fastly Compute

## Requirements

- Zig 0.14.0 or later (tested with Zig 0.15.0-dev)

## Building

```bash
# Standard build
zig build

# Optimized for release
zig build -Doptimize=ReleaseSmall
```

## Running

### Using the Command Line

```bash
# Run with stdio transport (default)
./zig-out/bin/mcp_server

# Run with HTTP transport
./zig-out/bin/mcp_server --transport http --port 7777

# Run with custom thread count and connection limits
./zig-out/bin/mcp_server --transport http --threads 4 --max-connections 500 --timeout 60000
```

### Using the Makefile

```bash
# Build the project
make build

# Run with stdio transport
make run

# Run with HTTP transport
make run-http
```

## Usage

### Standalone Server

The standalone server provides ready-to-use MCP functionality with minimal setup.

#### Built-in Tools

This MCP server comes with the following example tools out of the box:

- `echo`: Echoes back any provided parameters
- `reverse`: Takes a string input and returns its reverse

#### Command-line Options

```
Usage: mcp_server [options]

Options:
  --port, -p <port>                  Port to listen on (default: 7777)
  --host, -h <host>                  Host to bind to (default: 127.0.0.1)
  --transport, -t <transport>        Transport to use (stdio, http) (default: stdio)
  --threads, -j <count>              Number of worker threads (default: CPU core count)
  --max-connections, -c <count>      Maximum concurrent connections (default: 1000)
  --timeout, -T <milliseconds>       Connection timeout in milliseconds (default: 30000, 0 = no timeout)
  --help                             Print this help message

Server Endpoints:
  /jsonrpc                           Main JSON-RPC endpoint (POST)
  /health                            Health check endpoint (GET)
```

#### Advanced Usage

##### Threading Model

The HTTP transport uses a thread pool for handling concurrent connections. By default, it uses a number of threads equal to the available CPU cores, but you can adjust this with the `--threads` option.

##### Connection Limiting

To prevent resource exhaustion, you can limit the number of concurrent connections using the `--max-connections` option. When this limit is reached, new connections will be rejected.

##### Non-blocking Mode

Use the `--non-blocking` option to run the HTTP server in non-blocking mode. This starts a dedicated thread for the server, allowing the main thread to perform other tasks. This is especially useful when using the library in applications that need to do other work while the server is running.

##### Connection Timeouts

Each connection has a configurable timeout (default: 30 seconds) after which inactive connections are automatically closed. Set to 0 to disable timeouts completely.

##### Graceful Shutdown

The server supports graceful shutdown, which allows in-flight requests to complete before the server exits. This prevents abruptly terminating active connections during shutdown.

##### Server Metrics and Health Checks

The HTTP server provides metrics tracking, including:
- Total connections handled
- Active connections
- Bytes sent and received
- Request success/failure rates

A basic health endpoint at `/health` returns server status information.

## Client Examples

The server can be used with any client that implements the MCP protocol. We provide several example clients for demonstration.

### Python Client

Run the server first:

```bash
./zig-out/bin/mcp_server --transport http
```

Then run the Python client:

```bash
# Install required dependencies
pip install requests

# Run the example client
python examples/mcp_client.py --transport http --url "http://127.0.0.1:7777/jsonrpc"
```

The Python client demonstrates:
- Establishing a connection to the MCP server
- Protocol initialization and handshake
- Listing available tools
- Invoking tools with parameters
- Handling responses and errors

### JavaScript Client

For a Node.js client example:

```bash
# Make the script executable
chmod +x test_client.js

# Run the client (automatically starts the server in stdio mode)
./test_client.js
```

This JavaScript client shows:
- Communication over stdio transport
- Asynchronous MCP operation
- Proper request/response handling

### Building Your Own Client

The MCP protocol is based on JSON-RPC 2.0, making it easy to implement clients in any language. Key points to follow:

1. **Initialization**: Send an `initialize` request with your client capabilities
2. **Tool Discovery**: Use `mcp/tools/list` to discover available tools
3. **Tool Invocation**: Use `mcp/tools/invoke` with the tool name and parameters
4. **Shutdown**: Send a `shutdown` request when done

### Building for WebAssembly

The server can be compiled to WebAssembly for deployment in serverless environments:

```bash
zig build -Dtarget=wasm32-wasi -Doptimize=ReleaseSmall
```

When compiled for WebAssembly, the following restrictions apply:

1. **Stdio Transport Only**: The HTTP transport is automatically disabled in WebAssembly builds
2. **Command-line Options**: Most command-line options are unavailable (only `--help` works)
3. **Simplified API**: The API is automatically simplified to only include stdio-related fields

This makes the WebAssembly binary smaller and more focused for running in WebAssembly environments like Fastly Compute or other WASI-compatible serverless platforms where HTTP handling is typically provided by the host environment.

## Library Integration

Zig MCP Server is designed to be easily embedded in your Zig applications as a library.

### Adding the Dependency

#### In your build.zig file

```zig
const std = @import("std");

pub fn build(b: *std.Build) void {
    const target = b.standardTargetOptions(.{});
    const optimize = b.standardOptimizeOption(.{});

    // Add the zig-mcp dependency
    const zig_mcp_dep = b.dependency("zig-mcp", .{
        .target = target,
        .optimize = optimize,
    });

    // Get the module from the dependency
    const zig_mcp_mod = zig_mcp_dep.module("zig-mcp");

    // Create your application
    const exe = b.addExecutable(.{
        .name = "my_mcp_app",
        .root_source_file = b.path("src/main.zig"),
        .target = target,
        .optimize = optimize,
    });

    // Add the zig-mcp module to your application
    exe.addModule("zig-mcp", zig_mcp_mod);

    b.installArtifact(exe);
}
```

#### In your build.zig.zon file

```zig
.{
    .name = .your_app_name,
    .version = "0.1.0",
    .fingerprint = 0x..., // Replace with actual fingerprint
    .dependencies = .{
        .@"zig-mcp" = .{
            .url = "https://github.com/jedisct1/zig-mcp-server/archive/refs/tags/v0.1.0.tar.gz",
            .hash = "12345...", // Replace with actual hash
        },
    },
}
```

### Basic Integration Example

Here's a simple example showing how to integrate the MCP server into your application:

```zig
const std = @import("std");
const zig_mcp = @import("zig-mcp");

pub fn main() !void {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();

    // Define your tools
    const tools = [_]zig_mcp.mcp.Tool{
        .{
            .name = "hello",
            .description = "Greeting tool",
            .handler = &helloHandler,
        },
    };

    // Configure server settings with HTTP transport
    const settings = zig_mcp.mcp.Settings{
        .transport = .http,
        .host = "127.0.0.1",
        .port = 7777,
        .tools = &tools,
        .max_connections = 100,                  // Max 100 concurrent connections
        .thread_count = 4,                       // 4 worker threads
        .connection_timeout_ms = 30000,          // 30 second connection timeout
        .non_blocking_http = true,               // Run in non-blocking mode
    };

    // Create and start MCP server
    var server = try zig_mcp.mcp.Server.init(allocator, settings);
    defer server.deinit();

    std.debug.print("MCP Server starting\n", .{});
    try server.start();

    std.debug.print("Server running in background, you can continue with other tasks...\n", .{});

    // Since we're using non-blocking mode, the main thread can do other work
    var i: usize = 0;
    while (i < 5) : (i += 1) {
        std.time.sleep(5 * std.time.ns_per_s); // Sleep for 5 seconds
        std.debug.print("Main thread still active...\n", .{});
    }

    std.debug.print("Main application shutting down\n", .{});

    // Explicitly request a graceful shutdown before the defer
    server.shutdown();
    std.debug.print("Server shutdown requested, waiting for completion...\n", .{});

    // Allow some time for the shutdown to complete
    std.time.sleep(1 * std.time.ns_per_s);
}

// Tool handler implementation
fn helloHandler(ctx: *zig_mcp.jsonrpc.Context, params: std.json.Value) !std.json.Value {
    const allocator = ctx.allocator();

    // Extract name parameter if present
    const name = if (params.object.get("name")) |n|
        if (n == .string) n.string else "world"
    else
        "world";

    // Build response
    var result = std.json.Value{ .object = std.json.ObjectMap.init(allocator) };
    const greeting = try std.fmt.allocPrint(allocator, "Hello, {s}!", .{name});
    try result.object.put("greeting", std.json.Value{ .string = greeting });

    return result;
}
```

### Advanced Integration

#### Custom Tool Development

Creating custom tools is straightforward:

1. Implement a handler function with the `zig_mcp.mcp.ToolHandlerFn` signature
2. Add it to the tools list when configuring your server
3. Optionally include a JSON Schema definition for tool parameters

```zig
fn myComplexTool(ctx: *zig_mcp.jsonrpc.Context, params: std.json.Value) !std.json.Value {
    const allocator = ctx.allocator();

    // Extract and validate parameters
    const value1 = params.object.get("value1") orelse return zig_mcp.jsonrpc.Error.invalidParams;
    const value2 = params.object.get("value2") orelse return zig_mcp.jsonrpc.Error.invalidParams;

    if (value1 != .integer or value2 != .integer) {
        return zig_mcp.jsonrpc.Error.invalidParams;
    }

    // Business logic
    const result_value = value1.integer * value2.integer;

    // Format and return result
    var result = std.json.Value{ .object = std.json.ObjectMap.init(allocator) };
    try result.object.put("calculated_value", std.json.Value{ .integer = result_value });

    return result;
}
```

#### Transport Configuration

Choose the appropriate transport for your application:

- **HTTP Transport**: Ideal for networked applications, supports high concurrency
- **Stdio Transport**: Perfect for CLI tools and direct integration with LLM systems

#### Memory Management

The server uses an arena allocator for each request, automatically handling cleanup after each request/response cycle to prevent memory leaks.

## Current Status and Future Work

This project is under active development. The server has been improved with threading support, connection limiting, and timeouts, but several areas still need work:

1. **Stability Improvements**: Address potential panics during connection handling
2. **Stress Testing**: Verify behavior under high load and concurrent connections
3. **Secure Transport**: Add TLS support for secure connections
4. **Robust HTTP Parser**: Improve the HTTP parser to handle all edge cases
5. **Complete Error Handling**: Better error handling and recovery mechanisms
6. **Enhanced Logging**: More comprehensive logging system with different verbosity levels
7. **Connection Pooling**: For better performance with HTTP keep-alive
8. **Automated Tests**: Expand test coverage, especially for concurrency

```

`build.zig`:

```zig
const std = @import("std");

pub fn build(b: *std.Build) void {
    const target = b.standardTargetOptions(.{});
    const optimize = b.standardOptimizeOption(.{});

    // Create modules
    const net_mod = b.createModule(.{
        .root_source_file = b.path("src/net.zig"),
        .target = target,
        .optimize = optimize,
    });

    const jsonrpc_mod = b.createModule(.{
        .root_source_file = b.path("src/jsonrpc.zig"),
        .target = target,
        .optimize = optimize,
    });

    const mcp_mod = b.createModule(.{
        .root_source_file = b.path("src/mcp.zig"),
        .target = target,
        .optimize = optimize,
    });

    // Add dependencies between modules
    mcp_mod.addImport("jsonrpc", jsonrpc_mod);
    mcp_mod.addImport("net", net_mod);

    // Create main public module
    const zig_mcp_mod = b.addModule("zig-mcp", .{
        .root_source_file = b.path("src/lib.zig"), // Will create this file
        .target = target,
        .optimize = optimize,
    });

    // Add dependencies to the main module
    zig_mcp_mod.addImport("net", net_mod);
    zig_mcp_mod.addImport("jsonrpc", jsonrpc_mod);
    zig_mcp_mod.addImport("mcp", mcp_mod);

    // Create executable
    const server_mod = b.createModule(.{
        .root_source_file = b.path("src/bin/server.zig"),
        .target = target,
        .optimize = optimize,
    });

    // Add imports to server
    server_mod.addImport("zig-mcp", zig_mcp_mod);

    const exe = b.addExecutable(.{
        .name = "mcp_server",
        .root_module = server_mod,
    });

    b.installArtifact(exe);

    const run_cmd = b.addRunArtifact(exe);
    run_cmd.step.dependOn(b.getInstallStep());
    if (b.args) |args| {
        run_cmd.addArgs(args);
    }

    const run_step = b.step("run", "Run the app");
    run_step.dependOn(&run_cmd.step);

    // Add unit tests
    const lib_test_mod = b.createModule(.{
        .root_source_file = b.path("src/lib.zig"),
        .target = target,
        .optimize = optimize,
    });

    // Add dependencies to the test module
    lib_test_mod.addImport("net", net_mod);
    lib_test_mod.addImport("jsonrpc", jsonrpc_mod);
    lib_test_mod.addImport("mcp", mcp_mod);

    const lib_unit_tests = b.addTest(.{
        .root_module = lib_test_mod,
    });

    const run_lib_tests = b.addRunArtifact(lib_unit_tests);
    const test_step = b.step("test", "Run unit tests");
    test_step.dependOn(&run_lib_tests.step);
}

```

`build.zig.zon`:

```zon
.{
    .name = .mcp_server,
    .version = "0.1.0",
    .fingerprint = 0x301f264c5d9299eb,
    .dependencies = .{
    },
    .paths = .{
        "build.zig",
        "build.zig.zon",
        "src",
        "examples",
        "README.md",
        "Makefile",
    },
}

```

`examples/build.zig`:

```zig
const std = @import("std");

pub fn build(b: *std.Build) void {
    const target = b.standardTargetOptions(.{});
    const optimize = b.standardOptimizeOption(.{});

    // Create modules
    const net_mod = b.createModule(.{
        .root_source_file = b.path("../src/net.zig"),
        .target = target,
        .optimize = optimize,
    });

    const jsonrpc_mod = b.createModule(.{
        .root_source_file = b.path("../src/jsonrpc.zig"),
        .target = target,
        .optimize = optimize,
    });

    const mcp_mod = b.createModule(.{
        .root_source_file = b.path("../src/mcp.zig"),
        .target = target,
        .optimize = optimize,
    });

    // Add dependencies
    mcp_mod.addImport("jsonrpc", jsonrpc_mod);
    mcp_mod.addImport("net", net_mod);

    const zig_mcp_mod = b.createModule(.{
        .root_source_file = b.path("../src/lib.zig"),
        .target = target,
        .optimize = optimize,
    });

    zig_mcp_mod.addImport("net", net_mod);
    zig_mcp_mod.addImport("jsonrpc", jsonrpc_mod);
    zig_mcp_mod.addImport("mcp", mcp_mod);

    // Create the executable module
    const lib_example_mod = b.createModule(.{
        .root_source_file = b.path("lib_example.zig"),
        .target = target,
        .optimize = optimize,
    });

    // Add module imports
    lib_example_mod.addImport("zig-mcp", zig_mcp_mod);

    // Create executable
    const exe = b.addExecutable(.{
        .name = "lib_example",
        .root_module = lib_example_mod,
    });

    b.installArtifact(exe);

    const run_cmd = b.addRunArtifact(exe);
    run_cmd.step.dependOn(b.getInstallStep());
    if (b.args) |args| {
        run_cmd.addArgs(args);
    }

    const run_step = b.step("run", "Run the example");
    run_step.dependOn(&run_cmd.step);
}

```

`examples/lib_example.zig`:

```zig
const std = @import("std");
const zig_mcp = @import("zig-mcp");

pub fn main() !void {
    var gpa = std.heap.GeneralPurposeAllocator(.{}){};
    defer _ = gpa.deinit();
    const allocator = gpa.allocator();

    // Define your tools
    const tools = [_]zig_mcp.mcp.Tool{
        .{
            .name = "hello",
            .description = "Greeting tool",
            .handler = &helloHandler,
        },
    };

    // Configure server settings - use stdio transport instead of HTTP to avoid socket issues
    const settings = zig_mcp.mcp.Settings{
        .transport = .stdio,
        .tools = &tools,
    };

    // Create and start MCP server
    var server = try zig_mcp.mcp.Server.init(allocator, settings);
    defer server.deinit();

    std.debug.print("MCP Server starting\n", .{});

    // Start the server in a separate thread since the stdio transport is blocking
    var serverThread: ?std.Thread = null;

    serverThread = try std.Thread.spawn(.{}, struct {
        fn runServer(srv: *zig_mcp.mcp.Server) !void {
            try srv.start();
        }
    }.runServer, .{&server});

    std.debug.print("Server running in background, you can continue with other tasks...\n", .{});

    // Since we're running in a separate thread, the main thread can do other work
    var i: usize = 0;
    while (i < 2) : (i += 1) {
        std.time.sleep(2 * std.time.ns_per_s); // Sleep for 2 seconds
        std.debug.print("Main thread still active...\n", .{});
    }

    std.debug.print("Main application shutting down\n", .{});
    // Explicitly request a graceful shutdown
    server.shutdown();
    std.debug.print("Server shutdown requested, waiting for completion...\n", .{});

    // Wait for the server thread to complete
    if (serverThread) |thread| {
        thread.join();
    }

    std.debug.print("Server thread has joined, cleaning up resources...\n", .{});
    // Server resources will be cleaned up when server variable is dropped
}

// Tool handler implementation
fn helloHandler(ctx: *zig_mcp.jsonrpc.Context, params: std.json.Value) !std.json.Value {
    const allocator = ctx.allocator();

    // Extract name parameter if present
    const name = if (params.object.get("name")) |n|
        if (n == .string) n.string else "world"
    else
        "world";

    // Build response
    var result = std.json.Value{ .object = std.json.ObjectMap.init(allocator) };
    const greeting = try std.fmt.allocPrint(allocator, "Hello, {s}!", .{name});
    try result.object.put("greeting", std.json.Value{ .string = greeting });

    return result;
}

```

`examples/mcp_client.py`:

```py
#!/usr/bin/env python3
"""
Simple MCP client example that connects to an MCP server using stdio or HTTP transport.

Usage:
    python3 mcp_client.py --transport [stdio|http] --url [url]

Example:
    # Connect to a stdio-based server
    python3 mcp_client.py --transport stdio --command "./zig-out/bin/mcp_server"
    
    # Connect to an HTTP-based server
    python3 mcp_client.py --transport http --url "http://127.0.0.1:7777/jsonrpc"
"""

import argparse
import json
import random
import requests
import subprocess
import sys
import threading
import time
from typing import Dict, Any, Optional, List

class McpClient:
    """Simple MCP client implementation."""
    
    def __init__(self):
        self.request_id = 0
        self.process = None
        self.url = None
        self.initialized = False
        self.capabilities = None
    
    def _get_request_id(self) -> int:
        """Generate a unique request ID."""
        self.request_id += 1
        return self.request_id
    
    def connect_stdio(self, command: List[str]) -> None:
        """Connect to an MCP server using stdio transport."""
        print(f"Starting MCP server: {' '.join(command)}")
        self.process = subprocess.Popen(
            command,
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            universal_newlines=True,
            bufsize=1  # Line buffered
        )
        
        # Start a thread to read server's stderr and print it
        def read_stderr():
            while self.process.poll() is None:
                line = self.process.stderr.readline()
                if line:
                    print(f"SERVER LOG: {line.strip()}")
        
        threading.Thread(target=read_stderr, daemon=True).start()
    
    def connect_http(self, url: str) -> None:
        """Connect to an MCP server using HTTP transport."""
        self.url = url
        print(f"Connecting to MCP server at {url}")
    
    def send_request_stdio(self, method: str, params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """Send a request to the server using stdio transport."""
        if self.process is None:
            raise RuntimeError("Not connected to a server")
        
        request = {
            "jsonrpc": "2.0",
            "id": self._get_request_id(),
            "method": method,
        }
        
        if params is not None:
            request["params"] = params
        
        request_str = json.dumps(request)
        print(f"Sending request: {request_str}")
        
        # Write the request to the server's stdin
        self.process.stdin.write(request_str + "\n")
        self.process.stdin.flush()
        
        # Read the response from the server's stdout
        response_str = self.process.stdout.readline().strip()
        print(f"Received response: {response_str}")
        
        return json.loads(response_str)
    
    def send_request_http(self, method: str, params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """Send a request to the server using HTTP transport."""
        if self.url is None:
            raise RuntimeError("Not connected to a server")
        
        request = {
            "jsonrpc": "2.0",
            "id": self._get_request_id(),
            "method": method,
        }
        
        if params is not None:
            request["params"] = params
        
        request_str = json.dumps(request)
        print(f"Sending request: {request_str}")
        
        # Send the request to the server
        response = requests.post(self.url, json=request)
        response_str = response.text
        print(f"Received response: {response_str}")
        
        return json.loads(response_str)
    
    def send_request(self, method: str, params: Optional[Dict[str, Any]] = None) -> Dict[str, Any]:
        """Send a request to the server using the configured transport."""
        if self.process is not None:
            return self.send_request_stdio(method, params)
        elif self.url is not None:
            return self.send_request_http(method, params)
        else:
            raise RuntimeError("Not connected to a server")
    
    def initialize(self) -> None:
        """Initialize the MCP connection."""
        response = self.send_request("initialize", {
            "protocolVersion": "0.4.0",
            "capabilities": {
                "tools": {
                    "enabled": True
                }
            }
        })
        
        if "error" in response:
            raise RuntimeError(f"Failed to initialize: {response['error']}")
        
        self.capabilities = response["result"]["capabilities"]
        print(f"Server capabilities: {json.dumps(self.capabilities, indent=2)}")
        
        # Send initialized notification
        self.send_request("initialized")
        self.initialized = True
    
    def list_tools(self) -> List[Dict[str, Any]]:
        """Get the list of available tools."""
        response = self.send_request("mcp/tools/list")
        
        if "error" in response:
            raise RuntimeError(f"Failed to list tools: {response['error']}")
        
        tools = response["result"]["tools"]
        return tools
    
    def invoke_tool(self, name: str, params: Optional[Dict[str, Any]] = None) -> Any:
        """Invoke a tool on the server."""
        request_params = {
            "name": name
        }
        
        if params is not None:
            request_params["params"] = params
        
        response = self.send_request("mcp/tools/invoke", request_params)
        
        if "error" in response:
            raise RuntimeError(f"Failed to invoke tool: {response['error']}")
        
        return response["result"]
    
    def shutdown(self) -> None:
        """Shutdown the connection."""
        self.send_request("shutdown")
        
        if self.process is not None:
            self.process.terminate()
            self.process.wait()

def main():
    """Run the MCP client."""
    parser = argparse.ArgumentParser(description="Simple MCP client")
    parser.add_argument("--transport", choices=["stdio", "http"], required=True,
                        help="Transport to use (stdio or http)")
    parser.add_argument("--command", type=str, help="Command to run the MCP server (for stdio transport)")
    parser.add_argument("--url", type=str, help="URL of the MCP server (for HTTP transport)")
    
    args = parser.parse_args()
    
    client = McpClient()
    
    try:
        if args.transport == "stdio":
            if not args.command:
                parser.error("--command is required for stdio transport")
            client.connect_stdio(args.command.split())
        else:  # HTTP
            if not args.url:
                parser.error("--url is required for HTTP transport")
            client.connect_http(args.url)
        
        # Initialize the connection
        print("Initializing connection...")
        client.initialize()
        
        # List available tools
        print("\nListing available tools:")
        tools = client.list_tools()
        for tool in tools:
            print(f" - {tool['name']}: {tool['description']}")
        
        # Invoke the echo tool
        print("\nInvoking 'echo' tool:")
        echo_result = client.invoke_tool("echo", {"message": "Hello, MCP!"})
        print(f"Echo result: {json.dumps(echo_result, indent=2)}")
        
        # Invoke the reverse tool
        print("\nInvoking 'reverse' tool:")
        reverse_result = client.invoke_tool("reverse", {"text": "Hello, MCP!"})
        print(f"Reverse result: {json.dumps(reverse_result, indent=2)}")
        
        # Shutdown
        print("\nShutting down...")
        client.shutdown()
        
    except Exception as e:
        print(f"Error: {e}")
        if client is not None:
            client.shutdown()
        sys.exit(1)

if __name__ == "__main__":
    main()
```

`src/bin/server.zig`:

```zig
const std = @import("std");
const builtin = @import("builtin");
const mcp_lib = @import("zig-mcp");
const mcp = mcp_lib.mcp;
const jsonrpc = mcp_lib.jsonrpc;

// Detect WebAssembly target
const is_wasm = builtin.cpu.arch.isWasm();

pub fn main() !void {
    // Initialize allocator
    var gpa = std.heap.GeneralPurposeAllocator(.{ .enable_memory_limit = true }){};
    const allocator = gpa.allocator();
    defer {
        const check = gpa.deinit();
        if (check == .leak) {
            std.debug.print("MEMORY LEAK DETECTED!\n", .{});
        }
    }

    // Parse command line arguments
    var args_it = try std.process.argsWithAllocator(allocator);
    defer args_it.deinit();

    // Skip program name
    _ = args_it.skip();

    // Default settings with static strings for tool names and descriptions
    const tools = [_]mcp.Tool{
        .{
            .name = "echo",
            .description = "Echoes back whatever is sent to it",
            .handler = &echoHandler,
        },
        .{
            .name = "reverse",
            .description = "Reverses the input string",
            .handler = &reverseHandler,
        },
    };

    var settings = if (is_wasm) mcp.Settings{
        // WebAssembly version - only stdio transport is available
        .transport = .stdio,
        .tools = &tools,
    } else mcp.Settings{
        // Native version with all options
        .port = 7777,
        .host = "127.0.0.1",
        .transport = .stdio,
        .tools = &tools,
        .max_connections = 1000, // Default to 1000 max connections
        .thread_count = null, // Default to auto-detect (based on CPU cores)
        .connection_timeout_ms = 30000, // Default to 30 seconds timeout
    };

    // Parse command line arguments using stack-allocated buffer
    var arg_buf: [256]u8 = undefined;
    while (args_it.next()) |arg| {
        if (is_wasm) {
            // In WebAssembly mode, only --help is supported
            if (std.mem.eql(u8, arg, "--help")) {
                printHelp();
                return;
            } else {
                std.debug.print("Ignoring unsupported option '{s}' in WebAssembly mode\n", .{arg});
                // Skip the value if it's a key-value parameter
                if (std.mem.eql(u8, arg, "--port") or
                    std.mem.eql(u8, arg, "-p") or
                    std.mem.eql(u8, arg, "--host") or
                    std.mem.eql(u8, arg, "-h") or
                    std.mem.eql(u8, arg, "--transport") or
                    std.mem.eql(u8, arg, "-t") or
                    std.mem.eql(u8, arg, "--threads") or
                    std.mem.eql(u8, arg, "-j") or
                    std.mem.eql(u8, arg, "--max-connections") or
                    std.mem.eql(u8, arg, "-c") or
                    std.mem.eql(u8, arg, "--timeout") or
                    std.mem.eql(u8, arg, "-T"))
                {
                    _ = args_it.next();
                }
            }
        } else {
            // Full command-line parsing for native platforms
            if (std.mem.eql(u8, arg, "--port") or std.mem.eql(u8, arg, "-p")) {
                if (args_it.next()) |port_str| {
                    settings.port = try std.fmt.parseInt(u16, port_str, 10);
                }
            } else if (std.mem.eql(u8, arg, "--host") or std.mem.eql(u8, arg, "-h")) {
                if (args_it.next()) |host| {
                    // Copy host to static buffer
                    if (host.len < arg_buf.len) {
                        @memcpy(arg_buf[0..host.len], host);
                        settings.host = arg_buf[0..host.len];
                    } else {
                        std.debug.print("Host name too long, using default\n", .{});
                    }
                }
            } else if (std.mem.eql(u8, arg, "--transport") or std.mem.eql(u8, arg, "-t")) {
                if (args_it.next()) |transport| {
                    if (std.mem.eql(u8, transport, "stdio")) {
                        settings.transport = .stdio;
                    } else if (std.mem.eql(u8, transport, "http")) {
                        settings.transport = .http;
                    } else {
                        std.debug.print("Unknown transport: {s}. Using default.\n", .{transport});
                    }
                }
            } else if (std.mem.eql(u8, arg, "--threads") or std.mem.eql(u8, arg, "-j")) {
                if (args_it.next()) |threads_str| {
                    settings.thread_count = try std.fmt.parseInt(usize, threads_str, 10);
                }
            } else if (std.mem.eql(u8, arg, "--max-connections") or std.mem.eql(u8, arg, "-c")) {
                if (args_it.next()) |conn_str| {
                    settings.max_connections = try std.fmt.parseInt(usize, conn_str, 10);
                }
            } else if (std.mem.eql(u8, arg, "--timeout") or std.mem.eql(u8, arg, "-T")) {
                if (args_it.next()) |timeout_str| {
                    settings.connection_timeout_ms = try std.fmt.parseInt(u32, timeout_str, 10);
                }
            } else if (std.mem.eql(u8, arg, "--help")) {
                printHelp();
                return;
            }
        }
    }

    // Create and start MCP server
    var server = try mcp.Server.init(allocator, settings);
    defer server.deinit();

    std.debug.print("MCP Server starting with transport: {s}\n", .{@tagName(settings.transport)});

    if (is_wasm) {
        // WebAssembly-specific output
        std.debug.print("Running in WebAssembly mode with stdio transport\n", .{});
    } else if (settings.transport == .http) {
        // HTTP-specific output for native platforms
        const thread_count_str = if (settings.thread_count) |tc|
            std.fmt.allocPrint(allocator, "{d}", .{tc}) catch "(error)"
        else
            "(auto)";

        const max_connections = settings.max_connections orelse 1000;
        const timeout_str = if (settings.connection_timeout_ms == 0)
            "disabled"
        else
            std.fmt.allocPrint(allocator, "{d}ms", .{settings.connection_timeout_ms}) catch "?";

        defer {
            if (settings.thread_count != null and !std.mem.eql(u8, thread_count_str, "(error)"))
                allocator.free(@as([]u8, @constCast(thread_count_str)));

            if (settings.connection_timeout_ms != 0 and !std.mem.eql(u8, timeout_str, "?"))
                allocator.free(@as([]u8, @constCast(timeout_str)));
        }

        std.debug.print("Listening on http://{s}:{d} with {s} threads, {d} max connections, timeout: {s}\n", .{ settings.host, settings.port, thread_count_str, max_connections, timeout_str });
    }

    try server.start();
}

fn printHelp() void {
    if (is_wasm) {
        // WebAssembly-specific help text
        const wasm_help_text =
            \\Usage: zig-mcp [options]
            \\
            \\WebAssembly Version - Only stdio transport is available
            \\
            \\Options:
            \\  --help                             Print this help message
            \\
        ;
        std.debug.print("{s}", .{wasm_help_text});
    } else {
        // Full help text for native platforms
        const help_text =
            \\Usage: zig-mcp [options]
            \\
            \\Options:
            \\  --port, -p <port>                  Port to listen on (default: 7777)
            \\  --host, -h <host>                  Host to bind to (default: 127.0.0.1)
            \\  --transport, -t <transport>        Transport to use (stdio, http) (default: stdio)
            \\  --threads, -j <count>              Number of worker threads (default: CPU core count)
            \\  --max-connections, -c <count>      Maximum concurrent connections (default: 1000)
            \\  --timeout, -T <milliseconds>       Connection timeout in milliseconds (default: 30000, 0 = no timeout)
            \\  --help                             Print this help message
            \\
            \\When compiled for WebAssembly, only stdio transport is available.
            \\
        ;
        std.debug.print("{s}", .{help_text});
    }
}

// Tool handler implementations
fn echoHandler(ctx: *jsonrpc.Context, params: std.json.Value) !std.json.Value {
    // For echo, we just need to clone the params into our context
    return try mcp.cloneJsonValue(ctx.allocator(), params);
}

fn reverseHandler(ctx: *jsonrpc.Context, params: std.json.Value) !std.json.Value {
    // Get the allocator from the context
    const allocator = ctx.allocator();

    // Check if params has a "text" field
    const text_value = params.object.get("text") orelse {
        return jsonrpc.Error.invalidParams;
    };

    if (text_value != .string) {
        return jsonrpc.Error.invalidParams;
    }

    const text = text_value.string;

    // Use stack buffer for small strings, fall back to heap for larger ones
    var stack_buf: [1024]u8 = undefined;
    const reversed = if (text.len <= stack_buf.len) blk: {
        // Reverse the string in stack buffer
        for (text, 0..) |char, i| {
            stack_buf[text.len - 1 - i] = char;
        }
        // Allocate a copied string in our arena
        break :blk try allocator.dupe(u8, stack_buf[0..text.len]);
    } else blk: {
        // For larger strings, use heap allocation
        var heap_buf = try allocator.alloc(u8, text.len);
        // Reverse the string
        for (text, 0..) |char, i| {
            heap_buf[text.len - 1 - i] = char;
        }
        break :blk heap_buf;
    };

    // Create response object
    var result = std.json.Value{ .object = std.json.ObjectMap.init(allocator) };
    try result.object.put("reversed", std.json.Value{ .string = reversed });

    return result;
}

// Export tests
test {
    std.testing.refAllDecls(@This());
}

```

`src/jsonrpc.zig`:

```zig
const std = @import("std");

/// JSON-RPC 2.0 Constants
pub const VERSION = "2.0";

/// JSON-RPC 2.0 Error Codes
pub const ErrorCode = enum(i32) {
    // JSON-RPC 2.0 standard error codes
    parseError = -32700,
    invalidRequest = -32600,
    methodNotFound = -32601,
    invalidParams = -32602,
    internalError = -32603,

    // MCP specific error codes
    requestFailed = -32000,
    serverNotInitialized = -32002,
    unknownProtocolVersion = -32003,
};

/// JSON-RPC 2.0 Error type
pub const Error = error{
    parseError,
    invalidRequest,
    methodNotFound,
    invalidParams,
    internalError,
    requestFailed,
    serverNotInitialized,
    unknownProtocolVersion,

    // Additional error types for internal use
    messageIdMismatch,
};

/// Request/Response context for memory management
pub const Context = struct {
    arena: std.heap.ArenaAllocator,

    pub fn init(parent_allocator: std.mem.Allocator) Context {
        return .{
            .arena = std.heap.ArenaAllocator.init(parent_allocator),
        };
    }

    pub fn deinit(self: *Context) void {
        self.arena.deinit();
    }

    pub fn allocator(self: *Context) std.mem.Allocator {
        return self.arena.allocator();
    }

    /// Reset the arena, freeing all allocations at once
    pub fn reset(self: *Context) void {
        _ = self.arena.reset(.retain_capacity);
    }
};

/// Convert JSON value to string
pub fn stringifyValue(allocator: std.mem.Allocator, value: std.json.Value) ![]const u8 {
    var buffer = std.ArrayList(u8).init(allocator);
    errdefer buffer.deinit();
    try std.json.stringify(value, .{}, buffer.writer());
    return buffer.toOwnedSlice();
}

/// Create a JSON-RPC 2.0 error response
pub fn createErrorResponse(ctx: *Context, id: std.json.Value, code: ErrorCode, message: []const u8) !std.json.Value {
    const allocator = ctx.allocator();

    var error_obj = std.json.Value{ .object = std.json.ObjectMap.init(allocator) };
    try error_obj.object.put("code", std.json.Value{ .integer = @intFromEnum(code) });
    try error_obj.object.put("message", std.json.Value{ .string = try allocator.dupe(u8, message) });

    var response = std.json.Value{ .object = std.json.ObjectMap.init(allocator) };
    try response.object.put("jsonrpc", std.json.Value{ .string = "2.0" });
    try response.object.put("id", id);
    try response.object.put("error", error_obj);

    return response;
}

/// Create a JSON-RPC 2.0 success response
pub fn createSuccessResponse(ctx: *Context, id: std.json.Value, result: std.json.Value) !std.json.Value {
    const allocator = ctx.allocator();

    var response = std.json.Value{ .object = std.json.ObjectMap.init(allocator) };
    try response.object.put("jsonrpc", std.json.Value{ .string = "2.0" });
    try response.object.put("id", id);
    try response.object.put("result", result);

    return response;
}

/// Create a JSON-RPC 2.0 notification (no response expected)
pub fn createNotification(ctx: *Context, method: []const u8, params: ?std.json.Value) !std.json.Value {
    const allocator = ctx.allocator();

    var notification = std.json.Value{ .object = std.json.ObjectMap.init(allocator) };
    try notification.object.put("jsonrpc", std.json.Value{ .string = "2.0" });
    try notification.object.put("method", std.json.Value{ .string = try allocator.dupe(u8, method) });

    if (params) |p| {
        try notification.object.put("params", p);
    }

    return notification;
}

/// Create a JSON-RPC 2.0 request
pub fn createRequest(ctx: *Context, id: std.json.Value, method: []const u8, params: ?std.json.Value) !std.json.Value {
    const allocator = ctx.allocator();

    var request = std.json.Value{ .object = std.json.ObjectMap.init(allocator) };
    try request.object.put("jsonrpc", std.json.Value{ .string = "2.0" });
    try request.object.put("id", id);
    try request.object.put("method", std.json.Value{ .string = try allocator.dupe(u8, method) });

    if (params) |p| {
        try request.object.put("params", p);
    }

    return request;
}

/// Parse a JSON-RPC 2.0 message
/// Note: The parser owns the memory of the returned JSON value.
pub fn parseMessage(ctx: *Context, message: []const u8) !std.json.Value {
    var parsed = try std.json.parseFromSlice(std.json.Value, ctx.allocator(), message, .{});
    defer parsed.deinit();

    // Deep clone is not needed here since we're working with an arena allocator
    return parsed.value;
}

/// Validate a JSON-RPC 2.0 message
pub fn validateMessage(message: std.json.Value) !void {
    if (message != .object) {
        return Error.invalidRequest;
    }

    // Check for jsonrpc field
    const jsonrpc = message.object.get("jsonrpc") orelse {
        return Error.invalidRequest;
    };

    if (jsonrpc != .string or !std.mem.eql(u8, jsonrpc.string, "2.0")) {
        return Error.invalidRequest;
    }

    // Check if it's a request, notification, or response
    if (message.object.get("method")) |method| {
        // It's a request or notification
        if (method != .string) {
            return Error.invalidRequest;
        }

        // If it has an id, it's a request
        if (message.object.get("id")) |id| {
            if (id != .string and id != .integer and id != .null) {
                return Error.invalidRequest;
            }
        }

        // If it has params, they must be an object or array
        if (message.object.get("params")) |params| {
            if (params != .object and params != .array) {
                return Error.invalidRequest;
            }
        }
    } else {
        // It's a response
        const id = message.object.get("id") orelse {
            return Error.invalidRequest;
        };

        if (id != .string and id != .integer and id != .null) {
            return Error.invalidRequest;
        }

        // Must have either result or error
        const has_result = message.object.get("result") != null;
        const has_error = message.object.get("error") != null;

        if (has_result == has_error) {
            return Error.invalidRequest;
        }

        // If it has an error, it must be an object with code and message
        if (has_error) {
            const error_obj = message.object.get("error").?;
            if (error_obj != .object) {
                return Error.invalidRequest;
            }

            const code = error_obj.object.get("code") orelse {
                return Error.invalidRequest;
            };

            if (code != .integer) {
                return Error.invalidRequest;
            }

            const message_field = error_obj.object.get("message") orelse {
                return Error.invalidRequest;
            };

            if (message_field != .string) {
                return Error.invalidRequest;
            }
        }
    }
}

```

`src/lib.zig`:

```zig
const std = @import("std");
const builtin = @import("builtin");

// Detect WebAssembly target
const is_wasm = builtin.cpu.arch.isWasm();

/// Re-export MCP modules
pub const mcp = @import("mcp.zig");
pub const jsonrpc = @import("jsonrpc.zig");
// Only export net.zig on non-WebAssembly targets
pub const net = if (!is_wasm) @import("net.zig") else struct {};
pub const tool_handlers = @import("tools.zig");

/// Version of the zig-mcp library
pub const VERSION = "0.1.0";

/// Simple helper function to initialize and run an MCP server with custom tools
pub fn createServer(
    allocator: std.mem.Allocator,
    tool_list: []const mcp.Tool,
    transport_type: mcp.TransportType,
    host: []const u8,
    port: u16,
) !mcp.Server {
    if (is_wasm) {
        // In WebAssembly, we only use stdio transport and ignore host/port
        const settings = mcp.Settings{
            .transport = .stdio, // Force stdio for WebAssembly
            .tools = tool_list,
        };
        return try mcp.Server.init(allocator, settings);
    } else {
        // For non-WebAssembly platforms, use all parameters
        const settings = mcp.Settings{
            .transport = transport_type,
            .host = host,
            .port = port,
            .tools = tool_list,
        };
        return try mcp.Server.init(allocator, settings);
    }
}

/// Create a tool definition with the given name, description and handler
pub fn createTool(
    name: []const u8,
    description: []const u8,
    handler: mcp.ToolHandlerFn,
    parameters: ?std.json.Value,
) mcp.Tool {
    return .{
        .name = name,
        .description = description,
        .handler = handler,
        .parameters = parameters,
    };
}

test "main export test" {
    // This test imports and exercises all exported items
    _ = mcp;
    _ = jsonrpc;
    if (!is_wasm) {
        // Net module only available on non-WebAssembly platforms
        _ = net;
    }
    _ = tool_handlers;
    _ = VERSION;
    _ = createServer;
    _ = createTool;

    // Test basic module functionality
    const std_test = std.testing;

    // Mock a tool handler function for tests
    var test_context = jsonrpc.Context.init(std_test.allocator);
    defer test_context.deinit();

    // Create a test JSON value
    var test_value = std.json.Value{ .object = std.json.ObjectMap.init(test_context.allocator()) };
    try test_value.object.put("test", std.json.Value{ .string = "value" });

    // Create a tool with our mock handler
    const test_tool = createTool(
        "test_tool",
        "A test tool",
        testHandler,
        null,
    );

    // Basic validation of the tool
    try std_test.expectEqualStrings("test_tool", test_tool.name);
    try std_test.expectEqualStrings("A test tool", test_tool.description);
}

// Test handler function for tests
fn testHandler(ctx: *jsonrpc.Context, params: std.json.Value) !std.json.Value {
    _ = params;
    var result = std.json.Value{ .object = std.json.ObjectMap.init(ctx.allocator()) };
    try result.object.put("success", std.json.Value{ .bool = true });
    return result;
}

// Ensure all public declarations are tested
test {
    std.testing.refAllDecls(@This());
}

```

`src/main.zig`:

```zig
const std = @import("std");
const jsonrpc = @import("jsonrpc.zig");
const mcp = @import("mcp.zig");
const builtin = @import("builtin");

// Only import net.zig when not targeting WebAssembly
const is_wasm = builtin.cpu.arch.isWasm();
const net = if (!is_wasm) @import("net.zig") else struct {};

pub fn main() !void {
    // Initialize allocator
    var gpa = std.heap.GeneralPurposeAllocator(.{ .enable_memory_limit = true }){};
    const allocator = gpa.allocator();
    defer {
        const check = gpa.deinit();
        if (check == .leak) {
            std.debug.print("MEMORY LEAK DETECTED!\n", .{});
        }
    }

    // Parse command line arguments
    var args_it = try std.process.argsWithAllocator(allocator);
    defer args_it.deinit();

    // Skip program name
    _ = args_it.skip();

    // Default settings with static strings for tool names and descriptions
    const tools = [_]mcp.Tool{
        .{
            .name = "echo",
            .description = "Echoes back whatever is sent to it",
            .handler = &echoHandler,
        },
        .{
            .name = "reverse",
            .description = "Reverses the input string",
            .handler = &reverseHandler,
        },
    };

    // Configure settings based on platform
    var settings = if (is_wasm)
        // In WebAssembly, only stdio transport is available with limited settings
        mcp.Settings{
            .transport = .stdio,
            .tools = &tools,
        }
    else
        // On native platforms, all settings are available
        mcp.Settings{
            .port = 7777,
            .host = "127.0.0.1",
            .transport = .stdio,
            .tools = &tools,
            .max_connections = 1000, // Default to 1000 max connections
            .thread_count = null, // Default to auto-detect (based on CPU cores)
            .connection_timeout_ms = 30000, // Default to 30 seconds timeout
            .backlog_size = 128, // Default to 128 connections backlog
            .non_blocking_http = false, // Default to blocking HTTP server
        };

    // Parse command line arguments using stack-allocated buffer
    var arg_buf: [256]u8 = undefined;
    while (args_it.next()) |arg| {
        if (std.mem.eql(u8, arg, "--port") or std.mem.eql(u8, arg, "-p")) {
            if (args_it.next()) |port_str| {
                settings.port = try std.fmt.parseInt(u16, port_str, 10);
            }
        } else if (std.mem.eql(u8, arg, "--host") or std.mem.eql(u8, arg, "-h")) {
            if (args_it.next()) |host| {
                // Copy host to static buffer
                if (host.len < arg_buf.len) {
                    @memcpy(arg_buf[0..host.len], host);
                    settings.host = arg_buf[0..host.len];
                } else {
                    std.debug.print("Host name too long, using default\n", .{});
                }
            }
        } else if (std.mem.eql(u8, arg, "--transport") or std.mem.eql(u8, arg, "-t")) {
            if (is_wasm) {
                // For WebAssembly, only stdio transport is allowed
                std.debug.print("WebAssembly build only supports stdio transport\n", .{});
            } else if (args_it.next()) |transport| {
                if (std.mem.eql(u8, transport, "stdio")) {
                    settings.transport = .stdio;
                } else if (std.mem.eql(u8, transport, "http")) {
                    settings.transport = .http;
                } else {
                    std.debug.print("Unknown transport: {s}. Using default.\n", .{transport});
                }
            }
        } else if (std.mem.eql(u8, arg, "--threads") or std.mem.eql(u8, arg, "-j")) {
            if (is_wasm) {
                // Skip HTTP-specific arguments on WebAssembly
                std.debug.print("--threads option not available in WebAssembly build\n", .{});
                _ = args_it.next(); // Skip the value
            } else if (args_it.next()) |threads_str| {
                settings.thread_count = try std.fmt.parseInt(usize, threads_str, 10);
            }
        } else if (std.mem.eql(u8, arg, "--max-connections") or std.mem.eql(u8, arg, "-c")) {
            if (is_wasm) {
                // Skip HTTP-specific arguments on WebAssembly
                std.debug.print("--max-connections option not available in WebAssembly build\n", .{});
                _ = args_it.next(); // Skip the value
            } else if (args_it.next()) |conn_str| {
                settings.max_connections = try std.fmt.parseInt(usize, conn_str, 10);
            }
        } else if (std.mem.eql(u8, arg, "--timeout") or std.mem.eql(u8, arg, "-T")) {
            if (is_wasm) {
                // Skip HTTP-specific arguments on WebAssembly
                std.debug.print("--timeout option not available in WebAssembly build\n", .{});
                _ = args_it.next(); // Skip the value
            } else if (args_it.next()) |timeout_str| {
                settings.connection_timeout_ms = try std.fmt.parseInt(u32, timeout_str, 10);
            }
        } else if (std.mem.eql(u8, arg, "--backlog") or std.mem.eql(u8, arg, "-b")) {
            if (is_wasm) {
                // Skip HTTP-specific arguments on WebAssembly
                std.debug.print("--backlog option not available in WebAssembly build\n", .{});
                _ = args_it.next(); // Skip the value
            } else if (args_it.next()) |backlog_str| {
                settings.backlog_size = try std.fmt.parseInt(u32, backlog_str, 10);
            }
        } else if (std.mem.eql(u8, arg, "--non-blocking")) {
            if (is_wasm) {
                // Skip HTTP-specific arguments on WebAssembly
                std.debug.print("--non-blocking option not available in WebAssembly build\n", .{});
            } else {
                settings.non_blocking_http = true;
            }
        } else if (std.mem.eql(u8, arg, "--help")) {
            printHelp();
            return;
        }
    }

    // Create and start MCP server
    var server = try mcp.Server.init(allocator, settings);
    defer server.deinit();

    std.debug.print("MCP Server starting with transport: {s}\n", .{@tagName(settings.transport)});

    // HTTP-specific output is only available on non-WebAssembly platforms
    if (!is_wasm and settings.transport == .http) {
        const thread_count_str = if (settings.thread_count) |tc|
            std.fmt.allocPrint(allocator, "{d}", .{tc}) catch "(error)"
        else
            "(auto)";

        const max_connections = settings.max_connections orelse 1000;
        const timeout_str = if (settings.connection_timeout_ms == 0)
            "disabled"
        else
            std.fmt.allocPrint(allocator, "{d}ms", .{settings.connection_timeout_ms}) catch "?";

        defer {
            if (settings.thread_count != null and !std.mem.eql(u8, thread_count_str, "(error)"))
                allocator.free(@as([]u8, @constCast(thread_count_str)));

            if (settings.connection_timeout_ms != 0 and !std.mem.eql(u8, timeout_str, "?"))
                allocator.free(@as([]u8, @constCast(timeout_str)));
        }

        std.debug.print("Listening on http://{s}:{d} with {s} threads, {d} max connections, timeout: {s}\n", .{ settings.host, settings.port, thread_count_str, max_connections, timeout_str });
    } else if (is_wasm) {
        std.debug.print("Running in WebAssembly mode (stdio transport only)\n", .{});
    }

    try server.start();
}

fn printHelp() void {
    // Use different help text based on platform
    if (is_wasm) {
        // WebAssembly-specific help text
        const wasm_help_text =
            \\Usage: zig-mcp [options]
            \\
            \\WebAssembly Version - Only stdio transport is available
            \\
            \\Options:
            \\  --help                             Print this help message
            \\
        ;
        std.debug.print("{s}", .{wasm_help_text});
    } else {
        // Full help text for native platforms
        const help_text =
            \\Usage: zig-mcp [options]
            \\
            \\Options:
            \\  --port, -p <port>                  Port to listen on (default: 7777)
            \\  --host, -h <host>                  Host to bind to (default: 127.0.0.1)
            \\  --transport, -t <transport>        Transport to use (stdio, http) (default: stdio)
            \\  --threads, -j <count>              Number of worker threads (default: CPU core count)
            \\  --max-connections, -c <count>      Maximum concurrent connections (default: 1000)
            \\  --timeout, -T <milliseconds>       Connection timeout in milliseconds (default: 30000, 0 = no timeout)
            \\  --backlog, -b <count>              TCP connection backlog size (default: 128)
            \\  --non-blocking                     Run HTTP server in non-blocking mode
            \\  --help                             Print this help message
            \\
            \\Server Endpoints:
            \\  /jsonrpc                           Main JSON-RPC endpoint (POST)
            \\  /health                            Health check endpoint (GET)
            \\
        ;
        std.debug.print("{s}", .{help_text});
    }
}

// Tool handler implementations
fn echoHandler(ctx: *jsonrpc.Context, params: std.json.Value) !std.json.Value {
    // For echo, we just need to clone the params into our context
    return try mcp.cloneJsonValue(ctx.allocator(), params);
}

fn reverseHandler(ctx: *jsonrpc.Context, params: std.json.Value) !std.json.Value {
    // Get the allocator from the context
    const allocator = ctx.allocator();

    // Check if params has a "text" field
    const text_value = params.object.get("text") orelse {
        return jsonrpc.Error.invalidParams;
    };

    if (text_value != .string) {
        return jsonrpc.Error.invalidParams;
    }

    const text = text_value.string;

    // Use stack buffer for small strings, fall back to heap for larger ones
    var stack_buf: [1024]u8 = undefined;
    const reversed = if (text.len <= stack_buf.len) blk: {
        // Reverse the string in stack buffer
        for (text, 0..) |char, i| {
            stack_buf[text.len - 1 - i] = char;
        }
        // Allocate a copied string in our arena
        break :blk try allocator.dupe(u8, stack_buf[0..text.len]);
    } else blk: {
        // For larger strings, use heap allocation
        var heap_buf = try allocator.alloc(u8, text.len);
        // Reverse the string
        for (text, 0..) |char, i| {
            heap_buf[text.len - 1 - i] = char;
        }
        break :blk heap_buf;
    };

    // Create response object
    var result = std.json.Value{ .object = std.json.ObjectMap.init(allocator) };
    try result.object.put("reversed", std.json.Value{ .string = reversed });

    return result;
}

// Export tests
test {
    std.testing.refAllDecls(@This());
}

```

`src/mcp.zig`:

```zig
const std = @import("std");
const jsonrpc = @import("jsonrpc.zig");
const builtin = @import("builtin");

// Only import net.zig when not targeting WebAssembly
const is_wasm = builtin.cpu.arch.isWasm();
const net = if (!is_wasm) @import("net.zig") else struct {};

/// MCP Protocol Constants
pub const PROTOCOL_VERSION = "0.4.0";

/// Tool handler function type
/// Now uses context instead of allocator for memory management
pub const ToolHandlerFn = *const fn (ctx: *jsonrpc.Context, params: std.json.Value) anyerror!std.json.Value;

/// MCP Tool definition
pub const Tool = struct {
    /// Tool name - stored in static memory
    name: []const u8,
    /// Tool description - stored in static memory
    description: []const u8,
    /// Tool handler function
    handler: ToolHandlerFn,
    /// Optional parameters schema (JSON Schema) - should be stored in static memory
    parameters: ?std.json.Value = null,
};

/// Transport type
pub const TransportType = if (is_wasm)
    enum {
        /// When compiling for WebAssembly, only stdio transport is available
        stdio,
    }
else
    enum {
        stdio,
        http,
    };

/// MCP Server settings
pub const Settings = if (is_wasm) struct {
    /// Transport type - only stdio available in WebAssembly
    transport: TransportType = .stdio,
    /// Array of tools - stored in static memory
    tools: []const Tool = &[_]Tool{},
} else struct {
    /// Transport type
    transport: TransportType = .stdio,
    /// Host for HTTP transport - stored in static memory
    host: []const u8 = "127.0.0.1",
    /// Port for HTTP transport
    port: u16 = 7777,
    /// Array of tools - stored in static memory
    tools: []const Tool = &[_]Tool{},
    /// Maximum number of concurrent connections (for HTTP transport)
    max_connections: ?usize = null,
    /// Number of worker threads (for HTTP transport)
    /// If null, will use the number of CPU cores
    thread_count: ?usize = null,
    /// Connection timeout in milliseconds (for HTTP transport)
    /// If 0, no timeout is applied
    connection_timeout_ms: u32 = 30000,
    /// TCP backlog size for the listening socket (for HTTP transport)
    backlog_size: ?u32 = null,
    /// Run HTTP server in non-blocking mode
    /// This starts a separate thread for accepting connections, allowing
    /// the main thread to continue execution.
    non_blocking_http: bool = false,
};

/// MCP Server state
pub const ServerState = enum {
    created,
    initializing,
    ready,
    error_state,
    shutdown,
};

/// MCP Server implementation
pub const Server = struct {
    /// Parent allocator for general allocations
    parent_allocator: std.mem.Allocator,
    /// Server settings
    settings: Settings,
    /// Current server state
    state: ServerState,
    /// Map of registered tools
    tools: std.StringHashMap(Tool),
    /// HTTP server (if using HTTP transport) - only available on non-WebAssembly targets
    http_server: if (!is_wasm) ?net.HttpServer else void,
    /// A context arena for the current request-response cycle
    request_context: jsonrpc.Context,

    pub fn init(allocator: std.mem.Allocator, settings: Settings) !Server {
        var tools = std.StringHashMap(Tool).init(allocator);

        // Register all tools
        for (settings.tools) |tool| {
            try tools.put(tool.name, tool);
        }

        if (is_wasm) {
            // WebAssembly version - no HTTP support
            return Server{
                .parent_allocator = allocator,
                .settings = settings,
                .state = .created,
                .tools = tools,
                .http_server = {}, // void value for WebAssembly
                .request_context = jsonrpc.Context.init(allocator),
            };
        } else {
            // Native version with HTTP support
            return Server{
                .parent_allocator = allocator,
                .settings = settings,
                .state = .created,
                .tools = tools,
                .http_server = null,
                .request_context = jsonrpc.Context.init(allocator),
            };
        }
    }

    /// Explicitly request server shutdown
    /// This will initiate a graceful shutdown process
    pub fn shutdown(self: *Server) void {
        if (!is_wasm) {
            // Only try to shutdown HTTP server on non-WebAssembly platforms
            if (self.http_server) |*http_server| {
                http_server.shutdown();
            }
        }
        self.state = .shutdown;
    }

    pub fn deinit(self: *Server) void {
        // Ensure server is shut down before cleanup
        if (self.state != .shutdown) {
            self.shutdown();
        }

        // Cleanup server resources
        if (!is_wasm) {
            // Only try to deinit HTTP server on non-WebAssembly platforms
            if (self.http_server) |*http_server| {
                http_server.deinit();
            }
        }

        self.tools.deinit();
        self.request_context.deinit();
    }

    pub fn start(self: *Server) !void {
        if (is_wasm) {
            // In WebAssembly, we only support stdio transport
            try self.startStdioTransport();
        } else {
            // On other platforms, both transports are available
            switch (self.settings.transport) {
                .stdio => try self.startStdioTransport(),
                .http => try self.startHttpTransport(),
            }
        }
    }

    fn startStdioTransport(self: *Server) !void {
        const stdin = std.io.getStdIn().reader();
        const stdout = std.io.getStdOut().writer();

        self.state = .ready;

        while (self.state != .shutdown) {
            var buffer: [4096]u8 = undefined;
            const bytes_read = try stdin.read(&buffer);
            if (bytes_read == 0) {
                // EOF, exit
                break;
            }

            const message = buffer[0..bytes_read];
            const response = try self.handleRequest(message);
            if (response.len > 0) {
                try stdout.writeAll(response);
                try stdout.writeAll("\n");
            }

            // Reset the request context for the next iteration
            self.request_context.reset();
        }
    }

    fn startHttpTransport(self: *Server) !void {
        // HTTP transport is not available in WebAssembly
        if (is_wasm) {
            return error.HttpTransportNotAvailableInWebAssembly;
        } else {
            // Initialize the HTTP server with thread pool and connection limiting
            var http_server = try net.HttpServer.init(self.parent_allocator, self.settings.host, self.settings.port, self.settings.thread_count, // Use the configured thread count or detect CPU cores
                self.settings.max_connections, // Use the configured max connections or default
                self.settings.connection_timeout_ms, // Connection timeout in milliseconds
                self.settings.backlog_size // TCP backlog size
            );
            self.http_server = http_server;
            self.state = .ready;

            // Store server instance for the HTTP handler
            g_server = self;

            // Start the HTTP server in non-blocking mode if specified
            if (self.settings.non_blocking_http) {
                try http_server.startListening(handleHttpConnection);
            } else {
                try http_server.listen(handleHttpConnection);
            }
        }
    }

    // HTTP connection handler functions are only available on non-WebAssembly platforms
    fn handleHttpConnection(conn: *net.Connection) !void {
        if (is_wasm) {
            return error.HttpHandlerNotAvailableInWebAssembly;
        } else {
            // Use errdefer to ensure conn is closed only on error paths
            // The normal path will close when the connectionJob is cleaned up
            errdefer {
                if (!conn.is_closed) {
                    conn.deinit();
                }
            }

            var request = try conn.parseRequest();
            defer request.deinit();

            // Health check endpoint
            if (std.mem.eql(u8, request.method, "GET") and std.mem.eql(u8, request.path, "/health")) {
                // Simple static health response
                const health_response = "{\"status\":\"healthy\",\"server\":\"zig-mcp\"}";
                try conn.sendResponse(200, "application/json", health_response);
                return;
            }

            // Only handle POST requests to /jsonrpc for API
            if (!std.mem.eql(u8, request.method, "POST") or !std.mem.eql(u8, request.path, "/jsonrpc")) {
                try conn.sendResponse(404, "text/plain", "Not Found");
                return;
            }

            // Get server instance from the global pointer
            const server = g_server;

            // Process the JSON-RPC request
            const response = try server.handleRequest(request.body);

            // Send the response
            try conn.sendResponse(200, "application/json", response);

            // Reset the request context for the next request
            server.request_context.reset();
        }
    }

    // Global server pointer for the HTTP handler - only used in non-WebAssembly platforms
    var g_server: if (!is_wasm) *Server else void = if (!is_wasm) undefined else {};

    pub fn handleRequest(self: *Server, request_str: []const u8) ![]const u8 {
        // Parse the JSON-RPC request
        const request = jsonrpc.parseMessage(&self.request_context, request_str) catch |err| {
            std.debug.print("Error parsing request: {}\n", .{err});
            const error_response = try jsonrpc.createErrorResponse(&self.request_context, std.json.Value{ .null = {} }, .parseError, "Parse error");
            return try jsonrpc.stringifyValue(self.request_context.allocator(), error_response);
        };

        // Validate the JSON-RPC request
        jsonrpc.validateMessage(request) catch |err| {
            std.debug.print("Invalid request: {}\n", .{err});
            const error_response = try jsonrpc.createErrorResponse(&self.request_context, request.object.get("id") orelse std.json.Value{ .null = {} }, .invalidRequest, "Invalid Request");
            return try jsonrpc.stringifyValue(self.request_context.allocator(), error_response);
        };

        // Extract method and params
        const method = request.object.get("method") orelse {
            const error_response = try jsonrpc.createErrorResponse(&self.request_context, request.object.get("id") orelse std.json.Value{ .null = {} }, .invalidRequest, "Method not specified");
            return try jsonrpc.stringifyValue(self.request_context.allocator(), error_response);
        };

        if (method != .string) {
            const error_response = try jsonrpc.createErrorResponse(&self.request_context, request.object.get("id") orelse std.json.Value{ .null = {} }, .invalidRequest, "Method must be a string");
            return try jsonrpc.stringifyValue(self.request_context.allocator(), error_response);
        }

        const params = request.object.get("params") orelse std.json.Value{ .object = std.json.ObjectMap.init(self.request_context.allocator()) };

        // Check if this is an initialization request
        if (std.mem.eql(u8, method.string, "initialize")) {
            return try self.handleInitialize(request);
        }

        // Check if server is initialized
        if (self.state != .ready) {
            const error_response = try jsonrpc.createErrorResponse(&self.request_context, request.object.get("id") orelse std.json.Value{ .null = {} }, .serverNotInitialized, "Server not initialized");
            return try jsonrpc.stringifyValue(self.request_context.allocator(), error_response);
        }

        // Handle initialized notification
        if (std.mem.eql(u8, method.string, "initialized")) {
            // Just acknowledge, no response needed for notifications
            return &[_]u8{};
        }

        // Handle shutdown request
        if (std.mem.eql(u8, method.string, "shutdown")) {
            self.state = .shutdown;
            const response = try jsonrpc.createSuccessResponse(&self.request_context, request.object.get("id") orelse std.json.Value{ .null = {} }, std.json.Value{ .null = {} });
            return try jsonrpc.stringifyValue(self.request_context.allocator(), response);
        }

        // Parse mcp/tools/invoke methods
        if (std.mem.startsWith(u8, method.string, "mcp/tools/")) {
            const tool_method = method.string["mcp/tools/".len..];

            if (std.mem.eql(u8, tool_method, "list")) {
                return try self.handleToolsList(request);
            } else if (std.mem.eql(u8, tool_method, "invoke")) {
                return try self.handleToolInvoke(request, params);
            }
        }

        // Method not found
        const error_response = try jsonrpc.createErrorResponse(&self.request_context, request.object.get("id") orelse std.json.Value{ .null = {} }, .methodNotFound, "Method not found");
        return try jsonrpc.stringifyValue(self.request_context.allocator(), error_response);
    }

    fn handleInitialize(self: *Server, request: std.json.Value) ![]const u8 {
        self.state = .initializing;

        // Extract client capabilities from params
        const params = request.object.get("params") orelse {
            const error_response = try jsonrpc.createErrorResponse(&self.request_context, request.object.get("id") orelse std.json.Value{ .null = {} }, .invalidParams, "Params missing in initialize request");
            return try jsonrpc.stringifyValue(self.request_context.allocator(), error_response);
        };

        // Check protocol version (optional)
        if (params.object.get("protocolVersion")) |version| {
            if (version != .string or !std.mem.eql(u8, version.string, PROTOCOL_VERSION)) {
                const error_response = try jsonrpc.createErrorResponse(&self.request_context, request.object.get("id") orelse std.json.Value{ .null = {} }, .unknownProtocolVersion, "Unsupported protocol version");
                return try jsonrpc.stringifyValue(self.request_context.allocator(), error_response);
            }
        }

        // Create server capabilities
        var capabilities = std.json.Value{ .object = std.json.ObjectMap.init(self.request_context.allocator()) };
        try capabilities.object.put("protocolVersion", std.json.Value{ .string = try self.request_context.allocator().dupe(u8, PROTOCOL_VERSION) });

        // Add tools capability
        var tools_capability = std.json.Value{ .object = std.json.ObjectMap.init(self.request_context.allocator()) };
        try tools_capability.object.put("enabled", std.json.Value{ .bool = true });
        try capabilities.object.put("tools", tools_capability);

        // Create response
        var result = std.json.Value{ .object = std.json.ObjectMap.init(self.request_context.allocator()) };
        try result.object.put("capabilities", capabilities);
        try result.object.put("serverInfo", try createServerInfo(&self.request_context));

        const response = try jsonrpc.createSuccessResponse(&self.request_context, request.object.get("id") orelse std.json.Value{ .null = {} }, result);

        self.state = .ready;
        return try jsonrpc.stringifyValue(self.request_context.allocator(), response);
    }

    fn handleToolsList(self: *Server, request: std.json.Value) ![]const u8 {
        var tools_array = std.json.Value{ .array = std.json.Array.init(self.request_context.allocator()) };

        var tools_iter = self.tools.iterator();
        while (tools_iter.next()) |tool_entry| {
            const tool = tool_entry.value_ptr.*;
            var tool_obj = std.json.Value{ .object = std.json.ObjectMap.init(self.request_context.allocator()) };

            try tool_obj.object.put("name", std.json.Value{ .string = try self.request_context.allocator().dupe(u8, tool.name) });
            try tool_obj.object.put("description", std.json.Value{ .string = try self.request_context.allocator().dupe(u8, tool.description) });

            if (tool.parameters) |params| {
                // If parameters schema is provided, we need to clone it
                // into our arena allocator since it's in static memory
                const cloned = try cloneJsonValue(self.request_context.allocator(), params);
                try tool_obj.object.put("parameters", cloned);
            }

            try tools_array.array.append(tool_obj);
        }

        var result = std.json.Value{ .object = std.json.ObjectMap.init(self.request_context.allocator()) };
        try result.object.put("tools", tools_array);

        const response = try jsonrpc.createSuccessResponse(&self.request_context, request.object.get("id") orelse std.json.Value{ .null = {} }, result);

        return try jsonrpc.stringifyValue(self.request_context.allocator(), response);
    }

    fn handleToolInvoke(self: *Server, request: std.json.Value, params: std.json.Value) ![]const u8 {
        if (params != .object) {
            const error_response = try jsonrpc.createErrorResponse(&self.request_context, request.object.get("id") orelse std.json.Value{ .null = {} }, .invalidParams, "Params must be an object");
            return try jsonrpc.stringifyValue(self.request_context.allocator(), error_response);
        }

        // Extract tool name and params
        const name_value = params.object.get("name") orelse {
            const error_response = try jsonrpc.createErrorResponse(&self.request_context, request.object.get("id") orelse std.json.Value{ .null = {} }, .invalidParams, "Tool name missing");
            return try jsonrpc.stringifyValue(self.request_context.allocator(), error_response);
        };

        if (name_value != .string) {
            const error_response = try jsonrpc.createErrorResponse(&self.request_context, request.object.get("id") orelse std.json.Value{ .null = {} }, .invalidParams, "Tool name must be a string");
            return try jsonrpc.stringifyValue(self.request_context.allocator(), error_response);
        }

        const tool_params = params.object.get("params") orelse std.json.Value{ .object = std.json.ObjectMap.init(self.request_context.allocator()) };

        // Find the tool
        const tool = self.tools.get(name_value.string) orelse {
            const error_response = try jsonrpc.createErrorResponse(&self.request_context, request.object.get("id") orelse std.json.Value{ .null = {} }, .methodNotFound, "Tool not found");
            return try jsonrpc.stringifyValue(self.request_context.allocator(), error_response);
        };

        // Invoke the tool handler
        const result = tool.handler(&self.request_context, tool_params) catch |err| {
            std.debug.print("Error invoking tool: {}\n", .{err});
            const error_response = try jsonrpc.createErrorResponse(&self.request_context, request.object.get("id") orelse std.json.Value{ .null = {} }, .requestFailed, "Tool execution failed");
            return try jsonrpc.stringifyValue(self.request_context.allocator(), error_response);
        };

        const response = try jsonrpc.createSuccessResponse(&self.request_context, request.object.get("id") orelse std.json.Value{ .null = {} }, result);

        return try jsonrpc.stringifyValue(self.request_context.allocator(), response);
    }
};

/// Create server info object
fn createServerInfo(ctx: *jsonrpc.Context) !std.json.Value {
    const allocator = ctx.allocator();

    var server_info = std.json.Value{ .object = std.json.ObjectMap.init(allocator) };
    try server_info.object.put("name", std.json.Value{ .string = try allocator.dupe(u8, "zig-mcp") });
    try server_info.object.put("version", std.json.Value{ .string = try allocator.dupe(u8, "0.1.0") });
    return server_info;
}

/// Clone a JSON value using the given allocator
pub fn cloneJsonValue(allocator: std.mem.Allocator, value: std.json.Value) !std.json.Value {
    return switch (value) {
        .null, .bool, .integer, .float => value,
        .number_string => |s| std.json.Value{ .number_string = try allocator.dupe(u8, s) },
        .string => |s| std.json.Value{ .string = try allocator.dupe(u8, s) },
        .array => |a| blk: {
            var new_array = std.json.Array.init(allocator);
            errdefer new_array.deinit();

            try new_array.ensureTotalCapacity(a.items.len);
            for (a.items) |item| {
                try new_array.append(try cloneJsonValue(allocator, item));
            }

            break :blk std.json.Value{ .array = new_array };
        },
        .object => |o| blk: {
            var new_object = std.json.ObjectMap.init(allocator);
            errdefer {
                var iter = new_object.iterator();
                while (iter.next()) |entry| {
                    allocator.free(entry.key_ptr.*);
                }
                new_object.deinit();
            }

            var iter = o.iterator();
            while (iter.next()) |entry| {
                try new_object.put(try allocator.dupe(u8, entry.key_ptr.*), try cloneJsonValue(allocator, entry.value_ptr.*));
            }

            break :blk std.json.Value{ .object = new_object };
        },
    };
}

```

`src/mcp_test.zig`:

```zig
const std = @import("std");
const testing = std.testing;
const mcp = @import("mcp.zig");
const jsonrpc = @import("jsonrpc.zig");

// Test tool handlers
fn testEchoHandler(allocator: std.mem.Allocator, params: std.json.Value) !std.json.Value {
    _ = allocator;
    return params;
}

fn testReverseHandler(allocator: std.mem.Allocator, params: std.json.Value) !std.json.Value {
    // Check if params has a "text" field
    const text_value = params.object.get("text") orelse {
        return jsonrpc.Error.invalidParams;
    };

    if (text_value != .string) {
        return jsonrpc.Error.invalidParams;
    }

    const text = text_value.string;

    // Allocate buffer for the reversed string
    var reversed = try allocator.alloc(u8, text.len);
    defer allocator.free(reversed);

    // Reverse the string
    for (text, 0..) |char, i| {
        reversed[text.len - 1 - i] = char;
    }

    // Create response object
    var result = std.json.Value{ .object = std.json.ObjectMap.init(allocator) };
    try result.object.put("reversed", std.json.Value{ .string = try allocator.dupe(u8, reversed) });

    return result;
}

test "MCP Server Initialization" {
    // Create a test allocator
    var arena = std.heap.ArenaAllocator.init(testing.allocator);
    defer arena.deinit();
    const allocator = arena.allocator();

    // Create MCP server
    var server = try mcp.Server.init(allocator, .{
        .tools = &[_]mcp.Tool{
            .{
                .name = "test_echo",
                .description = "Test echo tool",
                .handler = &testEchoHandler,
            },
            .{
                .name = "test_reverse",
                .description = "Test reverse tool",
                .handler = &testReverseHandler,
            },
        },
    });

    // Initialize the array element to an invalid value first
    // Fix for Zig 0.14 compiler - to avoid uninitialized memory errors
    mcp.g_server = undefined;
    defer server.deinit();

    // Test initialization with a valid request
    const init_request =
        \\ {
        \\   "jsonrpc": "2.0",
        \\   "id": 1,
        \\   "method": "initialize",
        \\   "params": {
        \\     "protocolVersion": "0.4.0",
        \\     "capabilities": {
        \\       "tools": {
        \\         "enabled": true
        \\       }
        \\     }
        \\   }
        \\ }
    ;

    const init_response = try server.handleRequest(init_request);
    const init_response_parsed = try std.json.parseFromSlice(std.json.Value, allocator, init_response, .{});

    try testing.expectEqual(std.json.Value.Tag.object, init_response_parsed.value.tag);
    try testing.expect(init_response_parsed.value.object.contains("result"));

    const result = init_response_parsed.value.object.get("result").?;
    try testing.expectEqual(std.json.Value.Tag.object, result.tag);
    try testing.expect(result.object.contains("capabilities"));
    try testing.expect(result.object.contains("serverInfo"));

    const capabilities = result.object.get("capabilities").?;
    try testing.expectEqual(std.json.Value.Tag.object, capabilities.tag);
    try testing.expect(capabilities.object.contains("protocolVersion"));
    try testing.expect(capabilities.object.contains("tools"));

    const protocol_version = capabilities.object.get("protocolVersion").?;
    try testing.expectEqual(std.json.Value.Tag.string, protocol_version.tag);
    try testing.expectEqualStrings(mcp.PROTOCOL_VERSION, protocol_version.string);
}

test "MCP Server Tools" {
    // Create a test allocator
    var arena = std.heap.ArenaAllocator.init(testing.allocator);
    defer arena.deinit();
    const allocator = arena.allocator();

    // Create MCP server
    var server = try mcp.Server.init(allocator, .{
        .tools = &[_]mcp.Tool{
            .{
                .name = "test_echo",
                .description = "Test echo tool",
                .handler = &testEchoHandler,
            },
            .{
                .name = "test_reverse",
                .description = "Test reverse tool",
                .handler = &testReverseHandler,
            },
        },
    });

    // Initialize the array element to an invalid value first
    // Fix for Zig 0.14 compiler - to avoid uninitialized memory errors
    mcp.g_server = undefined;
    defer server.deinit();

    // Initialize the server first
    const init_request =
        \\ {
        \\   "jsonrpc": "2.0",
        \\   "id": 1,
        \\   "method": "initialize",
        \\   "params": {
        \\     "protocolVersion": "0.4.0",
        \\     "capabilities": {
        \\       "tools": {
        \\         "enabled": true
        \\       }
        \\     }
        \\   }
        \\ }
    ;

    _ = try server.handleRequest(init_request);

    // Send initialized notification
    const initialized_request =
        \\ {
        \\   "jsonrpc": "2.0",
        \\   "method": "initialized"
        \\ }
    ;

    _ = try server.handleRequest(initialized_request);

    // Test listing tools
    const list_tools_request =
        \\ {
        \\   "jsonrpc": "2.0",
        \\   "id": 2,
        \\   "method": "mcp/tools/list"
        \\ }
    ;

    const list_tools_response = try server.handleRequest(list_tools_request);
    const list_tools_parsed = try std.json.parseFromSlice(std.json.Value, allocator, list_tools_response, .{});

    try testing.expectEqual(std.json.Value.Tag.object, list_tools_parsed.value.tag);
    try testing.expect(list_tools_parsed.value.object.contains("result"));

    const list_result = list_tools_parsed.value.object.get("result").?;
    try testing.expectEqual(std.json.Value.Tag.object, list_result.tag);
    try testing.expect(list_result.object.contains("tools"));

    const tools = list_result.object.get("tools").?;
    try testing.expectEqual(std.json.Value.Tag.array, tools.tag);
    try testing.expectEqual(@as(usize, 2), tools.array.items.len);

    // Test invoking the echo tool
    const invoke_echo_request =
        \\ {
        \\   "jsonrpc": "2.0",
        \\   "id": 3,
        \\   "method": "mcp/tools/invoke",
        \\   "params": {
        \\     "name": "test_echo",
        \\     "params": {
        \\       "message": "Hello, MCP!"
        \\     }
        \\   }
        \\ }
    ;

    const invoke_echo_response = try server.handleRequest(invoke_echo_request);
    const invoke_echo_parsed = try std.json.parseFromSlice(std.json.Value, allocator, invoke_echo_response, .{});

    try testing.expectEqual(std.json.Value.Tag.object, invoke_echo_parsed.value.tag);
    try testing.expect(invoke_echo_parsed.value.object.contains("result"));

    const echo_result = invoke_echo_parsed.value.object.get("result").?;
    try testing.expectEqual(std.json.Value.Tag.object, echo_result.tag);
    try testing.expect(echo_result.object.contains("message"));

    const message = echo_result.object.get("message").?;
    try testing.expectEqual(std.json.Value.Tag.string, message.tag);
    try testing.expectEqualStrings("Hello, MCP!", message.string);

    // Test invoking the reverse tool
    const invoke_reverse_request =
        \\ {
        \\   "jsonrpc": "2.0",
        \\   "id": 4,
        \\   "method": "mcp/tools/invoke",
        \\   "params": {
        \\     "name": "test_reverse",
        \\     "params": {
        \\       "text": "Hello, MCP!"
        \\     }
        \\   }
        \\ }
    ;

    const invoke_reverse_response = try server.handleRequest(invoke_reverse_request);
    const invoke_reverse_parsed = try std.json.parseFromSlice(std.json.Value, allocator, invoke_reverse_response, .{});

    try testing.expectEqual(std.json.Value.Tag.object, invoke_reverse_parsed.value.tag);
    try testing.expect(invoke_reverse_parsed.value.object.contains("result"));

    const reverse_result = invoke_reverse_parsed.value.object.get("result").?;
    try testing.expectEqual(std.json.Value.Tag.object, reverse_result.tag);
    try testing.expect(reverse_result.object.contains("reversed"));

    const reversed = reverse_result.object.get("reversed").?;
    try testing.expectEqual(std.json.Value.Tag.string, reversed.tag);
    try testing.expectEqualStrings("!PCM ,olleH", reversed.string);
}

```

`src/net.zig`:

```zig
const std = @import("std");

/// HTTP Server implementation
/// Server metrics struct for tracking statistics
pub const ServerMetrics = struct {
    // Import atomic ordering constants for easier reference
    const Ordering = std.builtin.AtomicOrder;

    // Total connections since server start
    total_connections: std.atomic.Value(u64),
    // Total requests processed successfully
    total_requests: std.atomic.Value(u64),
    // Failed requests (e.g., parse errors, handler errors)
    failed_requests: std.atomic.Value(u64),
    // Connections rejected due to connection limit
    rejected_connections: std.atomic.Value(u64),
    // Total bytes received
    bytes_received: std.atomic.Value(u64),
    // Total bytes sent
    bytes_sent: std.atomic.Value(u64),
    // Timeouts that occurred
    timeouts: std.atomic.Value(u64),
    // Server start time for uptime calculation
    start_time: i64,

    /// Initialize server metrics with zero values
    pub fn init() ServerMetrics {
        return ServerMetrics{
            .total_connections = std.atomic.Value(u64).init(0),
            .total_requests = std.atomic.Value(u64).init(0),
            .failed_requests = std.atomic.Value(u64).init(0),
            .rejected_connections = std.atomic.Value(u64).init(0),
            .bytes_received = std.atomic.Value(u64).init(0),
            .bytes_sent = std.atomic.Value(u64).init(0),
            .timeouts = std.atomic.Value(u64).init(0),
            .start_time = std.time.milliTimestamp(),
        };
    }

    /// Get server uptime in milliseconds
    pub fn getUptime(self: *ServerMetrics) i64 {
        const now = std.time.milliTimestamp();
        return now - self.start_time;
    }

    /// Report server metrics as a formatted string
    pub fn report(self: *ServerMetrics, allocator: std.mem.Allocator) ![]const u8 {
        const uptime_ms = self.getUptime();
        const uptime_s = @as(f64, @floatFromInt(uptime_ms)) / 1000.0;

        return try std.fmt.allocPrint(allocator,
            \\Server Metrics:
            \\  Uptime: {d:.2} seconds
            \\  Total Connections: {}
            \\  Current Active Connections: {}
            \\  Total Requests: {}
            \\  Failed Requests: {}
            \\  Rejected Connections: {}
            \\  Timeouts: {}
            \\  Data Received: {} bytes
            \\  Data Sent: {} bytes
            \\
        , .{
            uptime_s,
            self.total_connections.load(Ordering.monotonic),
            self.total_connections.load(Ordering.monotonic) - self.total_requests.load(Ordering.monotonic),
            self.total_requests.load(Ordering.monotonic),
            self.failed_requests.load(Ordering.monotonic),
            self.rejected_connections.load(Ordering.monotonic),
            self.timeouts.load(Ordering.monotonic),
            self.bytes_received.load(Ordering.monotonic),
            self.bytes_sent.load(Ordering.monotonic),
        });
    }
};

pub const HttpServer = struct {
    // Import atomic ordering constants for easier reference
    const Ordering = std.builtin.AtomicOrder;

    // Define ListenContext struct here so it's accessible throughout HttpServer
    const ListenContext = struct {
        server: *HttpServer,
        handler: *const fn (*Connection) anyerror!void,
    };

    allocator: std.mem.Allocator,
    address: std.net.Address,
    server: std.net.Server,
    thread_pool: ?*ThreadPool,
    max_connections: usize,
    num_threads: usize,
    connection_timeout_ms: u32,
    // Graceful shutdown controls
    shutdown_requested: std.atomic.Value(bool),
    listen_thread: ?std.Thread,
    listen_context: ?*ListenContext, // Store the listen context for proper cleanup
    backlog_size: u32,
    // Server metrics
    metrics: ServerMetrics,
    // Use a simpler approach - just reuse the existing server instance
    // but set this flag to prevent more accept() calls
    server_closed: bool = false,

    /// Initialize a new HTTP server
    /// - host: The hostname to listen on
    /// - port: The port to listen on
    /// - num_threads: Number of worker threads (defaults to number of CPU cores)
    /// - max_connections: Maximum number of concurrent connections (defaults to 100)
    /// - connection_timeout_ms: Timeout for individual connections in milliseconds (defaults to 30000, 0 = no timeout)
    /// - backlog_size: TCP connection backlog size (defaults to 128)
    pub fn init(allocator: std.mem.Allocator, host: []const u8, port: u16, num_threads: ?usize, max_connections: ?usize, connection_timeout_ms: ?u32, backlog_size: ?u32) !HttpServer {
        const address = try std.net.Address.resolveIp(host, port);
        // Note: backlog_size is currently ignored as the Zig std lib in this version
        // doesn't support setting the backlog size directly. It will use the default.
        const server = try address.listen(.{
            .reuse_address = true,
        });

        // Default to number of logical CPU cores if thread count not specified
        const actual_num_threads = num_threads orelse @max(1, std.Thread.getCpuCount() catch 4);

        // Default to 100 max connections if not specified
        const actual_max_connections = max_connections orelse 100;

        // Default to 30 seconds timeout if not specified
        const actual_timeout_ms = connection_timeout_ms orelse 30000;

        return HttpServer{
            .allocator = allocator,
            .address = address,
            .server = server,
            .thread_pool = null,
            .max_connections = actual_max_connections,
            .num_threads = actual_num_threads,
            .connection_timeout_ms = actual_timeout_ms,
            .shutdown_requested = std.atomic.Value(bool).init(false),
            .listen_thread = null,
            .listen_context = null,
            .backlog_size = backlog_size orelse 128,
            .metrics = ServerMetrics.init(),
        };
    }

    pub fn deinit(self: *HttpServer) void {
        std.debug.print("HttpServer.deinit() called\n", .{});

        // Signal graceful shutdown
        self.shutdown();
        std.debug.print("Graceful shutdown initiated\n", .{});

        // Wait for listen thread to complete if it was started
        if (self.listen_thread) |thread| {
            std.debug.print("Waiting for listen thread to complete\n", .{});
            thread.join();
            std.debug.print("Listen thread completed\n", .{});
        }

        // Clean up listen context
        if (self.listen_context) |listen_ctx| {
            std.debug.print("Freeing listen context at {*}\n", .{listen_ctx});
            self.allocator.destroy(listen_ctx);
            self.listen_context = null;
        } else {
            std.debug.print("No listen context to free\n", .{});
        }

        // Clean up thread pool
        if (self.thread_pool) |thread_pool| {
            std.debug.print("Cleaning up thread pool at {*}\n", .{thread_pool});
            // Free thread_pool memory - this will call ThreadPool.deinit() method
            thread_pool.deinit();
            // thread_pool instance was heap-allocated in startListening, so we need to free it
            self.allocator.destroy(thread_pool);
            self.thread_pool = null;
        } else {
            std.debug.print("No thread pool to clean up\n", .{});
        }

        // Now it's safe to fully close the server
        if (!self.server_closed) {
            std.debug.print("Closing server socket\n", .{});
            self.server.deinit();
        } else {
            std.debug.print("Server socket was already marked as closed\n", .{});
        }
        std.debug.print("HttpServer.deinit() complete\n", .{});
    }

    /// Request a graceful shutdown of the server
    /// This will stop accepting new connections but let existing ones complete
    pub fn shutdown(self: *HttpServer) void {
        std.debug.print("HttpServer.shutdown() called\n", .{});

        // Set shutdown flag
        self.shutdown_requested.store(true, Ordering.monotonic);

        // Mark server as closed but don't actually close it to avoid the unreachable panic
        self.server_closed = true;
        std.debug.print("Server marked as closed\n", .{});

        // If we have a thread pool, wake it up for quicker shutdown
        if (self.thread_pool) |thread_pool| {
            // Signal all threads to shut down
            thread_pool.shutdown.store(true, Ordering.monotonic);

            // Wake up all worker threads
            for (0..thread_pool.threads.len) |_| {
                thread_pool.jobs.signal.post();
            }
            std.debug.print("Worker threads signaled to shut down\n", .{});
        }

        std.debug.print("HttpServer.shutdown() complete\n", .{});
    }

    /// Set the maximum number of concurrent connections
    pub fn setMaxConnections(self: *HttpServer, max_connections: usize) void {
        self.max_connections = max_connections;
        if (self.thread_pool) |thread_pool| {
            thread_pool.setMaxConnections(max_connections);
        }
    }

    /// Get the current number of active connections
    pub fn getCurrentConnections(self: *HttpServer) usize {
        if (self.thread_pool) |thread_pool| {
            return thread_pool.getCurrentConnections();
        }
        return 0;
    }

    /// Set the connection timeout in milliseconds
    /// A value of 0 means no timeout.
    pub fn setConnectionTimeout(self: *HttpServer, timeout_ms: u32) void {
        self.connection_timeout_ms = timeout_ms;
    }

    /// Get server metrics
    pub fn getMetrics(self: *HttpServer) *ServerMetrics {
        return &self.metrics;
    }

    /// Get formatted server metrics report
    pub fn getMetricsReport(self: *HttpServer) ![]const u8 {
        return try self.metrics.report(self.allocator);
    }

    /// Start listening for incoming connections and handle them with the provided handler function
    /// Returns immediately after starting the listener thread
    pub fn startListening(self: *HttpServer, handler: *const fn (*Connection) anyerror!void) !void {
        // Initialize the thread pool if not already done
        if (self.thread_pool == null) {
            self.thread_pool = try ThreadPool.init(self.allocator, self.num_threads, self.max_connections);
        }

        // Create listen context for the thread
        const listen_ctx = try self.allocator.create(ListenContext);
        errdefer self.allocator.destroy(listen_ctx);

        listen_ctx.* = .{
            .server = self,
            .handler = handler,
        };

        // Store the context for cleanup in deinit
        self.listen_context = listen_ctx;

        // Start a dedicated thread for accepting connections
        self.listen_thread = try std.Thread.spawn(.{}, struct {
            fn run(ctx: *ListenContext) void {
                // Debug output to verify context is being used
                std.debug.print("Listen thread started with context at {*}\n", .{ctx});

                listenThread(ctx.server, ctx.handler) catch |err| {
                    if (err != error.ShutdownRequested) {
                        std.debug.print("Listen thread error: {}\n", .{err});
                    }
                };
                // Note: we don't destroy ctx here anymore - it's handled in HttpServer.deinit
                std.debug.print("Listen thread exiting\n", .{});
            }
        }.run, .{listen_ctx});

        std.debug.print("HTTP server listening on {}, max connections: {}, thread count: {}, backlog: {}\n", .{ self.address, self.max_connections, self.num_threads, self.backlog_size });
        std.debug.print("Stored listen context at {*}\n", .{self.listen_context.?});
    }

    /// Run the listening loop in a separate thread
    /// This allows for graceful shutdown when needed
    fn listenThread(self: *HttpServer, handler: *const fn (*Connection) anyerror!void) !void {
        const thread_pool = self.thread_pool.?;
        std.debug.print("Listen thread main loop starting\n", .{});

        while (!self.shutdown_requested.load(Ordering.monotonic) and !self.server_closed) {
            // Before trying to accept, check shutdown flags
            if (self.shutdown_requested.load(Ordering.monotonic) or self.server_closed) {
                std.debug.print("Shutdown detected at start of loop, exiting listen thread\n", .{});
                break;
            }

            // Use a simpler approach - just check the shutdown flag periodically
            // And sleep a short time to avoid tight loops
            std.time.sleep(100 * std.time.ns_per_ms);

            // Check if we should shut down
            if (self.shutdown_requested.load(Ordering.monotonic) or self.server_closed) {
                std.debug.print("Shutdown detected after sleep, exiting listen thread\n", .{});
                break;
            }

            // Accept a connection (should be non-blocking now)
            const conn = self.server.accept() catch |err| {
                std.debug.print("Error accepting connection: {}\n", .{err});

                // If shutdown was requested, break out of the loop gracefully
                if (self.shutdown_requested.load(Ordering.monotonic) or self.server_closed) {
                    std.debug.print("Shutdown detected during accept error, exiting listen thread\n", .{});
                    break;
                }

                // Add a small sleep to prevent tight loop in case of persistent errors
                std.time.sleep(10 * std.time.ns_per_ms);
                continue;
            };

            // Check shutdown flag again after potentially long accept call
            if (self.shutdown_requested.load(Ordering.monotonic) or self.server_closed) {
                std.debug.print("Shutdown detected after accept, closing connection\n", .{});
                // Close the socket safely without trying to use the connection struct
                // This avoids any double-close issues during shutdown
                conn.stream.close();
                break;
            }

            // Update total connections metric
            _ = self.metrics.total_connections.fetchAdd(1, Ordering.monotonic);

            // If at connection limit, reject the connection
            if (thread_pool.getCurrentConnections() >= self.max_connections) {
                std.debug.print("Connection limit reached, rejecting connection from {}\n", .{conn.address});
                _ = self.metrics.rejected_connections.fetchAdd(1, Ordering.monotonic);
                conn.stream.close();
                continue;
            }

            // Allocate a new Connection on the heap so it persists after this function
            var connection_ptr = self.allocator.create(Connection) catch |err| {
                std.debug.print("Error allocating connection: {}\n", .{err});
                conn.stream.close();
                continue;
            };

            connection_ptr.* = Connection{
                .allocator = self.allocator,
                .stream = conn.stream,
                .address = conn.address,
                .timeout_ms = self.connection_timeout_ms,
                .created_at = std.time.milliTimestamp(),
                .server_metrics = &self.metrics,
                .is_closed = false, // Explicitly mark as not closed
            };

            // Create a job for the connection
            var job = self.allocator.create(ConnectionJob) catch |err| {
                std.debug.print("Error creating job: {}\n", .{err});
                connection_ptr.deinit();
                self.allocator.destroy(connection_ptr);
                continue;
            };

            job.* = ConnectionJob.init(connection_ptr, handler);

            // Submit the job to the thread pool
            thread_pool.submit(&job.job) catch |err| {
                std.debug.print("Error submitting job: {}\n", .{err});
                connection_ptr.deinit();
                self.allocator.destroy(connection_ptr);
                self.allocator.destroy(job);
                continue;
            };
        }

        // If we get here, shutdown was requested
        return error.ShutdownRequested;
    }

    /// Listen for incoming connections and handle them with the provided handler function
    /// This is a blocking call that runs until a shutdown is requested
    pub fn listen(self: *HttpServer, handler: *const fn (*Connection) anyerror!void) !void {
        // Initialize the thread pool if not already done
        if (self.thread_pool == null) {
            self.thread_pool = try ThreadPool.init(self.allocator, self.num_threads, self.max_connections);
        }

        const thread_pool = self.thread_pool.?;

        std.debug.print("HTTP server listening on {}, max connections: {}, thread count: {}, backlog: {}\n", .{ self.address, self.max_connections, self.num_threads, self.backlog_size });

        // Note: In this version of Zig, we can't set non-blocking mode directly
        // We'll handle timeouts in a different way

        while (!self.shutdown_requested.load(Ordering.monotonic)) {
            // Accept a connection (blocking call)
            const conn = self.server.accept() catch |err| {
                std.debug.print("Error accepting connection: {}\n", .{err});
                // Add a small sleep to prevent tight loop in case of persistent errors
                std.time.sleep(10 * std.time.ns_per_ms);
                continue;
            };

            // Periodically check the shutdown flag
            if (self.shutdown_requested.load(Ordering.monotonic)) {
                conn.stream.close();
                break;
            }

            // Allocate a new Connection on the heap so it persists after this function
            var connection_ptr = self.allocator.create(Connection) catch |err| {
                std.debug.print("Error allocating connection: {}\n", .{err});
                conn.stream.close();
                continue;
            };

            connection_ptr.* = Connection{
                .allocator = self.allocator,
                .stream = conn.stream,
                .address = conn.address,
                .timeout_ms = self.connection_timeout_ms,
                .created_at = std.time.milliTimestamp(),
                .server_metrics = &self.metrics,
                .is_closed = false, // Explicitly mark as not closed
            };

            // Create a job for the connection
            var job = self.allocator.create(ConnectionJob) catch |err| {
                std.debug.print("Error creating job: {}\n", .{err});
                connection_ptr.deinit();
                self.allocator.destroy(connection_ptr);
                continue;
            };

            job.* = ConnectionJob.init(connection_ptr, handler);

            // Submit the job to the thread pool
            thread_pool.submit(&job.job) catch |err| {
                std.debug.print("Error submitting job: {}\n", .{err});
                connection_ptr.deinit();
                self.allocator.destroy(connection_ptr);
                self.allocator.destroy(job);
                continue;
            };
        }
    }
};

/// HTTP Connection
pub const Connection = struct {
    // Import atomic ordering constants for easier reference
    const Ordering = std.builtin.AtomicOrder;

    allocator: std.mem.Allocator,
    stream: std.net.Stream,
    address: std.net.Address,
    /// Connection timeout in milliseconds. If 0, no timeout is applied.
    timeout_ms: u32,
    /// Timestamp when the connection was created
    created_at: i64,
    /// Reference to server metrics for tracking
    server_metrics: ?*ServerMetrics = null,
    /// Whether this connection has already been closed
    is_closed: bool = false,

    pub fn deinit(self: *Connection) void {
        // When connection is closed, update metrics for completed request
        if (self.server_metrics) |metrics| {
            _ = metrics.total_requests.fetchAdd(1, Ordering.monotonic);
        }

        // Only close the stream if it hasn't been closed already
        if (!self.is_closed) {
            self.stream.close();
            self.is_closed = true;
        }
    }

    /// Returns whether the connection has timed out
    pub fn hasTimedOut(self: *Connection) bool {
        if (self.timeout_ms == 0) return false;

        const now = std.time.milliTimestamp();
        const elapsed = now - self.created_at;
        const is_timed_out = elapsed > self.timeout_ms;

        // Record timeout in metrics if it occurred
        if (is_timed_out) {
            if (self.server_metrics) |metrics| {
                _ = metrics.timeouts.fetchAdd(1, Ordering.monotonic);
            }
        }

        return is_timed_out;
    }

    pub fn read(self: *Connection, buffer: []u8) !usize {
        // Check if connection has timed out
        if (self.hasTimedOut()) {
            return error.ConnectionTimedOut;
        }

        // Check if connection is already closed
        if (self.is_closed) {
            return error.ConnectionClosed;
        }

        // For simplicity, we're relying on the global timeout mechanism
        // The OS will typically have its own timeout mechanisms for inactive connections
        const bytes_read = self.stream.read(buffer) catch |err| {
            // If we get a broken pipe or connection reset, mark as closed
            switch (err) {
                error.BrokenPipe, error.ConnectionResetByPeer => {
                    self.is_closed = true;
                    return err;
                },
                else => return err,
            }
        };

        // Record bytes received in metrics
        if (self.server_metrics) |metrics| {
            _ = metrics.bytes_received.fetchAdd(bytes_read, Ordering.monotonic);
        }

        return bytes_read;
    }

    pub fn write(self: *Connection, buffer: []const u8) !usize {
        // Check if connection has timed out
        if (self.hasTimedOut()) {
            return error.ConnectionTimedOut;
        }

        // Check if connection is already closed
        if (self.is_closed) {
            return error.ConnectionClosed;
        }

        // For simplicity, we're relying on the global timeout mechanism
        // The OS will typically have its own timeout mechanisms for inactive connections
        const bytes_written = self.stream.write(buffer) catch |err| {
            // If we get a broken pipe or connection reset, mark as closed
            switch (err) {
                error.BrokenPipe, error.ConnectionResetByPeer => {
                    self.is_closed = true;
                    return err;
                },
                else => return err,
            }
        };

        // Record bytes sent in metrics
        if (self.server_metrics) |metrics| {
            _ = metrics.bytes_sent.fetchAdd(bytes_written, Ordering.monotonic);
        }

        return bytes_written;
    }

    pub fn writeAll(self: *Connection, buffer: []const u8) !void {
        // Check if connection has timed out
        if (self.hasTimedOut()) {
            return error.ConnectionTimedOut;
        }

        // Check if connection is already closed
        if (self.is_closed) {
            return error.ConnectionClosed;
        }

        var remaining = buffer;
        while (remaining.len > 0) {
            const bytes_written = try self.write(remaining);
            remaining = remaining[bytes_written..];
        }
    }

    /// Track a failed request in metrics
    pub fn recordFailedRequest(self: *Connection) void {
        if (self.server_metrics) |metrics| {
            _ = metrics.failed_requests.fetchAdd(1, Ordering.monotonic);
        }
    }

    /// Send an HTTP response
    pub fn sendResponse(self: *Connection, status_code: u16, content_type: []const u8, body: []const u8) !void {
        // Use stack-allocated buffer for static strings where possible
        const status_message = switch (status_code) {
            200 => "OK",
            400 => "Bad Request",
            404 => "Not Found",
            500 => "Internal Server Error",
            else => "Unknown",
        };

        // Build status line
        var status_line_buf: [128]u8 = undefined;
        const status_line = try std.fmt.bufPrint(&status_line_buf, "HTTP/1.1 {d} {s}\r\n", .{ status_code, status_message });
        try self.writeAll(status_line);

        // Content-Type header
        try self.writeAll("Content-Type: ");
        try self.writeAll(content_type);
        try self.writeAll("\r\n");

        // Content-Length header
        var content_length_buf: [64]u8 = undefined;
        const content_length = try std.fmt.bufPrint(&content_length_buf, "Content-Length: {d}\r\n", .{body.len});
        try self.writeAll(content_length);

        // Connection header and end of headers
        try self.writeAll("Connection: close\r\n\r\n");

        // Body
        try self.writeAll(body);
    }

    /// Parse HTTP request
    pub fn parseRequest(self: *Connection) !HttpRequest {
        // Use stack buffer for the HTTP request
        var buffer: [8192]u8 = undefined;
        const bytes_read = try self.read(&buffer);
        if (bytes_read == 0) {
            return error.ConnectionClosed;
        }

        const data = buffer[0..bytes_read];

        // Find the end of the request line
        const request_line_end = std.mem.indexOf(u8, data, "\r\n") orelse {
            return error.InvalidRequest;
        };

        const request_line = data[0..request_line_end];

        // Split the request line into method, path, and version
        var request_line_iter = std.mem.splitScalar(u8, request_line, ' ');
        const method = request_line_iter.next() orelse {
            return error.InvalidRequest;
        };
        const path = request_line_iter.next() orelse {
            return error.InvalidRequest;
        };
        const version = request_line_iter.next() orelse {
            return error.InvalidRequest;
        };

        // Find the end of the headers
        const headers_end = std.mem.indexOf(u8, data, "\r\n\r\n") orelse {
            return error.InvalidRequest;
        };

        const body_start = headers_end + 4;
        const body = if (body_start < bytes_read) data[body_start..] else "";

        return HttpRequest{
            .method = try self.allocator.dupe(u8, method),
            .path = try self.allocator.dupe(u8, path),
            .version = try self.allocator.dupe(u8, version),
            .body = try self.allocator.dupe(u8, body),
            .allocator = self.allocator,
        };
    }
};

/// HTTP Request
pub const HttpRequest = struct {
    allocator: std.mem.Allocator,
    method: []const u8,
    path: []const u8,
    version: []const u8,
    body: []const u8,

    pub fn deinit(self: *HttpRequest) void {
        self.allocator.free(self.method);
        self.allocator.free(self.path);
        self.allocator.free(self.version);
        self.allocator.free(self.body);
    }
};

/// A thread pool for handling concurrent connections
pub const ThreadPool = struct {
    // Import atomic ordering constants for easier reference
    const Ordering = std.builtin.AtomicOrder;

    allocator: std.mem.Allocator,
    threads: []std.Thread,
    jobs: JobQueue,
    shutdown: std.atomic.Value(bool),

    // Connection tracking with mutex protection
    conn_mutex: std.Thread.Mutex,
    max_connections: usize,
    current_connections: usize,

    /// Initialize a new thread pool with the given number of threads
    pub fn init(allocator: std.mem.Allocator, thread_count: usize, max_connections: usize) !*ThreadPool {
        var self = try allocator.create(ThreadPool);
        errdefer allocator.destroy(self);

        self.* = ThreadPool{
            .allocator = allocator,
            .threads = try allocator.alloc(std.Thread, thread_count),
            .jobs = JobQueue.init(allocator),
            .shutdown = std.atomic.Value(bool).init(false),
            .conn_mutex = std.Thread.Mutex{},
            .max_connections = max_connections,
            .current_connections = 0,
        };
        errdefer self.allocator.free(self.threads);
        errdefer self.jobs.deinit();

        // Set the shutdown pointer in the JobQueue
        self.jobs.setShutdownPtr(&self.shutdown);

        // Spawn worker threads
        for (0..thread_count) |i| {
            self.threads[i] = try std.Thread.spawn(.{}, workerThread, .{self});
        }

        return self;
    }

    /// Clean up the thread pool
    pub fn deinit(self: *ThreadPool) void {
        std.debug.print("ThreadPool.deinit() called on pool at {*}\n", .{self});

        // Signal all threads to shut down
        self.shutdown.store(true, Ordering.monotonic);
        std.debug.print("ThreadPool shutdown flag set\n", .{});

        // Wake up all worker threads so they can see the shutdown flag
        // Post once for each thread
        for (0..self.threads.len) |i| {
            std.debug.print("Waking up worker thread {}\n", .{i});
            self.jobs.signal.post();
        }

        // Wait for all threads to finish
        for (self.threads) |thread| {
            thread.join();
        }
        std.debug.print("All worker threads joined\n", .{});

        // Clean up resources
        std.debug.print("Freeing {} thread handles\n", .{self.threads.len});
        self.allocator.free(self.threads);
        std.debug.print("Cleaning up job queue\n", .{});
        self.jobs.deinit();
        std.debug.print("ThreadPool resources cleaned up\n", .{});
        // Note: We don't destroy self here - this is now the caller's responsibility
        // since the caller (HttpServer.deinit) has to free the ThreadPool instance
    }

    /// Submit a job to the thread pool
    pub fn submit(self: *ThreadPool, job: *Job) !void {
        // If we're at max connections, wait until a connection finishes
        while (true) {
            // Lock the mutex to check and update connection count
            self.conn_mutex.lock();

            if (self.current_connections < self.max_connections) {
                // We have capacity, increment and proceed
                self.current_connections += 1;
                self.conn_mutex.unlock();
                break;
            }

            // No capacity, unlock and wait
            self.conn_mutex.unlock();
            std.time.sleep(std.time.ns_per_ms * 10);
        }

        try self.jobs.push(job);
    }

    /// Set the maximum number of concurrent connections
    pub fn setMaxConnections(self: *ThreadPool, max_connections: usize) void {
        self.conn_mutex.lock();
        defer self.conn_mutex.unlock();
        self.max_connections = max_connections;
    }

    /// Get the current number of active connections
    pub fn getCurrentConnections(self: *ThreadPool) usize {
        self.conn_mutex.lock();
        defer self.conn_mutex.unlock();
        return self.current_connections;
    }

    /// Worker thread function
    fn workerThread(self: *ThreadPool) void {
        while (!self.shutdown.load(Ordering.monotonic)) {
            // Wait for a job, handling any errors
            const job = self.jobs.pop() catch |err| {
                std.debug.print("Error popping job: {}\n", .{err});
                // Sleep a bit to avoid tight loop in case of persistent errors
                std.time.sleep(std.time.ns_per_ms * 10);
                continue;
            };

            if (job) |j| {
                // Execute the job with error handling
                j.execute() catch |err| {
                    std.debug.print("Error executing job: {}\n", .{err});
                };

                // Decrement the connection count when the job is done
                self.conn_mutex.lock();
                self.current_connections -= 1;
                self.conn_mutex.unlock();
            } else {
                // No job was available despite a signal
                // This could happen if another thread got the job first
                // or if we're shutting down
                std.time.sleep(std.time.ns_per_ms);
            }
        }
    }
};

/// A queue of jobs for the thread pool
const JobQueue = struct {
    // Import atomic ordering constants for easier reference
    const Ordering = std.builtin.AtomicOrder;

    allocator: std.mem.Allocator,
    mutex: std.Thread.Mutex,
    jobs: std.ArrayList(*Job),
    signal: std.Thread.Semaphore,
    shutdown: *std.atomic.Value(bool),

    fn init(allocator: std.mem.Allocator) JobQueue {
        // Create a dummy shutdown atomic that's always false
        // This will be replaced with the ThreadPool's shutdown atomic when the ThreadPool is initialized
        const shutdown_ptr = allocator.create(std.atomic.Value(bool)) catch @panic("OOM");
        shutdown_ptr.* = std.atomic.Value(bool).init(false);

        return JobQueue{
            .allocator = allocator,
            .mutex = std.Thread.Mutex{},
            .jobs = std.ArrayList(*Job).init(allocator),
            .signal = std.Thread.Semaphore{},
            .shutdown = shutdown_ptr,
        };
    }

    fn setShutdownPtr(self: *JobQueue, shutdown: *std.atomic.Value(bool)) void {
        // Clean up the dummy shutdown atomic
        const old_ptr = self.shutdown;
        self.shutdown = shutdown;
        self.allocator.destroy(old_ptr);
    }

    fn deinit(self: *JobQueue) void {
        self.mutex.lock();
        defer self.mutex.unlock();

        // If any jobs are left, log a warning
        if (self.jobs.items.len > 0) {
            std.debug.print("Warning: {} jobs still in queue during shutdown\n", .{self.jobs.items.len});
        }

        self.jobs.deinit();
    }

    fn push(self: *JobQueue, job: *Job) !void {
        // Don't accept new jobs if we're shutting down
        if (self.shutdown.load(Ordering.monotonic)) {
            return error.ShuttingDown;
        }

        self.mutex.lock();
        defer self.mutex.unlock();

        try self.jobs.append(job);
        self.signal.post();
    }

    fn pop(self: *JobQueue) !?*Job {
        // If we're shutting down and there are no jobs, return null immediately
        if (self.shutdown.load(Ordering.monotonic)) {
            self.mutex.lock();
            defer self.mutex.unlock();

            if (self.jobs.items.len == 0) {
                return null;
            }
        }

        // Wait for a job to be available or shutdown
        self.signal.wait();

        self.mutex.lock();
        defer self.mutex.unlock();

        if (self.jobs.items.len == 0) {
            return null;
        }

        return self.jobs.orderedRemove(0);
    }
};

/// A job for the thread pool
pub const Job = struct {
    execute_fn: *const fn (*Job) anyerror!void,

    pub fn execute(self: *Job) !void {
        return self.execute_fn(self);
    }
};

/// HTTP connection job for the thread pool
pub const ConnectionJob = struct {
    job: Job,
    connection: *Connection,
    handler: *const fn (*Connection) anyerror!void,
    allocator: std.mem.Allocator,

    pub fn init(connection: *Connection, handler: *const fn (*Connection) anyerror!void) ConnectionJob {
        return ConnectionJob{
            .job = Job{ .execute_fn = executeHandler },
            .connection = connection,
            .handler = handler,
            .allocator = connection.allocator,
        };
    }

    fn executeHandler(job_ptr: *Job) !void {
        // Get the containing ConnectionJob from its job field
        const offset = @offsetOf(ConnectionJob, "job");
        const ptr = @as([*]u8, @ptrCast(job_ptr)) - offset;
        const self = @as(*ConnectionJob, @ptrCast(@alignCast(ptr)));

        // Execute the handler - this will close the connection on error
        self.handler(self.connection) catch |err| {
            std.debug.print("Error in connection handler: {}\n", .{err});
        };

        // Cleanup - make sure we don't double-close
        if (!self.connection.is_closed) {
            self.connection.deinit();
        }
        self.allocator.destroy(self.connection);
        self.allocator.destroy(self);
    }
};

```

`src/tools.zig`:

```zig
const std = @import("std");
const jsonrpc = @import("jsonrpc.zig");
const mcp = @import("mcp.zig");

/// Example tool handlers that can be used in applications
/// Echo handler that returns the input parameters unchanged
pub fn echoHandler(ctx: *jsonrpc.Context, params: std.json.Value) !std.json.Value {
    // For echo, we just need to clone the params into our context
    return try mcp.cloneJsonValue(ctx.allocator(), params);
}

/// Reverse handler that reverses a text string
pub fn reverseHandler(ctx: *jsonrpc.Context, params: std.json.Value) !std.json.Value {
    // Get the allocator from the context
    const allocator = ctx.allocator();

    // Check if params has a "text" field
    const text_value = params.object.get("text") orelse {
        return jsonrpc.Error.invalidParams;
    };

    if (text_value != .string) {
        return jsonrpc.Error.invalidParams;
    }

    const text = text_value.string;

    // Use stack buffer for small strings, fall back to heap for larger ones
    var stack_buf: [1024]u8 = undefined;
    const reversed = if (text.len <= stack_buf.len) blk: {
        // Reverse the string in stack buffer
        for (text, 0..) |char, i| {
            stack_buf[text.len - 1 - i] = char;
        }
        // Allocate a copied string in our arena
        break :blk try allocator.dupe(u8, stack_buf[0..text.len]);
    } else blk: {
        // For larger strings, use heap allocation
        var heap_buf = try allocator.alloc(u8, text.len);
        // Reverse the string
        for (text, 0..) |char, i| {
            heap_buf[text.len - 1 - i] = char;
        }
        break :blk heap_buf;
    };

    // Create response object
    var result = std.json.Value{ .object = std.json.ObjectMap.init(allocator) };
    try result.object.put("reversed", std.json.Value{ .string = reversed });

    return result;
}

// Example tool with parameters schema
pub fn createReverseToolWithSchema(allocator: std.mem.Allocator) !mcp.Tool {
    // Create a JSON Schema for the parameters
    var schema = std.json.Value{ .object = std.json.ObjectMap.init(allocator) };
    try schema.object.put("type", std.json.Value{ .string = "object" });

    var properties = std.json.Value{ .object = std.json.ObjectMap.init(allocator) };
    var text_prop = std.json.Value{ .object = std.json.ObjectMap.init(allocator) };
    try text_prop.object.put("type", std.json.Value{ .string = "string" });
    try text_prop.object.put("description", std.json.Value{ .string = "The text to reverse" });

    try properties.object.put("text", text_prop);
    try schema.object.put("properties", properties);

    var required = std.json.Value{ .array = std.json.Array.init(allocator) };
    try required.array.append(std.json.Value{ .string = "text" });
    try schema.object.put("required", required);

    return mcp.Tool{
        .name = "reverse",
        .description = "Reverses the input string",
        .handler = reverseHandler,
        .parameters = schema,
    };
}

test {
    std.testing.refAllDecls(@This());
}

```

`test_client.js`:

```js
#!/usr/bin/env node
/**
 * Basic MCP client for testing the Zig MCP server
 */

const { spawn } = require('child_process');
const readline = require('readline');

// Start the MCP server process
const server = spawn('./zig-out/bin/mcp_server', []);

// Set up process event handlers
server.on('error', (err) => {
  console.error('Failed to start MCP server:', err);
  process.exit(1);
});

server.stderr.on('data', (data) => {
  console.error(`SERVER LOG: ${data}`);
});

// Set up readline interface to read responses
const rl = readline.createInterface({
  input: server.stdout,
  crlfDelay: Infinity
});

// Process responses
rl.on('line', (line) => {
  if (line.trim() === '') return;
  
  try {
    const response = JSON.parse(line);
    console.log('Server response:', JSON.stringify(response, null, 2));
  } catch (e) {
    console.log('Raw server output:', line);
  }
});

// Send initialize request
function initialize() {
  const request = {
    jsonrpc: '2.0',
    id: 1,
    method: 'initialize',
    params: {
      protocolVersion: '0.4.0',
      capabilities: {
        tools: {
          enabled: true
        }
      }
    }
  };
  
  console.log('Sending initialize request...');
  server.stdin.write(JSON.stringify(request) + '\n');
}

// Send initialized notification
function initialized() {
  const notification = {
    jsonrpc: '2.0', 
    method: 'initialized'
  };
  
  console.log('Sending initialized notification...');
  server.stdin.write(JSON.stringify(notification) + '\n');
}

// List tools
function listTools() {
  const request = {
    jsonrpc: '2.0',
    id: 2,
    method: 'mcp/tools/list'
  };
  
  console.log('Sending tools list request...');
  server.stdin.write(JSON.stringify(request) + '\n');
}

// Invoke echo tool
function invokeEchoTool() {
  const request = {
    jsonrpc: '2.0',
    id: 3,
    method: 'mcp/tools/invoke',
    params: {
      name: 'echo',
      params: {
        message: 'Hello from Node.js client!'
      }
    }
  };
  
  console.log('Invoking echo tool...');
  server.stdin.write(JSON.stringify(request) + '\n');
}

// Invoke reverse tool
function invokeReverseTool() {
  const request = {
    jsonrpc: '2.0',
    id: 4,
    method: 'mcp/tools/invoke',
    params: {
      name: 'reverse',
      params: {
        text: 'Hello from Node.js client!'
      }
    }
  };
  
  console.log('Invoking reverse tool...');
  server.stdin.write(JSON.stringify(request) + '\n');
}

// Shutdown server
function shutdown() {
  const request = {
    jsonrpc: '2.0',
    id: 5,
    method: 'shutdown'
  };
  
  console.log('Sending shutdown request...');
  server.stdin.write(JSON.stringify(request) + '\n');
  
  // Exit after a short delay
  setTimeout(() => {
    server.kill();
    process.exit(0);
  }, 1000);
}

// Execute test sequence with delays
setTimeout(initialize, 1000);
setTimeout(initialized, 2000);
setTimeout(listTools, 3000);
setTimeout(invokeEchoTool, 4000);
setTimeout(invokeReverseTool, 5000);
setTimeout(shutdown, 6000);
```