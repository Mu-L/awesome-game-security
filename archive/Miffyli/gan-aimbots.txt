Project Path: arc_Miffyli_gan-aimbots_rprkue4l

Source Tree:

```txt
arc_Miffyli_gan-aimbots_rprkue4l
├── LICENSE
├── README.md
├── aimbots
│   ├── __init__.py
│   ├── aimbots.py
│   └── humanlike_aimbot_gan.py
├── bots.cfg
├── classification.py
├── data_collection_gan.py
├── data_collection_original.py
├── data_collection_performance.py
├── data_collection_recording.py
├── feature_extraction.py
├── plot.py
├── plot_paper.py
├── recording.py
├── requirements.txt
├── scenarios
│   └── cig.wad
├── scripts
│   ├── extract_features.sh
│   ├── extract_features_gan_data.sh
│   ├── plot_figures.sh
│   ├── run_all.sh
│   ├── run_classification.sh
│   ├── split_gan_data.sh
│   ├── test_gan_classifiers.sh
│   ├── train_gan_classifiers.sh
│   └── train_gans.sh
├── shared_parameters
│   ├── gan_group0_parameters.npz
│   └── gan_group1_parameters.npz
├── train_util.py
└── utils
    ├── __init__.py
    ├── mouse_emulation.py
    └── win_mouse_tools.py

```

`LICENSE`:

```
MIT License

Copyright (c) 2022 Anssi

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

```

`README.md`:

```md
Code and data used in the "GAN-Aimbots: Using Machine Learning for Cheating in First Person Shooters", to be published in IEEE Transactions on Games (early access version [here](https://ieeexplore.ieee.org/document/9774028)).

**Note:** Code quality is best classified as "researchy", mixed with bad case of not following code styles. 

For data, see [this Zenodo record](https://zenodo.org/record/6345323).

## Contents and overview

* `data` directory contains the data collected during the research (download from [Zenodo](https://zenodo.org/record/6345323)).
* `scripts` contains shell scripts that should be used to run experiments.
* `shared_parameters` contains the group 1 and 2 GAN-Aimbots used in the paper. They are also used by the recording scripts (see below).
* `scenarios` contains the Doom map/scenario files for setting up the game.
* Remaining directories/files are Python files that contain all the code for the experiments.

## Requirements

Playing with the aimbots in ViZDoom *only* works on Windows!

Experiments were ran on Python 3.6, but should work on any Python 3.x. For other requirements, see `requirements.txt`.

**Note**: To compare different classifiers, you also need to install [auto-sklearn](https://automl.github.io/auto-sklearn/master/).

## Running the experiments

To repeat the experiments in paper with shared data, run `./scripts/run_all.sh` in the root directory.
If all works out, this should train DNN classifiers in different setups and evaluate them, and results should
match closely to what was reported in the paper. This will also train the GAN-Aimbots, but they are not used
for the results, as that would require data collection.

The whole process should take well less than a hour. No GPU is needed.

All results will be printed out in the console window and figures are placed under `figures` directory.

## Trying out the game

Run one of the `data_collection_*` scripts to try out the game and different aimbots. For a newcomer,
we recommend playing `data_collection_performance.py` (takes 30min) which will let you play with and without
all aimbots used in the work.

## Data collection scripts

Scripts starting with `data_collection_*` are Python scripts that were used to gather the data,
in their original form (including the messages to users). These were packed into single executable
files (.exe) using PyInstaller.

Launching any of the following scripts prompts user to agree with a consent agreement, and after
agreeing launches a Doom game with or without aimbots. Data is stored in the same directory
where script was launched.

* `data_collection_original.py` is data collection 1, collecting data for light and strong aimbots (and no aimbot).
* `data_collection_gan.py` is data collection 2, collecting data for GAN group 1 and 2 aimbots (and no aimbot)
* `data_collection_performance.py` is data collection 3, collecting data for light, strong and GAN group 1 aimbots (and no aimbot).
* `data_collection_recording.py` is data collection 4, collecting video recordings of light, strong and GAN group 1 aimbots (and no aimbot).





```

`aimbots/aimbots.py`:

```py
#!/usr/bin/env python3
#
# aimbots.py 
# Implements bunch of different aimbots
#
import math as m
from random import uniform, gauss
from collections import deque
import numpy as np

TARGET_Y_RANGE = [0.32,  0.32]
TARGET_X_RANGE = [0.5,  0.5]

# If dx/dy angle is larger than this, 
# do not aim (i.e. does not aim at enemies
# too far away)
DEFAULT_MAX_ANGLE = 7

def pick_random_spot(bb):
    # Return random-ish spot from inside enemy bounding box
    # according to TARGET_X/Y_RANGE
    x_frac = uniform(*TARGET_X_RANGE)
    y_frac = uniform(*TARGET_Y_RANGE)
    return (bb[0] + (bb[2] - bb[0]) * x_frac, bb[1] + (bb[3] - bb[1]) * y_frac)

def select_closest_enemy(enemy_bbs, crosshair_x, crosshair_y):
    # Returns x,y of the closest enemy to crosshair
    # (x,y is the center of enemy).
    # enemy_bbs are bounding boxes of enemies ()
    min_dist = 1e99
    closest_bb = None
    # Select enemy whose bb is closest to ours
    for bb in enemy_bbs:
        # Distance to the center of the player
        dist = ((bb[0] + bb[2])//2 - crosshair_x)**2 + ((bb[1] + bb[3])//2 - crosshair_y)**2
        if dist < min_dist:
            min_dist = dist
            # Hurrr
            closest_bb = bb
    # No valid target, return bogus target
    if closest_bb is None:
        return [-100, -100]

    target_point = pick_random_spot(closest_bb)
    return target_point


def sign(x):
    """ 
    Return sign of x:
        -1 if x < 0 else 1
    """
    return -1 if x < 0 else 1


def ELU(x):
    """
    Exponential Linear Unit,
    as implemented in PyTorch:
        https://pytorch.org/docs/master/generated/torch.nn.ELU.html
    """
    return np.clip(x, 0, None) + np.clip(np.exp(x) - 1, None, 0)


def fnn_with_elus(x, weights, biases):
    """
    Run input through a fully-connected network
    with ELU activations, with layers
    with given weights and biases
    """
    for i in range(len(weights) - 1):
        x = (x @ weights[i].T) + biases[i]
        x = ELU(x)
    # Final mapping is linear
    x = (x @ weights[-1].T) + biases[-1]
    return x


class Aimbot:
    """ Abstract class for guidance """
    def __init__(self, width, height, fovx, fovy, crosshair_x, crosshair_y,
                 max_aim_angle = DEFAULT_MAX_ANGLE):
        self.width = width
        self.height = height
        self.fovx = fovx
        self.fovy = fovy
        self.crosshair_x = crosshair_x
        self.crosshair_y = crosshair_y

        self.max_aim_angle = max_aim_angle

    def pixels_to_deg(self, x, y):
        """ Returns degrees of deviation from center to target pixel """
        x_degrees = ((x - self.crosshair_x)/self.width)*self.fovx
        y_degrees = ((y - self.crosshair_y)/self.height)*self.fovy
        return [x_degrees, y_degrees]

    def deg_to_pixels(self, x_degrees, y_degrees):
        """ Returns screen location of given degrees of deviation from center """
        x = (x_degrees / self.fovx)*self.width + self.crosshair_x
        y = (y_degrees / self.fovy)*self.height + self.crosshair_y
        return [x, y]

    def add_jitter(self, dx, dy, noise_std=0.2):
        """
        Add small amount of gaussian jitter to the movement, 
        depending on the strength of the jump
        """
        dx += gauss(0, noise_std * dx + 0.00001)
        dy += gauss(0, noise_std * dy + 0.00001)
        return dx, dy

    def is_inside_allow_angle(self, dx, dy):
        """
        Check if the amount of movement we are about to do
        is inside allowed limits (self.max_aim_angle).
        """
        if abs(dx) < self.max_aim_angle and abs(dy) < self.max_aim_angle:
            return True

    def get_aiming(self, enemies):
        """ 
        Returns dx,dy where dx,dy is amount of degrees
        to move aim
        
        Parameters:
            enemies - List of [x,y] of visible enemies,
                      where x,y are the coordinates of 
                      enemy on screen
        Returns:
            dx,dy - Amount of degrees move should be moved
        """
        raise NotImplementedError

    def process_last_action(self, actions):
        """
        Receive last_actions from the game, 
        in case we want to keep track of something
        """
        pass

class SnapAimbot(Aimbot):
    """ Snap aim: Find closest target, and aim to it """

    def get_aiming(self, enemies):
        target = select_closest_enemy(enemies, self.crosshair_x, self.crosshair_y)
        return self.pixels_to_deg(target[0], target[1])


class MaxStepAimbot(Aimbot):
    """ 
    Snap with max steps: Find closest target and aim towards it 
    at most with some step size 
    """
    def __init__(self, width, height, fovx, fovy, crosshair_x, crosshair_y, max_hop=5,
                 max_aim_angle=DEFAULT_MAX_ANGLE):
        super().__init__(width, height, fovx, fovy, crosshair_x, crosshair_y, max_aim_angle)
        self.max_hop = max_hop

    def get_aiming(self, enemies):
        target = select_closest_enemy(enemies, self.crosshair_x, self.crosshair_y)
        dx,dy = self.pixels_to_deg(target[0], target[1])
        if not self.is_inside_allow_angle(dx, dy):
            return 0, 0

        # Limit amount of movement
        dx = sign(dx)*min(abs(dx), self.max_hop)
        dy = sign(dy)*min(abs(dy), self.max_hop)
        return self.add_jitter(dx,dy)


class RelativeAimbot(Aimbot):
    """ 
    Relative moving towards target:
        - Find closest
        - Move towards target relative to distance
    """
    def __init__(self, width, height, fovx, fovy, crosshair_x, crosshair_y, hop_frac=0.4, min_hop=1, 
                 max_aim_angle=DEFAULT_MAX_ANGLE):
        super().__init__(width, height, fovx, fovy, crosshair_x, crosshair_y, max_aim_angle)
        self.hop_frac = hop_frac
        self.min_hop = min_hop

    def get_aiming(self, enemies):
        target = select_closest_enemy(enemies, self.crosshair_x, self.crosshair_y)
        dx,dy = self.pixels_to_deg(target[0], target[1])
        if not self.is_inside_allow_angle(dx, dy):
            return 0, 0
        # Move relative to distance to target
        dx = dx*self.hop_frac if dx > self.min_hop else dx
        dy = dy*self.hop_frac if dy > self.min_hop else dy
        return self.add_jitter(dx,dy)


class GANAimbot(Aimbot):
    """
    Aimbot based on the GANs trained on the datasets.
    """
    def __init__(self, width, height, fovx, fovy, crosshair_x, crosshair_y, model_path,
                 num_previous_steps=20, num_outputs=5, max_aim_angle=DEFAULT_MAX_ANGLE):
        super().__init__(width, height, fovx, fovy, crosshair_x, crosshair_y, max_aim_angle)
        # Wonky stuff here because pyinstaller catched these imports and included whole of
        # PyTorch in the mix...
        raise RuntimeError("Remove commented imports below this")
        #from aimbots.humanlike_aimbot_gan import AimbotGenerator, LATENT_SIZE
        #import torch
        self.aimbot_generator = AimbotGenerator(
            LATENT_SIZE,
            num_previous_steps * 2 + 2,
            num_outputs * 2
        )
        self.aimbot_generator.load_state_dict(torch.load(model_path, map_location="cpu"))

        # Fixed random latent for generator
        self.latent = np.random.normal(size=(LATENT_SIZE,))

        self.num_outputs = num_outputs
        self.num_previous_steps = num_previous_steps

        self.last_steps = deque(maxlen=num_previous_steps)
        # Fill with zeros
        for i in range(num_previous_steps + 1):
            self.last_steps.append((0,0))

    def get_aiming(self, enemies):
        target = select_closest_enemy(enemies, self.crosshair_x, self.crosshair_y)
        dx, dy = self.pixels_to_deg(target[0], target[1])
        if not self.is_inside_allow_angle(dx, dy):
            return 0, 0
        # Build input vector
        input_features = np.array(self.last_steps).ravel()
        target = np.array((dx, dy))
        condition =  np.concatenate((input_features, target))

        prediction = self.aimbot_generator.forward_np(self.latent[None], condition[None])[0]

        # Take first step of the prediction as the
        # step we will take
        dx = prediction[0]
        dy = prediction[1]

        return dx, dy

    def process_last_action(self, actions):
        # Store the last mouse movements 
        # TODO hardcoded indices
        self.last_steps.append((
            actions[4],
            actions[5]
        ))


class GANAimbotNP(Aimbot):
    """
    Aimbot based on the GANs trained on the datasets.
    """
    def __init__(self, width, height, fovx, fovy, crosshair_x, crosshair_y, model_path,
                 num_previous_steps=20, num_outputs=5, max_aim_angle=DEFAULT_MAX_ANGLE):
        super().__init__(width, height, fovx, fovy, crosshair_x, crosshair_y, max_aim_angle)
        parameters = np.load(model_path, allow_pickle=True)
        self.weights = parameters["weights"]
        self.biases = parameters["biases"]

        # Fixed random latent for generator (known size)
        self.latent = np.random.normal(size=(16,))

        self.num_outputs = num_outputs
        self.num_previous_steps = num_previous_steps

        self.last_steps = deque(maxlen=num_previous_steps)
        # Fill with zeros
        for i in range(num_previous_steps + 1):
            self.last_steps.append((0,0))

    def get_aiming(self, enemies):
        target = select_closest_enemy(enemies, self.crosshair_x, self.crosshair_y)
        dx, dy = self.pixels_to_deg(target[0], target[1])
        if not self.is_inside_allow_angle(dx, dy):
            return 0, 0
        # Build input vector
        input_features = np.array(self.last_steps).ravel()
        target = np.array((dx, dy))
        x = np.concatenate((self.latent, input_features, target))

        prediction = fnn_with_elus(x, self.weights, self.biases)

        # Take first step of the prediction as the
        # step we will take
        dx = prediction[0]
        dy = prediction[1]

        return dx, dy

    def process_last_action(self, actions):
        # Store the last mouse movements 
        # TODO hardcoded indices
        self.last_steps.append((
            actions[4],
            actions[5]
        ))

```

`aimbots/humanlike_aimbot_gan.py`:

```py
#
# humanlike_aimbot_gan.py
# The good ol' GAN-solution
#
import numpy as np
import json
import argparse
import torch
from torch import nn
import torch.distributions
import random
from tqdm import tqdm
from collections import deque

parser = argparse.ArgumentParser("Train humanlike aimbots (GAN-style)")
parser.add_argument("--epochs", type=int, default=30)
parser.add_argument("--model", type=str, help="Path to input/output model")
parser.add_argument("operation", choices=["train", "visualize", "params_to_numpy"])
parser.add_argument("human_recordings", nargs="+", help=".pkl files containing human gameplay (from recording.py)")

# Trajectories are in format (dx1, dy1, dx2, dy2, ...)

BATCH_SIZE = 64
USE_GPU = True

# How many previous dx/dy will be included
# in the condition
NUM_PREVIOUS_FRAMES = 20

# For loading data from recordings
AIMANGLE_DELTA_YAW_IDX = 4
AIMANGLE_DELTA_PITCH_IDX = 5

# How many steps will be generated by GAN at any time
# In practice we would just use the first generated step
NUM_GENERATED_STEPS = 5

# Epsilon for numerical stability
EPSILON = 1e-5

# Random noise vector size
LATENT_SIZE = 16
# How many iterations between updating generator
GENERATOR_UPDATE_RATE = 5

# WGAN's weight clipping for discriminator.
# Taken from the original paper https://arxiv.org/pdf/1701.07875.pdf
WGAN_WEIGHT_CLIP = 0.01
WGAN_LEARNING_RATE = 0.00005


class AimbotGenerator(nn.Module):
    """
    The generator part of GAN, which will provide
    next hops.
    """

    def __init__(self,
                 latent_size,
                 condition_size,
                 dim_out,
                 use_gpu=False,
                 optimizer=torch.optim.RMSprop,
                 discriminator_loss_weight=1,
                 aimbot_loss_weight=1
                 ):
        """
        Args:
            latent_size (int): Size of the random input vector
            condition_size (int): Size of the condition vector
            dim_out (int): Number of features out
        """
        super().__init__()

        self.latent_size = latent_size
        self.condition_size = condition_size
        self.dim_out = dim_out

        self.discriminator_loss_weight = discriminator_loss_weight
        self.aimbot_loss_weight = aimbot_loss_weight

        # TODO hardcoded network
        # "+2" for the target
        self.head = torch.nn.Sequential(
            torch.nn.Linear(self.latent_size + self.condition_size, 64),
            torch.nn.ELU(),
            torch.nn.Linear(64, 64),
            torch.nn.ELU(),
            torch.nn.Linear(64, self.dim_out)
        )

        self.use_gpu = use_gpu
        self.device = "cuda" if use_gpu else "cpu"

        self.optimizer = optimizer(self.parameters(), lr=WGAN_LEARNING_RATE)

        self.to(self.device)

    def forward(self, latent, condition):
        return self.head(torch.cat((latent, condition), dim=1))

    def forward_np(self, latent, condition):
        """ Forward but for numpy arrays """
        return self(torch.from_numpy(latent).float().to(self.device),
                    torch.from_numpy(condition).float().to(self.device)).cpu().detach().numpy()

    def train_on_batch(self, conditions, discriminator):
        if self.use_gpu:
            conditions = conditions.to(self.device)

        # Predict some "hacking" movement
        latents = torch.randn((conditions.shape[0], LATENT_SIZE)).to(self.device)
        predictions = self(latents, conditions)

        # Ask discriminator what it thinks about the generated stuff,
        # and we want to minimize this (think it is human)
        discriminator_scores = discriminator(predictions, conditions)
        D_loss = torch.mean(discriminator_scores) * self.discriminator_loss_weight

        # Aimbot-encouragement: After the generated steps we should
        # be close to the target
        # Predictions are mouse movements x1, y1, x2, y2, x3, ...
        # TODO nasty hardcoding: The target is last part of the condition
        targets = conditions[:, -2:]
        dist_to_target_x = torch.sum(predictions[:, ::2], dim=1) - targets[:, 0]
        dist_to_target_y = torch.sum(predictions[:, 1::2], dim=1) - targets[:, 1]
        total_distance_to_target = torch.sqrt(dist_to_target_x**2 + dist_to_target_y**2)

        aimbot_loss = torch.mean(total_distance_to_target) * self.aimbot_loss_weight

        total_loss = D_loss + aimbot_loss

        # Update params
        self.optimizer.zero_grad()
        total_loss.backward()
        self.optimizer.step()

        return D_loss.item(), aimbot_loss.item()


class AimbotDiscriminator(nn.Module):
    """
    The discriminator part of the GAN, attempts to distinguish
    between human players and whatever generator generates.
    Outputs 1 for "hack", 0 for "bona fide". Note that
    this flipped of the general notion with GANs, but
    done here to stay consistent with rest of the code.
    """

    def __init__(self,
                 dim_in,
                 condition_size,
                 use_gpu=False,
                 optimizer=torch.optim.RMSprop,
                 human_loss_weight=1,
                 bot_loss_weight=1):
        """
        Args:
            dim_in (int): Number of features in
        """
        super().__init__()

        self.human_loss_weight = human_loss_weight
        self.bot_loss_weight = bot_loss_weight

        # Hardcoded network based on the
        # classification network
        self.head = torch.nn.Sequential(
            torch.nn.Linear(dim_in + condition_size, 512),
            torch.nn.ELU(),
            torch.nn.Linear(512, 512),
            torch.nn.ELU(),
            torch.nn.Linear(512, 1),
        ).cuda()

        self.use_gpu = use_gpu
        self.device = "cuda" if use_gpu else "cpu"

        self.optimizer = optimizer(self.parameters(), lr=WGAN_LEARNING_RATE)

        self.to(self.device)

    def forward(self, x, condition):
        # Return classification for trajectory
        # 0: Human
        # 1: Bot
        x = self.head(torch.cat((x, condition), dim=1))
        return x

    def forward_np(self, x, condition):
        """ Forward but for numpy arrays """
        return self(torch.from_numpy(x).float().to(self.device),
                    torch.from_numpy(condition).float().to(self.device)).cpu().detach().numpy()

    def train_on_batch(self, human_datas, conditions, generator):
        if self.use_gpu:
            human_datas = human_datas.to(self.device)
            conditions = conditions.to(self.device)

        human_predictions = self(human_datas, conditions)

        # Generate hack movement
        latents = torch.randn((human_datas.shape[0], LATENT_SIZE)).to(self.device)
        bot_trajectories = generator(latents, conditions)

        bot_predictions = self(bot_trajectories, conditions)

        # Minimize humans, maximize bots
        total_loss = (
            torch.mean(human_predictions) * self.human_loss_weight -
            torch.mean(bot_predictions) * self.bot_loss_weight
        )

        # Provide some kind of metrics how we are learning
        human_scores = torch.mean(human_predictions).item()
        bot_scores = torch.mean(bot_predictions).item()

        # Update params
        self.optimizer.zero_grad()
        total_loss.backward()
        self.optimizer.step()

        # WGAN weight clipping
        for p in self.parameters():
            p.data.clamp_(min=-WGAN_WEIGHT_CLIP, max=WGAN_WEIGHT_CLIP)

        return total_loss.item(), (human_scores, bot_scores)


def load_human_data(files):
    """
    Load samples of human trajectories from recorded files.
    Returns two arrays:
        condition (N x (NUM_PREVIOUS_STEPS*2 + 2)):
            previous mouse movements + target point
            (where player landed after NUM_GENERATED_STEPS)
        human_data (N x NUM_GENERATED_STEPS*2):
            How player moved to reach that target point
    Automatically skips files with aimbot enabled.
    """
    conditions = []
    human_data = []

    condition_size = NUM_PREVIOUS_FRAMES * 2
    human_data_size = NUM_GENERATED_STEPS * 2
    full_slice_size = condition_size + human_data_size
    for filename in tqdm(files):
        data = json.load(open(filename, "rb"))
        # Skip aimbotting ones
        if data["aimbot"] is not None:
            continue

        # Interleave yaws and pitches
        yaw_pitches = []
        for action in data["actions"]:
            yaw_pitches.append(action[AIMANGLE_DELTA_YAW_IDX])
            yaw_pitches.append(action[AIMANGLE_DELTA_PITCH_IDX])

        for idx, i in enumerate(range(full_slice_size, len(yaw_pitches), 2)):
            full_slice = yaw_pitches[i - full_slice_size:i]
            human_data_slice = full_slice[-human_data_size:]
            target_condition = [sum(human_data_slice[::2]), sum(human_data_slice[1::2])]
            condition = full_slice[:condition_size]

            conditions.append(np.array(condition + target_condition))
            human_data.append(np.array(human_data_slice))

    return np.array(conditions), np.array(human_data)


def main_visualize(args):
    from matplotlib import pyplot
    # Clip human data (we do not need much)
    human_data, targets = load_human_data(random.sample(args.human_recordings, 5))

    generator = AimbotGenerator(human_data.shape[1], NUM_GENERATED_STEPS * 2)
    generator.load_state_dict(torch.load(args.model + "_G"))

    # Pick random human trajectories, and compare predictions to
    # real steps
    idxs = list(range(len(human_data)))
    for rep in range(10):
        random_idx = random.choice(idxs)
        random_traj = human_data[random_idx]
        random_target = targets[random_idx]

        print(random_target)

        prediction = generator.forward_np(random_traj[None], random_target[None])[0]

        print(random_traj.reshape((-1, 2)))
        print(prediction.reshape((-1, 2)))

        input_traj = np.cumsum(random_traj.reshape((-1, 2)), axis=0)
        prediction = np.cumsum(prediction.reshape((-1, 2)), axis=0) + input_traj[-1]
        pyplot.axis("equal")
        pyplot.scatter(input_traj[:,0], input_traj[:,1])
        pyplot.scatter(input_traj[-1, 0] + random_target[0],
                       input_traj[-1, 1] + random_target[1],
                       c="g")
        pyplot.scatter(prediction[:, 0], prediction[:, 1], c="r")
        pyplot.show()
        pyplot.close()


def main_train(args):
    print("Loading human data...")
    conditions, human_data = load_human_data(args.human_recordings)
    human_data = human_data.astype(np.float32)
    conditions = conditions.astype(np.float32)

    human_data = torch.from_numpy(human_data)
    conditions = torch.from_numpy(conditions)

    condition_size = NUM_PREVIOUS_FRAMES * 2 + 2
    generated_size = NUM_GENERATED_STEPS * 2
    generator = AimbotGenerator(
        LATENT_SIZE,
        condition_size,
        generated_size,
        aimbot_loss_weight=1,
        discriminator_loss_weight=1,
        optimizer=torch.optim.Adam,
        use_gpu=USE_GPU
    )
    discriminator = AimbotDiscriminator(
        generated_size,
        condition_size,
        optimizer=torch.optim.Adam,
        human_loss_weight=1,
        bot_loss_weight=1,
        use_gpu=USE_GPU
    )

    # Two sets of random indices
    # one for D and one for G
    rand_idxs = np.arange(len(human_data))
    rand_idxs2 = np.arange(len(human_data))

    g_d_losses = deque(maxlen=100)
    g_aimbot_losses = deque(maxlen=100)
    d_losses = deque(maxlen=100)
    d_human_preds = deque(maxlen=100)
    d_bot_preds = deque(maxlen=100)

    for epoch in range(args.epochs):
        print("Epoch %d" % epoch)

        np.random.shuffle(rand_idxs)
        np.random.shuffle(rand_idxs2)

        iteration = 0
        for i in tqdm(range(0, len(rand_idxs) - BATCH_SIZE, BATCH_SIZE)):
            # ---Update D---
            batch_human_data = human_data[rand_idxs[i:i + BATCH_SIZE]]
            batch_conditions = conditions[rand_idxs[i:i + BATCH_SIZE]]

            d_loss, d_accs = discriminator.train_on_batch(
                batch_human_data,
                batch_conditions,
                generator
            )

            d_losses.append(d_loss)
            d_human_preds.append(d_accs[0])
            d_bot_preds.append(d_accs[1])

            # ---Update G---
            # Generate some dummy targets for aimbot to aim at
            if (iteration % GENERATOR_UPDATE_RATE) == 0:
                batch_conditions = conditions[rand_idxs2[i:i + BATCH_SIZE]]

                # First update generator
                g_d_loss, g_aimbot_loss = generator.train_on_batch(
                    batch_conditions,
                    discriminator
                )

                g_d_losses.append(g_d_loss)
                g_aimbot_losses.append(g_aimbot_loss)

            if (iteration % 100) == 0:
                tqdm.write("Iteration {}".format(iteration))
                tqdm.write("\tG_D loss (v):        {:.3f}".format(np.mean(g_d_losses)))
                tqdm.write("\tG_aimbot loss (v):   {:.3f}".format(np.mean(g_aimbot_losses)))
                tqdm.write("\tD loss (v):          {:.3f}".format(np.mean(d_losses)))
                tqdm.write("\tD human pred:        {:.3f}".format(np.mean(d_human_preds)))
                tqdm.write("\tD bot pred:          {:.3f}".format(np.mean(d_bot_preds)))

            iteration += 1

        if args.model is not None:
            torch.save(generator.state_dict(), args.model + "_G")
            torch.save(discriminator.state_dict(), args.model + "_D")


def params_to_numpy(args):
    """
    Take args.model, load the parameters
    and convert into nice numpy thing of
    weights and biases
    """
    params = torch.load(args.model)
    # Hardcoded generator parameter names
    weights = [
        params["head.0.weight"].cpu().numpy(),
        params["head.2.weight"].cpu().numpy(),
        params["head.4.weight"].cpu().numpy(),
    ]
    biases = [
        params["head.0.bias"].cpu().numpy(),
        params["head.2.bias"].cpu().numpy(),
        params["head.4.bias"].cpu().numpy(),
    ]
    output_file = args.model + "_numpy_params"
    np.savez(output_file, weights=weights, biases=biases)


if __name__ == '__main__':
    args = parser.parse_args()
    if args.operation == "train":
        main_train(args)
    elif args.operation == "params_to_numpy":
        params_to_numpy(args)
    else:
        main_visualize(args)

```

`bots.cfg`:

```cfg
{
    name        Rambo
    aiming      67
    perfection  50
    reaction    70
    isp         50
    color       "40 cf 00"
    skin        base
    //weaponpref    012385678
}

{
    name        McClane
    aiming      34
    perfection  75
    reaction    15
    isp         90
    color       "b0 b0 b0"
    skin        base
    //weaponpref    012345678
}

{
    name        MacGyver
    aiming      80
    perfection  67
    reaction    72
    isp         87
    color       "50 50 60"
    skin        base
    //weaponpref    012345678
}

{
    name        Plissken
    aiming      15
    perfection  50
    reaction    50
    isp         50
    color       "8f 00 00"
    skin        base
    //weaponpref    082345678
}

{
    name        Machete
    aiming      50
    perfection  13
    reaction    20
    isp         100
    color       "ff ff ff"
    skin        base
    //weaponpref    012345678
}

{
    name        Anderson
    aiming      45
    perfection  30
    reaction    70
    isp         60
    color       "ff af 3f"
    skin        base
    //weaponpref    012345678
}

```

`classification.py`:

```py
#!/usr/bin/env python3
#
# classification.py
# Read extracted features, train and evaluate
# different ML algorithms for classifying cheats from legit players
#
import argparse
import glob
import random
import pickle
import os
import math

import numpy as np

AVAILABLE_CLASSIFIERS = [
    "dnn",
    "random_forest",
    "decision_tree",
    "libsvm_svc",
    "bernoulli_nb",
    "sgd",
    "lda"
]

parser = argparse.ArgumentParser("Do classification on extracted features")
parser.add_argument("features_dir", help="Directory/file where feature npz files are stored (from feature_extraction.py)")
parser.add_argument("output_path", help="Path where classification outputs are stored (splits, trained models, scores)")
parser.add_argument("classifiers", type=str, nargs="+", choices=AVAILABLE_CLASSIFIERS, help="Classifiers to run data through")
parser.add_argument("--autosklearn-time-limit", type=int, default=5 * 60 * 60, help="Amount of time given per auto-sklearn run")
parser.add_argument("--eval-ratio", type=float, default=0.2, help="Amount of data to keep for evaluation")
parser.add_argument("--model-path", default=None, type=str, help="If given, use this model to evaluate given feature files.")
parser.add_argument("--train-test-split", default="train_test_split.pkl", type=str, help="File where train-test split is stored")
parser.add_argument("--included-aimbots", default=[1, 2], type=int, nargs="+", help="Aimbot IDs that are included in training/testing.")
parser.add_argument("--model-postfix", type=str, default="", help="String to append to models.")
parser.add_argument("--feature-files", type=str, nargs="*", default=None, help="Direct path to feature files that should be processed.")

NORMALIZATION_FILE_NAME = "feature_normalization.npz"

AUTO_SKLEARN_N_JOBS = 4

DNN_BATCH_SIZE = 64
DNN_NUM_EPOCHS = 50
DNN_VALIDATION_RATIO = 0.1


def train_dnn(args, X_train, y_train, model_path):
    import torch
    from torch.nn import functional as F
    from collections import deque

    from tqdm import tqdm

    # To balance the training.
    class_weights = [
        y_train.mean(),
        (1 - y_train).mean()
    ]

    num_validation = int(X_train.shape[0] * DNN_VALIDATION_RATIO)
    idxs = np.arange(X_train.shape[0])
    np.random.shuffle(idxs)
    validation_idxs = idxs[:num_validation]
    train_idxs = idxs[num_validation:]
    X_valid = X_train[validation_idxs]
    y_valid = y_train[validation_idxs]
    X_train = X_train[train_idxs]
    y_train = y_train[train_idxs]

    class_weights = torch.from_numpy(np.array(class_weights)).float().cuda()

    X_train = torch.from_numpy(X_train).float().cuda()
    y_train = torch.from_numpy(y_train).long().cuda()
    X_valid = torch.from_numpy(X_valid).float().cuda()
    y_valid = torch.from_numpy(y_valid).long().cuda()

    model = torch.nn.Sequential(
        torch.nn.Linear(X_train.shape[1], 512),
        torch.nn.ReLU(),
        torch.nn.Linear(512, 512),
        torch.nn.ReLU(),
        torch.nn.Linear(512, 2)
    ).cuda()

    num_iters = (X_train.shape[0] // DNN_BATCH_SIZE) * DNN_NUM_EPOCHS

    optimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-2)
    loss = torch.nn.CrossEntropyLoss(weight=class_weights)
    all_indeces = np.arange(X_train.shape[0])
    np.random.shuffle(all_indeces)
    cur_epoch_idx = 0

    losses = deque(maxlen=1000)
    for i in tqdm(range(num_iters)):
        random_idxs = all_indeces[cur_epoch_idx:cur_epoch_idx + DNN_BATCH_SIZE]
        cur_epoch_idx += DNN_BATCH_SIZE
        if cur_epoch_idx > (X_train.shape[0] - DNN_BATCH_SIZE):
            np.random.shuffle(all_indeces)
            cur_epoch_idx = 0

        inputs = X_train[random_idxs]
        targets = y_train[random_idxs]

        predictions = model(inputs)

        loss_output = loss(predictions, targets)

        optimizer.zero_grad()
        loss_output.backward()
        optimizer.step()

        losses.append(loss_output.item())

        if (i % 1000) == 0:
            valid_loss = None
            with torch.no_grad():
                valid_loss = loss(model(X_valid), y_valid).item()
            tqdm.write("Train Loss: {:.5f}  Valid loss: {:.5f}".format(
                sum(losses) / len(losses),
                valid_loss
            ))

    model = model.cpu()
    torch.save(model, model_path)

    # Will be assigned to the class below
    def predict_scores(x):
        x = torch.from_numpy(x).float()
        scores = model(x)
        return scores.cpu().detach().numpy()

    return predict_scores


def train_auto_sklearn(classifier, args, X_train, y_train, model_path):
    import autosklearn.classification
    model = autosklearn.classification.AutoSklearnClassifier(
        include_preprocessors=["no_preprocessing", ],
        include_estimators=[classifier, ],
        ensemble_size=1,
        initial_configurations_via_metalearning=0,
        time_left_for_this_task=args.autosklearn_time_limit,
        n_jobs=AUTO_SKLEARN_N_JOBS,
        ml_memory_limit=32000
    )

    model.fit(X_train.copy(), y_train.copy())

    with open(model_path, "wb") as f:
        pickle.dump(model, f)

    def predict_scores(x):
        """
        Not really a score...
        """
        return model.predict(x)

    return predict_scores


def load_or_create_split(ids, eval_ratio, file_path):
    """
    Check if file exists for train/test split.
    If not, create a split of ids where
    at least eval_ratio of ids are in evaluation.

    Returns (training_ids, testing_ids)
    """
    testing_ids = None
    training_ids = None
    if os.path.isfile(file_path):
        # Load from disk
        with open(file_path, "rb") as f:
            print("Loading data split from {}".format(file_path))
            split_data = pickle.load(f)
            training_ids = split_data["training_ids"]
            testing_ids = split_data["testing_ids"]
    else:
        # Make a split
        # Select players (computers) to keep
        # for training and testing
        print("Creating split")
        ids = set(ids)
        testing_ids = set(random.sample(ids, math.ceil(len(ids) * args.eval_ratio)))
        training_ids = ids - testing_ids

        # Save for later use
        with open(os.path.join(args.output_path, "train_test_split.pkl"), "wb") as f:
            pickle.dump(
                {"training_ids": training_ids, "testing_ids": testing_ids},
                f
            )
    return training_ids, testing_ids


def get_player_id(filename):
    """
    Return id of the player (hardware id + timestamp)
    for a given path to features or recordings
    """
    filename_split = os.path.basename(filename).split("_")
    # Timestamp + hardware id
    unique_id = filename_split[0] + "_" + filename_split[1]
    return unique_id


def main_evaluate(args):
    import torch

    if len(args.classifiers) > 1 or args.classifiers[0] != "dnn":
        raise ValueError("Only DNN is supported for evaluation")
    if not os.path.isfile(args.features_dir) and args.feature_files is None:
        raise ValueError("features_dir should be path to a feature file, or feature-files should be list of such.")

    # Load normalization data
    normalization_stats = np.load(os.path.join(os.path.dirname(args.model_path), NORMALIZATION_FILE_NAME))
    model = torch.load(args.model_path)

    # Try loading training-testing split. If could not load, just skip
    testing_ids = None
    if os.path.isfile(args.train_test_split):
        print("Loading testing IDs from {}".format(args.train_test_split))
        split = pickle.load(open(args.train_test_split, "rb"))
        testing_ids = split["testing_ids"]
    else:
        print("WARNING: Could not find train-test split file {}. Evaluating all given features!".format(args.train_test_split))

    feature_files = []
    if args.feature_files is None:
        feature_files = [args.features_dir]
    else:
        feature_files = args.feature_files

    features = []
    labels = []
    aimbot_classes = []

    for filename in feature_files:
        if testing_ids is not None:
            player_id = get_player_id(filename)
            if player_id not in testing_ids:
                continue
        # Features_dir is path to a npz file
        data = np.load(filename)

        features.append(data["features"])
        labels.append(data["labels"])
        aimbot_classes.append(data["aimbot_class"])
    features = np.concatenate(features, axis=0)
    labels = np.concatenate(labels, axis=0)
    aimbot_classes = np.concatenate(aimbot_classes, axis=0)

    normalized_features = (features - normalization_stats["means"]) / normalization_stats["stds"]

    scores = model(torch.from_numpy(normalized_features).float()).detach().numpy()

    # Use same naming as with main code
    np.savez(
        args.output_path,
        test_features=features,
        test_scores=scores,
        test_labels=labels,
        test_aimbots=aimbot_classes
    )


def main(args):
    data_files = []
    if args.feature_files is None:
        data_files = glob.glob(os.path.join(args.features_dir, "*"))
    else:
        data_files = args.feature_files
    # NOTE:
    # IDs attempt to be unique to each player.
    # They are a concatenation of timestamp when
    # files were sent along with the semi-unique hardware id.
    # This works because data uploading script
    # fixed these two when receiving files.
    ids = []
    datas = []
    for data_file in data_files:
        data = np.load(data_file)
        datas.append(data)
        unique_id = get_player_id(data_file)
        ids.append(unique_id)

    split_path = os.path.join(args.output_path, args.train_test_split)
    training_ids, testing_ids = load_or_create_split(set(ids), args.eval_ratio, split_path)

    print("Using {} hardware-ids for training and {} for evaluation".format(len(training_ids), len(testing_ids)))

    # Load and split the data
    X_train = []
    X_test = []
    y_train = []
    y_test = []
    aimbots_test = []
    for data, unique_id in zip(datas, ids):
        features = data["features"]
        labels = data["labels"]
        # All data per file uses same aimbot index
        aimbots = data["aimbot_class"]
        aimbot = aimbots[0]
        if aimbot in args.included_aimbots or aimbot == 0:
            if unique_id in training_ids:
                X_train.append(features)
                y_train.append(labels)
            else:
                X_test.append(features)
                y_test.append(labels)
                aimbots_test.append(data["aimbot_class"])
    X_train = np.concatenate(X_train, axis=0)
    y_train = np.concatenate(y_train, axis=0)
    X_test = np.concatenate(X_test, axis=0)
    y_test = np.concatenate(y_test, axis=0)
    aimbots_test = np.concatenate(aimbots_test, axis=0)

    # Get normalization parameters from training set or from file
    # if it exists.
    features_mean = None
    features_std = None
    normalization_file_path = os.path.join(args.output_path, NORMALIZATION_FILE_NAME)
    if os.path.isfile(normalization_file_path):
        print("Loading normalization stats from {}".format(NORMALIZATION_FILE_NAME))
        normalization_data = np.load(normalization_file_path)
        features_mean = normalization_data["means"]
        features_std = normalization_data["stds"]
    else:
        # Do not normalize last item in features (binary)
        features_mean = np.append(X_train[:, :-1].mean(axis=0), 0)
        features_std = np.append(X_train[:, :-1].std(axis=0), 1)
        np.savez(normalization_file_path, means=features_mean, stds=features_std)

    # Normalize features
    X_train = (X_train - features_mean) / features_std
    X_test = (X_test - features_mean) / features_std

    # TODO run through different classifiers. Create, train,
    # evaluate and store scores.
    for classifier_name in args.classifiers:
        predict_scores = None
        model_path = os.path.join(args.output_path, "{}{}_model.pkl".format(classifier_name, args.model_postfix))
        if classifier_name == "dnn":
            predict_scores = train_dnn(args, X_train, y_train, model_path)
        else:
            predict_scores = train_auto_sklearn(classifier_name, args, X_train, y_train, model_path)

        # Do predictions
        train_scores = predict_scores(X_train)
        test_scores = predict_scores(X_test)

        # Save scores
        output_path = os.path.join(args.output_path, "{}{}_scores.npz".format(classifier_name, args.model_postfix))
        np.savez(
            output_path,
            train_labels=y_train,
            train_scores=train_scores,
            test_labels=y_test,
            test_scores=test_scores,
            test_aimbots=aimbots_test
        )


if __name__ == '__main__':
    args = parser.parse_args()
    if args.model_path:
        main_evaluate(args)
    else:
        main(args)

```

`data_collection_gan.py`:

```py
#!/usr/bin/env python3
#
# data_collection_gan.py
# Main entrypoint for datacollection
#
import os
from recording import play_and_record_episodes
from time import sleep

AGREEMENT = """
 Machine learning versus machine learning: Case of aimbots.
 Organizer: Anssi Kanervisto (anssk@uef.fi)
            School of Computing, University of Eastern Finland
 ------------------------------------------------------------------------------
 BACKGROUND

 Terms:
     "Cheating": When a video-game player uses software ("cheat") to gain
                 an unfair advantage over other players.
     "Aimbot":   Particular cheat which assists player with aiming at
                 enemy players.

 Purpose of this study is two-fold:
     1) Detecting aimbot software from player's mouse
        movement using machine learning techniques
     2) Applying machine learning techniques to create
        aimbot that is not distinguishable from human players.

     Goal is to obtain public knowledge on such cheats, which can then
     be used to create better anti-cheating software.

 What data will be collected and how:
     In these experiments, you will play a game of Doom (1993)
     against computer-players. In some of the games, your aim
     will be assisted by software ("aimbot").
     The software will record your keypresses and mouse movement
     in the game.

     A hardware identifier of your machine will be included in the data.

     All data will be anonymous and no private information will be
     collected.

 How this data will be used:
     The recorded data will be used to...

     1) ... evaluate the quality of the machine-learning based aimbots
     2) ... used to train machine learning models to detect these aimbots

     This data may be released to the public.

     This data may be used in future research.

 Requirements:
     - A separate mouse (not a trackpad/mousepad)
     - 20 minutes of uninterrupted time (you can not pause the experiment)

 ------------------------------------------------------------------------------
 AGREEMENT

 By agreeing you:
     - ... confirm you recognize what data will be collected and how
       it will be used (scroll up).
     - ... are 18 years old or above.
     - ... fulfil the requirements (see above).
     - ... acknowledge there is no compensation.
     - ... acknowledge your participation is voluntary and you may withdraw at
       any point before end of the experiment.

 Input 'I agree' to continue, "quit" to close this software."""

INSTRUCTIONS = """
 INSTRUCTIONS

     This experiment will take 20 minutes, and consists
     of four 5-minute games of Doom (1993).

     Your goal is to score frags by shooting the enemies.
     You will find different weapons on the map, as well
     ammo for them and health/armor kits.

     For each game you will aimbot on or off, automatically
     set by this software. If aimbot is enabled, your aim will
     "home in" in to enemy targets once they are close enough
     to your crosshair.

     Once all games are finished, this script will upload
     recorded files to a server.

     NOTE: Avoid opening the menu (ESC) and unfocusing the window
           (clicking outside the game window or changing window)

 BUTTONS

     WASD:             Forward, left, backward and right
     SHIFT:            Run (hold down to move faster)
     Mouse:            Aim
     Left-mouse click: Shoot
     Scroll up/down:   Change weapon

     Note that you can also aim up/down.

 Press ENTER to start the game"""

AFTER_GAMES = """
 Games finished.
 Press ENTER to upload recordings to server.
 Note that these files will be locally removed after upload.
"""

FINISHED = """
 Everything done.
 Thank you for participating! Closing in 5 seconds."""

NUMBER_OF_EPISODES = 4
# 5 minutes
EPISODE_LENGTH = 35 * 60 * 5

MAPS = ["map03"] * NUMBER_OF_EPISODES

AIMBOTS = [None, None, "gan_group0", "gan_group1"]


def main_data_collection():
    os.system("cls")
    print(AGREEMENT)
    agreement = ""
    while agreement != "i agree" and agreement != "quit":
        agreement = input(" >>> ").lower()
    if agreement == "quit":
        exit(0)

    # Continue to instrunctions etc
    os.system("cls")
    print(INSTRUCTIONS)
    input()

    # Play games to create recordings
    play_and_record_episodes(
        NUMBER_OF_EPISODES,
        MAPS,
        AIMBOTS,
        "recording",
        timeout=EPISODE_LENGTH,
    )

    print(AFTER_GAMES)
    input()

    # Upload recordings to the server
    print("[NOTE] No data uploading in shared code")

    print(FINISHED)
    sleep(5)


if __name__ == '__main__':
    import sys

    # Workaround for pyinstaller:
    # Some of the local files are in
    # the temp folder used by pyinstaller,
    # so we need to navigate there.
    # Stackoverflow #57480958
    if hasattr(sys, "_MEIPASS"):
        os.chdir(sys._MEIPASS)

    main_data_collection()

```

`data_collection_original.py`:

```py
#!/usr/bin/env python3
#
# data_collection_original.py
# Main entrypoint for datacollection
#
import os
from recording import play_and_record_episodes
from time import sleep

AGREEMENT = """
 Machine learning versus machine learning: Case of aimbots.
 Organizer: Anssi Kanervisto (anssk@uef.fi)
            School of Computing, University of Eastern Finland
 ------------------------------------------------------------------------------
 BACKGROUND
 
 Terms:
     "Cheating": When a video-game player uses software ("cheat") to gain
                 an unfair advantage over other players.
     "Aimbot":   Particular cheat which assists player with aiming at 
                 enemy players.

 Purpose of this study is two-fold:
     1) Detecting aimbot software from player's mouse 
        movement using machine learning techniques
     2) Applying machine learning techniques to create
        aimbot that is not distinguishable from human players.

     Goal is to obtain public knowledge on such cheats, which can then
     be used to create better anti-cheating software.

 What data will be collected and how:
     In these experiments, you will play a game of Doom (1993)
     against computer-players. In some of the games, your aim
     will be assisted by software ("aimbot").
     The software will record your keypresses and mouse movement
     in the game.
 
     A hardware identifier of your machine will be included in the data. 

     All data will be anonymous and no private information will be 
     collected.

 How this data will be used:
     The recorded data will be used to...
 
     1) ... to train machine learning methods to detect aimbots from natural
        human gameplay.
     2) ... train an aimbot that can not not be detected by the detectors
        trained in previous step.

     This data may be released to the public.

     This data may be used in future research.

 Requirements:
     - A separate mouse (not a trackpad/mousepad)
     - 20 minutes of uninterrupted time (you can not pause the experiment)

 ------------------------------------------------------------------------------
 AGREEMENT

 By agreeing you:
     - ... confirm you recognize what data will be collected and how 
       it will be used (scroll up).
     - ... are 18 years old or above.
     - ... fulfil the requirements (see above).
     - ... acknowledge there is no compensation.
     - ... acknowledge your participation is voluntary and you may withdraw at 
       any point before end of the experiment.
 
 Input 'I agree' to continue, "quit" to close this software."""

INSTRUCTIONS = """
 INSTRUCTIONS
     
     This experiment will take 20 minutes, and consists
     of four 5-minute games of Doom (1993).
 
     Your goal is to score frags by shooting the enemies.
     You will find different weapons on the map, as well
     ammo for them and health/armor kits. 

     For each game you will aimbot on or off, automatically
     set by this software. If aimbot is enabled, your aim will 
     "home in" in to enemy targets once they are close enough
     to your crosshair.

     Once all games are finished, this script will upload
     recorded files to a server.

     NOTE: Avoid opening the menu (ESC) and unfocusing the window
           (clicking outside the game window or changing window)

 BUTTONS
    
     WASD:             Forward, left, backward and right
     SHIFT:            Run (hold down to move faster)
     Mouse:            Aim
     Left-mouse click: Shoot
     Scroll up/down:   Change weapon

     Note that you can also aim up/down.

 Press ENTER to start the game"""

AFTER_GAMES = """
 Games finished. 
 Press ENTER to upload recordings to server.
 Note that these files will be locally removed after upload.
"""

FINISHED = """
 Everything done.
 Thank you for participating! Closing in 5 seconds."""

NUMBER_OF_EPISODES = 4
# 5 minutes
EPISODE_LENGTH = 35 * 60 * 5

MAPS = ["map03"] * NUMBER_OF_EPISODES

AIMBOTS = [None, None, "ease_light", "ease_strong"]


def main_data_collection():
    os.system("cls")
    print(AGREEMENT)
    agreement = ""
    while agreement != "i agree" and agreement != "quit":
        agreement = input(" >>> ").lower()
    if agreement == "quit":
        exit(0)

    # Continue to instrunctions etc
    os.system("cls")
    print(INSTRUCTIONS)
    input()

    # Play games to create recordings
    play_and_record_episodes(NUMBER_OF_EPISODES, MAPS, AIMBOTS,
                             "recording", timeout=EPISODE_LENGTH)

    print(AFTER_GAMES)
    input()

    # Upload recordings to the server
    print("[NOTE] No data uploading in shared code")

    print(FINISHED)
    sleep(5)


if __name__ == '__main__':
    import sys

    # Workaround for pyinstaller:
    # Some of the local files are in
    # the temp folder used by pyinstaller,
    # so we need to navigate there.
    # Stackoverflow #57480958
    if hasattr(sys, "_MEIPASS"):
        os.chdir(sys._MEIPASS)

    main_data_collection()

```

`data_collection_performance.py`:

```py
#!/usr/bin/env python3
#
# data_collection_gan.py
# Main entrypoint for datacollection
#
import os
import random

from recording import play_and_record_episodes
from time import sleep

AGREEMENT = """
 Machine learning versus machine learning: Case of aimbots.
 Organizer: Anssi Kanervisto (anssk@uef.fi)
            School of Computing, University of Eastern Finland
 ------------------------------------------------------------------------------
 BACKGROUND

 Terms:
     "Cheating": When a video-game player uses software ("cheat") to gain
                 an unfair advantage over other players.
     "Aimbot":   Particular cheat which assists player with aiming at
                 enemy players.

 Purpose of this study is two-fold:
     1) Detecting aimbot software from player's mouse
        movement using machine learning techniques
     2) Applying machine learning techniques to create
        aimbot that is not distinguishable from human players.

     Goal is to obtain public knowledge on such cheats, which can then
     be used to create better anti-cheating software.

 What data will be collected and how:
     In these experiments, you will play a game of Doom (1993)
     against computer-players. In some of the games, your aim
     will be assisted by software ("aimbot").
     The software will record your keypresses and mouse movement
     in the game.

     A hardware identifier of your machine will be included in the data.

     All data will be anonymous and no private information will be
     collected.

 How this data will be used:
     The recorded data will be used to...

     1) ... evaluate the performance of machine learning based aimbots.

     This data may be released to the public.

     This data may be used in future research.

 Requirements:
     - A separate mouse (not a trackpad/mousepad)
     - 30 minutes of uninterrupted time (you can not pause the experiment)

 ------------------------------------------------------------------------------
 AGREEMENT

 By agreeing you:
     - ... confirm you recognize what data will be collected and how
       it will be used (scroll up).
     - ... are 18 years old or above.
     - ... fulfil the requirements (see above).
     - ... acknowledge there is no compensation.
     - ... acknowledge your participation is voluntary and you may withdraw at
       any point before end of the experiment.

 Input 'I agree' to continue, "quit" to close this software."""

INSTRUCTIONS = """
 INSTRUCTIONS

     This experiment will take 30 minutes, and consists
     of six games of Doom deathmatch against bots.

     Your goal is to score frags by shooting the enemies.
     You will find different weapons on the map, as well
     ammo for them and health/armor kits.

     For each game you will aimbot on or off, automatically
     set by this software. If aimbot is enabled, your aim will
     "home in" in to enemy targets once they are close enough
     to your crosshair.

     Once all games are finished, this script will upload
     recorded files to a server.

     NOTE: Avoid opening the menu (ESC) and unfocusing the window
           (clicking outside the game window or changing window)

 BUTTONS

     WASD:             Forward, left, backward and right
     SHIFT:            Run (hold down to move faster)
     Mouse:            Aim
     Left-mouse click: Shoot
     Scroll up/down:   Change weapon

     Note that you can also aim up/down.

 Press ENTER to proceed"""

AFTER_GAMES = """
 Games finished.
 Press ENTER to upload recordings to server.
 Note that these files will be locally removed after upload.
"""

FINISHED = """
 Everything done.
 Thank you for participating! Closing in 5 seconds.
"""

PLAYER_PERFORMANCE_QUERY = """
 Please provide your estimated familiarity with first-person shooter (FPS) games.
    1: I have very little experience with FPS games (less than a hour of experience)
    2: I am familiar with FPS games but do not actively play them (1 - 10 hours of experience)
    3: I am an experienced FPS player (10 - 100 hours of experience)
    4: I am a very experienced FPS player (above 100 hours of experience)
"""

NUMBER_OF_EPISODES = 6
# 10 minutes
EPISODE_LENGTH_10MIN = 35 * 60 * 10
# 2.5 minutes
EPISODE_LENGTH_2ANDHALFMIN = int(35 * 60 * 2.5)

MAPS = ["map03"] * NUMBER_OF_EPISODES

def main_data_collection():
    os.system("cls")
    print(AGREEMENT)
    agreement = ""
    while agreement != "i agree" and agreement != "quit":
        agreement = input(" >>> ").lower()
    if agreement == "quit":
        exit(0)

    # Continue to instrunctions etc
    os.system("cls")
    print(INSTRUCTIONS)
    input()

    # Ask for the player's performance-level
    os.system("cls")
    print(PLAYER_PERFORMANCE_QUERY)
    player_fps_familiarity = None
    while player_fps_familiarity is None:
        input_str = input(" Give your answer (single digit in 1 - 4): ")
        try:
            input_int = int(input_str)
            if input_int in [1, 2, 3, 4]:
                player_fps_familiarity = input_int
        except Exception:
            pass

    os.system("cls")
    print(
        " You will now proceed to play the games. You will start with two practice games:\n"
        "    1. Without aimbot (10min)\n"
        "    2. With aimbot (10min)\n"
        " The remaining four games (2.5min) will have random aimbots enabled.\n"
        " Your performance will only be recorded in the last four games.\n"
        " Press ENTER to start the first game."
    )
    input()

    # Create the set of aimbots
    recording_aimbots = [None, "ease_light", "ease_strong", "gan_group0"]
    random.shuffle(recording_aimbots)
    aimbots = [None, "ease_light"] + recording_aimbots

    episode_lengths = [
        EPISODE_LENGTH_10MIN,
        EPISODE_LENGTH_10MIN,
        EPISODE_LENGTH_2ANDHALFMIN,
        EPISODE_LENGTH_2ANDHALFMIN,
        EPISODE_LENGTH_2ANDHALFMIN,
        EPISODE_LENGTH_2ANDHALFMIN,
    ]

    # Play games to create recordings
    play_and_record_episodes(
        NUMBER_OF_EPISODES,
        MAPS,
        aimbots,
        "recording",
        timeout=episode_lengths,
        additional_data={"player-fps-familiarity": player_fps_familiarity}
    )

    print(AFTER_GAMES)
    input()

    # Upload recordings to the server
    print("[NOTE] No data uploading in shared code")

    print(FINISHED)
    sleep(5)


if __name__ == '__main__':
    import sys

    # Workaround for pyinstaller:
    # Some of the local files are in
    # the temp folder used by pyinstaller,
    # so we need to navigate there.
    # Stackoverflow #57480958
    if hasattr(sys, "_MEIPASS"):
        os.chdir(sys._MEIPASS)

    main_data_collection()

```

`data_collection_recording.py`:

```py
#!/usr/bin/env python3
#
# data_collection_recording.py
# Main entrypoint for datacollection (for recording videos with different videos)
#
import os
from recording import play_and_record_episodes
from time import sleep

import random

AGREEMENT = """
 Machine learning versus machine learning: Case of aimbots.
 Organizer: Anssi Kanervisto (anssk@uef.fi)
            School of Computing, University of Eastern Finland
 ------------------------------------------------------------------------------
 BACKGROUND

 Terms:
     "Cheating": When a video-game player uses software ("cheat") to gain
                 an unfair advantage over other players.
     "Aimbot":   Particular cheat which assists player with aiming at
                 enemy players.

 Purpose of this study is two-fold:
     1) Detecting aimbot software from player's mouse
        movement using machine learning techniques
     2) Applying machine learning techniques to create
        aimbot that is not distinguishable from human players.

     Goal is to obtain public knowledge on such cheats, which can then
     be used to create better anti-cheating software.

 What data will be collected and how:
     In these experiments, you will play a game of Doom (1993)
     against computer-players. In some of the games, your aim
     will be assisted by software ("aimbot").
     The software will record your keypresses and mouse movement
     in the game.

     A hardware identifier of your machine will be included in the data.

     All data will be anonymous and no private information will be
     collected.

 How this data will be used:
     The recorded data will be used to...

     1) ... evaluate the quality of the aimbots against human judges.
            The (anonymous) recorded gameplay will be shown to experienced
            game server admins and they will judge if gameplay should be
            considered suspicious (i.e. player is using a cheat) or not.

     This data may be released to the public.

     This data may be used in future research.

 Requirements:
     - A separate mouse (not a trackpad/mousepad)
     - 20 minutes of uninterrupted time (you can not pause the experiment)

 ------------------------------------------------------------------------------
 AGREEMENT

 By agreeing you:
     - ... confirm you recognize what data will be collected and how
       it will be used (scroll up).
     - ... are 18 years old or above.
     - ... fulfil the requirements (see above).
     - ... acknowledge there is no compensation.
     - ... acknowledge your participation is voluntary and you may withdraw at
       any point before end of the experiment.

 Input 'I agree' to continue, "quit" to close this software."""

INSTRUCTIONS = """
 INSTRUCTIONS

     This experiment will take 20 minutes, and consists
     of four 5-minute games of Doom (1993).

     Your goal is to score frags by shooting the enemies.
     You will find different weapons on the map, as well
     ammo for them and health/armor kits.

     For each game you will aimbot on or off, automatically
     set by this software. If aimbot is enabled, your aim will
     "home in" in to enemy targets once they are close enough
     to your crosshair.

     Try to appear as innocent as possible. That is: even with
     aimbot enabled, try to appear as if no aimbot were enabled.
     Pretend you are playing against other human players and
     you are cheating with the aimbot, and you have to avoid
     getting caught for using a cheat.

     Once all games are finished, you will have to provide
     the host of the experiment with the files this records.

     NOTE: Avoid opening the menu (ESC) and unfocusing the window
           (clicking outside the game window or changing window)

 BUTTONS

     WASD:             Forward, left, backward and right
     SHIFT:            Run (hold down to move faster)
     Mouse:            Aim
     Left-mouse click: Shoot
     Scroll up/down:   Change weapon

     Note that you can also aim up/down.

 Press ENTER to start the game"""

AFTER_GAMES = """
 Games finished.
 [NOTE] There is no data uploading in shared code.
 Thank you for participating!
"""


NUMBER_OF_EPISODES = 4
# 5 minutes
EPISODE_LENGTH = 35 * 60 * 5

MAPS = ["map03"] * NUMBER_OF_EPISODES

AIMBOTS = [None, "ease_light", "ease_strong", "gan_group0"]
# Shuffle the aimbots so the ordering is not known
random.shuffle(AIMBOTS)


def main_data_collection():
    os.system("cls")
    print(AGREEMENT)
    agreement = ""
    while agreement != "i agree" and agreement != "quit":
        agreement = input(" >>> ").lower()
    if agreement == "quit":
        exit(0)

    # Continue to instrunctions etc
    os.system("cls")
    print(INSTRUCTIONS)
    input()

    # Play games to create recordings
    play_and_record_episodes(
        NUMBER_OF_EPISODES,
        MAPS,
        AIMBOTS,
        "recording",
        timeout=EPISODE_LENGTH,
        record_video=True
    )

    print(AFTER_GAMES)


if __name__ == '__main__':
    import sys
    import glob
    import shutil

    original_dir = os.path.abspath(os.curdir)

    # Workaround for pyinstaller:
    # Some of the local files are in
    # the temp folder used by pyinstaller,
    # so we need to navigate there.
    # Stackoverflow #57480958
    if hasattr(sys, "_MEIPASS"):
        os.chdir(sys._MEIPASS)

    main_data_collection()

    # Move all data back to original location
    recordings = glob.glob("*_episode*")
    for recording in recordings:
        shutil.move(recording, os.path.join(original_dir, os.path.basename(recording)))

```

`feature_extraction.py`:

```py
#!/usr/bin/env python3
#
# feature_extraction.py 
# Turn player trajectories into features for 
# ML methods to classify to non-cheater / cheater
#
import math as m
import numpy as np
import json
import argparse
import os

parser = argparse.ArgumentParser("Player trajectories into ML features for classification")
parser.add_argument("method", choices=["vacnet"])
parser.add_argument("--vacnet_num_shots_per_feature", type=int, default=1)
parser.add_argument("--vacnet_hor_only", action="store_true")
parser.add_argument("--verbose", action="store_true")
parser.add_argument("gameplay_files", nargs="+")
parser.add_argument("output")

WIDTH = 640
HEIGHT = 480

# Match with CROSSHAIR_X/Y defined
# during recording
CROSSHAIR_Y = 201
CROSSHAIR_X = 320

# Maps weapon number to ammo per shot
# (e.g. super-shotgun uses two per shot)
WEAPON_TO_AMMO_PER_SHOT = {
    1: 1, # Fists
    2: 1, # Pistol
    3: 2, # Shotgun
    4: 1, # Minigun
    5: 1, # Rocket launcher
    6: 1, # Plasmagun
}

# Skip these weapons (do not include their
# shots in the features)
SKIP_WEAPONS = [
    5, # Rocket launcher
    6, # Plasmagun
]

# VACNet extraction default params
VACNET_SECONDS_BEFORE_SHOT = 1/2
VACNET_SECONDS_AFTER_SHOT  = 1/4

# Aimangle delta indexes in actions
AIMANGLE_DELTA_YAW_IDX = 4
AIMANGLE_DELTA_PITCH_IDX = 5

def extract_vacnet(episode_data, shots_per_feature, hor_only=False):
    """
    Do vacnet type of extraction on one episode of data.
    Returns numpy array of N x D of input features.

    Note: Features are in form 
        (dx1, dx2, dx3, ... , dy1, dy2, dy3, ... , is_hit)
    
    Source: (https://www.youtube.com/watch?v=ObhK8lUfIlc).
    Note: We do not include selected weapon
    """
    
    episode_length = len(episode_data["ammos"])
    frames_before_shot = int(VACNET_SECONDS_BEFORE_SHOT * 35)
    frames_after_shot  = int(VACNET_SECONDS_AFTER_SHOT  * 35)

    # Find indexes where shots happened
    shot_idxs = []
    ammos = episode_data["ammos"]
    weaps = episode_data["weapons"]
    last_ammo = None
    for i in range(1,episode_length):
        current_weapon = int(weaps[i])
        # Do not continue checking if this is a weapon
        # we should skip
        if current_weapon in SKIP_WEAPONS: continue
        # A shot: When number of 
        # ammo changed according per ammo_per_shot
        if (ammos[i - 1] - ammos[i]) == WEAPON_TO_AMMO_PER_SHOT[current_weapon]:
            # A shot
            shot_idxs.append(i)

    # For each shot, gather mouse movement before and 
    # after the shot, and include if it was a hit
    features = []
    yaw_deltas =   [action[AIMANGLE_DELTA_YAW_IDX] for action in  episode_data["actions"]]
    pitch_deltas = [action[AIMANGLE_DELTA_PITCH_IDX] for action in  episode_data["actions"]]
    damages = episode_data["damages"]
    for shot_idx in shot_idxs:
        a_hit = int(damages[shot_idx] != damages[shot_idx - 1])
        # Gather angle changes
        yaws = yaw_deltas[shot_idx - frames_before_shot : shot_idx + frames_after_shot]
        pitches = pitch_deltas[shot_idx - frames_before_shot : shot_idx + frames_after_shot]
        # Make sure we always have same-length frames
        if len(yaws) == (frames_before_shot + frames_after_shot):
            if hor_only:
                features.append(yaws + [a_hit])
            else:
                features.append(yaws + pitches + [a_hit])

    # Now take features of successive shots and combine them into
    # one feature (takes up space but easiest this way)
    successive_features = []
    for i in range(shots_per_feature, len(features)):
        successive_features.append(features[i - shots_per_feature:i])
    successive_features = np.array(successive_features)
    # Ravel extra dimension we have
    successive_features = successive_features.reshape((len(successive_features), -1))

    return successive_features

def main(args):
    gameplay_files = args.gameplay_files

    all_features   = []
    # 1 = cheating, 0 = legit
    all_labels     = []
    aimbot_classes = []

    for gameplay_file in gameplay_files:
        features = None
        data = json.load(open(gameplay_file, "r"))
        if args.method == "vacnet":
            features = extract_vacnet(data, args.vacnet_num_shots_per_feature, args.vacnet_hor_only)
        cheating = int(data["aimbot"] is not None and data["aimbot"] != "none")
        
        aimbot_class = 0
        if cheating:
            if data["aimbot"] == "ease_light":
                aimbot_class = 1
            elif data["aimbot"] == "ease_strong":
                aimbot_class = 2
            # GAN splitting
            elif data["aimbot"] == "gan_group0":
                aimbot_class = 10
            elif data["aimbot"] == "gan_group1":
                aimbot_class = 11

        all_features.append(features)
        all_labels.extend([cheating]*len(features))
        aimbot_classes.extend([aimbot_class]*len(features))

        if args.verbose:
            print("%s: %d features of label %d" % (gameplay_file, len(features), cheating))

    all_features = np.vstack(all_features)
    all_labels = np.array(all_labels).astype(np.int)
    aimbot_classes = np.array(aimbot_classes).astype(np.int)

    if args.verbose:
        print("Total legit:    %d (%.2f)" % (np.sum(all_labels == 0), 1 - np.mean(all_labels)))
        print("Total cheating: %d (%.2f)" % (np.sum(all_labels), np.mean(all_labels)))
        print("Total samples:  %d" % len(all_labels))

    np.savez(args.output, features=all_features, labels=all_labels, aimbot_class=aimbot_classes)

if __name__ == '__main__':
    args = parser.parse_args()
    main(args)

```

`plot.py`:

```py
#
# plot.py
# Visualizing data from different scripts
#
import os
from argparse import ArgumentParser

import numpy as np


def standardize_score_format(scores):
    """
    Get a ndarray of scores and
    convert them into (N, 2)
    scores, where first is "likelihood"
    for bona fide player and second
    is for cheating player.
    """
    if scores.ndim == 1:
        # Assume we have binary classification.
        # Turn this into 0.0 / 1.0 scores
        one_hot = np.eye(2)
        scores = one_hot[scores]
    return scores


def plot_classification_results(unparsed_args):
    parser = ArgumentParser("Go through classification score files and report results (see classification.py)")
    parser.add_argument("--inputs", type=str, required=True, nargs="+", help="Score .npz files to plot")
    parser.add_argument("output", type=str, help="Where to store store plots")
    args = parser.parse_args(unparsed_args)

    names = []
    datas = []
    for input_path in args.inputs:
        names.append(os.path.basename(input_path))
        data = np.load(input_path)
        data = dict(**data)
        # Standardize the score type, since some
        # classifiers only give fixed scores
        data["train_scores"] = standardize_score_format(data["train_scores"])
        data["test_scores"] = standardize_score_format(data["test_scores"])
        datas.append(data)

    # Print accuracies
    print("---Accuracies (balanced, argmax)---")
    print("{:<30} {:<10} {:<10}".format("Name", "Train", "Test"))
    for name, data in zip(names, datas):
        train_prediction = np.argmax(data["train_scores"], axis=1)
        train_labels = data["train_labels"]
        train_accuracy = (
            (1 - train_labels.mean()) * train_prediction[train_labels == 1].mean() +
            train_labels.mean() * (1 - train_prediction[train_labels == 0]).mean()
        )
        test_prediction = np.argmax(data["test_scores"], axis=1)
        test_labels = data["test_labels"]
        test_accuracy = (
            (1 - test_labels.mean()) * test_prediction[test_labels == 1].mean() +
            test_labels.mean() * (1 - test_prediction[test_labels == 0]).mean()
        )

        print("{:<30} {:<10.2f} {:<10.2f}".format(name, train_accuracy * 100, test_accuracy * 100))


AVAILABLE_OPERATIONS = {
    "classification-results": plot_classification_results,
}


if __name__ == '__main__':
    parser = ArgumentParser("Different plot utils")
    parser.add_argument("operation", choices=list(AVAILABLE_OPERATIONS.keys()), help="Operation to run")
    args, unparsed_args = parser.parse_known_args()

    operation_fn = AVAILABLE_OPERATIONS[args.operation]
    operation_fn(unparsed_args)

```

`plot_paper.py`:

```py
#
# plot_paper.py
# Hardcoded functions for plotting the final
# plots for the paper
#
import os
import pickle
from argparse import ArgumentParser
from glob import glob
import random
import json

import numpy as np
from matplotlib import pyplot
import sklearn.metrics
import scipy
from scipy.stats import ttest_ind

# Different directories.
# The non-GAN folders contain data from the first data collection
RECORDINGS_DIR = "data/data_collection_1"
GAN_RECORDINGS_DIR = "data/data_collection_2"
PERFORMANCE_RECORDINGS_DIR = "data/data_collection_3"
FEATURES_DIR = "features"
GAN_FEATURES_DIR = "gan_features"
HUMAN_GRADING_DIR = "data/data_collection_5"

# Aimangle delta indexes in actions
AIMANGLE_DELTA_YAW_IDX = 4
AIMANGLE_DELTA_PITCH_IDX = 5

# Mapping from aimbot_class integer to name of the aimbot
AIMBOT_FILE_NAMES = {
    0: None,
    1: "ease_light",
    2: "ease_strong",
    3: "gan",
    4: "gan_light",
    10: "gan_group0",
    11: "gan_group1"
}
AIMBOT_NAMES = {
    0: "None",
    1: "Light",
    2: "Strong",
    3: "GAN Strong",
    4: "GAN Light",
    10: "GAN (Group1)",
    11: "GAN (Group2)"
}

# Plotting constants
TITLE_KWARGS = dict(fontsize=27)
LEGEND_KWARGS = dict(fontsize=22)
TICK_PARAMS_KWARGS = dict(axis='both', which='both', labelsize=23)
LABEL_KWARGS = dict(fontsize=27)

# Colors the worst case -> known attack -> oracle -> best case lines
SCENARIO_COLORS = ["C3", "C1", "C0", "C2"]


def compute_fpr_fnr(bona_fide_scores, aimbot_scores):
    """
    Compute and return FPR and FNR points
    for system with given bona_fide (non-target)
    and aimbot (target) scores.
    Returns two arrays: fpr and fnr.
    """
    labels = np.concatenate(
        (
            np.zeros((bona_fide_scores.shape[0],)),
            np.ones((aimbot_scores.shape[0],))
        )
    ).astype(np.int64)
    all_scores = np.concatenate((bona_fide_scores, aimbot_scores))

    fpr, fnr, thresholds = sklearn.metrics.det_curve(labels, all_scores)
    return fpr, fnr


def compute_mindcf_eer(bona_fide_scores, aimbot_scores, hacker_prior):
    """
    Compute min DCF and EER of given bona fide (non-target) and hacker
    scores (target) under the given hacker_prior.
    Returns minDCF and eer (scalars).
    """
    # Import SIDEKIT here to avoid importing it when library is imported
    import sidekit

    # fast_minDCF function will take sigmoid of the prior,
    # so we take the inverse here (logit)
    logit_hacker_prior = np.log(hacker_prior / (1 - hacker_prior))

    results = sidekit.bosaris.fast_minDCF(aimbot_scores, bona_fide_scores, logit_hacker_prior, normalize=True)
    mindcf = results[0]
    eer = results[-1]
    return mindcf, eer


def print_metrics():
    """
    Calculate EERs and MinDCFs for the
    different scenarios
    """
    original_data = np.load("classification_results/dnn_scores.npz")
    worst_case = np.load("evaluation_scores/worst_case.npz")

    worst_case_scores = np.concatenate([data["test_scores"] for data in [original_data, worst_case]], axis=0)
    worst_case_aimbots = np.concatenate([data["test_aimbots"] for data in [original_data, worst_case]], axis=0)
    worst_case_data = {"test_scores": worst_case_scores, "test_aimbots": worst_case_aimbots}

    group1_data = np.load("evaluation_scores/known_attack_group1.npz")
    group2_data = np.load("evaluation_scores/known_attack_group2.npz")

    best_case_data = np.load("evaluation_scores/best_case.npz")

    train_light_data = np.load("evaluation_scores/trained_on_light.npz")
    train_strong_data = np.load("evaluation_scores/trained_on_strong.npz")
    best_case_original = np.load("evaluation_scores/best_case_original.npz")

    # We need to go over:
    # - Different aimbots (light, strong, gan1 and gan2)
    # - Different scenarios (worst-case, best case etc)
    # - EER and DCF
    # - Different priors for DCF
    # EER and DCF on x-axis
    # aimbots and scenarios on y-axis
    P_HACKERS = [0.5, 0.25, 0.1, 0.01]

    header_print_template = "{:<15}  {:<15}  {:<15}  {:<15}  {:<15}  {:<15}  {:<15}"
    print_template = "{:<15}& {:<15}& {:<15.2f}& {:<15.4f}& {:<15.4f}& {:<15.4f}& {:<15.4f}"

    # Print header
    print(header_print_template.format(
        *[
            "Aimbot",
            "Scenario",
            "EER(%)",
        ] + ["minDCF(p={})".format(p) for p in P_HACKERS]
    ))

    # Maps scenario name to mapping, that tells
    # which data should be used for aimbot
    scenarios = {
        "Worst-case": {
            # Nothing for light and strong aimbot here
            10: worst_case_data,
            11: worst_case_data
        },
        "Known-attack": {
            1: train_strong_data,
            2: train_light_data,
            10: group2_data,
            11: group1_data
        },
        "Oracle": {
            1: train_light_data,
            2: train_strong_data,
            10: group1_data,
            11: group2_data
        },
        "Train-on-test": {
            1: best_case_original,
            2: best_case_original,
            10: best_case_data,
            11: best_case_data
        },
    }

    for aimbot_class in [1, 2, 10, 11]:
        for scenario_name, scenario_mapping in scenarios.items():
            data = scenario_mapping.get(aimbot_class)
            if data is None:
                # Print emptys
                print(print_template.format(AIMBOT_NAMES[aimbot_class], scenario_name, *([np.nan] * (len(P_HACKERS) + 1))))
                continue
            bona_fide_scores = data["test_scores"][data["test_aimbots"] == 0, 1]
            aimbot_scores = data["test_scores"][data["test_aimbots"] == aimbot_class, 1]

            eer = None
            mindcfs = []
            for p_hacker in P_HACKERS:
                # EER will always be same so we can just
                # use the latest
                mindcf, eer = compute_mindcf_eer(bona_fide_scores, aimbot_scores, p_hacker)
                mindcfs.append(mindcf)
            eer = eer * 100

            # Remove whitespaces for spreadsheets not to flip out
            aimbot_name = AIMBOT_NAMES[aimbot_class].replace(" ", "")
            print(print_template.format(aimbot_name, scenario_name, eer, *mindcfs))


def plot_dets():
    """
    Plot the DET curves for classifier
    accuracy with and without GAN aimbots etc.

    Assume GAN classifiers have been trained and evaluated,
    and that results are in evaluation_scores.

    DET plotting code and adjustments are taken from scikit-learn:
    https://github.com/scikit-learn/scikit-learn/blob/main/sklearn/metrics/_plot/det_curve.py
    """

    DET_TICKS = [0.001, 0.01, 0.05, 0.20, 0.5, 0.80, 0.95, 0.99, 0.999]
    DET_TICKS_LOCATIONS = scipy.stats.norm.ppf(DET_TICKS)

    def adjust_ax_for_det(ax):
        """Adjust given axis to pretty-show DET plots"""
        # Code copied directly from the scikit-learn det_curve.py
        tick_labels = [
            '{:.0f}'.format(100 * s) for s in DET_TICKS
        ]
        ax.set_xticks(DET_TICKS_LOCATIONS)
        ax.set_xticklabels(tick_labels)
        ax.set_xlim(-3, 3)
        ax.set_yticks(DET_TICKS_LOCATIONS)
        ax.set_yticklabels(tick_labels)
        ax.set_ylim(-3, 3)

    original_data = np.load("classification_results/dnn_scores.npz")
    worst_case = np.load("evaluation_scores/worst_case.npz")

    worst_case_scores = np.concatenate([data["test_scores"] for data in [original_data, worst_case]], axis=0)
    worst_case_aimbots = np.concatenate([data["test_aimbots"] for data in [original_data, worst_case]], axis=0)
    worst_case_data = {"test_scores": worst_case_scores, "test_aimbots": worst_case_aimbots}

    group1_data = np.load("evaluation_scores/known_attack_group1.npz")
    group2_data = np.load("evaluation_scores/known_attack_group2.npz")

    best_case_data = np.load("evaluation_scores/best_case.npz")

    train_light_data = np.load("evaluation_scores/trained_on_light.npz")
    train_strong_data = np.load("evaluation_scores/trained_on_strong.npz")
    best_case_original = np.load("evaluation_scores/best_case_original.npz")

    fig, axs = pyplot.subplots(
        nrows=1,
        ncols=3,
        sharey="row",
        sharex="row",
        figsize=[3 * 6.4, 1 * 6.4]
    )

    # First plot: Original aimbots + GANs without training
    ax = axs[0]
    ax.grid(alpha=0.2)
    # Human scores are the second scores.
    for aimbot_class in [1, 2]:
        for i, data in enumerate([train_light_data, train_strong_data, best_case_original]):
            bona_fide_scores = data["test_scores"][data["test_aimbots"] == 0, 1]
            aimbot_scores = data["test_scores"][data["test_aimbots"] == aimbot_class, 1]
            fpr, fnr = compute_fpr_fnr(bona_fide_scores, aimbot_scores)
            style = "-" if aimbot_class == 1 else "--"
            # Special handling: For light aimbot
            # we need to flip the known-attack/oracle colors
            c = SCENARIO_COLORS[i + 1]
            if aimbot_class == 1:
                if i == 0:
                    # Oracle
                    c = SCENARIO_COLORS[2]
                elif i == 1:
                    # Known attack
                    c = SCENARIO_COLORS[1]

            ax.plot(
                scipy.stats.norm.ppf(fpr),
                scipy.stats.norm.ppf(fnr),
                c=SCENARIO_COLORS[i + 1],
                linestyle=style
            )
    ax.tick_params(**TICK_PARAMS_KWARGS)
    # Create bit wonkier legends
    lines = []
    legends = []
    legend_lines = [
        {"c": SCENARIO_COLORS[1], "style": "-", "name": "Known-attack"},
        {"c": SCENARIO_COLORS[2], "style": "-", "name": "Oracle"},
        {"c": SCENARIO_COLORS[3], "style": "-", "name": "Train-on-test"},
        # Super pretty way of doing an empty space in legend
        # Stackoverflow #28078846
        {"c": "w", "style": "-", "name": ""},
        {"c": "k", "style": "-", "name": "Light"},
        {"c": "k", "style": "--", "name": "Strong"},
    ]
    for legend_line in legend_lines:
        line, = ax.plot(fpr, fnr, c=legend_line["c"], linestyle=legend_line["style"])
        # Do not show in the plot
        line.remove()
        lines.append(line)
        legends.append(legend_line["name"])
    adjust_ax_for_det(ax)
    ax.legend(lines, legends, **LEGEND_KWARGS)
    ax.set_xlabel("False Positive Rate (%)", **LABEL_KWARGS)
    ax.set_ylabel("False Negative Rate (%)", **LABEL_KWARGS)
    ax.set_title("Heuristic aimbots", **TITLE_KWARGS)

    # Second plot: Group 1 results
    ax = axs[1]
    ax.grid(alpha=0.2)
    for aimbot_class in [10]:
        for i, data in enumerate([worst_case, group2_data, group1_data, best_case_data]):
            bona_fide_scores = data["test_scores"][data["test_aimbots"] == 0, 1]
            aimbot_scores = data["test_scores"][data["test_aimbots"] == aimbot_class, 1]
            fpr, fnr = compute_fpr_fnr(bona_fide_scores, aimbot_scores)
            ax.plot(
                scipy.stats.norm.ppf(fpr),
                scipy.stats.norm.ppf(fnr),
                c=SCENARIO_COLORS[i]
            )
    adjust_ax_for_det(ax)
    ax.tick_params(**TICK_PARAMS_KWARGS)
    ax.legend(["Worst-case", "Known attack", "Oracle", "Train-on-test"], **LEGEND_KWARGS)
    ax.set_xlabel("False Positive Rate (%)", **LABEL_KWARGS)
    ax.set_title("GAN, Group 1", **TITLE_KWARGS)

    # Third plot: Group 2 results
    ax = axs[2]
    ax.grid(alpha=0.2)
    for aimbot_class in [11]:
        for i, data in enumerate([worst_case_data, group1_data, group2_data, best_case_data]):
            bona_fide_scores = data["test_scores"][data["test_aimbots"] == 0, 1]
            aimbot_scores = data["test_scores"][data["test_aimbots"] == aimbot_class, 1]
            fpr, fnr = compute_fpr_fnr(bona_fide_scores, aimbot_scores)
            ax.plot(
                scipy.stats.norm.ppf(fpr),
                scipy.stats.norm.ppf(fnr),
                c=SCENARIO_COLORS[i]
            )
    adjust_ax_for_det(ax)
    ax.tick_params(**TICK_PARAMS_KWARGS)
    ax.legend(["Worst-case", "Known attack", "Oracle", "Train-on-test"], **LEGEND_KWARGS)
    ax.set_xlabel("False Positive Rate (%)", **LABEL_KWARGS)
    ax.set_title("GAN, Group 2", **TITLE_KWARGS)

    fig.tight_layout()
    fig.savefig("figures/dets.pdf", bbox_inches="tight", pad_inches=0.0)


def print_player_stats():
    """
    Go through recordings and extracted features, and print
    out player accuracy/performance (frags) with and without
    different aimbots
    """
    from feature_extraction import extract_vacnet

    # Assumes:
    #  - Performance recordings are in "performance_recordings/..."

    data_files = glob(os.path.join(PERFORMANCE_RECORDINGS_DIR, "*.json"))

    no_aimbot_frags = []
    light_aimbot_frags = []
    strong_aimbot_frags = []
    gan_aimbot_frags = []

    no_aimbot_accuracy = []
    light_aimbot_accuracy = []
    strong_aimbot_accuracy = []
    gan_aimbot_accuracy = []

    no_aimbot_weapon_distribution = []
    light_aimbot_weapon_distribution = []
    strong_aimbot_weapon_distribution = []
    gan_aimbot_weapon_distribution = []

    for filename in data_files:
        # Skip first two games which were used for warming up
        if "episode0" in filename or "episode1" in filename:
            continue
        data = json.load(open(filename, "rb"))
        frags = data["frags"][-1]
        aimbot = data["aimbot"]
        weapons = data["weapons"]
        weapons = np.eye(6)[np.array(weapons).astype(np.int) - 1]
        features = extract_vacnet(data, shots_per_feature=1, hor_only=False)
        hits = features[:, -1]
        accuracy = hits.mean()
        if aimbot == None:
            no_aimbot_frags.append(frags)
            no_aimbot_accuracy.append(accuracy)
            no_aimbot_weapon_distribution.append(weapons.mean(axis=0))
        elif aimbot == "ease_light":
            light_aimbot_frags.append(frags)
            light_aimbot_accuracy.append(accuracy)
            light_aimbot_weapon_distribution.append(weapons.mean(axis=0))
        elif aimbot == "ease_strong":
            strong_aimbot_frags.append(frags)
            strong_aimbot_accuracy.append(accuracy)
            strong_aimbot_weapon_distribution.append(weapons.mean(axis=0))
        elif aimbot == "gan_group0":
            gan_aimbot_frags.append(frags)
            gan_aimbot_accuracy.append(accuracy)
            gan_aimbot_weapon_distribution.append(weapons.mean(axis=0))
        else:
            raise ValueError("Unknown aimbot type {}".format(aimbot))

    assert len(no_aimbot_accuracy) == len(light_aimbot_accuracy) == len(strong_aimbot_accuracy) == len(gan_aimbot_accuracy)

    print("N={}".format(len(no_aimbot_frags)))

    print("no-aimbot frags:           {}".format(no_aimbot_frags))
    print("light-aimbot game frags:   {}".format(light_aimbot_frags))
    print("strong-aimbot game frags:  {}".format(strong_aimbot_frags))
    print("gan-aimbot game frags:     {}".format(gan_aimbot_frags))

    print("\nMean no-aimbot frags:           {:2.4f} +/- {:2.4f}".format(np.mean(no_aimbot_frags), np.std(no_aimbot_frags)))
    print("Mean light-aimbot game frags:   {:2.4f} +/- {:2.4f}".format(np.mean(light_aimbot_frags), np.std(light_aimbot_frags)))
    print("Mean strong-aimbot game frags:  {:2.4f} +/- {:2.4f}".format(np.mean(strong_aimbot_frags), np.std(strong_aimbot_frags)))
    print("Mean gan-aimbot game frags:     {:2.4f} +/- {:2.4f}".format(np.mean(gan_aimbot_frags), np.std(gan_aimbot_frags)))

    print("No vs. light-aimbot p-value:  {:.4f}".format(ttest_ind(no_aimbot_frags, light_aimbot_frags, equal_var=False, alternative="two-sided")[1]))
    print("No vs. strong-aimbot p-value: {:.4f}".format(ttest_ind(no_aimbot_frags, strong_aimbot_frags, equal_var=False, alternative="two-sided")[1]))
    print("No vs. gan-aimbot p-value:    {:.4f}".format(ttest_ind(no_aimbot_frags, gan_aimbot_frags, equal_var=False, alternative="two-sided")[1]))

    print("\nMean no-aimbot accuracy:           {:2.4f} +/- {:2.4f}".format(np.mean(no_aimbot_accuracy), np.std(no_aimbot_accuracy)))
    print("Mean light-aimbot game accuracy:   {:2.4f} +/- {:2.4f}".format(np.mean(light_aimbot_accuracy), np.std(light_aimbot_accuracy)))
    print("Mean strong-aimbot game accuracy:  {:2.4f} +/- {:2.4f}".format(np.mean(strong_aimbot_accuracy), np.std(strong_aimbot_accuracy)))
    print("Mean gan-aimbot game accuracy:     {:2.4f} +/- {:2.4f}".format(np.mean(gan_aimbot_accuracy), np.std(gan_aimbot_accuracy)))

    print("No vs. light-aimbot p-value:  {:.4f}".format(ttest_ind(no_aimbot_accuracy, light_aimbot_accuracy, equal_var=False, alternative="two-sided")[1]))
    print("No vs. strong-aimbot p-value: {:.4f}".format(ttest_ind(no_aimbot_accuracy, strong_aimbot_accuracy, equal_var=False, alternative="two-sided")[1]))
    print("No vs. gan-aimbot p-value:    {:.4f}".format(ttest_ind(no_aimbot_accuracy, gan_aimbot_accuracy, equal_var=False, alternative="two-sided")[1]))

    print("\n                            Fist Pist Shot Mini Rock Plas")
    print("Mean no-aimbot weapons:     {:.2f} {:.2f} {:.2f} {:.2f} {:.2f} {:.2f}".format(*np.mean(no_aimbot_weapon_distribution, axis=0).tolist()))
    print("Mean light-aimbot weapons:  {:.2f} {:.2f} {:.2f} {:.2f} {:.2f} {:.2f}".format(*np.mean(light_aimbot_weapon_distribution, axis=0).tolist()))
    print("Mean strong-aimbot weapons: {:.2f} {:.2f} {:.2f} {:.2f} {:.2f} {:.2f}".format(*np.mean(strong_aimbot_weapon_distribution, axis=0).tolist()))
    print("Mean gan-aimbot weapons:    {:.2f} {:.2f} {:.2f} {:.2f} {:.2f} {:.2f}".format(*np.mean(gan_aimbot_weapon_distribution, axis=0).tolist()))



def player_performance_vs_detection():
    """
    Analyse correlation between player's bona fide performance
    and detectability with different aimbots (e.g., "will weaker players be easier to detect when using aimbot"?)
    """
    from feature_extraction import extract_vacnet
    import torch

    # Assumes:
    #  - Performance recordings are in "performance_recordings/..."

    TORCH_MODEL_PATH = "gan_classification_results/dnn_group0_model.pkl"
    DATA_NORMALIZATION_PATH = "gan_classification_results/feature_normalization.npz"

    data_files = glob(os.path.join(PERFORMANCE_RECORDINGS_DIR, "*.json"))
    normalization_stats = np.load(DATA_NORMALIZATION_PATH)
    model = torch.load(TORCH_MODEL_PATH)

    no_aimbot_frags = {}
    no_aimbot_accuracy = {}

    no_aimbot_detection_scores = {}
    light_aimbot_detection_scores = {}
    strong_aimbot_detection_scores = {}
    gan_aimbot_detection_scores = {}

    for filename in data_files:
        # Skip first two games which were used for warming up
        if "episode0" in filename or "episode1" in filename:
            continue
        player_id = "_".join(os.path.basename(filename).split("_")[:2])
        data = json.load(open(filename, "rb"))
        frags = data["frags"][-1]
        aimbot = data["aimbot"]
        weapons = data["weapons"]
        weapons = np.eye(6)[np.array(weapons).astype(np.int) - 1]
        features = extract_vacnet(data, shots_per_feature=1, hor_only=False)
        hits = features[:, -1]
        accuracy = hits.mean()
        normalized_features = (features - normalization_stats["means"]) / normalization_stats["stds"]
        scores = model(torch.from_numpy(normalized_features).float()).detach().numpy()[:, 1]
        mean_score = scores.mean()
        if aimbot == None:
            no_aimbot_frags[player_id] = frags
            no_aimbot_accuracy[player_id] = accuracy
            no_aimbot_detection_scores[player_id] = mean_score
        elif aimbot == "ease_light":
            light_aimbot_detection_scores[player_id] = mean_score
        elif aimbot == "ease_strong":
            strong_aimbot_detection_scores[player_id] = mean_score
        elif aimbot == "gan_group0":
            gan_aimbot_detection_scores[player_id] = mean_score
        else:
            raise ValueError("Unknown aimbot type {}".format(aimbot))

    assert len(no_aimbot_detection_scores) == len(light_aimbot_detection_scores) == len(strong_aimbot_detection_scores) == len(gan_aimbot_detection_scores)

    player_ids = list(no_aimbot_detection_scores.keys())
    no_aimbot_detection_scores = [no_aimbot_detection_scores[player_id] for player_id in player_ids]
    light_aimbot_detection_scores = [light_aimbot_detection_scores[player_id] for player_id in player_ids]
    strong_aimbot_detection_scores = [strong_aimbot_detection_scores[player_id] for player_id in player_ids]
    gan_aimbot_detection_scores = [gan_aimbot_detection_scores[player_id] for player_id in player_ids]
    no_aimbot_frags = [no_aimbot_frags[player_id] for player_id in player_ids]
    no_aimbot_accuracy = [no_aimbot_accuracy[player_id] for player_id in player_ids]

    fig, axs = pyplot.subplots(nrows=5, ncols=2, figsize=(5.0 * 2, 3.2 * 5))

    for colum_idx, frag_or_accuracy in enumerate(("Kills", "Accuracy")):
        no_aimbot_x_axis = no_aimbot_frags if frag_or_accuracy == "Kills" else no_aimbot_accuracy

        axs[0, colum_idx].scatter(no_aimbot_x_axis, no_aimbot_detection_scores, label="No Aimbot", color="blue")
        axs[0, colum_idx].scatter(no_aimbot_x_axis, light_aimbot_detection_scores, label="Light Aimbot", color="green")
        axs[0, colum_idx].scatter(no_aimbot_x_axis, strong_aimbot_detection_scores, label="Strong Aimbot", color="red")
        axs[0, colum_idx].scatter(no_aimbot_x_axis, gan_aimbot_detection_scores, label="GAN Aimbot", color="orange")
        axs[0, colum_idx].set_xlabel("{} (without aimbot)".format(frag_or_accuracy))
        axs[0, colum_idx].set_ylabel("Detection score\n(Higher = hacking)")
        axs[0, colum_idx].legend()

        axs[1, colum_idx].scatter(no_aimbot_x_axis, no_aimbot_detection_scores)
        axs[1, colum_idx].set_xlabel("{} (without aimbot)".format(frag_or_accuracy))
        axs[1, colum_idx].set_ylabel("Detection score\n(higher = hacking)")
        axs[1, colum_idx].set_title("No Aimbot (corr = {:.3f})".format(np.corrcoef(no_aimbot_x_axis, no_aimbot_detection_scores)[0, 1]))

        axs[2, colum_idx].scatter(no_aimbot_x_axis, light_aimbot_detection_scores)
        axs[2, colum_idx].set_xlabel("{} (without aimbot)".format(frag_or_accuracy))
        axs[2, colum_idx].set_ylabel("Detection score\n(higher = hacking)")
        axs[2, colum_idx].set_title("Light Aimbot (corr = {:.3f})".format(np.corrcoef(no_aimbot_x_axis, light_aimbot_detection_scores)[0, 1]))

        axs[3, colum_idx].scatter(no_aimbot_x_axis, strong_aimbot_detection_scores)
        axs[3, colum_idx].set_xlabel("{} (without aimbot)".format(frag_or_accuracy))
        axs[3, colum_idx].set_ylabel("Detection score\n(higher = hacking)")
        axs[3, colum_idx].set_title("Strong Aimbot (corr = {:.3f})".format(np.corrcoef(no_aimbot_x_axis, strong_aimbot_detection_scores)[0, 1]))

        axs[4, colum_idx].scatter(no_aimbot_x_axis, gan_aimbot_detection_scores)
        axs[4, colum_idx].set_xlabel("{} (without aimbot)".format(frag_or_accuracy))
        axs[4, colum_idx].set_ylabel("Detection score\n(higher = hacking)")
        axs[4, colum_idx].set_title("GAN Aimbot (corr = {:.3f})".format(np.corrcoef(no_aimbot_x_axis, gan_aimbot_detection_scores)[0, 1]))

    pyplot.tight_layout()
    fig.savefig("figures/player_performance_vs_detection.png", dpi=200)


def multi_vector_classification():
    """
    Analysis of doing classification with multiple data vectors
    """
    from classification import get_player_id
    import torch

    VECTOR_AMOUNTS = list(range(1, 81, 1))
    N_REPEATS = 200

    LINE_NAMES = [
        "Light",
        "Strong",
        "GAN"
    ]
    AIMBOT_CLASS = [
        1,
        2,
        10
    ]
    TORCH_MODEL_PATHS = [
        "gan_classification_results/dnn_aimbot1_model.pkl",
        "gan_classification_results/dnn_aimbot2_model.pkl",
        "gan_classification_results/dnn_group0_model.pkl"
    ]
    DATA_NORMALIZATION_PATH = "gan_classification_results/feature_normalization.npz"
    TRAIN_TEST_SPLIT_FILE = "gan_classification_results/train_test_split.pkl"
    normalization_stats = np.load(DATA_NORMALIZATION_PATH)

    testing_ids = None
    with open(TRAIN_TEST_SPLIT_FILE, "rb") as f:
        split_data = pickle.load(f)
        testing_ids = split_data["testing_ids"]

    # Line names -> {"bonafide": bonafide_scores, "hacking":aimbot_scores}
    line_scores = {}
    for line_name, aimbot_class, torch_model_path in zip(LINE_NAMES, AIMBOT_CLASS, TORCH_MODEL_PATHS):
        model = torch.load(torch_model_path)
        feature_files = glob(os.path.join("gan_classification_data", "*"))
        bonafide_player_scores = []
        hacking_player_scores = []

        for feature_file in feature_files:
            player_id = get_player_id(feature_file)
            if player_id not in testing_ids:
                continue
            data = np.load(feature_file)
            # Aimbot is same over all samples
            aimbot_type = int(data["aimbot_class"][0])
            features = data["features"]

            if aimbot_type not in [0, aimbot_class]:
                continue

            normalized_features = (features - normalization_stats["means"]) / normalization_stats["stds"]
            scores = model(torch.from_numpy(normalized_features).float()).detach().numpy()[:, 1]

            if aimbot_type == 0:
                bonafide_player_scores.append(scores.tolist())
            else:
                hacking_player_scores.append(scores.tolist())
        line_scores[line_name] = {"bonafide": bonafide_player_scores, "hacking": hacking_player_scores}

    # Now, for each "VECTOR_AMOUNTS" (number of points per player)
    # we repeat N_REPEATS times
    # we take vector_amount points per player by sampling, average scores and try to do classifying

    line_eers = dict((name, []) for name in LINE_NAMES)
    line_stds = dict((name, []) for name in LINE_NAMES)

    for n_vectors in VECTOR_AMOUNTS:
        for line_name in LINE_NAMES:
            bonafide_scores = line_scores[line_name]["bonafide"]
            hacking_scores = line_scores[line_name]["hacking"]
            eers = []
            for _ in range(N_REPEATS):
                average_bonafide_scores = [np.mean(random.sample(scores, n_vectors)) for scores in bonafide_scores]
                average_hacking_scores = [np.mean(random.sample(scores, n_vectors)) for scores in hacking_scores]
                mind_dcf, eer = compute_mindcf_eer(np.array(average_bonafide_scores), np.array(average_hacking_scores), 0.5)
                eers.append(eer * 100)
            line_eers[line_name].append(np.mean(eers))
            line_stds[line_name].append(np.std(eers))

    fig = pyplot.figure(figsize=[6.4 * 0.9, 4.8 * 0.55])
    ax = pyplot.gca()
    for line_name in LINE_NAMES:
        eers = np.array(line_eers[line_name])
        stds = np.array(line_stds[line_name])
        ax.plot(VECTOR_AMOUNTS, eers, label=line_name)
        ax.fill_between(VECTOR_AMOUNTS, np.clip(eers - stds, 0, None), eers + stds, alpha=0.2)
    ax.set_ylim(-2, 22)
    ax.grid(alpha=0.2)
    ax.legend(fontsize="large")
    ax.set_xlabel("Number of features per game", fontsize="x-large")
    ax.set_ylabel("Equal error rate (%)", fontsize="x-large")
    ax.tick_params(axis='both', which='both', labelsize="large")
    pyplot.tight_layout()
    fig.savefig("figures/multi_vector_classification.pdf", bbox_inches="tight", pad_inches=0.0)


def plot_mouse_analysis():
    """
    Analyze mouse movement of bona fide and hacking players
    """
    import matplotlib.colors as mcolors
    import scipy.stats

    AXIS_RANGE = 5

    # Load data
    recordings = glob(os.path.join(RECORDINGS_DIR, "*"))
    gan_recordings = glob(os.path.join(GAN_RECORDINGS_DIR, "*"))

    bona_fide_mouse_movement = []
    heuristic_aimbot_mouse_movement = []
    gan_aimbot_mouse_movement = []

    for filename in (recordings + gan_recordings):
        data = json.load(open(filename, "rb"))
        actions = data["actions"]
        # Take yaw and pitch
        mouse_movements = np.array([
            (a[AIMANGLE_DELTA_YAW_IDX], a[AIMANGLE_DELTA_PITCH_IDX]) for a in actions
        ])
        if "episode0" in filename or "episode1" in filename:
            # Bona fide gameplay
            bona_fide_mouse_movement.append(mouse_movements)
        else:
            if filename in recordings:
                # Heuristic aimbot
                heuristic_aimbot_mouse_movement.append(mouse_movements)
            else:
                gan_aimbot_mouse_movement.append(mouse_movements)

    bona_fide_individual_data = bona_fide_mouse_movement
    heuristic_aimbot_individual_data = heuristic_aimbot_mouse_movement
    gan_aimbot_individual_data = gan_aimbot_mouse_movement

    bona_fide_mouse_movement = np.concatenate(bona_fide_mouse_movement, axis=0)
    heuristic_aimbot_mouse_movement = np.concatenate(heuristic_aimbot_mouse_movement, axis=0)
    gan_aimbot_mouse_movement = np.concatenate(gan_aimbot_mouse_movement, axis=0)

    # Plot and print out some results
    figure, axs = pyplot.subplots(
        nrows=1,
        ncols=3,
        sharey="all",
        figsize=[4.8 * 3, 4.8]
    )

    # Put data and names in lists we will index in loop
    datas = [
        bona_fide_mouse_movement,
        heuristic_aimbot_mouse_movement,
        gan_aimbot_mouse_movement
    ]

    individual_datas = [
        bona_fide_individual_data,
        heuristic_aimbot_individual_data,
        gan_aimbot_individual_data
    ]

    titles = [
        "Bona fide",
        "Heuristic aimbot",
        "GAN aimbot"
    ]

    for i in range(3):
        data = datas[i]
        individual_data = individual_datas[i]
        title = titles[i]
        ax = axs[i]

        yaws = data[:, 0]
        pitches = data[:, 1]

        # Print out some basic stats
        print("Statistics for {}".format(title))
        print("\tYaw       {:2.4f} +/- {:2.4f}".format(yaws.mean(), yaws.std()))
        print("\tPitch     {:2.4f} +/- {:2.4f}".format(pitches.mean(), pitches.std()))
        print("\t|Yaw|     {:2.4f} +/- {:2.4f}".format(np.abs(yaws).mean(), np.abs(yaws).std()))
        print("\t|Pitch|   {:2.4f} +/- {:2.4f}".format(np.abs(pitches).mean(), np.abs(pitches).std()))
        print("\tCorr + p  {:.5f} ({:.5f})".format(*scipy.stats.pearsonr(np.abs(yaws), np.abs(pitches))))

        yaw_diff_corr = np.mean([scipy.stats.pearsonr(x[:-1, 0], x[1:, 0])[0] for x in individual_data])
        pitch_diff_corr = np.mean([scipy.stats.pearsonr(x[:-1, 1], x[1:, 1])[0] for x in individual_data])
        print("\tStep Corr  {:.5f} {:.5f}".format(yaw_diff_corr, pitch_diff_corr))
        print("\tStep Corr avg. {:.5f}".format((yaw_diff_corr + pitch_diff_corr) / 2))

        # Remove zero-movements from the plot
        zeros = (yaws == 0) & (pitches == 0)
        yaws = yaws[~zeros]
        pitches = pitches[~zeros]

        ax.hist2d(
            yaws,
            pitches,
            bins=50,
            range=((-AXIS_RANGE, AXIS_RANGE), (-AXIS_RANGE, AXIS_RANGE)),
            norm=mcolors.PowerNorm(0.5),
            density=True
        )
        ax.set_title(title)

    pyplot.tight_layout()
    figure.savefig("figures/mouse_dist.png", dpi=200)


def plot_trajectories():
    """
    Plot bunch of example trajectories from each aimbot category.
    """

    EXAMPLES_PER_CATEGORY = 10

    # Load data
    recordings = glob(os.path.join(FEATURES_DIR, "*"))
    gan_recordings = glob(os.path.join(GAN_FEATURES_DIR, "*"))

    bona_fide_features = []
    heuristic_aimbot_features = []
    gan_aimbot_features = []

    for filename in (recordings + gan_recordings):
        data = np.load(filename)
        features = data["features"]
        if "episode0" in filename or "episode1" in filename:
            # Bona fide gameplay
            bona_fide_features.append(features)
        elif "episode3" in filename and filename in recordings:
            # Add strong aimbots to heuristic aimbots
            heuristic_aimbot_features.append(features)
        elif "episode2" in filename and filename in recordings:
            # Skip light aimbots
            pass
        else:
            # Recording is from gan_aimbot
            gan_aimbot_features.append(features)

    bona_fide_features = np.concatenate(bona_fide_features, axis=0)
    heuristic_aimbot_features = np.concatenate(heuristic_aimbot_features, axis=0)
    gan_aimbot_features = np.concatenate(gan_aimbot_features, axis=0)

    figure, axs = pyplot.subplots(
        nrows=3,
        ncols=EXAMPLES_PER_CATEGORY,
        figsize=[4.8 * (EXAMPLES_PER_CATEGORY / 3), 4.8],
        sharex="none",
        sharey="none"
    )

    titles = [
        "Bona fide",
        "Strong\naimbot",
        "GAN\naimbot"
    ]

    datas = [
        bona_fide_features,
        heuristic_aimbot_features,
        gan_aimbot_features
    ]

    for type_i in range(3):
        data = datas[type_i]
        for example_i in range(EXAMPLES_PER_CATEGORY):
            ax = axs[type_i, example_i]
            # Pick random feature
            random_pick = data[random.randint(0, len(data) - 1)]

            # Turn the feature vector back into trajectory.
            # Assuming VAC-net-like features with a ton of hardcoding
            trajectory = np.array([random_pick[:25], random_pick[25:50]]).T
            trajectory = np.cumsum(trajectory, axis=0)
            # Center around the point where we shot
            trajectory -= trajectory[16]
            # Plot
            ax.plot(trajectory[:, 0], trajectory[:, 1], alpha=0.5)

            colors = ["g"] + (["b"] * 15) + ["m"] + (["b"] * 7) + ["r"]
            sizes = [50] + ([7] * 15) + [50] + ([7] * 7) + [50]
            ax.axis("equal")
            ax.set_xticks([])
            ax.set_yticks([])
            ax.scatter(trajectory[:, 0], trajectory[:, 1], s=sizes, c=colors)

            # Draw again but only important bits to overwrite over blues
            sizes = [50] + ([0] * 15) + [50] + ([0] * 7) + [50]
            ax.scatter(trajectory[:, 0], trajectory[:, 1], s=sizes, c=colors)

            if example_i == 0:
                # Add titles
                ax.set_ylabel(titles[type_i], fontsize=20)

    pyplot.tight_layout()
    pyplot.subplots_adjust(wspace=0.03)
    figure.savefig("figures/mouse_trajectories.pdf", bbox_inches="tight", pad_inches=0.0)


def plot_human_grading():
    """
    Plot the opinion-scores of the recordings being hackers.
    """

    ground_truth_data = json.load(open(os.path.join(HUMAN_GRADING_DIR, "ground_truth.json")))
    ground_truth_aimbots = [x["aimbot-name"] for x in ground_truth_data]
    ground_truth_aimbots = [x if x != "none" else None for x in ground_truth_aimbots]
    aimbot_file_names_transposed = dict((v, k) for k, v in AIMBOT_FILE_NAMES.items())
    ground_truth_aimbot_labels = [aimbot_file_names_transposed[x] for x in ground_truth_aimbots]
    ground_truth_aimbot_labels = np.array(ground_truth_aimbot_labels)

    # Load answers.
    # Assume answers in same order as the ground-truth items.
    # Also offset results to [0, 2].
    experienced_judge_answers = []
    fps_gamer_answers = []
    for filepath in glob(os.path.join(HUMAN_GRADING_DIR, "answers", "experienced_judges", "*")):
        experienced_judge_answers.append(np.loadtxt(filepath)[:, 1] - 1)
    for filepath in glob(os.path.join(HUMAN_GRADING_DIR, "answers", "fps_gamers", "*")):
        fps_gamer_answers.append(np.loadtxt(filepath)[:, 1] - 1)

    # Average/std of the grading
    experienced_judge_means = []
    experienced_judge_stds = []
    fps_gamer_means = []
    fps_gamer_stds = []
    aimbot_names = [
        "None",
        "GAN",
        "Light",
        "Strong",
    ]
    aimbot_labels = [
        aimbot_file_names_transposed[None],
        aimbot_file_names_transposed["gan_group0"],
        aimbot_file_names_transposed["ease_light"],
        aimbot_file_names_transposed["ease_strong"],
    ]

    # Matrix of percentages (aimbot_type, answer).
    # Hard-coded three answers
    experienced_judge_grading_ratios = np.zeros((len(aimbot_labels), 3))
    fps_gamer_grading_ratios = np.zeros((len(aimbot_labels), 3))

    # Get mean answers per aimbot.
    # We might want to change this to showing proportions...
    for aimbot_i, aimbot_label in enumerate(aimbot_labels):
        # Mask for the answers for this specific aimbot
        mask = ground_truth_aimbot_labels == aimbot_label
        experienced_judge_label_answers = np.concatenate([
            x[mask] for x in experienced_judge_answers
        ])
        fps_gamer_label_answers = np.concatenate([
            x[mask] for x in fps_gamer_answers
        ])
        experienced_judge_means.append(experienced_judge_label_answers.mean())
        experienced_judge_stds.append(experienced_judge_label_answers.std())
        fps_gamer_means.append(fps_gamer_label_answers.mean())
        fps_gamer_stds.append(fps_gamer_label_answers.std())
        # Also store ratio of different gradings
        for grade_i, grade in enumerate([0, 1, 2]):
            experienced_judge_grading_ratios[aimbot_i, grade_i] = np.mean(
                experienced_judge_label_answers == grade
            )
            fps_gamer_grading_ratios[aimbot_i, grade_i] = np.mean(
                fps_gamer_label_answers == grade
            )

    print("Experienced judge ratios (y = grade, y = aimbot)")
    print(experienced_judge_grading_ratios.T * 100)
    print("\nFPS gamer ratios")
    print(fps_gamer_grading_ratios.T * 100)

    # Plot results
    # Taking guidance from matplotlib tutorial
    #   https://matplotlib.org/3.1.1/gallery/lines_bars_and_markers/barchart.html#sphx-glr-gallery-lines-bars-and-markers-barchart-py
    fig = pyplot.figure(figsize=[6.4 * 1.2, 4.8 * 1.2])
    x_range = np.arange(len(aimbot_names))
    width = 0.35
    pyplot.bar(
        x_range - width / 2,
        experienced_judge_means,
        width,
        yerr=experienced_judge_stds,
        label="Experienced\njudges"
    )
    pyplot.bar(
        x_range + width / 2,
        fps_gamer_means,
        width,
        yerr=fps_gamer_stds,
        label="FPS players"
    )

    ax = pyplot.gca()
    ax.set_yticks([0, 1, 2])
    ax.set_yticklabels(("Not\nSuspicious", "Suspicious", "Cheating"))
    ax.set_xticks(x_range)
    ax.set_xticklabels(aimbot_names)
    ax.tick_params(**TICK_PARAMS_KWARGS)
    pyplot.legend(loc="upper left", **LEGEND_KWARGS)
    pyplot.grid(axis="y", alpha=0.2)

    pyplot.tight_layout()

    pyplot.savefig("figures/human_grading.pdf")


def print_dataset_statistics():
    """
    Print out statistics of our datasets (how many participants, how much data,
    how many features etc etc).

    NOTE: This assumes that we have ran all classification etc. code to produce
        train-test splits and whatnot.
    """
    from classification import get_player_id

    # This file exists after running GAN-classification stuff
    TRAIN_TEST_SPLIT_FILE = "gan_classification_results/train_test_split.pkl"
    HEURISTIC_FEATURES_DIR = "features"
    GAN_FEATURES_DIR = "gan_features"

    training_ids = None
    testing_ids = None
    with open(TRAIN_TEST_SPLIT_FILE, "rb") as f:
        split_data = pickle.load(f)
        training_ids = split_data["training_ids"]
        testing_ids = split_data["testing_ids"]

    print("Total number of IDs: {} for training, {} for testing".format(len(training_ids), len(testing_ids)))

    data_collections = ["heuristic", "gan"]
    data_feature_dirs = [HEURISTIC_FEATURES_DIR, GAN_FEATURES_DIR]
    for data_collection, data_feature_dir in zip (data_collections, data_feature_dirs):
        print("Results for collection '{}'".format(data_collection))

        feature_files = glob(os.path.join(data_feature_dir, "*"))
        train_feature_sizes = []
        test_feature_sizes = []
        train_aimbot_feature_sizes = {}
        test_aimbot_feature_sizes = {}
        train_participants = set()
        test_participants = set()

        for feature_file in feature_files:
            player_id = get_player_id(feature_file)
            data = np.load(feature_file)
            num_features = len(data["features"])
            # Aimbot is same over all samples
            aimbot_type = data["aimbot_class"][0]

            if player_id in training_ids:
                # Sanity check
                if player_id in testing_ids:
                    raise RuntimeError("A player id exists both in testing and training set!")
                train_feature_sizes.append(num_features)
                train_participants.add(player_id)
                train_aimbot_feature_sizes[aimbot_type] = train_aimbot_feature_sizes.get(aimbot_type, []) + [num_features]
            elif player_id in testing_ids:
                test_feature_sizes.append(num_features)
                test_participants.add(player_id)
                test_aimbot_feature_sizes[aimbot_type] = test_aimbot_feature_sizes.get(aimbot_type, []) + [num_features]
            else:
                raise RuntimeError("A player ID was not assigned to testing or training set!")

        print("\tTraining set: {} participants, {} features".format(len(train_participants), sum(train_feature_sizes)))
        for aimbot_class, feature_counts in train_aimbot_feature_sizes.items():
            print("\t\tAimbot {}: {} features".format(aimbot_class, sum(feature_counts)))
        print("\tTesting set:  {} participants, {} features".format(len(test_participants), sum(test_feature_sizes)))
        for aimbot_class, feature_counts in test_aimbot_feature_sizes.items():
            print("\t\tAimbot {}: {} features".format(aimbot_class, sum(feature_counts)))


AVAILABLE_OPERATIONS = {
    "all": None,
    "dets": plot_dets,
    "classification-metrics": print_metrics,
    "player-stats": print_player_stats,
    "mouse-analysis": plot_mouse_analysis,
    "plot-trajectories": plot_trajectories,
    "human-grading": plot_human_grading,
    "data-statistics": print_dataset_statistics,
    "player-stats-detection": player_performance_vs_detection,
    "multi-vector-classification": multi_vector_classification
}

if __name__ == '__main__':
    parser = ArgumentParser("Different plot utils")
    parser.add_argument("operation", choices=list(AVAILABLE_OPERATIONS.keys()), help="Operation to run")
    args = parser.parse_args()

    if args.operation == "all":
        for plot_function in AVAILABLE_OPERATIONS.values():
            if plot_function is not None:
                plot_function()
    else:
        operation_fn = AVAILABLE_OPERATIONS[args.operation]
        operation_fn()

```

`recording.py`:

```py
#!/usr/bin/env python3
#
# main.py
# Play ViZDoom against bots with aimbots
#
import math as m
import numpy as np
import vizdoom as vzd
from vizdoom import Button
from aimbots.aimbots import *
from utils.mouse_emulation import move_mouse
from time import time
from uuid import getnode
import json
import argparse
import cv2

parser = argparse.ArgumentParser("Play Vizdoom with aimbots, and record footage")
parser.add_argument("--episodes", type=int, default=10)
parser.add_argument("--bots", type=int, default=6)
parser.add_argument("--timeout", type=int, default=1000)
parser.add_argument("--record_frames", action="store_true")
parser.add_argument("--aimbot", type=str, default="none",
                    choices=["none", "snap", "ease", "max_step", "ease_light", "ease_strong", "gan", "gan_light"])
parser.add_argument("--map", type=str, default="map03")
parser.add_argument("--model", type=str, default="", help="Path to stored model for aimbots that trained parameters.")
parser.add_argument("output", type=str, help="The name of output recordings")

WIDTH = 640
HEIGHT = 480

# Not in the center if HUD is enabled
CROSSHAIR_Y = 201
CROSSHAIR_X = 320

# If True, aimbot will always aim at stuff
AIMBOT_ALWAYS_ON = True

# Maximum distance to any possible target
# this is to avoid jittering
MAX_TARGET_DIST = 800

DEBUG_PRINTS = False
DEBUG_FRAMES = False

FOVX = 90
FOVY = FOVX * (WIDTH/HEIGHT)

# mouse_move delta x -> amount of degrees in game
# Calibrated for my mouse
# (doing mouse_move(1,0) will cause TURN_LEFT_RIGHT_DELTA to be this)
X_TO_GAME = 0.17578125
# Same for delta y
Y_TO_GAME = 0.087890625
GAME_TO_X = 1/X_TO_GAME
GAME_TO_Y = 1/Y_TO_GAME

# Enable buttons here rather than config file,
# just for tiny bit of more security
AVAILABLE_BUTTONS = [
    Button.MOVE_LEFT,
    Button.MOVE_RIGHT,
    Button.MOVE_FORWARD,
    Button.MOVE_BACKWARD,
    Button.TURN_LEFT_RIGHT_DELTA,
    Button.LOOK_UP_DOWN_DELTA,
    Button.MOVE_FORWARD_BACKWARD_DELTA,
    Button.SPEED,
    Button.ATTACK,
    Button.SELECT_NEXT_WEAPON,
    Button.SELECT_PREV_WEAPON,
]

def get_visible_enemies(state, player_pos, max_distance=MAX_TARGET_DIST):
    """
    Returns list of centers of visible enemies, and another
    list of bounding boxes of the visible enemies (x0,y0,x1,y1).

    Also do not select targets too far away
    """
    enemy_objs = [obj for obj in state.labels if obj.object_name == "DoomPlayer"]
    img = state.labels_buffer
    enemy_middle_points = []
    enemy_bounding_boxes = []
    enemy_velocities = []
    for obj in enemy_objs:
        # Do not aim at yourself, dummy!
        if obj.value == 255: continue
        
        # Check distance to opponent
        distance_to_opponent = (
            (player_pos[0]-obj.object_position_x)**2 + 
            (player_pos[1]-obj.object_position_y)**2 +
            (player_pos[2]-obj.object_position_z)**2
        )
        if m.sqrt(distance_to_opponent) >= max_distance: continue

        # Use stuff from label info
        bbox = (obj.x, obj.y, obj.x + obj.width, obj.y + obj.height)
        enemy_bounding_boxes.append(bbox)
        enemy_velocities.append((obj.object_velocity_x, 
                                 obj.object_velocity_y, 
                                 obj.object_velocity_z))

    return enemy_bounding_boxes, enemy_velocities

def move_aim(dx,dy):
    # Move mouse by delta x/y amount of degrees
    dx = dx * GAME_TO_X
    dy = dy * GAME_TO_Y
    
    move_mouse(dx, dy)

def play_and_record_episodes(num_episodes, maps, aimbots, output,
                             timeout = 1000, num_bots = 6, store_frames = DEBUG_FRAMES,
                             record_video = False, additional_data = None):
    """
    num_episodes (int): Number of episodes to play
    maps (List): List of maps to play, one per episode
    aimbots (List): List of aimbots to use, one per episodfe
    output (str): Prefix of the output files
    timeout (int or List): Timeout of one episode (or list of timeouts, one per episode)
    record_video (bool): If true, record .avi video of the gameplay
    additional_data (dict): Additional data to put into saved json files
    """
    aimbot_args = (WIDTH, HEIGHT, FOVX, FOVY, CROSSHAIR_X, CROSSHAIR_Y)

    if isinstance(timeout, int):
        timeout = [timeout] * num_episodes
    else:
        assert len(timeout) == num_episodes

    game = vzd.DoomGame()

    game.set_doom_scenario_path("scenarios/cig.wad")
    game.set_labels_buffer_enabled(True)
    # Enables freelook in engine
    game.add_game_args("+freelook 1 +norawinput 1 -deathmatch")

    # Set settings here, just in case somebody starts
    # messing with the config file
    for button in AVAILABLE_BUTTONS:
        game.add_available_button(button)

    game.set_doom_map(maps[0])
    game.set_sound_enabled(True)
    game.set_screen_resolution(vzd.ScreenResolution.RES_640X480)
    game.set_render_hud(True)
    game.set_render_weapon(True)
    game.set_render_crosshair(True)
    game.set_window_visible(True)
    game.set_mode(vzd.Mode.SPECTATOR)

    game.init()

    # Set buttons
    game.send_game_command("bind w +forward")
    game.send_game_command("bind a +moveleft")
    game.send_game_command("bind s +back")
    game.send_game_command("bind d +moveright")

    # Deaths / damagecount does not update
    # between episodes, so keep track of it here
    last_ep_damages = 0.0
    last_ep_deaths = 0
    aimbot = None
    aimbot_name = None
    for episode_i in range(num_episodes):

        video_recorder = None
        if record_video:
            fourcc = cv2.VideoWriter_fourcc(*'mp4v')
            filename = output + ("_episode%d.mp4" % episode_i)
            video_recorder = cv2.VideoWriter(
                filename, fourcc, 35.0, (640, 480)
            )

        # Select new aimbot
        aimbot_name = aimbots[episode_i]
        if aimbot_name is None or aimbot_name == "none":
            aimbot = None
        elif aimbot_name == "ease_strong":
            aimbot = RelativeAimbot(*aimbot_args, max_aim_angle=15, hop_frac=0.6)
        elif aimbot_name == "ease_light":
            aimbot = RelativeAimbot(*aimbot_args, max_aim_angle=5, hop_frac=0.4)
        elif aimbot_name == "gan_group0":
            # Fixed model paths
            aimbot = GANAimbotNP(*aimbot_args, model_path="./shared_parameters/gan_group0_parameters.npz", max_aim_angle=15)
        elif aimbot_name == "gan_group1":
            # Fixed model paths
            aimbot = GANAimbotNP(*aimbot_args, model_path="./shared_parameters/gan_group1_parameters", max_aim_angle=15)


        if aimbot_name == "ease_strong":
            print("Game #{} , Aimbot ON (strong)".format(episode_i + 1))
        elif aimbot_name == "ease_light":
            print("Game #{} , Aimbot ON (light)".format(episode_i + 1))
        elif aimbot_name is not None and "gan" in aimbot_name:
            print("Game #{} , Aimbot ON".format(episode_i + 1))
        else:
            print("Game #{} , Aimbot {}".format(episode_i + 1, "OFF" if aimbot is None else "ON"))
        
        game.set_episode_timeout(timeout[episode_i])

        # Select new map
        game.set_doom_map(maps[episode_i])

        game.new_episode()

        game.send_game_command("removebots")
        for i in range(num_bots):
            game.send_game_command("addbot")

        # Stored actions, enemy locations
        # and enemy bbs
        stored_actions = []
        stored_damages = []
        stored_ammos = []
        stored_weaps = []
        stored_frags = []
        stored_deaths = []
        stored_vels = []
        stored_enemies = []
        stored_enemy_bbs = []
        stored_enemy_vels = []
        # For debuggin
        stored_frames = []

        last_action = []
        while not game.is_episode_finished():
            if game.is_player_dead():
                game.respawn_player()
            
            state = game.get_state()

            if state is None:
                game.advance_action()
                continue
            
            last_action = game.get_last_action()
            
            #start_time = time()
            # Measured max. 5ms latency here (not too bad)
            enemy_bbs = []
            if aimbot is not None:
                aimbot.process_last_action(last_action)
            if AIMBOT_ALWAYS_ON:
                player_pos = (
                    game.get_game_variable(vzd.GameVariable.POSITION_X),
                    game.get_game_variable(vzd.GameVariable.POSITION_Y),
                    game.get_game_variable(vzd.GameVariable.POSITION_Z),
                )
                enemy_bbs, enemy_vels = get_visible_enemies(state, player_pos)
                
                if len(enemy_bbs) > 0 and aimbot is not None:
                    dx,dy = aimbot.get_aiming(enemy_bbs)
                    if dx != 0 or dy != 0:
                        move_aim(dx, dy)
            
            #print("ms for aimbot: %f" % ((time() - start_time)*1000))
            
            reward = game.get_last_reward()
            damage_done = game.get_game_variable(vzd.GameVariable.DAMAGECOUNT) - last_ep_damages
            ammo = game.get_game_variable(vzd.GameVariable.SELECTED_WEAPON_AMMO)
            weap = game.get_game_variable(vzd.GameVariable.SELECTED_WEAPON)
            frags = game.get_game_variable(vzd.GameVariable.FRAGCOUNT)
            deaths = game.get_game_variable(vzd.GameVariable.DEATHCOUNT) - last_ep_deaths

            velocities = (
                game.get_game_variable(vzd.GameVariable.VELOCITY_X),
                game.get_game_variable(vzd.GameVariable.VELOCITY_Y),
                game.get_game_variable(vzd.GameVariable.VELOCITY_Z),
            )

            if DEBUG_PRINTS:
                print("State #" + str(state.number))
                print("Game variables: ", state.game_variables)
                print("Action:", last_action)
                print("Reward:", reward)
                print("Dmgcount: ", damage_done)
                print("Frags: ", frags)
                print("Deaths: ", deaths)
                print("Weap: ", weap)
                print("Ammo: ", ammo)
                print("=====================")

            if store_frames:
                stored_frames.append(state.screen_buffer)
            if video_recorder is not None:
                image = state.screen_buffer
                # Move channel to last and flip RGB to BGR
                image = image.transpose([1, 2, 0])
                video_recorder.write(image[..., ::-1])
            stored_actions.append(last_action)
            stored_damages.append(damage_done)
            stored_ammos.append(ammo)
            stored_weaps.append(weap)
            stored_frags.append(frags)
            stored_deaths.append(deaths)
            stored_vels.append(velocities)
            stored_enemy_bbs.append(enemy_bbs)
            stored_enemy_vels.append(enemy_vels)

            game.advance_action()

        last_ep_damages = game.get_game_variable(vzd.GameVariable.DAMAGECOUNT)
        last_ep_deaths = game.get_game_variable(vzd.GameVariable.DEATHCOUNT)

        filename = output + ("_episode%d.json" % episode_i)
        save_dict = {
            "timestamp": int(time()),
            "hwid": int(getnode()),
            "aimbot": aimbot_name,
            "frames": stored_frames, # For debugging
            "actions": stored_actions,
            "damages": stored_damages,
            "ammos": stored_ammos,
            "weapons": stored_weaps,
            "frags": stored_frags,
            "deaths":  stored_deaths,
            "velocities": stored_vels,
            "enemy_bbs": stored_enemy_bbs,
            "enemy_vels": stored_enemy_vels,
        }
        if additional_data is not None:
            assert isinstance(additional_data, dict)
            save_dict.update(additional_data)

        with open(filename, "w") as f:
            json.dump(save_dict, f)

        if video_recorder is not None:
            video_recorder.release()

    game.close()

if __name__ == '__main__':
    args = parser.parse_args()
    play_and_record_episodes(args.episodes, 
                             [args.map] * args.episodes,
                             [args.aimbot] * args.episodes,
                             args.output,
                             num_bots = args.bots, 
                             timeout = args.timeout,
                             store_frames = args.record_frames)

```

`requirements.txt`:

```txt
torch==1.8.1
scipy==1.6.1
numpy==1.18.1
scikit-learn
sidekit
matplotlib==3.4.1
opencv-python
vizdoom

```

`scripts/extract_features.sh`:

```sh
#!/bin/bash
mkdir -p features
for filename in data/data_collection_1/*; do
    python3 feature_extraction.py vacnet $filename features/$(basename $filename)
done


```

`scripts/extract_features_gan_data.sh`:

```sh
#!/bin/bash
mkdir -p gan_features
for filename in data/data_collection_2/*; do
    python3 feature_extraction.py vacnet $filename gan_features/$(basename $filename)
done

```

`scripts/plot_figures.sh`:

```sh
#!/bin/bash
# Plot all the figures shared in the paper
# and print out the statistics
mkdir -p figures

python3 plot_paper.py all

```

`scripts/run_all.sh`:

```sh
#!/bin/bash
# Run all experiments using the shared data

echo "Note: Data Collection 1 would happen here (and data should be placed in data/data_collection_1)"

# Extract VACNet-like features for the recordings
./scripts/extract_features.sh
# Train initial classifier and other classifiers for comparing different classifiers
./scripts/run_classification.sh

# Split data into two groups for training GANs and train GANs
./scripts/split_gan_data.sh
./scripts/train_gans.sh

echo "Note: Data Collection 2 would happen here (and data should be placed in data/data_collection_2)"
echo "Note: Data Collection 3 would happen here (and data should be placed in data/data_collection_3)"
echo "Note: Data Collections 4 and 5 would happen here (and judges' answers put into data/data_collection_5)"

# Extract features for the GAN classifier
./scripts/extract_features_gan_data.sh

# Train and test classifiers in different scenarios
./scripts/train_gan_classifiers.sh
./scripts/test_gan_classifiers.sh

# Print and plot all results
./scripts/plot_figures.sh

```

`scripts/run_classification.sh`:

```sh
#!/bin/bash
# Initial training of DNN and training of different models for comparison (only on light/strong aimbot data)
mkdir -p classification_results
# First train only the DNN part. This will also create train-test split
python3 classification.py features classification_results dnn
# Then train other models if auto-sklearn is present (separated to different script in case you only want to run DNN experiments)
python3 classification.py features classification_results random_forest decision_tree libsvm_svc bernoulli_nb sgd lda
# And plot the results
python3 plot.py classification-results dummy --inputs classification_results/*_scores.npz
```

`scripts/split_gan_data.sh`:

```sh
#!/bin/bash
# Create Group 1 and 2 training sets for training two GAN
# Use evaluation set of the first data collection for this.
python3 train_util.py split-eval-data ./data/data_collection_1 ./classification_results/train_test_split.pkl gan_train_data
```

`scripts/test_gan_classifiers.sh`:

```sh
#!/bin/bash
# Test GAN classifiers in different ways
# Run after train_gan_classifiers.sh

mkdir -p evaluation_scores

# Worst-case scenario: GAN aimbots are completely
# new and not included in the training set.
# Test against the original DNN
python3 classification.py dummy evaluation_scores/worst_case.npz dnn --model-path classification_results/dnn_model.pkl --feature-files gan_classification_data/* --train-test-split gan_classification_results/train_test_split.pkl

# Known-attack: Some GAN data is included in the training
# set, but not specifically the one used by the hackers.
# This also includes oracle: Data from the same aimbot
python3 classification.py dummy evaluation_scores/known_attack_group1.npz dnn --model-path gan_classification_results/dnn_group0_model.pkl --feature-files gan_classification_data/* --train-test-split gan_classification_results/train_test_split.pkl
python3 classification.py dummy evaluation_scores/known_attack_group2.npz dnn --model-path gan_classification_results/dnn_group1_model.pkl --feature-files gan_classification_data/* --train-test-split gan_classification_results/train_test_split.pkl

# Best-case: Training set also includes evaluation data
python3 classification.py dummy evaluation_scores/best_case.npz dnn --model-path gan_classification_results/dnn_all_train_model.pkl --feature-files gan_classification_data/* --train-test-split gan_classification_results/train_test_split.pkl

# -- Repeat above on original aimbots for completeness --
python3 classification.py dummy evaluation_scores/trained_on_light.npz dnn --model-path gan_classification_results/dnn_aimbot1_model.pkl --feature-files gan_classification_data/* --train-test-split gan_classification_results/train_test_split.pkl
python3 classification.py dummy evaluation_scores/trained_on_strong.npz dnn --model-path gan_classification_results/dnn_aimbot2_model.pkl --feature-files gan_classification_data/* --train-test-split gan_classification_results/train_test_split.pkl

# Best-case (training data contains testing data)
python3 classification.py dummy evaluation_scores/best_case_original.npz dnn --model-path gan_classification_results/dnn_original_all_train_model.pkl --feature-files gan_classification_data/* --train-test-split gan_classification_results/train_test_split.pkl
```

`scripts/train_gan_classifiers.sh`:

```sh
#!/bin/bash
# Create new training/testing sets given the new GAN data,
# move data to new folder and train new classifiers
mkdir -p gan_classification_data gan_classification_results

# Update train-test split with GAN data
# A sensible split (fifty-fifty, with more for training set)
python3 ./train_util.py update-split ./gan_features/ ./classification_results/train_test_split.pkl gan_classification_results/train_test_split.pkl
# A best-case split: all data goes to training (this will be used to train best-case classifier)
python3 ./train_util.py update-split ./gan_features/ ./classification_results/train_test_split.pkl gan_classification_results/train_all_gan_split.pkl --eval-ratio 0.0
# A best-case split for original aimbots too: train on all data
python3 ./train_util.py update-split ./features/ none gan_classification_results/original_train_all_split.pkl --eval-ratio 0.0
# Copython3 normalization stats too
cp ./classification_results/feature_normalization.npz ./gan_classification_results

# Copython3 original and new data into a single folder (to keep the original data untouched)
cp ./features/* ./gan_features/* ./gan_classification_data

# Train two models, both trained on different GAN-aimbots.
# aimbot id 10 is for group 0 GAN, 11 for group 1.
for group_id in 0 1; do
    # Train on proper train-test split
    python3 classification.py gan_classification_data gan_classification_results dnn --model-postfix _group${group_id} --included-aimbots 1${group_id}
done

# Train on all GAN data (best-case scenario)
python3 classification.py gan_classification_data gan_classification_results dnn --model-postfix _all_train --included-aimbots 10 11 --train-test-split train_all_gan_split.pkl

# For completeness, do same as above for strong and light aimbots (train on one, test on another)
for aimbot in 1 2; do
    # Train on proper train-test split
    python3 classification.py gan_classification_data gan_classification_results dnn --model-postfix _aimbot${aimbot} --included-aimbots ${aimbot}
done
# Train on all heuristic data (best-case for strong/light aimbot)
python3 classification.py gan_classification_data gan_classification_results dnn --model-postfix _original_all_train --included-aimbots 1 2 --train-test-split original_train_all_split.pkl

```

`scripts/train_gans.sh`:

```sh
#!/bin/bash
# Train one aimbot gan per data directory.
# Hardcoded number of groups.
mkdir -p gan_models
for group_id in 0 1; do
    python3 aimbots/humanlike_aimbot_gan.py train gan_train_data/group${group_id}/* --model gan_models/gan_group${group_id} --epochs 100
    # Also convert the generator into numpython3 arrays so we can use it for aimbotting.
    python3 aimbots/humanlike_aimbot_gan.py params_to_numpython3 dummy --model gan_models/gan_group${group_id}_G
done

```

`train_util.py`:

```py
#
# train_util.py
# Different utilities for training data and splitting
#
import os
import pickle
import glob
import random
import math
from argparse import ArgumentParser
import shutil


def split_eval_data(unparsed_args):
    """
    Take train_test_split file from classification.py,
    split the eval set into different groups and copy
    files under a new directory.

    Used to create different training sets for GANs.
    """
    parser = ArgumentParser("Split recording files of eval-set players into different groups")
    parser.add_argument("recording_dir", type=str, help="Directory where recordings reside.")
    parser.add_argument("train_eval_split", type=str, help="Path to train_eval split file from classification.py.")
    parser.add_argument("output", type=str, help="Directory where different groups are created.")
    parser.add_argument("--num-sets", type=int, default=2, help="Number of groups to create.")
    parser.add_argument("--num-remove-ids", type=int, default=1, help="Number of ids to remove before split.")
    args = parser.parse_args(unparsed_args)

    split = pickle.load(open(args.train_eval_split, "rb"))
    eval_ids = list(split["testing_ids"])
    random.shuffle(eval_ids)
    # Remove any ids if we want to do so
    eval_ids = eval_ids[:-args.num_remove_ids]

    recording_files = glob.glob(os.path.join(args.recording_dir, "*"))

    # Split evaluation IDs to groups of --num-sets
    items_per_group = len(eval_ids) / args.num_sets
    assert int(items_per_group) == items_per_group, "Could not make an even split with {} eval ids".format(len(eval_ids))
    items_per_group = int(items_per_group)

    random.shuffle(eval_ids)

    eval_groups = [eval_ids[i:i + items_per_group] for i in range(0, len(eval_ids), items_per_group)]

    # Go over groups, create output directories
    # and put recordings there
    for i, eval_group in enumerate(eval_groups):
        output_dir = os.path.join(args.output, "group{}".format(i))
        os.makedirs(output_dir)
        for recording_file_path in recording_files:
            for eval_id in eval_group:
                if eval_id in recording_file_path:
                    destination_file = os.path.join(output_dir, os.path.basename(recording_file_path))
                    shutil.copy(recording_file_path, destination_file)


def update_train_test_split_with_gan(unparsed_args):
    """
    Take existing train-test split file, and bunch of GAN-aimbot features.
    Split the new data into train-test split and append them into the
    train-test split file.
    """
    parser = ArgumentParser("Update train-test split with GAN-aimbot data")
    parser.add_argument("features_dir", type=str, help="Directory where features reside.")
    parser.add_argument("train_eval_split", type=str, help="Path to train_eval split file from classification.py.")
    parser.add_argument("output", type=str, help="Path where updated train-test split should be stored.")
    parser.add_argument("--eval-ratio", type=float, default=0.45, help="Amount of data to keep for evaluation")
    args = parser.parse_args(unparsed_args)

    data_files = glob.glob(os.path.join(args.features_dir, "*"))
    ids = []
    for data_file in data_files:
        filename_split = os.path.basename(data_file).split("_")
        # Timestamp + hardware id
        unique_id = filename_split[0] + "_" + filename_split[1]
        ids.append(unique_id)

    ids = set(ids)
    testing_ids = set(random.sample(ids, math.ceil(len(ids) * args.eval_ratio)))
    training_ids = ids - testing_ids

    if args.train_eval_split != "none":
        original_split = pickle.load(open(args.train_eval_split, "rb"))
    else:
        original_split = {"training_ids": set(), "testing_ids": set()}

    original_split["training_ids"].update(training_ids)
    original_split["testing_ids"].update(testing_ids)

    with open(args.output, "wb") as f:
        pickle.dump(original_split, f)


AVAILABLE_OPERATIONS = {
    "split-eval-data": split_eval_data,
    "update-split": update_train_test_split_with_gan,
}

if __name__ == '__main__':
    parser = ArgumentParser("Different utils for training")
    parser.add_argument("operation", choices=list(AVAILABLE_OPERATIONS.keys()), help="Operation to run")
    args, unparsed_args = parser.parse_known_args()

    operation_fn = AVAILABLE_OPERATIONS[args.operation]
    operation_fn(unparsed_args)

```

`utils/mouse_emulation.py`:

```py
#!/usr/bin/env python3
#
# mouse_emulation.py
# Tools to emulate mouse movement.
#

import os
import sys

sys_move_mouse = None
if sys.platform == "win32":
    from .win_mouse_tools import move_mouse
    sys_move_mouse = move_mouse
else:
    raise NotImplementedError("Only Windows platform is supported for running aimbots.")

def move_mouse(delta_x, delta_y):
    """
    Move mouse by delta_x, delta_y amount, relative
    to current position.

    Positive delta_x: Right (on screen)
    Positive delta_y: Down (on screen)
    """
    if delta_x == 0 and delta_y == 0:
        return

    sys_move_mouse(int(round(delta_x)), int(round(delta_y)))

```

`utils/win_mouse_tools.py`:

```py
#!/usr/bin/env python3
#
# windows_mouse.py 
# Tools to emulate mouse movement on Windows
#

from ctypes import *
from ctypes.wintypes import DWORD, LONG, ULONG, WORD

M1_VK = 0x1
M2_VK = 0x2
MOUSEEVENTF_MOVE        = 0x0001 #/* mouse move */
MOUSEEVENTF_ABSOLUTE    = 0x8000 #/* absolute move */
MOUSEEVENTF_LEFTDOWN    = 0x0002
MOUSEEVENTF_LEFTUP      = 0x0004
MOUSEEVENTF_RIGHTDOWN   = 0x0008
MOUSEEVENTF_RIGHTUP     = 0x0010
INPUT_MOUSE = 0
INPUT_KEYBD = 1

class MOUSEINPUT(Structure):
    _fields_ = [ ("dx", LONG),
                 ("dy", LONG),
                 ("mouseData", DWORD),
                 ("dwFlags", DWORD),
                 ("time", DWORD),
                 ("dwExtraInfo", POINTER(ULONG))
                ]

class KEYBDINPUT(Structure):
    _fields_ = [ ("wVk", WORD),
                 ("wScan", WORD),
                 ("dwFlags", DWORD),
                 ("time", DWORD),
                 ("dwExtraInfo", POINTER(ULONG))
                ]
    
class HARDWAREINPUT(Structure):
    _fields_ = [ ("uMsg", DWORD),
                 ("wParamL", WORD),
                 ("wParamH", WORD),
                ]

class _INPUT_UNION(Union):
    _fields_ = [("mi", MOUSEINPUT),
                ("ki", KEYBDINPUT),
                ("hi", HARDWAREINPUT),
                ]

class INPUT(Structure):
    _anonymous_ = ("iu",)
    _fields_ = [ ("type", DWORD),
                 ("iu", _INPUT_UNION)]
minput = INPUT()
minput.type = INPUT_MOUSE
minput.mi.dwFlags = MOUSEEVENTF_MOVE

def move_mouse(delta_x, delta_y):
    global minput
    if delta_x == 0 and delta_y == 0:
        return (0, 0)

    minput.mi.dx = delta_x
    minput.mi.dy = delta_y
    windll.User32.SendInput(1, byref(minput), sizeof(minput))

```