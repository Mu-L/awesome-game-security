Project Path: arc_j-hc_FlagSecurePatcher_nuu_z_r6

Source Tree:

```txt
arc_j-hc_FlagSecurePatcher_nuu_z_r6
├── LICENSE
├── README.md
├── module
│   ├── META-INF
│   │   └── com
│   │       └── google
│   │           └── android
│   │               ├── update-binary
│   │               └── updater-script
│   ├── customize.sh
│   ├── module.prop
│   ├── post-fs-data.sh
│   ├── uninstall.sh
│   └── util
│       ├── bin
│       │   ├── arm
│       │   │   ├── zip
│       │   │   └── zipalign
│       │   ├── arm64
│       │   │   ├── zip
│       │   │   └── zipalign
│       │   ├── x64
│       │   │   ├── zip
│       │   │   └── zipalign
│       │   └── x86
│       │       ├── zip
│       │       └── zipalign
│       └── lib
│           ├── arm
│           │   ├── libandroid-base.so
│           │   ├── libandroid-cutils.so
│           │   ├── libandroid-support.so
│           │   ├── libandroid-utils.so
│           │   ├── libandroid-ziparchive.so
│           │   ├── libbz2.so
│           │   ├── libbz2.so.1.0
│           │   ├── libbz2.so.1.0.8
│           │   ├── libc++_shared.so
│           │   ├── libz.so
│           │   ├── libz.so.1
│           │   ├── libz.so.1.3.1
│           │   ├── libzopfli.so
│           │   └── libzopflipng.so
│           ├── arm64
│           │   ├── libandroid-base.so
│           │   ├── libandroid-cutils.so
│           │   ├── libandroid-support.so
│           │   ├── libandroid-utils.so
│           │   ├── libandroid-ziparchive.so
│           │   ├── libbz2.so
│           │   ├── libbz2.so.1.0
│           │   ├── libbz2.so.1.0.8
│           │   ├── libc++_shared.so
│           │   ├── libz.so
│           │   ├── libz.so.1
│           │   ├── libz.so.1.3.1
│           │   ├── libzopfli.so
│           │   └── libzopflipng.so
│           ├── x64
│           │   ├── libandroid-base.so
│           │   ├── libandroid-cutils.so
│           │   ├── libandroid-support.so
│           │   ├── libandroid-utils.so
│           │   ├── libandroid-ziparchive.so
│           │   ├── libbz2.so
│           │   ├── libbz2.so.1.0
│           │   ├── libbz2.so.1.0.8
│           │   ├── libc++_shared.so
│           │   ├── libz.so
│           │   ├── libz.so.1
│           │   ├── libz.so.1.3.1
│           │   ├── libzopfli.so
│           │   └── libzopflipng.so
│           └── x86
│               ├── libandroid-base.so
│               ├── libandroid-cutils.so
│               ├── libandroid-support.so
│               ├── libandroid-utils.so
│               ├── libandroid-ziparchive.so
│               ├── libbz2.so
│               ├── libbz2.so.1.0
│               ├── libbz2.so.1.0.8
│               ├── libc++_shared.so
│               ├── libz.so
│               ├── libz.so.1
│               ├── libz.so.1.3.1
│               ├── libzopfli.so
│               └── libzopflipng.so
├── paccer
│   └── jni
│       ├── paccer.cpp
│       └── slicer
│           ├── Makefile
│           ├── bytecode_encoder.cc
│           ├── code_ir.cc
│           ├── common.cc
│           ├── control_flow_graph.cc
│           ├── debuginfo_encoder.cc
│           ├── dex_bytecode.cc
│           ├── dex_format.cc
│           ├── dex_ir.cc
│           ├── dex_ir_builder.cc
│           ├── dex_utf8.cc
│           ├── export
│           │   └── slicer
│           │       ├── arrayview.h
│           │       ├── buffer.h
│           │       ├── bytecode_encoder.h
│           │       ├── chronometer.h
│           │       ├── code_ir.h
│           │       ├── common.h
│           │       ├── control_flow_graph.h
│           │       ├── debuginfo_encoder.h
│           │       ├── dex_bytecode.h
│           │       ├── dex_format.h
│           │       ├── dex_instruction_list.h
│           │       ├── dex_ir.h
│           │       ├── dex_ir_builder.h
│           │       ├── dex_leb128.h
│           │       ├── dex_utf8.h
│           │       ├── hash_table.h
│           │       ├── index_map.h
│           │       ├── instrumentation.h
│           │       ├── intrusive_list.h
│           │       ├── memview.h
│           │       ├── reader.h
│           │       ├── scopeguard.h
│           │       ├── tryblocks_encoder.h
│           │       └── writer.h
│           ├── instrumentation.cc
│           ├── reader.cc
│           ├── tryblocks_encoder.cc
│           └── writer.cc
└── update.json

```

`LICENSE`:

```
                                 Apache License
                           Version 2.0, January 2004
                        http://www.apache.org/licenses/

   TERMS AND CONDITIONS FOR USE, REPRODUCTION, AND DISTRIBUTION

   1. Definitions.

      "License" shall mean the terms and conditions for use, reproduction,
      and distribution as defined by Sections 1 through 9 of this document.

      "Licensor" shall mean the copyright owner or entity authorized by
      the copyright owner that is granting the License.

      "Legal Entity" shall mean the union of the acting entity and all
      other entities that control, are controlled by, or are under common
      control with that entity. For the purposes of this definition,
      "control" means (i) the power, direct or indirect, to cause the
      direction or management of such entity, whether by contract or
      otherwise, or (ii) ownership of fifty percent (50%) or more of the
      outstanding shares, or (iii) beneficial ownership of such entity.

      "You" (or "Your") shall mean an individual or Legal Entity
      exercising permissions granted by this License.

      "Source" form shall mean the preferred form for making modifications,
      including but not limited to software source code, documentation
      source, and configuration files.

      "Object" form shall mean any form resulting from mechanical
      transformation or translation of a Source form, including but
      not limited to compiled object code, generated documentation,
      and conversions to other media types.

      "Work" shall mean the work of authorship, whether in Source or
      Object form, made available under the License, as indicated by a
      copyright notice that is included in or attached to the work
      (an example is provided in the Appendix below).

      "Derivative Works" shall mean any work, whether in Source or Object
      form, that is based on (or derived from) the Work and for which the
      editorial revisions, annotations, elaborations, or other modifications
      represent, as a whole, an original work of authorship. For the purposes
      of this License, Derivative Works shall not include works that remain
      separable from, or merely link (or bind by name) to the interfaces of,
      the Work and Derivative Works thereof.

      "Contribution" shall mean any work of authorship, including
      the original version of the Work and any modifications or additions
      to that Work or Derivative Works thereof, that is intentionally
      submitted to Licensor for inclusion in the Work by the copyright owner
      or by an individual or Legal Entity authorized to submit on behalf of
      the copyright owner. For the purposes of this definition, "submitted"
      means any form of electronic, verbal, or written communication sent
      to the Licensor or its representatives, including but not limited to
      communication on electronic mailing lists, source code control systems,
      and issue tracking systems that are managed by, or on behalf of, the
      Licensor for the purpose of discussing and improving the Work, but
      excluding communication that is conspicuously marked or otherwise
      designated in writing by the copyright owner as "Not a Contribution."

      "Contributor" shall mean Licensor and any individual or Legal Entity
      on behalf of whom a Contribution has been received by Licensor and
      subsequently incorporated within the Work.

   2. Grant of Copyright License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      copyright license to reproduce, prepare Derivative Works of,
      publicly display, publicly perform, sublicense, and distribute the
      Work and such Derivative Works in Source or Object form.

   3. Grant of Patent License. Subject to the terms and conditions of
      this License, each Contributor hereby grants to You a perpetual,
      worldwide, non-exclusive, no-charge, royalty-free, irrevocable
      (except as stated in this section) patent license to make, have made,
      use, offer to sell, sell, import, and otherwise transfer the Work,
      where such license applies only to those patent claims licensable
      by such Contributor that are necessarily infringed by their
      Contribution(s) alone or by combination of their Contribution(s)
      with the Work to which such Contribution(s) was submitted. If You
      institute patent litigation against any entity (including a
      cross-claim or counterclaim in a lawsuit) alleging that the Work
      or a Contribution incorporated within the Work constitutes direct
      or contributory patent infringement, then any patent licenses
      granted to You under this License for that Work shall terminate
      as of the date such litigation is filed.

   4. Redistribution. You may reproduce and distribute copies of the
      Work or Derivative Works thereof in any medium, with or without
      modifications, and in Source or Object form, provided that You
      meet the following conditions:

      (a) You must give any other recipients of the Work or
          Derivative Works a copy of this License; and

      (b) You must cause any modified files to carry prominent notices
          stating that You changed the files; and

      (c) You must retain, in the Source form of any Derivative Works
          that You distribute, all copyright, patent, trademark, and
          attribution notices from the Source form of the Work,
          excluding those notices that do not pertain to any part of
          the Derivative Works; and

      (d) If the Work includes a "NOTICE" text file as part of its
          distribution, then any Derivative Works that You distribute must
          include a readable copy of the attribution notices contained
          within such NOTICE file, excluding those notices that do not
          pertain to any part of the Derivative Works, in at least one
          of the following places: within a NOTICE text file distributed
          as part of the Derivative Works; within the Source form or
          documentation, if provided along with the Derivative Works; or,
          within a display generated by the Derivative Works, if and
          wherever such third-party notices normally appear. The contents
          of the NOTICE file are for informational purposes only and
          do not modify the License. You may add Your own attribution
          notices within Derivative Works that You distribute, alongside
          or as an addendum to the NOTICE text from the Work, provided
          that such additional attribution notices cannot be construed
          as modifying the License.

      You may add Your own copyright statement to Your modifications and
      may provide additional or different license terms and conditions
      for use, reproduction, or distribution of Your modifications, or
      for any such Derivative Works as a whole, provided Your use,
      reproduction, and distribution of the Work otherwise complies with
      the conditions stated in this License.

   5. Submission of Contributions. Unless You explicitly state otherwise,
      any Contribution intentionally submitted for inclusion in the Work
      by You to the Licensor shall be under the terms and conditions of
      this License, without any additional terms or conditions.
      Notwithstanding the above, nothing herein shall supersede or modify
      the terms of any separate license agreement you may have executed
      with Licensor regarding such Contributions.

   6. Trademarks. This License does not grant permission to use the trade
      names, trademarks, service marks, or product names of the Licensor,
      except as required for reasonable and customary use in describing the
      origin of the Work and reproducing the content of the NOTICE file.

   7. Disclaimer of Warranty. Unless required by applicable law or
      agreed to in writing, Licensor provides the Work (and each
      Contributor provides its Contributions) on an "AS IS" BASIS,
      WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or
      implied, including, without limitation, any warranties or conditions
      of TITLE, NON-INFRINGEMENT, MERCHANTABILITY, or FITNESS FOR A
      PARTICULAR PURPOSE. You are solely responsible for determining the
      appropriateness of using or redistributing the Work and assume any
      risks associated with Your exercise of permissions under this License.

   8. Limitation of Liability. In no event and under no legal theory,
      whether in tort (including negligence), contract, or otherwise,
      unless required by applicable law (such as deliberate and grossly
      negligent acts) or agreed to in writing, shall any Contributor be
      liable to You for damages, including any direct, indirect, special,
      incidental, or consequential damages of any character arising as a
      result of this License or out of the use or inability to use the
      Work (including but not limited to damages for loss of goodwill,
      work stoppage, computer failure or malfunction, or any and all
      other commercial damages or losses), even if such Contributor
      has been advised of the possibility of such damages.

   9. Accepting Warranty or Additional Liability. While redistributing
      the Work or Derivative Works thereof, You may choose to offer,
      and charge a fee for, acceptance of support, warranty, indemnity,
      or other liability obligations and/or rights consistent with this
      License. However, in accepting such obligations, You may act only
      on Your own behalf and on Your sole responsibility, not on behalf
      of any other Contributor, and only if You agree to indemnify,
      defend, and hold each Contributor harmless for any liability
      incurred by, or claims asserted against, such Contributor by reason
      of your accepting any such warranty or additional liability.

   END OF TERMS AND CONDITIONS

   APPENDIX: How to apply the Apache License to your work.

      To apply the Apache License to your work, attach the following
      boilerplate notice, with the fields enclosed by brackets "[]"
      replaced with your own identifying information. (Don't include
      the brackets!)  The text should be enclosed in the appropriate
      comment syntax for the file format. We also recommend that a
      file or class name and description of purpose be included on the
      same "printed page" as the copyright notice for easier
      identification within third-party archives.

   Copyright [] []

   Licensed under the Apache License, Version 2.0 (the "License");
   you may not use this file except in compliance with the License.
   You may obtain a copy of the License at

       http://www.apache.org/licenses/LICENSE-2.0

   Unless required by applicable law or agreed to in writing, software
   distributed under the License is distributed on an "AS IS" BASIS,
   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   See the License for the specific language governing permissions and
   limitations under the License.
```

`README.md`:

```md
> [!WARNING]  
> This module was deprecated in favor of [ih8SecureLock](https://github.com/j-hc/ih8SecureLock)

### FlagSecurePatcher

Magisk module to patch services jars on device to stop apps from preventing taking screenshots and block screenshot listeners that was introduced in A14.

```

`module/META-INF/com/google/android/update-binary`:

```
#!/sbin/sh

#################
# Initialization
#################

umask 022

# echo before loading util_functions
ui_print() { echo "$1"; }

require_new_magisk() {
  ui_print "*******************************"
  ui_print " Please install Magisk v20.4+! "
  ui_print "*******************************"
  exit 1
}

#########################
# Load util_functions.sh
#########################

OUTFD=$2
ZIPFILE=$3

mount /data 2>/dev/null

[ -f /data/adb/magisk/util_functions.sh ] || require_new_magisk
. /data/adb/magisk/util_functions.sh
[ $MAGISK_VER_CODE -lt 20400 ] && require_new_magisk

install_module
exit 0

```

`module/META-INF/com/google/android/updater-script`:

```
#MAGISK

```

`module/customize.sh`:

```sh
set -eu

LIBPATH="$MODPATH/util/lib/${ARCH}"
alias zip='LD_LIBRARY_PATH=$LIBPATH $MODPATH/util/bin/$ARCH/zip'
alias zipalign='LD_LIBRARY_PATH=$LIBPATH $MODPATH/util/bin/$ARCH/zipalign'
alias paccer='LD_LIBRARY_PATH=$LIBPATH $MODPATH/util/bin/$ARCH/paccer'
chmod -R 755 "$MODPATH/util/"
TMPPATH="$MODPATH/tmp"

BDATE_PROP=$(getprop ro.build.date.utc)

log() { ui_print "[+] $1"; }
loge() { ui_print "[-] $1"; }

run() {
    TARGET_JAR=$1
    PATCHES_FOR_JAR=$2
    TARGET_JAR_NAME=${TARGET_JAR##*/}
    TARGET_JAR_BASE=${TARGET_JAR_NAME%.*}
    if [ "${TARGET_JAR:0:8}" = "/system/" ]; then
        TARGET_JAR_PATH=${MODPATH}${TARGET_JAR%/*}
    else
        TARGET_JAR_PATH=${MODPATH}/system${TARGET_JAR%/*}
    fi
    mkdir "$TMPPATH"

    cp "$(magisk --path 2>/dev/null)/.magisk/mirror${TARGET_JAR}" "$TMPPATH" 2>/dev/null ||
        cp "/data/adb/modules/flagsecurepatcher/${TARGET_JAR_NAME}.bak.${BDATE_PROP}" "$TMPPATH/$TARGET_JAR_NAME" 2>/dev/null ||
        if [ ! -d "/data/adb/modules/flagsecurepatcher/system/" ]; then
            cp "$TARGET_JAR" "$TMPPATH" || abort "not found: '$TARGET_JAR'"
        else abort "Stock jar was not found. Uninstall the module, reboot and reflash."; fi
    cp "$TMPPATH/$TARGET_JAR_NAME" "$MODPATH/${TARGET_JAR_NAME}.bak.${BDATE_PROP}"

    log "Extracting $TARGET_JAR_BASE"
    mkdir "$TMPPATH/$TARGET_JAR_BASE"
    unzip -q "$TMPPATH/$TARGET_JAR_NAME" -d "$TMPPATH/$TARGET_JAR_BASE"
    [ -f "$TMPPATH/$TARGET_JAR_BASE/classes.dex" ] || abort "ROM is not supported"

    log "Patching"
    PATCHED_OK=false
    for DEX in "$TMPPATH/$TARGET_JAR_BASE"/classes*; do
        if ! OP=$(paccer "$DEX" "$DEX" "$PATCHES_FOR_JAR" 2>&1); then
            abort "paccer error (${DEX##*/}): '$OP'"
        fi
        if [ "$OP" ]; then
            PATCHED_OK=true
            printf "%s\n" "$OP" | while read -r l; do
                log "(${DEX##*/}) $l"
            done
            ui_print ""
        fi
    done
    if [ $PATCHED_OK = false ]; then
        loge "No patch was successful for $TARGET_JAR_BASE"
        rm -r "$TMPPATH"
        return 0
    fi

    if [ "$ARCH" = x64 ]; then INS_SET=x86_64; else INS_SET=$ARCH; fi
    mkdir -p "${TARGET_JAR_PATH}/oat/$INS_SET"

    log "Zipaligning"
    cd "$TMPPATH/$TARGET_JAR_BASE/"
    zip -q0r "$TMPPATH/$TARGET_JAR_BASE-patched.zip" .
    cd "$MODPATH"

    PATCHED_JAR=${TARGET_JAR_PATH}/${TARGET_JAR_NAME}
    if ! OP=$(zipalign -p -z 4 "$TMPPATH/$TARGET_JAR_BASE-patched.zip" "$PATCHED_JAR" 2>&1); then
        abort "ERROR: zipalign failed '$OP'"
    fi
    set_perm "$PATCHED_JAR" 0 0 644 u:object_r:system_file:s0

    log "Optimizing"
    dex2oat --dex-file="$PATCHED_JAR" --android-root=/system \
        --instruction-set="$INS_SET" --oat-file="${TARGET_JAR_PATH}/oat/${INS_SET}/${TARGET_JAR_BASE}.odex" \
        --app-image-file="${TARGET_JAR_PATH}/oat/${INS_SET}/${TARGET_JAR_BASE}.art" --no-generate-debug-info \
        --generate-mini-debug-info || {
        D2O_LOG=$(logcat -d -s "dex2oat")
        ui_print "dex2oat failed."
        ui_print "$D2O_LOG"
        abort
    }
    for ext in odex vdex art; do
        set_perm "${TARGET_JAR_PATH}/oat/$INS_SET/${TARGET_JAR_BASE}.${ext}" 0 0 644 u:object_r:system_file:s0
    done

    rm -r "$TMPPATH"
    TARGET_OAT_NAME=${TARGET_JAR//\//@} TARGET_OAT_NAME=${TARGET_OAT_NAME:1}
    rm /data/dalvik-cache/"$INS_SET"/"$TARGET_OAT_NAME"@classes.* 2>/dev/null || :
    rm /data/misc/apexdata/com.android.art/dalvik-cache/"$INS_SET"/"$TARGET_OAT_NAME"@classes.* 2>/dev/null || :
}

# patch definitions for specific methods, feel free to add yours
services_PATCHES="
isSecureLocked              :RET_FALSE;
notifyScreenshotListeners   :RET_EMPTY_LIST;
isAllowAudioPlaybackCapture :RET_TRUE;
isScreenCaptureAllowed      :RET_TRUE;
getScreenCaptureDisabled    :RET_FALSE;
notAllowCaptureDisplay      :RET_FALSE;
"
semwifi_PATCHES="isSecureLocked:RET_FALSE;"
miui_PATCHES="notAllowCaptureDisplay:RET_FALSE;"

run "/system/framework/services.jar" "$services_PATCHES" || abort

if [ -f "/system/framework/semwifi-service.jar" ]; then
    ui_print ""
    log "OneUI detected: semwifi-service.jar"
    run "/system/framework/semwifi-service.jar" "$semwifi_PATCHES" || abort
elif [ -f "/system_ext/framework/miui-services.jar" ]; then
    ui_print ""
    log "HyperOS detected: miui-services.jar"
    run "/system_ext/framework/miui-services.jar" "$miui_PATCHES" || abort
fi

if [ ! -d "$MODPATH/system/" ] && [ ! -d "$MODPATH/system_ext/" ]; then
    abort "  All patches failed!"
fi

rm -r "$MODPATH/util"

ui_print ""
ui_print "  by github.com/j-hc"

set +eu

```

`module/module.prop`:

```prop
id=flagsecurepatcher
name=FlagSecurePatcher
version=r17
versionCode=17
author=j-hc
description=Prevent apps from blocking and listening to your screenshots
updateJson=https://raw.githubusercontent.com/j-hc/FlagSecurePatcher/master/update.json

```

`module/post-fs-data.sh`:

```sh
MODDIR=${0%/*}
BDATE_PROP=$(getprop ro.build.date.utc)

if [ -z "$(find "$MODDIR" -name "*.bak.${BDATE_PROP}" -maxdepth 1 -print -quit)" ]; then
	touch "$MODDIR"/disable
	sed -i "s/^des.*/description=⚠️ Needs reflash: Patch was applied on an older OS/g" "$MODDIR/module.prop"
fi

```

`module/uninstall.sh`:

```sh
rm /data/dalvik-cache/*/system@framework@services.jar@classes.*
rm /data/misc/apexdata/com.android.art/dalvik-cache/*/system@framework@services.jar@classes.*

rm /data/dalvik-cache/*/system@framework@semwifi-service.jar@classes.*
rm /data/misc/apexdata/com.android.art/dalvik-cache/*/system@framework@semwifi-service.jar@classes.*

rm /data/dalvik-cache/*/system_ext@framework@miui-services.jar@classes.*
rm /data/misc/apexdata/com.android.art/dalvik-cache/*/system_ext@framework@miui-services.jar@classes.*

```

`paccer/jni/paccer.cpp`:

```cpp
#include <sys/stat.h>

#include <cstddef>
#include <cstdio>
#include <cstdlib>
#include <cstring>
#include <vector>

#include "slicer/code_ir.h"
#include "slicer/dex_format.h"
#include "slicer/dex_ir_builder.h"
#include "slicer/reader.h"
#include "slicer/writer.h"

enum class PatchType { RET_EMPTY_LIST, RET_FALSE, RET_TRUE };

static inline bool patchTypeFromStr(const char* str, PatchType& t) {
    if (strcmp(str, "RET_EMPTY_LIST") == 0) t = PatchType::RET_EMPTY_LIST;
    else if (strcmp(str, "RET_TRUE") == 0) t = PatchType::RET_TRUE;
    else if (strcmp(str, "RET_FALSE") == 0) t = PatchType::RET_FALSE;
    else return false;
    return true;
}

static inline const char* retTypeFromPatch(PatchType t) {
    switch (t) {
        case PatchType::RET_EMPTY_LIST:
            return "Ljava/util/List;";
        case PatchType::RET_FALSE:
        case PatchType::RET_TRUE:
            return "Z";
        default:
            assert(false && "unreachable");
    }
}

struct PatchMethod {
    std::string method_name;
    std::string parent_name;
    PatchType patch_type;
};

static std::vector<PatchMethod> parsePatchesArg(const char* list) {
    std::vector<PatchMethod> ps;
    int i = 0;
    for (;;) {
        PatchMethod pm;
        int j = 0;
        bool type_turn = false;
        std::string patch_type_str;
        for (;;) {
            char c = list[i + j++];
            if (c == '\0') break;
            if (c == ';') break;
            if (isspace(c)) continue;
            if (c == ':') {
                type_turn = true;
                continue;
            }
            if (type_turn) patch_type_str.push_back(c);
            else pm.method_name.push_back(c);
        }
        if (pm.method_name.empty() || patch_type_str.empty()) break;
        if (!patchTypeFromStr(patch_type_str.c_str(), pm.patch_type)) {
            fprintf(stderr, "Invalid patch type '%s'\n", patch_type_str.c_str());
            return {};
        }
        ps.push_back(std::move(pm));
        i += j;
    }

    return ps;
}

bool createNewImg(std::shared_ptr<ir::DexFile> dex_ir, const char* out_dex_filename) {
    struct Allocator : public dex::Writer::Allocator {
        virtual void* Allocate(size_t size) { return ::malloc(size); }
        virtual void Free(void* ptr) { ::free(ptr); }
    };

    size_t new_image_size = 0;
    dex::u1* new_image = nullptr;
    Allocator allocator;

    dex::Writer writer(dex_ir);
    new_image = writer.CreateImage(&allocator, &new_image_size);

    if (new_image == nullptr) {
        fprintf(stderr, "Cannot create a new .dex image\n");
        return false;
    }

    FILE* out_file = fopen(out_dex_filename, "wb");
    if (out_file == nullptr) {
        fprintf(stderr, "Cannot create output .dex file (%s)\n", out_dex_filename);
        return false;
    }
    assert(fwrite(new_image, 1, new_image_size, out_file) == new_image_size);
    fclose(out_file);
    allocator.Free(new_image);

    return true;
}

void retEmptyList(lir::CodeIr& code_ir, ir::Builder& builder) {
    ir::MethodDecl* mdecl =
        builder.GetMethodDecl(builder.GetAsciiString("emptyList"),
                              builder.GetProto(builder.GetType("Ljava/util/List;"), builder.GetTypeList({})),
                              builder.GetType("Ljava/util/Collections;"));

    auto* invokeOp = code_ir.Alloc<lir::Bytecode>();
    invokeOp->opcode = dex::OP_INVOKE_STATIC;
    invokeOp->operands.push_back(code_ir.Alloc<lir::VRegList>());
    invokeOp->operands.push_back(code_ir.Alloc<lir::Method>(mdecl, mdecl->orig_index));

    auto* moveOp = code_ir.Alloc<lir::Bytecode>();
    moveOp->opcode = dex::OP_MOVE_RESULT_OBJECT;
    moveOp->operands.push_back(code_ir.Alloc<lir::VReg>(1));

    auto* retOp = code_ir.Alloc<lir::Bytecode>();
    retOp->opcode = dex::OP_RETURN_OBJECT;
    retOp->operands.push_back(code_ir.Alloc<lir::VReg>(1));

    code_ir.instructions.insert(code_ir.instructions.begin(), retOp);
    code_ir.instructions.insert(code_ir.instructions.begin(), moveOp);
    code_ir.instructions.insert(code_ir.instructions.begin(), invokeOp);
}

void retEmptyListField(lir::CodeIr& code_ir, ir::Builder& builder) {
    auto* sgetOp = code_ir.Alloc<lir::Bytecode>();
    sgetOp->opcode = dex::OP_SGET_OBJECT;
    sgetOp->operands.push_back(code_ir.Alloc<lir::VReg>(0));

    auto fieldDecl =
        builder.GetFieldDecl(builder.GetAsciiString("EMPTY_LIST"), builder.GetType("Ljava/util/Collections;"),
                             builder.GetType("Ljava/util/List;"));

    auto* field = code_ir.Alloc<lir::Field>(fieldDecl, fieldDecl->orig_index);
    sgetOp->operands.push_back(field);

    auto* retOp = code_ir.Alloc<lir::Bytecode>();
    retOp->opcode = dex::OP_RETURN_OBJECT;
    retOp->operands.push_back(code_ir.Alloc<lir::VReg>(0));

    code_ir.instructions.insert(code_ir.instructions.begin(), retOp);
    code_ir.instructions.insert(code_ir.instructions.begin(), sgetOp);
}

void retConst(lir::CodeIr& code_ir, ir::Builder& builder, int v) {
    lir::Bytecode* retOp = code_ir.Alloc<lir::Bytecode>();
    retOp->opcode = dex::OP_RETURN;
    retOp->operands.push_back(code_ir.Alloc<lir::VReg>(0));

    lir::Bytecode* constOp = code_ir.Alloc<lir::Bytecode>();
    constOp->opcode = dex::OP_CONST_4;
    constOp->operands.push_back(code_ir.Alloc<lir::VReg>(0));
    constOp->operands.push_back(code_ir.Alloc<lir::Const32>(v));

    code_ir.instructions.insert(code_ir.instructions.begin(), retOp);
    code_ir.instructions.insert(code_ir.instructions.begin(), constOp);
}

ir::EncodedMethod* findMethod(std::shared_ptr<ir::DexFile> dex_ir, PatchMethod& p) {
    ir::EncodedMethod* method = nullptr;
    for (auto& ir_method : dex_ir->encoded_methods) {
        // printf("%s->%s%s\n", ir_method->decl->parent->Decl().c_str(), ir_method->decl->name->c_str(),
        //        ir_method->decl->prototype->Signature().c_str());

        if (strcmp(ir_method->decl->name->c_str(), p.method_name.c_str()) == 0 &&
            strcmp(ir_method->decl->prototype->return_type->descriptor->c_str(), retTypeFromPatch(p.patch_type)) == 0 &&
            (p.parent_name.empty() || strcmp(ir_method->decl->parent->Decl().c_str(), p.parent_name.c_str()) == 0) &&
            ir_method->code != nullptr

        ) {
            method = ir_method.get();
            break;
        }
    }
    return method;
}

void patchDex(std::shared_ptr<ir::DexFile> dex_ir, PatchMethod& p, ir::EncodedMethod* method) {
    method->code->registers = method->code->ins_count + 1;

    lir::CodeIr code_ir(method, dex_ir);
    ir::Builder builder(dex_ir);

    auto it = code_ir.instructions.begin();
    while (it != code_ir.instructions.end()) {
        auto instr = *it++;
        code_ir.instructions.Remove(instr);
    }

    switch (p.patch_type) {
        case PatchType::RET_EMPTY_LIST:
            retEmptyList(code_ir, builder);
            break;
        case PatchType::RET_FALSE:
            retConst(code_ir, builder, 0);
            break;
        case PatchType::RET_TRUE:
            retConst(code_ir, builder, 1);
            break;
        default:
            assert(false && "unreachable");
    }
    code_ir.Assemble();
}

static void printUsage(const char* program_name) {
    fprintf(stderr,
            "Usage:\n  %s <in dex> <out dex> <patch definitions>\n"
            "  Example patch defs.:\n"
            "    methodName1:RET_FALSE;\n"
            "    methodName2:RET_TRUE;\n"
            "    methodName3:RET_EMPTY_LIST;\n",
            program_name);
}

int main(int argc, char* argv[]) {
    if (argc != 4) {
        printUsage(argv[0]);
        return 1;
    }
    const char* dex_filename = argv[1];
    const char* out_dex_filename = argv[2];
    auto patches = parsePatchesArg(argv[3]);
    if (patches.empty()) {
        printUsage(argv[0]);
        return 1;
    }

    struct stat path_stat;
    stat(dex_filename, &path_stat);
    if (!S_ISREG(path_stat.st_mode)) {
        fprintf(stderr, "'%s' is not a regular file.\n", dex_filename);
        return 1;
    }

    FILE* in_file = fopen(dex_filename, "rb");
    if (in_file == nullptr) {
        fprintf(stderr, "Cannot open input .dex file (%s)\n", dex_filename);
        return 1;
    }

    fseek(in_file, 0, SEEK_END);
    size_t in_size = ftell(in_file);

    std::unique_ptr<dex::u1[]> in_buff(new dex::u1[in_size]);

    fseek(in_file, 0, SEEK_SET);
    assert(fread(in_buff.get(), 1, in_size, in_file) == in_size);

    dex::Reader reader(in_buff.get(), in_size);
    reader.CreateFullIr();
    auto dex_ir = reader.GetIr();

    bool patched = false;
    for (auto& p : patches) {
        auto method = findMethod(dex_ir, p);
        if (method == nullptr) {
            printf("Method not found: %s()%s\n", p.method_name.c_str(), retTypeFromPatch(p.patch_type));
            continue;
        }
        patchDex(dex_ir, p, method);
        printf("Patched: %s\n", p.method_name.c_str());
        patched = true;
    }
    fclose(in_file);

    if (patched) {
        if (!createNewImg(dex_ir, out_dex_filename)) return 1;
    }

    return 0;
}

```

`paccer/jni/slicer/Makefile`:

```
SLICER_SRCS := \
    bytecode_encoder.cc \
    code_ir.cc \
    common.cc \
    control_flow_graph.cc \
    debuginfo_encoder.cc \
    dex_bytecode.cc \
    dex_format.cc \
    dex_ir.cc \
    dex_ir_builder.cc \
    dex_utf8.cc \
    instrumentation.cc \
    reader.cc \
    tryblocks_encoder.cc \
    writer.cc

SLICER_INCLUDES := -I./export
SLICER_CFLAGS := \
    -ggdb \
    -Wall \
    -Wno-sign-compare \
    -Wno-unused-parameter \
    -Wno-shift-count-overflow \
    -Wno-missing-braces

SLICER_LIBS := -lz

libslicer.a: $(SLICER_SRCS)
	g++ -std=c++17 -fno-rtti -static $(SLICER_CFLAGS) $(SLICER_INCLUDES) -c $(SLICER_SRCS)
	ar rcs $@ *.o
	rm -f *.o

.PHONY: all clean

all: libslice.so

clean:
	rm -f *.o libslice.so

```

`paccer/jni/slicer/bytecode_encoder.cc`:

```cc
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include "slicer/bytecode_encoder.h"

#include "slicer/common.h"
#include "slicer/chronometer.h"

#include <assert.h>
#include <sstream>
#include <iomanip>

namespace lir {

// Pack a 16bit word: 00AA
static dex::u2 Pack_Z_8(dex::u4 a) {
  dex::u2 fa = (a & 0xff);
  SLICER_CHECK_EQ(fa, a);
  return fa;
}

// Pack a 16bit word: AABB
static dex::u2 Pack_8_8(dex::u4 a, dex::u4 b) {
  dex::u2 fa = (a & 0xff);
  SLICER_CHECK_EQ(fa, a);
  dex::u2 fb = (b & 0xff);
  SLICER_CHECK_EQ(fb, b);
  return (fa << 8) | fb;
}

// Pack a 16bit word: ABCC
static dex::u2 Pack_4_4_8(dex::u4 a, dex::u4 b, dex::u4 c) {
  dex::u2 fa = (a & 0xf);
  SLICER_CHECK_EQ(fa, a);
  dex::u2 fb = (b & 0xf);
  SLICER_CHECK_EQ(fb, b);
  dex::u2 fc = (c & 0xff);
  SLICER_CHECK_EQ(fc, c);
  return (fa << 12) | (fb << 8) | fc;
}

// Pack a 16bit word: ABCD
static dex::u2 Pack_4_4_4_4(dex::u4 a, dex::u4 b, dex::u4 c, dex::u4 d) {
  dex::u2 fa = (a & 0xf);
  SLICER_CHECK_EQ(fa, a);
  dex::u2 fb = (b & 0xf);
  SLICER_CHECK_EQ(fb, b);
  dex::u2 fc = (c & 0xf);
  SLICER_CHECK_EQ(fc, c);
  dex::u2 fd = (d & 0xf);
  SLICER_CHECK_EQ(fd, d);
  return (fa << 12) | (fb << 8) | (fc << 4) | fd;
}

// Pack a 16bit word: AAAA
static dex::u2 Pack_16(dex::u4 a) {
  dex::u2 fa = (a & 0xffff);
  SLICER_CHECK_EQ(fa, a);
  return fa;
}

// Trim a 4bit signed integer, making sure we're not discarding significant bits
static dex::u4 Trim_S0(dex::u4 value) {
  dex::u4 trim = value & 0xf;
  SLICER_CHECK_EQ(dex::u4(dex::s4(trim << 28) >> 28), value);
  return trim;
}

// Trim a 8bit signed integer, making sure we're not discarding significant bits
static dex::u4 Trim_S1(dex::u4 value) {
  dex::u4 trim = value & 0xff;
  SLICER_CHECK_EQ(dex::u4(dex::s4(trim << 24) >> 24), value);
  return trim;
}

// Trim a 16bit signed integer, making sure we're not discarding significant bits
static dex::u4 Trim_S2(dex::u4 value) {
  dex::u4 trim = value & 0xffff;
  SLICER_CHECK_EQ(dex::u4(dex::s4(trim << 16) >> 16), value);
  return trim;
}

// Returns a register operand, checking the match between format and type
// (register fields can encode either a single 32bit vreg or a wide 64bit vreg pair)
static dex::u4 GetRegA(const Bytecode* bytecode, int index) {
  auto verify_flags = dex::GetVerifyFlagsFromOpcode(bytecode->opcode);
  return (verify_flags & dex::kVerifyRegAWide) != 0
             ? bytecode->CastOperand<VRegPair>(index)->base_reg
             : bytecode->CastOperand<VReg>(index)->reg;
}

// Returns a register operand, checking the match between format and type
// (register fields can encode either a single 32bit vreg or a wide 64bit vreg pair)
static dex::u4 GetRegB(const Bytecode* bytecode, int index) {
  auto verify_flags = dex::GetVerifyFlagsFromOpcode(bytecode->opcode);
  return (verify_flags & dex::kVerifyRegBWide) != 0
             ? bytecode->CastOperand<VRegPair>(index)->base_reg
             : bytecode->CastOperand<VReg>(index)->reg;
}

// Returns a register operand, checking the match between format and type
// (register fields can encode either a single 32bit vreg or a wide 64bit vreg pair)
static dex::u4 GetRegC(const Bytecode* bytecode, int index) {
  auto verify_flags = dex::GetVerifyFlagsFromOpcode(bytecode->opcode);
  return (verify_flags & dex::kVerifyRegCWide) != 0
             ? bytecode->CastOperand<VRegPair>(index)->base_reg
             : bytecode->CastOperand<VReg>(index)->reg;
}

// Encode one instruction into a .dex bytecode
//
// NOTE: the formats and the operand notation is documented here:
//   https://source.android.com/devices/tech/dalvik/instruction-formats.html
//
bool BytecodeEncoder::Visit(Bytecode* bytecode) {
  bytecode->offset = offset_;
  dex::Opcode opcode = bytecode->opcode;

  // Unconditionally replace short (8bit) branches with
  // medium-range (16bit) branches. This should cover 99.999% of
  // the cases and it avoids a more complex branch length handling.
  if (opcode == dex::OP_GOTO) {
    opcode = dex::OP_GOTO_16;
  }

  auto buff_offset = bytecode_.size();
  auto format = dex::GetFormatFromOpcode(opcode);

  switch (format) {
    case dex::k10x:  // op
    {
      SLICER_CHECK_EQ(bytecode->operands.size(), 0);
      bytecode_.Push<dex::u2>(Pack_Z_8(opcode));
    } break;

    case dex::k12x:  // op vA, vB
    {
      SLICER_CHECK_EQ(bytecode->operands.size(), 2);
      dex::u4 vA = GetRegA(bytecode, 0);
      dex::u4 vB = GetRegB(bytecode, 1);
      bytecode_.Push<dex::u2>(Pack_4_4_8(vB, vA, opcode));
    } break;

    case dex::k22x:  // op vAA, vBBBB
    {
      SLICER_CHECK_EQ(bytecode->operands.size(), 2);
      dex::u4 vA = GetRegA(bytecode, 0);
      dex::u4 vB = GetRegB(bytecode, 1);
      bytecode_.Push<dex::u2>(Pack_8_8(vA, opcode));
      bytecode_.Push<dex::u2>(Pack_16(vB));
    } break;

    case dex::k32x:  // op vAAAA, vBBBB
    {
      SLICER_CHECK_EQ(bytecode->operands.size(), 2);
      dex::u4 vA = GetRegA(bytecode, 0);
      dex::u4 vB = GetRegB(bytecode, 1);
      bytecode_.Push<dex::u2>(Pack_Z_8(opcode));
      bytecode_.Push<dex::u2>(Pack_16(vA));
      bytecode_.Push<dex::u2>(Pack_16(vB));
    } break;

    case dex::k11n:  // op vA, #+B
    {
      SLICER_CHECK_EQ(bytecode->operands.size(), 2);
      dex::u4 vA = GetRegA(bytecode, 0);
      dex::u4 B = Trim_S0(bytecode->CastOperand<Const32>(1)->u.u4_value);
      bytecode_.Push<dex::u2>(Pack_4_4_8(B, vA, opcode));
    } break;

    case dex::k21s:  // op vAA, #+BBBB
    {
      SLICER_CHECK_EQ(bytecode->operands.size(), 2);
      dex::u4 vA = GetRegA(bytecode, 0);
      dex::u4 B = Trim_S2(bytecode->CastOperand<Const32>(1)->u.u4_value);
      bytecode_.Push<dex::u2>(Pack_8_8(vA, opcode));
      bytecode_.Push<dex::u2>(Pack_16(B));
    } break;

    case dex::k11x:  // op vAA
    {
      SLICER_CHECK_EQ(bytecode->operands.size(), 1);
      dex::u4 vA = GetRegA(bytecode, 0);
      bytecode_.Push<dex::u2>(Pack_8_8(vA, opcode));
    } break;

    case dex::k31i:  // op vAA, #+BBBBBBBB
    {
      SLICER_CHECK_EQ(bytecode->operands.size(), 2);
      dex::u4 vA = GetRegA(bytecode, 0);
      dex::u4 B = bytecode->CastOperand<Const32>(1)->u.u4_value;
      bytecode_.Push<dex::u2>(Pack_8_8(vA, opcode));
      bytecode_.Push<dex::u2>(Pack_16(B & 0xffff));
      bytecode_.Push<dex::u2>(Pack_16(B >> 16));
    } break;

    case dex::k20t:  // op +AAAA
    {
      SLICER_CHECK_EQ(bytecode->operands.size(), 1);
      auto label = bytecode->CastOperand<CodeLocation>(0)->label;
      dex::u4 A = 0;
      if (label->offset != kInvalidOffset) {
        assert(label->offset <= offset_);
        A = label->offset - offset_;
        SLICER_CHECK_NE(A, 0);
        SLICER_CHECK_EQ((A >> 16), 0xffff);  // TODO: out of range!
      } else {
        fixups_.push_back(LabelFixup(offset_, label, true));
      }
      bytecode_.Push<dex::u2>(Pack_Z_8(opcode));
      bytecode_.Push<dex::u2>(Pack_16(A & 0xffff));
    } break;

    case dex::k30t:  // op +AAAAAAAA
    {
      SLICER_CHECK_EQ(bytecode->operands.size(), 1);
      auto label = bytecode->CastOperand<CodeLocation>(0)->label;
      dex::u4 A = 0;
      if (label->offset != kInvalidOffset) {
        // NOTE: goto/32 can branch to itself
        assert(label->offset <= offset_);
        A = label->offset - offset_;
      } else {
        fixups_.push_back(LabelFixup(offset_, label, false));
      }
      bytecode_.Push<dex::u2>(Pack_Z_8(opcode));
      bytecode_.Push<dex::u2>(Pack_16(A & 0xffff));
      bytecode_.Push<dex::u2>(Pack_16(A >> 16));
    } break;

    case dex::k21t:  // op vAA, +BBBB
    {
      SLICER_CHECK_EQ(bytecode->operands.size(), 2);
      dex::u4 vA = GetRegA(bytecode, 0);
      auto label = bytecode->CastOperand<CodeLocation>(1)->label;
      dex::u4 B = 0;
      if (label->offset != kInvalidOffset) {
        assert(label->offset <= offset_);
        B = label->offset - offset_;
        SLICER_CHECK_NE(B, 0);
        SLICER_CHECK_EQ((B >> 16), 0xffff);  // TODO: out of range!
      } else {
        fixups_.push_back(LabelFixup(offset_, label, true));
      }
      bytecode_.Push<dex::u2>(Pack_8_8(vA, opcode));
      bytecode_.Push<dex::u2>(Pack_16(B & 0xffff));
    } break;

    case dex::k22t:  // op vA, vB, +CCCC
    {
      SLICER_CHECK_EQ(bytecode->operands.size(), 3);
      dex::u4 vA = GetRegA(bytecode, 0);
      dex::u4 vB = GetRegB(bytecode, 1);
      auto label = bytecode->CastOperand<CodeLocation>(2)->label;
      dex::u4 C = 0;
      if (label->offset != kInvalidOffset) {
        assert(label->offset <= offset_);
        C = label->offset - offset_;
        SLICER_CHECK_NE(C, 0);
        SLICER_CHECK_EQ((C >> 16), 0xffff);  // TODO: out of range!
      } else {
        fixups_.push_back(LabelFixup(offset_, label, true));
      }
      bytecode_.Push<dex::u2>(Pack_4_4_8(vB, vA, opcode));
      bytecode_.Push<dex::u2>(Pack_16(C & 0xffff));
    } break;

    case dex::k31t:  // op vAA, +BBBBBBBB
    {
      SLICER_CHECK_EQ(bytecode->operands.size(), 2);
      dex::u4 vA = GetRegA(bytecode, 0);
      auto label = bytecode->CastOperand<CodeLocation>(1)->label;
      dex::u4 B = 0;
      if (label->offset != kInvalidOffset) {
        assert(label->offset <= offset_);
        B = label->offset - offset_;
        SLICER_CHECK_NE(B, 0);
      } else {
        fixups_.push_back(LabelFixup(offset_, label, false));
      }
      bytecode_.Push<dex::u2>(Pack_8_8(vA, opcode));
      bytecode_.Push<dex::u2>(Pack_16(B & 0xffff));
      bytecode_.Push<dex::u2>(Pack_16(B >> 16));
    } break;

    case dex::k23x:  // op vAA, vBB, vCC
    {
      SLICER_CHECK_EQ(bytecode->operands.size(), 3);
      dex::u4 vA = GetRegA(bytecode, 0);
      dex::u4 vB = GetRegB(bytecode, 1);
      dex::u4 vC = GetRegC(bytecode, 2);
      bytecode_.Push<dex::u2>(Pack_8_8(vA, opcode));
      bytecode_.Push<dex::u2>(Pack_8_8(vC, vB));
    } break;

    case dex::k22b:  // op vAA, vBB, #+CC
    {
      SLICER_CHECK_EQ(bytecode->operands.size(), 3);
      dex::u4 vA = GetRegA(bytecode, 0);
      dex::u4 vB = GetRegB(bytecode, 1);
      dex::u4 C = Trim_S1(bytecode->CastOperand<Const32>(2)->u.u4_value);
      bytecode_.Push<dex::u2>(Pack_8_8(vA, opcode));
      bytecode_.Push<dex::u2>(Pack_8_8(C, vB));
    } break;

    case dex::k22s:  // op vA, vB, #+CCCC
    {
      SLICER_CHECK_EQ(bytecode->operands.size(), 3);
      dex::u4 vA = GetRegA(bytecode, 0);
      dex::u4 vB = GetRegB(bytecode, 1);
      dex::u4 C = Trim_S2(bytecode->CastOperand<Const32>(2)->u.u4_value);
      bytecode_.Push<dex::u2>(Pack_4_4_8(vB, vA, opcode));
      bytecode_.Push<dex::u2>(Pack_16(C));
    } break;

    case dex::k22c:  // op vA, vB, thing@CCCC
    {
      SLICER_CHECK_EQ(bytecode->operands.size(), 3);
      dex::u4 vA = GetRegA(bytecode, 0);
      dex::u4 vB = GetRegB(bytecode, 1);
      dex::u4 C = bytecode->CastOperand<IndexedOperand>(2)->index;
      bytecode_.Push<dex::u2>(Pack_4_4_8(vB, vA, opcode));
      bytecode_.Push<dex::u2>(Pack_16(C));
    } break;

    case dex::k21c:  // op vAA, thing@BBBB
    {
      SLICER_CHECK_EQ(bytecode->operands.size(), 2);
      dex::u4 vA = GetRegA(bytecode, 0);
      dex::u4 B = bytecode->CastOperand<IndexedOperand>(1)->index;
      bytecode_.Push<dex::u2>(Pack_8_8(vA, opcode));
      bytecode_.Push<dex::u2>(Pack_16(B));
    } break;

    case dex::k31c:  // op vAA, string@BBBBBBBB
    {
      SLICER_CHECK_EQ(bytecode->operands.size(), 2);
      dex::u4 vA = GetRegA(bytecode, 0);
      dex::u4 B = bytecode->CastOperand<IndexedOperand>(1)->index;
      bytecode_.Push<dex::u2>(Pack_8_8(vA, opcode));
      bytecode_.Push<dex::u2>(Pack_16(B & 0xffff));
      bytecode_.Push<dex::u2>(Pack_16(B >> 16));
    } break;

    case dex::k35c:  // op {vC,vD,vE,vF,vG}, thing@BBBB
    {
      SLICER_CHECK_EQ(bytecode->operands.size(), 2);
      const auto& regs = bytecode->CastOperand<VRegList>(0)->registers;
      dex::u4 B = bytecode->CastOperand<IndexedOperand>(1)->index;
      dex::u4 A = regs.size();
      dex::u4 C = (A > 0) ? regs[0] : 0;
      dex::u4 D = (A > 1) ? regs[1] : 0;
      dex::u4 E = (A > 2) ? regs[2] : 0;
      dex::u4 F = (A > 3) ? regs[3] : 0;
      dex::u4 G = (A > 4) ? regs[4] : 0;
      bytecode_.Push<dex::u2>(Pack_4_4_8(A, G, opcode));
      bytecode_.Push<dex::u2>(Pack_16(B));
      bytecode_.Push<dex::u2>(Pack_4_4_4_4(F, E, D, C));

      // keep track of the outs_count
      if ((dex::GetFlagsFromOpcode(opcode) & dex::kInvoke) != 0) {
        outs_count_ = std::max(outs_count_, A);
      }
    } break;

    case dex::k3rc:  // op {vCCCC .. v(CCCC+AA-1)}, thing@BBBB
    {
      SLICER_CHECK_EQ(bytecode->operands.size(), 2);
      auto vreg_range = bytecode->CastOperand<VRegRange>(0);
      dex::u4 A = vreg_range->count;
      dex::u4 B = bytecode->CastOperand<IndexedOperand>(1)->index;
      dex::u4 C = vreg_range->base_reg;
      bytecode_.Push<dex::u2>(Pack_8_8(A, opcode));
      bytecode_.Push<dex::u2>(Pack_16(B));
      bytecode_.Push<dex::u2>(Pack_16(C));

      // keep track of the outs_count
      if ((dex::GetFlagsFromOpcode(opcode) & dex::kInvoke) != 0) {
        outs_count_ = std::max(outs_count_, A);
      }
    } break;

    case dex::k51l:  // op vAA, #+BBBBBBBBBBBBBBBB
    {
      SLICER_CHECK_EQ(bytecode->operands.size(), 2);
      dex::u4 vA = GetRegA(bytecode, 0);
      dex::u8 B = bytecode->CastOperand<Const64>(1)->u.u8_value;
      bytecode_.Push<dex::u2>(Pack_8_8(vA, opcode));
      bytecode_.Push<dex::u2>(Pack_16((B >> 0) & 0xffff));
      bytecode_.Push<dex::u2>(Pack_16((B >> 16) & 0xffff));
      bytecode_.Push<dex::u2>(Pack_16((B >> 32) & 0xffff));
      bytecode_.Push<dex::u2>(Pack_16((B >> 48) & 0xffff));
    } break;

    case dex::k45cc:  // op {vC, vD, vE, vF, vG}, thing@BBBB, other@HHHH
    {
      SLICER_CHECK_EQ(bytecode->operands.size(), 3);
      const auto& regs = bytecode->CastOperand<VRegList>(0)->registers;
      dex::u4 A = regs.size();
      dex::u4 B = bytecode->CastOperand<IndexedOperand>(1)->index;
      dex::u4 H = bytecode->CastOperand<IndexedOperand>(2)->index;
      dex::u4 C = (A > 0) ? regs[0] : 0;
      dex::u4 D = (A > 1) ? regs[1] : 0;
      dex::u4 E = (A > 2) ? regs[2] : 0;
      dex::u4 F = (A > 3) ? regs[3] : 0;
      dex::u4 G = (A > 4) ? regs[4] : 0;
      bytecode_.Push<dex::u2>(Pack_4_4_8(A, G, opcode));
      bytecode_.Push<dex::u2>(Pack_16(B));
      bytecode_.Push<dex::u2>(Pack_4_4_4_4(F, E, D, C));
      bytecode_.Push<dex::u2>(Pack_16(H));

      // keep track of the outs_count
      if ((dex::GetFlagsFromOpcode(opcode) & dex::kInvoke) != 0) {
        outs_count_ = std::max(outs_count_, A);
      }
    } break;

    case dex::k4rcc:  // op {vCCCC .. v(CCCC+AA-1)}, thing@BBBB, other@HHHH
    {
      SLICER_CHECK_EQ(bytecode->operands.size(), 3);
      auto vreg_range = bytecode->CastOperand<VRegRange>(0);
      dex::u4 A = vreg_range->count;
      dex::u4 B = bytecode->CastOperand<IndexedOperand>(1)->index;
      dex::u4 C = vreg_range->base_reg;
      dex::u4 H = bytecode->CastOperand<IndexedOperand>(2)->index;
      bytecode_.Push<dex::u2>(Pack_8_8(A, opcode));
      bytecode_.Push<dex::u2>(Pack_16(B));
      bytecode_.Push<dex::u2>(Pack_16(C));
      bytecode_.Push<dex::u2>(Pack_16(H));

      // keep track of the outs_count
      if ((dex::GetFlagsFromOpcode(opcode) & dex::kInvoke) != 0) {
        outs_count_ = std::max(outs_count_, A);
      }
    } break;

    case dex::k21h:  // op vAA, #+BBBB0000[00000000]
      SLICER_CHECK_EQ(bytecode->operands.size(), 2);
      switch (opcode) {
        case dex::OP_CONST_HIGH16: {
          dex::u4 vA = GetRegA(bytecode, 0);
          dex::u4 B = bytecode->CastOperand<Const32>(1)->u.u4_value >> 16;
          bytecode_.Push<dex::u2>(Pack_8_8(vA, opcode));
          bytecode_.Push<dex::u2>(Pack_16(B));
        } break;

        case dex::OP_CONST_WIDE_HIGH16: {
          dex::u4 vA = GetRegA(bytecode, 0);
          dex::u4 B = bytecode->CastOperand<Const64>(1)->u.u8_value >> 48;
          bytecode_.Push<dex::u2>(Pack_8_8(vA, opcode));
          bytecode_.Push<dex::u2>(Pack_16(B));
        } break;

        default: {
          std::stringstream ss;
          ss << "Unexpected fmt21h opcode: " << opcode;
          SLICER_FATAL(ss.str());
        }
      }
      break;

    default: {
      std::stringstream ss;
      ss << "Unexpected format: " << format;
      SLICER_FATAL(ss.str());
    }
  }

  SLICER_CHECK_EQ(bytecode_.size() - buff_offset, 2 * GetWidthFromFormat(format));
  offset_ += GetWidthFromFormat(format);
  return true;
}

bool BytecodeEncoder::Visit(PackedSwitchPayload* packed_switch) {
  SLICER_CHECK_EQ(offset_ % 2, 0);

  // keep track of the switches
  packed_switch->offset = offset_;
  auto& instr = packed_switches_[offset_];
  SLICER_CHECK_EQ(instr, nullptr);
  instr = packed_switch;

  // we're going to fix up the offsets in a later pass
  auto orig_size = bytecode_.size();
  bytecode_.Push<dex::u2>(dex::kPackedSwitchSignature);
  bytecode_.Push<dex::u2>(Pack_16(packed_switch->targets.size()));
  bytecode_.Push<dex::s4>(packed_switch->first_key);
  for (size_t i = 0; i < packed_switch->targets.size(); ++i) {
    bytecode_.Push<dex::u4>(0);
  }

  // offset is in 16bit units, not bytes
  offset_ += (bytecode_.size() - orig_size) / 2;

  return true;
}

bool BytecodeEncoder::Visit(SparseSwitchPayload* sparse_switch) {
  SLICER_CHECK_EQ(offset_ % 2, 0);

  // keep track of the switches
  sparse_switch->offset = offset_;
  auto& instr = sparse_switches_[offset_];
  SLICER_CHECK_EQ(instr, nullptr);
  instr = sparse_switch;

  // we're going to fix up the offsets in a later pass
  auto orig_size = bytecode_.size();
  bytecode_.Push<dex::u2>(dex::kSparseSwitchSignature);
  bytecode_.Push<dex::u2>(Pack_16(sparse_switch->switch_cases.size()));
  for (const auto& switch_case : sparse_switch->switch_cases) {
    bytecode_.Push<dex::s4>(switch_case.key);
  }
  for (size_t i = 0; i < sparse_switch->switch_cases.size(); ++i) {
    bytecode_.Push<dex::u4>(0);
  }
  offset_ += (bytecode_.size() - orig_size) / 2;

  return true;
}

bool BytecodeEncoder::Visit(ArrayData* array_data) {
  SLICER_CHECK_EQ(offset_ % 2, 0);

  array_data->offset = offset_;
  auto orig_size = bytecode_.size();
  // kArrayDataSignature is already included by array_data->data
  // (no need to emit here)
  bytecode_.Push(array_data->data);
  offset_ += (bytecode_.size() - orig_size) / 2;
  return true;
}

bool BytecodeEncoder::Visit(Label* label) {
  // aligned label?
  if (label->aligned && offset_ % 2 == 1) {
    bytecode_.Push<dex::u2>(dex::OP_NOP);
    ++offset_;
  }

  label->offset = offset_;
  return true;
}

bool BytecodeEncoder::Visit(DbgInfoHeader* dbg_header) {
  dbg_header->offset = offset_;
  return true;
}

bool BytecodeEncoder::Visit(DbgInfoAnnotation* dbg_annotation) {
  dbg_annotation->offset = offset_;
  return true;
}

bool BytecodeEncoder::Visit(TryBlockBegin* try_begin) {
  try_begin->offset = offset_;
  return true;
}

bool BytecodeEncoder::Visit(TryBlockEnd* try_end) {
  try_end->offset = offset_;
  return true;
}

void BytecodeEncoder::FixupSwitchOffsets() {
  dex::u2* const begin = bytecode_.ptr<dex::u2>(0);
  dex::u2* const end = begin + bytecode_.size() / 2;
  dex::u2* ptr = begin;
  while (ptr < end) {
    const auto opcode = dex::OpcodeFromBytecode(*ptr);
    const auto offset = ptr - begin;
    if (opcode == dex::OP_PACKED_SWITCH) {
      auto dex_instr = dex::DecodeInstruction(ptr);
      FixupPackedSwitch(offset, offset + dex::s4(dex_instr.vB));
    } else if (opcode == dex::OP_SPARSE_SWITCH) {
      auto dex_instr = dex::DecodeInstruction(ptr);
      FixupSparseSwitch(offset, offset + dex::s4(dex_instr.vB));
    }
    auto isize = dex::GetWidthFromBytecode(ptr);
    SLICER_CHECK_GT(isize, 0);
    ptr += isize;
  }
  SLICER_CHECK_EQ(ptr, end);
}

void BytecodeEncoder::FixupPackedSwitch(dex::u4 base_offset,
                                        dex::u4 payload_offset) {
  auto instr = packed_switches_[payload_offset];
  SLICER_CHECK_NE(instr, nullptr);

  auto payload = bytecode_.ptr<dex::PackedSwitchPayload>(payload_offset * 2);
  SLICER_CHECK_EQ(payload->ident, dex::kPackedSwitchSignature);
  SLICER_CHECK(reinterpret_cast<dex::u1*>(payload->targets + payload->size) <=
        bytecode_.data() + bytecode_.size());

  for (int i = 0; i < payload->size; ++i) {
    auto label = instr->targets[i];
    assert(label->offset != kInvalidOffset);
    payload->targets[i] = label->offset - base_offset;
  }
}

void BytecodeEncoder::FixupSparseSwitch(dex::u4 base_offset,
                                        dex::u4 payload_offset) {
  auto instr = sparse_switches_[payload_offset];
  SLICER_CHECK_NE(instr, nullptr);

  auto payload = bytecode_.ptr<dex::SparseSwitchPayload>(payload_offset * 2);
  SLICER_CHECK_EQ(payload->ident, dex::kSparseSwitchSignature);

  dex::s4* const targets = payload->data + payload->size;
  SLICER_CHECK(reinterpret_cast<dex::u1*>(targets + payload->size) <=
        bytecode_.data() + bytecode_.size());

  for (int i = 0; i < payload->size; ++i) {
    auto label = instr->switch_cases[i].target;
    assert(label->offset != kInvalidOffset);
    targets[i] = label->offset - base_offset;
  }
}

void BytecodeEncoder::FixupLabels() {
  for (const LabelFixup& fixup : fixups_) {
    dex::u4 label_offset = fixup.label->offset;
    assert(label_offset != kInvalidOffset);
    assert(label_offset > fixup.offset);
    dex::u4 rel_offset = label_offset - fixup.offset;
    SLICER_CHECK_NE(rel_offset, 0);
    dex::u2* instr = bytecode_.ptr<dex::u2>(fixup.offset * 2);
    if (fixup.short_fixup) {
      // TODO: explicit out-of-range check
      assert(instr[1] == 0);
      instr[1] = Pack_16(rel_offset);
    } else {
      assert(instr[1] == 0);
      assert(instr[2] == 0);
      instr[1] = Pack_16(rel_offset & 0xffff);
      instr[2] = Pack_16(rel_offset >> 16);
    }
  }
}

void BytecodeEncoder::Encode(ir::Code* ir_code, std::shared_ptr<ir::DexFile> dex_ir) {
  SLICER_CHECK(bytecode_.empty());
  SLICER_CHECK_EQ(offset_, 0);
  SLICER_CHECK_EQ(outs_count_, 0);

  packed_switches_.clear();
  sparse_switches_.clear();

  // reset all instruction offsets
  for (auto instr : instructions_) {
    instr->offset = kInvalidOffset;
  }

  // generate the .dex bytecodes
  for (auto instr : instructions_) {
    instr->Accept(this);
  }

  // no more appending (read & write is ok)
  bytecode_.Seal(2);

  FixupLabels();
  FixupSwitchOffsets();

  // update ir::Code
  ir_code->instructions = slicer::ArrayView<const dex::u2>(
      bytecode_.ptr<dex::u2>(0), bytecode_.size() / 2);
  ir_code->outs_count = outs_count_;

  // attach the new bytecode
  dex_ir->AttachBuffer(std::move(bytecode_));
}

}  // namespace lir

```

`paccer/jni/slicer/code_ir.cc`:

```cc
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include "slicer/code_ir.h"

#include "slicer/bytecode_encoder.h"
#include "slicer/common.h"
#include "slicer/debuginfo_encoder.h"
#include "slicer/dex_bytecode.h"
#include "slicer/dex_format.h"
#include "slicer/dex_ir.h"
#include "slicer/dex_leb128.h"
#include "slicer/tryblocks_encoder.h"

#include <algorithm>
#include <iomanip>
#include <sstream>
#include <vector>

namespace lir {

void CodeIr::Assemble() {
  auto ir_code = ir_method->code;
  SLICER_CHECK_NE(ir_code, nullptr);

  // new .dex bytecode
  //
  // NOTE: this must be done before the debug information and
  //   try/catch blocks since here is where we update the final offsets
  //
  BytecodeEncoder bytecode_encoder(instructions);
  bytecode_encoder.Encode(ir_code, dex_ir);

  // debug information
  if (ir_code->debug_info != nullptr) {
    DebugInfoEncoder dbginfo_encoder(instructions);
    dbginfo_encoder.Encode(ir_method, dex_ir);
  }

  // try/catch blocks
  TryBlocksEncoder try_blocks_encoder(instructions);
  try_blocks_encoder.Encode(ir_code, dex_ir);
}

void CodeIr::DisassembleTryBlocks(const ir::Code* ir_code) {
  int nextTryBlockId = 1;
  for (const auto& tryBlock : ir_code->try_blocks) {
    auto try_block_begin = Alloc<TryBlockBegin>();
    try_block_begin->id = nextTryBlockId++;
    try_block_begin->offset = tryBlock.start_addr;

    auto try_block_end = Alloc<TryBlockEnd>();
    try_block_end->try_begin = try_block_begin;
    try_block_end->offset = tryBlock.start_addr + tryBlock.insn_count;

    // parse the catch handlers
    const dex::u1* ptr =
        ir_code->catch_handlers.ptr<dex::u1>() + tryBlock.handler_off;
    int catchCount = dex::ReadSLeb128(&ptr);

    for (int catchIndex = 0; catchIndex < std::abs(catchCount); ++catchIndex) {
      CatchHandler handler = {};

      // type
      dex::u4 type_index = dex::ReadULeb128(&ptr);
      handler.ir_type = dex_ir->types_map[type_index];
      SLICER_CHECK_NE(handler.ir_type, nullptr);

      // address
      dex::u4 address = dex::ReadULeb128(&ptr);
      handler.label = GetLabel(address);

      try_block_end->handlers.push_back(handler);
    }

    // catch_all handler?
    //
    // NOTE: this is used to generate code for the "finally" blocks
    //  (see Java Virtual Machine Specification - 3.13 "Compiling finally")
    //
    if (catchCount < 1) {
      dex::u4 address = dex::ReadULeb128(&ptr);
      try_block_end->catch_all = GetLabel(address);
    }

    // we should have at least one handler
    SLICER_CHECK(!try_block_end->handlers.empty() ||
          try_block_end->catch_all != nullptr);

    try_begins_.push_back(try_block_begin);
    try_ends_.push_back(try_block_end);
  }
}

void CodeIr::DisassembleDebugInfo(const ir::DebugInfo* ir_debug_info) {
  if (ir_debug_info == nullptr) {
    return;
  }

  // debug info state machine registers
  dex::u4 address = 0;
  int line = ir_debug_info->line_start;
  ir::String* source_file = ir_method->decl->parent->class_def->source_file;

  // header
  if (!ir_debug_info->param_names.empty()) {
    auto dbg_header = Alloc<DbgInfoHeader>();
    dbg_header->param_names = ir_debug_info->param_names;
    dbg_header->offset = 0;
    dbg_annotations_.push_back(dbg_header);
  }

  // initial source file
  {
    auto annotation = Alloc<DbgInfoAnnotation>(dex::DBG_SET_FILE);
    annotation->offset = 0;
    annotation->operands.push_back(Alloc<String>(
        source_file, source_file ? source_file->orig_index : dex::kNoIndex));
    dbg_annotations_.push_back(annotation);
  }

  // initial line number - redundant?
  {
    auto annotation = Alloc<DbgInfoAnnotation>(dex::DBG_ADVANCE_LINE);
    annotation->offset = 0;
    annotation->operands.push_back(Alloc<LineNumber>(line));
    dbg_annotations_.push_back(annotation);
  }

  // debug info annotations
  const dex::u1* ptr = ir_debug_info->data.ptr<dex::u1>();
  dex::u1 opcode = 0;
  while ((opcode = *ptr++) != dex::DBG_END_SEQUENCE) {
    DbgInfoAnnotation* annotation = nullptr;

    switch (opcode) {
      case dex::DBG_ADVANCE_PC:
        // addr_diff
        address += dex::ReadULeb128(&ptr);
        break;

      case dex::DBG_ADVANCE_LINE:
        // line_diff
        line += dex::ReadSLeb128(&ptr);
        SLICER_WEAK_CHECK(line >= 0);
        break;

      case dex::DBG_START_LOCAL: {
        annotation = Alloc<DbgInfoAnnotation>(opcode);

        // register_num
        annotation->operands.push_back(Alloc<VReg>(dex::ReadULeb128(&ptr)));

        // name
        dex::u4 name_index = dex::ReadULeb128(&ptr) - 1;
        annotation->operands.push_back(GetString(name_index));

        // type
        dex::u4 type_index = dex::ReadULeb128(&ptr) - 1;
        annotation->operands.push_back(GetType(type_index));
      } break;

      case dex::DBG_START_LOCAL_EXTENDED: {
        annotation = Alloc<DbgInfoAnnotation>(opcode);

        // register_num
        annotation->operands.push_back(Alloc<VReg>(dex::ReadULeb128(&ptr)));

        // name
        dex::u4 name_index = dex::ReadULeb128(&ptr) - 1;
        annotation->operands.push_back(GetString(name_index));

        // type
        dex::u4 type_index = dex::ReadULeb128(&ptr) - 1;
        annotation->operands.push_back(GetType(type_index));

        // signature
        dex::u4 sig_index = dex::ReadULeb128(&ptr) - 1;
        annotation->operands.push_back(GetString(sig_index));
      } break;

      case dex::DBG_END_LOCAL:
      case dex::DBG_RESTART_LOCAL:
        annotation = Alloc<DbgInfoAnnotation>(opcode);
        // register_num
        annotation->operands.push_back(Alloc<VReg>(dex::ReadULeb128(&ptr)));
        break;

      case dex::DBG_SET_PROLOGUE_END:
        annotation = Alloc<DbgInfoAnnotation>(opcode);
        break;

      case dex::DBG_SET_EPILOGUE_BEGIN:
        annotation = Alloc<DbgInfoAnnotation>(opcode);
        break;

      case dex::DBG_SET_FILE: {
        annotation = Alloc<DbgInfoAnnotation>(opcode);

        // source file name
        dex::u4 name_index = dex::ReadULeb128(&ptr) - 1;
        source_file = (name_index == dex::kNoIndex)
                          ? nullptr
                          : dex_ir->strings_map[name_index];
        annotation->operands.push_back(Alloc<String>(source_file, name_index));
      } break;

      default: {
        int adjusted_opcode = opcode - dex::DBG_FIRST_SPECIAL;
        line += dex::DBG_LINE_BASE + (adjusted_opcode % dex::DBG_LINE_RANGE);
        address += (adjusted_opcode / dex::DBG_LINE_RANGE);
        SLICER_WEAK_CHECK(line >= 0);
        annotation = Alloc<DbgInfoAnnotation>(dex::DBG_ADVANCE_LINE);
        annotation->operands.push_back(Alloc<LineNumber>(line));
      } break;
    }

    if (annotation != nullptr) {
      annotation->offset = address;
      dbg_annotations_.push_back(annotation);
    }
  }
}

void CodeIr::DisassembleBytecode(const ir::Code* ir_code) {
  const dex::u2* begin = ir_code->instructions.begin();
  const dex::u2* end = ir_code->instructions.end();
  const dex::u2* ptr = begin;

  while (ptr < end) {
    auto isize = dex::GetWidthFromBytecode(ptr);
    SLICER_CHECK_GT(isize, 0);

    dex::u4 offset = ptr - begin;

    Instruction* instr = nullptr;
    switch (*ptr) {
      case dex::kPackedSwitchSignature:
        instr = DecodePackedSwitch(ptr, offset);
        break;

      case dex::kSparseSwitchSignature:
        instr = DecodeSparseSwitch(ptr, offset);
        break;

      case dex::kArrayDataSignature:
        instr = DecodeArrayData(ptr, offset);
        break;

      default:
        instr = DecodeBytecode(ptr, offset);
        break;
    }

    instr->offset = offset;
    instructions.push_back(instr);
    ptr += isize;
  }
  SLICER_CHECK_EQ(ptr, end);
}

void CodeIr::FixupSwitches() {
  const dex::u2* begin = ir_method->code->instructions.begin();

  // packed switches
  for (auto& fixup : packed_switches_) {
    FixupPackedSwitch(fixup.second.instr, fixup.second.base_offset,
                      begin + fixup.first);
  }

  // sparse switches
  for (auto& fixup : sparse_switches_) {
    FixupSparseSwitch(fixup.second.instr, fixup.second.base_offset,
                      begin + fixup.first);
  }
}

// merge a set of extra instructions into the instruction list
template <class I_LIST, class E_LIST>
static void MergeInstructions(I_LIST& instructions, const E_LIST& extra) {

  // the extra instructins must be sorted by offset
  SLICER_CHECK(std::is_sorted(extra.begin(), extra.end(),
                        [](const Instruction* a, const Instruction* b) {
                          return a->offset < b->offset;
                        }));

  auto instrIt = instructions.begin();
  auto extraIt = extra.begin();

  while (extraIt != extra.end()) {
    if (instrIt == instructions.end() ||
        (*extraIt)->offset == (*instrIt)->offset) {
      instructions.insert(instrIt, *extraIt);
      ++extraIt;
    } else {
      ++instrIt;
    }
  }
}

void CodeIr::Disassemble() {
  nodes_.clear();
  labels_.clear();

  try_begins_.clear();
  try_ends_.clear();
  dbg_annotations_.clear();
  packed_switches_.clear();
  sparse_switches_.clear();

  auto ir_code = ir_method->code;
  if (ir_code == nullptr) {
    return;
  }

  // decode the .dex bytecodes
  DisassembleBytecode(ir_code);

  // try/catch blocks
  DisassembleTryBlocks(ir_code);

  // debug information
  DisassembleDebugInfo(ir_code->debug_info);

  // fixup switches
  FixupSwitches();

  // assign label ids
  std::vector<Label*> tmp_labels;
  int nextLabelId = 1;
  for (auto& label : labels_) {
    label.second->id = nextLabelId++;
    tmp_labels.push_back(label.second);
  }

  // merge the labels into the instructions stream
  MergeInstructions(instructions, dbg_annotations_);
  MergeInstructions(instructions, try_begins_);
  MergeInstructions(instructions, tmp_labels);
  MergeInstructions(instructions, try_ends_);
}

PackedSwitchPayload* CodeIr::DecodePackedSwitch(const dex::u2* /*ptr*/,
                                         dex::u4 offset) {
  // actual decoding is delayed to FixupPackedSwitch()
  // (since the label offsets are relative to the referring
  //  instruction, not the switch data)
  SLICER_CHECK_EQ(offset % 2, 0);
  auto& instr = packed_switches_[offset].instr;
  SLICER_CHECK_EQ(instr, nullptr);
  instr = Alloc<PackedSwitchPayload>();
  return instr;
}

void CodeIr::FixupPackedSwitch(PackedSwitchPayload* instr, dex::u4 base_offset,
                               const dex::u2* ptr) {
  SLICER_CHECK(instr->targets.empty());

  auto dex_packed_switch = reinterpret_cast<const dex::PackedSwitchPayload*>(ptr);
  SLICER_CHECK_EQ(dex_packed_switch->ident, dex::kPackedSwitchSignature);

  instr->first_key = dex_packed_switch->first_key;
  for (dex::u2 i = 0; i < dex_packed_switch->size; ++i) {
    instr->targets.push_back(
        GetLabel(base_offset + dex_packed_switch->targets[i]));
  }
}

SparseSwitchPayload* CodeIr::DecodeSparseSwitch(const dex::u2* /*ptr*/,
                                         dex::u4 offset) {
  // actual decoding is delayed to FixupSparseSwitch()
  // (since the label offsets are relative to the referring
  //  instruction, not the switch data)
  SLICER_CHECK_EQ(offset % 2, 0);
  auto& instr = sparse_switches_[offset].instr;
  SLICER_CHECK_EQ(instr, nullptr);
  instr = Alloc<SparseSwitchPayload>();
  return instr;
}

void CodeIr::FixupSparseSwitch(SparseSwitchPayload* instr, dex::u4 base_offset,
                               const dex::u2* ptr) {
  SLICER_CHECK(instr->switch_cases.empty());

  auto dex_sparse_switch = reinterpret_cast<const dex::SparseSwitchPayload*>(ptr);
  SLICER_CHECK_EQ(dex_sparse_switch->ident, dex::kSparseSwitchSignature);

  auto& data = dex_sparse_switch->data;
  auto& size = dex_sparse_switch->size;

  for (dex::u2 i = 0; i < size; ++i) {
    SparseSwitchPayload::SwitchCase switch_case = {};
    switch_case.key = data[i];
    switch_case.target = GetLabel(base_offset + data[i + size]);
    instr->switch_cases.push_back(switch_case);
  }
}

ArrayData* CodeIr::DecodeArrayData(const dex::u2* ptr, dex::u4 offset) {
  auto dex_array_data = reinterpret_cast<const dex::ArrayData*>(ptr);
  SLICER_CHECK_EQ(dex_array_data->ident, dex::kArrayDataSignature);
  SLICER_CHECK_EQ(offset % 2, 0);

  auto instr = Alloc<ArrayData>();
  instr->data = slicer::MemView(ptr, dex::GetWidthFromBytecode(ptr) * 2);
  return instr;
}

Operand* CodeIr::GetRegA(const dex::Instruction& dex_instr) {
  auto verify_flags = dex::GetVerifyFlagsFromOpcode(dex_instr.opcode);
  if ((verify_flags & dex::kVerifyRegAWide) != 0) {
    return Alloc<VRegPair>(dex_instr.vA);
  } else {
    return Alloc<VReg>(dex_instr.vA);
  }
}

Operand* CodeIr::GetRegB(const dex::Instruction& dex_instr) {
  auto verify_flags = dex::GetVerifyFlagsFromOpcode(dex_instr.opcode);
  if ((verify_flags & dex::kVerifyRegBWide) != 0) {
    return Alloc<VRegPair>(dex_instr.vB);
  } else {
    return Alloc<VReg>(dex_instr.vB);
  }
}

Operand* CodeIr::GetRegC(const dex::Instruction& dex_instr) {
  auto verify_flags = dex::GetVerifyFlagsFromOpcode(dex_instr.opcode);
  if ((verify_flags & dex::kVerifyRegCWide) != 0) {
    return Alloc<VRegPair>(dex_instr.vC);
  } else {
    return Alloc<VReg>(dex_instr.vC);
  }
}

Bytecode* CodeIr::DecodeBytecode(const dex::u2* ptr, dex::u4 offset) {
  auto dex_instr = dex::DecodeInstruction(ptr);

  auto instr = Alloc<Bytecode>();
  instr->opcode = dex_instr.opcode;

  auto index_type = dex::GetIndexTypeFromOpcode(dex_instr.opcode);
  auto format = dex::GetFormatFromOpcode(dex_instr.opcode);
  switch (format) {
    case dex::k10x:  // op
      break;

    case dex::k12x:  // op vA, vB
    case dex::k22x:  // op vAA, vBBBB
    case dex::k32x:  // op vAAAA, vBBBB
      instr->operands.push_back(GetRegA(dex_instr));
      instr->operands.push_back(GetRegB(dex_instr));
      break;

    case dex::k11n:  // op vA, #+B
    case dex::k21s:  // op vAA, #+BBBB
    case dex::k31i:  // op vAA, #+BBBBBBBB
      instr->operands.push_back(GetRegA(dex_instr));
      instr->operands.push_back(Alloc<Const32>(dex_instr.vB));
      break;

    case dex::k11x:  // op vAA
      instr->operands.push_back(GetRegA(dex_instr));
      break;

    case dex::k10t:  // op +AA
    case dex::k20t:  // op +AAAA
    case dex::k30t:  // op +AAAAAAAA
    {
      auto label = GetLabel(offset + dex::s4(dex_instr.vA));
      instr->operands.push_back(Alloc<CodeLocation>(label));
    } break;

    case dex::k21t:  // op vAA, +BBBB
    case dex::k31t:  // op vAA, +BBBBBBBB
    {
      dex::u4 targetOffset = offset + dex::s4(dex_instr.vB);
      instr->operands.push_back(GetRegA(dex_instr));
      auto label = GetLabel(targetOffset);
      instr->operands.push_back(Alloc<CodeLocation>(label));

      if (dex_instr.opcode == dex::OP_PACKED_SWITCH) {
        label->aligned = true;
        dex::u4& base_offset = packed_switches_[targetOffset].base_offset;
        SLICER_CHECK_EQ(base_offset, kInvalidOffset);
        base_offset = offset;
      } else if (dex_instr.opcode == dex::OP_SPARSE_SWITCH) {
        label->aligned = true;
        dex::u4& base_offset = sparse_switches_[targetOffset].base_offset;
        SLICER_CHECK_EQ(base_offset, kInvalidOffset);
        base_offset = offset;
      } else if (dex_instr.opcode == dex::OP_FILL_ARRAY_DATA) {
        label->aligned = true;
      }
    } break;

    case dex::k23x:  // op vAA, vBB, vCC
      instr->operands.push_back(GetRegA(dex_instr));
      instr->operands.push_back(GetRegB(dex_instr));
      instr->operands.push_back(GetRegC(dex_instr));
      break;

    case dex::k22t:  // op vA, vB, +CCCC
    {
      instr->operands.push_back(GetRegA(dex_instr));
      instr->operands.push_back(GetRegB(dex_instr));
      auto label = GetLabel(offset + dex::s4(dex_instr.vC));
      instr->operands.push_back(Alloc<CodeLocation>(label));
    } break;

    case dex::k22b:  // op vAA, vBB, #+CC
    case dex::k22s:  // op vA, vB, #+CCCC
      instr->operands.push_back(GetRegA(dex_instr));
      instr->operands.push_back(GetRegB(dex_instr));
      instr->operands.push_back(Alloc<Const32>(dex_instr.vC));
      break;

    case dex::k22c:  // op vA, vB, thing@CCCC
      instr->operands.push_back(GetRegA(dex_instr));
      instr->operands.push_back(GetRegB(dex_instr));
      instr->operands.push_back(GetIndexedOperand(index_type, dex_instr.vC));
      break;

    case dex::k21c:  // op vAA, thing@BBBB
    case dex::k31c:  // op vAA, string@BBBBBBBB
      instr->operands.push_back(GetRegA(dex_instr));
      instr->operands.push_back(GetIndexedOperand(index_type, dex_instr.vB));
      break;

    case dex::k35c:  // op {vC,vD,vE,vF,vG}, thing@BBBB
    {
      SLICER_CHECK_LE(dex_instr.vA, 5);
      auto vreg_list = Alloc<VRegList>();
      for (dex::u4 i = 0; i < dex_instr.vA; ++i) {
        vreg_list->registers.push_back(dex_instr.arg[i]);
      }
      instr->operands.push_back(vreg_list);
      instr->operands.push_back(GetIndexedOperand(index_type, dex_instr.vB));
    } break;

    case dex::k3rc:  // op {vCCCC .. v(CCCC+AA-1)}, thing@BBBB
    {
      auto vreg_range = Alloc<VRegRange>(dex_instr.vC, dex_instr.vA);
      instr->operands.push_back(vreg_range);
      instr->operands.push_back(GetIndexedOperand(index_type, dex_instr.vB));
    } break;

    case dex::k45cc: // op {vC, vD, vE, vF, vG}, thing@BBBB, other@HHHH
    {
      auto vreg_list = Alloc<VRegList>();
      SLICER_CHECK_LE(dex_instr.vA, 5);
      // vC if necessary.
      if (dex_instr.vA > 1) {
        vreg_list->registers.push_back(dex_instr.vC);
      }
      // Add vD,vE,vF,vG as necessary.
      for (dex::u4 i = 1; i < dex_instr.vA; ++i) {
        vreg_list->registers.push_back(dex_instr.arg[i - 1]);
      }
      instr->operands.push_back(vreg_list);
      instr->operands.push_back(GetIndexedOperand(index_type, dex_instr.vB));
      dex::u4 vH = dex_instr.arg[4];
      auto proto_operand = GetSecondIndexedOperand(index_type, vH);
      instr->operands.push_back(proto_operand);
    } break;

    case dex::k4rcc:  // op {vCCCC .. v(CCCC+AA-1)}, thing@BBBB, other@HHHH
    {
      auto vreg_range = Alloc<VRegRange>(dex_instr.vC, dex_instr.vA);
      instr->operands.push_back(vreg_range);
      instr->operands.push_back(GetIndexedOperand(index_type, dex_instr.vB));
      dex::u4 vH = dex_instr.arg[4];
      auto proto_operand = GetSecondIndexedOperand(index_type, vH);
      instr->operands.push_back(proto_operand);
    } break;

    case dex::k21h:  // op vAA, #+BBBB0000[00000000]
      switch (dex_instr.opcode) {
        case dex::OP_CONST_HIGH16:
          instr->operands.push_back(GetRegA(dex_instr));
          instr->operands.push_back(Alloc<Const32>(dex_instr.vB << 16));
          break;

        case dex::OP_CONST_WIDE_HIGH16:
          instr->operands.push_back(GetRegA(dex_instr));
          instr->operands.push_back(Alloc<Const64>(dex::u8(dex_instr.vB) << 48));
          break;

        default: {
          std::stringstream ss;
          ss << "Unexpected opcode: " << dex_instr.opcode;
          SLICER_FATAL(ss.str());
        }
      }
      break;

    case dex::k51l:  // op vAA, #+BBBBBBBBBBBBBBBB
      instr->operands.push_back(GetRegA(dex_instr));
      instr->operands.push_back(Alloc<Const64>(dex_instr.vB_wide));
      break;

    default: {
      std::stringstream ss;
      ss << "Unexpected bytecode format " << format << " for opcode " << dex_instr.opcode;
      SLICER_FATAL(ss.str());
    }
  }

  return instr;
}

// Get a indexed object (string, field, ...)
// (index must be valid != kNoIndex)
IndexedOperand* CodeIr::GetIndexedOperand(dex::InstructionIndexType index_type,
                                          dex::u4 index) {
  SLICER_CHECK_NE(index, dex::kNoIndex);
  switch (index_type) {
    case dex::kIndexStringRef:
      return Alloc<String>(dex_ir->strings_map[index], index);

    case dex::kIndexTypeRef:
      return Alloc<Type>(dex_ir->types_map[index], index);

    case dex::kIndexFieldRef:
      return Alloc<Field>(dex_ir->fields_map[index], index);

    case dex::kIndexMethodRef:
    case dex::kIndexMethodAndProtoRef:
      return Alloc<Method>(dex_ir->methods_map[index], index);

    case dex::kIndexMethodHandleRef:
      return Alloc<MethodHandle>(dex_ir->method_handles_map[index], index);

    default:
      std::stringstream ss;
      ss << "Unexpected index type 0x";
      ss << std::hex << std::setfill('0') << std::setw(2) << index_type;
      SLICER_FATAL(ss.str());
  }
}

// Get the second indexed object (if any).
IndexedOperand* CodeIr::GetSecondIndexedOperand(dex::InstructionIndexType index_type,
                                                dex::u4 index) {
  SLICER_CHECK_NE(index, dex::kNoIndex);
  SLICER_CHECK_EQ(index_type, dex::kIndexMethodAndProtoRef);
  return Alloc<Proto>(dex_ir->protos_map[index], index);
}

// Get a type based on its index (potentially kNoIndex)
Type* CodeIr::GetType(dex::u4 index) {
  auto ir_type = (index == dex::kNoIndex) ? nullptr : dex_ir->types_map[index];
  return Alloc<Type>(ir_type, index);
}

// Get a string based on its index (potentially kNoIndex)
String* CodeIr::GetString(dex::u4 index) {
  auto ir_string = (index == dex::kNoIndex) ? nullptr : dex_ir->strings_map[index];
  return Alloc<String>(ir_string, index);
}

// Get en existing, or new label for a particular offset
Label* CodeIr::GetLabel(dex::u4 offset) {
  auto& p = labels_[offset];
  if (p == nullptr) {
    p = Alloc<Label>(offset);
  }
  ++p->refCount;
  return p;
}

}  // namespace lir

```

`paccer/jni/slicer/common.cc`:

```cc
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include "slicer/common.h"

#include <stdio.h>
#include <stdlib.h>

#include <iostream>
#include <sstream>
#include <set>
#include <utility>

namespace slicer {

static void log_(const std::string& msg) {
  printf("%s", msg.c_str());
  fflush(stdout);
}

static logger_type log = log_;

void set_logger(logger_type new_logger) {
  log = new_logger;
}

// Helper for the default SLICER_CHECK() policy
void _checkFailed(const char* expr, int line, const char* file) {
  std::stringstream ss;
  ss << std::endl << "SLICER_CHECK failed [";
  ss << expr << "] at " << file << ":" << line;
  ss << std::endl << std::endl;
  log(ss.str());
  abort();
}

void _checkFailedOp(const void* lhs, const void* rhs, const char* op, const char* suffix, int line,
                    const char* file) {
  std::stringstream ss;
  ss << std::endl << "SLICER_CHECK_" << suffix << " failed [";
  ss << lhs << " " << op << " " << rhs;
  ss << "] at " << file << ":" << line;
  log(ss.str());
  abort();
}

void _checkFailedOp(uint32_t lhs, uint32_t rhs, const char* op, const char* suffix, int line,
                    const char* file) {
  std::stringstream ss;
  ss << std::endl << "SLICER_CHECK_" << suffix << " failed [";
  ss << lhs << " " << op << " " << rhs;
  ss << "] at " << file << ":" << line;
  log(ss.str());
  abort();
}

// keep track of the failures we already saw to avoid spamming with duplicates
thread_local std::set<std::pair<int, const char*>> weak_failures;

// Helper for the default SLICER_WEAK_CHECK() policy
//
// TODO: implement a modal switch (abort/continue)
//
void _weakCheckFailed(const char* expr, int line, const char* file) {
  auto failure_id = std::make_pair(line, file);
  if (weak_failures.find(failure_id) == weak_failures.end()) {
    std::stringstream ss;
    ss << std::endl << "SLICER_WEAK_CHECK failed [";
    ss << expr << "] at " << file << ":";
    ss << line << std::endl << std::endl;
    log(ss.str());
    weak_failures.insert(failure_id);
  }
}

// Prints a formatted message and aborts
void _fatal(const std::string& msg) {
  log("SLICER_FATAL: " + msg);
  abort();
}

} // namespace slicer


```

`paccer/jni/slicer/control_flow_graph.cc`:

```cc
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include "slicer/control_flow_graph.h"

namespace lir {

std::vector<BasicBlock> BasicBlocksVisitor::Finish() {
  // the .dex format specification has the following constraint:
  //
  //  B17	The last reachable instruction of a method must either be a
  //  backwards goto or branch, a return, or a throw instruction. It must not
  //  be possible to leave the insns array at the bottom.	4.8.2.20
  //
  // NOTE: this is a very aggressive check though since in the LIR we also
  //  have labels, annotations, directives, etc. For example it's possible to have
  //  debug annotations (.line, .endlocal, ...) after the last bytecode.
  //
  SLICER_WEAK_CHECK(state_ == State::Outside);
  SLICER_CHECK(state_ != State::BlockBody);
  current_block_.region = {};
  state_ = State::Outside;
  return std::move(basic_blocks_);
}

bool BasicBlocksVisitor::Visit(Bytecode* bytecode) {
  switch (state_) {
    case State::Outside:
      StartBlock(bytecode);
      state_ = State::BlockBody;
      break;
    case State::BlockHeader:
      state_ = State::BlockBody;
      break;
    case State::BlockBody:
      // inside basic block body, nothing to do.
      break;
  }

  // terminate the current block?
  bool terminate_block = false;
  const auto flags = dex::GetFlagsFromOpcode(bytecode->opcode);
  if (model_exceptions_) {
    constexpr auto exit_instr_flags =
        dex::kBranch |
        dex::kSwitch |
        dex::kThrow |
        dex::kReturn;
    terminate_block = (flags & exit_instr_flags) != 0;
  } else {
    constexpr auto exit_instr_flags =
        dex::kBranch |
        dex::kSwitch |
        dex::kReturn;
    terminate_block = bytecode->opcode == dex::OP_THROW || (flags & exit_instr_flags) != 0;
  }
  if (terminate_block) {
      EndBlock(bytecode);
  }

  return true;
}

bool BasicBlocksVisitor::Visit(Label* label) {
  switch (state_) {
    case State::Outside:
      StartBlock(label);
      break;
    case State::BlockBody:
      EndBlock(label->prev);
      StartBlock(label);
      break;
    case State::BlockHeader:
      break;
  }
  return true;
}

bool BasicBlocksVisitor::HandleAnnotation(Instruction* instr) {
  if (state_ == State::Outside) {
    StartBlock(instr);
  }
  return true;
}

bool BasicBlocksVisitor::SkipInstruction(Instruction* instr) {
  if (state_ != State::Outside) {
    EndBlock(instr->prev);
  }
  return true;
}

void BasicBlocksVisitor::StartBlock(Instruction* instr) {
  assert(instr != nullptr);
  assert(state_ == State::Outside);
  // mark the location of the "first" instruction,
  // "last" will be set when we end the basic block.
  current_block_.region.first = instr;
  current_block_.region.last = nullptr;
  state_ = State::BlockHeader;
}

void BasicBlocksVisitor::EndBlock(Instruction* instr) {
  assert(instr != nullptr);
  if (state_ == State::BlockBody) {
    ++current_block_.id;
    assert(current_block_.region.first != nullptr);
    current_block_.region.last = instr;
    basic_blocks_.push_back(current_block_);
  } else {
    assert(state_ == State::BlockHeader);
  }
  current_block_.region = {};
  state_ = State::Outside;
}

void ControlFlowGraph::CreateBasicBlocks(bool model_exceptions) {
  BasicBlocksVisitor visitor(model_exceptions);
  for (auto instr : code_ir->instructions) {
    instr->Accept(&visitor);
  }
  basic_blocks = visitor.Finish();
}

}  // namespace lir

```

`paccer/jni/slicer/debuginfo_encoder.cc`:

```cc
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include "slicer/debuginfo_encoder.h"

#include "slicer/common.h"

#include <assert.h>
#include <sstream>
#include <iomanip>


namespace lir {

bool DebugInfoEncoder::Visit(DbgInfoHeader* dbg_header) {
  assert(param_names_ == nullptr);
  param_names_ = &dbg_header->param_names;
  return true;
}

bool DebugInfoEncoder::Visit(DbgInfoAnnotation* dbg_annotation) {
  // keep the address in sync
  if (last_address_ != dbg_annotation->offset) {
    SLICER_CHECK_GT(dbg_annotation->offset, last_address_);
    dbginfo_.Push<dex::u1>(dex::DBG_ADVANCE_PC);
    dbginfo_.PushULeb128(dbg_annotation->offset - last_address_);
    last_address_ = dbg_annotation->offset;
  }

  // encode the annotation itself
  switch (dbg_annotation->dbg_opcode) {
    case dex::DBG_ADVANCE_LINE: {
      // DBG_ANDVANCE_LINE is used a bit differently in the code IR
      // vs the .dex image: the code IR uses it exclusively for source
      // location (the .line directive) while .dex format uses it to
      // advance the "line" register without emitting a "position entry"
      int line = dbg_annotation->CastOperand<LineNumber>(0)->line;
      if (line_start_ == 0) {
        // it's not perfectly clear from the .dex specification
        // if initial line == 0 is valid, but a number of existing
        // .dex files do this so we have to support it
        SLICER_CHECK_GE(line, 0);
        line_start_ = line;
      } else {
        SLICER_WEAK_CHECK(line >= 0);
        int delta = line - last_line_;
        int adj_opcode = delta - dex::DBG_LINE_BASE;
        // out of range for special opcode?
        if (adj_opcode < 0 || adj_opcode >= dex::DBG_LINE_RANGE) {
          dbginfo_.Push<dex::u1>(dex::DBG_ADVANCE_LINE);
          dbginfo_.PushSLeb128(delta);
          adj_opcode = -dex::DBG_LINE_BASE;
        }
        assert(adj_opcode >= 0 && dex::DBG_FIRST_SPECIAL + adj_opcode < 256);
        dex::u1 special_opcode = dex::DBG_FIRST_SPECIAL + adj_opcode;
        dbginfo_.Push<dex::u1>(special_opcode);
      }
      last_line_ = line;
    } break;

    case dex::DBG_START_LOCAL: {
      auto reg = dbg_annotation->CastOperand<VReg>(0)->reg;
      auto name_index = dbg_annotation->CastOperand<String>(1)->index;
      auto type_index = dbg_annotation->CastOperand<Type>(2)->index;
      dbginfo_.Push<dex::u1>(dex::DBG_START_LOCAL);
      dbginfo_.PushULeb128(reg);
      dbginfo_.PushULeb128(name_index + 1);
      dbginfo_.PushULeb128(type_index + 1);
    } break;

    case dex::DBG_START_LOCAL_EXTENDED: {
      auto reg = dbg_annotation->CastOperand<VReg>(0)->reg;
      auto name_index = dbg_annotation->CastOperand<String>(1)->index;
      auto type_index = dbg_annotation->CastOperand<Type>(2)->index;
      auto sig_index = dbg_annotation->CastOperand<String>(3)->index;
      dbginfo_.Push<dex::u1>(dex::DBG_START_LOCAL_EXTENDED);
      dbginfo_.PushULeb128(reg);
      dbginfo_.PushULeb128(name_index + 1);
      dbginfo_.PushULeb128(type_index + 1);
      dbginfo_.PushULeb128(sig_index + 1);
    } break;

    case dex::DBG_END_LOCAL:
    case dex::DBG_RESTART_LOCAL: {
      auto reg = dbg_annotation->CastOperand<VReg>(0)->reg;
      dbginfo_.Push<dex::u1>(dbg_annotation->dbg_opcode);
      dbginfo_.PushULeb128(reg);
    } break;

    case dex::DBG_SET_PROLOGUE_END:
    case dex::DBG_SET_EPILOGUE_BEGIN:
      dbginfo_.Push<dex::u1>(dbg_annotation->dbg_opcode);
      break;

    case dex::DBG_SET_FILE: {
      auto file_name = dbg_annotation->CastOperand<String>(0);
      if (file_name->ir_string != source_file_) {
        source_file_ = file_name->ir_string;
        dbginfo_.Push<dex::u1>(dex::DBG_SET_FILE);
        dbginfo_.PushULeb128(file_name->index + 1);
      }
    } break;

    default: {
      std::stringstream ss;
      ss << "Unexpected debug info opcode: " << dbg_annotation->dbg_opcode;
      SLICER_FATAL(ss.str());
    }
  }

  return true;
}

void DebugInfoEncoder::Encode(ir::EncodedMethod* ir_method, std::shared_ptr<ir::DexFile> dex_ir) {
  auto ir_debug_info = ir_method->code->debug_info;

  SLICER_CHECK(dbginfo_.empty());
  SLICER_CHECK_EQ(param_names_, nullptr);
  SLICER_CHECK_EQ(line_start_, 0);
  SLICER_CHECK_EQ(last_line_, 0);
  SLICER_CHECK_EQ(last_address_, 0);
  SLICER_CHECK_EQ(source_file_, nullptr);

  // generate new debug info
  source_file_ = ir_method->decl->parent->class_def->source_file;
  for (auto instr : instructions_) {
    instr->Accept(this);
  }
  dbginfo_.Push<dex::u1>(dex::DBG_END_SEQUENCE);
  dbginfo_.Seal(1);

  SLICER_CHECK(!dbginfo_.empty());

  // update ir::DebugInfo
  ir_debug_info->line_start = line_start_;
  ir_debug_info->data = slicer::MemView(dbginfo_.data(), dbginfo_.size());

  if (param_names_ != nullptr) {
    ir_debug_info->param_names = *param_names_;
  } else {
    ir_debug_info->param_names = {};
  }

  // attach the debug info buffer to the dex IR
  dex_ir->AttachBuffer(std::move(dbginfo_));
}

}  // namespace lir

```

`paccer/jni/slicer/dex_bytecode.cc`:

```cc
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include "slicer/dex_bytecode.h"

#include "slicer/common.h"

#include <array>
#include <iomanip>
#include <sstream>

namespace dex {

Opcode OpcodeFromBytecode(u2 bytecode) {
  Opcode opcode = Opcode(bytecode & 0xff);
  return opcode;
}

// Table that maps each opcode to the index type implied by that opcode
static constexpr std::array<InstructionDescriptor, kNumPackedOpcodes>
    gInstructionDescriptors = {{
#define INSTRUCTION_DESCR(o, c, p, format, index, flags, e, vflags) \
  {                                                                 \
      vflags,                                                       \
      format,                                                       \
      index,                                                        \
      flags,                                                        \
  },
#include "export/slicer/dex_instruction_list.h"
        DEX_INSTRUCTION_LIST(INSTRUCTION_DESCR)
#undef DEX_INSTRUCTION_LIST
#undef INSTRUCTION_DESCR
    }};

InstructionIndexType GetIndexTypeFromOpcode(Opcode opcode) {
  return gInstructionDescriptors[opcode].index_type;
}

InstructionFormat GetFormatFromOpcode(Opcode opcode) {
  return gInstructionDescriptors[opcode].format;
}

OpcodeFlags GetFlagsFromOpcode(Opcode opcode) {
  return gInstructionDescriptors[opcode].flags;
}

VerifyFlags GetVerifyFlagsFromOpcode(Opcode opcode) {
  return gInstructionDescriptors[opcode].verify_flags;
}

size_t GetWidthFromFormat(InstructionFormat format) {
  switch (format) {
    case k10x:
    case k12x:
    case k11n:
    case k11x:
    case k10t:
      return 1;
    case k20t:
    case k20bc:
    case k21c:
    case k22x:
    case k21s:
    case k21t:
    case k21h:
    case k23x:
    case k22b:
    case k22s:
    case k22t:
    case k22c:
    case k22cs:
      return 2;
    case k30t:
    case k31t:
    case k31c:
    case k32x:
    case k31i:
    case k35c:
    case k35ms:
    case k35mi:
    case k3rc:
    case k3rms:
    case k3rmi:
      return 3;
    case k45cc:
    case k4rcc:
      return 4;
    case k51l:
      return 5;
  }
}

size_t GetWidthFromBytecode(const u2* bytecode) {
  size_t width = 0;
  if (*bytecode == kPackedSwitchSignature) {
    width = 4 + bytecode[1] * 2;
  } else if (*bytecode == kSparseSwitchSignature) {
    width = 2 + bytecode[1] * 4;
  } else if (*bytecode == kArrayDataSignature) {
    u2 elemWidth = bytecode[1];
    u4 len = bytecode[2] | (((u4)bytecode[3]) << 16);
    // The plus 1 is to round up for odd size and width.
    width = 4 + (elemWidth * len + 1) / 2;
  } else {
    width = GetWidthFromFormat(
        GetFormatFromOpcode(OpcodeFromBytecode(bytecode[0])));
  }
  return width;
}

// Dalvik opcode names.
static constexpr std::array<const char*, kNumPackedOpcodes> gOpcodeNames = {
#define INSTRUCTION_NAME(o, c, pname, f, i, a, e, v) pname,
#include "export/slicer/dex_instruction_list.h"
    DEX_INSTRUCTION_LIST(INSTRUCTION_NAME)
#undef DEX_INSTRUCTION_LIST
#undef INSTRUCTION_NAME
};

const char* GetOpcodeName(Opcode opcode) { return gOpcodeNames[opcode]; }

// Helpers for DecodeInstruction()
static u4 InstA(u2 inst) { return (inst >> 8) & 0x0f; }
static u4 InstB(u2 inst) { return inst >> 12; }
static u4 InstAA(u2 inst) { return inst >> 8; }

// Helper for DecodeInstruction()
static u4 FetchU4(const u2* ptr) { return ptr[0] | (u4(ptr[1]) << 16); }

// Helper for DecodeInstruction()
static u8 FetchU8(const u2* ptr) {
  return FetchU4(ptr) | (u8(FetchU4(ptr + 2)) << 32);
}

// Decode a Dalvik bytecode and extract the individual fields
Instruction DecodeInstruction(const u2* bytecode) {
  u2 inst = bytecode[0];
  Opcode opcode = OpcodeFromBytecode(inst);
  InstructionFormat format = GetFormatFromOpcode(opcode);

  Instruction dec = {};
  dec.opcode = opcode;

  switch (format) {
    case k10x:  // op
      return dec;
    case k12x:  // op vA, vB
      dec.vA = InstA(inst);
      dec.vB = InstB(inst);
      return dec;
    case k11n:  // op vA, #+B
      dec.vA = InstA(inst);
      dec.vB = s4(InstB(inst) << 28) >> 28;  // sign extend 4-bit value
      return dec;
    case k11x:  // op vAA
      dec.vA = InstAA(inst);
      return dec;
    case k10t:                    // op +AA
      dec.vA = s1(InstAA(inst));  // sign-extend 8-bit value
      return dec;
    case k20t:                   // op +AAAA
      dec.vA = s2(bytecode[1]);  // sign-extend 16-bit value
      return dec;
    case k20bc:  // [opt] op AA, thing@BBBB
    case k21c:   // op vAA, thing@BBBB
    case k22x:   // op vAA, vBBBB
      dec.vA = InstAA(inst);
      dec.vB = bytecode[1];
      return dec;
    case k21s:  // op vAA, #+BBBB
    case k21t:  // op vAA, +BBBB
      dec.vA = InstAA(inst);
      dec.vB = s2(bytecode[1]);  // sign-extend 16-bit value
      return dec;
    case k21h:  // op vAA, #+BBBB0000[00000000]
      dec.vA = InstAA(inst);
      // The value should be treated as right-zero-extended, but we don't
      // actually do that here. Among other things, we don't know if it's
      // the top bits of a 32- or 64-bit value.
      dec.vB = bytecode[1];
      return dec;
    case k23x:  // op vAA, vBB, vCC
      dec.vA = InstAA(inst);
      dec.vB = bytecode[1] & 0xff;
      dec.vC = bytecode[1] >> 8;
      return dec;
    case k22b:  // op vAA, vBB, #+CC
      dec.vA = InstAA(inst);
      dec.vB = bytecode[1] & 0xff;
      dec.vC = s1(bytecode[1] >> 8);  // sign-extend 8-bit value
      return dec;
    case k22s:  // op vA, vB, #+CCCC
    case k22t:  // op vA, vB, +CCCC
      dec.vA = InstA(inst);
      dec.vB = InstB(inst);
      dec.vC = s2(bytecode[1]);  // sign-extend 16-bit value
      return dec;
    case k22c:   // op vA, vB, thing@CCCC
    case k22cs:  // [opt] op vA, vB, field offset CCCC
      dec.vA = InstA(inst);
      dec.vB = InstB(inst);
      dec.vC = bytecode[1];
      return dec;
    case k30t:  // op +AAAAAAAA
      dec.vA = FetchU4(bytecode + 1);
      return dec;
    case k31t:  // op vAA, +BBBBBBBB
    case k31c:  // op vAA, string@BBBBBBBB
      dec.vA = InstAA(inst);
      dec.vB = FetchU4(bytecode + 1);
      return dec;
    case k32x:  // op vAAAA, vBBBB
      dec.vA = bytecode[1];
      dec.vB = bytecode[2];
      return dec;
    case k31i:  // op vAA, #+BBBBBBBB
      dec.vA = InstAA(inst);
      dec.vB = FetchU4(bytecode + 1);
      return dec;
    case k35c:               // op {vC, vD, vE, vF, vG}, thing@BBBB
    case k35ms:              // [opt] invoke-virtual+super
    case k35mi: {            // [opt] inline invoke
      dec.vA = InstB(inst);  // This is labeled A in the spec.
      dec.vB = bytecode[1];

      u2 regList = bytecode[2];

      // Copy the argument registers into the arg[] array, and
      // also copy the first argument (if any) into vC. (The
      // Instruction structure doesn't have separate
      // fields for {vD, vE, vF, vG}, so there's no need to make
      // copies of those.) Note that cases 5..2 fall through.
      switch (dec.vA) {
        case 5:
          // A fifth arg is verboten for inline invokes
          SLICER_CHECK_NE(format, k35mi);

          // Per note at the top of this format decoder, the
          // fifth argument comes from the A field in the
          // instruction, but it's labeled G in the spec.
          dec.arg[4] = InstA(inst);
          FALLTHROUGH_INTENDED;
        case 4:
          dec.arg[3] = (regList >> 12) & 0x0f;
          FALLTHROUGH_INTENDED;
        case 3:
          dec.arg[2] = (regList >> 8) & 0x0f;
          FALLTHROUGH_INTENDED;
        case 2:
          dec.arg[1] = (regList >> 4) & 0x0f;
          FALLTHROUGH_INTENDED;
        case 1:
          dec.vC = dec.arg[0] = regList & 0x0f;
          FALLTHROUGH_INTENDED;
        case 0:
          // Valid, but no need to do anything
          return dec;
      }
    }
      SLICER_CHECK(!"Invalid arg count in 35c/35ms/35mi");
    case k3rc:   // op {vCCCC .. v(CCCC+AA-1)}, meth@BBBB
    case k3rms:  // [opt] invoke-virtual+super/range
    case k3rmi:  // [opt] execute-inline/range
      dec.vA = InstAA(inst);
      dec.vB = bytecode[1];
      dec.vC = bytecode[2];
      return dec;
    case k45cc: {
      // AG op BBBB FEDC HHHH
      dec.vA = InstB(inst);  // This is labelled A in the spec.
      dec.vB = bytecode[1];  // vB meth@BBBB

      u2 regList = bytecode[2];
      dec.vC = regList & 0xf;
      dec.arg[0] = (regList >> 4) & 0xf;  // vD
      dec.arg[1] = (regList >> 8) & 0xf;  // vE
      dec.arg[2] = (regList >> 12);       // vF
      dec.arg[3] = InstA(inst);           // vG
      dec.arg[4] = bytecode[3];           // vH proto@HHHH
    }
      return dec;
    case k4rcc:
      // AA op BBBB CCCC HHHH
      dec.vA = InstAA(inst);
      dec.vB = bytecode[1];
      dec.vC = bytecode[2];
      dec.arg[4] = bytecode[3];  // vH proto@HHHH
      return dec;
    case k51l:  // op vAA, #+BBBBBBBBBBBBBBBB
      dec.vA = InstAA(inst);
      dec.vB_wide = FetchU8(bytecode + 1);
      return dec;
  }

  std::stringstream ss;
  ss << "Can't decode unexpected format " << format << " for " << opcode;
  SLICER_FATAL(ss.str());
}

static inline std::string HexByte(int value) {
  std::stringstream ss;
  ss << "0x" << std::setw(2) << std::setfill('0') << std::hex << value;
  return ss.str();
}

std::ostream& operator<<(std::ostream& os, Opcode opcode) {
  return os << "[" << HexByte(opcode) << "] " << gOpcodeNames[opcode];
}

std::ostream& operator<<(std::ostream& os, InstructionFormat format) {
  switch (format) {
  #define EMIT_INSTRUCTION_FORMAT_NAME(name) \
    case InstructionFormat::k##name: return os << #name;
  #include "export/slicer/dex_instruction_list.h"
  DEX_INSTRUCTION_FORMAT_LIST(EMIT_INSTRUCTION_FORMAT_NAME)
  #undef EMIT_INSTRUCTION_FORMAT_NAME
  #undef DEX_INSTRUCTION_FORMAT_LIST
  #undef DEX_INSTRUCTION_LIST
  }
  return os << "[" << HexByte(format) << "] " << "Unknown";
}

}  // namespace dex

```

`paccer/jni/slicer/dex_format.cc`:

```cc
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include "slicer/dex_format.h"

#include "slicer/common.h"

#include <sstream>
#include <cstdlib>
#include <zlib.h>

namespace dex {

// The expected format of the magic is dex\nXXX\0 where XXX are digits. We extract this value.
// Returns 0 if the version can not be parsed.
u4 Header::GetVersion(const void* magic) {
  const char* version = reinterpret_cast<const char*>(magic) + 4;
  return version[3] == '\0' ? strtol(version, nullptr, 10) : 0;
}

// Compute the DEX file checksum for a memory-mapped DEX file
u4 ComputeChecksum(const Header* header) {
  const u1* start = reinterpret_cast<const u1*>(header);

  uLong adler = adler32(0L, Z_NULL, 0);
  const int non_sum = sizeof(header->magic) + sizeof(header->checksum);

  return static_cast<u4>(
      adler32(adler, start + non_sum, header->file_size - non_sum));
}

// Returns the human-readable name for a primitive type
static const char* PrimitiveTypeName(char type_char) {
  switch (type_char) {
    case 'B': return "byte";
    case 'C': return "char";
    case 'D': return "double";
    case 'F': return "float";
    case 'I': return "int";
    case 'J': return "long";
    case 'S': return "short";
    case 'V': return "void";
    case 'Z': return "boolean";
  }
  SLICER_CHECK(!"unexpected type");
  return nullptr;
}

// Converts a type descriptor to human-readable "dotted" form.  For
// example, "Ljava/lang/String;" becomes "java.lang.String", and
// "[I" becomes "int[]".
std::string DescriptorToDecl(const char* descriptor) {
  std::stringstream ss;

  int array_dimensions = 0;
  while (*descriptor == '[') {
    ++array_dimensions;
    ++descriptor;
  }

  if (*descriptor == 'L') {
    for (++descriptor; *descriptor != ';'; ++descriptor) {
      SLICER_CHECK_NE(*descriptor, '\0');
      ss << (*descriptor == '/' ? '.' : *descriptor);
    }
  } else {
    ss << PrimitiveTypeName(*descriptor);
  }

  SLICER_CHECK_EQ(descriptor[1], '\0');

  // add the array brackets
  for (int i = 0; i < array_dimensions; ++i) {
    ss << "[]";
  }

  return ss.str();
}

// Converts a type descriptor to a single "shorty" char
// (ex. "LFoo;" and "[[I" become 'L', "I" stays 'I')
char DescriptorToShorty(const char* descriptor) {
  // skip array dimensions
  int array_dimensions = 0;
  while (*descriptor == '[') {
    ++array_dimensions;
    ++descriptor;
  }

  char short_descriptor = *descriptor;
  if (short_descriptor == 'L') {
    // skip the full class name
    for(; *descriptor && *descriptor != ';'; ++descriptor);
    SLICER_CHECK_EQ(*descriptor, ';');
  }

  SLICER_CHECK_EQ(descriptor[1], '\0');
  SLICER_CHECK(short_descriptor == 'L' || PrimitiveTypeName(short_descriptor) != nullptr);

  return array_dimensions > 0 ? 'L' : short_descriptor;
}

}  // namespace dex

```

`paccer/jni/slicer/dex_ir.cc`:

```cc
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include "slicer/dex_ir.h"

#include "slicer/chronometer.h"
#include "slicer/dex_utf8.h"
#include "slicer/dex_format.h"

#include <cstdint>
#include <algorithm>
#include <memory>
#include <sstream>
#include <vector>

namespace ir {

// DBJ2a string hash
static uint32_t HashString(const char* cstr) {
  uint32_t hash = 5381;  // DBJ2 magic prime value
  while (*cstr) {
    hash = ((hash << 5) + hash) ^ *cstr++;
  }
  return hash;
}

uint32_t StringsHasher::Hash(const char* string_key) const {
  return HashString(string_key);
}

bool StringsHasher::Compare(const char* string_key, const String* string) const {
  return dex::Utf8Cmp(string_key, string->c_str()) == 0;
}

uint32_t ProtosHasher::Hash(const std::string& proto_key) const {
  return HashString(proto_key.c_str());
}

bool ProtosHasher::Compare(const std::string& proto_key, const Proto* proto) const {
  return proto_key == proto->Signature();
}

MethodKey MethodsHasher::GetKey(const EncodedMethod* method) const {
  MethodKey method_key;
  method_key.class_descriptor = method->decl->parent->descriptor;
  method_key.method_name = method->decl->name;
  method_key.prototype = method->decl->prototype;
  return method_key;
}

uint32_t MethodsHasher::Hash(const MethodKey& method_key) const {
  return static_cast<uint32_t>(std::hash<void*>{}(method_key.class_descriptor) ^
                               std::hash<void*>{}(method_key.method_name) ^
                               std::hash<void*>{}(method_key.prototype));
}

bool MethodsHasher::Compare(const MethodKey& method_key, const EncodedMethod* method) const {
  return method_key.class_descriptor == method->decl->parent->descriptor &&
         method_key.method_name == method->decl->name &&
         method_key.prototype == method->decl->prototype;
}

// Human-readable type declaration
std::string Type::Decl() const {
  return dex::DescriptorToDecl(descriptor->c_str());
}

Type::Category Type::GetCategory() const {
  switch (*descriptor->c_str()) {
    case 'L':
    case '[':
      return Category::Reference;
    case 'V':
      return Category::Void;
    case 'D':
    case 'J':
      return Category::WideScalar;
    default:
      return Category::Scalar;
  }
}

// Create the corresponding JNI signature:
//  https://docs.oracle.com/javase/8/docs/technotes/guides/jni/spec/types.html#type_signatures
std::string Proto::Signature() const {
  std::stringstream ss;
  ss << "(";
  if (param_types != nullptr) {
    for (const auto& type : param_types->types) {
      ss << type->descriptor->c_str();
    }
  }
  ss << ")";
  ss << return_type->descriptor->c_str();
  return ss.str();
}

bool MethodHandle::IsField(){
  return (
    method_handle_type == dex::METHOD_HANDLE_TYPE_STATIC_PUT ||
    method_handle_type == dex::METHOD_HANDLE_TYPE_STATIC_GET ||
    method_handle_type == dex::METHOD_HANDLE_TYPE_INSTANCE_PUT ||
    method_handle_type == dex::METHOD_HANDLE_TYPE_INSTANCE_GET
  );
}

// Helper for IR normalization
// (it sorts items and update the numeric idexes to match)
template <class T, class C>
static void IndexItems(std::vector<T>& items, C comp) {
  std::sort(items.begin(), items.end(), comp);
  for (size_t i = 0; i < items.size(); ++i) {
    items[i]->index = i;
  }
}

// Helper for IR normalization (DFS for topological sort)
//
// NOTE: this recursive version is clean and simple and we know
//  that the max depth is bounded (exactly 1 for JVMTI and a small
//  max for general case - the largest .dex file in AOSP has 5000 classes
//  total)
//
void DexFile::TopSortClassIndex(Class* irClass, dex::u4* nextIndex) {
  if (irClass->index == dex::u4(-1)) {
    if (irClass->super_class && irClass->super_class->class_def) {
      TopSortClassIndex(irClass->super_class->class_def, nextIndex);
    }

    if (irClass->interfaces) {
      for (Type* interfaceType : irClass->interfaces->types) {
        if (interfaceType->class_def) {
          TopSortClassIndex(interfaceType->class_def, nextIndex);
        }
      }
    }

    SLICER_CHECK_LT(*nextIndex, classes.size());
    irClass->index = (*nextIndex)++;
  }
}

// Helper for IR normalization
// (topological sort the classes)
void DexFile::SortClassIndexes() {
  for (auto& irClass : classes) {
    irClass->index = dex::u4(-1);
  }

  dex::u4 nextIndex = 0;
  for (auto& irClass : classes) {
    TopSortClassIndex(irClass.get(), &nextIndex);
  }
}

// Helper for NormalizeClass()
static void SortEncodedFields(std::vector<EncodedField*>* fields) {
  std::sort(fields->begin(), fields->end(),
            [](const EncodedField* a, const EncodedField* b) {
              SLICER_CHECK(a->decl->index != b->decl->index || a == b);
              return a->decl->index < b->decl->index;
            });
}

// Helper for NormalizeClass()
static void SortEncodedMethods(std::vector<EncodedMethod*>* methods) {
  std::sort(methods->begin(), methods->end(),
            [](const EncodedMethod* a, const EncodedMethod* b) {
              SLICER_CHECK(a->decl->index != b->decl->index || a == b);
              return a->decl->index < b->decl->index;
            });
}

// Helper for IR normalization
// (sort the field & method arrays)
static void NormalizeClass(Class* irClass) {
  SortEncodedFields(&irClass->static_fields);
  SortEncodedFields(&irClass->instance_fields);
  SortEncodedMethods(&irClass->direct_methods);
  SortEncodedMethods(&irClass->virtual_methods);
}

// Prepare the IR for generating a .dex image
// (the .dex format requires a specific sort order for some of the arrays, etc...)
//
// TODO: not a great solution - move this logic to the writer!
//
// TODO: the comparison predicate can be better expressed by using std::tie()
//  Ex. FieldDecl has a method comp() returning tie(parent->index, name->index, type->index)
//
void DexFile::Normalize() {
  // sort build the .dex indexes
  IndexItems(strings, [](const own<String>& a, const own<String>& b) {
    // this list must be sorted by std::string contents, using UTF-16 code point values
    // (not in a locale-sensitive manner)
    return dex::Utf8Cmp(a->c_str(), b->c_str()) < 0;
  });

  IndexItems(types, [](const own<Type>& a, const own<Type>& b) {
    // this list must be sorted by string_id index
    return a->descriptor->index < b->descriptor->index;
  });

  IndexItems(protos, [](const own<Proto>& a, const own<Proto>& b) {
    // this list must be sorted in return-type (by type_id index) major order,
    // and then by argument list (lexicographic ordering, individual arguments
    // ordered by type_id index)
    if (a->return_type->index != b->return_type->index) {
      return a->return_type->index < b->return_type->index;
    } else {
      std::vector<Type*> empty;
      const auto& aParamTypes = a->param_types ? a->param_types->types : empty;
      const auto& bParamTypes = b->param_types ? b->param_types->types : empty;
      return std::lexicographical_compare(
          aParamTypes.begin(), aParamTypes.end(), bParamTypes.begin(),
          bParamTypes.end(),
          [](const Type* t1, const Type* t2) { return t1->index < t2->index; });
    }
  });

  IndexItems(fields, [](const own<FieldDecl>& a, const own<FieldDecl>& b) {
    // this list must be sorted, where the defining type (by type_id index) is
    // the major order, field name (by string_id index) is the intermediate
    // order, and type (by type_id index) is the minor order
    return (a->parent->index != b->parent->index)
               ? a->parent->index < b->parent->index
               : (a->name->index != b->name->index)
                     ? a->name->index < b->name->index
                     : a->type->index < b->type->index;
  });

  IndexItems(methods, [](const own<MethodDecl>& a, const own<MethodDecl>& b) {
    // this list must be sorted, where the defining type (by type_id index) is
    // the major order, method name (by string_id index) is the intermediate
    // order, and method prototype (by proto_id index) is the minor order
    return (a->parent->index != b->parent->index)
               ? a->parent->index < b->parent->index
               : (a->name->index != b->name->index)
                     ? a->name->index < b->name->index
                     : a->prototype->index < b->prototype->index;
  });

  // reverse topological sort
  //
  // the classes must be ordered such that a given class's superclass and
  // implemented interfaces appear in the list earlier than the referring
  // class
  //
  // CONSIDER: for the BCI-only scenario we can avoid this
  //
  SortClassIndexes();

  IndexItems(classes, [&](const own<Class>& a, const own<Class>& b) {
    SLICER_CHECK_LT(a->index, classes.size());
    SLICER_CHECK_LT(b->index, classes.size());
    SLICER_CHECK(a->index != b->index || a == b);
    return a->index < b->index;
  });

  // normalize class data
  for (const auto& irClass : classes) {
    NormalizeClass(irClass.get());
  }

  // normalize annotations
  for (const auto& irAnnotation : annotations) {
    // elements must be sorted in increasing order by string_id index
    auto& elements = irAnnotation->elements;
    std::sort(elements.begin(), elements.end(),
              [](const AnnotationElement* a, const AnnotationElement* b) {
                return a->name->index < b->name->index;
              });
  }

  // normalize "annotation_set_item"
  for (const auto& irAnnotationSet : annotation_sets) {
    // The elements must be sorted in increasing order, by type_idx
    auto& annotations = irAnnotationSet->annotations;
    std::sort(annotations.begin(), annotations.end(),
              [](const Annotation* a, const Annotation* b) {
                return a->type->index < b->type->index;
              });
  }

  // normalize "annotations_directory_item"
  for (const auto& irAnnotationDirectory : annotations_directories) {
    // field_annotations: The elements of the list must be
    // sorted in increasing order, by field_idx
    auto& field_annotations = irAnnotationDirectory->field_annotations;
    std::sort(field_annotations.begin(), field_annotations.end(),
              [](const FieldAnnotation* a, const FieldAnnotation* b) {
                return a->field_decl->index < b->field_decl->index;
              });

    // method_annotations: The elements of the list must be
    // sorted in increasing order, by method_idx
    auto& method_annotations = irAnnotationDirectory->method_annotations;
    std::sort(method_annotations.begin(), method_annotations.end(),
              [](const MethodAnnotation* a, const MethodAnnotation* b) {
                return a->method_decl->index < b->method_decl->index;
              });

    // parameter_annotations: The elements of the list must be
    // sorted in increasing order, by method_idx
    auto& param_annotations = irAnnotationDirectory->param_annotations;
    std::sort(param_annotations.begin(), param_annotations.end(),
              [](const ParamAnnotation* a, const ParamAnnotation* b) {
                return a->method_decl->index < b->method_decl->index;
              });
  }
}

} // namespace ir


```

`paccer/jni/slicer/dex_ir_builder.cc`:

```cc
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include "slicer/dex_ir_builder.h"

#include <sstream>
#include <string.h>

namespace ir {

bool MethodId::Match(MethodDecl* method_decl) const {
  return ::strcmp(class_descriptor, method_decl->parent->descriptor->c_str()) == 0
    && ::strcmp(method_name, method_decl->name->c_str()) == 0
    && method_decl->prototype->Signature() == signature;
}

EncodedMethod* Builder::FindMethod(const MethodId& method_id) const {
  // first, lookup the strings
  auto ir_descriptor = FindAsciiString(method_id.class_descriptor);
  auto ir_method_name = FindAsciiString(method_id.method_name);
  if (ir_descriptor == nullptr || ir_method_name == nullptr) {
    return nullptr;
  }

  // look up the prototype
  auto ir_prototype = FindPrototype(method_id.signature);
  if (ir_prototype == nullptr) {
    return nullptr;
  }

  // look up the method itself
  ir::MethodKey method_key;
  method_key.class_descriptor = ir_descriptor;
  method_key.method_name = ir_method_name;
  method_key.prototype = ir_prototype;
  return dex_ir_->methods_lookup.Lookup(method_key);
}

Proto* Builder::FindPrototype(const char* signature) const {
  return dex_ir_->prototypes_lookup.Lookup(signature);
}

String* Builder::FindAsciiString(const char* cstr) const {
    return dex_ir_->strings_lookup.Lookup(cstr);
}

String* Builder::GetAsciiString(const char* cstr) {
  // look for the string first...
  auto ir_string = FindAsciiString(cstr);
  if(ir_string != nullptr) {
    return ir_string;
  }

  // create a new string data
  dex::u4 len = strlen(cstr);
  slicer::Buffer buff;
  buff.PushULeb128(len);
  buff.Push(cstr, len + 1);
  buff.Seal(1);

  // create the new .dex IR string node
  ir_string = dex_ir_->Alloc<String>();
  ir_string->data = slicer::MemView(buff.data(), buff.size());

  // update the index -> ir node map
  auto new_index = dex_ir_->strings_indexes.AllocateIndex();
  auto& ir_node = dex_ir_->strings_map[new_index];
  SLICER_CHECK_EQ(ir_node, nullptr);
  ir_node = ir_string;
  ir_string->orig_index = new_index;

  // attach the new string data to the .dex IR
  dex_ir_->AttachBuffer(std::move(buff));

  // update the strings lookup table
  dex_ir_->strings_lookup.Insert(ir_string);

  return ir_string;
}

Type* Builder::GetType(String* descriptor) {
  // look for an existing type
  for (const auto& ir_type : dex_ir_->types) {
    if (ir_type->descriptor == descriptor) {
      return ir_type.get();
    }
  }

  // create a new type
  auto ir_type = dex_ir_->Alloc<Type>();
  ir_type->descriptor = descriptor;

  // update the index -> ir node map
  auto new_index = dex_ir_->types_indexes.AllocateIndex();
  auto& ir_node = dex_ir_->types_map[new_index];
  SLICER_CHECK_EQ(ir_node, nullptr);
  ir_node = ir_type;
  ir_type->orig_index = new_index;

  return ir_type;
}

TypeList* Builder::GetTypeList(const std::vector<Type*>& types) {
  if (types.empty()) {
    return nullptr;
  }

  // look for an existing TypeList
  for (const auto& ir_type_list : dex_ir_->type_lists) {
    if (ir_type_list->types == types) {
      return ir_type_list.get();
    }
  }

  // create a new TypeList
  auto ir_type_list = dex_ir_->Alloc<TypeList>();
  ir_type_list->types = types;
  return ir_type_list;
}

// Helper for GetProto()
static std::string CreateShorty(Type* return_type, TypeList* param_types) {
  std::stringstream ss;
  ss << dex::DescriptorToShorty(return_type->descriptor->c_str());
  if (param_types != nullptr) {
    for (auto param_type : param_types->types) {
      ss << dex::DescriptorToShorty(param_type->descriptor->c_str());
    }
  }
  return ss.str();
}

Proto* Builder::GetProto(Type* return_type, TypeList* param_types) {
  // create "shorty" descriptor automatically
  auto shorty = GetAsciiString(CreateShorty(return_type, param_types).c_str());

  // look for an existing proto
  for (const auto& ir_proto : dex_ir_->protos) {
    if (ir_proto->shorty == shorty &&
        ir_proto->return_type == return_type &&
        ir_proto->param_types == param_types) {
      return ir_proto.get();
    }
  }

  // create a new proto
  auto ir_proto = dex_ir_->Alloc<Proto>();
  ir_proto->shorty = shorty;
  ir_proto->return_type = return_type;
  ir_proto->param_types = param_types;

  // update the index -> ir node map
  auto new_index = dex_ir_->protos_indexes.AllocateIndex();
  auto& ir_node = dex_ir_->protos_map[new_index];
  SLICER_CHECK_EQ(ir_node, nullptr);
  ir_node = ir_proto;
  ir_proto->orig_index = new_index;

  // update the prototypes lookup table
  dex_ir_->prototypes_lookup.Insert(ir_proto);

  return ir_proto;
}

FieldDecl* Builder::GetFieldDecl(String* name, Type* type, Type* parent) {
  // look for an existing field
  for (const auto& ir_field : dex_ir_->fields) {
    if (ir_field->name == name &&
        ir_field->type == type &&
        ir_field->parent == parent) {
      return ir_field.get();
    }
  }

  // create a new field declaration
  auto ir_field = dex_ir_->Alloc<FieldDecl>();
  ir_field->name = name;
  ir_field->type = type;
  ir_field->parent = parent;

  // update the index -> ir node map
  auto new_index = dex_ir_->fields_indexes.AllocateIndex();
  auto& ir_node = dex_ir_->fields_map[new_index];
  SLICER_CHECK_EQ(ir_node, nullptr);
  ir_node = ir_field;
  ir_field->orig_index = new_index;

  return ir_field;
}

MethodDecl* Builder::GetMethodDecl(String* name, Proto* proto, Type* parent) {
  // look for an existing method
  for (const auto& ir_method : dex_ir_->methods) {
    if (ir_method->name == name &&
        ir_method->prototype == proto &&
        ir_method->parent == parent) {
      return ir_method.get();
    }
  }

  // create a new method declaration
  auto ir_method = dex_ir_->Alloc<MethodDecl>();
  ir_method->name = name;
  ir_method->prototype = proto;
  ir_method->parent = parent;

  // update the index -> ir node map
  auto new_index = dex_ir_->methods_indexes.AllocateIndex();
  auto& ir_node = dex_ir_->methods_map[new_index];
  SLICER_CHECK_EQ(ir_node, nullptr);
  ir_node = ir_method;
  ir_method->orig_index = new_index;

  return ir_method;
}

} // namespace ir


```

`paccer/jni/slicer/dex_utf8.cc`:

```cc
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include "slicer/dex_format.h"

namespace dex {

// Retrieve the next UTF-16 character from a UTF-8 string.
// Advances "*pUtf8Ptr" to the start of the next character.
//
// NOTE: If a string is corrupted by dropping a '\0' in the middle
// of a 3-byte sequence, you can end up overrunning the buffer with
// reads (and possibly with the writes if the length was computed and
// cached before the damage). For performance reasons, this function
// assumes that the string being parsed is known to be valid (e.g., by
// already being verified).
static u2 GetUtf16FromUtf8(const char** pUtf8Ptr) {
  u4 one = *(*pUtf8Ptr)++;
  if ((one & 0x80) != 0) {
    // two- or three-byte encoding
    u4 two = *(*pUtf8Ptr)++;
    if ((one & 0x20) != 0) {
      // three-byte encoding
      u4 three = *(*pUtf8Ptr)++;
      return ((one & 0x0f) << 12) | ((two & 0x3f) << 6) | (three & 0x3f);
    } else {
      // two-byte encoding
      return ((one & 0x1f) << 6) | (two & 0x3f);
    }
  } else {
    // one-byte encoding
    return one;
  }
}

int Utf8Cmp(const char* s1, const char* s2) {
  for (;;) {
    if (*s1 == '\0') {
      if (*s2 == '\0') {
        return 0;
      }
      return -1;
    } else if (*s2 == '\0') {
      return 1;
    }

    int utf1 = GetUtf16FromUtf8(&s1);
    int utf2 = GetUtf16FromUtf8(&s2);
    int diff = utf1 - utf2;

    if (diff != 0) {
      return diff;
    }
  }
}

}  // namespace dex

```

`paccer/jni/slicer/export/slicer/arrayview.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include "common.h"

#include <stdlib.h>

namespace slicer {

// A shallow array view
template <class T>
class ArrayView {
 public:
  ArrayView() = default;

  ArrayView(const ArrayView&) = default;
  ArrayView& operator=(const ArrayView&) = default;

  ArrayView(T* ptr, size_t count) : begin_(ptr), end_(ptr + count) {}

  T* begin() const { return begin_; }
  T* end() const { return end_; }

  T* data() const { return begin_; }

  T& operator[](size_t i) const {
    SLICER_CHECK_LT(i, size());
    return *(begin_ + i);
  }

  size_t size() const { return end_ - begin_; }
  bool empty() const { return begin_ == end_; }

 private:
  T* begin_ = nullptr;
  T* end_ = nullptr;
};

} // namespace slicer


```

`paccer/jni/slicer/export/slicer/buffer.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include "arrayview.h"
#include "common.h"
#include "dex_leb128.h"
#include "memview.h"

#include <assert.h>
#include <string>
#include <algorithm>
#include <vector>
#include <cstring>

namespace slicer {

// A simple growing memory buffer
//
// NOTE: pointers into this buffer are not stable
//   since it may be relocated as it expands.
//
class Buffer {
 public:
  Buffer() = default;

  ~Buffer() { Free(); }

  Buffer(const Buffer&) = delete;
  Buffer& operator=(const Buffer&) = delete;

  Buffer(Buffer&& b) {
    std::swap(buff_, b.buff_);
    std::swap(size_, b.size_);
    std::swap(capacity_, b.capacity_);
  }

  Buffer& operator=(Buffer&& b) {
    Free();
    std::swap(buff_, b.buff_);
    std::swap(size_, b.size_);
    std::swap(capacity_, b.capacity_);
    return *this;
  }

 public:
  // Align the total size and prevent further changes
  size_t Seal(size_t alignment) {
    SLICER_CHECK(!sealed_);
    Align(alignment);
    sealed_ = true;
    return size();
  }

  // Returns a pointer within the buffer
  //
  // NOTE: the returned pointer is "ephemeral" and
  //   is only valid until the next buffer push/alloc
  //
  template <class T>
  T* ptr(size_t offset) {
    SLICER_CHECK_LE(offset + sizeof(T), size_);
    return reinterpret_cast<T*>(buff_ + offset);
  }

  // Align the buffer size to the specified alignment
  void Align(size_t alignment) {
    assert(alignment > 0);
    size_t rem = size_ % alignment;
    if (rem != 0) {
      Alloc(alignment - rem);
    }
  }

  size_t Alloc(size_t size) {
    size_t offset = size_;
    Expand(size);
    std::memset(buff_ + offset, 0, size);
    return offset;
  }

  size_t Push(const void* ptr, size_t size) {
    size_t offset = size_;
    Expand(size);
    std::memcpy(buff_ + offset, ptr, size);
    return offset;
  }

  size_t Push(const MemView& memView) {
    return Push(memView.ptr(), memView.size());
  }

  template <class T>
  size_t Push(const ArrayView<T>& a) {
    return Push(a.data(), a.size() * sizeof(T));
  }

  template <class T>
  size_t Push(const std::vector<T>& v) {
    return Push(v.data(), v.size() * sizeof(T));
  }

  size_t Push(const Buffer& buff) {
    SLICER_CHECK_NE(&buff, this);
    return Push(buff.data(), buff.size());
  }

  // TODO: this is really dangerous since it would
  //   write any type - sometimes not what you expect.
  //
  template <class T>
  size_t Push(const T& value) {
    return Push(&value, sizeof(value));
  }

  size_t PushULeb128(dex::u4 value) {
    dex::u1 tmp[4];
    dex::u1* end = dex::WriteULeb128(tmp, value);
    assert(end > tmp && end - tmp <= 4);
    return Push(tmp, end - tmp);
  }

  size_t PushSLeb128(dex::s4 value) {
    dex::u1 tmp[4];
    dex::u1* end = dex::WriteSLeb128(tmp, value);
    assert(end > tmp && end - tmp <= 4);
    return Push(tmp, end - tmp);
  }

  size_t size() const { return size_; }

  bool empty() const { return size_ == 0; }

  void Free() {
    ::free(buff_);
    buff_ = nullptr;
    size_ = 0;
    capacity_ = 0;
  }

  const dex::u1* data() const {
    SLICER_CHECK_NE(buff_, nullptr);
    return buff_;
  }

 private:
  void Expand(size_t size) {
    SLICER_CHECK(!sealed_);
    if (size_ + size > capacity_) {
      capacity_ = std::max(size_t(capacity_ * 1.5), size_ + size);
      buff_ = static_cast<dex::u1*>(::realloc(buff_, capacity_));
      SLICER_CHECK_NE(buff_, nullptr);
    }
    size_ += size;
  }

 private:
  dex::u1* buff_ = nullptr;
  size_t size_ = 0;
  size_t capacity_ = 0;
  bool sealed_ = false;
};

} // namespace slicer


```

`paccer/jni/slicer/export/slicer/bytecode_encoder.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include "buffer.h"
#include "common.h"
#include "code_ir.h"
#include "dex_ir.h"

#include <assert.h>
#include <vector>

namespace lir {

// Generates .dex bytecode from code IR
class BytecodeEncoder : public Visitor {
 public:
  explicit BytecodeEncoder(const InstructionsList& instructions)
    : instructions_(instructions) {
  }

  ~BytecodeEncoder() = default;

  void Encode(ir::Code* ir_code, std::shared_ptr<ir::DexFile> dex_ir);

 private:
  // the visitor interface
  virtual bool Visit(Bytecode* bytecode) override;
  virtual bool Visit(PackedSwitchPayload* packed_switch) override;
  virtual bool Visit(SparseSwitchPayload* sparse_switch) override;
  virtual bool Visit(ArrayData* array_data) override;
  virtual bool Visit(Label* label) override;
  virtual bool Visit(DbgInfoHeader* dbg_header) override;
  virtual bool Visit(DbgInfoAnnotation* dbg_annotation) override;
  virtual bool Visit(TryBlockBegin* try_begin) override;
  virtual bool Visit(TryBlockEnd* try_end) override;

  // fixup helpers
  void FixupSwitchOffsets();
  void FixupPackedSwitch(dex::u4 base_offset, dex::u4 payload_offset);
  void FixupSparseSwitch(dex::u4 base_offset, dex::u4 payload_offset);
  void FixupLabels();

 private:
  // Structure used to track code location fixups
  struct LabelFixup {
    dex::u4 offset;       // instruction to be fixed up
    const Label* label;   // target label
    bool short_fixup;     // 16bit or 32bit fixup?

    LabelFixup(dex::u4 offset, Label* label, bool short_fixup) :
      offset(offset), label(label), short_fixup(short_fixup) {}
  };

 private:
  slicer::Buffer bytecode_;
  std::vector<LabelFixup> fixups_;

  // Current bytecode offset (in 16bit units)
  dex::u4 offset_ = 0;

  // Number of registers using for outgoing arguments
  dex::u4 outs_count_ = 0;

  // Keeping track of the switch payload instructions for late fixups
  // (map encoded bytecode offset -> LIR instruction)
  std::map<dex::u4, const PackedSwitchPayload*> packed_switches_;
  std::map<dex::u4, const SparseSwitchPayload*> sparse_switches_;

  const InstructionsList& instructions_;
};

} // namespace lir


```

`paccer/jni/slicer/export/slicer/chronometer.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include <chrono>

namespace slicer {

// A very simple timing chronometer
class Chronometer {
  using Clock = std::chrono::high_resolution_clock;

 public:
  // elapsed time is in milliseconds
  explicit Chronometer(double& elapsed, bool cumulative = false) :
              elapsed_(elapsed), cumulative_(cumulative) {
    start_time_ = Clock::now();
  }

  ~Chronometer() {
    Clock::time_point end_time = Clock::now();
    std::chrono::duration<double, std::milli> ms = end_time - start_time_;
    if (cumulative_) {
      elapsed_ += ms.count();
    } else {
      elapsed_ = ms.count();
    }
  }

  Chronometer(const Chronometer&) = delete;
  Chronometer& operator=(const Chronometer&) = delete;

 private:
  double& elapsed_;
  Clock::time_point start_time_;
  bool cumulative_;
};

} // namespace slicer


```

`paccer/jni/slicer/export/slicer/code_ir.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#if defined(__clang__)
  #if __has_feature(cxx_rtti)
    #define RTTI_ENABLED 1
  #endif
#endif

#include "common.h"
#include "memview.h"
#include "dex_bytecode.h"
#include "dex_format.h"
#include "dex_ir.h"
#include "intrusive_list.h"

#include <assert.h>
#include <stdio.h>
#include <stdlib.h>

#include <algorithm>
#include <cstdint>
#include <list>
#include <map>
#include <memory>
#include <utility>
#include <vector>

namespace lir {

template <class T>
using own = std::unique_ptr<T>;

constexpr dex::u4 kInvalidOffset = dex::u4(-1);

struct Bytecode;
struct PackedSwitchPayload;
struct SparseSwitchPayload;
struct ArrayData;
struct Label;
struct TryBlockBegin;
struct TryBlockEnd;
struct Const32;
struct Const64;
struct VReg;
struct VRegPair;
struct VRegList;
struct VRegRange;
struct CodeLocation;
struct String;
struct Type;
struct Field;
struct Method;
struct MethodHandle;
struct Proto;
struct DbgInfoHeader;
struct LineNumber;
struct DbgInfoAnnotation;

// Code IR visitor interface
class Visitor {
 public:
  Visitor() = default;
  virtual ~Visitor() = default;

  Visitor(const Visitor&) = delete;
  Visitor& operator=(const Visitor&) = delete;

  // instructions
  virtual bool Visit(Bytecode* bytecode) { return false; }
  virtual bool Visit(PackedSwitchPayload* packed_switch) { return false; }
  virtual bool Visit(SparseSwitchPayload* sparse_switch) { return false; }
  virtual bool Visit(ArrayData* array_data) { return false; }
  virtual bool Visit(Label* label) { return false; }
  virtual bool Visit(DbgInfoHeader* dbg_header) { return false; }
  virtual bool Visit(DbgInfoAnnotation* dbg_annotation) { return false; }
  virtual bool Visit(TryBlockBegin* try_begin) { return false; }
  virtual bool Visit(TryBlockEnd* try_end) { return false; }

  // operands
  virtual bool Visit(CodeLocation* location) { return false; }
  virtual bool Visit(Const32* const32) { return false; }
  virtual bool Visit(Const64* const64) { return false; }
  virtual bool Visit(VReg* vreg) { return false; }
  virtual bool Visit(VRegPair* vreg_pair) { return false; }
  virtual bool Visit(VRegList* vreg_list) { return false; }
  virtual bool Visit(VRegRange* vreg_range) { return false; }
  virtual bool Visit(String* string) { return false; }
  virtual bool Visit(Type* type) { return false; }
  virtual bool Visit(Field* field) { return false; }
  virtual bool Visit(Method* method) { return false; }
  virtual bool Visit(Proto* proto) { return false; }
  virtual bool Visit(LineNumber* line) { return false; }
  virtual bool Visit(MethodHandle* mh) { return false; }
};

// The root of the polymorphic code IR nodes hierarchy
//
// NOTE: in general it's possible to "reuse" code IR nodes
//   (ie. refcount > 1) although extra care is required since
//   modifications to shared nodes will be visible in multiple places
//   (notable exception: instruction nodes can't be reused)
//
struct Node {
  Node() = default;
  virtual ~Node() = default;

  Node(const Node&) = delete;
  Node& operator=(const Node&) = delete;

  virtual bool Accept(Visitor* visitor) { return false; }
};

struct Operand : public Node {};

struct Const32 : public Operand {
  union {
    dex::s4 s4_value;
    dex::u4 u4_value;
    float float_value;
  } u;

  explicit Const32(dex::u4 value) { u.u4_value = value; }

  virtual bool Accept(Visitor* visitor) override { return visitor->Visit(this); }
};

struct Const64 : public Operand {
  union {
    dex::s8 s8_value;
    dex::u8 u8_value;
    double double_value;
  } u;

  explicit Const64(dex::u8 value) { u.u8_value = value; }

  virtual bool Accept(Visitor* visitor) override { return visitor->Visit(this); }
};

struct VReg : public Operand {
  dex::u4 reg;

  explicit VReg(dex::u4 reg) : reg(reg) {}

  virtual bool Accept(Visitor* visitor) override { return visitor->Visit(this); }
};

struct VRegPair : public Operand {
  dex::u4 base_reg;

  explicit VRegPair(dex::u4 base_reg) : base_reg(base_reg) {}

  virtual bool Accept(Visitor* visitor) override { return visitor->Visit(this); }
};

struct VRegList : public Operand {
  std::vector<dex::u4> registers;

  virtual bool Accept(Visitor* visitor) override { return visitor->Visit(this); }
};

struct VRegRange : public Operand {
  dex::u4 base_reg;
  int count;

  VRegRange(dex::u4 base_reg, int count) : base_reg(base_reg), count(count) {}

  virtual bool Accept(Visitor* visitor) override { return visitor->Visit(this); }
};

struct IndexedOperand : public Operand {
  dex::u4 index;

  explicit IndexedOperand(dex::u4 index) : index(index) {}
};

struct String : public IndexedOperand {
  ir::String* ir_string;

  String(ir::String* ir_string, dex::u4 index) : IndexedOperand(index), ir_string(ir_string) {}

  virtual bool Accept(Visitor* visitor) override { return visitor->Visit(this); }
};

struct Type : public IndexedOperand {
  ir::Type* ir_type;

  Type(ir::Type* ir_type, dex::u4 index) : IndexedOperand(index), ir_type(ir_type) {}

  virtual bool Accept(Visitor* visitor) override { return visitor->Visit(this); }
};

struct Field : public IndexedOperand {
  ir::FieldDecl* ir_field;

  Field(ir::FieldDecl* ir_field, dex::u4 index) : IndexedOperand(index), ir_field(ir_field) {}

  virtual bool Accept(Visitor* visitor) override { return visitor->Visit(this); }
};

struct Method : public IndexedOperand {
  ir::MethodDecl* ir_method;

  Method(ir::MethodDecl* ir_method, dex::u4 index) : IndexedOperand(index), ir_method(ir_method) {
    SLICER_CHECK_NE(ir_method, nullptr);
  }

  virtual bool Accept(Visitor* visitor) override { return visitor->Visit(this); }
};

struct MethodHandle : public IndexedOperand {
  ir::MethodHandle* ir_method_handle;

  MethodHandle(ir::MethodHandle* ir_method_handle, dex::u4 index) : IndexedOperand(index), ir_method_handle(ir_method_handle) {
    SLICER_CHECK_NE(ir_method_handle, nullptr);
  }

  virtual bool Accept(Visitor* visitor) override { return visitor->Visit(this); }
};

struct Proto : public IndexedOperand {
  ir::Proto* ir_proto;

  Proto(ir::Proto* ir_proto, dex::u4 index) : IndexedOperand(index), ir_proto(ir_proto) {}

  virtual bool Accept(Visitor* visitor) override { return visitor->Visit(this); }
};

struct CodeLocation : public Operand {
  Label* label;

  explicit CodeLocation(Label* label) : label(label) {}

  virtual bool Accept(Visitor* visitor) override { return visitor->Visit(this); }
};

// Code IR is a linked list of Instructions
struct Instruction : public Node {
  // absolute offset from the start of the method
  dex::u4 offset = 0;

  Instruction* prev = nullptr;
  Instruction* next = nullptr;
};

using InstructionsList = slicer::IntrusiveList<Instruction>;

namespace detail {

template<class T>
inline T* CastOperand(Operand* op) {
#ifdef RTTI_ENABLED
  T* operand = dynamic_cast<T*>(op);
  SLICER_CHECK_NE(operand, nullptr);
  return operand;
#else
  SLICER_CHECK_NE(op, nullptr);
  struct CastVisitor : public Visitor {
    T* converted = nullptr;
    bool Visit(T* val) override {
      converted = val;
      return true;
    }
  };
  CastVisitor cv;
  op->Accept(&cv);
  SLICER_CHECK_NE(cv.converted, nullptr);
  return cv.converted;
#endif
}

// Special-case for IndexedOperand.
template<>
inline IndexedOperand* CastOperand<IndexedOperand>(Operand* op) {
#ifdef RTTI_ENABLED
  IndexedOperand* operand = dynamic_cast<IndexedOperand*>(op);
  SLICER_CHECK_NE(operand, nullptr);
  return operand;
#else
  SLICER_CHECK_NE(op, nullptr);
  struct CastVisitor : public Visitor {
    IndexedOperand* converted = nullptr;
    bool Visit(String* val) override {
      converted = val;
      return true;
    }
    bool Visit(Type* val) override {
      converted = val;
      return true;
    }
    bool Visit(Field* val) override {
      converted = val;
      return true;
    }
    bool Visit(Method* val) override {
      converted = val;
      return true;
    }
    bool Visit(MethodHandle* val) override {
      converted = val;
      return true;
    }
    bool Visit(Proto* val) override {
      converted = val;
      return true;
    }
  };
  CastVisitor cv;
  op->Accept(&cv);
  SLICER_CHECK_NE(cv.converted, nullptr);
  return cv.converted;
#endif
}

}  // namespace detail

struct Bytecode : public Instruction {
  dex::Opcode opcode = dex::OP_NOP;
  std::vector<Operand*> operands;

  template<class T>
  T* CastOperand(int index) const {
    return detail::CastOperand<T>(operands[index]);
  }

  virtual bool Accept(Visitor* visitor) override { return visitor->Visit(this); }
};

struct PackedSwitchPayload : public Instruction {
  dex::s4 first_key = 0;
  std::vector<Label*> targets;

  virtual bool Accept(Visitor* visitor) override { return visitor->Visit(this); }
};

struct SparseSwitchPayload : public Instruction {
  struct SwitchCase {
    dex::s4 key = 0;
    Label* target = nullptr;
  };

  std::vector<SwitchCase> switch_cases;

  virtual bool Accept(Visitor* visitor) override { return visitor->Visit(this); }
};

struct ArrayData : public Instruction {
  slicer::MemView data;

  virtual bool Accept(Visitor* visitor) override { return visitor->Visit(this); }
};

struct Label : public Instruction {
  int id = 0;
  int refCount = 0;
  bool aligned = false;

  explicit Label(dex::u4 offset) { this->offset = offset; }

  virtual bool Accept(Visitor* visitor) override { return visitor->Visit(this); }
};

struct TryBlockBegin : public Instruction {
  int id = 0;

  virtual bool Accept(Visitor* visitor) override { return visitor->Visit(this); }
};

struct CatchHandler {
  ir::Type* ir_type = nullptr;
  Label* label = nullptr;
};

struct TryBlockEnd : public Instruction {
  TryBlockBegin* try_begin = nullptr;
  std::vector<CatchHandler> handlers;
  Label* catch_all = nullptr;

  virtual bool Accept(Visitor* visitor) override { return visitor->Visit(this); }
};

struct DbgInfoHeader : public Instruction {
  std::vector<ir::String*> param_names;

  virtual bool Accept(Visitor* visitor) override { return visitor->Visit(this); }
};

struct LineNumber : public Operand {
  int line = 0;

  explicit LineNumber(int line) : line(line) {
    SLICER_WEAK_CHECK(line >= 0);
  }

  virtual bool Accept(Visitor* visitor) override { return visitor->Visit(this); }
};

struct DbgInfoAnnotation : public Instruction {
  dex::u1 dbg_opcode = 0;
  std::vector<Operand*> operands;

  explicit DbgInfoAnnotation(dex::u1 dbg_opcode) : dbg_opcode(dbg_opcode) {}

  template<class T>
  T* CastOperand(int index) const {
    return detail::CastOperand<T>(operands[index]);
  }

  virtual bool Accept(Visitor* visitor) override { return visitor->Visit(this); }
};

// Code IR container and manipulation interface
struct CodeIr {
  // linked list of the method's instructions
  InstructionsList instructions;

  ir::EncodedMethod* ir_method = nullptr;
  std::shared_ptr<ir::DexFile> dex_ir;

 public:
  CodeIr(ir::EncodedMethod* ir_method, std::shared_ptr<ir::DexFile> dex_ir)
      : ir_method(ir_method), dex_ir(dex_ir) {
    Disassemble();
  }

  // No copy/move semantics
  CodeIr(const CodeIr&) = delete;
  CodeIr& operator=(const CodeIr&) = delete;

  void Assemble();

  void Accept(Visitor* visitor) {
    for (auto instr : instructions) {
      instr->Accept(visitor);
    }
  }

  template <class T, class... Args>
  T* Alloc(Args&&... args) {
    auto p = new T(std::forward<Args>(args)...);
    nodes_.push_back(own<T>(p));
    return p;
  }

 private:
  void Disassemble();
  void DisassembleBytecode(const ir::Code* ir_code);
  void DisassembleTryBlocks(const ir::Code* ir_code);
  void DisassembleDebugInfo(const ir::DebugInfo* ir_debug_info);

  void FixupSwitches();
  void FixupPackedSwitch(PackedSwitchPayload* instr, dex::u4 base_offset, const dex::u2* ptr);
  void FixupSparseSwitch(SparseSwitchPayload* instr, dex::u4 base_offset, const dex::u2* ptr);

  SparseSwitchPayload* DecodeSparseSwitch(const dex::u2* /*ptr*/, dex::u4 offset);
  PackedSwitchPayload* DecodePackedSwitch(const dex::u2* /*ptr*/, dex::u4 offset);
  ArrayData* DecodeArrayData(const dex::u2* ptr, dex::u4 offset);
  Bytecode* DecodeBytecode(const dex::u2* ptr, dex::u4 offset);

  IndexedOperand* GetIndexedOperand(dex::InstructionIndexType index_type, dex::u4 index);
  IndexedOperand* GetSecondIndexedOperand(dex::InstructionIndexType index_type, dex::u4 index);

  Type* GetType(dex::u4 index);
  String* GetString(dex::u4 index);
  Label* GetLabel(dex::u4 offset);

  Operand* GetRegA(const dex::Instruction& dex_instr);
  Operand* GetRegB(const dex::Instruction& dex_instr);
  Operand* GetRegC(const dex::Instruction& dex_instr);

 private:
  // the "master index" of all the LIR owned nodes
  std::vector<own<Node>> nodes_;

  // data structures for fixing up switch payloads
  struct PackedSwitchFixup {
    PackedSwitchPayload* instr = nullptr;
    dex::u4 base_offset = kInvalidOffset;
  };

  struct SparseSwitchFixup {
    SparseSwitchPayload* instr = nullptr;
    dex::u4 base_offset = kInvalidOffset;
  };

  // used during bytecode raising
  std::map<dex::u4, Label*> labels_;
  std::map<dex::u4, PackedSwitchFixup> packed_switches_;
  std::map<dex::u4, SparseSwitchFixup> sparse_switches_;

  // extra instructions/annotations created during raising
  // (intended to be merged in with the main instruction
  //  list at end of the IR raising phase)
  std::vector<TryBlockBegin*> try_begins_;
  std::vector<TryBlockEnd*> try_ends_;
  std::vector<Instruction*> dbg_annotations_;
};

}  // namespace lir

```

`paccer/jni/slicer/export/slicer/common.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include <stdint.h>
#include <string>

namespace slicer {

// Encapsulate the runtime check and error reporting policy.
// (currently a simple fail-fast but the the intention is to allow customization)
void _checkFailed(const char* expr, int line, const char* file) __attribute__((noreturn));
#define SLICER_CHECK(expr) do { if(!(expr)) slicer::_checkFailed(#expr, __LINE__, __FILE__); } while(false)

// Helper methods for SLICER_CHECK_OP macro.
void _checkFailedOp(const void* lhs, const void* rhs, const char* op, const char* suffix,
                    int line, const char* file)
  __attribute__((noreturn));
void _checkFailedOp(uint32_t lhs, uint32_t rhs, const char* op, const char* suffix, int line,
                    const char* file)
  __attribute__((noreturn));

#define SLICER_CHECK_OP(lhs, rhs, op, suffix) \
  do { \
    if (!((lhs) op (rhs))) { \
      slicer::_checkFailedOp(lhs, rhs, #op, suffix, __LINE__, __FILE__); \
    } \
  } while(false)

// Macros that check the binary relation between two values. If the relation is not true,
// the values are logged and the process aborts.
#define SLICER_CHECK_EQ(a, b) SLICER_CHECK_OP(a, b, ==, "EQ")
#define SLICER_CHECK_NE(a, b) SLICER_CHECK_OP(a, b, !=, "NE")
#define SLICER_CHECK_LT(a, b) SLICER_CHECK_OP(a, b,  <, "LT")
#define SLICER_CHECK_LE(a, b) SLICER_CHECK_OP(a, b, <=, "LE")
#define SLICER_CHECK_GT(a, b) SLICER_CHECK_OP(a, b,  >, "GT")
#define SLICER_CHECK_GE(a, b) SLICER_CHECK_OP(a, b, >=, "GE")

// A modal check: if the strict mode is enabled, it behaves as a SLICER_CHECK,
// otherwise it will only log a warning and continue
//
// NOTE: we use SLICER_WEAK_CHECK for .dex format validations that are frequently
//   violated by existing apps. So we need to be able to annotate these common
//   problems and potentially ignoring them for parity with the Android runtime.
//
void _weakCheckFailed(const char* expr, int line, const char* file);
#define SLICER_WEAK_CHECK(expr) do { if(!(expr)) slicer::_weakCheckFailed(#expr, __LINE__, __FILE__); } while(false)

// Report a fatal condition with a printf-formatted message
void _fatal(const std::string& msg) __attribute__((noreturn));
#define SLICER_FATAL(msg) slicer::_fatal(msg)

// Annotation customization point for extra validation / state.
#ifdef NDEBUG
#define SLICER_EXTRA(x)
#else
#define SLICER_EXTRA(x) x
#endif

#ifndef FALLTHROUGH_INTENDED
#ifdef __clang__
#define FALLTHROUGH_INTENDED [[clang::fallthrough]]
#else
#define FALLTHROUGH_INTENDED
#endif // __clang__
#endif // FALLTHROUGH_INTENDED

typedef void (*logger_type)(const std::string&);

// By default, slicer prints error messages to stdout. Users can set their own
// callback.
void set_logger(const logger_type new_logger);

} // namespace slicer


```

`paccer/jni/slicer/export/slicer/control_flow_graph.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include "code_ir.h"
#include "common.h"

#include <vector>

namespace lir {

// Represents a contiguous code "region"
struct Region {
  Instruction* first = nullptr;
  Instruction* last = nullptr;
};

struct BasicBlock {
  int id = 0;       // real basic blocks have id > 0
  Region region;
};

// LIR visitor used to build the list of basic blocks
class BasicBlocksVisitor : public Visitor {
  enum class State { Outside, BlockHeader, BlockBody };

 public:
  explicit BasicBlocksVisitor(bool model_exceptions) : model_exceptions_(model_exceptions) {
    current_block_.id = 0;
  }

  ~BasicBlocksVisitor() {
    assert(state_ == State::Outside);
  }

  // Used to mark the end of instruction stream
  // Returns the list of basic blocks
  std::vector<BasicBlock> Finish();

 private:
  bool Visit(Bytecode* bytecode) override;
  bool Visit(Label* label) override;

  // Debug info annotations
  bool Visit(DbgInfoHeader* dbg_header) override { return HandleAnnotation(dbg_header); }
  bool Visit(DbgInfoAnnotation* dbg_annotation) override { return HandleAnnotation(dbg_annotation); }

  // EH annotations
  bool Visit(TryBlockBegin* try_begin) override { return SkipInstruction(try_begin); }
  bool Visit(TryBlockEnd* try_end) override { return SkipInstruction(try_end); }

  // data payload
  bool Visit(PackedSwitchPayload* packed_switch) override  { return SkipInstruction(packed_switch); }
  bool Visit(SparseSwitchPayload* sparse_switch) override { return SkipInstruction(sparse_switch); }
  bool Visit(ArrayData* array_data) override { return SkipInstruction(array_data); }

  bool HandleAnnotation(Instruction* instr);
  bool SkipInstruction(Instruction* instr);

  // Starts a new basic block starting with the specified instruction
  void StartBlock(Instruction* instr);

  // Ends the current basic block at the specified instruction
  void EndBlock(Instruction* instr);

 private:
  State state_ = State::Outside;
  BasicBlock current_block_;
  std::vector<BasicBlock> basic_blocks_;
  const bool model_exceptions_;
};

// The Control Flow Graph (CFG) for the specified method LIR
struct ControlFlowGraph {
  // The list of basic blocks, as non-overlapping regions,
  // sorted by the byte offset of the region start
  std::vector<BasicBlock> basic_blocks;

  const CodeIr* code_ir;

 public:
  ControlFlowGraph(const CodeIr* code_ir, bool model_exceptions) : code_ir(code_ir) {
    CreateBasicBlocks(model_exceptions);
  }

 private:
  void CreateBasicBlocks(bool model_exceptions);
};

}  // namespace lir

```

`paccer/jni/slicer/export/slicer/debuginfo_encoder.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include "buffer.h"
#include "chronometer.h"
#include "common.h"
#include "code_ir.h"
#include "dex_ir.h"

#include <vector>

namespace lir {

// Generates debug info from code IR
class DebugInfoEncoder : public Visitor {
 private:
  virtual bool Visit(DbgInfoHeader* dbg_header) override;
  virtual bool Visit(DbgInfoAnnotation* dbg_annotation) override;

 public:
  explicit DebugInfoEncoder(const InstructionsList& instructions)
    : instructions_(instructions) {
  }

  ~DebugInfoEncoder() = default;

  void Encode(ir::EncodedMethod* ir_method, std::shared_ptr<ir::DexFile> dex_ir);

 private:
  std::vector<ir::String*>* param_names_ = nullptr;
  dex::u4 line_start_ = 0;
  dex::u4 last_line_ = 0;
  dex::u4 last_address_ = 0;
  ir::String* source_file_ = nullptr;
  slicer::Buffer dbginfo_;
  const InstructionsList& instructions_;
};

} // namespace lir


```

`paccer/jni/slicer/export/slicer/dex_bytecode.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include "dex_format.h"

#include <iosfwd>
#include <stddef.h>

// .dex bytecode definitions and helpers:
// https://source.android.com/devices/tech/dalvik/dalvik-bytecode.html

namespace dex {

// The number of Dalvik opcodes
constexpr size_t kNumPackedOpcodes = 0x100;

// Switch table and array data signatures are a code unit consisting
// of "NOP" (0x00) in the low-order byte and a non-zero identifying
// code in the high-order byte. (A true NOP is 0x0000.)
constexpr u2 kPackedSwitchSignature = 0x0100;
constexpr u2 kSparseSwitchSignature = 0x0200;
constexpr u2 kArrayDataSignature = 0x0300;

// Include for  DEX_INSTRUCTION_LIST and DEX_INSTRUCTION_FORMAT_LIST
#include "dex_instruction_list.h"

// Enumeration of all Dalvik opcodes
enum Opcode : u1 {
#define INSTRUCTION_ENUM(opcode, cname, ...) OP_##cname = (opcode),
  DEX_INSTRUCTION_LIST(INSTRUCTION_ENUM)
#undef INSTRUCTION_ENUM
};

// Instruction formats associated with Dalvik opcodes
enum InstructionFormat : u1 {
#define INSTRUCTION_FORMAT_ENUM(name) k##name,
#include "dex_instruction_list.h"
  DEX_INSTRUCTION_FORMAT_LIST(INSTRUCTION_FORMAT_ENUM)
#undef INSTRUCTION_FORMAT_ENUM
};

#undef DEX_INSTRUCTION_FORMAT_LIST
#undef DEX_INSTRUCTION_LIST

using OpcodeFlags = u1;
enum : OpcodeFlags {
  kBranch = 0x01,         // conditional or unconditional branch
  kContinue = 0x02,       // flow can continue to next statement
  kSwitch = 0x04,         // switch statement
  kThrow = 0x08,          // could cause an exception to be thrown
  kReturn = 0x10,         // returns, no additional statements
  kInvoke = 0x20,         // a flavor of invoke
  kUnconditional = 0x40,  // unconditional branch
  kExperimental = 0x80,   // is an experimental opcode
};

using VerifyFlags = u4;
enum : VerifyFlags {
  kVerifyNothing = 0x0000000,
  kVerifyRegA = 0x0000001,
  kVerifyRegAWide = 0x0000002,
  kVerifyRegB = 0x0000004,
  kVerifyRegBField = 0x0000008,
  kVerifyRegBMethod = 0x0000010,
  kVerifyRegBNewInstance = 0x0000020,
  kVerifyRegBString = 0x0000040,
  kVerifyRegBType = 0x0000080,
  kVerifyRegBWide = 0x0000100,
  kVerifyRegC = 0x0000200,
  kVerifyRegCField = 0x0000400,
  kVerifyRegCNewArray = 0x0000800,
  kVerifyRegCType = 0x0001000,
  kVerifyRegCWide = 0x0002000,
  kVerifyArrayData = 0x0004000,
  kVerifyBranchTarget = 0x0008000,
  kVerifySwitchTargets = 0x0010000,
  kVerifyVarArg = 0x0020000,
  kVerifyVarArgNonZero = 0x0040000,
  kVerifyVarArgRange = 0x0080000,
  kVerifyVarArgRangeNonZero = 0x0100000,
  kVerifyRuntimeOnly = 0x0200000,
  kVerifyError = 0x0400000,
  kVerifyRegHPrototype = 0x0800000,
  kVerifyRegBCallSite = 0x1000000,
  kVerifyRegBMethodHandle = 0x2000000,
  kVerifyRegBPrototype = 0x4000000,
};

// Types of indexed reference that are associated with opcodes whose
// formats include such an indexed reference (e.g., 21c and 35c).
enum InstructionIndexType : u1 {
  kIndexUnknown = 0,
  kIndexNone,               // has no index
  kIndexVaries,             // "It depends." Used for throw-verification-error
  kIndexTypeRef,            // type reference index
  kIndexStringRef,          // string reference index
  kIndexMethodRef,          // method reference index
  kIndexFieldRef,           // field reference index
  kIndexInlineMethod,       // inline method index (for inline linked methods)
  kIndexVtableOffset,       // vtable offset (for static linked methods)
  kIndexFieldOffset,        // field offset (for static linked fields)
  kIndexMethodAndProtoRef,  // method index and proto index
  kIndexCallSiteRef,        // call site index
  kIndexMethodHandleRef,    // constant method handle reference index
  kIndexProtoRef,           // constant prototype reference index
};

// Holds the contents of a decoded instruction.
struct Instruction {
  u4 vA;          // the A field of the instruction
  u4 vB;          // the B field of the instruction
  u8 vB_wide;     // 64bit version of the B field (for k51l)
  u4 vC;          // the C field of the instruction
  u4 arg[5];      // vC/D/E/F/G in invoke or filled-new-array
  Opcode opcode;  // instruction opcode
};

// "packed-switch-payload" format
struct PackedSwitchPayload {
  u2 ident;
  u2 size;
  s4 first_key;
  s4 targets[];
};

// "sparse-switch-payload" format
struct SparseSwitchPayload {
  u2 ident;
  u2 size;
  s4 data[];
};

// "fill-array-data-payload" format
struct ArrayData {
  u2 ident;
  u2 element_width;
  u4 size;
  u1 data[];
};

// Collect the enums in a struct for better locality.
struct InstructionDescriptor {
  u4 verify_flags;  // Set of VerifyFlag.
  InstructionFormat format;
  InstructionIndexType index_type;
  u1 flags;  // Set of Flags.
};

// Extracts the opcode from a Dalvik code unit (bytecode)
Opcode OpcodeFromBytecode(u2 bytecode);

// Returns the name of an opcode
const char* GetOpcodeName(Opcode opcode);

// Returns the index type associated with the specified opcode
InstructionIndexType GetIndexTypeFromOpcode(Opcode opcode);

// Returns the format associated with the specified opcode
InstructionFormat GetFormatFromOpcode(Opcode opcode);

// Returns the flags for the specified opcode
OpcodeFlags GetFlagsFromOpcode(Opcode opcode);

// Returns the verify flags for the specified opcode
VerifyFlags GetVerifyFlagsFromOpcode(Opcode opcode);

// Returns the instruction width for the specified opcode format
size_t GetWidthFromFormat(InstructionFormat format);

// Return the width of the specified instruction, or 0 if not defined.  Also
// works for special OP_NOP entries, including switch statement data tables
// and array data.
size_t GetWidthFromBytecode(const u2* bytecode);

// Decode a .dex bytecode
Instruction DecodeInstruction(const u2* bytecode);

// Writes a hex formatted opcode to an output stream.
std::ostream& operator<<(std::ostream& os, Opcode opcode);

// Writes name of format to an outputstream.
std::ostream& operator<<(std::ostream& os, InstructionFormat format);

}  // namespace dex

```

`paccer/jni/slicer/export/slicer/dex_format.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include <stdint.h>
#include <string>

// Definitions for .dex file format structures and helpers.
//
// The names for the structures and fields follows the specification:
// https://source.android.com/devices/tech/dalvik/dex-format.html

namespace dex {

// These match the definitions in the VM specification
typedef uint8_t u1;
typedef uint16_t u2;
typedef uint32_t u4;
typedef uint64_t u8;
typedef int8_t s1;
typedef int16_t s2;
typedef int32_t s4;
typedef int64_t s8;

// General constants
constexpr u4 kEndianConstant = 0x12345678;
constexpr u4 kNoIndex = 0xffffffff;
constexpr u4 kSHA1DigestLen = 20;

// Annotation visibility
constexpr u1 kVisibilityBuild   = 0x00;
constexpr u1 kVisibilityRuntime = 0x01;
constexpr u1 kVisibilitySystem  = 0x02;

// Special visibility: encoded_annotation, not annotation_item
constexpr u1 kVisibilityEncoded = 0xff;

// encoded_value types
constexpr u1 kEncodedByte           = 0x00;
constexpr u1 kEncodedShort          = 0x02;
constexpr u1 kEncodedChar           = 0x03;
constexpr u1 kEncodedInt            = 0x04;
constexpr u1 kEncodedLong           = 0x06;
constexpr u1 kEncodedFloat          = 0x10;
constexpr u1 kEncodedDouble         = 0x11;
constexpr u1 kEncodedString         = 0x17;
constexpr u1 kEncodedType           = 0x18;
constexpr u1 kEncodedField          = 0x19;
constexpr u1 kEncodedMethod         = 0x1a;
constexpr u1 kEncodedEnum           = 0x1b;
constexpr u1 kEncodedArray          = 0x1c;
constexpr u1 kEncodedAnnotation     = 0x1d;
constexpr u1 kEncodedNull           = 0x1e;
constexpr u1 kEncodedBoolean        = 0x1f;

// encoded_value header
constexpr u1 kEncodedValueTypeMask  = 0x1f;
constexpr u1 kEncodedValueArgShift  = 5;

// access_flags
constexpr u4 kAccPublic                 = 0x0001;     // class, field, method, ic
constexpr u4 kAccPrivate                = 0x0002;     // field, method, ic
constexpr u4 kAccProtected              = 0x0004;     // field, method, ic
constexpr u4 kAccStatic                 = 0x0008;     // field, method, ic
constexpr u4 kAccFinal                  = 0x0010;     // class, field, method, ic
constexpr u4 kAccSynchronized           = 0x0020;     // method (only allowed on natives)
constexpr u4 kAccSuper                  = 0x0020;     // class (not used in dex)
constexpr u4 kAccVolatile               = 0x0040;     // field
constexpr u4 kAccBridge                 = 0x0040;     // method
constexpr u4 kAccTransient              = 0x0080;     // field
constexpr u4 kAccVarargs                = 0x0080;     // method
constexpr u4 kAccNative                 = 0x0100;     // method
constexpr u4 kAccInterface              = 0x0200;     // class, ic
constexpr u4 kAccAbstract               = 0x0400;     // class, method, ic
constexpr u4 kAccStrict                 = 0x0800;     // method
constexpr u4 kAccSynthetic              = 0x1000;     // class, field, method, ic
constexpr u4 kAccAnnotation             = 0x2000;     // class, ic
constexpr u4 kAccEnum                   = 0x4000;     // class, field, ic
constexpr u4 kAccConstructor            = 0x00010000; // method (dex only) <(cl)init>
constexpr u4 kAccDeclaredSynchronized   = 0x00020000; // method (dex only)

// map_item type codes
constexpr u2 kHeaderItem                = 0x0000;
constexpr u2 kStringIdItem              = 0x0001;
constexpr u2 kTypeIdItem                = 0x0002;
constexpr u2 kProtoIdItem               = 0x0003;
constexpr u2 kFieldIdItem               = 0x0004;
constexpr u2 kMethodIdItem              = 0x0005;
constexpr u2 kClassDefItem              = 0x0006;
constexpr u2 kMethodHandleItem          = 0x0008;
constexpr u2 kMapList                   = 0x1000;
constexpr u2 kTypeList                  = 0x1001;
constexpr u2 kAnnotationSetRefList      = 0x1002;
constexpr u2 kAnnotationSetItem         = 0x1003;
constexpr u2 kClassDataItem             = 0x2000;
constexpr u2 kCodeItem                  = 0x2001;
constexpr u2 kStringDataItem            = 0x2002;
constexpr u2 kDebugInfoItem             = 0x2003;
constexpr u2 kAnnotationItem            = 0x2004;
constexpr u2 kEncodedArrayItem          = 0x2005;
constexpr u2 kAnnotationsDirectoryItem  = 0x2006;

// debug info opcodes
constexpr u1 DBG_END_SEQUENCE           = 0x00;
constexpr u1 DBG_ADVANCE_PC             = 0x01;
constexpr u1 DBG_ADVANCE_LINE           = 0x02;
constexpr u1 DBG_START_LOCAL            = 0x03;
constexpr u1 DBG_START_LOCAL_EXTENDED   = 0x04;
constexpr u1 DBG_END_LOCAL              = 0x05;
constexpr u1 DBG_RESTART_LOCAL          = 0x06;
constexpr u1 DBG_SET_PROLOGUE_END       = 0x07;
constexpr u1 DBG_SET_EPILOGUE_BEGIN     = 0x08;
constexpr u1 DBG_SET_FILE               = 0x09;
constexpr u1 DBG_FIRST_SPECIAL          = 0x0a;


// method handle type
constexpr u1 METHOD_HANDLE_TYPE_STATIC_PUT = 0x00;
constexpr u1 METHOD_HANDLE_TYPE_STATIC_GET = 0x01;
constexpr u1 METHOD_HANDLE_TYPE_INSTANCE_PUT = 0x02;
constexpr u1 METHOD_HANDLE_TYPE_INSTANCE_GET = 0x03;
constexpr u1 METHOD_HANDLE_TYPE_INVOKE_STATIC = 0x04;
constexpr u1 METHOD_HANDLE_TYPE_INVOKE_INSTANCE = 0x05;
constexpr u1 METHOD_HANDLE_TYPE_INVOKE_CONSTRUCTOR = 0x06;
constexpr u1 METHOD_HANDLE_TYPE_INVOKE_DIRECT = 0x07;
constexpr u1 METHOD_HANDLE_TYPE_INVOKE_INTERFACE = 0x08;

// special debug info values
constexpr int DBG_LINE_BASE = -4;
constexpr int DBG_LINE_RANGE = 15;

// "header_item"
struct Header {
  static constexpr size_t kV40Size = 0x70;  // Same as all previous dex versions.
  static constexpr size_t kV41Size = 0x78;  // Added container_{size,off} fields.
                                            // See http://go/dex-container-format
  static constexpr size_t kMaxSize = kV41Size;

  static constexpr u4 kV41 = 41;
  static constexpr u4 kMinVersion = 35;  // Minimum supported dex version.
  static constexpr u4 kMaxVersion = 41;  // Maximum supported dex version.

  // Parse magic number and extract the version integer. E.g.: `dex\n123\0` returns `123`.
  // Returns 0 upon failure.
  static u4 GetVersion(const void* magic);

  u4 GetVersion() const {
    return GetVersion(magic);
  }

  u4 ContainerSize() const {
    return header_size >= kV41Size ? container_size : file_size;
  }

  u4 ContainerOff() const {
    return header_size >= kV41Size ? container_off : 0;
  }

  void SetContainer(u4 off, u4 size) {
    container_off = off;
    container_size = size;
  }

  u1 magic[8];
  u4 checksum;
  u1 signature[kSHA1DigestLen];
  u4 file_size;
  u4 header_size;
  u4 endian_tag;
  u4 link_size;
  u4 link_off;
  u4 map_off;
  u4 string_ids_size;
  u4 string_ids_off;
  u4 type_ids_size;
  u4 type_ids_off;
  u4 proto_ids_size;
  u4 proto_ids_off;
  u4 field_ids_size;
  u4 field_ids_off;
  u4 method_ids_size;
  u4 method_ids_off;
  u4 class_defs_size;
  u4 class_defs_off;
  u4 data_size;
  u4 data_off;

 private:
  u4 container_size;
  u4 container_off;
};

// "map_item"
struct MapItem {
  u2 type;
  u2 unused;
  u4 size;
  u4 offset;
};

// "map_list"
struct MapList {
  u4 size;
  MapItem list[];
};

// "string_id_item"
struct StringId {
  u4 string_data_off;
};

// "type_id_item"
struct TypeId {
  u4 descriptor_idx;
};

// "field_id_item"
struct FieldId {
  u2 class_idx;
  u2 type_idx;
  u4 name_idx;
};

// "method_id_item"
struct MethodId {
  u2 class_idx;
  u2 proto_idx;
  u4 name_idx;
};

// "proto_id_item"
struct ProtoId {
  u4 shorty_idx;
  u4 return_type_idx;
  u4 parameters_off;
};

// "class_def_item"
struct ClassDef {
  u4 class_idx;
  u4 access_flags;
  u4 superclass_idx;
  u4 interfaces_off;
  u4 source_file_idx;
  u4 annotations_off;
  u4 class_data_off;
  u4 static_values_off;
};

// "method_handle_item"
struct MethodHandle {
  u2 method_handle_type;
  u2 unused;
  u2 field_or_method_id;
  u2 unused2;
};

// "type_item"
struct TypeItem {
  u2 type_idx;
};

// "type_list"
struct TypeList {
  u4 size;
  TypeItem list[];
};

// "code_item"
struct Code {
  u2 registers_size;
  u2 ins_size;
  u2 outs_size;
  u2 tries_size;
  u4 debug_info_off;
  u4 insns_size;
  u2 insns[];
  // followed by optional u2 padding
  // followed by try_item[tries_size]
  // followed by uleb128 handlersSize
  // followed by catch_handler_item[handlersSize]
};

// "try_item"
struct TryBlock {
  u4 start_addr;
  u2 insn_count;
  u2 handler_off;
};

// "annotations_directory_item"
struct AnnotationsDirectoryItem {
  u4 class_annotations_off;
  u4 fields_size;
  u4 methods_size;
  u4 parameters_size;
  // followed by FieldAnnotationsItem[fields_size]
  // followed by MethodAnnotationsItem[methods_size]
  // followed by ParameterAnnotationsItem[parameters_size]
};

// "field_annotations_item"
struct FieldAnnotationsItem {
  u4 field_idx;
  u4 annotations_off;
};

// "method_annotations_item"
struct MethodAnnotationsItem {
  u4 method_idx;
  u4 annotations_off;
};

// "parameter_annotations_item"
struct ParameterAnnotationsItem {
  u4 method_idx;
  u4 annotations_off;
};

// "annotation_set_ref_item"
struct AnnotationSetRefItem {
  u4 annotations_off;
};

// "annotation_set_ref_list"
struct AnnotationSetRefList {
  u4 size;
  AnnotationSetRefItem list[];
};

// "annotation_set_item"
struct AnnotationSetItem {
  u4 size;
  u4 entries[];
};

// "annotation_item"
struct AnnotationItem {
  u1 visibility;
  u1 annotation[];
};

// Compute DEX checksum
u4 ComputeChecksum(const Header* header);

// Converts a type descriptor to a human-readable declaration
std::string DescriptorToDecl(const char* descriptor);

// Converts a type descriptor to the equivalent shorty type descriptor
char DescriptorToShorty(const char* descriptor);

}  // namespace dex

```

`paccer/jni/slicer/export/slicer/dex_instruction_list.h`:

```h
/*
 * Copyright (C) 2019 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#ifndef ART_LIBDEXFILE_DEX_DEX_INSTRUCTION_LIST_H_
#define ART_LIBDEXFILE_DEX_DEX_INSTRUCTION_LIST_H_

/**
 * Cloned from //art/libdexfile/dex/dex_instruction_list.h.
 */

// V(opcode, instruction_code, name, format, index, flags, extended_flags, verifier_flags);
#define DEX_INSTRUCTION_LIST(V) \
  V(0x00, NOP, "nop", k10x, kIndexNone, kContinue, 0, kVerifyNothing) \
  V(0x01, MOVE, "move", k12x, kIndexNone, kContinue, 0, kVerifyRegA | kVerifyRegB) \
  V(0x02, MOVE_FROM16, "move/from16", k22x, kIndexNone, kContinue, 0, kVerifyRegA | kVerifyRegB) \
  V(0x03, MOVE_16, "move/16", k32x, kIndexNone, kContinue, 0, kVerifyRegA | kVerifyRegB) \
  V(0x04, MOVE_WIDE, "move-wide", k12x, kIndexNone, kContinue, 0, kVerifyRegAWide | kVerifyRegBWide) \
  V(0x05, MOVE_WIDE_FROM16, "move-wide/from16", k22x, kIndexNone, kContinue, 0, kVerifyRegAWide | kVerifyRegBWide) \
  V(0x06, MOVE_WIDE_16, "move-wide/16", k32x, kIndexNone, kContinue, 0, kVerifyRegAWide | kVerifyRegBWide) \
  V(0x07, MOVE_OBJECT, "move-object", k12x, kIndexNone, kContinue, 0, kVerifyRegA | kVerifyRegB) \
  V(0x08, MOVE_OBJECT_FROM16, "move-object/from16", k22x, kIndexNone, kContinue, 0, kVerifyRegA | kVerifyRegB) \
  V(0x09, MOVE_OBJECT_16, "move-object/16", k32x, kIndexNone, kContinue, 0, kVerifyRegA | kVerifyRegB) \
  V(0x0A, MOVE_RESULT, "move-result", k11x, kIndexNone, kContinue, 0, kVerifyRegA) \
  V(0x0B, MOVE_RESULT_WIDE, "move-result-wide", k11x, kIndexNone, kContinue, 0, kVerifyRegAWide) \
  V(0x0C, MOVE_RESULT_OBJECT, "move-result-object", k11x, kIndexNone, kContinue, 0, kVerifyRegA) \
  V(0x0D, MOVE_EXCEPTION, "move-exception", k11x, kIndexNone, kContinue, 0, kVerifyRegA) \
  V(0x0E, RETURN_VOID, "return-void", k10x, kIndexNone, kReturn, 0, kVerifyNothing) \
  V(0x0F, RETURN, "return", k11x, kIndexNone, kReturn, 0, kVerifyRegA) \
  V(0x10, RETURN_WIDE, "return-wide", k11x, kIndexNone, kReturn, 0, kVerifyRegAWide) \
  V(0x11, RETURN_OBJECT, "return-object", k11x, kIndexNone, kReturn, 0, kVerifyRegA) \
  V(0x12, CONST_4, "const/4", k11n, kIndexNone, kContinue, kRegBFieldOrConstant, kVerifyRegA) \
  V(0x13, CONST_16, "const/16", k21s, kIndexNone, kContinue, kRegBFieldOrConstant, kVerifyRegA) \
  V(0x14, CONST, "const", k31i, kIndexNone, kContinue, kRegBFieldOrConstant, kVerifyRegA) \
  V(0x15, CONST_HIGH16, "const/high16", k21h, kIndexNone, kContinue, kRegBFieldOrConstant, kVerifyRegA) \
  V(0x16, CONST_WIDE_16, "const-wide/16", k21s, kIndexNone, kContinue, kRegBFieldOrConstant, kVerifyRegAWide) \
  V(0x17, CONST_WIDE_32, "const-wide/32", k31i, kIndexNone, kContinue, kRegBFieldOrConstant, kVerifyRegAWide) \
  V(0x18, CONST_WIDE, "const-wide", k51l, kIndexNone, kContinue, kRegBFieldOrConstant, kVerifyRegAWide) \
  V(0x19, CONST_WIDE_HIGH16, "const-wide/high16", k21h, kIndexNone, kContinue, kRegBFieldOrConstant, kVerifyRegAWide) \
  V(0x1A, CONST_STRING, "const-string", k21c, kIndexStringRef, kContinue | kThrow, 0, kVerifyRegA | kVerifyRegBString) \
  V(0x1B, CONST_STRING_JUMBO, "const-string/jumbo", k31c, kIndexStringRef, kContinue | kThrow, 0, kVerifyRegA | kVerifyRegBString) \
  V(0x1C, CONST_CLASS, "const-class", k21c, kIndexTypeRef, kContinue | kThrow, 0, kVerifyRegA | kVerifyRegBType) \
  V(0x1D, MONITOR_ENTER, "monitor-enter", k11x, kIndexNone, kContinue | kThrow, kClobber, kVerifyRegA) \
  V(0x1E, MONITOR_EXIT, "monitor-exit", k11x, kIndexNone, kContinue | kThrow, kClobber, kVerifyRegA) \
  V(0x1F, CHECK_CAST, "check-cast", k21c, kIndexTypeRef, kContinue | kThrow, 0, kVerifyRegA | kVerifyRegBType) \
  V(0x20, INSTANCE_OF, "instance-of", k22c, kIndexTypeRef, kContinue | kThrow, 0, kVerifyRegA | kVerifyRegB | kVerifyRegCType) \
  V(0x21, ARRAY_LENGTH, "array-length", k12x, kIndexNone, kContinue | kThrow, 0, kVerifyRegA | kVerifyRegB) \
  V(0x22, NEW_INSTANCE, "new-instance", k21c, kIndexTypeRef, kContinue | kThrow, kClobber, kVerifyRegA | kVerifyRegBNewInstance) \
  V(0x23, NEW_ARRAY, "new-array", k22c, kIndexTypeRef, kContinue | kThrow, kClobber, kVerifyRegA | kVerifyRegB | kVerifyRegCNewArray) \
  V(0x24, FILLED_NEW_ARRAY, "filled-new-array", k35c, kIndexTypeRef, kContinue | kThrow, kClobber, kVerifyRegBType | kVerifyVarArg) \
  V(0x25, FILLED_NEW_ARRAY_RANGE, "filled-new-array/range", k3rc, kIndexTypeRef, kContinue | kThrow, kClobber, kVerifyRegBType | kVerifyVarArgRange) \
  V(0x26, FILL_ARRAY_DATA, "fill-array-data", k31t, kIndexNone, kContinue | kThrow, kClobber, kVerifyRegA | kVerifyArrayData) \
  V(0x27, THROW, "throw", k11x, kIndexNone, kThrow, 0, kVerifyRegA) \
  V(0x28, GOTO, "goto", k10t, kIndexNone, kBranch | kUnconditional, 0, kVerifyBranchTarget) \
  V(0x29, GOTO_16, "goto/16", k20t, kIndexNone, kBranch | kUnconditional, 0, kVerifyBranchTarget) \
  V(0x2A, GOTO_32, "goto/32", k30t, kIndexNone, kBranch | kUnconditional, 0, kVerifyBranchTarget) \
  V(0x2B, PACKED_SWITCH, "packed-switch", k31t, kIndexNone, kContinue | kSwitch, 0, kVerifyRegA | kVerifySwitchTargets) \
  V(0x2C, SPARSE_SWITCH, "sparse-switch", k31t, kIndexNone, kContinue | kSwitch, 0, kVerifyRegA | kVerifySwitchTargets) \
  V(0x2D, CMPL_FLOAT, "cmpl-float", k23x, kIndexNone, kContinue, 0, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x2E, CMPG_FLOAT, "cmpg-float", k23x, kIndexNone, kContinue, 0, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x2F, CMPL_DOUBLE, "cmpl-double", k23x, kIndexNone, kContinue, 0, kVerifyRegA | kVerifyRegBWide | kVerifyRegCWide) \
  V(0x30, CMPG_DOUBLE, "cmpg-double", k23x, kIndexNone, kContinue, 0, kVerifyRegA | kVerifyRegBWide | kVerifyRegCWide) \
  V(0x31, CMP_LONG, "cmp-long", k23x, kIndexNone, kContinue, 0, kVerifyRegA | kVerifyRegBWide | kVerifyRegCWide) \
  V(0x32, IF_EQ, "if-eq", k22t, kIndexNone, kContinue | kBranch, 0, kVerifyRegA | kVerifyRegB | kVerifyBranchTarget) \
  V(0x33, IF_NE, "if-ne", k22t, kIndexNone, kContinue | kBranch, 0, kVerifyRegA | kVerifyRegB | kVerifyBranchTarget) \
  V(0x34, IF_LT, "if-lt", k22t, kIndexNone, kContinue | kBranch, 0, kVerifyRegA | kVerifyRegB | kVerifyBranchTarget) \
  V(0x35, IF_GE, "if-ge", k22t, kIndexNone, kContinue | kBranch, 0, kVerifyRegA | kVerifyRegB | kVerifyBranchTarget) \
  V(0x36, IF_GT, "if-gt", k22t, kIndexNone, kContinue | kBranch, 0, kVerifyRegA | kVerifyRegB | kVerifyBranchTarget) \
  V(0x37, IF_LE, "if-le", k22t, kIndexNone, kContinue | kBranch, 0, kVerifyRegA | kVerifyRegB | kVerifyBranchTarget) \
  V(0x38, IF_EQZ, "if-eqz", k21t, kIndexNone, kContinue | kBranch, 0, kVerifyRegA | kVerifyBranchTarget) \
  V(0x39, IF_NEZ, "if-nez", k21t, kIndexNone, kContinue | kBranch, 0, kVerifyRegA | kVerifyBranchTarget) \
  V(0x3A, IF_LTZ, "if-ltz", k21t, kIndexNone, kContinue | kBranch, 0, kVerifyRegA | kVerifyBranchTarget) \
  V(0x3B, IF_GEZ, "if-gez", k21t, kIndexNone, kContinue | kBranch, 0, kVerifyRegA | kVerifyBranchTarget) \
  V(0x3C, IF_GTZ, "if-gtz", k21t, kIndexNone, kContinue | kBranch, 0, kVerifyRegA | kVerifyBranchTarget) \
  V(0x3D, IF_LEZ, "if-lez", k21t, kIndexNone, kContinue | kBranch, 0, kVerifyRegA | kVerifyBranchTarget) \
  V(0x3E, UNUSED_3E, "unused-3e", k10x, kIndexUnknown, 0, 0, kVerifyError) \
  V(0x3F, UNUSED_3F, "unused-3f", k10x, kIndexUnknown, 0, 0, kVerifyError) \
  V(0x40, UNUSED_40, "unused-40", k10x, kIndexUnknown, 0, 0, kVerifyError) \
  V(0x41, UNUSED_41, "unused-41", k10x, kIndexUnknown, 0, 0, kVerifyError) \
  V(0x42, UNUSED_42, "unused-42", k10x, kIndexUnknown, 0, 0, kVerifyError) \
  V(0x43, UNUSED_43, "unused-43", k10x, kIndexUnknown, 0, 0, kVerifyError) \
  V(0x44, AGET, "aget", k23x, kIndexNone, kContinue | kThrow, kLoad, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x45, AGET_WIDE, "aget-wide", k23x, kIndexNone, kContinue | kThrow, kLoad, kVerifyRegAWide | kVerifyRegB | kVerifyRegC) \
  V(0x46, AGET_OBJECT, "aget-object", k23x, kIndexNone, kContinue | kThrow, kLoad, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x47, AGET_BOOLEAN, "aget-boolean", k23x, kIndexNone, kContinue | kThrow, kLoad, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x48, AGET_BYTE, "aget-byte", k23x, kIndexNone, kContinue | kThrow, kLoad, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x49, AGET_CHAR, "aget-char", k23x, kIndexNone, kContinue | kThrow, kLoad, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x4A, AGET_SHORT, "aget-short", k23x, kIndexNone, kContinue | kThrow, kLoad, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x4B, APUT, "aput", k23x, kIndexNone, kContinue | kThrow, kStore, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x4C, APUT_WIDE, "aput-wide", k23x, kIndexNone, kContinue | kThrow, kStore, kVerifyRegAWide | kVerifyRegB | kVerifyRegC) \
  V(0x4D, APUT_OBJECT, "aput-object", k23x, kIndexNone, kContinue | kThrow, kStore, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x4E, APUT_BOOLEAN, "aput-boolean", k23x, kIndexNone, kContinue | kThrow, kStore, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x4F, APUT_BYTE, "aput-byte", k23x, kIndexNone, kContinue | kThrow, kStore, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x50, APUT_CHAR, "aput-char", k23x, kIndexNone, kContinue | kThrow, kStore, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x51, APUT_SHORT, "aput-short", k23x, kIndexNone, kContinue | kThrow, kStore, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x52, IGET, "iget", k22c, kIndexFieldRef, kContinue | kThrow, kLoad | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB | kVerifyRegCField) \
  V(0x53, IGET_WIDE, "iget-wide", k22c, kIndexFieldRef, kContinue | kThrow, kLoad | kRegCFieldOrConstant, kVerifyRegAWide | kVerifyRegB | kVerifyRegCField) \
  V(0x54, IGET_OBJECT, "iget-object", k22c, kIndexFieldRef, kContinue | kThrow, kLoad | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB | kVerifyRegCField) \
  V(0x55, IGET_BOOLEAN, "iget-boolean", k22c, kIndexFieldRef, kContinue | kThrow, kLoad | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB | kVerifyRegCField) \
  V(0x56, IGET_BYTE, "iget-byte", k22c, kIndexFieldRef, kContinue | kThrow, kLoad | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB | kVerifyRegCField) \
  V(0x57, IGET_CHAR, "iget-char", k22c, kIndexFieldRef, kContinue | kThrow, kLoad | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB | kVerifyRegCField) \
  V(0x58, IGET_SHORT, "iget-short", k22c, kIndexFieldRef, kContinue | kThrow, kLoad | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB | kVerifyRegCField) \
  V(0x59, IPUT, "iput", k22c, kIndexFieldRef, kContinue | kThrow, kStore | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB | kVerifyRegCField) \
  V(0x5A, IPUT_WIDE, "iput-wide", k22c, kIndexFieldRef, kContinue | kThrow, kStore | kRegCFieldOrConstant, kVerifyRegAWide | kVerifyRegB | kVerifyRegCField) \
  V(0x5B, IPUT_OBJECT, "iput-object", k22c, kIndexFieldRef, kContinue | kThrow, kStore | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB | kVerifyRegCField) \
  V(0x5C, IPUT_BOOLEAN, "iput-boolean", k22c, kIndexFieldRef, kContinue | kThrow, kStore | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB | kVerifyRegCField) \
  V(0x5D, IPUT_BYTE, "iput-byte", k22c, kIndexFieldRef, kContinue | kThrow, kStore | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB | kVerifyRegCField) \
  V(0x5E, IPUT_CHAR, "iput-char", k22c, kIndexFieldRef, kContinue | kThrow, kStore | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB | kVerifyRegCField) \
  V(0x5F, IPUT_SHORT, "iput-short", k22c, kIndexFieldRef, kContinue | kThrow, kStore | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB | kVerifyRegCField) \
  V(0x60, SGET, "sget", k21c, kIndexFieldRef, kContinue | kThrow, kLoad | kRegBFieldOrConstant, kVerifyRegA | kVerifyRegBField) \
  V(0x61, SGET_WIDE, "sget-wide", k21c, kIndexFieldRef, kContinue | kThrow, kLoad | kRegBFieldOrConstant, kVerifyRegAWide | kVerifyRegBField) \
  V(0x62, SGET_OBJECT, "sget-object", k21c, kIndexFieldRef, kContinue | kThrow, kLoad | kRegBFieldOrConstant, kVerifyRegA | kVerifyRegBField) \
  V(0x63, SGET_BOOLEAN, "sget-boolean", k21c, kIndexFieldRef, kContinue | kThrow, kLoad | kRegBFieldOrConstant, kVerifyRegA | kVerifyRegBField) \
  V(0x64, SGET_BYTE, "sget-byte", k21c, kIndexFieldRef, kContinue | kThrow, kLoad | kRegBFieldOrConstant, kVerifyRegA | kVerifyRegBField) \
  V(0x65, SGET_CHAR, "sget-char", k21c, kIndexFieldRef, kContinue | kThrow, kLoad | kRegBFieldOrConstant, kVerifyRegA | kVerifyRegBField) \
  V(0x66, SGET_SHORT, "sget-short", k21c, kIndexFieldRef, kContinue | kThrow, kLoad | kRegBFieldOrConstant, kVerifyRegA | kVerifyRegBField) \
  V(0x67, SPUT, "sput", k21c, kIndexFieldRef, kContinue | kThrow, kStore | kRegBFieldOrConstant, kVerifyRegA | kVerifyRegBField) \
  V(0x68, SPUT_WIDE, "sput-wide", k21c, kIndexFieldRef, kContinue | kThrow, kStore | kRegBFieldOrConstant, kVerifyRegAWide | kVerifyRegBField) \
  V(0x69, SPUT_OBJECT, "sput-object", k21c, kIndexFieldRef, kContinue | kThrow, kStore | kRegBFieldOrConstant, kVerifyRegA | kVerifyRegBField) \
  V(0x6A, SPUT_BOOLEAN, "sput-boolean", k21c, kIndexFieldRef, kContinue | kThrow, kStore | kRegBFieldOrConstant, kVerifyRegA | kVerifyRegBField) \
  V(0x6B, SPUT_BYTE, "sput-byte", k21c, kIndexFieldRef, kContinue | kThrow, kStore | kRegBFieldOrConstant, kVerifyRegA | kVerifyRegBField) \
  V(0x6C, SPUT_CHAR, "sput-char", k21c, kIndexFieldRef, kContinue | kThrow, kStore | kRegBFieldOrConstant, kVerifyRegA | kVerifyRegBField) \
  V(0x6D, SPUT_SHORT, "sput-short", k21c, kIndexFieldRef, kContinue | kThrow, kStore | kRegBFieldOrConstant, kVerifyRegA | kVerifyRegBField) \
  V(0x6E, INVOKE_VIRTUAL, "invoke-virtual", k35c, kIndexMethodRef, kContinue | kThrow | kInvoke, 0, kVerifyRegBMethod | kVerifyVarArgNonZero) \
  V(0x6F, INVOKE_SUPER, "invoke-super", k35c, kIndexMethodRef, kContinue | kThrow | kInvoke, 0, kVerifyRegBMethod | kVerifyVarArgNonZero) \
  V(0x70, INVOKE_DIRECT, "invoke-direct", k35c, kIndexMethodRef, kContinue | kThrow | kInvoke, 0, kVerifyRegBMethod | kVerifyVarArgNonZero) \
  V(0x71, INVOKE_STATIC, "invoke-static", k35c, kIndexMethodRef, kContinue | kThrow | kInvoke, 0, kVerifyRegBMethod | kVerifyVarArg) \
  V(0x72, INVOKE_INTERFACE, "invoke-interface", k35c, kIndexMethodRef, kContinue | kThrow | kInvoke, 0, kVerifyRegBMethod | kVerifyVarArgNonZero) \
  V(0x73, RETURN_VOID_NO_BARRIER, "return-void-no-barrier", k10x, kIndexNone, kReturn, 0, kVerifyNothing) \
  V(0x74, INVOKE_VIRTUAL_RANGE, "invoke-virtual/range", k3rc, kIndexMethodRef, kContinue | kThrow | kInvoke, 0, kVerifyRegBMethod | kVerifyVarArgRangeNonZero) \
  V(0x75, INVOKE_SUPER_RANGE, "invoke-super/range", k3rc, kIndexMethodRef, kContinue | kThrow | kInvoke, 0, kVerifyRegBMethod | kVerifyVarArgRangeNonZero) \
  V(0x76, INVOKE_DIRECT_RANGE, "invoke-direct/range", k3rc, kIndexMethodRef, kContinue | kThrow | kInvoke, 0, kVerifyRegBMethod | kVerifyVarArgRangeNonZero) \
  V(0x77, INVOKE_STATIC_RANGE, "invoke-static/range", k3rc, kIndexMethodRef, kContinue | kThrow | kInvoke, 0, kVerifyRegBMethod | kVerifyVarArgRange) \
  V(0x78, INVOKE_INTERFACE_RANGE, "invoke-interface/range", k3rc, kIndexMethodRef, kContinue | kThrow | kInvoke, 0, kVerifyRegBMethod | kVerifyVarArgRangeNonZero) \
  V(0x79, UNUSED_79, "unused-79", k10x, kIndexUnknown, 0, 0, kVerifyError) \
  V(0x7A, UNUSED_7A, "unused-7a", k10x, kIndexUnknown, 0, 0, kVerifyError) \
  V(0x7B, NEG_INT, "neg-int", k12x, kIndexNone, kContinue, 0, kVerifyRegA | kVerifyRegB) \
  V(0x7C, NOT_INT, "not-int", k12x, kIndexNone, kContinue, 0, kVerifyRegA | kVerifyRegB) \
  V(0x7D, NEG_LONG, "neg-long", k12x, kIndexNone, kContinue, 0, kVerifyRegAWide | kVerifyRegBWide) \
  V(0x7E, NOT_LONG, "not-long", k12x, kIndexNone, kContinue, 0, kVerifyRegAWide | kVerifyRegBWide) \
  V(0x7F, NEG_FLOAT, "neg-float", k12x, kIndexNone, kContinue, 0, kVerifyRegA | kVerifyRegB) \
  V(0x80, NEG_DOUBLE, "neg-double", k12x, kIndexNone, kContinue, 0, kVerifyRegAWide | kVerifyRegBWide) \
  V(0x81, INT_TO_LONG, "int-to-long", k12x, kIndexNone, kContinue, kCast, kVerifyRegAWide | kVerifyRegB) \
  V(0x82, INT_TO_FLOAT, "int-to-float", k12x, kIndexNone, kContinue, kCast, kVerifyRegA | kVerifyRegB) \
  V(0x83, INT_TO_DOUBLE, "int-to-double", k12x, kIndexNone, kContinue, kCast, kVerifyRegAWide | kVerifyRegB) \
  V(0x84, LONG_TO_INT, "long-to-int", k12x, kIndexNone, kContinue, kCast, kVerifyRegA | kVerifyRegBWide) \
  V(0x85, LONG_TO_FLOAT, "long-to-float", k12x, kIndexNone, kContinue, kCast, kVerifyRegA | kVerifyRegBWide) \
  V(0x86, LONG_TO_DOUBLE, "long-to-double", k12x, kIndexNone, kContinue, kCast, kVerifyRegAWide | kVerifyRegBWide) \
  V(0x87, FLOAT_TO_INT, "float-to-int", k12x, kIndexNone, kContinue, kCast, kVerifyRegA | kVerifyRegB) \
  V(0x88, FLOAT_TO_LONG, "float-to-long", k12x, kIndexNone, kContinue, kCast, kVerifyRegAWide | kVerifyRegB) \
  V(0x89, FLOAT_TO_DOUBLE, "float-to-double", k12x, kIndexNone, kContinue, kCast, kVerifyRegAWide | kVerifyRegB) \
  V(0x8A, DOUBLE_TO_INT, "double-to-int", k12x, kIndexNone, kContinue, kCast, kVerifyRegA | kVerifyRegBWide) \
  V(0x8B, DOUBLE_TO_LONG, "double-to-long", k12x, kIndexNone, kContinue, kCast, kVerifyRegAWide | kVerifyRegBWide) \
  V(0x8C, DOUBLE_TO_FLOAT, "double-to-float", k12x, kIndexNone, kContinue, kCast, kVerifyRegA | kVerifyRegBWide) \
  V(0x8D, INT_TO_BYTE, "int-to-byte", k12x, kIndexNone, kContinue, kCast, kVerifyRegA | kVerifyRegB) \
  V(0x8E, INT_TO_CHAR, "int-to-char", k12x, kIndexNone, kContinue, kCast, kVerifyRegA | kVerifyRegB) \
  V(0x8F, INT_TO_SHORT, "int-to-short", k12x, kIndexNone, kContinue, kCast, kVerifyRegA | kVerifyRegB) \
  V(0x90, ADD_INT, "add-int", k23x, kIndexNone, kContinue, kAdd, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x91, SUB_INT, "sub-int", k23x, kIndexNone, kContinue, kSubtract, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x92, MUL_INT, "mul-int", k23x, kIndexNone, kContinue, kMultiply, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x93, DIV_INT, "div-int", k23x, kIndexNone, kContinue | kThrow, kDivide, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x94, REM_INT, "rem-int", k23x, kIndexNone, kContinue | kThrow, kRemainder, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x95, AND_INT, "and-int", k23x, kIndexNone, kContinue, kAnd, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x96, OR_INT, "or-int", k23x, kIndexNone, kContinue, kOr, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x97, XOR_INT, "xor-int", k23x, kIndexNone, kContinue, kXor, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x98, SHL_INT, "shl-int", k23x, kIndexNone, kContinue, kShl, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x99, SHR_INT, "shr-int", k23x, kIndexNone, kContinue, kShr, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x9A, USHR_INT, "ushr-int", k23x, kIndexNone, kContinue, kUshr, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0x9B, ADD_LONG, "add-long", k23x, kIndexNone, kContinue, kAdd, kVerifyRegAWide | kVerifyRegBWide | kVerifyRegCWide) \
  V(0x9C, SUB_LONG, "sub-long", k23x, kIndexNone, kContinue, kSubtract, kVerifyRegAWide | kVerifyRegBWide | kVerifyRegCWide) \
  V(0x9D, MUL_LONG, "mul-long", k23x, kIndexNone, kContinue, kMultiply, kVerifyRegAWide | kVerifyRegBWide | kVerifyRegCWide) \
  V(0x9E, DIV_LONG, "div-long", k23x, kIndexNone, kContinue | kThrow, kDivide, kVerifyRegAWide | kVerifyRegBWide | kVerifyRegCWide) \
  V(0x9F, REM_LONG, "rem-long", k23x, kIndexNone, kContinue | kThrow, kRemainder, kVerifyRegAWide | kVerifyRegBWide | kVerifyRegCWide) \
  V(0xA0, AND_LONG, "and-long", k23x, kIndexNone, kContinue, kAnd, kVerifyRegAWide | kVerifyRegBWide | kVerifyRegCWide) \
  V(0xA1, OR_LONG, "or-long", k23x, kIndexNone, kContinue, kOr, kVerifyRegAWide | kVerifyRegBWide | kVerifyRegCWide) \
  V(0xA2, XOR_LONG, "xor-long", k23x, kIndexNone, kContinue, kXor, kVerifyRegAWide | kVerifyRegBWide | kVerifyRegCWide) \
  V(0xA3, SHL_LONG, "shl-long", k23x, kIndexNone, kContinue, kShl, kVerifyRegAWide | kVerifyRegBWide | kVerifyRegC) \
  V(0xA4, SHR_LONG, "shr-long", k23x, kIndexNone, kContinue, kShr, kVerifyRegAWide | kVerifyRegBWide | kVerifyRegC) \
  V(0xA5, USHR_LONG, "ushr-long", k23x, kIndexNone, kContinue, kUshr, kVerifyRegAWide | kVerifyRegBWide | kVerifyRegC) \
  V(0xA6, ADD_FLOAT, "add-float", k23x, kIndexNone, kContinue, kAdd, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0xA7, SUB_FLOAT, "sub-float", k23x, kIndexNone, kContinue, kSubtract, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0xA8, MUL_FLOAT, "mul-float", k23x, kIndexNone, kContinue, kMultiply, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0xA9, DIV_FLOAT, "div-float", k23x, kIndexNone, kContinue, kDivide, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0xAA, REM_FLOAT, "rem-float", k23x, kIndexNone, kContinue, kRemainder, kVerifyRegA | kVerifyRegB | kVerifyRegC) \
  V(0xAB, ADD_DOUBLE, "add-double", k23x, kIndexNone, kContinue, kAdd, kVerifyRegAWide | kVerifyRegBWide | kVerifyRegCWide) \
  V(0xAC, SUB_DOUBLE, "sub-double", k23x, kIndexNone, kContinue, kSubtract, kVerifyRegAWide | kVerifyRegBWide | kVerifyRegCWide) \
  V(0xAD, MUL_DOUBLE, "mul-double", k23x, kIndexNone, kContinue, kMultiply, kVerifyRegAWide | kVerifyRegBWide | kVerifyRegCWide) \
  V(0xAE, DIV_DOUBLE, "div-double", k23x, kIndexNone, kContinue, kDivide, kVerifyRegAWide | kVerifyRegBWide | kVerifyRegCWide) \
  V(0xAF, REM_DOUBLE, "rem-double", k23x, kIndexNone, kContinue, kRemainder, kVerifyRegAWide | kVerifyRegBWide | kVerifyRegCWide) \
  V(0xB0, ADD_INT_2ADDR, "add-int/2addr", k12x, kIndexNone, kContinue, kAdd, kVerifyRegA | kVerifyRegB) \
  V(0xB1, SUB_INT_2ADDR, "sub-int/2addr", k12x, kIndexNone, kContinue, kSubtract, kVerifyRegA | kVerifyRegB) \
  V(0xB2, MUL_INT_2ADDR, "mul-int/2addr", k12x, kIndexNone, kContinue, kMultiply, kVerifyRegA | kVerifyRegB) \
  V(0xB3, DIV_INT_2ADDR, "div-int/2addr", k12x, kIndexNone, kContinue | kThrow, kDivide, kVerifyRegA | kVerifyRegB) \
  V(0xB4, REM_INT_2ADDR, "rem-int/2addr", k12x, kIndexNone, kContinue | kThrow, kRemainder, kVerifyRegA | kVerifyRegB) \
  V(0xB5, AND_INT_2ADDR, "and-int/2addr", k12x, kIndexNone, kContinue, kAnd, kVerifyRegA | kVerifyRegB) \
  V(0xB6, OR_INT_2ADDR, "or-int/2addr", k12x, kIndexNone, kContinue, kOr, kVerifyRegA | kVerifyRegB) \
  V(0xB7, XOR_INT_2ADDR, "xor-int/2addr", k12x, kIndexNone, kContinue, kXor, kVerifyRegA | kVerifyRegB) \
  V(0xB8, SHL_INT_2ADDR, "shl-int/2addr", k12x, kIndexNone, kContinue, kShl, kVerifyRegA | kVerifyRegB) \
  V(0xB9, SHR_INT_2ADDR, "shr-int/2addr", k12x, kIndexNone, kContinue, kShr, kVerifyRegA | kVerifyRegB) \
  V(0xBA, USHR_INT_2ADDR, "ushr-int/2addr", k12x, kIndexNone, kContinue, kUshr, kVerifyRegA | kVerifyRegB) \
  V(0xBB, ADD_LONG_2ADDR, "add-long/2addr", k12x, kIndexNone, kContinue, kAdd, kVerifyRegAWide | kVerifyRegBWide) \
  V(0xBC, SUB_LONG_2ADDR, "sub-long/2addr", k12x, kIndexNone, kContinue, kSubtract, kVerifyRegAWide | kVerifyRegBWide) \
  V(0xBD, MUL_LONG_2ADDR, "mul-long/2addr", k12x, kIndexNone, kContinue, kMultiply, kVerifyRegAWide | kVerifyRegBWide) \
  V(0xBE, DIV_LONG_2ADDR, "div-long/2addr", k12x, kIndexNone, kContinue | kThrow, kDivide, kVerifyRegAWide | kVerifyRegBWide) \
  V(0xBF, REM_LONG_2ADDR, "rem-long/2addr", k12x, kIndexNone, kContinue | kThrow, kRemainder, kVerifyRegAWide | kVerifyRegBWide) \
  V(0xC0, AND_LONG_2ADDR, "and-long/2addr", k12x, kIndexNone, kContinue, kAnd, kVerifyRegAWide | kVerifyRegBWide) \
  V(0xC1, OR_LONG_2ADDR, "or-long/2addr", k12x, kIndexNone, kContinue, kOr, kVerifyRegAWide | kVerifyRegBWide) \
  V(0xC2, XOR_LONG_2ADDR, "xor-long/2addr", k12x, kIndexNone, kContinue, kXor, kVerifyRegAWide | kVerifyRegBWide) \
  V(0xC3, SHL_LONG_2ADDR, "shl-long/2addr", k12x, kIndexNone, kContinue, kShl, kVerifyRegAWide | kVerifyRegB) \
  V(0xC4, SHR_LONG_2ADDR, "shr-long/2addr", k12x, kIndexNone, kContinue, kShr, kVerifyRegAWide | kVerifyRegB) \
  V(0xC5, USHR_LONG_2ADDR, "ushr-long/2addr", k12x, kIndexNone, kContinue, kUshr, kVerifyRegAWide | kVerifyRegB) \
  V(0xC6, ADD_FLOAT_2ADDR, "add-float/2addr", k12x, kIndexNone, kContinue, kAdd, kVerifyRegA | kVerifyRegB) \
  V(0xC7, SUB_FLOAT_2ADDR, "sub-float/2addr", k12x, kIndexNone, kContinue, kSubtract, kVerifyRegA | kVerifyRegB) \
  V(0xC8, MUL_FLOAT_2ADDR, "mul-float/2addr", k12x, kIndexNone, kContinue, kMultiply, kVerifyRegA | kVerifyRegB) \
  V(0xC9, DIV_FLOAT_2ADDR, "div-float/2addr", k12x, kIndexNone, kContinue, kDivide, kVerifyRegA | kVerifyRegB) \
  V(0xCA, REM_FLOAT_2ADDR, "rem-float/2addr", k12x, kIndexNone, kContinue, kRemainder, kVerifyRegA | kVerifyRegB) \
  V(0xCB, ADD_DOUBLE_2ADDR, "add-double/2addr", k12x, kIndexNone, kContinue, kAdd, kVerifyRegAWide | kVerifyRegBWide) \
  V(0xCC, SUB_DOUBLE_2ADDR, "sub-double/2addr", k12x, kIndexNone, kContinue, kSubtract, kVerifyRegAWide | kVerifyRegBWide) \
  V(0xCD, MUL_DOUBLE_2ADDR, "mul-double/2addr", k12x, kIndexNone, kContinue, kMultiply, kVerifyRegAWide | kVerifyRegBWide) \
  V(0xCE, DIV_DOUBLE_2ADDR, "div-double/2addr", k12x, kIndexNone, kContinue, kDivide, kVerifyRegAWide | kVerifyRegBWide) \
  V(0xCF, REM_DOUBLE_2ADDR, "rem-double/2addr", k12x, kIndexNone, kContinue, kRemainder, kVerifyRegAWide | kVerifyRegBWide) \
  V(0xD0, ADD_INT_LIT16, "add-int/lit16", k22s, kIndexNone, kContinue, kAdd | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB) \
  V(0xD1, RSUB_INT, "rsub-int", k22s, kIndexNone, kContinue, kSubtract | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB) \
  V(0xD2, MUL_INT_LIT16, "mul-int/lit16", k22s, kIndexNone, kContinue, kMultiply | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB) \
  V(0xD3, DIV_INT_LIT16, "div-int/lit16", k22s, kIndexNone, kContinue | kThrow, kDivide | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB) \
  V(0xD4, REM_INT_LIT16, "rem-int/lit16", k22s, kIndexNone, kContinue | kThrow, kRemainder | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB) \
  V(0xD5, AND_INT_LIT16, "and-int/lit16", k22s, kIndexNone, kContinue, kAnd | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB) \
  V(0xD6, OR_INT_LIT16, "or-int/lit16", k22s, kIndexNone, kContinue, kOr | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB) \
  V(0xD7, XOR_INT_LIT16, "xor-int/lit16", k22s, kIndexNone, kContinue, kXor | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB) \
  V(0xD8, ADD_INT_LIT8, "add-int/lit8", k22b, kIndexNone, kContinue, kAdd | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB) \
  V(0xD9, RSUB_INT_LIT8, "rsub-int/lit8", k22b, kIndexNone, kContinue, kSubtract | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB) \
  V(0xDA, MUL_INT_LIT8, "mul-int/lit8", k22b, kIndexNone, kContinue, kMultiply | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB) \
  V(0xDB, DIV_INT_LIT8, "div-int/lit8", k22b, kIndexNone, kContinue | kThrow, kDivide | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB) \
  V(0xDC, REM_INT_LIT8, "rem-int/lit8", k22b, kIndexNone, kContinue | kThrow, kRemainder | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB) \
  V(0xDD, AND_INT_LIT8, "and-int/lit8", k22b, kIndexNone, kContinue, kAnd | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB) \
  V(0xDE, OR_INT_LIT8, "or-int/lit8", k22b, kIndexNone, kContinue, kOr | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB) \
  V(0xDF, XOR_INT_LIT8, "xor-int/lit8", k22b, kIndexNone, kContinue, kXor | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB) \
  V(0xE0, SHL_INT_LIT8, "shl-int/lit8", k22b, kIndexNone, kContinue, kShl | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB) \
  V(0xE1, SHR_INT_LIT8, "shr-int/lit8", k22b, kIndexNone, kContinue, kShr | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB) \
  V(0xE2, USHR_INT_LIT8, "ushr-int/lit8", k22b, kIndexNone, kContinue, kUshr | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB) \
  V(0xE3, IGET_QUICK, "iget-quick", k22c, kIndexFieldOffset, kContinue | kThrow, kLoad | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB | kVerifyRuntimeOnly) \
  V(0xE4, IGET_WIDE_QUICK, "iget-wide-quick", k22c, kIndexFieldOffset, kContinue | kThrow, kLoad | kRegCFieldOrConstant, kVerifyRegAWide | kVerifyRegB | kVerifyRuntimeOnly) \
  V(0xE5, IGET_OBJECT_QUICK, "iget-object-quick", k22c, kIndexFieldOffset, kContinue | kThrow, kLoad | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB | kVerifyRuntimeOnly) \
  V(0xE6, IPUT_QUICK, "iput-quick", k22c, kIndexFieldOffset, kContinue | kThrow, kStore | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB | kVerifyRuntimeOnly) \
  V(0xE7, IPUT_WIDE_QUICK, "iput-wide-quick", k22c, kIndexFieldOffset, kContinue | kThrow, kStore | kRegCFieldOrConstant, kVerifyRegAWide | kVerifyRegB | kVerifyRuntimeOnly) \
  V(0xE8, IPUT_OBJECT_QUICK, "iput-object-quick", k22c, kIndexFieldOffset, kContinue | kThrow, kStore | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB | kVerifyRuntimeOnly) \
  V(0xE9, INVOKE_VIRTUAL_QUICK, "invoke-virtual-quick", k35c, kIndexVtableOffset, kContinue | kThrow | kInvoke, 0, kVerifyVarArgNonZero | kVerifyRuntimeOnly) \
  V(0xEA, INVOKE_VIRTUAL_RANGE_QUICK, "invoke-virtual/range-quick", k3rc, kIndexVtableOffset, kContinue | kThrow | kInvoke, 0, kVerifyVarArgRangeNonZero | kVerifyRuntimeOnly) \
  V(0xEB, IPUT_BOOLEAN_QUICK, "iput-boolean-quick", k22c, kIndexFieldOffset, kContinue | kThrow, kStore | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB | kVerifyRuntimeOnly) \
  V(0xEC, IPUT_BYTE_QUICK, "iput-byte-quick", k22c, kIndexFieldOffset, kContinue | kThrow, kStore | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB | kVerifyRuntimeOnly) \
  V(0xED, IPUT_CHAR_QUICK, "iput-char-quick", k22c, kIndexFieldOffset, kContinue | kThrow, kStore | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB | kVerifyRuntimeOnly) \
  V(0xEE, IPUT_SHORT_QUICK, "iput-short-quick", k22c, kIndexFieldOffset, kContinue | kThrow, kStore | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB | kVerifyRuntimeOnly) \
  V(0xEF, IGET_BOOLEAN_QUICK, "iget-boolean-quick", k22c, kIndexFieldOffset, kContinue | kThrow, kLoad | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB | kVerifyRuntimeOnly) \
  V(0xF0, IGET_BYTE_QUICK, "iget-byte-quick", k22c, kIndexFieldOffset, kContinue | kThrow, kLoad | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB | kVerifyRuntimeOnly) \
  V(0xF1, IGET_CHAR_QUICK, "iget-char-quick", k22c, kIndexFieldOffset, kContinue | kThrow, kLoad | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB | kVerifyRuntimeOnly) \
  V(0xF2, IGET_SHORT_QUICK, "iget-short-quick", k22c, kIndexFieldOffset, kContinue | kThrow, kLoad | kRegCFieldOrConstant, kVerifyRegA | kVerifyRegB | kVerifyRuntimeOnly) \
  V(0xF3, UNUSED_F3, "unused-f3", k10x, kIndexUnknown, 0, 0, kVerifyError) \
  V(0xF4, UNUSED_F4, "unused-f4", k10x, kIndexUnknown, 0, 0, kVerifyError) \
  V(0xF5, UNUSED_F5, "unused-f5", k10x, kIndexUnknown, 0, 0, kVerifyError) \
  V(0xF6, UNUSED_F6, "unused-f6", k10x, kIndexUnknown, 0, 0, kVerifyError) \
  V(0xF7, UNUSED_F7, "unused-f7", k10x, kIndexUnknown, 0, 0, kVerifyError) \
  V(0xF8, UNUSED_F8, "unused-f8", k10x, kIndexUnknown, 0, 0, kVerifyError) \
  V(0xF9, UNUSED_F9, "unused-f9", k10x, kIndexUnknown, 0, 0, kVerifyError) \
  V(0xFA, INVOKE_POLYMORPHIC, "invoke-polymorphic", k45cc, kIndexMethodAndProtoRef, kContinue | kThrow | kInvoke, 0, kVerifyRegBMethod | kVerifyVarArgNonZero | kVerifyRegHPrototype) \
  V(0xFB, INVOKE_POLYMORPHIC_RANGE, "invoke-polymorphic/range", k4rcc, kIndexMethodAndProtoRef, kContinue | kThrow | kInvoke, 0, kVerifyRegBMethod | kVerifyVarArgRangeNonZero | kVerifyRegHPrototype) \
  V(0xFC, INVOKE_CUSTOM, "invoke-custom", k35c, kIndexCallSiteRef, kContinue | kThrow, 0, kVerifyRegBCallSite | kVerifyVarArg) \
  V(0xFD, INVOKE_CUSTOM_RANGE, "invoke-custom/range", k3rc, kIndexCallSiteRef, kContinue | kThrow, 0, kVerifyRegBCallSite | kVerifyVarArgRange) \
  V(0xFE, CONST_METHOD_HANDLE, "const-method-handle", k21c, kIndexMethodHandleRef, kContinue | kThrow, 0, kVerifyRegA | kVerifyRegBMethodHandle) \
  V(0xFF, CONST_METHOD_TYPE, "const-method-type", k21c, kIndexProtoRef, kContinue | kThrow, 0, kVerifyRegA | kVerifyRegBPrototype)

#define DEX_INSTRUCTION_FORMAT_LIST(V) \
  V(10x)  /* op */                                                  \
  V(12x)  /* op vA, vB */                                           \
  V(11n)  /* op vA, #+B */                                          \
  V(11x)  /* op vAA */                                              \
  V(10t)  /* op +AA */                                              \
  V(20t)  /* op +AAAA */                                            \
  V(20bc) /* [opt] op AA, thing@BBBB */                             \
  V(22x)  /* op vAA, vBBBB */                                       \
  V(21t)  /* op vAA, +BBBB */                                       \
  V(21s)  /* op vAA, #+BBBB */                                      \
  V(21h)  /* op vAA, #+BBBB00000[00000000] */                       \
  V(21c)  /* op vAA, thing@BBBB */                                  \
  V(23x)  /* op vAA, vBB, vCC */                                    \
  V(22b)  /* op vAA, vBB, #+CC */                                   \
  V(22t)  /* op vA, vB, +CCCC */                                    \
  V(22s)  /* op vA, vB, #+CCCC */                                   \
  V(22c)  /* op vA, vB, thing@CCCC */                               \
  V(22cs) /* [opt] op vA, vB, field offset CCCC */                  \
  V(30t)  /* op +AAAAAAAA */                                        \
  V(32x)  /* op vAAAA, vBBBB */                                     \
  V(31i)  /* op vAA, #+BBBBBBBB */                                  \
  V(31t)  /* op vAA, +BBBBBBBB */                                   \
  V(31c)  /* op vAA, string@BBBBBBBB */                             \
  V(35c)  /* op {vC,vD,vE,vF,vG}, thing@BBBB */                     \
  V(35ms) /* [opt] invoke-virtual+super */                          \
  V(3rc)  /* op {vCCCC .. v(CCCC+AA-1)}, thing@BBBB */              \
  V(3rms) /* [opt] invoke-virtual+super/range */                    \
  V(35mi) /* [opt] inline invoke */                                 \
  V(3rmi) /* [opt] inline invoke/range */                           \
  V(45cc) /* op {vC, vD, vE, vF, vG}, meth@BBBB, proto@HHHH */      \
  V(4rcc) /* op {VCCCC .. v(CCCC+AA-1)}, meth@BBBB, proto@HHHH */   \
  V(51l)  /* op vAA, #+BBBBBBBBBBBBBBBB */

#endif  // ART_LIBDEXFILE_DEX_DEX_INSTRUCTION_LIST_H_
#undef ART_LIBDEXFILE_DEX_DEX_INSTRUCTION_LIST_H_  // the guard in this file is just for cpplint

```

`paccer/jni/slicer/export/slicer/dex_ir.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include "arrayview.h"
#include "buffer.h"
#include "common.h"
#include "dex_format.h"
#include "dex_leb128.h"
#include "hash_table.h"
#include "index_map.h"
#include "memview.h"

#include <stdlib.h>
#include <map>
#include <memory>
#include <vector>
#include <string>

// A simple, lightweight IR to abstract the key .dex structures
//
// 1. All the cross-IR references are modeled as plain pointers.
// 2. Newly allocated nodes are mem-zeroed first
//
// This IR can mirror any .dex file, although for JVMTI BCI
// it's expected to construct the IR for the single modified class only
// (and include only the nodes referenced from that class)

#define SLICER_IR_TYPE     \
  using Node::Node; \
  friend struct DexFile;

#define SLICER_IR_INDEXED_TYPE           \
  using IndexedNode::IndexedNode; \
  friend struct DexFile;

namespace ir {

// convenience notation
template <class T>
using own = std::unique_ptr<T>;

struct Node;
struct IndexedNode;
struct EncodedValue;
struct EncodedArray;
struct String;
struct Type;
struct TypeList;
struct Proto;
struct MethodHandle;
struct FieldDecl;
struct EncodedField;
struct DebugInfo;
struct Code;
struct MethodDecl;
struct EncodedMethod;
struct AnnotationElement;
struct Annotation;
struct AnnotationSet;
struct AnnotationSetRefList;
struct FieldAnnotation;
struct MethodAnnotation;
struct ParamAnnotation;
struct AnnotationsDirectory;
struct Class;
struct DexFile;

// The base class for all the .dex IR types:
//   This is not a polymorphic interface, but
//   a way to constrain the allocation and ownership
//   of .dex IR nodes.
struct Node {
  void* operator new(size_t size) {
    return ::calloc(1, size);
  }

  void* operator new[](size_t size) {
    return ::calloc(1, size);
  }

  void operator delete(void* ptr) {
    ::free(ptr);
  }

  void operator delete[](void* ptr) {
    ::free(ptr);
  }

 public:
  Node(const Node&) = delete;
  Node& operator=(const Node&) = delete;

 protected:
  Node() = default;
  ~Node() = default;
};

// a concession for the convenience of the .dex writer
//
// TODO: consider moving the indexing to the writer.
//
struct IndexedNode : public Node {
  SLICER_IR_TYPE;

  // this is the index in the generated image
  // (not the original index)
  dex::u4 index;

  // original indexe
  // (from the source .dex image or allocated post reader)
  dex::u4 orig_index;
};

struct EncodedValue : public Node {
  SLICER_IR_TYPE;

  dex::u1 type;
  union {
    int8_t byte_value;
    int16_t short_value;
    uint16_t char_value;
    int32_t int_value;
    int64_t long_value;
    float float_value;
    double double_value;
    String* string_value;
    Type* type_value;
    FieldDecl* field_value;
    MethodDecl* method_value;
    FieldDecl* enum_value;
    EncodedArray* array_value;
    Annotation* annotation_value;
    bool bool_value;
  } u;

  SLICER_EXTRA(slicer::MemView original);
};

struct EncodedArray : public Node {
  SLICER_IR_TYPE;

  std::vector<EncodedValue*> values;
};

struct String : public IndexedNode {
  SLICER_IR_INDEXED_TYPE;

  // opaque DEX "string_data_item"
  slicer::MemView data;

  const char* c_str() const {
    const dex::u1* strData = data.ptr<dex::u1>();
    dex::ReadULeb128(&strData);
    return reinterpret_cast<const char*>(strData);
  }
};

struct Type : public IndexedNode {
  SLICER_IR_INDEXED_TYPE;

  enum class Category { Void, Scalar, WideScalar, Reference };

  String* descriptor;
  Class* class_def;

  std::string Decl() const;
  Category GetCategory() const;
};

struct TypeList : public Node {
  SLICER_IR_TYPE;

  std::vector<Type*> types;
};

struct Proto : public IndexedNode {
  SLICER_IR_INDEXED_TYPE;

  String* shorty;
  Type* return_type;
  TypeList* param_types;

  std::string Signature() const;
};

struct MethodHandle : public IndexedNode {
  SLICER_IR_INDEXED_TYPE;

  dex::u2 method_handle_type;
  MethodDecl* method;
  FieldDecl* field;

  bool IsField();
};

struct FieldDecl : public IndexedNode {
  SLICER_IR_INDEXED_TYPE;

  String* name;
  Type* type;
  Type* parent;
};

struct EncodedField : public Node {
  SLICER_IR_TYPE;

  FieldDecl* decl;
  dex::u4 access_flags;
};

struct DebugInfo : public Node {
  SLICER_IR_TYPE;

  dex::u4 line_start;
  std::vector<String*> param_names;

  // original debug info opcodes stream
  // (must be "relocated" when creating a new .dex image)
  slicer::MemView data;
};

struct Code : public Node {
  SLICER_IR_TYPE;

  dex::u2 registers;
  dex::u2 ins_count;
  dex::u2 outs_count;
  slicer::ArrayView<const dex::u2> instructions;
  slicer::ArrayView<const dex::TryBlock> try_blocks;
  slicer::MemView catch_handlers;
  DebugInfo* debug_info;
};

struct MethodDecl : public IndexedNode {
  SLICER_IR_INDEXED_TYPE;

  String* name;
  Proto* prototype;
  Type* parent;
};

struct EncodedMethod : public Node {
  SLICER_IR_TYPE;

  MethodDecl* decl;
  Code* code;
  dex::u4 access_flags;
};

struct AnnotationElement : public Node {
  SLICER_IR_TYPE;

  String* name;
  EncodedValue* value;
};

struct Annotation : public Node {
  SLICER_IR_TYPE;

  Type* type;
  std::vector<AnnotationElement*> elements;
  dex::u1 visibility;
};

struct AnnotationSet : public Node {
  SLICER_IR_TYPE;

  std::vector<Annotation*> annotations;
};

struct AnnotationSetRefList : public Node {
  SLICER_IR_TYPE;

  std::vector<AnnotationSet*> annotations;
};

struct FieldAnnotation : public Node {
  SLICER_IR_TYPE;

  FieldDecl* field_decl;
  AnnotationSet* annotations;
};

struct MethodAnnotation : public Node {
  SLICER_IR_TYPE;

  MethodDecl* method_decl;
  AnnotationSet* annotations;
};

struct ParamAnnotation : public Node {
  SLICER_IR_TYPE;

  MethodDecl* method_decl;
  AnnotationSetRefList* annotations;
};

struct AnnotationsDirectory : public Node {
  SLICER_IR_TYPE;

  AnnotationSet* class_annotation;
  std::vector<FieldAnnotation*> field_annotations;
  std::vector<MethodAnnotation*> method_annotations;
  std::vector<ParamAnnotation*> param_annotations;
};

struct Class : public IndexedNode {
  SLICER_IR_INDEXED_TYPE;

  Type* type;
  dex::u4 access_flags;
  Type* super_class;
  TypeList* interfaces;
  String* source_file;
  AnnotationsDirectory* annotations;
  EncodedArray* static_init;

  std::vector<EncodedField*> static_fields;
  std::vector<EncodedField*> instance_fields;
  std::vector<EncodedMethod*> direct_methods;
  std::vector<EncodedMethod*> virtual_methods;
};

// ir::String hashing
struct StringsHasher {
  const char* GetKey(const String* string) const { return string->c_str(); }
  uint32_t Hash(const char* string_key) const;
  bool Compare(const char* string_key, const String* string) const;
};

// ir::Proto hashing
struct ProtosHasher {
  std::string GetKey(const Proto* proto) const { return proto->Signature(); }
  uint32_t Hash(const std::string& proto_key) const;
  bool Compare(const std::string& proto_key, const Proto* proto) const;
};

// ir::EncodedMethod hashing
struct MethodKey {
  String* class_descriptor = nullptr;
  String* method_name = nullptr;
  Proto* prototype = nullptr;
};

struct MethodsHasher {
  MethodKey GetKey(const EncodedMethod* method) const;
  uint32_t Hash(const MethodKey& method_key) const;
  bool Compare(const MethodKey& method_key, const EncodedMethod* method) const;
};

using StringsLookup = slicer::HashTable<const char*, String, StringsHasher>;
using PrototypesLookup = slicer::HashTable<const std::string&, Proto, ProtosHasher>;
using MethodsLookup = slicer::HashTable<const MethodKey&, EncodedMethod, MethodsHasher>;

// The main container/root for a .dex IR
struct DexFile {
  // indexed structures
  std::vector<own<String>> strings;
  std::vector<own<Type>> types;
  std::vector<own<Proto>> protos;
  std::vector<own<FieldDecl>> fields;
  std::vector<own<MethodDecl>> methods;
  std::vector<own<Class>> classes;
  std::vector<own<MethodHandle>> method_handles;

  // data segment structures
  std::vector<own<EncodedField>> encoded_fields;
  std::vector<own<EncodedMethod>> encoded_methods;
  std::vector<own<TypeList>> type_lists;
  std::vector<own<Code>> code;
  std::vector<own<DebugInfo>> debug_info;
  std::vector<own<EncodedValue>> encoded_values;
  std::vector<own<EncodedArray>> encoded_arrays;
  std::vector<own<Annotation>> annotations;
  std::vector<own<AnnotationElement>> annotation_elements;
  std::vector<own<AnnotationSet>> annotation_sets;
  std::vector<own<AnnotationSetRefList>> annotation_set_ref_lists;
  std::vector<own<AnnotationsDirectory>> annotations_directories;
  std::vector<own<FieldAnnotation>> field_annotations;
  std::vector<own<MethodAnnotation>> method_annotations;
  std::vector<own<ParamAnnotation>> param_annotations;

  // original index to IR node mappings
  //
  // CONSIDER: we only need to carry around
  //   the relocation for the referenced items
  //
  std::map<dex::u4, Type*> types_map;
  std::map<dex::u4, String*> strings_map;
  std::map<dex::u4, Proto*> protos_map;
  std::map<dex::u4, FieldDecl*> fields_map;
  std::map<dex::u4, MethodDecl*> methods_map;
  std::map<dex::u4, Class*> classes_map;
  std::map<dex::u4, MethodHandle*> method_handles_map;

  // original .dex header "magic" signature
  slicer::MemView magic;

  // keep track of the used index values
  // (so we can easily allocate new ones)
  IndexMap strings_indexes;
  IndexMap types_indexes;
  IndexMap protos_indexes;
  IndexMap fields_indexes;
  IndexMap methods_indexes;
  IndexMap classes_indexes;
  IndexMap method_handle_indexes;

  // lookup hash tables
  StringsLookup strings_lookup;
  MethodsLookup methods_lookup;
  PrototypesLookup prototypes_lookup;

 public:
  DexFile() = default;

  // No copy/move semantics
  DexFile(const DexFile&) = delete;
  DexFile& operator=(const DexFile&) = delete;

  template <class T>
  T* Alloc() {
    T* p = new T();
    Track(p);
    return p;
  }

  void AttachBuffer(slicer::Buffer&& buffer) {
    buffers_.push_back(std::move(buffer));
  }

  void Normalize();

 private:
  void TopSortClassIndex(Class* irClass, dex::u4* nextIndex);
  void SortClassIndexes();

  template <class T>
  void PushOwn(std::vector<own<T>>& v, T* p) {
    v.push_back(own<T>(p));
  }

  void Track(String* p) { PushOwn(strings, p); }
  void Track(Type* p) { PushOwn(types, p); }
  void Track(Proto* p) { PushOwn(protos, p); }
  void Track(FieldDecl* p) { PushOwn(fields, p); }
  void Track(MethodDecl* p) { PushOwn(methods, p); }
  void Track(Class* p) { PushOwn(classes, p); }
  void Track(MethodHandle* p) { PushOwn(method_handles, p); }

  void Track(EncodedField* p) { PushOwn(encoded_fields, p); }
  void Track(EncodedMethod* p) { PushOwn(encoded_methods, p); }
  void Track(TypeList* p) { PushOwn(type_lists, p); }
  void Track(Code* p) { PushOwn(code, p); }
  void Track(DebugInfo* p) { PushOwn(debug_info, p); }
  void Track(EncodedValue* p) { PushOwn(encoded_values, p); }
  void Track(EncodedArray* p) { PushOwn(encoded_arrays, p); }
  void Track(Annotation* p) { PushOwn(annotations, p); }
  void Track(AnnotationElement* p) { PushOwn(annotation_elements, p); }
  void Track(AnnotationSet* p) { PushOwn(annotation_sets, p); }
  void Track(AnnotationSetRefList* p) { PushOwn(annotation_set_ref_lists, p); }
  void Track(AnnotationsDirectory* p) { PushOwn(annotations_directories, p); }
  void Track(FieldAnnotation* p) { PushOwn(field_annotations, p); }
  void Track(MethodAnnotation* p) { PushOwn(method_annotations, p); }
  void Track(ParamAnnotation* p) { PushOwn(param_annotations, p); }

private:
  // additional memory buffers owned by this .dex IR
  std::vector<slicer::Buffer> buffers_;
};

}  // namespace ir

#undef SLICER_IR_TYPE
#undef SLICER_IR_INDEXED_TYPE

```

`paccer/jni/slicer/export/slicer/dex_ir_builder.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include "common.h"
#include "dex_ir.h"

#include <memory>

namespace ir {

// Packing together the name components which identify a Java method
// (depending on the use some fields, ex. signature, are optional)
//
// NOTE: the "signature" uses the JNI signature syntax:
//  https://docs.oracle.com/javase/8/docs/technotes/guides/jni/spec/types.html#type_signatures
//
struct MethodId {
  const char* class_descriptor;
  const char* method_name;
  const char* signature;

  MethodId(const char* class_descriptor, const char* method_name, const char* signature = nullptr)
      : class_descriptor(class_descriptor), method_name(method_name), signature(signature) {
    assert(class_descriptor != nullptr);
    assert(method_name != nullptr);
  }

  bool Match(MethodDecl* method_decl) const;
};

// This class enables modifications to a .dex IR
class Builder {
 public:
  explicit Builder(std::shared_ptr<ir::DexFile> dex_ir) : dex_ir_(dex_ir) {}

  // No copy/move semantics
  Builder(const Builder&) = delete;
  Builder& operator=(const Builder&) = delete;

  // Get/Create .dex IR nodes
  // (get existing instance or create a new one)
  String* GetAsciiString(const char* cstr);
  Type* GetType(String* descriptor);
  Proto* GetProto(Type* return_type, TypeList* param_types);
  FieldDecl* GetFieldDecl(String* name, Type* type, Type* parent);
  MethodDecl* GetMethodDecl(String* name, Proto* proto, Type* parent);
  TypeList* GetTypeList(const std::vector<Type*>& types);

  // Convenience overloads
  Type* GetType(const char* descriptor) {
    return GetType(GetAsciiString(descriptor));
  }

  // Locate an existing method definition
  // (returns nullptr if the method is not found)
  EncodedMethod* FindMethod(const MethodId& method_id) const;

 private:
  // Locate an existing .dex IR string
  // (returns nullptr if the string is not found)
  String* FindAsciiString(const char* cstr) const;

  // Locate an existing .dex IR prototype
  // (returns nullptr if the prototype is not found)
  Proto* FindPrototype(const char* signature) const;

 private:
  std::shared_ptr<ir::DexFile> dex_ir_;
};

}  // namespace ir

```

`paccer/jni/slicer/export/slicer/dex_leb128.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include "dex_format.h"

// LEB128 encode/decode helpers:
// https://source.android.com/devices/tech/dalvik/dex-format.html

namespace dex {

// Reads an unsigned LEB128 value, updating the given pointer to
// point just past the end of the read value.
inline u4 ReadULeb128(const u1** pptr) {
  const u1* ptr = *pptr;
  u4 result = *(ptr++);

  if (result > 0x7f) {
    u4 cur = *(ptr++);
    result = (result & 0x7f) | ((cur & 0x7f) << 7);
    if (cur > 0x7f) {
      cur = *(ptr++);
      result |= (cur & 0x7f) << 14;
      if (cur > 0x7f) {
        cur = *(ptr++);
        result |= (cur & 0x7f) << 21;
        if (cur > 0x7f) {
          // We don't check to see if cur is out of
          // range here, meaning we tolerate garbage in the
          // high four-order bits.
          cur = *(ptr++);
          result |= cur << 28;
        }
      }
    }
  }

  *pptr = ptr;
  return result;
}

// Reads a signed LEB128 value, updating the given pointer to
// point just past the end of the read value.
inline s4 ReadSLeb128(const u1** pptr) {
  const u1* ptr = *pptr;
  s4 result = *(ptr++);

  if (result <= 0x7f) {
    result = (result << 25) >> 25;
  } else {
    s4 cur = *(ptr++);
    result = (result & 0x7f) | ((cur & 0x7f) << 7);
    if (cur <= 0x7f) {
      result = (result << 18) >> 18;
    } else {
      cur = *(ptr++);
      result |= (cur & 0x7f) << 14;
      if (cur <= 0x7f) {
        result = (result << 11) >> 11;
      } else {
        cur = *(ptr++);
        result |= (cur & 0x7f) << 21;
        if (cur <= 0x7f) {
          result = (result << 4) >> 4;
        } else {
          // Note: We don't check to see if cur is out of
          // range here, meaning we tolerate garbage in the
          // high four-order bits.
          cur = *(ptr++);
          result |= cur << 28;
        }
      }
    }
  }

  *pptr = ptr;
  return result;
}

// Writes a 32-bit value in unsigned ULEB128 format.
// Returns the updated pointer.
inline u1* WriteULeb128(u1* ptr, u4 data) {
  for (;;) {
    u1 out = data & 0x7f;
    if (out != data) {
      *ptr++ = out | 0x80;
      data >>= 7;
    } else {
      *ptr++ = out;
      break;
    }
  }
  return ptr;
}

// Writes a 32-bit value in signed ULEB128 format.
// Returns the updated pointer.
inline u1* WriteSLeb128(u1* ptr, s4 value) {
  u4 extra_bits = static_cast<u4>(value ^ (value >> 31)) >> 6;
  u1 out = value & 0x7f;
  while (extra_bits != 0u) {
    *ptr++ = out | 0x80;
    value >>= 7;
    out = value & 0x7f;
    extra_bits >>= 7;
  }
  *ptr++ = out;
  return ptr;
}

}  // namespace dex

```

`paccer/jni/slicer/export/slicer/dex_utf8.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include "dex_format.h"

// MUTF-8 (Modified UTF-8) Encoding helpers:
// https://source.android.com/devices/tech/dalvik/dex-format.html

namespace dex {

// Compare two '\0'-terminated modified UTF-8 strings, using Unicode
// code point values for comparison. This treats different encodings
// for the same code point as equivalent, except that only a real '\0'
// byte is considered the string terminator. The return value is as
// for strcmp().
int Utf8Cmp(const char* s1, const char* s2);

}  // namespace dex

```

`paccer/jni/slicer/export/slicer/hash_table.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include <cstdint>
#include <memory>
#include <vector>

namespace slicer {

// A specialized Key -> T* map (note that, unlike std:: containers, the values
// are always pointers here, and we don't explicitly store the lookup keys)
//
// Implemented as an incrementally resizable hash table: we split the logical hash table
// into two internal fixed size tables, the "full table" and a "insertion table".
// When the insertion table overflows, we allocate a larger hashtable to replace
// it and "insertion table" becomes the "full table" (the old "full table" is
// rehashed into the new hash table)
//
// Similar to open addressing hash tables, all the buckets are a single,
// contiguous array. But this table is growing and the collisions are still handled
// as chains (using indexes instead of pointers).
//
// The result is faster than std::unordered_map and uses ~25% of
// the memory used by std::unordered_map<const char*, String*>
//
// The Hash template argument is a type which must implement:
//   1. hash function   : uint32_t Hash(const Key& key)
//   2. key compare     : bool Compare(const Key& key, T* value)
//   3. key extraction  : Key GetKey(T* value)
//   4. copy semantics
//
template<class Key, class T, class Hash>
class HashTable {
 private:
  // the index type inside the bucket array
  using Index = uint32_t;

  static constexpr Index kInitialHashBuckets = (1 << 7) - 1;
  static constexpr Index kAvgChainLength = 2;
  static constexpr Index kInvalidIndex = static_cast<Index>(-1);
  static constexpr double kResizeFactor = 1.6;

  struct __attribute__((packed)) Bucket {
    T* value = nullptr;
    Index next = kInvalidIndex;
  };

  class Partition {
   public:
    Partition(Index size, const Hash& hasher);
    bool Insert(T* value);
    T* Lookup(const Key& key, uint32_t hash_value) const;
    Index HashBuckets() const { return hash_buckets_; }
    void InsertAll(const Partition& src);
    void PrintStats(const char* name, bool verbose);

   private:
    std::vector<Bucket> buckets_;
    const Index hash_buckets_;
    Hash hasher_;
  };

 public:
  explicit HashTable(const Hash& hasher = Hash()) : hasher_(hasher) {
    // we start with full_table_ == nullptr
    insertion_table_.reset(new Partition(kInitialHashBuckets, hasher_));
  }

  ~HashTable() = default;

  // No move or copy semantics
  HashTable(const HashTable&) = delete;
  HashTable& operator=(const HashTable&) = delete;

  // Insert a new, non-nullptr T* into the hash table
  // (we only store unique values so the new value must
  // not be in the table already)
  void Insert(T* value);

  // Lookup an existing value
  // (returns nullptr if the value is not found)
  T* Lookup(const Key& key) const;

  void PrintStats(const char* name, bool verbose);

 private:
  std::unique_ptr<Partition> full_table_;
  std::unique_ptr<Partition> insertion_table_;
  Hash hasher_;
};

template<class Key, class T, class Hash>
HashTable<Key, T, Hash>::Partition::Partition(Index size, const Hash& hasher)
    : hash_buckets_(size), hasher_(hasher) {
  // allocate space for the hash buckets + avg chain length
  buckets_.reserve(hash_buckets_ * kAvgChainLength);
  buckets_.resize(hash_buckets_);
}

// Similar to the "cellar" version of coalesced hashing,
// the buckets array is divided into a fixed set of entries
// addressable by the hash value [0 .. hash_buckets_) and
// extra buckets for the collision chains [hash_buckets_, buckets_.size())
// Unlike coalesced hashing, our "cellar" is growing so we don't actually
// have to coalesce any chains.
//
// Returns true if the insertion succeeded, false if the table overflows
// (we never insert more than the pre-reserved capacity)
//
template<class Key, class T, class Hash>
bool HashTable<Key, T, Hash>::Partition::Insert(T* value) {
  SLICER_CHECK_NE(value, nullptr);
  // overflow?
  if (buckets_.size() + 1 > buckets_.capacity()) {
    return false;
  }
  auto key = hasher_.GetKey(value);
  Index bucket_index = hasher_.Hash(key) % hash_buckets_;
  if (buckets_[bucket_index].value == nullptr) {
    buckets_[bucket_index].value = value;
  } else {
    Bucket new_bucket = {};
    new_bucket.value = value;
    new_bucket.next = buckets_[bucket_index].next;
    buckets_[bucket_index].next = buckets_.size();
    buckets_.push_back(new_bucket);
  }
  return true;
}

template<class Key, class T, class Hash>
T* HashTable<Key, T, Hash>::Partition::Lookup(const Key& key, uint32_t hash_value) const {
  assert(hash_value == hasher_.Hash(key));
  Index bucket_index = hash_value % hash_buckets_;
  for (Index index = bucket_index; index != kInvalidIndex; index = buckets_[index].next) {
    auto value = buckets_[index].value;
    if (value == nullptr) {
      assert(index < hash_buckets_);
      break;
    } else if (hasher_.Compare(key, value)) {
      return value;
    }
  }
  return nullptr;
}

template<class Key, class T, class Hash>
void HashTable<Key, T, Hash>::Partition::InsertAll(const Partition& src) {
  for (const auto& bucket : src.buckets_) {
    if (bucket.value != nullptr) {
      SLICER_CHECK(Insert(bucket.value));
    }
  }
}

// Try to insert into the "insertion table". If that overflows,
// we allocate a new, larger hash table, move "full table" value to it
// and "insertion table" becomes the new "full table".
template<class Key, class T, class Hash>
void HashTable<Key, T, Hash>::Insert(T* value) {
  assert(Lookup(hasher_.GetKey(value)) == nullptr);
  if (!insertion_table_->Insert(value)) {
    std::unique_ptr<Partition> new_hash_table(
        new Partition(insertion_table_->HashBuckets() * kResizeFactor, hasher_));
    if (full_table_) {
      new_hash_table->InsertAll(*full_table_);
    }
    SLICER_CHECK(new_hash_table->Insert(value));
    full_table_ = std::move(insertion_table_);
    insertion_table_ = std::move(new_hash_table);
  }
}

// First look into the "full table" and if the value is
// not found there look into the "insertion table" next
template<class Key, class T, class Hash>
T* HashTable<Key, T, Hash>::Lookup(const Key& key) const {
  auto hash_value = hasher_.Hash(key);
  if (full_table_) {
    auto value = full_table_->Lookup(key, hash_value);
    if (value != nullptr) {
      return value;
    }
  }
  return insertion_table_->Lookup(key, hash_value);
}

template<class Key, class T, class Hash>
void HashTable<Key, T, Hash>::Partition::PrintStats(const char* name, bool verbose) {
  int max_chain_length = 0;
  int sum_chain_length = 0;
  int used_buckets = 0;
  for (Index i = 0; i < hash_buckets_; ++i) {
    if (verbose) printf("%4d : ", i);
    if (buckets_[i].value != nullptr) {
      ++used_buckets;
      int chain_length = 0;
      for (Index ci = i; buckets_[ci].next != kInvalidIndex; ci = buckets_[ci].next) {
        SLICER_CHECK_NE(buckets_[ci].value, nullptr);
        ++chain_length;
        if (verbose) printf("*");
      }
      max_chain_length = std::max(max_chain_length, chain_length);
      sum_chain_length += chain_length;
    }
    if (verbose) printf("\n");
  }

  int avg_chain_length = used_buckets ? sum_chain_length / used_buckets : 0;

  printf("\nHash table partition (%s):\n", name);
  printf("  hash_buckets                   : %u\n", hash_buckets_);
  printf("  size/capacity                  : %zu / %zu\n", buckets_.size(), buckets_.capacity());
  printf("  used_buckets                   : %d\n", used_buckets);
  printf("  max_chain_length               : %d\n", max_chain_length);
  printf("  avg_chain_length               : %d\n", avg_chain_length);
}

template<class Key, class T, class Hash>
void HashTable<Key, T, Hash>::PrintStats(const char* name, bool verbose) {
  printf("\nHash table stats (%s)\n", name);
  if (full_table_) {
    full_table_->PrintStats("full_table", verbose);
  }
  insertion_table_->PrintStats("insertion_table", verbose);
}

}  // namespace slicer

```

`paccer/jni/slicer/export/slicer/index_map.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include "common.h"
#include "dex_format.h"

#include <vector>

namespace ir {

// A simple index tracking and allocator
class IndexMap {
 public:
  dex::u4 AllocateIndex() {
    const auto size = indexes_map_.size();
    while (alloc_pos_ < size && indexes_map_[alloc_pos_]) {
      ++alloc_pos_;
    }
    MarkUsedIndex(alloc_pos_);
    return alloc_pos_++;
  }

  void MarkUsedIndex(dex::u4 index) {
    if (index >= indexes_map_.size()) {
      indexes_map_.resize(index + 1);
    }
    SLICER_CHECK(!indexes_map_[index]);
    indexes_map_[index] = true;
  }

 private:
  std::vector<bool> indexes_map_;
  dex::u4 alloc_pos_ = 0;
};

}  // namespace ir

```

`paccer/jni/slicer/export/slicer/instrumentation.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include "code_ir.h"
#include "common.h"
#include "dex_ir.h"
#include "dex_ir_builder.h"

#include <memory>
#include <set>
#include <utility>
#include <vector>

namespace slicer {

// Interface for a single transformation operation
class Transformation {
 public:
  virtual ~Transformation() = default;
  virtual bool Apply(lir::CodeIr* code_ir) = 0;
};

// Insert a call to the "entry hook" at the start of the instrumented method:
// The "entry hook" will be forwarded the original incoming arguments plus
// an explicit "this" argument for non-static methods.
class EntryHook : public Transformation {
 public:
  enum class Tweak {
    None,
    // Expose the "this" argument of non-static methods as the "Object" type.
    // This can be helpful when the code you want to handle the hook doesn't
    // have access to the actual type in its classpath.
    ThisAsObject,
    // Forward incoming arguments as an array. Zero-th element of the array is
    // the method signature. First element of the array is
    // "this" object if instrumented method isn't static.
    // It is helpul, when you inject the same hook into the different
    // methods.
    ArrayParams,
  };

  explicit EntryHook(const ir::MethodId& hook_method_id, Tweak tweak)
      : hook_method_id_(hook_method_id), tweak_(tweak) {
    // hook method signature is generated automatically
    SLICER_CHECK_EQ(hook_method_id_.signature, nullptr);
  }

  // TODO: Delete this legacy constrcutor.
  // It is left in temporarily so we can move callers away from it to the new
  // `tweak` constructor.
  explicit EntryHook(const ir::MethodId& hook_method_id,
                     bool use_object_type_for_this_argument = false)
      : EntryHook(hook_method_id, use_object_type_for_this_argument
                                      ? Tweak::ThisAsObject
                                      : Tweak::None) {}

  virtual bool Apply(lir::CodeIr* code_ir) override;

 private:
  ir::MethodId hook_method_id_;
  Tweak tweak_;

  bool InjectArrayParamsHook(lir::CodeIr* code_ir, lir::Bytecode* bytecode);
};

// Insert a call to the "exit hook" method before every return
// in the instrumented method. The "exit hook" will be passed the
// original return value and it may return a new return value.
class ExitHook : public Transformation {
 public:
  enum class Tweak {
    None = 0,
    // return value will be passed as "Object" type.
    // This can be helpful when the code you want to handle the hook doesn't
    // have access to the actual type in its classpath or when you want to inject
    // the same hook in multiple methods.
    ReturnAsObject = 1 << 0,
    // Pass method signature as the first parameter of the hook method.
    PassMethodSignature = 1 << 1,
  };

   explicit ExitHook(const ir::MethodId& hook_method_id, Tweak tweak)
      : hook_method_id_(hook_method_id), tweak_(tweak) {
    // hook method signature is generated automatically
    SLICER_CHECK_EQ(hook_method_id_.signature, nullptr);
  }

  explicit ExitHook(const ir::MethodId& hook_method_id) : ExitHook(hook_method_id, Tweak::None) {}

  virtual bool Apply(lir::CodeIr* code_ir) override;

 private:
  ir::MethodId hook_method_id_;
  Tweak tweak_;
};

inline ExitHook::Tweak operator|(ExitHook::Tweak a, ExitHook::Tweak b) {
  return static_cast<ExitHook::Tweak>(static_cast<int>(a) | static_cast<int>(b));
}

inline int operator&(ExitHook::Tweak a, ExitHook::Tweak b) {
  return static_cast<int>(a) & static_cast<int>(b);
}

// Base class for detour hooks. Replace every occurrence of specific opcode with
// something else. The detour is a static method which takes the same arguments
// as the original method plus an explicit "this" argument and returns the same
// type as the original method. Derived classes must implement GetNewOpcode.
class DetourHook : public Transformation {
 public:
  DetourHook(const ir::MethodId& orig_method_id,
             const ir::MethodId& detour_method_id)
      : orig_method_id_(orig_method_id), detour_method_id_(detour_method_id) {
    // detour method signature is automatically created
    // to match the original method and must not be explicitly specified
    SLICER_CHECK_EQ(detour_method_id_.signature, nullptr);
  }

  virtual bool Apply(lir::CodeIr* code_ir) override;

 protected:
  ir::MethodId orig_method_id_;
  ir::MethodId detour_method_id_;

  // Returns a new opcode to replace the desired opcode or OP_NOP otherwise.
  virtual dex::Opcode GetNewOpcode(dex::Opcode opcode) = 0;
};

// Replace every invoke-virtual[/range] to the a specified method with
// a invoke-static[/range] to the detour method.
class DetourVirtualInvoke : public DetourHook {
 public:
  DetourVirtualInvoke(const ir::MethodId& orig_method_id,
                      const ir::MethodId& detour_method_id)
      : DetourHook(orig_method_id, detour_method_id) {}

 protected:
  virtual dex::Opcode GetNewOpcode(dex::Opcode opcode) override;
};

// Replace every invoke-interface[/range] to the a specified method with
// a invoke-static[/range] to the detour method.
class DetourInterfaceInvoke : public DetourHook {
 public:
  DetourInterfaceInvoke(const ir::MethodId& orig_method_id,
                        const ir::MethodId& detour_method_id)
      : DetourHook(orig_method_id, detour_method_id) {}

 protected:
  virtual dex::Opcode GetNewOpcode(dex::Opcode opcode) override;
};

// Allocates scratch registers without doing a full register allocation
class AllocateScratchRegs : public Transformation {
 public:
  explicit AllocateScratchRegs(int allocate_count, bool allow_renumbering = true)
    : allocate_count_(allocate_count), allow_renumbering_(allow_renumbering) {
    SLICER_CHECK_GT(allocate_count, 0);
  }

  virtual bool Apply(lir::CodeIr* code_ir) override;

  const std::set<dex::u4>& ScratchRegs() const {
    SLICER_CHECK_EQ(scratch_regs_.size(), static_cast<size_t>(allocate_count_));
    return scratch_regs_;
  }

 private:
  void RegsRenumbering(lir::CodeIr* code_ir);
  void ShiftParams(lir::CodeIr* code_ir);
  void Allocate(lir::CodeIr* code_ir, dex::u4 first_reg, int count);

 private:
  const int allocate_count_;
  const bool allow_renumbering_;
  int left_to_allocate_ = 0;
  std::set<dex::u4> scratch_regs_;
};

// A friendly helper for instrumenting existing methods: it allows batching
// a set of transformations to be applied to method (the batching allow it
// to build and encode the code IR once per method regardless of how many
// transformation are applied)
//
// For example, if we want to add both entry and exit hooks to a
// Hello.Test(int) method, the code would look like this:
//
//    ...
//    slicer::MethodInstrumenter mi(dex_ir);
//    mi.AddTransformation<slicer::EntryHook>(ir::MethodId("LTracer;", "OnEntry"));
//    mi.AddTransformation<slicer::ExitHook>(ir::MethodId("LTracer;", "OnExit"));
//    SLICER_CHECK(mi.InstrumentMethod(ir::MethodId("LHello;", "Test", "(I)I")));
//    ...
//
class MethodInstrumenter {
 public:
  explicit MethodInstrumenter(std::shared_ptr<ir::DexFile> dex_ir) : dex_ir_(dex_ir) {}

  // No copy/move semantics
  MethodInstrumenter(const MethodInstrumenter&) = delete;
  MethodInstrumenter& operator=(const MethodInstrumenter&) = delete;

  // Queue a transformation
  // (T is a class derived from Transformation)
  template<class T, class... Args>
  T* AddTransformation(Args&&... args) {
    T* transformation = new T(std::forward<Args>(args)...);
    transformations_.emplace_back(transformation);
    return transformation;
  }

  // Apply all the queued transformations to the specified method
  bool InstrumentMethod(ir::EncodedMethod* ir_method);
  bool InstrumentMethod(const ir::MethodId& method_id);

 private:
  std::shared_ptr<ir::DexFile> dex_ir_;
  std::vector<std::unique_ptr<Transformation>> transformations_;
};

}  // namespace slicer

```

`paccer/jni/slicer/export/slicer/intrusive_list.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include "common.h"

#include <assert.h>

namespace slicer {

// A minimal intrusive linked list with a STL-style container interface
// (It works for any type T which has T* next, prev fields)
//
template <class T>
class IntrusiveList {
 public:
  struct Iterator {
    explicit Iterator(T* p) : p_(p) {}

    bool operator==(Iterator other) const { return p_ == other.p_; }
    bool operator!=(Iterator other) const { return p_ != other.p_; }

    T* operator*() const {
      assert(p_ != nullptr);
      return p_;
    }

    Iterator operator++() {
      assert(p_ != nullptr);
      p_ = p_->next;
      return *this;
    }

    Iterator operator++(int) {
      auto tmp(*this);
      operator++();
      return tmp;
    }

    Iterator operator--() {
      assert(p_ != nullptr);
      p_ = p_->prev;
      return *this;
    }

    Iterator operator--(int) {
      auto tmp(*this);
      operator--();
      return tmp;
    }

   private:
    T* p_;
  };

 public:
  IntrusiveList() = default;
  ~IntrusiveList() = default;

  IntrusiveList(const IntrusiveList&) = delete;
  IntrusiveList& operator=(const IntrusiveList&) = delete;

  void push_back(T* p) {
    insert(end(), p);
  }

  Iterator insert(Iterator it, T* p) {
    return InsertBefore(*it, p);
  }

  Iterator InsertBefore(T* pos, T* p) {
    assert(p != nullptr);
    assert(p->next == nullptr);
    assert(p->prev == nullptr);
    assert(pos != nullptr);
    p->prev = pos->prev;
    if (pos == begin_) {
      assert(pos->prev == nullptr);
      begin_ = p;
    } else {
      assert(pos->prev != nullptr);
      p->prev->next = p;
    }
    p->next = pos;
    pos->prev = p;
    return Iterator(p);
  }

  Iterator InsertAfter(T* pos, T* p) {
    assert(p != nullptr);
    assert(p->next == nullptr);
    assert(p->prev == nullptr);
    assert(pos != nullptr);
    assert(pos != &end_sentinel_);
    p->next = pos->next;
    p->next->prev = p;
    p->prev = pos;
    pos->next = p;
    return Iterator(p);
  }

  void Remove(T* pos) {
    SLICER_CHECK_NE(pos, end_);
    if (pos->prev != nullptr) {
      assert(pos != begin_);
      pos->prev->next = pos->next;
    } else {
      assert(pos == begin_);
      begin_ = pos->next;
    }
    assert(pos->next != nullptr);
    pos->next->prev = pos->prev;
    pos->prev = nullptr;
    pos->next = nullptr;
  }

  bool empty() const { return begin_ == end_; }

  Iterator begin() const { return Iterator(begin_); }
  Iterator end() const { return Iterator(end_); }

 private:
  T* begin_ = &end_sentinel_;
  T* const end_ = &end_sentinel_;
  T end_sentinel_;
};

}  // namespace slicer

```

`paccer/jni/slicer/export/slicer/memview.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include "common.h"

#include <assert.h>
#include <stdlib.h>

namespace slicer {

// A shallow, non-owning reference to a "view" inside a memory buffer
class MemView {
 public:
  MemView() : ptr_(nullptr), size_(0) {}

  MemView(const void* ptr, size_t size) : ptr_(ptr), size_(size) {
    assert(size > 0);
  }

  ~MemView() = default;

  template <class T = void>
  const T* ptr() const {
    return static_cast<const T*>(ptr_);
  }

  size_t size() const { return size_; }

 private:
  const void* ptr_;
  size_t size_;
};

} // namespace slicer


```

`paccer/jni/slicer/export/slicer/reader.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include "common.h"
#include "dex_format.h"
#include "dex_ir.h"

#include <assert.h>
#include <stdlib.h>
#include <map>
#include <memory>

namespace dex {

// Provides both a low level iteration over the .dex
// structures and incremental .dex IR creation.
//
// NOTES:
// - only little-endian .dex files and host machines are supported
// - aggresive structure validation & minimal semantic validation
//
class Reader {
 public:
  Reader(const dex::u1* image, size_t size);
  ~Reader() = default;

  // No copy/move semantics
  Reader(const Reader&) = delete;
  Reader& operator=(const Reader&) = delete;

 public:
  // Low level dex format interface
  const dex::Header* Header() const { return header_; }
  const char* GetStringMUTF8(dex::u4 index) const;
  slicer::ArrayView<const dex::ClassDef> ClassDefs() const;
  slicer::ArrayView<const dex::StringId> StringIds() const;
  slicer::ArrayView<const dex::TypeId> TypeIds() const;
  slicer::ArrayView<const dex::FieldId> FieldIds() const;
  slicer::ArrayView<const dex::MethodId> MethodIds() const;
  slicer::ArrayView<const dex::ProtoId> ProtoIds() const;
  slicer::ArrayView<const dex::MethodHandle> MethodHandles() const;
  const dex::MapList* DexMapList() const;

  // IR creation interface
  std::shared_ptr<ir::DexFile> GetIr() const { return dex_ir_; }
  void CreateFullIr();
  void CreateClassIr(dex::u4 index);
  dex::u4 FindClassIndex(const char* class_descriptor) const;

 private:
  // Internal access to IR nodes for indexed .dex structures
  ir::Class* GetClass(dex::u4 index);
  ir::Type* GetType(dex::u4 index);
  ir::FieldDecl* GetFieldDecl(dex::u4 index);
  ir::MethodDecl* GetMethodDecl(dex::u4 index);
  ir::Proto* GetProto(dex::u4 index);
  ir::String* GetString(dex::u4 index);
  ir::MethodHandle* GetMethodHandle(dex::u4 index);

  // Parsing annotations
  ir::AnnotationsDirectory* ExtractAnnotations(dex::u4 offset);
  ir::Annotation* ExtractAnnotationItem(dex::u4 offset);
  ir::AnnotationSet* ExtractAnnotationSet(dex::u4 offset);
  ir::AnnotationSetRefList* ExtractAnnotationSetRefList(dex::u4 offset);
  ir::FieldAnnotation* ParseFieldAnnotation(const dex::u1** pptr);
  ir::MethodAnnotation* ParseMethodAnnotation(const dex::u1** pptr);
  ir::ParamAnnotation* ParseParamAnnotation(const dex::u1** pptr);
  ir::EncodedField* ParseEncodedField(const dex::u1** pptr, dex::u4* baseIndex);
  ir::Annotation* ParseAnnotation(const dex::u1** pptr);
  ir::MethodHandle* ParseMethodHandle(dex::u4 index);

  // Parse encoded values and arrays
  ir::EncodedValue* ParseEncodedValue(const dex::u1** pptr);
  ir::EncodedArray* ParseEncodedArray(const dex::u1** pptr);
  ir::EncodedArray* ExtractEncodedArray(dex::u4 offset);

  // Parse root .dex structures
  ir::Class* ParseClass(dex::u4 index);
  ir::EncodedMethod* ParseEncodedMethod(const dex::u1** pptr, dex::u4* baseIndex);
  ir::Type* ParseType(dex::u4 index);
  ir::FieldDecl* ParseFieldDecl(dex::u4 index);
  ir::MethodDecl* ParseMethodDecl(dex::u4 index);
  ir::TypeList* ExtractTypeList(dex::u4 offset);
  ir::Proto* ParseProto(dex::u4 index);
  ir::String* ParseString(dex::u4 index);

  // Parse code and debug information
  ir::DebugInfo* ExtractDebugInfo(dex::u4 offset);
  ir::Code* ExtractCode(dex::u4 offset);
  void ParseInstructions(slicer::ArrayView<const dex::u2> code);

  // Convert a file pointer (absolute offset) to an in-memory pointer
  template <class T>
  const T* ptr(int offset) const {
    SLICER_CHECK_GE(offset, 0 && offset + sizeof(T) <= size_);
    return reinterpret_cast<const T*>(image_ + offset);
  }

  // Convert a data section file pointer (absolute offset) to an in-memory pointer
  // (offset should be inside the data section)
  template <class T>
  const T* dataPtr(int offset) const {
    SLICER_CHECK_GE(offset, header_->data_off && offset + sizeof(T) <= size_);
    return reinterpret_cast<const T*>(image_ + offset);
  }

  // Map an indexed section to an ArrayView<T>
  template <class T>
  slicer::ArrayView<const T> section(int offset, int count) const {
    return slicer::ArrayView<const T>(ptr<T>(offset), count);
  }

  // Simple accessor for a MUTF8 string data
  const dex::u1* GetStringData(dex::u4 index) const {
    auto& stringId = StringIds()[index];
    return dataPtr<dex::u1>(stringId.string_data_off);
  }

  void ValidateHeader();

 private:
  // the in-memory .dex image
  const dex::u1* image_;
  size_t size_;

  // .dex image header
  const dex::Header* header_;

  // .dex IR associated with the reader
  std::shared_ptr<ir::DexFile> dex_ir_;

  // maps for de-duplicating items identified by file pointers
  std::map<dex::u4, ir::TypeList*> type_lists_;
  std::map<dex::u4, ir::Annotation*> annotations_;
  std::map<dex::u4, ir::AnnotationSet*> annotation_sets_;
  std::map<dex::u4, ir::AnnotationsDirectory*> annotations_directories_;
  std::map<dex::u4, ir::EncodedArray*> encoded_arrays_;
};

}  // namespace dex

```

`paccer/jni/slicer/export/slicer/scopeguard.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include <utility>

namespace slicer {

// A simple and lightweight scope guard and macro
// (inspired by Andrei Alexandrescu's C++11 Scope Guard)
//
// Here is how it's used:
//
//  FILE* file = std::fopen(...);
//  SLICER_SCOPE_EXIT {
//      std::fclose(file);
//  };
//
// "file" will be closed at the end of the enclosing scope,
//  regardless of how the scope is exited
//
class ScopeGuardHelper
{
    template<class T>
    class ScopeGuard
    {
    public:
        explicit ScopeGuard(T closure) :
            closure_(std::move(closure))
        {
        }

        ~ScopeGuard()
        {
            closure_();
        }

        // move constructor only
        ScopeGuard(ScopeGuard&&) = default;
        ScopeGuard(const ScopeGuard&) = delete;
        ScopeGuard& operator=(const ScopeGuard&) = delete;
        ScopeGuard& operator=(ScopeGuard&&) = delete;

    private:
        T closure_;
    };

public:
    template<class T>
    ScopeGuard<T> operator<<(T closure)
    {
        return ScopeGuard<T>(std::move(closure));
    }
};

#define SLICER_SG_MACRO_CONCAT2(a, b) a ## b
#define SLICER_SG_MACRO_CONCAT(a, b) SLICER_SG_MACRO_CONCAT2(a, b)
#define SLICER_SG_ANONYMOUS(prefix)  SLICER_SG_MACRO_CONCAT(prefix, __COUNTER__)

#define SLICER_SCOPE_EXIT \
    auto SLICER_SG_ANONYMOUS(_scope_guard_) = slicer::ScopeGuardHelper() << [&]()

} // namespace slicer


```

`paccer/jni/slicer/export/slicer/tryblocks_encoder.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include "buffer.h"
#include "chronometer.h"
#include "code_ir.h"
#include "common.h"
#include "dex_ir.h"

namespace lir {

// Generates try/catch blocks from code IR
class TryBlocksEncoder : public Visitor {
 private:
  virtual bool Visit(TryBlockEnd* try_end) override;

 public:
  explicit TryBlocksEncoder(const InstructionsList& instructions)
    : instructions_(instructions) {
  }

  ~TryBlocksEncoder() = default;

  void Encode(ir::Code* ir_code, std::shared_ptr<ir::DexFile> dex_ir);

 private:
  slicer::Buffer handlers_;
  slicer::Buffer tries_;
  const InstructionsList& instructions_;
};

} // namespace lir


```

`paccer/jni/slicer/export/slicer/writer.h`:

```h
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#pragma once

#include "arrayview.h"
#include "buffer.h"
#include "common.h"
#include "dex_format.h"
#include "dex_ir.h"

#include <map>
#include <memory>
#include <vector>

namespace dex {

// Specialized buffer for creating a .dex image section
// (tracking the section offset, section type, ...)
class Section : public slicer::Buffer {
 public:
  explicit Section(dex::u2 mapEntryType) : map_entry_type_(mapEntryType) {}
  ~Section() = default;

  Section(const Section&) = delete;
  Section& operator=(const Section&) = delete;

  void SetOffset(dex::u4 offset) {
    SLICER_CHECK_EQ(offset > 0 && offset % 4, 0);
    offset_ = offset;
  }

  dex::u4 SectionOffset() const {
    SLICER_CHECK_EQ(offset_ > 0 && offset_ % 4, 0);
    return ItemsCount() > 0 ? offset_ : 0;
  }

  dex::u4 AbsoluteOffset(dex::u4 itemOffset) const {
    SLICER_CHECK_GT(offset_, 0);
    SLICER_CHECK_LT(itemOffset, size());
    return offset_ + itemOffset;
  }

  // TODO: return absolute offsets?
  dex::u4 AddItem(dex::u4 alignment = 1) {
    ++count_;
    Align(alignment);
    return size();
  }

  dex::u4 ItemsCount() const { return count_; }

  dex::u2 MapEntryType() const { return map_entry_type_; }

 private:
  dex::u4 offset_ = 0;
  dex::u4 count_ = 0;
  const dex::u2 map_entry_type_;
};

// A specialized container for an .dex index section
// (strings, types, fields, methods, ...)
template <class T>
class Index {
 public:
  explicit Index(dex::u2 mapEntryType) : map_entry_type_(mapEntryType) {}
  ~Index() = default;

  Index(const Index&) = delete;
  Index& operator=(const Index&) = delete;

  dex::u4 Init(dex::u4 offset, dex::u4 count) {
    values_.reset(new T[count]);
    offset_ = offset;
    count_ = count;
    return size();
  }

  void Free() {
    values_.reset();
    offset_ = 0;
    count_ = 0;
  }

  dex::u4 SectionOffset() const {
    SLICER_CHECK_EQ(offset_ > 0 && offset_ % 4, 0);
    return ItemsCount() > 0 ? offset_ : 0;
  }

  T* begin() { return values_.get(); }
  T* end() { return begin() + count_; }

  bool empty() const { return count_ == 0; }

  dex::u4 ItemsCount() const { return count_; }
  const T* data() const { return values_.get(); }
  dex::u4 size() const { return count_ * sizeof(T); }

  T& operator[](int i) {
    SLICER_CHECK_GE(i, 0 && i < count_);
    return values_[i];
  }

  dex::u2 MapEntryType() const { return map_entry_type_; }

 private:
  dex::u4 offset_ = 0;
  dex::u4 count_ = 0;
  std::unique_ptr<T[]> values_;
  const dex::u2 map_entry_type_;
};

// Creates an in-memory .dex image from a .dex IR
class Writer {
  // The container for the individual sections in a .dex image
  // (factored out from Writer for a more granular lifetime control)
  struct DexImage {
    DexImage()
        : string_ids(dex::kStringIdItem),
          type_ids(dex::kTypeIdItem),
          proto_ids(dex::kProtoIdItem),
          field_ids(dex::kFieldIdItem),
          method_ids(dex::kMethodIdItem),
          class_defs(dex::kClassDefItem),
          method_handles(dex::kMethodHandleItem),
          string_data(dex::kStringDataItem),
          type_lists(dex::kTypeList),
          debug_info(dex::kDebugInfoItem),
          encoded_arrays(dex::kEncodedArrayItem),
          code(dex::kCodeItem),
          class_data(dex::kClassDataItem),
          ann_directories(dex::kAnnotationsDirectoryItem),
          ann_set_ref_lists(dex::kAnnotationSetRefList),
          ann_sets(dex::kAnnotationSetItem),
          ann_items(dex::kAnnotationItem),
          map_list(dex::kMapList) {}

    Index<dex::StringId> string_ids;
    Index<dex::TypeId> type_ids;
    Index<dex::ProtoId> proto_ids;
    Index<dex::FieldId> field_ids;
    Index<dex::MethodId> method_ids;
    Index<dex::ClassDef> class_defs;
    Index<dex::MethodHandle> method_handles;

    Section string_data;
    Section type_lists;
    Section debug_info;
    Section encoded_arrays;
    Section code;
    Section class_data;
    Section ann_directories;
    Section ann_set_ref_lists;
    Section ann_sets;
    Section ann_items;
    Section map_list;
  };

 public:
  // interface for allocating the final in-memory image
  struct Allocator {
    virtual void* Allocate(size_t size) = 0;
    virtual void Free(void* ptr) = 0;
    virtual ~Allocator() = default;
  };

 public:
  explicit Writer(std::shared_ptr<ir::DexFile> dex_ir) : dex_ir_(dex_ir) {}
  ~Writer() = default;

  Writer(const Writer&) = delete;
  Writer& operator=(const Writer&) = delete;

  // .dex image creation
  dex::u1* CreateImage(Allocator* allocator, size_t* new_image_size);

 private:
  // helpers for creating various .dex sections
  dex::u4 CreateStringDataSection(dex::u4 section_offset);
  dex::u4 CreateMapSection(dex::u4 section_offset);
  dex::u4 CreateAnnItemSection(dex::u4 section_offset);
  dex::u4 CreateAnnSetsSection(dex::u4 section_offset);
  dex::u4 CreateAnnSetRefListsSection(dex::u4 section_offset);
  dex::u4 CreateTypeListsSection(dex::u4 section_offset);
  dex::u4 CreateCodeItemSection(dex::u4 section_offset);
  dex::u4 CreateDebugInfoSection(dex::u4 section_offset);
  dex::u4 CreateClassDataSection(dex::u4 section_offset);
  dex::u4 CreateAnnDirectoriesSection(dex::u4 section_offset);
  dex::u4 CreateEncodedArrayItemSection(dex::u4 section_offset);

  // back-fill the indexes
  void FillTypes();
  void FillProtos();
  void FillFields();
  void FillMethods();
  void FillClassDefs();
  void FillMethodHandles();

  // helpers for writing .dex structures
  dex::u4 WriteTypeList(const std::vector<ir::Type*>& types);
  dex::u4 WriteAnnotationItem(const ir::Annotation* ir_annotation);
  dex::u4 WriteAnnotationSet(const ir::AnnotationSet* ir_annotation_set);
  dex::u4 WriteAnnotationSetRefList(const ir::AnnotationSetRefList* ir_annotation_set_ref_list);
  dex::u4 WriteClassAnnotations(const ir::Class* ir_class);
  dex::u4 WriteDebugInfo(const ir::DebugInfo* ir_debug_info);
  dex::u4 WriteCode(const ir::Code* ir_code);
  dex::u4 WriteClassData(const ir::Class* ir_class);
  dex::u4 WriteClassStaticValues(const ir::Class* ir_class);

  // Map indexes from the original .dex to the
  // corresponding index in the new image
  dex::u4 MapStringIndex(dex::u4 index) const;
  dex::u4 MapTypeIndex(dex::u4 index) const;
  dex::u4 MapFieldIndex(dex::u4 index) const;
  dex::u4 MapMethodIndex(dex::u4 index) const;
  dex::u4 MapProtoIndex(dex::u4 index) const;
  dex::u4 MapMethodHandleIndex(dex::u4 index) const;

  // writing parts of a class definition
  void WriteInstructions(slicer::ArrayView<const dex::u2> instructions);
  void WriteTryBlocks(const ir::Code* ir_code);
  void WriteEncodedField(const ir::EncodedField* irEncodedField, dex::u4* base_index);
  void WriteEncodedMethod(const ir::EncodedMethod* irEncodedMethod, dex::u4* base_index);

  dex::u4 FilePointer(const ir::Node* ir_node) const;

 private:
  std::shared_ptr<ir::DexFile> dex_ir_;
  std::unique_ptr<DexImage> dex_;

  // CONSIDER: we can have multiple maps per IR node type
  //  (that's what the reader does)
  std::map<const ir::Node*, dex::u4> node_offset_;
};

}  // namespace dex

```

`paccer/jni/slicer/instrumentation.cc`:

```cc
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include "slicer/instrumentation.h"

#include "slicer/dex_ir_builder.h"

#include <iomanip>
#include <sstream>

namespace slicer {

namespace {

struct BytecodeConvertingVisitor : public lir::Visitor {
  lir::Bytecode* out = nullptr;
  bool Visit(lir::Bytecode* bytecode) {
    out = bytecode;
    return true;
  }
};

void BoxValue(lir::Bytecode* bytecode,
              lir::CodeIr* code_ir,
              ir::Type* type,
              dex::u4 src_reg,
              dex::u4 dst_reg) {
  bool is_wide = false;
  const char* boxed_type_name = nullptr;
  switch (*(type->descriptor)->c_str()) {
    case 'Z':
      boxed_type_name = "Ljava/lang/Boolean;";
      break;
    case 'B':
      boxed_type_name = "Ljava/lang/Byte;";
      break;
    case 'C':
      boxed_type_name = "Ljava/lang/Character;";
      break;
    case 'S':
      boxed_type_name = "Ljava/lang/Short;";
      break;
    case 'I':
      boxed_type_name = "Ljava/lang/Integer;";
      break;
    case 'J':
      is_wide = true;
      boxed_type_name = "Ljava/lang/Long;";
      break;
    case 'F':
      boxed_type_name = "Ljava/lang/Float;";
      break;
    case 'D':
      is_wide = true;
      boxed_type_name = "Ljava/lang/Double;";
      break;
  }
  SLICER_CHECK_NE(boxed_type_name, nullptr);

  ir::Builder builder(code_ir->dex_ir);
  std::vector<ir::Type*> param_types;
  param_types.push_back(type);

  auto boxed_type = builder.GetType(boxed_type_name);
  auto ir_proto = builder.GetProto(boxed_type, builder.GetTypeList(param_types));

  auto ir_method_decl = builder.GetMethodDecl(
      builder.GetAsciiString("valueOf"), ir_proto, boxed_type);

  auto boxing_method = code_ir->Alloc<lir::Method>(ir_method_decl, ir_method_decl->orig_index);

  auto args = code_ir->Alloc<lir::VRegRange>(src_reg, 1 + is_wide);
  auto boxing_invoke = code_ir->Alloc<lir::Bytecode>();
  boxing_invoke->opcode = dex::OP_INVOKE_STATIC_RANGE;
  boxing_invoke->operands.push_back(args);
  boxing_invoke->operands.push_back(boxing_method);
  code_ir->instructions.InsertBefore(bytecode, boxing_invoke);

  auto move_result = code_ir->Alloc<lir::Bytecode>();
  move_result->opcode = dex::OP_MOVE_RESULT_OBJECT;
  move_result->operands.push_back(code_ir->Alloc<lir::VReg>(dst_reg));
  code_ir->instructions.InsertBefore(bytecode, move_result);
}

std::string MethodLabel(ir::EncodedMethod* ir_method) {
  auto signature_str = ir_method->decl->prototype->Signature();
  return ir_method->decl->parent->Decl() + "->" + ir_method->decl->name->c_str() + signature_str;
}

}  // namespace

bool EntryHook::Apply(lir::CodeIr* code_ir) {
  lir::Bytecode* bytecode = nullptr;
  // find the first bytecode in the method body to insert the hook before it
  for (auto instr : code_ir->instructions) {
    BytecodeConvertingVisitor visitor;
    instr->Accept(&visitor);
    bytecode = visitor.out;
    if (bytecode != nullptr) {
      break;
    }
  }
  if (bytecode == nullptr) {
    return false;
  }
  if (tweak_ == Tweak::ArrayParams) {
    return InjectArrayParamsHook(code_ir, bytecode);
  }

  ir::Builder builder(code_ir->dex_ir);
  const auto ir_method = code_ir->ir_method;

  // construct the hook method declaration
  std::vector<ir::Type*> param_types;
  if ((ir_method->access_flags & dex::kAccStatic) == 0) {
    ir::Type* this_argument_type;
    switch (tweak_) {
      case Tweak::ThisAsObject:
        this_argument_type = builder.GetType("Ljava/lang/Object;");
        break;
      default:
        this_argument_type = ir_method->decl->parent;
        break;
    }
    param_types.push_back(this_argument_type);
  }
  if (ir_method->decl->prototype->param_types != nullptr) {
    const auto& orig_param_types = ir_method->decl->prototype->param_types->types;
    param_types.insert(param_types.end(), orig_param_types.begin(), orig_param_types.end());
  }

  auto ir_proto = builder.GetProto(builder.GetType("V"),
                                   builder.GetTypeList(param_types));

  auto ir_method_decl = builder.GetMethodDecl(
      builder.GetAsciiString(hook_method_id_.method_name), ir_proto,
      builder.GetType(hook_method_id_.class_descriptor));

  auto hook_method = code_ir->Alloc<lir::Method>(ir_method_decl, ir_method_decl->orig_index);

  // argument registers
  auto regs = ir_method->code->registers;
  auto args_count = ir_method->code->ins_count;
  auto args = code_ir->Alloc<lir::VRegRange>(regs - args_count, args_count);

  // invoke hook bytecode
  auto hook_invoke = code_ir->Alloc<lir::Bytecode>();
  hook_invoke->opcode = dex::OP_INVOKE_STATIC_RANGE;
  hook_invoke->operands.push_back(args);
  hook_invoke->operands.push_back(hook_method);

  // insert the hook before the first bytecode in the method body
  code_ir->instructions.InsertBefore(bytecode, hook_invoke);
  return true;
}

void GenerateShiftParamsCode(lir::CodeIr* code_ir, lir::Instruction* position, dex::u4 shift) {
  const auto ir_method = code_ir->ir_method;

  // Since the goal is to relocate the registers when extra scratch registers are needed,
  // if there are no parameters this is a no-op.
  if (ir_method->code->ins_count == 0) {
    return;
  }

  // build a param list with the explicit "this" argument for non-static methods
  std::vector<ir::Type*> param_types;
  if ((ir_method->access_flags & dex::kAccStatic) == 0) {
    param_types.push_back(ir_method->decl->parent);
  }
  if (ir_method->decl->prototype->param_types != nullptr) {
    const auto& orig_param_types = ir_method->decl->prototype->param_types->types;
    param_types.insert(param_types.end(), orig_param_types.begin(), orig_param_types.end());
  }

  const dex::u4 regs = ir_method->code->registers;
  const dex::u4 ins_count = ir_method->code->ins_count;
  SLICER_CHECK_GE(regs, ins_count);

  // generate the args "relocation" instructions
  dex::u4 reg = regs - ins_count;
  for (const auto& type : param_types) {
    auto move = code_ir->Alloc<lir::Bytecode>();
    switch (type->GetCategory()) {
      case ir::Type::Category::Reference:
        move->opcode = dex::OP_MOVE_OBJECT_16;
        move->operands.push_back(code_ir->Alloc<lir::VReg>(reg - shift));
        move->operands.push_back(code_ir->Alloc<lir::VReg>(reg));
        reg += 1;
        break;
      case ir::Type::Category::Scalar:
        move->opcode = dex::OP_MOVE_16;
        move->operands.push_back(code_ir->Alloc<lir::VReg>(reg - shift));
        move->operands.push_back(code_ir->Alloc<lir::VReg>(reg));
        reg += 1;
        break;
      case ir::Type::Category::WideScalar:
        move->opcode = dex::OP_MOVE_WIDE_16;
        move->operands.push_back(code_ir->Alloc<lir::VRegPair>(reg - shift));
        move->operands.push_back(code_ir->Alloc<lir::VRegPair>(reg));
        reg += 2;
        break;
      case ir::Type::Category::Void:
        SLICER_FATAL("void parameter type");
    }
    code_ir->instructions.InsertBefore(position, move);
  }
}

bool EntryHook::InjectArrayParamsHook(lir::CodeIr* code_ir, lir::Bytecode* bytecode) {
  ir::Builder builder(code_ir->dex_ir);
  const auto ir_method = code_ir->ir_method;
  auto param_types_list = ir_method->decl->prototype->param_types;
  auto param_types = param_types_list != nullptr ? param_types_list->types : std::vector<ir::Type*>();
  bool is_static = (ir_method->access_flags & dex::kAccStatic) != 0;

  // number of registers that we need to operate
  dex::u2 regs_count = 3;
  auto non_param_regs = ir_method->code->registers - ir_method->code->ins_count;

  // do we have enough registers to operate?
  bool needsExtraRegs = non_param_regs < regs_count;
  if (needsExtraRegs) {
    // we don't have enough registers, so we allocate more, we will shift
    // params to their original registers later.
    code_ir->ir_method->code->registers += regs_count - non_param_regs;
  }

  // use three first registers:
  // all three are needed when we "aput" a string/boxed-value (1) into an array (2) at an index (3)

  // register that will store size of during allocation
  // later will be reused to store index when do "aput"
  dex::u4 array_size_reg = 0;
  // register that will store an array that will be passed
  // as a parameter in entry hook
  dex::u4 array_reg = 1;
  // stores result of boxing (if it's needed); also stores the method signature string
  dex::u4 value_reg = 2;
  // array size bytecode
  auto const_size_op = code_ir->Alloc<lir::Bytecode>();
  const_size_op->opcode = dex::OP_CONST;
  const_size_op->operands.push_back(code_ir->Alloc<lir::VReg>(array_size_reg));
  const_size_op->operands.push_back(code_ir->Alloc<lir::Const32>(
      2 + param_types.size())); // method signature + params + "this" object
  code_ir->instructions.InsertBefore(bytecode, const_size_op);

  // allocate array
  const auto obj_array_type = builder.GetType("[Ljava/lang/Object;");
  auto allocate_array_op = code_ir->Alloc<lir::Bytecode>();
  allocate_array_op->opcode = dex::OP_NEW_ARRAY;
  allocate_array_op->operands.push_back(code_ir->Alloc<lir::VReg>(array_reg));
  allocate_array_op->operands.push_back(code_ir->Alloc<lir::VReg>(array_size_reg));
  allocate_array_op->operands.push_back(
      code_ir->Alloc<lir::Type>(obj_array_type, obj_array_type->orig_index));
  code_ir->instructions.InsertBefore(bytecode, allocate_array_op);

  // fill the array with parameters passed into function

  std::vector<ir::Type*> types;
  types.push_back(builder.GetType("Ljava/lang/String;")); // method signature string
  if (!is_static) {
    types.push_back(ir_method->decl->parent); // "this" object
  }

  types.insert(types.end(), param_types.begin(), param_types.end()); // parameters

  // register where params start
  dex::u4 current_reg = ir_method->code->registers - ir_method->code->ins_count;
  // reuse not needed anymore register to store indexes
  dex::u4 array_index_reg = array_size_reg;
  int i = 0;
  for (auto type: types) {
    dex::u4 src_reg = 0;
    if (i == 0) { // method signature string
      // e.g. const-string v2, "(I[Ljava/lang/String;)Ljava/lang/String;"
      // for (int, String[]) -> String
      auto const_str_op = code_ir->Alloc<lir::Bytecode>();
      const_str_op->opcode = dex::OP_CONST_STRING;
      const_str_op->operands.push_back(code_ir->Alloc<lir::VReg>(value_reg)); // dst
      auto method_label = builder.GetAsciiString(MethodLabel(ir_method).c_str());
      const_str_op->operands.push_back(
          code_ir->Alloc<lir::String>(method_label, method_label->orig_index)); // src
      code_ir->instructions.InsertBefore(bytecode, const_str_op);
      src_reg = value_reg;
    } else if (type->GetCategory() != ir::Type::Category::Reference) {
      BoxValue(bytecode, code_ir, type, current_reg, value_reg);
      src_reg = value_reg;
      current_reg += 1 + (type->GetCategory() == ir::Type::Category::WideScalar);
    } else {
      src_reg = current_reg;
      current_reg++;
    }

    auto index_const_op = code_ir->Alloc<lir::Bytecode>();
    index_const_op->opcode = dex::OP_CONST;
    index_const_op->operands.push_back(code_ir->Alloc<lir::VReg>(array_index_reg));
    index_const_op->operands.push_back(code_ir->Alloc<lir::Const32>(i++));
    code_ir->instructions.InsertBefore(bytecode, index_const_op);

    auto aput_op = code_ir->Alloc<lir::Bytecode>();
    aput_op->opcode = dex::OP_APUT_OBJECT;
    aput_op->operands.push_back(code_ir->Alloc<lir::VReg>(src_reg));
    aput_op->operands.push_back(code_ir->Alloc<lir::VReg>(array_reg));
    aput_op->operands.push_back(code_ir->Alloc<lir::VReg>(array_index_reg));
    code_ir->instructions.InsertBefore(bytecode, aput_op);

    // if function is static, then jumping over index 1
    //  since null should be be passed in this case
    if (i == 1 && is_static) i++;
  }

  std::vector<ir::Type*> hook_param_types;
  hook_param_types.push_back(obj_array_type);

  auto ir_proto = builder.GetProto(builder.GetType("V"),
                                   builder.GetTypeList(hook_param_types));

  auto ir_method_decl = builder.GetMethodDecl(
      builder.GetAsciiString(hook_method_id_.method_name), ir_proto,
      builder.GetType(hook_method_id_.class_descriptor));

  auto hook_method = code_ir->Alloc<lir::Method>(ir_method_decl, ir_method_decl->orig_index);
  auto args = code_ir->Alloc<lir::VRegRange>(array_reg, 1);
  auto hook_invoke = code_ir->Alloc<lir::Bytecode>();
  hook_invoke->opcode = dex::OP_INVOKE_STATIC_RANGE;
  hook_invoke->operands.push_back(args);
  hook_invoke->operands.push_back(hook_method);
  code_ir->instructions.InsertBefore(bytecode, hook_invoke);

  // clean up registries used by us
  // registers are assigned to a marker value 0xFE_FE_FE_FE (decimal
  // value: -16843010) to help identify use of uninitialized registers.
  for (dex::u2 i = 0; i < regs_count; ++i) {
    auto cleanup = code_ir->Alloc<lir::Bytecode>();
    cleanup->opcode = dex::OP_CONST;
    cleanup->operands.push_back(code_ir->Alloc<lir::VReg>(i));
    cleanup->operands.push_back(code_ir->Alloc<lir::Const32>(0xFEFEFEFE));
    code_ir->instructions.InsertBefore(bytecode, cleanup);
  }

  // now we have to shift params to their original registers
  if (needsExtraRegs) {
    GenerateShiftParamsCode(code_ir, bytecode, regs_count - non_param_regs);
  }
  return true;
}

bool ExitHook::Apply(lir::CodeIr* code_ir) {
  ir::Builder builder(code_ir->dex_ir);
  const auto ir_method = code_ir->ir_method;
  const auto declared_return_type = ir_method->decl->prototype->return_type;
  bool return_as_object = (tweak_ & Tweak::ReturnAsObject) != 0;
  // do we have a void-return method?
  bool return_void = (::strcmp(declared_return_type->descriptor->c_str(), "V") == 0);
  // returnAsObject supports only object return type;
  SLICER_CHECK(!return_as_object ||
      (declared_return_type->GetCategory() == ir::Type::Category::Reference));
  const auto return_type = return_as_object ? builder.GetType("Ljava/lang/Object;")
      : declared_return_type;

  bool pass_method_signature = (tweak_ & Tweak::PassMethodSignature) != 0;
  // construct the hook method declaration
  std::vector<ir::Type*> param_types;
  if (pass_method_signature) {
    param_types.push_back(builder.GetType("Ljava/lang/String;"));
  }
  if (!return_void) {
    param_types.push_back(return_type);
  }

  auto ir_proto = builder.GetProto(return_type, builder.GetTypeList(param_types));

  auto ir_method_decl = builder.GetMethodDecl(
      builder.GetAsciiString(hook_method_id_.method_name), ir_proto,
      builder.GetType(hook_method_id_.class_descriptor));

  auto hook_method = code_ir->Alloc<lir::Method>(ir_method_decl, ir_method_decl->orig_index);

  // find and instrument all return instructions
  for (auto instr : code_ir->instructions) {
    BytecodeConvertingVisitor visitor;
    instr->Accept(&visitor);
    auto bytecode = visitor.out;
    if (bytecode == nullptr) {
      continue;
    }

    dex::Opcode move_result_opcode = dex::OP_NOP;
    dex::u4 reg = 0;
    int reg_count = 0;
    switch (bytecode->opcode) {
      case dex::OP_RETURN_VOID:
        SLICER_CHECK(return_void);
        break;
      case dex::OP_RETURN:
        SLICER_CHECK(!return_void);
        move_result_opcode = dex::OP_MOVE_RESULT;
        reg = bytecode->CastOperand<lir::VReg>(0)->reg;
        reg_count = 1;
        break;
      case dex::OP_RETURN_OBJECT:
        SLICER_CHECK(!return_void);
        move_result_opcode = dex::OP_MOVE_RESULT_OBJECT;
        reg = bytecode->CastOperand<lir::VReg>(0)->reg;
        reg_count = 1;
        break;
      case dex::OP_RETURN_WIDE:
        SLICER_CHECK(!return_void);
        move_result_opcode = dex::OP_MOVE_RESULT_WIDE;
        reg = bytecode->CastOperand<lir::VRegPair>(0)->base_reg;
        reg_count = 2;
        break;
      default:
        // skip the bytecode...
        continue;
    }

    dex::u4 scratch_reg = 0;
    // load method signature into scratch_reg
    if (pass_method_signature) {
      // is there a register that can be overtaken
      bool needsScratchReg = ir_method->code->registers < reg_count + 1;
      if (needsScratchReg) {
        // don't renumber registers underneath us
        slicer::AllocateScratchRegs alloc_regs(1, false);
        alloc_regs.Apply(code_ir);
      }

      // we need use one register before results to put signature there
      // however result starts in register 0, thefore it is shifted
      // to register 1
      if (reg == 0 && bytecode->opcode != dex::OP_RETURN_VOID) {
        auto move_op = code_ir->Alloc<lir::Bytecode>();
        switch (bytecode->opcode) {
          case dex::OP_RETURN_OBJECT:
            move_op->opcode = dex::OP_MOVE_OBJECT_16;
            move_op->operands.push_back(code_ir->Alloc<lir::VReg>(reg + 1));
            move_op->operands.push_back(code_ir->Alloc<lir::VReg>(reg));
            break;
          case dex::OP_RETURN:
            move_op->opcode = dex::OP_MOVE_16;
            move_op->operands.push_back(code_ir->Alloc<lir::VReg>(reg + 1));
            move_op->operands.push_back(code_ir->Alloc<lir::VReg>(reg));
            break;
          case dex::OP_RETURN_WIDE:
            move_op->opcode = dex::OP_MOVE_WIDE_16;
            move_op->operands.push_back(code_ir->Alloc<lir::VRegPair>(reg + 1));
            move_op->operands.push_back(code_ir->Alloc<lir::VRegPair>(reg));
            break;
          default: {
              std::stringstream ss;
              ss <<"Unexpected bytecode opcode: " << bytecode->opcode;
              SLICER_FATAL(ss.str());
            }
        }
        code_ir->instructions.InsertBefore(bytecode, move_op);
        // return is the last call, return is shifted to one, so taking over 0 registry
        scratch_reg = 0;
      } else {
        // return is the last call, so we're taking over previous registry
        scratch_reg = bytecode->opcode == dex::OP_RETURN_VOID ? 0 : reg - 1;
      }


      // return is the last call, so we're taking over previous registry
      auto method_label = builder.GetAsciiString(MethodLabel(ir_method).c_str());
      auto const_str_op = code_ir->Alloc<lir::Bytecode>();
      const_str_op->opcode = dex::OP_CONST_STRING;
      const_str_op->operands.push_back(code_ir->Alloc<lir::VReg>(scratch_reg)); // dst
      const_str_op->operands.push_back(code_ir->Alloc<lir::String>(method_label, method_label->orig_index)); // src
      code_ir->instructions.InsertBefore(bytecode, const_str_op);
    }

    auto args = pass_method_signature
        ? code_ir->Alloc<lir::VRegRange>(scratch_reg, reg_count + 1)
        : code_ir->Alloc<lir::VRegRange>(reg, reg_count);
    auto hook_invoke = code_ir->Alloc<lir::Bytecode>();
    hook_invoke->opcode = dex::OP_INVOKE_STATIC_RANGE;
    hook_invoke->operands.push_back(args);
    hook_invoke->operands.push_back(hook_method);
    code_ir->instructions.InsertBefore(bytecode, hook_invoke);

    // move result back to the right register
    //
    // NOTE: we're reusing the original return's operand,
    //   which is valid and more efficient than allocating
    //   a new LIR node, but it's also fragile: we need to be
    //   very careful about mutating shared nodes.
    //
    if (move_result_opcode != dex::OP_NOP) {
      auto move_result = code_ir->Alloc<lir::Bytecode>();
      move_result->opcode = move_result_opcode;
      move_result->operands.push_back(bytecode->operands[0]);
      code_ir->instructions.InsertBefore(bytecode, move_result);

      if ((tweak_ & Tweak::ReturnAsObject) != 0) {
        auto check_cast = code_ir->Alloc<lir::Bytecode>();
        check_cast->opcode = dex::OP_CHECK_CAST;
        check_cast->operands.push_back(code_ir->Alloc<lir::VReg>(reg));
        check_cast->operands.push_back(
            code_ir->Alloc<lir::Type>(declared_return_type, declared_return_type->orig_index));
        code_ir->instructions.InsertBefore(bytecode, check_cast);
      }
    }
  }

  return true;
}

bool DetourHook::Apply(lir::CodeIr* code_ir) {
  ir::Builder builder(code_ir->dex_ir);

  // search for matching invoke-virtual[/range] bytecodes
  for (auto instr : code_ir->instructions) {
    BytecodeConvertingVisitor visitor;
    instr->Accept(&visitor);
    auto bytecode = visitor.out;
    if (bytecode == nullptr) {
      continue;
    }

    dex::Opcode new_call_opcode = GetNewOpcode(bytecode->opcode);
    if (new_call_opcode == dex::OP_NOP) {
      continue;
    }

    auto orig_method = bytecode->CastOperand<lir::Method>(1)->ir_method;
    if (!orig_method_id_.Match(orig_method)) {
      // this is not the method you're looking for...
      continue;
    }

    // construct the detour method declaration
    // (matching the original method, plus an explicit "this" argument)
    std::vector<ir::Type*> param_types;
    param_types.push_back(orig_method->parent);
    if (orig_method->prototype->param_types != nullptr) {
      const auto& orig_param_types = orig_method->prototype->param_types->types;
      param_types.insert(param_types.end(), orig_param_types.begin(),
                         orig_param_types.end());
    }

    auto ir_proto = builder.GetProto(orig_method->prototype->return_type,
                                     builder.GetTypeList(param_types));

    auto ir_method_decl = builder.GetMethodDecl(
        builder.GetAsciiString(detour_method_id_.method_name), ir_proto,
        builder.GetType(detour_method_id_.class_descriptor));

    auto detour_method =
        code_ir->Alloc<lir::Method>(ir_method_decl, ir_method_decl->orig_index);

    // We mutate the original invoke bytecode in-place: this is ok
    // because lir::Instructions can't be shared (referenced multiple times)
    // in the code IR. It's also simpler and more efficient than allocating a
    // new IR invoke bytecode.
    bytecode->opcode = new_call_opcode;
    bytecode->operands[1] = detour_method;
  }

  return true;
}

dex::Opcode DetourVirtualInvoke::GetNewOpcode(dex::Opcode opcode) {
  switch (opcode) {
    case dex::OP_INVOKE_VIRTUAL:
      return dex::OP_INVOKE_STATIC;
    case dex::OP_INVOKE_VIRTUAL_RANGE:
      return dex::OP_INVOKE_STATIC_RANGE;
    default:
      // skip instruction ...
      return dex::OP_NOP;
  }
}

dex::Opcode DetourInterfaceInvoke::GetNewOpcode(dex::Opcode opcode) {
  switch (opcode) {
    case dex::OP_INVOKE_INTERFACE:
      return dex::OP_INVOKE_STATIC;
    case dex::OP_INVOKE_INTERFACE_RANGE:
      return dex::OP_INVOKE_STATIC_RANGE;
    default:
      // skip instruction ...
      return dex::OP_NOP;
  }
}

// Register re-numbering visitor
// (renumbers vN to vN+shift)
class RegsRenumberVisitor : public lir::Visitor {
 public:
  explicit RegsRenumberVisitor(int shift) : shift_(shift) {
    SLICER_CHECK_GT(shift, 0);
  }

 private:
  virtual bool Visit(lir::Bytecode* bytecode) override {
    for (auto operand : bytecode->operands) {
      operand->Accept(this);
    }
    return true;
  }

  virtual bool Visit(lir::DbgInfoAnnotation* dbg_annotation) override {
    for (auto operand : dbg_annotation->operands) {
      operand->Accept(this);
    }
    return true;
  }

  virtual bool Visit(lir::VReg* vreg) override {
    vreg->reg += shift_;
    return true;
  }

  virtual bool Visit(lir::VRegPair* vreg_pair) override {
    vreg_pair->base_reg += shift_;
    return true;
  }

  virtual bool Visit(lir::VRegList* vreg_list) override {
    for (auto& reg : vreg_list->registers) {
      reg += shift_;
    }
    return true;
  }

  virtual bool Visit(lir::VRegRange* vreg_range) override {
    vreg_range->base_reg += shift_;
    return true;
  }

 private:
  int shift_ = 0;
};

// Try to allocate registers by renumbering the existing allocation
//
// NOTE: we can't bump the register count over 16 since it may
//  make existing bytecodes "unencodable" (if they have 4 bit reg fields)
//
void AllocateScratchRegs::RegsRenumbering(lir::CodeIr* code_ir) {
  SLICER_CHECK_GT(left_to_allocate_, 0);
  int delta = std::min(left_to_allocate_,
                       16 - static_cast<int>(code_ir->ir_method->code->registers));
  if (delta < 1) {
    // can't allocate any registers through renumbering
    return;
  }
  assert(delta <= 16);

  // renumber existing registers
  RegsRenumberVisitor visitor(delta);
  for (auto instr : code_ir->instructions) {
    instr->Accept(&visitor);
  }

  // we just allocated "delta" registers (v0..vX)
  Allocate(code_ir, 0, delta);
}

// Allocates registers by generating prologue code to relocate params
// into their original registers (parameters are allocated in the last IN registers)
//
// There are three types of register moves depending on the value type:
// 1. vreg -> vreg
// 2. vreg/wide -> vreg/wide
// 3. vreg/obj -> vreg/obj
//
void AllocateScratchRegs::ShiftParams(lir::CodeIr* code_ir) {
  const auto ir_method = code_ir->ir_method;
  SLICER_CHECK_GT(left_to_allocate_, 0);

  const dex::u4 shift = left_to_allocate_;
  Allocate(code_ir, ir_method->code->registers, left_to_allocate_);
  assert(left_to_allocate_ == 0);

  // generate the args "relocation" instructions
  auto first_instr = *(code_ir->instructions.begin());
  GenerateShiftParamsCode(code_ir, first_instr, shift);
}

// Mark [first_reg, first_reg + count) as scratch registers
void AllocateScratchRegs::Allocate(lir::CodeIr* code_ir, dex::u4 first_reg, int count) {
  SLICER_CHECK(count > 0 && count <= left_to_allocate_);
  code_ir->ir_method->code->registers += count;
  left_to_allocate_ -= count;
  for (int i = 0; i < count; ++i) {
    SLICER_CHECK(scratch_regs_.insert(first_reg + i).second);
  }
}

// Allocate scratch registers without doing a full register allocation:
//
// 1. if there are not params, increase the method regs count and we're done
// 2. if the method uses less than 16 registers, we can renumber the existing registers
// 3. if we still have registers to allocate, increase the method registers count,
//     and generate prologue code to shift the param regs into their original registers
//
bool AllocateScratchRegs::Apply(lir::CodeIr* code_ir) {
  const auto code = code_ir->ir_method->code;
  // .dex bytecode allows up to 64k vregs
  SLICER_CHECK_LE(code->registers + allocate_count_, (1 << 16));

  scratch_regs_.clear();
  left_to_allocate_ = allocate_count_;

  // can we allocate by simply incrementing the method regs count?
  if (code->ins_count == 0) {
    Allocate(code_ir, code->registers, left_to_allocate_);
    return true;
  }

  // allocate as many registers as possible using renumbering
  if (allow_renumbering_) {
    RegsRenumbering(code_ir);
  }

  // if we still have registers to allocate, generate prologue
  // code to shift the params into their original registers
  if (left_to_allocate_ > 0) {
    ShiftParams(code_ir);
  }

  assert(left_to_allocate_ == 0);
  assert(scratch_regs_.size() == size_t(allocate_count_));
  return true;
}

bool MethodInstrumenter::InstrumentMethod(ir::EncodedMethod* ir_method) {
  SLICER_CHECK_NE(ir_method, nullptr);
  if (ir_method->code == nullptr) {
    // can't instrument abstract methods
    return false;
  }

  // apply all the queued transformations
  lir::CodeIr code_ir(ir_method, dex_ir_);
  for (const auto& transformation : transformations_) {
    if (!transformation->Apply(&code_ir)) {
      // the transformation failed, bail out...
      return false;
    }
  }
  code_ir.Assemble();
  return true;
}

bool MethodInstrumenter::InstrumentMethod(const ir::MethodId& method_id) {
  // locate the method to be instrumented
  ir::Builder builder(dex_ir_);
  auto ir_method = builder.FindMethod(method_id);
  if (ir_method == nullptr) {
    // we couldn't find the specified method
    return false;
  }
  return InstrumentMethod(ir_method);
}

}  // namespace slicer

```

`paccer/jni/slicer/reader.cc`:

```cc
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include "slicer/reader.h"

#include "slicer/chronometer.h"
#include "slicer/dex_bytecode.h"
#include "slicer/dex_leb128.h"

#include <assert.h>
#include <string.h>
#include <cstdio>
#include <type_traits>
#include <cstdlib>

namespace dex {

Reader::Reader(const dex::u1* image, size_t size) : image_(image), size_(size) {
  // init the header reference
  header_ = ptr<dex::Header>(0);
  ValidateHeader();

  // start with an "empty" .dex IR
  dex_ir_ = std::make_shared<ir::DexFile>();
  dex_ir_->magic = slicer::MemView(header_, sizeof(dex::Header::magic));
}

slicer::ArrayView<const dex::ClassDef> Reader::ClassDefs() const {
  return section<dex::ClassDef>(header_->class_defs_off,
                                header_->class_defs_size);
}

slicer::ArrayView<const dex::StringId> Reader::StringIds() const {
  return section<dex::StringId>(header_->string_ids_off,
                                header_->string_ids_size);
}

slicer::ArrayView<const dex::TypeId> Reader::TypeIds() const {
  return section<dex::TypeId>(header_->type_ids_off,
                              header_->type_ids_size);
}

slicer::ArrayView<const dex::FieldId> Reader::FieldIds() const {
  return section<dex::FieldId>(header_->field_ids_off,
                               header_->field_ids_size);
}

slicer::ArrayView<const dex::MethodId> Reader::MethodIds() const {
  return section<dex::MethodId>(header_->method_ids_off,
                                header_->method_ids_size);
}

slicer::ArrayView<const dex::ProtoId> Reader::ProtoIds() const {
  return section<dex::ProtoId>(header_->proto_ids_off,
                               header_->proto_ids_size);
}

slicer::ArrayView<const dex::MethodHandle> Reader::MethodHandles() const {
  const dex::MapList* ml = DexMapList();
  if(ml == nullptr){
    slicer::ArrayView<const dex::MethodHandle> ret;
    return ret;
  }

  // Find MethodHandle entry
  const dex::MapItem* mi = nullptr;
  for(int i = 0; i < ml->size; i++){
    if(ml->list[i].type == dex::kMethodHandleItem){
      mi = &(ml->list[i]);
      break;
    }
  }

  if(mi == nullptr){
    slicer::ArrayView<const dex::MethodHandle> ret;
    return ret;
  }

  return section<dex::MethodHandle>(mi->offset, mi->size);
}

const dex::MapList* Reader::DexMapList() const {
  return dataPtr<dex::MapList>(header_->map_off);
}

const char* Reader::GetStringMUTF8(dex::u4 index) const {
  if (index == dex::kNoIndex) {
    return "<no_string>";
  }
  const dex::u1* strData = GetStringData(index);
  dex::ReadULeb128(&strData);
  return reinterpret_cast<const char*>(strData);
}

void Reader::CreateFullIr() {
  size_t classCount = ClassDefs().size();
  for (size_t i = 0; i < classCount; ++i) {
    CreateClassIr(i);
  }
}

void Reader::CreateClassIr(dex::u4 index) {
  auto ir_class = GetClass(index);
  SLICER_CHECK_NE(ir_class, nullptr);
}

// Returns the index of the class with the specified
// descriptor, or kNoIndex if not found
dex::u4 Reader::FindClassIndex(const char* class_descriptor) const {
  auto classes = ClassDefs();
  auto types = TypeIds();
  for (dex::u4 i = 0; i < classes.size(); ++i) {
    auto typeId = types[classes[i].class_idx];
    const char* descriptor = GetStringMUTF8(typeId.descriptor_idx);
    if (strcmp(class_descriptor, descriptor) == 0) {
      return i;
    }
  }
  return dex::kNoIndex;
}

// map a .dex index to corresponding .dex IR node
//
// NOTES:
//  1. the mapping between an index and the indexed
//     .dex IR nodes is 1:1
//  2. we do a single index lookup for both existing
//     nodes as well as new nodes
//  3. placeholder is an invalid, but non-null pointer value
//     used to check that the mapping lookup/update is atomic
//  4. there should be no recursion with the same index
//     (we use the placeholder value to guard against this too)
//
ir::Class* Reader::GetClass(dex::u4 index) {
  SLICER_CHECK_NE(index, dex::kNoIndex);
  auto& p = dex_ir_->classes_map[index];
  auto placeholder = reinterpret_cast<ir::Class*>(1);
  if (p == nullptr) {
    p = placeholder;
    auto newClass = ParseClass(index);
    SLICER_CHECK_EQ(p, placeholder);
    p = newClass;
    dex_ir_->classes_indexes.MarkUsedIndex(index);
  }
  SLICER_CHECK_NE(p, placeholder);
  return p;
}

// map a .dex index to corresponding .dex IR node
// (see the Reader::GetClass() comments)
ir::Type* Reader::GetType(dex::u4 index) {
  SLICER_CHECK_NE(index, dex::kNoIndex);
  auto& p = dex_ir_->types_map[index];
  auto placeholder = reinterpret_cast<ir::Type*>(1);
  if (p == nullptr) {
    p = placeholder;
    auto newType = ParseType(index);
    SLICER_CHECK_EQ(p, placeholder);
    p = newType;
    dex_ir_->types_indexes.MarkUsedIndex(index);
  }
  SLICER_CHECK_NE(p, placeholder);
  return p;
}

// map a .dex index to corresponding .dex IR node
// (see the Reader::GetClass() comments)
ir::FieldDecl* Reader::GetFieldDecl(dex::u4 index) {
  SLICER_CHECK_NE(index, dex::kNoIndex);
  auto& p = dex_ir_->fields_map[index];
  auto placeholder = reinterpret_cast<ir::FieldDecl*>(1);
  if (p == nullptr) {
    p = placeholder;
    auto newField = ParseFieldDecl(index);
    SLICER_CHECK_EQ(p, placeholder);
    p = newField;
    dex_ir_->fields_indexes.MarkUsedIndex(index);
  }
  SLICER_CHECK_NE(p, placeholder);
  return p;
}

ir::MethodHandle* Reader::GetMethodHandle(dex::u4 index){
  SLICER_CHECK_NE(index, dex::kNoIndex);
  auto& p = dex_ir_->method_handles_map[index];
  auto placeholder = reinterpret_cast<ir::MethodHandle*>(1);
  if(p == nullptr) {
    p = placeholder;
    auto newMethodHandle = ParseMethodHandle(index);
    SLICER_CHECK_EQ(p, placeholder);
    p = newMethodHandle;
    dex_ir_->method_handle_indexes.MarkUsedIndex(index);
  }

  SLICER_CHECK_NE(p, placeholder);
  return p;
}

// map a .dex index to corresponding .dex IR node
// (see the Reader::GetClass() comments)
ir::MethodDecl* Reader::GetMethodDecl(dex::u4 index) {
  SLICER_CHECK_NE(index, dex::kNoIndex);
  auto& p = dex_ir_->methods_map[index];
  auto placeholder = reinterpret_cast<ir::MethodDecl*>(1);
  if (p == nullptr) {
    p = placeholder;
    auto newMethod = ParseMethodDecl(index);
    SLICER_CHECK_EQ(p, placeholder);
    p = newMethod;
    dex_ir_->methods_indexes.MarkUsedIndex(index);
  }
  SLICER_CHECK_NE(p, placeholder);
  return p;
}

// map a .dex index to corresponding .dex IR node
// (see the Reader::GetClass() comments)
ir::Proto* Reader::GetProto(dex::u4 index) {
  SLICER_CHECK_NE(index, dex::kNoIndex);
  auto& p = dex_ir_->protos_map[index];
  auto placeholder = reinterpret_cast<ir::Proto*>(1);
  if (p == nullptr) {
    p = placeholder;
    auto newProto = ParseProto(index);
    SLICER_CHECK_EQ(p, placeholder);
    p = newProto;
    dex_ir_->protos_indexes.MarkUsedIndex(index);
  }
  SLICER_CHECK_NE(p, placeholder);
  return p;
}

// map a .dex index to corresponding .dex IR node
// (see the Reader::GetClass() comments)
ir::String* Reader::GetString(dex::u4 index) {
  SLICER_CHECK_NE(index, dex::kNoIndex);
  auto& p = dex_ir_->strings_map[index];
  auto placeholder = reinterpret_cast<ir::String*>(1);
  if (p == nullptr) {
    p = placeholder;
    auto newString = ParseString(index);
    SLICER_CHECK_EQ(p, placeholder);
    p = newString;
    dex_ir_->strings_indexes.MarkUsedIndex(index);
  }
  SLICER_CHECK_NE(p, placeholder);
  return p;
}

ir::Class* Reader::ParseClass(dex::u4 index) {
  auto& dex_class_def = ClassDefs()[index];
  auto ir_class = dex_ir_->Alloc<ir::Class>();

  ir_class->type = GetType(dex_class_def.class_idx);
  assert(ir_class->type->class_def == nullptr);
  ir_class->type->class_def = ir_class;

  ir_class->access_flags = dex_class_def.access_flags;
  ir_class->interfaces = ExtractTypeList(dex_class_def.interfaces_off);

  if (dex_class_def.superclass_idx != dex::kNoIndex) {
    ir_class->super_class = GetType(dex_class_def.superclass_idx);
  }

  if (dex_class_def.source_file_idx != dex::kNoIndex) {
    ir_class->source_file = GetString(dex_class_def.source_file_idx);
  }

  if (dex_class_def.class_data_off != 0) {
    const dex::u1* class_data = dataPtr<dex::u1>(dex_class_def.class_data_off);

    dex::u4 static_fields_count = dex::ReadULeb128(&class_data);
    dex::u4 instance_fields_count = dex::ReadULeb128(&class_data);
    dex::u4 direct_methods_count = dex::ReadULeb128(&class_data);
    dex::u4 virtual_methods_count = dex::ReadULeb128(&class_data);

    dex::u4 base_index = dex::kNoIndex;
    for (dex::u4 i = 0; i < static_fields_count; ++i) {
      auto field = ParseEncodedField(&class_data, &base_index);
      ir_class->static_fields.push_back(field);
    }

    base_index = dex::kNoIndex;
    for (dex::u4 i = 0; i < instance_fields_count; ++i) {
      auto field = ParseEncodedField(&class_data, &base_index);
      ir_class->instance_fields.push_back(field);
    }

    base_index = dex::kNoIndex;
    for (dex::u4 i = 0; i < direct_methods_count; ++i) {
      auto method = ParseEncodedMethod(&class_data, &base_index);
      ir_class->direct_methods.push_back(method);
    }

    base_index = dex::kNoIndex;
    for (dex::u4 i = 0; i < virtual_methods_count; ++i) {
      auto method = ParseEncodedMethod(&class_data, &base_index);
      ir_class->virtual_methods.push_back(method);
    }
  }

  ir_class->static_init = ExtractEncodedArray(dex_class_def.static_values_off);
  ir_class->annotations = ExtractAnnotations(dex_class_def.annotations_off);
  ir_class->orig_index = index;

  return ir_class;
}

ir::AnnotationsDirectory* Reader::ExtractAnnotations(dex::u4 offset) {
  if (offset == 0) {
    return nullptr;
  }

  SLICER_CHECK_EQ(offset % 4, 0);

  // first check if we already extracted the same "annotations_directory_item"
  auto& ir_annotations = annotations_directories_[offset];
  if (ir_annotations == nullptr) {
    ir_annotations = dex_ir_->Alloc<ir::AnnotationsDirectory>();

    auto dex_annotations = dataPtr<dex::AnnotationsDirectoryItem>(offset);

    ir_annotations->class_annotation =
        ExtractAnnotationSet(dex_annotations->class_annotations_off);

    const dex::u1* ptr = reinterpret_cast<const dex::u1*>(dex_annotations + 1);

    for (dex::u4 i = 0; i < dex_annotations->fields_size; ++i) {
      ir_annotations->field_annotations.push_back(ParseFieldAnnotation(&ptr));
    }

    for (dex::u4 i = 0; i < dex_annotations->methods_size; ++i) {
      ir_annotations->method_annotations.push_back(ParseMethodAnnotation(&ptr));
    }

    for (dex::u4 i = 0; i < dex_annotations->parameters_size; ++i) {
      ir_annotations->param_annotations.push_back(ParseParamAnnotation(&ptr));
    }
  }
  return ir_annotations;
}

ir::Annotation* Reader::ExtractAnnotationItem(dex::u4 offset) {
  SLICER_CHECK_NE(offset, 0);

  // first check if we already extracted the same "annotation_item"
  auto& ir_annotation = annotations_[offset];
  if (ir_annotation == nullptr) {
    auto dexAnnotationItem = dataPtr<dex::AnnotationItem>(offset);
    const dex::u1* ptr = dexAnnotationItem->annotation;
    ir_annotation = ParseAnnotation(&ptr);
    ir_annotation->visibility = dexAnnotationItem->visibility;
  }
  return ir_annotation;
}

ir::AnnotationSet* Reader::ExtractAnnotationSet(dex::u4 offset) {
  if (offset == 0) {
    return nullptr;
  }

  SLICER_CHECK_EQ(offset % 4, 0);

  // first check if we already extracted the same "annotation_set_item"
  auto& ir_annotation_set = annotation_sets_[offset];
  if (ir_annotation_set == nullptr) {
    ir_annotation_set = dex_ir_->Alloc<ir::AnnotationSet>();

    auto dex_annotation_set = dataPtr<dex::AnnotationSetItem>(offset);
    for (dex::u4 i = 0; i < dex_annotation_set->size; ++i) {
      auto ir_annotation = ExtractAnnotationItem(dex_annotation_set->entries[i]);
      assert(ir_annotation != nullptr);
      ir_annotation_set->annotations.push_back(ir_annotation);
    }
  }
  return ir_annotation_set;
}

ir::AnnotationSetRefList* Reader::ExtractAnnotationSetRefList(dex::u4 offset) {
  SLICER_CHECK_EQ(offset % 4, 0);

  auto dex_annotation_set_ref_list = dataPtr<dex::AnnotationSetRefList>(offset);
  auto ir_annotation_set_ref_list = dex_ir_->Alloc<ir::AnnotationSetRefList>();

  for (dex::u4 i = 0; i < dex_annotation_set_ref_list->size; ++i) {
    dex::u4 entry_offset = dex_annotation_set_ref_list->list[i].annotations_off;
    if (entry_offset != 0) {
      auto ir_annotation_set = ExtractAnnotationSet(entry_offset);
      SLICER_CHECK_NE(ir_annotation_set, nullptr);
      ir_annotation_set_ref_list->annotations.push_back(ir_annotation_set);
    }
  }

  return ir_annotation_set_ref_list;
}

ir::FieldAnnotation* Reader::ParseFieldAnnotation(const dex::u1** pptr) {
  auto dex_field_annotation = reinterpret_cast<const dex::FieldAnnotationsItem*>(*pptr);
  auto ir_field_annotation = dex_ir_->Alloc<ir::FieldAnnotation>();

  ir_field_annotation->field_decl = GetFieldDecl(dex_field_annotation->field_idx);

  ir_field_annotation->annotations =
      ExtractAnnotationSet(dex_field_annotation->annotations_off);
  SLICER_CHECK_NE(ir_field_annotation->annotations, nullptr);

  *pptr += sizeof(dex::FieldAnnotationsItem);
  return ir_field_annotation;
}

ir::MethodAnnotation* Reader::ParseMethodAnnotation(const dex::u1** pptr) {
  auto dex_method_annotation =
      reinterpret_cast<const dex::MethodAnnotationsItem*>(*pptr);
  auto ir_method_annotation = dex_ir_->Alloc<ir::MethodAnnotation>();

  ir_method_annotation->method_decl = GetMethodDecl(dex_method_annotation->method_idx);

  ir_method_annotation->annotations =
      ExtractAnnotationSet(dex_method_annotation->annotations_off);
  SLICER_CHECK_NE(ir_method_annotation->annotations, nullptr);

  *pptr += sizeof(dex::MethodAnnotationsItem);
  return ir_method_annotation;
}

ir::ParamAnnotation* Reader::ParseParamAnnotation(const dex::u1** pptr) {
  auto dex_param_annotation =
      reinterpret_cast<const dex::ParameterAnnotationsItem*>(*pptr);
  auto ir_param_annotation = dex_ir_->Alloc<ir::ParamAnnotation>();

  ir_param_annotation->method_decl = GetMethodDecl(dex_param_annotation->method_idx);

  ir_param_annotation->annotations =
      ExtractAnnotationSetRefList(dex_param_annotation->annotations_off);
  SLICER_CHECK_NE(ir_param_annotation->annotations, nullptr);

  *pptr += sizeof(dex::ParameterAnnotationsItem);
  return ir_param_annotation;
}

ir::EncodedField* Reader::ParseEncodedField(const dex::u1** pptr, dex::u4* base_index) {
  auto ir_encoded_field = dex_ir_->Alloc<ir::EncodedField>();

  auto field_index = dex::ReadULeb128(pptr);
  SLICER_CHECK_NE(field_index, dex::kNoIndex);
  if (*base_index != dex::kNoIndex) {
    SLICER_CHECK_NE(field_index, 0);
    field_index += *base_index;
  }
  *base_index = field_index;

  ir_encoded_field->decl = GetFieldDecl(field_index);
  ir_encoded_field->access_flags = dex::ReadULeb128(pptr);

  return ir_encoded_field;
}

// Parse an encoded variable-length integer value
// (sign-extend signed types, zero-extend unsigned types)
template <class T>
static T ParseIntValue(const dex::u1** pptr, size_t size) {
  static_assert(std::is_integral<T>::value, "must be an integral type");

  SLICER_CHECK_GT(size, 0);
  SLICER_CHECK_LE(size, sizeof(T));

  T value = 0;
  for (int i = 0; i < size; ++i) {
    value |= T(*(*pptr)++) << (i * 8);
  }

  // sign-extend?
  if (std::is_signed<T>::value) {
    size_t shift = (sizeof(T) - size) * 8;
    value = T(value << shift) >> shift;
  }

  return value;
}

// Parse an encoded variable-length floating point value
// (zero-extend to the right)
template <class T>
static T ParseFloatValue(const dex::u1** pptr, size_t size) {
  SLICER_CHECK_GT(size, 0);
  SLICER_CHECK_LE(size, sizeof(T));

  T value = 0;
  int start_byte = sizeof(T) - size;
  for (dex::u1* p = reinterpret_cast<dex::u1*>(&value) + start_byte; size > 0;
       --size) {
    *p++ = *(*pptr)++;
  }
  return value;
}

ir::EncodedValue* Reader::ParseEncodedValue(const dex::u1** pptr) {
  auto ir_encoded_value = dex_ir_->Alloc<ir::EncodedValue>();

  SLICER_EXTRA(auto base_ptr = *pptr);

  dex::u1 header = *(*pptr)++;
  dex::u1 type = header & dex::kEncodedValueTypeMask;
  dex::u1 arg = header >> dex::kEncodedValueArgShift;

  ir_encoded_value->type = type;

  switch (type) {
    case dex::kEncodedByte:
      ir_encoded_value->u.byte_value = ParseIntValue<int8_t>(pptr, arg + 1);
      break;

    case dex::kEncodedShort:
      ir_encoded_value->u.short_value = ParseIntValue<int16_t>(pptr, arg + 1);
      break;

    case dex::kEncodedChar:
      ir_encoded_value->u.char_value = ParseIntValue<uint16_t>(pptr, arg + 1);
      break;

    case dex::kEncodedInt:
      ir_encoded_value->u.int_value = ParseIntValue<int32_t>(pptr, arg + 1);
      break;

    case dex::kEncodedLong:
      ir_encoded_value->u.long_value = ParseIntValue<int64_t>(pptr, arg + 1);
      break;

    case dex::kEncodedFloat:
      ir_encoded_value->u.float_value = ParseFloatValue<float>(pptr, arg + 1);
      break;

    case dex::kEncodedDouble:
      ir_encoded_value->u.double_value = ParseFloatValue<double>(pptr, arg + 1);
      break;

    case dex::kEncodedString: {
      dex::u4 index = ParseIntValue<dex::u4>(pptr, arg + 1);
      ir_encoded_value->u.string_value = GetString(index);
    } break;

    case dex::kEncodedType: {
      dex::u4 index = ParseIntValue<dex::u4>(pptr, arg + 1);
      ir_encoded_value->u.type_value = GetType(index);
    } break;

    case dex::kEncodedField: {
      dex::u4 index = ParseIntValue<dex::u4>(pptr, arg + 1);
      ir_encoded_value->u.field_value = GetFieldDecl(index);
    } break;

    case dex::kEncodedMethod: {
      dex::u4 index = ParseIntValue<dex::u4>(pptr, arg + 1);
      ir_encoded_value->u.method_value = GetMethodDecl(index);
    } break;

    case dex::kEncodedEnum: {
      dex::u4 index = ParseIntValue<dex::u4>(pptr, arg + 1);
      ir_encoded_value->u.enum_value = GetFieldDecl(index);
    } break;

    case dex::kEncodedArray:
      SLICER_CHECK_EQ(arg, 0);
      ir_encoded_value->u.array_value = ParseEncodedArray(pptr);
      break;

    case dex::kEncodedAnnotation:
      SLICER_CHECK_EQ(arg, 0);
      ir_encoded_value->u.annotation_value = ParseAnnotation(pptr);
      break;

    case dex::kEncodedNull:
      SLICER_CHECK_EQ(arg, 0);
      break;

    case dex::kEncodedBoolean:
      SLICER_CHECK_LT(arg, 2);
      ir_encoded_value->u.bool_value = (arg == 1);
      break;

    default:
      SLICER_CHECK(!"unexpected value type");
  }

  SLICER_EXTRA(ir_encoded_value->original = slicer::MemView(base_ptr, *pptr - base_ptr));

  return ir_encoded_value;
}

ir::Annotation* Reader::ParseAnnotation(const dex::u1** pptr) {
  auto ir_annotation = dex_ir_->Alloc<ir::Annotation>();

  dex::u4 type_index = dex::ReadULeb128(pptr);
  dex::u4 elements_count = dex::ReadULeb128(pptr);

  ir_annotation->type = GetType(type_index);
  ir_annotation->visibility = dex::kVisibilityEncoded;

  for (dex::u4 i = 0; i < elements_count; ++i) {
    auto ir_element = dex_ir_->Alloc<ir::AnnotationElement>();

    ir_element->name = GetString(dex::ReadULeb128(pptr));
    ir_element->value = ParseEncodedValue(pptr);

    ir_annotation->elements.push_back(ir_element);
  }

  return ir_annotation;
}

ir::EncodedArray* Reader::ParseEncodedArray(const dex::u1** pptr) {
  auto ir_encoded_array = dex_ir_->Alloc<ir::EncodedArray>();

  dex::u4 count = dex::ReadULeb128(pptr);
  for (dex::u4 i = 0; i < count; ++i) {
    ir_encoded_array->values.push_back(ParseEncodedValue(pptr));
  }

  return ir_encoded_array;
}

ir::EncodedArray* Reader::ExtractEncodedArray(dex::u4 offset) {
  if (offset == 0) {
    return nullptr;
  }

  // first check if we already extracted the same "annotation_item"
  auto& ir_encoded_array = encoded_arrays_[offset];
  if (ir_encoded_array == nullptr) {
    auto ptr = dataPtr<dex::u1>(offset);
    ir_encoded_array = ParseEncodedArray(&ptr);
  }
  return ir_encoded_array;
}

ir::DebugInfo* Reader::ExtractDebugInfo(dex::u4 offset) {
  if (offset == 0) {
    return nullptr;
  }

  auto ir_debug_info = dex_ir_->Alloc<ir::DebugInfo>();
  const dex::u1* ptr = dataPtr<dex::u1>(offset);

  ir_debug_info->line_start = dex::ReadULeb128(&ptr);

  // TODO: implicit this param for non-static methods?
  dex::u4 param_count = dex::ReadULeb128(&ptr);
  for (dex::u4 i = 0; i < param_count; ++i) {
    dex::u4 name_index = dex::ReadULeb128(&ptr) - 1;
    auto ir_string =
        (name_index == dex::kNoIndex) ? nullptr : GetString(name_index);
    ir_debug_info->param_names.push_back(ir_string);
  }

  // parse the debug info opcodes and note the
  // references to strings and types (to make sure the IR
  // is the full closure of all referenced items)
  //
  // TODO: design a generic debug info iterator?
  //
  auto base_ptr = ptr;
  dex::u1 opcode = 0;
  while ((opcode = *ptr++) != dex::DBG_END_SEQUENCE) {
    switch (opcode) {
      case dex::DBG_ADVANCE_PC:
        // addr_diff
        dex::ReadULeb128(&ptr);
        break;

      case dex::DBG_ADVANCE_LINE:
        // line_diff
        dex::ReadSLeb128(&ptr);
        break;

      case dex::DBG_START_LOCAL: {
        // register_num
        dex::ReadULeb128(&ptr);

        dex::u4 name_index = dex::ReadULeb128(&ptr) - 1;
        if (name_index != dex::kNoIndex) {
          GetString(name_index);
        }

        dex::u4 type_index = dex::ReadULeb128(&ptr) - 1;
        if (type_index != dex::kNoIndex) {
          GetType(type_index);
        }
      } break;

      case dex::DBG_START_LOCAL_EXTENDED: {
        // register_num
        dex::ReadULeb128(&ptr);

        dex::u4 name_index = dex::ReadULeb128(&ptr) - 1;
        if (name_index != dex::kNoIndex) {
          GetString(name_index);
        }

        dex::u4 type_index = dex::ReadULeb128(&ptr) - 1;
        if (type_index != dex::kNoIndex) {
          GetType(type_index);
        }

        dex::u4 sig_index = dex::ReadULeb128(&ptr) - 1;
        if (sig_index != dex::kNoIndex) {
          GetString(sig_index);
        }
      } break;

      case dex::DBG_END_LOCAL:
      case dex::DBG_RESTART_LOCAL:
        // register_num
        dex::ReadULeb128(&ptr);
        break;

      case dex::DBG_SET_FILE: {
        dex::u4 name_index = dex::ReadULeb128(&ptr) - 1;
        if (name_index != dex::kNoIndex) {
          GetString(name_index);
        }
      } break;
    }
  }

  ir_debug_info->data = slicer::MemView(base_ptr, ptr - base_ptr);

  return ir_debug_info;
}

ir::Code* Reader::ExtractCode(dex::u4 offset) {
  if (offset == 0) {
    return nullptr;
  }

  SLICER_CHECK_EQ(offset % 4, 0);

  auto dex_code = dataPtr<dex::Code>(offset);
  auto ir_code = dex_ir_->Alloc<ir::Code>();

  ir_code->registers = dex_code->registers_size;
  ir_code->ins_count = dex_code->ins_size;
  ir_code->outs_count = dex_code->outs_size;

  // instructions array
  ir_code->instructions =
      slicer::ArrayView<const dex::u2>(dex_code->insns, dex_code->insns_size);

  // parse the instructions to discover references to other
  // IR nodes (see debug info stream parsing too)
  ParseInstructions(ir_code->instructions);

  // try blocks & handlers
  //
  // TODO: a generic try/catch blocks iterator?
  //
  if (dex_code->tries_size != 0) {
    dex::u4 aligned_count = (dex_code->insns_size + 1) / 2 * 2;
    auto tries =
        reinterpret_cast<const dex::TryBlock*>(dex_code->insns + aligned_count);
    auto handlers_list =
        reinterpret_cast<const dex::u1*>(tries + dex_code->tries_size);

    ir_code->try_blocks =
        slicer::ArrayView<const dex::TryBlock>(tries, dex_code->tries_size);

    // parse the handlers list (and discover embedded references)
    auto ptr = handlers_list;

    dex::u4 handlers_count = dex::ReadULeb128(&ptr);
    SLICER_WEAK_CHECK(handlers_count <= dex_code->tries_size);

    for (dex::u4 handler_index = 0; handler_index < handlers_count; ++handler_index) {
      int catch_count = dex::ReadSLeb128(&ptr);

      for (int catch_index = 0; catch_index < std::abs(catch_count); ++catch_index) {
        dex::u4 type_index = dex::ReadULeb128(&ptr);
        GetType(type_index);

        // address
        dex::ReadULeb128(&ptr);
      }

      if (catch_count < 1) {
        // catch_all_addr
        dex::ReadULeb128(&ptr);
      }
    }

    ir_code->catch_handlers = slicer::MemView(handlers_list, ptr - handlers_list);
  }

  ir_code->debug_info = ExtractDebugInfo(dex_code->debug_info_off);

  return ir_code;
}

ir::EncodedMethod* Reader::ParseEncodedMethod(const dex::u1** pptr, dex::u4* base_index) {
  auto ir_encoded_method = dex_ir_->Alloc<ir::EncodedMethod>();

  auto method_index = dex::ReadULeb128(pptr);
  SLICER_CHECK_NE(method_index, dex::kNoIndex);
  if (*base_index != dex::kNoIndex) {
    SLICER_CHECK_NE(method_index, 0);
    method_index += *base_index;
  }
  *base_index = method_index;

  ir_encoded_method->decl = GetMethodDecl(method_index);
  ir_encoded_method->access_flags = dex::ReadULeb128(pptr);

  dex::u4 code_offset = dex::ReadULeb128(pptr);
  ir_encoded_method->code = ExtractCode(code_offset);

  // update the methods lookup table
  dex_ir_->methods_lookup.Insert(ir_encoded_method);

  return ir_encoded_method;
}

ir::Type* Reader::ParseType(dex::u4 index) {
  auto& dex_type = TypeIds()[index];
  auto ir_type = dex_ir_->Alloc<ir::Type>();

  ir_type->descriptor = GetString(dex_type.descriptor_idx);
  ir_type->orig_index = index;

  return ir_type;
}

ir::FieldDecl* Reader::ParseFieldDecl(dex::u4 index) {
  auto& dex_field = FieldIds()[index];
  auto ir_field = dex_ir_->Alloc<ir::FieldDecl>();

  ir_field->name = GetString(dex_field.name_idx);
  ir_field->type = GetType(dex_field.type_idx);
  ir_field->parent = GetType(dex_field.class_idx);
  ir_field->orig_index = index;

  return ir_field;
}

ir::MethodHandle* Reader::ParseMethodHandle(dex::u4 index){
  auto& dex_method_handle = MethodHandles()[index];
  auto ir_method_handle = dex_ir_->Alloc<ir::MethodHandle>();

  ir_method_handle->method_handle_type = dex_method_handle.method_handle_type;

  if(ir_method_handle->IsField()){
    ir_method_handle->field = GetFieldDecl(dex_method_handle.field_or_method_id);
  }
  else {
    ir_method_handle->method = GetMethodDecl(dex_method_handle.field_or_method_id);
  }

  return ir_method_handle;
}

ir::MethodDecl* Reader::ParseMethodDecl(dex::u4 index) {
  auto& dex_method = MethodIds()[index];
  auto ir_method = dex_ir_->Alloc<ir::MethodDecl>();

  ir_method->name = GetString(dex_method.name_idx);
  ir_method->prototype = GetProto(dex_method.proto_idx);
  ir_method->parent = GetType(dex_method.class_idx);
  ir_method->orig_index = index;

  return ir_method;
}

ir::TypeList* Reader::ExtractTypeList(dex::u4 offset) {
  if (offset == 0) {
    return nullptr;
  }

  // first check to see if we already extracted the same "type_list"
  auto& ir_type_list = type_lists_[offset];
  if (ir_type_list == nullptr) {
    ir_type_list = dex_ir_->Alloc<ir::TypeList>();

    auto dex_type_list = dataPtr<dex::TypeList>(offset);
    SLICER_WEAK_CHECK(dex_type_list->size > 0);

    for (dex::u4 i = 0; i < dex_type_list->size; ++i) {
      ir_type_list->types.push_back(GetType(dex_type_list->list[i].type_idx));
    }
  }

  return ir_type_list;
}

ir::Proto* Reader::ParseProto(dex::u4 index) {
  auto& dex_proto = ProtoIds()[index];
  auto ir_proto = dex_ir_->Alloc<ir::Proto>();

  ir_proto->shorty = GetString(dex_proto.shorty_idx);
  ir_proto->return_type = GetType(dex_proto.return_type_idx);
  ir_proto->param_types = ExtractTypeList(dex_proto.parameters_off);
  ir_proto->orig_index = index;

  // update the prototypes lookup table
  dex_ir_->prototypes_lookup.Insert(ir_proto);

  return ir_proto;
}

ir::String* Reader::ParseString(dex::u4 index) {
  auto ir_string = dex_ir_->Alloc<ir::String>();

  auto data = GetStringData(index);
  auto cstr = data;
  dex::ReadULeb128(&cstr);
  size_t size = (cstr - data) + ::strlen(reinterpret_cast<const char*>(cstr)) + 1;

  ir_string->data = slicer::MemView(data, size);
  ir_string->orig_index = index;

  // update the strings lookup table
  dex_ir_->strings_lookup.Insert(ir_string);

  return ir_string;
}

void Reader::ParseInstructions(slicer::ArrayView<const dex::u2> code) {
  const dex::u2* ptr = code.begin();
  while (ptr < code.end()) {
    auto dex_instr = dex::DecodeInstruction(ptr);

    dex::u4 index = dex::kNoIndex;
    dex::u4 index2 = dex::kNoIndex;
    switch (dex::GetFormatFromOpcode(dex_instr.opcode)) {
      case dex::k20bc:
      case dex::k21c:
      case dex::k31c:
      case dex::k35c:
      case dex::k3rc:
        index = dex_instr.vB;
        break;

      case dex::k45cc:
      case dex::k4rcc:
        index = dex_instr.vB;
        index2 = dex_instr.arg[4];
        break;

      case dex::k22c:
        index = dex_instr.vC;
        break;

      default:
        break;
    }

    switch (GetIndexTypeFromOpcode(dex_instr.opcode)) {
      case dex::kIndexStringRef:
        GetString(index);
        break;

      case dex::kIndexTypeRef:
        GetType(index);
        break;

      case dex::kIndexFieldRef:
        GetFieldDecl(index);
        break;

      case dex::kIndexMethodRef:
        GetMethodDecl(index);
        break;

      case dex::kIndexMethodAndProtoRef:
        GetMethodDecl(index);
        GetProto(index2);
        break;

      case dex::kIndexMethodHandleRef:
        GetMethodHandle(index);
        break;

      default:
        break;
    }

    auto isize = dex::GetWidthFromBytecode(ptr);
    SLICER_CHECK_GT(isize, 0);
    ptr += isize;
  }
  SLICER_CHECK_EQ(ptr, code.end());
}

// Basic .dex header structural checks
void Reader::ValidateHeader() {
  SLICER_CHECK_GT(size_, dex::Header::kV40Size);

  // Known issue: For performance reasons the initial size_ passed to jvmti events might be an
  // estimate. b/72402467
  SLICER_CHECK_LE(header_->file_size, size_);
  // Check that we support this version of dex header
  SLICER_CHECK(
      header_->header_size == dex::Header::kV40Size ||
      header_->header_size == dex::Header::kV41Size);
  SLICER_CHECK_EQ(header_->endian_tag, dex::kEndianConstant);
  SLICER_CHECK_EQ(header_->data_size % 4, 0);

  // If the dex file is within container with other dex files,
  // adjust the base address to the start of the container.
  SLICER_CHECK_LE(header_->ContainerSize() - header_->ContainerOff(), size_);
  image_ -= header_->ContainerOff();
  size_ = header_->ContainerSize();

  // Known issue: The fields might be slighly corrupted b/65452964
  // SLICER_CHECK_LE(header_->data_off + header_->data_size, size_);

  SLICER_CHECK_EQ(header_->string_ids_off % 4, 0);
  SLICER_CHECK_LT(header_->type_ids_size, 65536);
  SLICER_CHECK_EQ(header_->type_ids_off % 4, 0);
  SLICER_CHECK_LT(header_->proto_ids_size, 65536);
  SLICER_CHECK_EQ(header_->proto_ids_off % 4, 0);
  SLICER_CHECK_EQ(header_->field_ids_off % 4, 0);
  SLICER_CHECK_EQ(header_->method_ids_off % 4, 0);
  SLICER_CHECK_EQ(header_->class_defs_off % 4, 0);
  SLICER_CHECK_GE(header_->map_off, header_->data_off);
  SLICER_CHECK_LT(header_->map_off, size_);
  SLICER_CHECK_EQ(header_->link_size, 0);
  SLICER_CHECK_EQ(header_->link_off, 0);
  SLICER_CHECK_EQ(header_->data_off % 4, 0);
  SLICER_CHECK_EQ(header_->map_off % 4, 0);

  // we seem to have .dex files with extra bytes at the end ...
  // Known issue: For performance reasons the initial size_ passed to jvmti events might be an
  // estimate. b/72402467
  SLICER_WEAK_CHECK(header_->data_off + header_->data_size <= size_);

  // but we should still have the whole data section

  // Known issue: The fields might be slightly corrupted b/65452964
  // Known issue: For performance reasons the initial size_ passed to jvmti events might be an
  // estimate. b/72402467
  // SLICER_CHECK_LE(header_->data_off + header_->data_size, size_);

  // validate the map
  // (map section size = sizeof(MapList::size) + sizeof(MapList::list[size])
  auto map_list = ptr<dex::MapList>(header_->map_off);
  SLICER_CHECK_GT(map_list->size, 0);
  auto map_section_size =
      sizeof(dex::u4) + sizeof(dex::MapItem) * map_list->size;
  SLICER_CHECK_LE(header_->map_off + map_section_size, size_);
}

}  // namespace dex

```

`paccer/jni/slicer/tryblocks_encoder.cc`:

```cc
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include "slicer/tryblocks_encoder.h"

#include "slicer/chronometer.h"
#include "slicer/common.h"

namespace lir {

bool TryBlocksEncoder::Visit(TryBlockEnd* try_end) {
  const dex::u4 begin_offset = try_end->try_begin->offset;
  const dex::u4 end_offset = try_end->offset;
  SLICER_CHECK_GT(end_offset, begin_offset);
  SLICER_CHECK_LT(end_offset - begin_offset, (1 << 16));

  // generate the "try_item"
  dex::TryBlock try_block = {};
  try_block.start_addr = begin_offset;
  try_block.insn_count = end_offset - begin_offset;
  try_block.handler_off = handlers_.size();
  tries_.Push(try_block);

  // generate the "encoded_catch_handler"
  dex::s4 catch_count = try_end->handlers.size();
  handlers_.PushSLeb128(try_end->catch_all ? -catch_count : catch_count);
  for (int catch_index = 0; catch_index < catch_count; ++catch_index) {
    const CatchHandler& handler = try_end->handlers[catch_index];
    // type_idx
    handlers_.PushULeb128(handler.ir_type->orig_index);
    // address
    SLICER_CHECK_NE(handler.label->offset, kInvalidOffset);
    handlers_.PushULeb128(handler.label->offset);
  }
  if (try_end->catch_all != nullptr) {
    // address
    SLICER_CHECK_NE(try_end->catch_all->offset, kInvalidOffset);
    handlers_.PushULeb128(try_end->catch_all->offset);
  }

  return true;
}

void TryBlocksEncoder::Encode(ir::Code* ir_code, std::shared_ptr<ir::DexFile> dex_ir) {
  SLICER_CHECK(handlers_.empty());
  SLICER_CHECK(tries_.empty());

  // first, count the number of try blocks
  struct TryBlockEndVisitor : public Visitor {
    int tries_count = 0;
    bool Visit(TryBlockEnd* try_end) override {
      ++tries_count;
      return true;
    }
  };
  TryBlockEndVisitor visitor;
  for (auto instr : instructions_) {
    instr->Accept(&visitor);
  }
  int tries_count = visitor.tries_count;
  SLICER_CHECK_LT(tries_count, (1 << 16));

  // no try blocks?
  if (tries_count == 0) {
    ir_code->try_blocks = {};
    ir_code->catch_handlers = {};
    return;
  }

  // "encoded_catch_handler_list.size"
  handlers_.PushULeb128(tries_count);

  // generate the try blocks & encoded catch handlers
  //
  // NOTE: try_item[tries_count] :
  //  "Elements of the array must be non-overlapping in range and
  //  in order from low to high address. This element is only present
  //  if tries_size is non-zero"
  //
  // NOTE: we're not de-duplicating catch_handlers
  //   (generate one catch_handler for each try block)
  //
  for (auto instr : instructions_) {
    instr->Accept(this);
  }
  SLICER_CHECK(!tries_.empty());
  SLICER_CHECK(!handlers_.empty());
  tries_.Seal(1);
  handlers_.Seal(1);

  // update ir::Code
  auto tries_ptr = tries_.ptr<const dex::TryBlock>(0);
  ir_code->try_blocks = slicer::ArrayView<const dex::TryBlock>(tries_ptr, tries_count);
  ir_code->catch_handlers = slicer::MemView(handlers_.data(), handlers_.size());

  // attach the generated try/catch blocks to the dex IR
  dex_ir->AttachBuffer(std::move(tries_));
  dex_ir->AttachBuffer(std::move(handlers_));
}

}  // namespace lir

```

`paccer/jni/slicer/writer.cc`:

```cc
/*
 * Copyright (C) 2017 The Android Open Source Project
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with the License.
 * You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 */

#include "slicer/writer.h"

#include "slicer/common.h"
#include "slicer/scopeguard.h"
#include "slicer/dex_bytecode.h"
#include "slicer/dex_format.h"
#include "slicer/dex_ir.h"
#include "slicer/dex_leb128.h"

#include <assert.h>
#include <type_traits>
#include <vector>
#include <string.h>
#include <algorithm>

namespace dex {

// Returns the IR node index, or kNoIndex for null IR nodes
template <class T>
static dex::u4 OptIndex(const T* ir_node) {
  return ir_node != nullptr ? ir_node->index : dex::kNoIndex;
}

// Helper for creating the header of an encoded value
static void WriteEncodedValueHeader(dex::u1 type, int arg, Section& data) {
  assert((type & ~dex::kEncodedValueTypeMask) == 0);
  assert(arg >= 0 && arg < 8);
  dex::u1 header = dex::u1(type | (arg << dex::kEncodedValueArgShift));
  data.Push<dex::u1>(header);
}

// Writes an integer encoded value
template <class T>
static void WriteIntValue(dex::u1 type, T value, Section& data) {
  dex::u1 buff[sizeof(T)] = {};
  dex::u1* dst = buff;

  if (std::is_signed<T>::value) {
    const bool positive = (value >= 0);
    while (positive ? value >= 0x80 : value < -0x80) {
      *dst++ = value & 0xff;
      value >>= 8;
    }
    *dst++ = value & 0xff;
  } else {
    do {
      *dst++ = value & 0xff;
      value >>= 8;
    } while (value != 0);
  }

  size_t size = dst - buff;
  assert(size > 0 && size <= sizeof(T));
  WriteEncodedValueHeader(type, size - 1, data);
  data.Push(buff, size);
}

// Writes a floating point encoded value
template <class T>
static void WriteFloatValue(dex::u1 type, T value, Section& data) {
  dex::u1 buff[sizeof(T)] = {};
  auto src = reinterpret_cast<const dex::u1*>(&value);
  size_t size = sizeof(T);

  // skip "rightmost" zero bytes
  while (size > 1 && *src == 0) {
    --size;
    ++src;
  }

  // copy the rest...
  for (size_t i = 0; i < size; ++i) {
    buff[i] = src[i];
  }

  assert(size > 0 && size <= sizeof(T));
  WriteEncodedValueHeader(type, size - 1, data);
  data.Push(buff, size);
}

static void WriteEncodedArray(const ir::EncodedArray* ir_array, Section& data);
static void WriteAnnotation(const ir::Annotation* ir_annotation, Section& data);

// "encoded_value"
static void WriteEncodedValue(const ir::EncodedValue* ir_value, Section& data) {
  SLICER_EXTRA(auto offset = data.size());

  dex::u1 type = ir_value->type;
  switch (type) {
    case dex::kEncodedByte:
      WriteIntValue(type, ir_value->u.byte_value, data);
      break;

    case dex::kEncodedShort:
      WriteIntValue(type, ir_value->u.short_value, data);
      break;

    case dex::kEncodedChar:
      WriteIntValue(type, ir_value->u.char_value, data);
      break;

    case dex::kEncodedInt:
      WriteIntValue(type, ir_value->u.int_value, data);
      break;

    case dex::kEncodedLong:
      WriteIntValue(type, ir_value->u.long_value, data);
      break;

    case dex::kEncodedFloat:
      WriteFloatValue(type, ir_value->u.float_value, data);
      break;

    case dex::kEncodedDouble:
      WriteFloatValue(type, ir_value->u.double_value, data);
      break;

    case dex::kEncodedString:
      WriteIntValue<dex::u4>(type, ir_value->u.string_value->index, data);
      break;

    case dex::kEncodedType:
      WriteIntValue<dex::u4>(type, ir_value->u.type_value->index, data);
      break;

    case dex::kEncodedField:
      WriteIntValue<dex::u4>(type, ir_value->u.field_value->index, data);
      break;

    case dex::kEncodedMethod:
      WriteIntValue<dex::u4>(type, ir_value->u.method_value->index, data);
      break;

    case dex::kEncodedEnum:
      WriteIntValue<dex::u4>(type, ir_value->u.enum_value->index, data);
      break;

    case dex::kEncodedArray:
      WriteEncodedValueHeader(type, 0, data);
      WriteEncodedArray(ir_value->u.array_value, data);
      break;

    case dex::kEncodedAnnotation:
      WriteEncodedValueHeader(type, 0, data);
      WriteAnnotation(ir_value->u.annotation_value, data);
      break;

    case dex::kEncodedNull:
      WriteEncodedValueHeader(type, 0, data);
      break;

    case dex::kEncodedBoolean: {
      int arg = ir_value->u.bool_value ? 1 : 0;
      WriteEncodedValueHeader(type, arg, data);
    } break;

    default:
      SLICER_CHECK(!"unexpected value type");
  }

  // optionally check the encoding against the original one
  // (if possible, some of the values contain relocated indexes)
  SLICER_EXTRA({
    switch (type) {
      case dex::kEncodedByte:
      case dex::kEncodedShort:
      case dex::kEncodedChar:
      case dex::kEncodedInt:
      case dex::kEncodedLong:
      case dex::kEncodedFloat:
      case dex::kEncodedDouble:
      case dex::kEncodedNull:
      case dex::kEncodedBoolean:
        auto ptr = data.ptr<const dex::u1>(offset);
        auto size = data.size() - offset;
        SLICER_CHECK_EQ(size, ir_value->original.size());
        SLICER_CHECK_EQ(memcmp(ptr, ir_value->original.ptr(), size), 0);
        break;
    }
  });
}

// "encoded_annotation"
static void WriteAnnotation(const ir::Annotation* ir_annotation, Section& data) {
  data.PushULeb128(ir_annotation->type->index);
  data.PushULeb128(ir_annotation->elements.size());
  for (auto irAnnotationElement : ir_annotation->elements) {
    data.PushULeb128(irAnnotationElement->name->index);
    WriteEncodedValue(irAnnotationElement->value, data);
  }
}

// "encoded_array"
static void WriteEncodedArray(const ir::EncodedArray* ir_array, Section& data) {
  const auto& values = ir_array->values;
  data.PushULeb128(values.size());
  for (auto irEncodedValue : values) {
    WriteEncodedValue(irEncodedValue, data);
  }
}

// helper for concatenating .dex sections into the final image
template <class T>
static void CopySection(const T& section, dex::u1* image, dex::u4 image_size) {
  if (section.size() == 0) {
    SLICER_CHECK_EQ(section.ItemsCount(), 0);
    return;
  }

  SLICER_CHECK_GT(section.ItemsCount(), 0);
  dex::u4 offset = section.SectionOffset();
  dex::u4 size = section.size();
  SLICER_CHECK_GE(offset, dex::Header::kV40Size);
  SLICER_CHECK_LE(offset + size, image_size);

  ::memcpy(image + offset, section.data(), size);
}

static u4 ReadU4(const u2* ptr) { return ptr[0] | (u4(ptr[1]) << 16); }

static void WriteU4(u2* ptr, u4 val) {
  ptr[0] = val & 0xffff;
  ptr[1] = val >> 16;
}

// This is the main interface for the .dex writer
// (returns nullptr on failure)
dex::u1* Writer::CreateImage(Allocator* allocator, size_t* new_image_size) {
  // create a new DexImage
  dex_.reset(new DexImage);

  SLICER_SCOPE_EXIT {
      dex_.reset();
  };

  // TODO: revisit IR normalization
  // (ideally we shouldn't change the IR while generating an image)
  dex_ir_->Normalize();

  int version = Header::GetVersion(dex_ir_->magic.ptr());

  SLICER_CHECK_NE(version, 0);
  SLICER_CHECK_GE(version, Header::kMinVersion);
  SLICER_CHECK_LE(version, Header::kMaxVersion);
  u4 header_size = version >= Header::kV41 ? Header::kV41Size : Header::kV40Size;

  // track the current offset within the .dex image
  dex::u4 offset = 0;

  // allocate the image and index sections
  // (they will be back-filled)
  offset += header_size;
  offset += dex_->string_ids.Init(offset, dex_ir_->strings.size());
  offset += dex_->type_ids.Init(offset, dex_ir_->types.size());
  offset += dex_->proto_ids.Init(offset, dex_ir_->protos.size());
  offset += dex_->field_ids.Init(offset, dex_ir_->fields.size());
  offset += dex_->method_ids.Init(offset, dex_ir_->methods.size());
  offset += dex_->class_defs.Init(offset, dex_ir_->classes.size());
  offset += dex_->method_handles.Init(offset, dex_ir_->method_handles.size());

  // the base offset for the "data" meta-section
  SLICER_CHECK_EQ(offset % 4, 0);
  const dex::u4 data_offset = offset;

  // we must create the sections in a very specific
  // order due to file pointers across sections
  offset += CreateStringDataSection(offset);
  offset += CreateTypeListsSection(offset);
  offset += CreateDebugInfoSection(offset);
  offset += CreateEncodedArrayItemSection(offset);
  offset += CreateCodeItemSection(offset);
  offset += CreateClassDataSection(offset);
  offset += CreateAnnItemSection(offset);
  offset += CreateAnnSetsSection(offset);
  offset += CreateAnnSetRefListsSection(offset);
  offset += CreateAnnDirectoriesSection(offset);
  offset += CreateMapSection(offset);

  // back-fill the indexes
  FillTypes();
  FillFields();
  FillProtos();
  FillMethods();
  FillClassDefs();
  FillMethodHandles();

  // allocate the final buffer for the .dex image
  SLICER_CHECK_EQ(offset % 4, 0);
  const dex::u4 image_size = offset;
  dex::u1* image = static_cast<dex::u1*>(allocator->Allocate(image_size));
  if (image == nullptr) {
    // memory allocation failed, bailing out...
    return nullptr;
  }
  memset(image, 0, image_size);

  // finally, back-fill the header
  SLICER_CHECK_GT(image_size, header_size);

  dex::Header* header = reinterpret_cast<dex::Header*>(image + 0);

  // magic signature
  memcpy(header->magic, dex_ir_->magic.ptr(), dex_ir_->magic.size());

  header->file_size = image_size;
  header->header_size = header_size;
  header->endian_tag = dex::kEndianConstant;

  header->link_size = 0;
  header->link_off = 0;

  header->map_off = dex_->map_list.SectionOffset();
  header->string_ids_size = dex_->string_ids.ItemsCount();
  header->string_ids_off = dex_->string_ids.SectionOffset();
  header->type_ids_size = dex_->type_ids.ItemsCount();
  header->type_ids_off = dex_->type_ids.SectionOffset();
  header->proto_ids_size = dex_->proto_ids.ItemsCount();
  header->proto_ids_off = dex_->proto_ids.SectionOffset();
  header->field_ids_size = dex_->field_ids.ItemsCount();
  header->field_ids_off = dex_->field_ids.SectionOffset();
  header->method_ids_size = dex_->method_ids.ItemsCount();
  header->method_ids_off = dex_->method_ids.SectionOffset();
  header->class_defs_size = dex_->class_defs.ItemsCount();
  header->class_defs_off = dex_->class_defs.SectionOffset();
  header->data_size = image_size - data_offset;
  header->data_off = data_offset;
  if (version >= Header::kV41) {
    header->data_size = 0;
    header->data_off = 0;
    header->SetContainer(0, header->file_size);
  }

  // copy the individual sections to the final image
  CopySection(dex_->string_ids, image, image_size);
  CopySection(dex_->type_ids, image, image_size);
  CopySection(dex_->proto_ids, image, image_size);
  CopySection(dex_->field_ids, image, image_size);
  CopySection(dex_->method_ids, image, image_size);
  CopySection(dex_->class_defs, image, image_size);
  CopySection(dex_->method_handles, image, image_size);
  CopySection(dex_->string_data, image, image_size);
  CopySection(dex_->type_lists, image, image_size);
  CopySection(dex_->debug_info, image, image_size);
  CopySection(dex_->encoded_arrays, image, image_size);
  CopySection(dex_->code, image, image_size);
  CopySection(dex_->class_data, image, image_size);
  CopySection(dex_->ann_directories, image, image_size);
  CopySection(dex_->ann_set_ref_lists, image, image_size);
  CopySection(dex_->ann_sets, image, image_size);
  CopySection(dex_->ann_items, image, image_size);
  CopySection(dex_->map_list, image, image_size);

  // checksum
  header->checksum = dex::ComputeChecksum(header);

  *new_image_size = image_size;
  return image;
}

// "string_id_item" + string data section
dex::u4 Writer::CreateStringDataSection(dex::u4 section_offset) {
  auto& section = dex_->string_data;
  section.SetOffset(section_offset);

  const auto& strings = dex_ir_->strings;
  for (size_t i = 0; i < strings.size(); ++i) {
    const auto& ir_string = strings[i];
    auto dexStringId = &dex_->string_ids[i];

    dex::u4 offset = section.AddItem();
    section.Push(ir_string->data);
    dexStringId->string_data_off = section.AbsoluteOffset(offset);
  }

  dex::u4 size = section.Seal(4);
  return size;
}

// Helper for creating the map section
template <class T>
static void AddMapItem(const T& section, std::vector<dex::MapItem>& items) {
  if (section.ItemsCount() > 0) {
    SLICER_CHECK_GE(section.SectionOffset(), dex::Header::kV40Size);
    dex::MapItem map_item = {};
    map_item.type = section.MapEntryType();
    map_item.size = section.ItemsCount();
    map_item.offset = section.SectionOffset();
    items.push_back(map_item);
  }
}

// map_list section
dex::u4 Writer::CreateMapSection(dex::u4 section_offset) {
  auto& section = dex_->map_list;
  section.SetOffset(section_offset);
  section.AddItem(4);

  std::vector<dex::MapItem> map_items;

  dex::MapItem headerItem = {};
  headerItem.type = dex::kHeaderItem;
  headerItem.size = 1;
  headerItem.offset = 0;
  map_items.push_back(headerItem);

  AddMapItem(dex_->string_ids, map_items);
  AddMapItem(dex_->type_ids, map_items);
  AddMapItem(dex_->proto_ids, map_items);
  AddMapItem(dex_->field_ids, map_items);
  AddMapItem(dex_->method_ids, map_items);
  AddMapItem(dex_->class_defs, map_items);
  AddMapItem(dex_->method_handles, map_items);
  AddMapItem(dex_->string_data, map_items);
  AddMapItem(dex_->type_lists, map_items);
  AddMapItem(dex_->debug_info, map_items);
  AddMapItem(dex_->encoded_arrays, map_items);
  AddMapItem(dex_->code, map_items);
  AddMapItem(dex_->class_data, map_items);
  AddMapItem(dex_->ann_directories, map_items);
  AddMapItem(dex_->ann_set_ref_lists, map_items);
  AddMapItem(dex_->ann_sets, map_items);
  AddMapItem(dex_->ann_items, map_items);
  AddMapItem(dex_->map_list, map_items);

  std::sort(map_items.begin(), map_items.end(),
            [](const dex::MapItem& a, const dex::MapItem& b) {
              SLICER_CHECK_NE(a.offset, b.offset);
              return a.offset < b.offset;
            });

  section.Push<dex::u4>(map_items.size());
  section.Push(map_items);
  return section.Seal(4);
}

// annotation_item section
dex::u4 Writer::CreateAnnItemSection(dex::u4 section_offset) {
  dex_->ann_items.SetOffset(section_offset);

  for (const auto& ir_node : dex_ir_->annotations) {
    if (ir_node->visibility != dex::kVisibilityEncoded) {
      // TODO: factor out the node_offset_ updating
      dex::u4& offset = node_offset_[ir_node.get()];
      SLICER_CHECK_EQ(offset, 0);
      offset = WriteAnnotationItem(ir_node.get());
    }
  }

  return dex_->ann_items.Seal(4);
}

// annotation_set_item section
dex::u4 Writer::CreateAnnSetsSection(dex::u4 section_offset) {
  dex_->ann_sets.SetOffset(section_offset);

  for (const auto& ir_node : dex_ir_->annotation_sets) {
    dex::u4& offset = node_offset_[ir_node.get()];
    SLICER_CHECK_EQ(offset, 0);
    offset = WriteAnnotationSet(ir_node.get());
  }

  return dex_->ann_sets.Seal(4);
}

// annotation_set_ref_list section
dex::u4 Writer::CreateAnnSetRefListsSection(dex::u4 section_offset) {
  dex_->ann_set_ref_lists.SetOffset(section_offset);

  for (const auto& ir_node : dex_ir_->annotation_set_ref_lists) {
    dex::u4& offset = node_offset_[ir_node.get()];
    SLICER_CHECK_EQ(offset, 0);
    offset = WriteAnnotationSetRefList(ir_node.get());
  }

  return dex_->ann_set_ref_lists.Seal(4);
}

// type_list section
dex::u4 Writer::CreateTypeListsSection(dex::u4 section_offset) {
  dex_->type_lists.SetOffset(section_offset);

  for (const auto& ir_type_list : dex_ir_->type_lists) {
    dex::u4& offset = node_offset_[ir_type_list.get()];
    SLICER_CHECK_EQ(offset, 0);
    offset = WriteTypeList(ir_type_list->types);
  }

  return dex_->type_lists.Seal(4);
}

// code_item section
dex::u4 Writer::CreateCodeItemSection(dex::u4 section_offset) {
  dex_->code.SetOffset(section_offset);

  for (const auto& ir_node : dex_ir_->code) {
    dex::u4& offset = node_offset_[ir_node.get()];
    SLICER_CHECK_EQ(offset, 0);
    offset = WriteCode(ir_node.get());
  }

  dex::u4 size = dex_->code.Seal(4);
  return size;
}

// debug info section
dex::u4 Writer::CreateDebugInfoSection(dex::u4 section_offset) {
  dex_->debug_info.SetOffset(section_offset);

  for (const auto& ir_node : dex_ir_->debug_info) {
    dex::u4& offset = node_offset_[ir_node.get()];
    SLICER_CHECK_EQ(offset, 0);
    offset = WriteDebugInfo(ir_node.get());
  }

  dex::u4 size = dex_->debug_info.Seal(4);
  return size;
}

// class_data_item section
dex::u4 Writer::CreateClassDataSection(dex::u4 section_offset) {
  dex_->class_data.SetOffset(section_offset);

  const auto& classes = dex_ir_->classes;
  for (size_t i = 0; i < classes.size(); ++i) {
    auto ir_class = classes[i].get();
    auto dex_class_def = &dex_->class_defs[i];
    dex_class_def->class_data_off = WriteClassData(ir_class);
  }

  dex::u4 size = dex_->class_data.Seal(4);
  return size;
}

// annotations_directory section
dex::u4 Writer::CreateAnnDirectoriesSection(dex::u4 section_offset) {
  dex_->ann_directories.SetOffset(section_offset);

  const auto& classes = dex_ir_->classes;
  for (size_t i = 0; i < classes.size(); ++i) {
    auto ir_class = classes[i].get();
    auto dex_class_def = &dex_->class_defs[i];
    dex_class_def->annotations_off = WriteClassAnnotations(ir_class);
  }

  return dex_->ann_directories.Seal(4);
}

// encoded_array_item section
dex::u4 Writer::CreateEncodedArrayItemSection(dex::u4 section_offset) {
  dex_->encoded_arrays.SetOffset(section_offset);

  const auto& classes = dex_ir_->classes;
  for (size_t i = 0; i < classes.size(); ++i) {
    auto ir_class = classes[i].get();
    auto dex_class_def = &dex_->class_defs[i];
    dex_class_def->static_values_off = WriteClassStaticValues(ir_class);
  }

  return dex_->encoded_arrays.Seal(4);
}

// "type_id_item"
void Writer::FillTypes() {
  const auto& types = dex_ir_->types;
  for (size_t i = 0; i < types.size(); ++i) {
    const auto& ir_type = types[i];
    auto dexTypeId = &dex_->type_ids[i];
    // CONSIDER: an automatic index check would be nice
    dexTypeId->descriptor_idx = ir_type->descriptor->index;
  }
}

// "proto_id_item"
void Writer::FillProtos() {
  const auto& protos = dex_ir_->protos;
  for (size_t i = 0; i < protos.size(); ++i) {

    const auto& irProto = protos[i];
    auto dexProtoId = &dex_->proto_ids[i];

    dexProtoId->shorty_idx = irProto->shorty->index;
    dexProtoId->return_type_idx = irProto->return_type->index;
    dexProtoId->parameters_off = FilePointer(irProto->param_types);
  }
}

void Writer::FillMethodHandles(){
  const auto& methodHandles = dex_ir_->method_handles;
  for(size_t i = 0; i < methodHandles.size(); ++i){

    const auto& irMethodHandle = methodHandles[i];
    auto dexMethodHandle = &dex_->method_handles[i];

    dexMethodHandle->method_handle_type = irMethodHandle->method_handle_type;

    if(irMethodHandle->IsField()){
      dexMethodHandle->field_or_method_id = irMethodHandle->field->index;
    }
    else{
      dexMethodHandle->field_or_method_id = irMethodHandle->method->index;
    }
  }
}

// "field_id_item"
void Writer::FillFields() {
  const auto& fields = dex_ir_->fields;
  for (size_t i = 0; i < fields.size(); ++i) {
    const auto& ir_field = fields[i];
    auto dexFieldId = &dex_->field_ids[i];
    dexFieldId->class_idx = ir_field->parent->index;
    dexFieldId->type_idx = ir_field->type->index;
    dexFieldId->name_idx = ir_field->name->index;
  }
}

// "method_id_item"
void Writer::FillMethods() {
  const auto& methods = dex_ir_->methods;
  for (size_t i = 0; i < methods.size(); ++i) {
    const auto& ir_method = methods[i];
    auto dexMethodId = &dex_->method_ids[i];
    dexMethodId->class_idx = ir_method->parent->index;
    dexMethodId->proto_idx = ir_method->prototype->index;
    dexMethodId->name_idx = ir_method->name->index;
  }
}

// "class_def_item"
void Writer::FillClassDefs() {
  const auto& classes = dex_ir_->classes;
  for (size_t i = 0; i < classes.size(); ++i) {
    auto ir_class = classes[i].get();
    auto dex_class_def = &dex_->class_defs[i];
    dex_class_def->class_idx = ir_class->type->index;
    dex_class_def->access_flags = ir_class->access_flags;
    dex_class_def->superclass_idx = OptIndex(ir_class->super_class);
    dex_class_def->source_file_idx = OptIndex(ir_class->source_file);
    dex_class_def->interfaces_off = FilePointer(ir_class->interfaces);

    // NOTE: we already set some offsets when we created the
    //  corresponding .dex section:
    //
    //  ->annotations_off
    //  ->class_data_off
    //  ->static_values_off
  }
}

// "type_list"
dex::u4 Writer::WriteTypeList(const std::vector<ir::Type*>& types) {
  if (types.empty()) {
    return 0;
  }

  auto& data = dex_->type_lists;
  dex::u4 offset = data.AddItem(4);
  data.Push<dex::u4>(types.size());
  for (auto ir_type : types) {
    data.Push<dex::u2>(ir_type->index);
  }
  return data.AbsoluteOffset(offset);
}

// "annotation_item"
dex::u4 Writer::WriteAnnotationItem(const ir::Annotation* ir_annotation) {
  SLICER_CHECK_NE(ir_annotation->visibility, dex::kVisibilityEncoded);

  auto& data = dex_->ann_items;
  dex::u4 offset = data.AddItem();
  data.Push<dex::u1>(ir_annotation->visibility);
  WriteAnnotation(ir_annotation, data);
  return data.AbsoluteOffset(offset);
}

// "annotation_set_item"
dex::u4 Writer::WriteAnnotationSet(const ir::AnnotationSet* ir_annotation_set) {
  SLICER_CHECK_NE(ir_annotation_set, nullptr);

  const auto& annotations = ir_annotation_set->annotations;

  auto& data = dex_->ann_sets;
  dex::u4 offset = data.AddItem(4);
  data.Push<dex::u4>(annotations.size());
  for (auto ir_annotation : annotations) {
    data.Push<dex::u4>(FilePointer(ir_annotation));
  }
  return data.AbsoluteOffset(offset);
}

// "annotation_set_ref_list"
dex::u4 Writer::WriteAnnotationSetRefList(
    const ir::AnnotationSetRefList* ir_annotation_set_ref_list) {
  SLICER_CHECK_NE(ir_annotation_set_ref_list, nullptr);

  const auto& annotations = ir_annotation_set_ref_list->annotations;

  auto& data = dex_->ann_set_ref_lists;
  dex::u4 offset = data.AddItem(4);
  data.Push<dex::u4>(annotations.size());
  for (auto ir_annotation_set : annotations) {
    data.Push<dex::u4>(FilePointer(ir_annotation_set));
  }
  return data.AbsoluteOffset(offset);
}

// "annotations_directory_item"
dex::u4 Writer::WriteClassAnnotations(const ir::Class* ir_class) {
  if (ir_class->annotations == nullptr) {
    return 0;
  }

  auto ir_annotations = ir_class->annotations;

  dex::u4& offset = node_offset_[ir_annotations];
  if (offset == 0) {
    // in order to write a contiguous "annotations_directory_item" we do two
    // passes :
    // 1. write the field/method/params annotations content
    // 2. write the directory (including the field/method/params arrays)
    std::vector<dex::FieldAnnotationsItem> dex_field_annotations;
    std::vector<dex::MethodAnnotationsItem> dex_method_annotations;
    std::vector<dex::ParameterAnnotationsItem> dex_param_annotations;

    for (auto irItem : ir_annotations->field_annotations) {
      dex::FieldAnnotationsItem dex_item = {};
      dex_item.field_idx = irItem->field_decl->index;
      dex_item.annotations_off = FilePointer(irItem->annotations);
      dex_field_annotations.push_back(dex_item);
    }

    for (auto irItem : ir_annotations->method_annotations) {
      dex::MethodAnnotationsItem dex_item = {};
      dex_item.method_idx = irItem->method_decl->index;
      dex_item.annotations_off = FilePointer(irItem->annotations);
      dex_method_annotations.push_back(dex_item);
    }

    for (auto irItem : ir_annotations->param_annotations) {
      dex::ParameterAnnotationsItem dex_item = {};
      dex_item.method_idx = irItem->method_decl->index;
      dex_item.annotations_off = FilePointer(irItem->annotations);
      dex_param_annotations.push_back(dex_item);
    }

    dex::u4 class_annotations_offset =
        FilePointer(ir_annotations->class_annotation);

    // now that the annotations content is written,
    // we can write down the "annotations_directory_item"
    dex::AnnotationsDirectoryItem dex_annotations = {};
    dex_annotations.class_annotations_off = class_annotations_offset;
    dex_annotations.fields_size = ir_annotations->field_annotations.size();
    dex_annotations.methods_size = ir_annotations->method_annotations.size();
    dex_annotations.parameters_size = ir_annotations->param_annotations.size();

    auto& data = dex_->ann_directories;
    offset = data.AddItem(4);
    data.Push(dex_annotations);
    data.Push(dex_field_annotations);
    data.Push(dex_method_annotations);
    data.Push(dex_param_annotations);
    offset = data.AbsoluteOffset(offset);
  }
  return offset;
}

// "debug_info_item"
dex::u4 Writer::WriteDebugInfo(const ir::DebugInfo* ir_debug_info) {
  SLICER_CHECK_NE(ir_debug_info, nullptr);

  auto& data = dex_->debug_info;
  dex::u4 offset = data.AddItem();

  // debug info "header"
  data.PushULeb128(ir_debug_info->line_start);
  data.PushULeb128(ir_debug_info->param_names.size());
  for (auto ir_string : ir_debug_info->param_names) {
    data.PushULeb128(OptIndex(ir_string) + 1);
  }

  // debug info "state machine bytecodes"
  const dex::u1* src = ir_debug_info->data.ptr<dex::u1>();
  dex::u1 opcode = 0;
  while ((opcode = *src++) != dex::DBG_END_SEQUENCE) {
    data.Push<dex::u1>(opcode);

    switch (opcode) {
      case dex::DBG_ADVANCE_PC:
        // addr_diff
        data.PushULeb128(dex::ReadULeb128(&src));
        break;

      case dex::DBG_ADVANCE_LINE:
        // line_diff
        data.PushSLeb128(dex::ReadSLeb128(&src));
        break;

      case dex::DBG_START_LOCAL: {
        // register_num
        data.PushULeb128(dex::ReadULeb128(&src));

        dex::u4 name_index = dex::ReadULeb128(&src) - 1;
        data.PushULeb128(MapStringIndex(name_index) + 1);

        dex::u4 type_index = dex::ReadULeb128(&src) - 1;
        data.PushULeb128(MapTypeIndex(type_index) + 1);
      } break;

      case dex::DBG_START_LOCAL_EXTENDED: {
        // register_num
        data.PushULeb128(dex::ReadULeb128(&src));

        dex::u4 name_index = dex::ReadULeb128(&src) - 1;
        data.PushULeb128(MapStringIndex(name_index) + 1);

        dex::u4 type_index = dex::ReadULeb128(&src) - 1;
        data.PushULeb128(MapTypeIndex(type_index) + 1);

        dex::u4 sig_index = dex::ReadULeb128(&src) - 1;
        data.PushULeb128(MapStringIndex(sig_index) + 1);
      } break;

      case dex::DBG_END_LOCAL:
      case dex::DBG_RESTART_LOCAL:
        // register_num
        data.PushULeb128(dex::ReadULeb128(&src));
        break;

      case dex::DBG_SET_FILE: {
        dex::u4 name_index = dex::ReadULeb128(&src) - 1;
        data.PushULeb128(MapStringIndex(name_index) + 1);
      } break;
    }
  }
  data.Push<dex::u1>(dex::DBG_END_SEQUENCE);

  return data.AbsoluteOffset(offset);
}

// instruction[] array
void Writer::WriteInstructions(slicer::ArrayView<const dex::u2> instructions) {
  SLICER_CHECK(!instructions.empty());

  auto offset = dex_->code.Push(instructions);
  dex::u2* ptr = dex_->code.ptr<dex::u2>(offset);
  dex::u2* const end = ptr + instructions.size();

  // relocate the instructions
  while (ptr < end) {
    auto opcode = dex::OpcodeFromBytecode(*ptr);
    dex::u2* idx = &ptr[1];
    dex::u2* idx2 = nullptr;

    size_t idx_size = 0;
    switch (dex::GetFormatFromOpcode(opcode)) {
      case dex::k20bc:
      case dex::k21c:
      case dex::k35c:
      case dex::k3rc:
      case dex::k22c:
        idx_size = 2;
        break;

      case dex::k31c:
        idx_size = 4;
        break;

      case dex::k45cc:
      case dex::k4rcc:
        idx_size = 2;
        idx2 = &ptr[3];
      break;

      default:
        break;
    }

    switch (dex::GetIndexTypeFromOpcode(opcode)) {
      case dex::kIndexStringRef:
        if (idx_size == 4) {
          dex::u4 new_index = MapStringIndex(ReadU4(idx));
          SLICER_CHECK_NE(new_index, dex::kNoIndex);
          WriteU4(idx, new_index);
        } else {
          SLICER_CHECK_EQ(idx_size, 2);
          dex::u4 new_index = MapStringIndex(*idx);
          SLICER_CHECK_NE(new_index, dex::kNoIndex);
          SLICER_CHECK_EQ(dex::u2(new_index), new_index);
          *idx = dex::u2(new_index);
        }
        break;

      case dex::kIndexTypeRef: {
        SLICER_CHECK_EQ(idx_size, 2);
        dex::u4 new_index = MapTypeIndex(*idx);
        SLICER_CHECK_NE(new_index, dex::kNoIndex);
        SLICER_CHECK_EQ(dex::u2(new_index), new_index);
        *idx = dex::u2(new_index);
      } break;

      case dex::kIndexFieldRef: {
        SLICER_CHECK_EQ(idx_size, 2);
        dex::u4 new_index = MapFieldIndex(*idx);
        SLICER_CHECK_NE(new_index, dex::kNoIndex);
        SLICER_CHECK_EQ(dex::u2(new_index), new_index);
        *idx = dex::u2(new_index);
      } break;

      case dex::kIndexMethodRef: {
        SLICER_CHECK_EQ(idx_size, 2);
        dex::u4 new_index = MapMethodIndex(*idx);
        SLICER_CHECK_NE(new_index, dex::kNoIndex);
        SLICER_CHECK_EQ(dex::u2(new_index), new_index);
        *idx = dex::u2(new_index);
      } break;

      case dex::kIndexMethodAndProtoRef: {
        SLICER_CHECK_EQ(idx_size, 2);
        dex::u4 new_index = MapMethodIndex(*idx);
        SLICER_CHECK_NE(new_index, dex::kNoIndex);
        SLICER_CHECK_EQ(dex::u2(new_index), new_index);
        *idx = dex::u2(new_index);
        dex::u4 new_index2 = MapProtoIndex(*idx2);
        SLICER_CHECK_NE(new_index2, dex::kNoIndex);
        SLICER_CHECK_EQ(dex::u2(new_index2), new_index2);
        *idx2 = dex::u2(new_index2);
      } break;

      case dex::kIndexMethodHandleRef: {
        SLICER_CHECK_EQ(idx_size, 2);
        dex::u4 new_index = MapMethodHandleIndex(*idx);
        SLICER_CHECK_NE(new_index, dex::kNoIndex);
        SLICER_CHECK_EQ(dex::u2(new_index), new_index);
        *idx = dex::u2(new_index);
      } break;

      default:
        break;
    }

    auto isize = dex::GetWidthFromBytecode(ptr);
    SLICER_CHECK_GT(isize, 0);
    ptr += isize;
  }
  SLICER_CHECK_EQ(ptr, end);
}

// "try_item[] + encoded_catch_handler_list"
void Writer::WriteTryBlocks(const ir::Code* irCode) {
  SLICER_CHECK(!irCode->try_blocks.empty());

  // use a temporary buffer to build the "encoded_catch_handler_list"
  slicer::Buffer handlers_list;
  auto original_list = irCode->catch_handlers.ptr<dex::u1>();
  auto ptr = original_list;
  std::map<dex::u2, dex::u2> handlers_offset_map;

  dex::u4 handlers_count = dex::ReadULeb128(&ptr);
  handlers_list.PushULeb128(handlers_count);

  for (dex::u4 handler_index = 0; handler_index < handlers_count; ++handler_index) {
    // track the oldOffset/newOffset mapping
    handlers_offset_map[ptr - original_list] = handlers_list.size();

    // parse each "encoded_catch_handler"
    int catch_count = dex::ReadSLeb128(&ptr);
    handlers_list.PushSLeb128(catch_count);

    for (int catch_index = 0; catch_index < std::abs(catch_count); ++catch_index) {
      // type_idx
      dex::u4 type_index = dex::ReadULeb128(&ptr);
      handlers_list.PushULeb128(MapTypeIndex(type_index));

      // address
      handlers_list.PushULeb128(dex::ReadULeb128(&ptr));
    }

    if (catch_count < 1) {
      // catch_all_addr
      handlers_list.PushULeb128(dex::ReadULeb128(&ptr));
    }
  }

  handlers_list.Seal(1);

  // now write everything (try_item[] and encoded_catch_handler_list)
  auto& data = dex_->code;
  dex::u4 tries_offset = data.size();
  data.Push(irCode->try_blocks);
  data.Push(handlers_list);

  // finally relocate the offsets to handlers
  for (dex::TryBlock& dex_try : slicer::ArrayView<dex::TryBlock>(
           data.ptr<dex::TryBlock>(tries_offset), irCode->try_blocks.size())) {
    dex::u2 new_Handler_offset = handlers_offset_map[dex_try.handler_off];
    SLICER_CHECK_NE(new_Handler_offset, 0);
    dex_try.handler_off = new_Handler_offset;
  }
}

// "code_item"
dex::u4 Writer::WriteCode(const ir::Code* irCode) {
  SLICER_CHECK_NE(irCode, nullptr);

  dex::Code dex_code = {};
  dex_code.registers_size = irCode->registers;
  dex_code.ins_size = irCode->ins_count;
  dex_code.outs_size = irCode->outs_count;
  dex_code.tries_size = irCode->try_blocks.size();
  dex_code.debug_info_off = FilePointer(irCode->debug_info);
  dex_code.insns_size = irCode->instructions.size();

  auto& data = dex_->code;
  dex::u4 offset = data.AddItem(4);
  data.Push(&dex_code, offsetof(dex::Code, insns));
  WriteInstructions(irCode->instructions);
  if (!irCode->try_blocks.empty()) {
    data.Align(4);
    WriteTryBlocks(irCode);
  }
  return data.AbsoluteOffset(offset);
}

// "encoded_field"
void Writer::WriteEncodedField(const ir::EncodedField* ir_encoded_field,
                       dex::u4* base_index) {
  dex::u4 index_delta = ir_encoded_field->decl->index;
  SLICER_CHECK_NE(index_delta, dex::kNoIndex);
  if (*base_index != dex::kNoIndex) {
    SLICER_CHECK_GT(index_delta, *base_index);
    index_delta = index_delta - *base_index;
  }
  *base_index = ir_encoded_field->decl->index;

  auto& data = dex_->class_data;
  data.PushULeb128(index_delta);
  data.PushULeb128(ir_encoded_field->access_flags);
}

// "encoded_method"
void Writer::WriteEncodedMethod(const ir::EncodedMethod* ir_encoded_method,
                        dex::u4* base_index) {
  dex::u4 index_delta = ir_encoded_method->decl->index;
  SLICER_CHECK_NE(index_delta, dex::kNoIndex);
  if (*base_index != dex::kNoIndex) {
    SLICER_CHECK_GT(index_delta, *base_index);
    index_delta = index_delta - *base_index;
  }
  *base_index = ir_encoded_method->decl->index;

  dex::u4 code_offset = FilePointer(ir_encoded_method->code);

  auto& data = dex_->class_data;
  data.PushULeb128(index_delta);
  data.PushULeb128(ir_encoded_method->access_flags);
  data.PushULeb128(code_offset);
}

// "class_data_item"
dex::u4 Writer::WriteClassData(const ir::Class* ir_class) {
  if (ir_class->static_fields.empty() && ir_class->instance_fields.empty() &&
      ir_class->direct_methods.empty() && ir_class->virtual_methods.empty()) {
    return 0;
  }

  auto& data = dex_->class_data;
  dex::u4 offset = data.AddItem();

  data.PushULeb128(ir_class->static_fields.size());
  data.PushULeb128(ir_class->instance_fields.size());
  data.PushULeb128(ir_class->direct_methods.size());
  data.PushULeb128(ir_class->virtual_methods.size());

  dex::u4 base_index = dex::kNoIndex;
  for (auto ir_encoded_field : ir_class->static_fields) {
    WriteEncodedField(ir_encoded_field, &base_index);
  }

  base_index = dex::kNoIndex;
  for (auto ir_encoded_field : ir_class->instance_fields) {
    WriteEncodedField(ir_encoded_field, &base_index);
  }

  base_index = dex::kNoIndex;
  for (auto ir_encoded_method : ir_class->direct_methods) {
    WriteEncodedMethod(ir_encoded_method, &base_index);
  }

  base_index = dex::kNoIndex;
  for (auto ir_encoded_method : ir_class->virtual_methods) {
    WriteEncodedMethod(ir_encoded_method, &base_index);
  }

  return data.AbsoluteOffset(offset);
}

// "encoded_array_item"
dex::u4 Writer::WriteClassStaticValues(const ir::Class* ir_class) {
  if (ir_class->static_init == nullptr) {
    return 0;
  }

  dex::u4& offset = node_offset_[ir_class->static_init];
  if (offset == 0) {
    auto& data = dex_->encoded_arrays;
    offset = data.AddItem();
    WriteEncodedArray(ir_class->static_init, data);
    offset = data.AbsoluteOffset(offset);
  }
  return offset;
}

// Map an index from the original .dex to the new index
dex::u4 Writer::MapStringIndex(dex::u4 index) const {
  if (index != dex::kNoIndex) {
    index = dex_ir_->strings_map.at(index)->index;
    SLICER_CHECK_NE(index, dex::kNoIndex);
  }
  return index;
}

// Map an index from the original .dex to the new index
dex::u4 Writer::MapTypeIndex(dex::u4 index) const {
  if (index != dex::kNoIndex) {
    index = dex_ir_->types_map.at(index)->index;
    SLICER_CHECK_NE(index, dex::kNoIndex);
  }
  return index;
}

// Map an index from the original .dex to the new index
dex::u4 Writer::MapFieldIndex(dex::u4 index) const {
  if (index != dex::kNoIndex) {
    index = dex_ir_->fields_map.at(index)->index;
    SLICER_CHECK_NE(index, dex::kNoIndex);
  }
  return index;
}

// Map an index from the original .dex to the new index
dex::u4 Writer::MapMethodIndex(dex::u4 index) const {
  if (index != dex::kNoIndex) {
    index = dex_ir_->methods_map.at(index)->index;
    SLICER_CHECK_NE(index, dex::kNoIndex);
  }
  return index;
}

// Map an index from the original .dex to the new index
dex::u4 Writer::MapMethodHandleIndex(dex::u4 index) const {
  if (index != dex::kNoIndex) {
    index = dex_ir_->method_handles_map.at(index)->index;
    SLICER_CHECK_NE(index, dex::kNoIndex);
  }
  return index;
}

// Map an index from the original .dex to the new index
dex::u4 Writer::MapProtoIndex(dex::u4 index) const {
  if (index != dex::kNoIndex) {
    index = dex_ir_->protos_map.at(index)->index;
    SLICER_CHECK_NE(index, dex::kNoIndex);
  }
  return index;
}

// .dex IR node to file pointer (absolute offset)
dex::u4 Writer::FilePointer(const ir::Node* ir_node) const {
  if (ir_node == nullptr) {
    return 0;
  }
  auto it = node_offset_.find(ir_node);
  SLICER_CHECK(it != node_offset_.end());
  dex::u4 offset = it->second;
  SLICER_CHECK_GT(offset, 0);
  return offset;
}

}  // namespace dex

```

`update.json`:

```json
{
	"version": "r17",
	"versionCode": 17,
	"zipUrl": "https://github.com/j-hc/FlagSecurePatcher/releases/latest/download/flag-secure-patcher-r17.zip",
	"changelog": "https://raw.githubusercontent.com/j-hc/FlagSecurePatcher/master/README.md"
}

```