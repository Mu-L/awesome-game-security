Project Path: arc_milakov_int_fastdiv_0lwl9p_4

Source Tree:

```txt
arc_milakov_int_fastdiv_0lwl9p_4
├── README.md
├── int_fastdiv.h
└── tests
    ├── Makefile
    ├── cuda_common.h
    ├── functional_test.cu
    └── performance_test.cu

```

`README.md`:

```md
Fast integer division
=====================

Integer division is known to be relatively slow on modern CPUs and GPUs. The compiler generates ~30 instructions for a single integer division operation:

```c++
int q = n / d;
```

But if the divisor is known at compile time then the compiler calculates a pair of magic numbers `M` and `s`, such that

```c++
q = hi32bits(n * M) >> s; // it works for all integer n
```

Well, it is a little bit more complex: there are some corner cases requring additional operations. Nevertheless these multiplication and right shift remain the core of this fast division.

*int_fastdiv* class
=================

What if you have integer division and the divisor is not known at compile time? If you do integer division by the same divisor multiple times then you might use the same trick the compiler does, here in runtime. And you don't have to do it manually - **int_fastdiv** class does all the dirty work, calculating those magic numbers. All you need to do is to `#include "int_fastdiv.h"` and replace `int` type of the divisor with `int_fastdiv`.

The class has all the necessary constructors and operators defined to allow you using objects of this class as if they were integers. Specifically, it overrides / and % operators to utilize precomputed magic numbers.

Example
=======

I created this class with CUDA kernels in mind, but you should be able to use it in plain C++ code. Suppose you have a kernel which accepts integer parameter `d` and divides by this `d` somewhere in kernel code, and C code which runs this kernel:

```c++
__global__ kernel_name(int d)
{
  int elem_id = blockIdx.x * blockDim.x + threadIdx.x;
  int q = elem_id / d;
  ...
}
...
kernel_name<<<grid_size,threadblock_size>>>(rand());
```

Here we add `#include` directive and replace the type of the kernel's parameter with `int_fastdiv`:

```c++
#include "int_fastdiv.h"
...
__global__ kernel_name(int_fastdiv d)
{
  int elem_id = blockIdx.x * blockDim.x + threadIdx.x;
  int q = elem_id / d;
  ...
}
...
kernel_name<<<grid_size,threadblock_size>>>(rand());
```

That's it. `int_fastdiv` object will be constructed right when you call the kernel - on the host, once. Each thread of the CUDA kernel will utlizie fast integer division procedure when dividing `elem_id` by `d` of type `int_fastdiv`.

Performance
===========

Experiments show that division by `int_fastdiv` is about 2x faster than plain division by integer.

License
=======

It is an open-source software distributed under the [Apache License v2.0](http://www.apache.org/licenses/LICENSE-2.0).

```

`int_fastdiv.h`:

```h
/*
 *  Copyright 2014 Maxim Milakov
 *
 *  Licensed under the Apache License, Version 2.0 (the "License");
 *  you may not use this file except in compliance with the License.
 *  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 *  Unless required by applicable law or agreed to in writing, software
 *  distributed under the License is distributed on an "AS IS" BASIS,
 *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *  See the License for the specific language governing permissions and
 *  limitations under the License.
 */

#ifndef _INT_FASTDIV_KJGIUHFG
#define _INT_FASTDIV_KJGIUHFG

class int_fastdiv
{
public:
	// divisor != 0 
	__host__ __device__ __forceinline__
	int_fastdiv(int divisor = 0)
	: d(divisor)
	{
		update_magic_numbers();
	}

	__host__ __device__ __forceinline__
	int_fastdiv& operator =(int divisor)
	{
		this->d = divisor;
		update_magic_numbers();
		return *this;
	}

	__host__ __device__ __forceinline__
	operator int() const
	{
		return d;
	}

private:
	int d;
	int M;
	int s;
	int n_add_sign;

	// Hacker's Delight, Second Edition, Chapter 10, Integer Division By Constants
	__host__ __device__ __forceinline__
	void update_magic_numbers()
	{
		if (d == 1)
		{
			M = 0;
			s = -1;
			n_add_sign = 1;
			return;
		}
		else if (d == -1)
		{
			M = 0;
			s = -1;
			n_add_sign = -1;
			return;
		}

		int p;
		unsigned int ad, anc, delta, q1, r1, q2, r2, t;
		const unsigned two31 = 0x80000000;
		ad = (d == 0) ? 1 : abs(d);
		t = two31 + ((unsigned int)d >> 31);
		anc = t - 1 - t % ad;
		p = 31;
		q1 = two31 / anc;
		r1 = two31 - q1 * anc;
		q2 = two31 / ad;
		r2 = two31 - q2 * ad;
		do
		{
			++p;
			q1 = 2 * q1;
			r1 = 2 * r1;
			if (r1 >= anc)
			{
				++q1;
				r1 -= anc;
			}
			q2 = 2 * q2;
			r2 = 2 * r2;
			if (r2 >= ad)
			{
				++q2;
				r2 -= ad;
			}
			delta = ad - r2;
		} while (q1 < delta || (q1 == delta && r1 == 0));
		this->M = q2 + 1;
		if (d < 0)
			this->M = -this->M;
		this->s = p - 32;

		if ((d > 0) && (M < 0))
			n_add_sign = 1;
		else if ((d < 0) && (M > 0))
			n_add_sign = -1;
		else
			n_add_sign = 0;			
	}

	__host__ __device__ __forceinline__
	friend int operator/(const int divident, const int_fastdiv& divisor);
};

__host__ __device__ __forceinline__
int operator/(const int n, const int_fastdiv& divisor)
{
	int q;
#ifdef __CUDA_ARCH__
	asm("mul.hi.s32 %0, %1, %2;" : "=r"(q) : "r"(divisor.M), "r"(n));
#else
	q = (((unsigned long long)((long long)divisor.M * (long long)n)) >> 32);
#endif
	q += n * divisor.n_add_sign;
	if (divisor.s >= 0)
	{
		q >>= divisor.s; // we rely on this to be implemented as arithmetic shift
		q += (((unsigned int)q) >> 31);
	}
	return q;
}

__host__ __device__ __forceinline__
int operator%(const int n, const int_fastdiv& divisor)
{
	int quotient = n / divisor;
	int remainder = n - quotient * divisor;
	return remainder;
}

__host__ __device__ __forceinline__
int operator/(const unsigned int n, const int_fastdiv& divisor)
{
	return ((int)n) / divisor;
}

__host__ __device__ __forceinline__
int operator%(const unsigned int n, const int_fastdiv& divisor)
{
	return ((int)n) % divisor;
}

__host__ __device__ __forceinline__
int operator/(const short n, const int_fastdiv& divisor)
{
	return ((int)n) / divisor;
}

__host__ __device__ __forceinline__
int operator%(const short n, const int_fastdiv& divisor)
{
	return ((int)n) % divisor;
}

__host__ __device__ __forceinline__
int operator/(const unsigned short n, const int_fastdiv& divisor)
{
	return ((int)n) / divisor;
}

__host__ __device__ __forceinline__
int operator%(const unsigned short n, const int_fastdiv& divisor)
{
	return ((int)n) % divisor;
}

__host__ __device__ __forceinline__
int operator/(const char n, const int_fastdiv& divisor)
{
	return ((int)n) / divisor;
}

__host__ __device__ __forceinline__
int operator%(const char n, const int_fastdiv& divisor)
{
	return ((int)n) % divisor;
}

__host__ __device__ __forceinline__
int operator/(const unsigned char n, const int_fastdiv& divisor)
{
	return ((int)n) / divisor;
}

__host__ __device__ __forceinline__
int operator%(const unsigned char n, const int_fastdiv& divisor)
{
	return ((int)n) % divisor;
}

#endif

```

`tests/Makefile`:

```
all: performance_test functional_test

performance_test: performance_test.cu ../int_fastdiv.h Makefile
	nvcc -o performance_test performance_test.cu -lineinfo -gencode arch=compute_20,code=sm_20 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=\"compute_50,sm_50\"

functional_test: functional_test.cu ../int_fastdiv.h Makefile
	nvcc -o functional_test functional_test.cu -gencode arch=compute_20,code=sm_20 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=\"compute_50,sm_50\"

clean:
	nvcc -o performance_test performance_test.cu -gencode arch=compute_20,code=sm_20 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=\"compute_50,sm_50\" -clean
	nvcc -o functional_test functional_test.cu -gencode arch=compute_20,code=sm_20 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=\"compute_50,sm_50\" -clean
	$(RM) performance_test functional_test

```

`tests/cuda_common.h`:

```h
/*
 *  Copyright 2014 Maxim Milakov
 *
 *  Licensed under the Apache License, Version 2.0 (the "License");
 *  you may not use this file except in compliance with the License.
 *  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 *  Unless required by applicable law or agreed to in writing, software
 *  distributed under the License is distributed on an "AS IS" BASIS,
 *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *  See the License for the specific language governing permissions and
 *  limitations under the License.
 */

#include <cuda_runtime.h>
#include <iostream>

#define cuda_safe_call(callstr) {cudaError_t error_code = callstr; if (error_code != cudaSuccess) { std::cerr << std::endl << "CUDA error '" << cudaGetErrorString(error_code) << "' at file " << __FILE__ << " at line " << __LINE__ << std::endl; exit(1);}}

```

`tests/functional_test.cu`:

```cu
/*
 *  Copyright 2014 Maxim Milakov
 *
 *  Licensed under the Apache License, Version 2.0 (the "License");
 *  you may not use this file except in compliance with the License.
 *  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 *  Unless required by applicable law or agreed to in writing, software
 *  distributed under the License is distributed on an "AS IS" BASIS,
 *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *  See the License for the specific language governing permissions and
 *  limitations under the License.
 */

#include <iostream>
#include <stdio.h>
#include <cuda_runtime.h>
#include <string>

#include "cuda_common.h"
#include "../int_fastdiv.h"

__global__ void check(int_fastdiv divisor, int * results)
{
	int divident = blockIdx.x * blockDim.x + threadIdx.x;

	int quotient = divident / (int)divisor;
	int fast_quotient = divident / divisor;

	if (quotient != fast_quotient)
	{
		int error_id = atomicAdd(&results[0], 1);
		if (error_id == 0)
		{
			results[1] = divident;
			results[2] = quotient;
			results[3] = fast_quotient;
		}
	}

	divident = -divident;

	quotient = divident / (int)divisor;
	fast_quotient = divident / divisor;

	if (quotient != fast_quotient)
	{
		int error_id = atomicAdd(&results[0], 1);
		if (error_id == 0)
		{
			results[1] = divident;
			results[2] = quotient;
			results[3] = fast_quotient;
		}
	}
}

int gpu_check()
{
	const int threadblock_size = 256;
	const int divisor_count = 100000;
	const int divident_count = 1000000;

	int grid_size = (divident_count + threadblock_size - 1) / threadblock_size;

	int buf[4];
	int * buf_d;
	cuda_safe_call(cudaMalloc(&buf_d, sizeof(int) * 4));

	std::cout << "Running GPU functional test on " << divisor_count << " divisors, with " << grid_size * threadblock_size << " dividents for each divisor" << std::endl;
	for(int d = 1; d < divisor_count; ++d)
	{
		for(int sign = 1; sign >= -1; sign -= 2)
		{
			int divisor = d * sign;

			std::cout << "Checking divisor " << divisor << "... ";

			cuda_safe_call(cudaMemset(buf_d, 0, sizeof(int) * 4));
			check<<<grid_size,threadblock_size>>>(divisor, buf_d);
			cuda_safe_call(cudaMemcpy(buf, buf_d, sizeof(int) * 4, cudaMemcpyDeviceToHost));
			cuda_safe_call(cudaDeviceSynchronize());

			if (buf[0] > 0)
			{
				std::cout << buf[0] << " wrong results, one of them is for divident " << buf[1] << ", correct quotient = " << buf[2] << ", fast computed quotient = " << buf[3] << std::endl;
				return 1;
			}

			std::cout << "done" << std::endl;
		}
	}

	cuda_safe_call(cudaFree(buf_d));

	return 0;
}

int cpu_check()
{
	const int divisor_count = 100000;
	const int divident_count = 1000000;
	std::cout << "Running CPU functional test on " << divisor_count << " divisors, with " << divident_count << " dividents for each divisor" << std::endl;
	for(int d = 1; d < divisor_count; ++d)
	{
		for(int sign = 1; sign >= -1; sign -= 2)
		{
			int divisor = d * sign;

			std::cout << "Checking divisor " << divisor << "... ";

			int_fastdiv fast_divisor(divisor);

			for(int dd = 0; dd < divident_count; ++dd)
			{
				for(int ss = 1; ss >= -1; ss -= 2)
				{
					int divident = dd * ss;

					int quotient = divident / divisor;
					int fast_quotient = divident / fast_divisor;
					if (quotient != fast_quotient)
					{
						std::cout << "wrong result for divident " << divident << ", correct quotient = " << quotient << ", fast computed quotient = " << fast_quotient << std::endl;
						return 1;
					}
				}
			}

			std::cout << "done" << std::endl;
		}
	}

	return 0;
}

int main(int argc, char* argv[])
{
	bool run_gpu = false;

	if (argc > 1)
		run_gpu = (strcmp(argv[1], "gpu") == 0);

	int res;
	if (run_gpu)
		res = gpu_check();
	else
		res = cpu_check();

	return res;
}

```

`tests/performance_test.cu`:

```cu
/*
 *  Copyright 2014 Maxim Milakov
 *
 *  Licensed under the Apache License, Version 2.0 (the "License");
 *  you may not use this file except in compliance with the License.
 *  You may obtain a copy of the License at
 *
 *      http://www.apache.org/licenses/LICENSE-2.0
 *
 *  Unless required by applicable law or agreed to in writing, software
 *  distributed under the License is distributed on an "AS IS" BASIS,
 *  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 *  See the License for the specific language governing permissions and
 *  limitations under the License.
 */

#include <iostream>
#include <stdio.h>
#include <cuda_runtime.h>

#include "cuda_common.h"
#include "../int_fastdiv.h"

template<typename divisor_type>
__global__ void throughput_test(
	divisor_type d1,
	divisor_type d2,
	divisor_type d3,
	int dummy,
	int * buf)
{
	int elem_id = blockIdx.x * blockDim.x + threadIdx.x;

	int x1 = elem_id / d1;
	int x2 = elem_id / d2;
	int x3 = elem_id / d3;

	int aggregate = x1 + x2 + x3;	
	if (aggregate & dummy == 1)
		buf[0] = aggregate;
}

template<typename divisor_type>
__global__ void latency_test(
	divisor_type d1,
	divisor_type d2,
	divisor_type d3,
	divisor_type d4,
	divisor_type d5,
	divisor_type d6,
	divisor_type d7,
	divisor_type d8,
	divisor_type d9,
	divisor_type d10,
	int dummy,
	int * buf)
{
	int elem_id = blockIdx.x * blockDim.x + threadIdx.x;

	int x = elem_id;
	x = x / d1;
	x = x / d2;
	x = x / d3;
	x = x / d4;
	x = x / d5;
	x = x / d6;
	x = x / d7;
	x = x / d8;
	x = x / d9;
	x = x / d10;

	if (x & dummy == 1)
		buf[0] = x;
}

int main(int argc, char* argv[])
{
	int grid_size = 32 * 1024;
	int threadblock_size = 256;

	cudaEvent_t start, stop;
	float elapsed_time_slow;
	float elapsed_time_fast;

	cuda_safe_call(cudaEventCreate(&start));
	cuda_safe_call(cudaEventCreate(&stop));

	{
		std::cout << "THROUGHPUT TEST" << std::endl;

		std::cout << "Benchmarking plain division by constant... ";
		cuda_safe_call(cudaEventRecord(start, 0));
		throughput_test<int><<<grid_size, threadblock_size>>>(3, 5, 7, 0, 0);
		cuda_safe_call(cudaEventRecord(stop, 0));
		cuda_safe_call(cudaEventSynchronize(stop));
		cuda_safe_call(cudaEventElapsedTime(&elapsed_time_slow, start, stop));
		std::cout << elapsed_time_slow << " milliseconds" << std::endl;

		std::cout << "Benchmarking fast division by constant... ";
		cuda_safe_call(cudaEventRecord(start, 0));
		throughput_test<int_fastdiv><<<grid_size, threadblock_size>>>(3, 5, 7, 0, 0);
		cuda_safe_call(cudaEventRecord(stop, 0));
		cuda_safe_call(cudaEventSynchronize(stop));
		cuda_safe_call(cudaEventElapsedTime(&elapsed_time_fast, start, stop));
		std::cout << elapsed_time_fast << " milliseconds" << std::endl;

		std::cout << "Speedup = " << elapsed_time_slow / elapsed_time_fast << std::endl;
	}

	{
		std::cout << "LATENCY TEST" << std::endl;

		std::cout << "Benchmarking plain division by constant... ";
		cuda_safe_call(cudaEventRecord(start, 0));
		latency_test<int><<<grid_size, threadblock_size>>>(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 0);
		cuda_safe_call(cudaEventRecord(stop, 0));
		cuda_safe_call(cudaEventSynchronize(stop));
		cuda_safe_call(cudaEventElapsedTime(&elapsed_time_slow, start, stop));
		std::cout << elapsed_time_slow << " milliseconds" << std::endl;

		std::cout << "Benchmarking fast division by constant... ";
		cuda_safe_call(cudaEventRecord(start, 0));
		latency_test<int_fastdiv><<<grid_size, threadblock_size>>>(1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 0, 0);
		cuda_safe_call(cudaEventRecord(stop, 0));
		cuda_safe_call(cudaEventSynchronize(stop));
		cuda_safe_call(cudaEventElapsedTime(&elapsed_time_fast, start, stop));
		std::cout << elapsed_time_fast << " milliseconds" << std::endl;

		std::cout << "Speedup = " << elapsed_time_slow / elapsed_time_fast << std::endl;
	}

	cuda_safe_call(cudaEventDestroy(start));
	cuda_safe_call(cudaEventDestroy(stop));

	return 0;
}

```