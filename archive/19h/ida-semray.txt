Project Path: arc_19h_ida-semray_ucksr08g

Source Tree:

```txt
arc_19h_ida-semray_ucksr08g
├── README.md
├── dumper.py
├── ida-plugin.json
├── micro-analyzer.py
├── ptn_utils.py
└── semray.py

```

`README.md`:

```md
# SemRay - AI-Powered Semantic Analysis for IDA Pro

SemRay is a powerful IDA Pro plugin that leverages Google's Gemini AI to provide intelligent semantic analysis of binary code. It automatically suggests meaningful function names, detailed comments, and descriptive variable renames based on deep contextual understanding of your code.

## Features

- **Intelligent Function Naming**: Generate concise, descriptive function names that encode role and domain (e.g., `crc32_checksum`, `parse_http_header`)
- **Comprehensive Comments**: Automatically create detailed multi-line comments explaining function behavior
- **Variable Renaming**: Suggest meaningful names for local variables and function arguments
- **Context-Aware Analysis**: Analyzes callers, callees, and cross-references to understand function relationships
- **Flexible Analysis Modes**:
  - Analyze single functions
  - Analyze all functions in context
  - Analyze functions within N levels of call depth
- **Multiple Content Modes**: Choose between decompiled C code or raw assembly for LLM analysis
- **Optional CodeDumper Integration**: Enhanced context discovery with virtual calls, jump tables, and PTN provenance annotations
- **Interactive UI**: Review and selectively apply suggested changes through an intuitive tabbed interface

## Requirements

### Essential

- **IDA Pro 7.6+** with Python 3 and PyQt5 support
- **Hex-Rays Decompiler** (for decompilation mode and PTN analysis)
- **Python Libraries**:
  ```bash
  pip install google-genai pydantic
  ```
- **Google AI API Key**: Required for Gemini API access

## Installation

### 1. Plugin Installation

Copy the plugin directory to your IDA plugins folder:

```bash
# Linux
cp -r semray ~/.idapro/plugins/semray

# Windows
copy semray "C:\Users\YourName\AppData\Roaming\Hex-Rays\IDA Pro\plugins\semray"

# macOS
cp -r semray ~/Library/Application\ Support/Hex-Rays/IDA\ Pro/plugins/semray
```

Alternatively, you can place it directly in the IDA installation's plugins directory:

```bash
# Example for Linux
cp -r semray /opt/ida-pro/plugins/semray
```

### 2. Python Dependencies

Install required Python libraries in IDA's Python environment:

```bash
# If using system Python (ensure it matches IDA's Python version)
pip install google-genai pydantic

# If using IDA's bundled Python
/path/to/ida/python3 -m pip install google-genai pydantic
```

### 3. API Key Configuration

Set your Google AI API key as an environment variable:

```bash
# Linux/macOS - Add to ~/.bashrc or ~/.zshrc
export GOOGLE_API_KEY="your-api-key-here"

# Windows - Set as system environment variable
setx GOOGLE_API_KEY "your-api-key-here"
```

To obtain a Google AI API key:
1. Visit [Google AI Studio](https://makersuite.google.com/app/apikey)
2. Sign in with your Google account
3. Create a new API key
4. Copy and set it as the `GOOGLE_API_KEY` environment variable

### 4. Verify Installation

Start IDA Pro and check the output window for:
```
Initializing SemRay (Google AI Semantic Analysis) plugin.
SemRay: CodeDumper integration enabled.  # (if CodeDumper is available)
SemRay (Google AI Semantic Analysis) initialized successfully.
```

## Usage

### Quick Start

1. **Navigate to a function** in IDA Pro (Disassembly or Pseudocode view)
2. **Right-click** to open the context menu
3. Select **SemRay Analysis** from the menu
4. Choose your analysis mode:
   - **Analyze CURRENT Func Only**: Analyzes only the selected function
   - **Analyze ALL Funcs in Context**: Analyzes the function plus all callers/callees in context
   - **Analyze Current + N Levels**: Analyzes functions within N depth levels

### Configuration Prompts

When you trigger an analysis, you'll be prompted for:

1. **Content Mode**: Choose between:
   - **Decompiled**: Uses Hex-Rays decompiled C pseudocode (recommended)
   - **Assembly**: Uses raw disassembly (useful when decompilation fails)

2. **Context Depths**:
   - **Caller Depth**: How many levels of calling functions to include (default: 1)
   - **Callee Depth**: How many levels of called functions to include (default: 1)
   - **Analysis Depth**: (Depth-limited mode only) How many function levels to analyze

### Analysis Workflow

1. **Context Collection**: The plugin gathers code, call graphs, cross-references, and literals
2. **LLM Processing**: Sends the context to Google's Gemini model for semantic analysis
3. **Results Display**: Opens a tabbed UI showing suggestions for each function
4. **Review & Apply**: 
   - Review each suggestion
   - Uncheck items you don't want to apply
   - Click **Apply Selected** to update your IDB
   - Click **Close** to dismiss without changes

### Results UI

The results window displays tabs for each analyzed function, showing:

- **Suggested Function Name**: With reasoning and evidence
- **Suggested Comment**: Multi-line documentation of function behavior
- **Variable Renames**: Original → New name mappings with explanations

Each suggestion has a checkbox - uncheck to exclude it from being applied.

### Batch Analysis

You can also analyze multiple functions at once:

1. Go to **Edit → Plugins → SemRay (Google AI Semantic Analysis)**
2. Enter comma-separated function names or addresses:
   ```
   sub_401000, parse_header, 0x402340
   ```
3. Choose content mode and context depths
4. Review and apply results

## How It Works

### Context Building

SemRay builds rich context for the LLM by collecting:

1. **Code Content**:
   - Decompiled C pseudocode (via Hex-Rays)
   - Or raw disassembly with labels and addresses

2. **Call Graph**:
   - Direct calls
   - Indirect calls
   - Virtual calls (with CodeDumper)
   - Jump tables (with CodeDumper)
   - Tail calls

3. **Semantic Hints**:
   - String literals referenced in functions
   - Large constant values
   - Function prototypes/signatures

4. **PTN Annotations** (with CodeDumper):
   - Provenance tracking of data flows
   - Virtual table analysis
   - Enhanced cross-reference context

### LLM Processing

The plugin sends a carefully crafted prompt to Google's Gemini model that includes:

- **Persona**: "You are an expert reverse engineer"
- **Naming Contract**: Rules for meaningful, non-generic names
- **Call Graph**: Relationships between functions
- **Code Context**: All relevant source code
- **Schema Enforcement**: Structured JSON output via response schema

The LLM analyzes the code holistically and provides:
- Function names that encode purpose and domain
- Detailed comments explaining behavior
- Evidence-based reasoning for each suggestion
- Variable renames that clarify intent

### Name Validation

The plugin filters out generic/unhelpful names using regex patterns:
- Rejects: `var5`, `tmp`, `foo`, `bar`, `helper`, `unused`
- Only accepts: meaningful, descriptive identifiers

### IDB Updates

When you apply changes, the plugin:
1. Sets function comments (with word wrapping)
2. Renames functions (with collision checking)
3. Renames local variables (using Hex-Rays API)
4. Marks affected functions as dirty
5. Refreshes pseudocode views automatically

## Configuration

### Model Selection

By default, SemRay uses `gemini-flash-latest` for speed and cost-efficiency. To change the model, edit `semray.py`:

```python
DEFAULT_GEMINI_MODEL = "gemini-flash-latest"  # or "gemini-pro-latest"
MODELS_TO_REGISTER = [DEFAULT_GEMINI_MODEL]
```

### Default Depths

Customize default analysis depths:

```python
DEFAULT_CONTEXT_CALLER_DEPTH = 1
DEFAULT_CONTEXT_CALLEE_DEPTH = 1
DEFAULT_ANALYSIS_DEPTH = 1
```

### Cross-Reference Types

Control which reference types are considered (when using CodeDumper):

```python
DEFAULT_XREF_TYPES = {
    'direct_call',
    'indirect_call',
    'data_ref',
    'immediate_ref',
    'tail_call_push_ret',
    'virtual_call',
    'jump_table',
}
```

### Safety Settings

The plugin disables Google AI's content filtering to avoid blocking reverse engineering content. Adjust in `semray.py` if needed:

```python
DEFAULT_SAFETY_SETTINGS = [
    types.SafetySetting(category='HARM_CATEGORY_HATE_SPEECH', threshold='BLOCK_NONE'),
    types.SafetySetting(category='HARM_CATEGORY_DANGEROUS_CONTENT', threshold='BLOCK_NONE'),
    types.SafetySetting(category='HARM_CATEGORY_HARASSMENT', threshold='BLOCK_NONE'),
    types.SafetySetting(category='HARM_CATEGORY_SEXUALLY_EXPLICIT', threshold='BLOCK_NONE'),
]
```

## CodeDumper Integration

SemRay can optionally use the CodeDumper plugin for enhanced capabilities:

### With CodeDumper

- Advanced virtual call resolution via v-table analysis
- Jump table detection and analysis
- Detailed cross-reference reasons
- PTN (Provenance Tracking Network) annotations showing data flow
- More comprehensive context discovery

### Without CodeDumper

- Falls back to standard IDA API functions
- Basic call graph analysis
- Direct and indirect call tracking
- Fully functional but with less contextual information

The plugin automatically detects CodeDumper and enables integration if available.

## Troubleshooting

### Plugin Not Loading

**Check IDA Output Window** for error messages:
- "PyQt5 not found": Install PyQt5 in IDA's Python environment
- "pydantic not found": Install pydantic (`pip install pydantic`)
- "google-genai not found": Install google-genai (`pip install google-genai`)

### API Key Issues

**"GOOGLE_API_KEY environment variable not set"**:
- Verify the environment variable is set: `echo $GOOGLE_API_KEY` (Linux/Mac) or `echo %GOOGLE_API_KEY%` (Windows)
- Restart IDA Pro after setting the variable
- Check for typos in the variable name

### Empty or Blocked Responses

**"Google AI response was empty or blocked"**:
- Check Google AI API quota/billing
- Review safety settings if content is being filtered
- Try a simpler function first to verify API connectivity

### Decompilation Failures

**"Decompilation FAILED"**:
- Ensure Hex-Rays decompiler is installed and licensed
- Try **Assembly** mode instead of **Decompiled** mode
- Some functions may not decompile due to code complexity

### Variable Rename Failures

**Variables not renamed**:
- Ensure the function can be decompiled
- Check that variable names match exactly (case-sensitive)
- Some variables may be compiler-generated and cannot be renamed

### Performance Issues

**Slow analysis**:
- Reduce caller/callee depth (try 1 or 2 instead of higher values)
- Analyze fewer functions at once
- Use "Analyze CURRENT Func Only" for individual functions
- Consider using `gemini-flash-latest` instead of `gemini-pro`

## Best Practices

1. **Start Small**: Begin with single function analysis to verify setup and understand results
2. **Iterative Refinement**: Analyze high-level functions first, then drill down into details
3. **Context Balance**: More context improves accuracy but increases cost and time
   - Depth 1-2: Fast, good for focused analysis
   - Depth 3+: Slower, better for understanding complex relationships
4. **Review Carefully**: Always review suggestions before applying - AI can make mistakes
5. **Backup Your IDB**: Keep backups before applying large batch changes
6. **Use Decompiled Mode**: Generally provides better results than assembly
7. **Check Naming Contract**: Ensure suggested names follow your team's conventions

## Architecture

### Plugin Structure

```
semray/
├── semray.py              # Main plugin file
├── ida-plugin.json        # IDA plugin metadata
└── codedump/              # Optional CodeDumper integration
    ├── codedump.py        # Context discovery utilities
    ├── micro-analyzer.py  # Micro-architectural analysis
    └── ptn_utils.py       # PTN provenance tracking
```

### Key Components

1. **Configuration** (Lines 127-173): Constants, API settings, models
2. **Data Models** (Lines 186-219): Pydantic schemas for validation
3. **Context Builder** (Lines 337-496): Gathers code, call graphs, semantics
4. **Analysis Orchestrator** (Lines 501-647): Manages the analysis pipeline
5. **UI Components** (Lines 650-908): PyQt5 widgets for results display
6. **IDA Integration** (Lines 911-1207): Actions, hooks, plugin lifecycle

### Execution Flow

```
User Action (Right-click menu)
    ↓
CtxActionHandler.activate()
    ↓
async_call() orchestrates:
    ↓
1. build_context_material() [IDA main thread]
    ↓
2. Construct LLM prompt with context
    ↓
3. do_google_ai_analysis() [Background thread]
    ↓
4. Parse & validate JSON response
    ↓
5. do_show_ui() [UI thread]
    ↓
User reviews and clicks "Apply Selected"
    ↓
_perform_ida_updates() [IDA main thread]
    ↓
IDB updated, views refreshed
```

## License

This plugin is provided as-is for reverse engineering and security research purposes.

## Contributing

Contributions are welcome! Key areas for improvement:
- Support for additional LLM providers (OpenAI, Claude, etc.)
- Enhanced prompt engineering for better results
- Additional context extraction strategies
- UI/UX improvements
- Performance optimizations

## Changelog

### Current Version
- Initial release with Google AI (Gemini) integration
- Support for decompiled and assembly analysis modes
- Optional CodeDumper integration
- Interactive UI for reviewing suggestions
- Concurrent analysis prevention
- Comprehensive error handling and fallbacks

## Support

For issues, questions, or feature requests, please check the output window in IDA Pro for diagnostic information and error messages.

## Credits

- Built on IDA Pro's powerful reverse engineering platform
- Leverages Google's Gemini AI for semantic understanding
- Integrates with CodeDumper plugin for enhanced context (optional)
- Uses Pydantic for robust data validation

```

`dumper.py`:

```py
# -*- coding: utf-8 -*-
"""
CodeDumper + PTN

Summary:
  IDA Pro + Hex-Rays plugin to:
  1) Dump decompiled code for function(s) with callers/callees/refs; annotates each function block
     with compact provenance lines (@PTN) near the code, including upstream (I:) and downstream (E:) edges,
     aliases (A:), and global relationships (G:).
  2) Generate DOT graphs of the call graph.
  3) Generate PTN files describing dataflow provenance (locals/params/globals) across calls, including
     aliasing (e.g., &a1[123]) and global write→read relationships.
  4) Dump assembly for function(s) with callers/callees/refs in the same order & layout as the decompiled
     dump, including the same PTN annotations & xref summaries.
  5) Inject per-instruction @PTN hints inline in assembly by correlating callsites and global touches
     back to item EAs. (Uses CTREE to collect callsite EAs and expression EAs for global touches.)

Requirements:
  - IDA Pro 7.6+
  - Hex-Rays Decompiler
  - PyQt5 for dialogs (if missing, plugin still loads but dialogs may fail)
"""

import ida_kernwin
import ida_hexrays
import ida_funcs
import ida_name
import ida_bytes
import idaapi
import idautils
import idc
import ida_xref
import ida_nalt
import ida_ua
import ida_idp
import ida_segment
import ida_ida
import ida_gdl
import ida_lines

import threading
import os
import sys
from functools import partial
import traceback
import time
import re
from collections import defaultdict
from typing import Dict, Set, List, Tuple

try:
    from PyQt5 import QtCore, QtGui, QtWidgets
except ImportError:
    pass

PLUGIN_DIR = os.path.dirname(__file__)
if PLUGIN_DIR and PLUGIN_DIR not in sys.path:
    sys.path.append(PLUGIN_DIR)

from ptn_utils import PTNEmitter, FunctionSummary  # type: ignore
from micro_analyzer import analyze_functions_ctree  # type: ignore

PLUGIN_NAME = "CodeDumper"
ACTION_ID_CTX = "codedumper:dump_callers_callees_refs_ctx"
ACTION_LABEL_CTX = "Dump Function + Callers/Callees/Refs..."
ACTION_TOOLTIP_CTX = "Decompile current function, callers, callees, and referenced functions to a C file"
ACTION_ID_DOT_CTX = "codedumper:generate_dot_ctx"
ACTION_LABEL_DOT_CTX = "Generate DOT Graph + Callers/Callees/Refs..."
ACTION_TOOLTIP_DOT_CTX = "Generate DOT graph for current function, callers, callees, and referenced functions"
ACTION_ID_PTN_CTX = "codedumper:generate_ptn_ctx"
ACTION_LABEL_PTN_CTX = "Generate PTN + Callers/Callees/Refs..."
ACTION_TOOLTIP_PTN_CTX = "Generate PTN provenance for current function, callers, callees, and references"
ACTION_ID_PTN_COPY_CTX = "codedumper:copy_ptn_var_ctx"
ACTION_LABEL_PTN_COPY_CTX = "Copy PTN for Identifier Under Cursor"
ACTION_TOOLTIP_PTN_COPY_CTX = "Copy provenance lines for identifier under cursor"

# Assembly dump actions (single & multi)
ACTION_ID_ASM_CTX = "codedumper:dump_asm_ctx"
ACTION_LABEL_ASM_CTX = "Dump Assembly + Callers/Callees/Refs..."
ACTION_TOOLTIP_ASM_CTX = "Disassemble current function, callers, callees, and referenced functions to an ASM file"

MENU_PATH_CTX = "Dump code/"

ACTION_ID_CODE_MULTI = "codedumper:dump_code_multi"
ACTION_LABEL_CODE_MULTI = "Dump Code for Multiple Functions..."
ACTION_TOOLTIP_CODE_MULTI = "Decompile a list of functions and their combined callers/callees/refs to a C file"
ACTION_ID_DOT_MULTI = "codedumper:generate_dot_multi"
ACTION_LABEL_DOT_MULTI = "Generate DOT Graph for Multiple Functions..."
ACTION_TOOLTIP_DOT_MULTI = "Generate DOT graph for a list of functions and their combined callers/callees/refs"
ACTION_ID_PTN_MULTI = "codedumper:generate_ptn_multi"
ACTION_LABEL_PTN_MULTI = "Generate PTN for Multiple Functions..."
ACTION_TOOLTIP_PTN_MULTI = "Generate PTN for a list of functions and their combined callers/callees/refs"
ACTION_ID_ASM_MULTI = "codedumper:dump_asm_multi"
ACTION_LABEL_ASM_MULTI = "Dump Assembly for Multiple Functions..."
ACTION_TOOLTIP_ASM_MULTI = "Disassemble a list of functions and their combined callers/callees/refs to an ASM file"

MENU_PATH_MULTI = f"Edit/{PLUGIN_NAME}/"

g_dump_in_progress = set()
g_multi_dump_active = False
g_dump_lock = threading.Lock()

def find_callers_recursive(target_ea, current_depth, max_depth, visited_eas, edges=None, allowed_types=None):
    if allowed_types is None:
        allowed_types = set(['direct_call', 'indirect_call', 'data_ref', 'immediate_ref', 'tail_call_push_ret', 'virtual_call', 'jump_table'])
    if current_depth > max_depth:
        return set()
    if target_ea in visited_eas:
        return set()
    visited_eas.add(target_ea)
    callers = set()
    ref_ea = ida_xref.get_first_cref_to(target_ea)
    while ref_ea != idaapi.BADADDR:
        caller_func = ida_funcs.get_func(ref_ea)
        if caller_func:
            caller_ea = caller_func.start_ea
            if 'direct_call' in allowed_types:
                if edges is not None:
                    edges[caller_ea][target_ea].add('direct_call')
                if caller_ea not in visited_eas:
                    callers.add(caller_ea)
                    callers.update(find_callers_recursive(caller_ea, current_depth + 1, max_depth, visited_eas, edges=edges, allowed_types=allowed_types))
        ref_ea = ida_xref.get_next_cref_to(target_ea, ref_ea)
    return callers

def detect_indirect_target(ea, func_start_ea, bb_start, bb_end):
    possible_targets = set()
    mnem = idc.print_insn_mnem(ea)
    if mnem not in ['call', 'jmp']:
        return possible_targets
    op_type = idc.get_operand_type(ea, 0)
    if op_type in [idaapi.o_reg, idaapi.o_mem, idaapi.o_phrase, idaapi.o_displ]:
        current_ea = ea - idc.get_item_size(ea)
        traced_regs = set()
        if op_type == idaapi.o_reg:
            traced_regs.add(idc.get_operand_value(ea, 0))
        elif op_type in [idaapi.o_phrase, idaapi.o_displ]:
            traced_regs.add(idc.get_operand_value(ea, 0))
        while current_ea >= bb_start and current_ea < bb_end:
            prev_mnem = idc.print_insn_mnem(current_ea)
            if prev_mnem.startswith('mov'):
                prev_op_type0 = idc.get_operand_type(current_ea, 0)
                prev_op_type1 = idc.get_operand_type(current_ea, 1)
                if prev_op_type0 == idaapi.o_reg and idc.get_operand_value(current_ea, 0) in traced_regs:
                    if prev_op_type1 == idaapi.o_imm:
                        imm_val = idc.get_operand_value(current_ea, 1)
                        if ida_funcs.get_func(imm_val):
                            possible_targets.add(imm_val)
                    elif prev_op_type1 == idaapi.o_mem:
                        mem_addr = idc.get_operand_value(current_ea, 1)
                        if ida_bytes.is_func(ida_bytes.get_flags(mem_addr)):
                            possible_targets.add(mem_addr)
                    traced_regs.remove(idc.get_operand_value(current_ea, 0))
                    if not traced_regs:
                        break
            current_ea -= idc.get_item_size(current_ea)
    return possible_targets

def detect_jump_tables(ea):
    si = ida_nalt.get_switch_info(ea)
    if si:
        cases = ida_xref.calc_switch_cases(ea, si)
        if cases:
            targets = set(cases.targets)
            return [tgt for tgt in targets if ida_funcs.get_func(tgt)]
    op_type = idc.get_operand_type(ea, 0)
    if op_type == idaapi.o_displ and idc.print_insn_mnem(ea) == 'jmp':
        base = idc.get_operand_value(ea, 0)
        entries = []
        ptr_size = 8 if ida_ida.inf_is_64bit() else 4
        for i in range(20):
            ptr = ida_bytes.get_qword(base + i * ptr_size) if ptr_size == 8 else ida_bytes.get_dword(base + i * ptr_size)
            if ptr == 0 or not ida_funcs.get_func(ptr):
                break
            entries.append(ptr)
        if len(entries) > 1:
            return entries
    return []

def find_vtables():
    vtables = {}
    code_seg = ida_segment.get_segm_by_name(".text") or ida_segment.get_segm_by_name("__text")
    if not code_seg:
        return vtables
    data_segs = [ida_segment.getseg(s) for s in idautils.Segments()
                 if (ida_segment.getseg(s).perm & ida_segment.SEGPERM_EXEC) == 0 and
                    (ida_segment.getseg(s).perm & ida_segment.SEGPERM_WRITE) == 0]
    ptr_size = 8 if ida_ida.inf_is_64bit() else 4
    for seg in data_segs:
        ea = seg.start_ea
        end = seg.end_ea
        while ea < end:
            if ea % ptr_size != 0:
                ea += 1
                continue
            count = 0
            vfuncs = []
            current = ea
            while current < end:
                ptr = ida_bytes.get_qword(current) if ptr_size == 8 else ida_bytes.get_dword(current)
                if ptr == 0 or not ida_funcs.get_func(ptr) or ida_segment.getseg(ptr).start_ea != code_seg.start_ea:
                    break
                vfuncs.append(ptr)
                count += 1
                current += ptr_size
            if count >= 3:
                vtables[ea] = vfuncs
                ea = current
            else:
                ea += ptr_size
    return vtables

def resolve_virtual_calls(target_ea, edges, vtables, allowed_types):
    if 'virtual_call' not in allowed_types:
        return
    func = ida_funcs.get_func(target_ea)
    if not func:
        return
    current_item_ea = func.start_ea
    while current_item_ea < func.end_ea:
        mnem = idc.print_insn_mnem(current_item_ea)
        if mnem == 'call':
            op_type = idc.get_operand_type(current_item_ea, 0)
            if op_type == idaapi.o_displ:
                offset = idc.get_operand_value(current_item_ea, 1)
                ptr_size = 8 if ida_ida.inf_is_64bit() else 4
                index = offset // ptr_size if ptr_size else 0
                for vt_ea, vfuncs in vtables.items():
                    if index < len(vfuncs):
                        vfunc = vfuncs[index]
                        edges[target_ea][vfunc].add('virtual_call')
        current_item_ea = idc.next_head(current_item_ea, func.end_ea)

def detect_dynamic_imports(target_ea, edges):
    resolver_ea = ida_name.get_name_ea(idaapi.BADADDR, "GetProcAddress")
    if resolver_ea == idaapi.BADADDR:
        return
    for xref in idautils.XrefsTo(resolver_ea, 0):
        if xref.type == ida_xref.fl_CN:
            call_ea = xref.frm
            next_ea = idc.next_head(call_ea)
            while next_ea < ida_funcs.get_func(call_ea).end_ea:
                mnem = idc.print_insn_mnem(next_ea)
                if mnem == 'call' and idc.get_operand_type(next_ea, 0) == idaapi.o_reg:
                    pass
                next_ea = idc.next_head(next_ea)

def find_callees_recursive(target_ea, current_depth, max_depth, visited_eas, edges=None, vtables=None, allowed_types=None):
    if allowed_types is None:
        allowed_types = set(['direct_call', 'indirect_call', 'data_ref', 'immediate_ref', 'tail_call_push_ret', 'virtual_call', 'jump_table'])
    if current_depth > max_depth:
        return set()
    if target_ea in visited_eas:
        return set()
    visited_eas.add(target_ea)
    callees_and_refs = set()
    func = ida_funcs.get_func(target_ea)
    if not func:
        return callees_and_refs
    if vtables is None:
        vtables = find_vtables()
    if edges:
        resolve_virtual_calls(target_ea, edges, vtables, allowed_types)
        detect_dynamic_imports(target_ea, edges)

    current_item_ea = func.start_ea
    insn = ida_ua.insn_t()
    next_insn = ida_ua.insn_t()
    flowchart = ida_gdl.FlowChart(func)

    while current_item_ea < func.end_ea and current_item_ea != idaapi.BADADDR:
        insn_len = ida_ua.decode_insn(insn, current_item_ea)
        if insn_len == 0:
            next_ea = idc.next_head(current_item_ea, func.end_ea)
            if next_ea <= current_item_ea: break
            current_item_ea = next_ea
            continue

        bb = next((b for b in flowchart if b.start_ea <= current_item_ea < b.end_ea), None)
        if bb and 'indirect_call' in allowed_types:
            indirect_targets = detect_indirect_target(current_item_ea, func.start_ea, bb.start_ea, bb.end_ea)
            for itgt in indirect_targets:
                if edges is not None:
                    edges[target_ea][itgt].add('indirect_call')
                if itgt not in visited_eas:
                    callees_and_refs.add(itgt)
                    recursive_results = find_callees_recursive(itgt, current_depth + 1, max_depth, visited_eas, edges=edges, vtables=vtables, allowed_types=allowed_types)
                    callees_and_refs.update(recursive_results)

        if 'jump_table' in allowed_types:
            jt_targets = detect_jump_tables(current_item_ea)
            for jtt in jt_targets:
                if edges is not None:
                    edges[target_ea][jtt].add('jump_table')
                if jtt not in visited_eas:
                    callees_and_refs.add(jtt)
                    recursive_results = find_callees_recursive(jtt, current_depth + 1, max_depth, visited_eas, edges=edges, vtables=vtables, allowed_types=allowed_types)
                    callees_and_refs.update(recursive_results)

        cref_ea = ida_xref.get_first_cref_from(current_item_ea)
        while cref_ea != idaapi.BADADDR:
            ref_func = ida_funcs.get_func(cref_ea)
            if ref_func and ref_func.start_ea == cref_ea:
                if 'direct_call' in allowed_types:
                    if edges is not None:
                        edges[target_ea][cref_ea].add('direct_call')
                    if cref_ea not in visited_eas:
                        callees_and_refs.add(cref_ea)
                        recursive_results = find_callees_recursive(cref_ea, current_depth + 1, max_depth, visited_eas, edges=edges, vtables=vtables, allowed_types=allowed_types)
                        callees_and_refs.update(recursive_results)
            cref_ea = ida_xref.get_next_cref_from(current_item_ea, cref_ea)

        dref_ea = ida_xref.get_first_dref_from(current_item_ea)
        while dref_ea != idaapi.BADADDR:
            ref_func = ida_funcs.get_func(dref_ea)
            if ref_func and ref_func.start_ea == dref_ea:
                if 'data_ref' in allowed_types:
                    if edges is not None:
                        edges[target_ea][dref_ea].add('data_ref')
                    if dref_ea not in visited_eas:
                        callees_and_refs.add(dref_ea)
                        recursive_results = find_callees_recursive(dref_ea, current_depth + 1, max_depth, visited_eas, edges=edges, vtables=vtables, allowed_types=allowed_types)
                        callees_and_refs.update(recursive_results)
            dref_ea = ida_xref.get_next_dref_from(current_item_ea, dref_ea)

        is_push_imm_func = False
        pushed_func_addr = idaapi.BADADDR

        for i in range(idaapi.UA_MAXOP):
            op = insn.ops[i]
            if op.type == idaapi.o_void: break
            if op.type == idaapi.o_imm:
                imm_val = op.value
                ref_func = ida_funcs.get_func(imm_val)
                if ref_func and ref_func.start_ea == imm_val:
                    mnem = insn.get_canon_mnem()
                    added = False
                    if 'immediate_ref' in allowed_types:
                        if edges is not None:
                            edges[target_ea][imm_val].add('immediate_ref')
                        added = True
                    if mnem == "push":
                        is_push_imm_func = True
                        pushed_func_addr = imm_val
                    if is_push_imm_func:
                        next_insn_ea = current_item_ea + insn_len
                        if next_insn_ea < func.end_ea:
                            next_insn_len = ida_ua.decode_insn(next_insn, next_insn_ea)
                            if next_insn_len > 0:
                                if ida_idp.is_ret_insn(next_insn, ida_idp.IRI_RET_LITERALLY):
                                    if 'tail_call_push_ret' in allowed_types:
                                        if edges is not None:
                                            edges[target_ea][pushed_func_addr].add('tail_call_push_ret')
                                        added = True
                    if added:
                        if imm_val not in visited_eas:
                            callees_and_refs.add(imm_val)
                            recursive_results = find_callees_recursive(imm_val, current_depth + 1, max_depth, visited_eas, edges=edges, vtables=vtables, allowed_types=allowed_types)
                            callees_and_refs.update(recursive_results)

        next_ea = current_item_ea + insn_len
        if next_ea <= current_item_ea:
            next_ea = idc.next_head(current_item_ea, func.end_ea)
            if next_ea <= current_item_ea: break
        current_item_ea = next_ea

    return callees_and_refs

def decompile_functions_main(eas_to_decompile):
    results = {}
    total = len(eas_to_decompile)
    count = 0
    if not ida_hexrays.init_hexrays_plugin():
        for func_ea in eas_to_decompile:
            func_name = ida_name.get_name(func_ea) or f"sub_{func_ea:X}"
            results[func_ea] = f"// Decompilation FAILED for {func_name} (0x{func_ea:X}) - Hex-Rays init failed"
        return results
    sorted_eas_list = sorted(list(eas_to_decompile))
    for func_ea in sorted_eas_list:
        count += 1
        func_name = ida_name.get_name(func_ea) or f"sub_{func_ea:X}"
        ida_kernwin.replace_wait_box(f"Decompiling {count}/{total}: {func_name}")
        try:
            cfunc = ida_hexrays.decompile(func_ea)
            if cfunc:
                results[func_ea] = str(cfunc)
            else:
                results[func_ea] = f"// Decompilation FAILED for {func_name} (0x{func_ea:X}) - Decompiler returned None"
        except ida_hexrays.DecompilationFailure as e:
            results[func_ea] = f"// Decompilation ERROR for {func_name} (0x{func_ea:X}): {e}"
        except Exception as e:
            results[func_ea] = f"// Decompilation UNEXPECTED ERROR for {func_name} (0x{func_ea:X}): {e}"
            traceback.print_exc()
    return results

def disassemble_functions_main(eas_to_disasm) -> Dict[int, List[Tuple[str, int, str]]]:
    """
    Disassemble the functions identified by 'eas_to_disasm' and return a dict:
      ea -> list of tuples (kind, ea, text) where kind ∈ {'label','inst'}.
    For 'label' entries, 'ea' is the address of the label (0 for function header label).
    For 'inst' entries, 'ea' is the instruction EA, and 'text' is the disassembly for that item.
    Runs in the IDA main thread via execute_sync (caller responsibility).
    """
    results: Dict[int, List[Tuple[str, int, str]]] = {}
    total = len(eas_to_disasm)
    count = 0
    sorted_eas_list = sorted(list(eas_to_disasm))
    for func_ea in sorted_eas_list:
        count += 1
        func_name = ida_name.get_name(func_ea) or f"sub_{func_ea:X}"
        ida_kernwin.replace_wait_box(f"Disassembling {count}/{total}: {func_name}")
        func = ida_funcs.get_func(func_ea)
        if not func:
            results[func_ea] = [("label", 0, f"; Disassembly FAILED for {func_name} (0x{func_ea:X}) - no function at address")]
            continue
        lines: List[Tuple[str, int, str]] = []
        # Emit a function header label for readability in the ASM body.
        lines.append(("label", 0, f"{func_name}:"))
        try:
            for ea in idautils.FuncItems(func_ea):
                # Insert a local label if this address has a visible name (e.g., 'loc_...' labels).
                try:
                    lab = ida_name.get_name(ea) or ""
                except Exception:
                    lab = ""
                if lab and ea != func_ea:
                    lines.append(("label", ea, f"{lab}:"))
                # Preferred disassembly line generation (with tag removal).
                s = None
                try:
                    s = ida_lines.generate_disasm_line(ea, 0)
                    if s:
                        try:
                            s = ida_lines.tag_remove(s)
                        except Exception:
                            pass
                except Exception:
                    s = None
                if not s:
                    try:
                        s = idc.GetDisasm(ea)
                    except Exception:
                        s = None
                if not s:
                    try:
                        item_sz = idc.get_item_size(ea) or 1
                    except Exception:
                        item_sz = 1
                    bytes_repr = " ".join(f"{ida_bytes.get_wide_byte(ea+i):02X}" for i in range(item_sz))
                    s = f"db {bytes_repr}"
                lines.append(("inst", ea, s))
        except Exception:
            traceback.print_exc()
            lines.append(("label", 0, "; ERROR: Exception during disassembly traversal"))
        results[func_ea] = lines
    return results

def get_edge_style(reasons_set):
    if 'virtual_call' in reasons_set:
        return "bold"
    if 'direct_call' in reasons_set:
        return "solid"
    if 'tail_call_push_ret' in reasons_set:
        return "dashed,bold"
    if 'indirect_call' in reasons_set or 'jump_table' in reasons_set:
        return "dashed"
    if 'data_ref' in reasons_set or 'immediate_ref' in reasons_set:
        return "dotted"
    return "dotted"

def _augment_edges_with_ctree_calls(fs_summaries: Dict[int, FunctionSummary], edges):
    for fea, fs in fs_summaries.items():
        for au in fs.arguses:
            if au.callee_ea:
                edges[fea][au.callee_ea].add('direct_call')

def write_code_file(output_file_path, decompiled_results, start_func_eas, caller_depth, callee_depth, edges, fs_summaries: Dict[int, FunctionSummary], max_chars=0):
    num_funcs_written = 0
    try:
        name_map_container = [{}]
        eas_to_get_names = list(decompiled_results.keys())

        def get_names_main(eas, container):
            names = {}
            for ea in eas:
                names[ea] = ida_funcs.get_func_name(ea) or f"sub_{ea:X}"
            container[0] = names
            return 1

        sync_status = ida_kernwin.execute_sync(lambda: get_names_main(eas_to_get_names, name_map_container), ida_kernwin.MFF_READ)
        name_map = name_map_container[0] if sync_status == 1 else {ea: f"sub_{ea:X}" for ea in eas_to_get_names}

        all_nodes = set(decompiled_results.keys())

        # Augment edges with ctree-derived direct calls (catches PLT/IAT like strcpy)
        _augment_edges_with_ctree_calls(fs_summaries, edges)

        out_degrees = [(len(edges[ea]), ea) for ea in all_nodes]
        sorted_out_degrees = sorted(out_degrees, key=lambda x: (x[0], x[1]))
        sorted_eas = [t[1] for t in sorted_out_degrees]

        ptn = PTNEmitter(fs_summaries)
        per_func_ann = ptn.per_function_annotations(max(1, callee_depth))

        included_eas = set(all_nodes)
        removed_eas = set()
        if max_chars > 0:
            func_blocks_for_sizing = []
            for func_ea in sorted_eas:
                func_name = name_map.get(func_ea, f"sub_{func_ea:X}")
                incoming = [fr for fr in edges if func_ea in edges[fr]]
                outgoing = edges[func_ea]
                ann = per_func_ann.get(func_ea, "")
                code_or_error = decompiled_results[func_ea]
                block_str = ''.join([
                    f"// Incoming xrefs for {func_name} (0x{func_ea:X}): {len(incoming)} refs\n",
                    f"// Outgoing xrefs for {func_name} (0x{func_ea:X}): {len(outgoing)} refs\n",
                    ann,
                    f"// --- Function: {func_name}...\n", code_or_error, "\n// --- End Function...\n\n"
                ])
                func_blocks_for_sizing.append({'ea': func_ea, 'block_size': len(block_str), 'code_len': len(code_or_error)})

            current_size = sum(d['block_size'] for d in func_blocks_for_sizing)
            if current_size > max_chars:
                removable = [d for d in func_blocks_for_sizing if d['ea'] not in start_func_eas]
                removable.sort(key=lambda d: d['code_len'])
                while current_size > max_chars and removable:
                    to_remove = removable.pop(0)
                    included_eas.remove(to_remove['ea'])
                    removed_eas.add(to_remove['ea'])
                    current_size -= to_remove['block_size']

        sorted_included_eas = [ea for ea in sorted_eas if ea in included_eas]

        header_lines = []
        header_lines.append(f"// Decompiled code dump generated by {PLUGIN_NAME}\n")

        header_lines.append("\n")

        header_lines.append(
            "// --------\n"
            "#PTN v0\n"
            "// @PTN LEGEND\n"
            "// Nodes: L(F,i)=local i in function F; P(F,i)=param i of F; G(addr)=global at addr; F(Fx)=function Fx.\n"
            "// Slices: @[off:len] in bytes; '?' unknown; '&' = address-of; '*' = deref; optional cast as :(type).\n"
            "// A: alias inside function   => A: dst := src[@slice][mode][:cast] {meta}\n"
            "// I: inbound (caller→this)   => I: origin -> P(F,i) {caller=F?,cs=0x...,conf=...}\n"
            "// E: outbound (this→callee)  => E: origin -> A(F?,arg) [-> A(F?,arg)...] {cs=0x...,conf=...}\n"
            "// G: global touch/summary    => G: F(F?) -> G(0xADDR)   or   G: F(writer) -> G(0xADDR) -> F(reader)\n"
            "// Dictionary entry (per function block): // @PTN D:F?=0xEA,Name\n"
            "// --------\n"
        )

        header_lines.append("\n")

        if len(start_func_eas) == 1:
            start_ea = list(start_func_eas)[0]
            header_lines.append(f"// Start Function: 0x{start_ea:X} ({name_map.get(start_ea, '')})\n")
        else:
            header_lines.append("// Start Functions:\n")
            for start_ea in sorted(list(start_func_eas)):
                header_lines.append(f"//   - 0x{start_ea:X} ({name_map.get(start_ea, '')})\n")

        header_lines.append(f"// Caller Depth: {caller_depth}\n")
        header_lines.append(f"// Callee/Ref Depth: {callee_depth}\n")
        if max_chars > 0:
            header_lines.append(f"// Max Characters: {max_chars}\n")
        header_lines.append(f"// Total Functions Found: {len(all_nodes)}\n")
        header_lines.append(f"// Included Functions ({len(included_eas)}):\n")
        for func_ea in sorted_included_eas:
            func_name = name_map.get(func_ea, f"sub_{func_ea:X}")
            header_lines.append(f"//   - {func_name} (0x{func_ea:X})\n")
        if removed_eas:
            header_lines.append(f"// Removed Functions ({len(removed_eas)}):\n")
            for func_ea in sorted(removed_eas):
                func_name = name_map.get(func_ea, f"sub_{func_ea:X}")
                header_lines.append(f"//   - {func_name} (0x{func_ea:X})\n")
        else:
            header_lines.append(f"// Removed Functions: None\n")
        header_lines.append(f"// {'-'*60}\n\n")
        header = ''.join(header_lines)

        final_content_blocks = []
        for func_ea in sorted_included_eas:
            func_name = name_map.get(func_ea, f"sub_{func_ea:X}")
            all_incoming = [fr for fr in edges if func_ea in edges[fr]]
            filtered_incoming = [fr for fr in all_incoming if fr in included_eas]
            incoming_strs = []
            for fr in sorted(filtered_incoming):
                reasons = sorted(edges[fr][func_ea])
                reason_str = '/'.join(reasons)
                src_name = name_map.get(fr, f"sub_{fr:X}")
                incoming_strs.append(f"{src_name} (0x{fr:X}) [{reason_str}]")
            incoming_line = f"// Incoming xrefs for {func_name} (0x{func_ea:X}): {', '.join(incoming_strs) or 'None'}\n"

            all_outgoing = edges[func_ea]
            filtered_outgoing = {to: reasons for to, reasons in all_outgoing.items() if to in included_eas}
            outgoing_strs = []
            for to in sorted(filtered_outgoing):
                reasons = sorted(filtered_outgoing[to])
                reason_str = '/'.join(reasons)
                dst_name = name_map.get(to, f"sub_{to:X}")
                outgoing_strs.append(f"{dst_name} (0x{to:X}) [{reason_str}]")
            outgoing_line = f"// Outgoing xrefs for {func_name} (0x{func_ea:X}): {', '.join(outgoing_strs) or 'None'}\n"

            code_or_error = decompiled_results[func_ea]
            ann = per_func_ann.get(func_ea, "")

            block = [
                incoming_line,
                outgoing_line,
                ann,
                f"// --- Function: {func_name} (0x{func_ea:X}) ---\n",
                code_or_error + "\n",
                f"// --- End Function: {func_name} (0x{func_ea:X}) ---\n\n"
            ]
            final_content_blocks.append(''.join(block))

        content = header + ''.join(final_content_blocks)
        with open(output_file_path, "w", encoding="utf-8") as f:
            f.write(content)
        num_funcs_written = len(included_eas)
        return num_funcs_written

    except Exception as e:
        traceback.print_exc()
        error_msg = f"{PLUGIN_NAME}: Error writing dump file:\n{e}"
        ida_kernwin.execute_ui_requests([lambda msg=error_msg: ida_kernwin.warning(msg)])
        return 0

def write_asm_file(output_file_path, asm_results: Dict[int, List[Tuple[str, int, str]]],
                   start_func_eas, caller_depth, callee_depth, edges,
                   fs_summaries: Dict[int, FunctionSummary], max_chars=0):
    """
    Write an ASM dump mirroring the structure & ordering of write_code_file.
    Inject per-instruction @PTN hints inline (as trailing // comments or separate comment lines).
    """
    num_funcs_written = 0
    try:
        name_map_container = [{}]
        eas_to_get_names = list(asm_results.keys())

        def get_names_main(eas, container):
            names = {}
            for ea in eas:
                names[ea] = ida_funcs.get_func_name(ea) or f"sub_{ea:X}"
            container[0] = names
            return 1

        sync_status = ida_kernwin.execute_sync(lambda: get_names_main(eas_to_get_names, name_map_container), ida_kernwin.MFF_READ)
        name_map = name_map_container[0] if sync_status == 1 else {ea: f"sub_{ea:X}" for ea in eas_to_get_names}

        all_nodes = set(asm_results.keys())

        _augment_edges_with_ctree_calls(fs_summaries, edges)

        out_degrees = [(len(edges[ea]), ea) for ea in all_nodes]
        sorted_out_degrees = sorted(out_degrees, key=lambda x: (x[0], x[1]))
        sorted_eas = [t[1] for t in sorted_out_degrees]

        ptn = PTNEmitter(fs_summaries)
        per_func_ann = ptn.per_function_annotations(max(1, callee_depth))
        # Per-instruction hints: fea -> {ea -> [hint_str_without_comment_prefix]}
        per_inst_hints = ptn.per_instruction_hints(max(1, callee_depth))

        def format_asm_with_hints(func_ea: int, items: List[Tuple[str, int, str]]) -> str:
            lines_out: List[str] = []
            hint_map = per_inst_hints.get(func_ea, {})
            for kind, ea, text in items:
                if kind == "label":
                    lines_out.append(text)
                    continue
                # 'inst' line
                line = f"0x{ea:X}: {text}"
                hints = hint_map.get(ea, [])
                if hints:
                    # Emit instruction, then per-hint short comment lines for readability
                    lines_out.append(line)
                    for h in hints:
                        lines_out.append(f"    // {h}")
                else:
                    lines_out.append(line)
            return "\n".join(lines_out)

        # Prepare blocks (including sizing with max_chars)
        included_eas = set(all_nodes)
        removed_eas = set()
        func_text_cache: Dict[int, str] = {}
        if max_chars > 0:
            func_blocks_for_sizing = []
            for func_ea in sorted_eas:
                func_name = name_map.get(func_ea, f"sub_{func_ea:X}")
                incoming = [fr for fr in edges if func_ea in edges[fr]]
                outgoing = edges[func_ea]
                ann = per_func_ann.get(func_ea, "")
                code_text = func_text_cache.setdefault(func_ea, format_asm_with_hints(func_ea, asm_results[func_ea]))
                block_str = ''.join([
                    f"// Incoming xrefs for {func_name} (0x{func_ea:X}): {len(incoming)} refs\n",
                    f"// Outgoing xrefs for {func_name} (0x{func_ea:X}): {len(outgoing)} refs\n",
                    ann,
                    f"// --- Function: {func_name}...\n", code_text, "\n// --- End Function...\n\n"
                ])
                func_blocks_for_sizing.append({'ea': func_ea, 'block_size': len(block_str), 'code_len': len(code_text)})

            current_size = sum(d['block_size'] for d in func_blocks_for_sizing)
            if current_size > max_chars:
                removable = [d for d in func_blocks_for_sizing if d['ea'] not in start_func_eas]
                removable.sort(key=lambda d: d['code_len'])
                while current_size > max_chars and removable:
                    to_remove = removable.pop(0)
                    included_eas.remove(to_remove['ea'])
                    removed_eas.add(to_remove['ea'])
                    current_size -= to_remove['block_size']

        sorted_included_eas = [ea for ea in sorted_eas if ea in included_eas]

        header_lines = []
        header_lines.append(f"// Assembly dump generated by {PLUGIN_NAME}\n")

        header_lines.append("\n")

        header_lines.append(
            "// --------\n"
            "#PTN v0\n"
            "// @PTN LEGEND\n"
            "// Nodes: L(F,i)=local i in function F; P(F,i)=param i of F; G(addr)=global at addr; F(Fx)=function Fx.\n"
            "// Slices: @[off:len] in bytes; '?' unknown; '&' = address-of; '*' = deref; optional cast as :(type).\n"
            "// A: alias inside function   => A: dst := src[@slice][mode][:cast] {meta}\n"
            "// I: inbound (caller→this)   => I: origin -> P(F,i) {caller=F?,cs=0x...,conf=...}\n"
            "// E: outbound (this→callee)  => E: origin -> A(F?,arg) [-> A(F?,arg)...] {cs=0x...,conf=...}\n"
            "// G: global touch/summary    => G: F(F?) -> G(0xADDR)   or   G: F(writer) -> G(0xADDR) -> F(reader)\n"
            "// Dictionary entry (per function block): // @PTN D:F?=0xEA,Name\n"
            "// --------\n"
        )

        header_lines.append("\n")

        if len(start_func_eas) == 1:
            start_ea = list(start_func_eas)[0]
            header_lines.append(f"// Start Function: 0x{start_ea:X} ({name_map.get(start_ea, '')})\n")
        else:
            header_lines.append("// Start Functions:\n")
            for start_ea in sorted(list(start_func_eas)):
                header_lines.append(f"//   - 0x{start_ea:X} ({name_map.get(start_ea, '')})\n")

        header_lines.append(f"// Caller Depth: {caller_depth}\n")
        header_lines.append(f"// Callee/Ref Depth: {callee_depth}\n")
        if max_chars > 0:
            header_lines.append(f"// Max Characters: {max_chars}\n")
        header_lines.append(f"// Total Functions Found: {len(all_nodes)}\n")
        header_lines.append(f"// Included Functions ({len(included_eas)}):\n")
        for func_ea in sorted_included_eas:
            func_name = name_map.get(func_ea, f"sub_{func_ea:X}")
            header_lines.append(f"//   - {func_name} (0x{func_ea:X})\n")
        if removed_eas:
            header_lines.append(f"// Removed Functions ({len(removed_eas)}):\n")
            for func_ea in sorted(removed_eas):
                func_name = name_map.get(func_ea, f"sub_{func_ea:X}")
                header_lines.append(f"//   - {func_name} (0x{func_ea:X})\n")
        else:
            header_lines.append(f"// Removed Functions: None\n")
        header_lines.append(f"// {'-'*60}\n\n")
        header = ''.join(header_lines)

        final_content_blocks = []
        for func_ea in sorted_included_eas:
            func_name = name_map.get(func_ea, f"sub_{func_ea:X}")
            all_incoming = [fr for fr in edges if func_ea in edges[fr]]
            filtered_incoming = [fr for fr in all_incoming if fr in included_eas]
            incoming_strs = []
            for fr in sorted(filtered_incoming):
                reasons = sorted(edges[fr][func_ea])
                reason_str = '/'.join(reasons)
                src_name = name_map.get(fr, f"sub_{fr:X}")
                incoming_strs.append(f"{src_name} (0x{fr:X}) [{reason_str}]")
            incoming_line = f"// Incoming xrefs for {func_name} (0x{func_ea:X}): {', '.join(incoming_strs) or 'None'}\n"

            all_outgoing = edges[func_ea]
            filtered_outgoing = {to: reasons for to, reasons in all_outgoing.items() if to in included_eas}
            outgoing_strs = []
            for to in sorted(filtered_outgoing):
                reasons = sorted(filtered_outgoing[to])
                reason_str = '/'.join(reasons)
                dst_name = name_map.get(to, f"sub_{to:X}")
                outgoing_strs.append(f"{dst_name} (0x{to:X}) [{reason_str}]")
            outgoing_line = f"// Outgoing xrefs for {func_name} (0x{func_ea:X}): {', '.join(outgoing_strs) or 'None'}\n"

            code_text = func_text_cache.get(func_ea) or format_asm_with_hints(func_ea, asm_results[func_ea])
            ann = per_func_ann.get(func_ea, "")

            block = [
                incoming_line,
                outgoing_line,
                ann,
                f"// --- Function: {func_name} (0x{func_ea:X}) ---\n",
                code_text + "\n",
                f"// --- End Function: {func_name} (0x{func_ea:X}) ---\n\n"
            ]
            final_content_blocks.append(''.join(block))

        content = header + ''.join(final_content_blocks)
        with open(output_file_path, "w", encoding="utf-8") as f:
            f.write(content)
        num_funcs_written = len(included_eas)
        return num_funcs_written

    except Exception as e:
        traceback.print_exc()
        error_msg = f"{PLUGIN_NAME}: Error writing ASM file:\n{e}"
        ida_kernwin.execute_ui_requests([lambda msg=error_msg: ida_kernwin.warning(msg)])
        return 0

def write_dot_file(output_file_path, edges, all_nodes, start_func_eas, caller_depth, callee_depth):
    num_nodes_written = 0
    try:
        name_map = {}
        name_map_container = [{}]
        eas_to_get_names = list(all_nodes)

        def get_names_main(eas, container):
            names = {}
            for ea in eas:
                names[ea] = ida_funcs.get_func_name(ea) or f"sub_{ea:X}"
            container[0] = names
            return 1

        sync_status = ida_kernwin.execute_sync(lambda: get_names_main(eas_to_get_names, name_map_container), ida_kernwin.MFF_READ)
        if sync_status == 1:
            name_map = name_map_container[0]
        else:
            for ea in eas_to_get_names:
                name_map[ea] = f"sub_{ea:X}"

        with open(output_file_path, "w", encoding="utf-8") as f:
            f.write(f"# DOT graph generated by {PLUGIN_NAME}\n")
            if len(start_func_eas) == 1:
                start_ea = list(start_func_eas)[0]
                f.write(f"# Start Function: 0x{start_ea:X} ({name_map.get(start_ea, '')})\n")
            else:
                f.write("# Start Functions:\n")
                for start_ea in sorted(list(start_func_eas)):
                    f.write(f"#   - 0x{start_ea:X} ({name_map.get(start_ea, '')})\n")
            f.write(f"# Caller Depth: {caller_depth}\n")
            f.write(f"# Callee/Ref Depth: {callee_depth}\n")
            f.write(f"# Total Nodes: {len(all_nodes)}\n")
            f.write("#\n# --- Legend ---\n")
            f.write("# Solid Line: Direct Call\n")
            f.write("# Bold Line: Virtual Call\n")
            f.write("# Dashed Line: Indirect Call / Jump Table\n")
            f.write("# Bold Dashed Line: Tail Call (push/ret)\n")
            f.write("# Dotted Line: Data / Immediate Reference\n")
            f.write(f"# {'-'*60}\n\n")

            f.write("digraph CallGraph {\n")
            f.write("    graph [splines=ortho];\n")
            f.write("    node [shape=box, style=filled, fillcolor=lightblue];\n")
            f.write("    edge [color=gray50];\n")

            sorted_nodes = sorted(list(all_nodes))
            for ea in sorted_nodes:
                name = name_map[ea]
                if len(name) > 40:
                    name = name[:37] + "..."
                label = f"{name}\\n(0x{ea:X})"
                fillcolor = "fillcolor=red" if ea in start_func_eas else ""
                f.write(f"    \"0x{ea:X}\" [label=\"{label}\" {fillcolor}];\n")

            for from_ea in sorted_nodes:
                if from_ea in edges:
                    for to_ea in sorted(edges[from_ea]):
                        if to_ea in all_nodes:
                            reasons_set = edges[from_ea][to_ea]
                            style = get_edge_style(reasons_set)
                            tooltip_str = '/'.join(sorted(reasons_set))
                            f.write(f"    \"0x{from_ea:X}\" -> \"0x{to_ea:X}\" [style={style}, tooltip=\"{tooltip_str}\"];\n")
            f.write("}\n")

        num_nodes_written = len(all_nodes)
        return num_nodes_written

    except Exception as e:
        traceback.print_exc()
        error_msg = f"{PLUGIN_NAME}: Error writing DOT file:\n{e}"
        ida_kernwin.execute_ui_requests([lambda msg=error_msg: ida_kernwin.warning(msg)])
        return 0

def write_ptn_file(output_file_path, fs_summaries: Dict[int, FunctionSummary], start_func_eas: Set[int], callee_depth: int):
    try:
        emitter = PTNEmitter(fs_summaries)
        if output_file_path.lower().endswith(".json"):
            content = emitter.emit_ptn_json(start_eas=start_func_eas, callee_depth=max(1, callee_depth), restrict_eas=None)
        else:
            content = emitter.emit_ptn(start_eas=start_func_eas, callee_depth=max(1, callee_depth), restrict_eas=None)
        with open(output_file_path, "w", encoding="utf-8") as f:
            f.write(content)
        return len(content)
    except Exception as e:
        traceback.print_exc()
        error_msg = f"{PLUGIN_NAME}: Error writing PTN file:\n{e}"
        ida_kernwin.execute_ui_requests([lambda msg=error_msg: ida_kernwin.warning(msg)])
        return 0

def dump_task(start_func_eas, caller_depth, callee_depth, output_file_path, mode='code', xref_types=None, max_chars=0):
    if xref_types is None:
        xref_types = set(['direct_call', 'indirect_call', 'data_ref', 'immediate_ref', 'tail_call_push_ret', 'virtual_call', 'jump_table'])

    global g_multi_dump_active, g_dump_in_progress

    start_func_names = []
    start_names_container = [[]]

    def get_start_names_main(eas, container):
        names = []
        for ea in eas:
            name = ida_funcs.get_func_name(ea) or f"sub_{ea:X}"
            names.append(f"{name}(0x{ea:X})")
        container[0] = names
        return 1

    sync_status = ida_kernwin.execute_sync(lambda: get_start_names_main(start_func_eas, start_names_container), ida_kernwin.MFF_READ)
    if sync_status == 1:
        start_func_names = start_names_container[0]
    print(f"{PLUGIN_NAME}: Background task for {len(start_func_eas)} function(s) mode={mode}: {', '.join(start_func_names) if start_func_names else ''}")
    print(f"  Callers={caller_depth}, Callees={callee_depth}, Output={output_file_path}")
    print(f"  Xref Types: {', '.join(sorted(xref_types))}")
    print(f"  Max Chars: {max_chars}")

    try:
        all_nodes = set(start_func_eas)
        edges = defaultdict(lambda: defaultdict(set))
        ida_kernwin.execute_ui_requests([lambda: ida_kernwin.show_wait_box(f"Finding callers/callees/refs for {len(start_func_eas)} functions...")])

        visited_callers = set()
        if caller_depth > 0:
            caller_result_container = [set()]
            visited_caller_container = [set()]

            def run_find_multi_callers_main(container, visited_set_container, edges, allowed_types):
                combined_callers = set()
                for start_ea in start_func_eas:
                    found = find_callers_recursive(start_ea, 1, caller_depth, visited_set_container[0], edges=edges, allowed_types=allowed_types)
                    combined_callers.update(found)
                container[0] = combined_callers
                return 1

            sync_status = ida_kernwin.execute_sync(lambda: run_find_multi_callers_main(caller_result_container, visited_caller_container, edges, xref_types), ida_kernwin.MFF_READ)
            if sync_status == 1:
                total_caller_eas = caller_result_container[0]
                visited_callers = visited_caller_container[0]
                all_nodes |= visited_callers
                all_nodes.update(total_caller_eas)
            else:
                ida_kernwin.execute_ui_requests([ida_kernwin.hide_wait_box])
                ida_kernwin.warning(f"{PLUGIN_NAME}: Failed to find callers.")
                return

        visited_callees = set()
        if callee_depth > 0:
            callee_result_container = [set()]
            visited_callee_container = [set()]

            def run_find_multi_callees_main(container, visited_set_container, edges, allowed_types):
                combined_callees = set()
                vtables = find_vtables()
                for start_ea in start_func_eas:
                    found = find_callees_recursive(start_ea, 1, callee_depth, visited_set_container[0], edges=edges, vtables=vtables, allowed_types=allowed_types)
                    combined_callees.update(found)
                container[0] = combined_callees
                return 1

            sync_status = ida_kernwin.execute_sync(lambda: run_find_multi_callees_main(callee_result_container, visited_callee_container, edges, xref_types), ida_kernwin.MFF_READ)
            if sync_status == 1:
                total_callee_ref_eas = callee_result_container[0]
                visited_callees = visited_callee_container[0]
                all_nodes |= visited_callees
                all_nodes.update(total_callee_ref_eas)
            else:
                ida_kernwin.execute_ui_requests([ida_kernwin.hide_wait_box])
                ida_kernwin.warning(f"{PLUGIN_NAME}: Failed to find callees/refs.")
                return

        total_nodes = len(all_nodes)
        if total_nodes == 0:
            ida_kernwin.execute_ui_requests([ida_kernwin.hide_wait_box])
            ida_kernwin.warning(f"{PLUGIN_NAME}: No functions/nodes found.")
            return

        fs_summaries_container = [{}]
        def run_analyze_main(container, eas):
            try:
                container[0] = analyze_functions_ctree(eas)
                return 1
            except Exception:
                traceback.print_exc()
                container[0] = {}
                return 0

        analyze_status = ida_kernwin.execute_sync(lambda: run_analyze_main(fs_summaries_container, all_nodes), ida_kernwin.MFF_READ)
        fs_summaries: Dict[int, FunctionSummary] = fs_summaries_container[0] if analyze_status == 1 else {}

        if mode == 'code':
            decompiled_results = {}
            decomp_result_container = [{}]
            def run_decompile_main(container, eas):
                try:
                    container[0] = decompile_functions_main(eas)
                    return 1
                except Exception:
                    traceback.print_exc()
                    container[0] = {}
                    return 0
            sync_status = ida_kernwin.execute_sync(lambda: run_decompile_main(decomp_result_container, all_nodes), ida_kernwin.MFF_WRITE)
            if sync_status == 1:
                decompiled_results = decomp_result_container[0]
            ida_kernwin.execute_ui_requests([ida_kernwin.hide_wait_box])
            num_written = write_code_file(output_file_path, decompiled_results, start_func_eas, caller_depth, callee_depth, edges, fs_summaries, max_chars=max_chars)

        elif mode == 'graph':
            ida_kernwin.execute_ui_requests([ida_kernwin.hide_wait_box])
            num_written = write_dot_file(output_file_path, edges, all_nodes, start_func_eas, caller_depth, callee_depth)

        elif mode == 'ptn':
            ida_kernwin.execute_ui_requests([ida_kernwin.hide_wait_box])
            num_written = write_ptn_file(output_file_path, fs_summaries, set(all_nodes), callee_depth=max(1, callee_depth))

        elif mode == 'asm':
            asm_result_container = [{}]
            def run_disasm_main(container, eas):
                try:
                    container[0] = disassemble_functions_main(eas)
                    return 1
                except Exception:
                    traceback.print_exc()
                    container[0] = {}
                    return 0
            sync_status = ida_kernwin.execute_sync(lambda: run_disasm_main(asm_result_container, all_nodes), ida_kernwin.MFF_READ)
            asm_results = asm_result_container[0] if sync_status == 1 else {}
            ida_kernwin.execute_ui_requests([ida_kernwin.hide_wait_box])
            num_written = write_asm_file(output_file_path, asm_results, start_func_eas, caller_depth, callee_depth, edges, fs_summaries, max_chars=max_chars)

        else:
            ida_kernwin.execute_ui_requests([ida_kernwin.hide_wait_box])
            ida_kernwin.warning(f"{PLUGIN_NAME}: Unknown mode '{mode}'.")
            return

        if num_written > 0:
            type_str = "functions" if mode in ('code', 'asm') else ("nodes" if mode == 'graph' else "bytes")
            final_message = f"{PLUGIN_NAME}: Successfully wrote {num_written} {type_str} to:\n{output_file_path}"
            ida_kernwin.execute_sync(lambda: (ida_kernwin.info(final_message), 1)[1], ida_kernwin.MFF_WRITE)

    except Exception as e:
        traceback.print_exc()
        ida_kernwin.execute_ui_requests([lambda: ida_kernwin.warning(f"{PLUGIN_NAME}: An unexpected error occurred.")])
        ida_kernwin.execute_ui_requests([ida_kernwin.hide_wait_box])
    finally:
        with g_dump_lock:
            if len(start_func_eas) == 1:
                g_dump_in_progress.discard(list(start_func_eas)[0])
            else:
                global g_multi_dump_active
                g_multi_dump_active = False

class DumpCtxActionHandler(ida_kernwin.action_handler_t):
    def activate(self, ctx):
        global g_dump_in_progress, g_multi_dump_active
        widget = ctx.widget
        widget_type = ida_kernwin.get_widget_type(widget)
        if widget_type != ida_kernwin.BWN_PSEUDOCODE:
            return 1
        vu = ida_hexrays.get_widget_vdui(widget)
        if not vu or not vu.cfunc:
            ida_kernwin.warning(f"{PLUGIN_NAME}: Decompilation not available for this function.")
            return 1
        start_func_ea = vu.cfunc.entry_ea
        start_func_name = ida_funcs.get_func_name(start_func_ea) or f"sub_{start_func_ea:X}"
        with g_dump_lock:
            if start_func_ea in g_dump_in_progress:
                ida_kernwin.warning(f"{PLUGIN_NAME}: Dump already running for {start_func_name}.")
                return 1
            if g_multi_dump_active:
                ida_kernwin.warning(f"{PLUGIN_NAME}: A multi-function dump is currently running.")
                return 1
            g_dump_in_progress.add(start_func_ea)
        input_results = {"caller_depth": -1, "callee_depth": -1, "output_file": None, "xref_types": None, "max_chars": 0}
        input_container = [input_results]
        def get_inputs_main(container):
            c_depth = ida_kernwin.ask_long(0, "Enter Caller Depth (e.g., 0, 1, 2)")
            if c_depth is None: return 0
            container[0]["caller_depth"] = int(c_depth) if c_depth >= 0 else 0
            ca_depth = ida_kernwin.ask_long(1, "Enter Callee/Ref Depth (e.g., 0, 1, 2)")
            if ca_depth is None: return 0
            container[0]["callee_depth"] = int(ca_depth) if ca_depth >= 0 else 0
            xref_types_str = ida_kernwin.ask_str("all", 0, "Enter comma-separated xref types to include (or 'all'):\n"
                                                         "direct_call,indirect_call,data_ref,immediate_ref,tail_call_push_ret,virtual_call,jump_table")
            if xref_types_str is None: return 0
            if xref_types_str.strip().lower() == 'all':
                container[0]["xref_types"] = set(['direct_call', 'indirect_call', 'data_ref', 'immediate_ref', 'tail_call_push_ret', 'virtual_call', 'jump_table'])
            else:
                container[0]["xref_types"] = set([t.strip() for t in xref_types_str.split(',') if t.strip()])
            m_chars = ida_kernwin.ask_long(0, "Enter maximum characters for the output file (0 for no limit)")
            if m_chars is None: return 0
            container[0]["max_chars"] = int(m_chars) if m_chars >= 0 else 0
            default_filename = re.sub(r'[<>:"/\\|?*]', '_', f"{start_func_name}_dump_callers{c_depth}_callees{ca_depth}.c")
            output_file = ida_kernwin.ask_file(True, default_filename, "Select Output C File")
            if not output_file: return 0
            container[0]["output_file"] = output_file
            return 1
        sync_status = ida_kernwin.execute_sync(lambda: get_inputs_main(input_container), ida_kernwin.MFF_WRITE)
        final_inputs = input_container[0]
        caller_depth = final_inputs["caller_depth"]
        callee_depth = final_inputs["callee_depth"]
        output_file_path = final_inputs["output_file"]
        xref_types = final_inputs["xref_types"]
        max_chars = final_inputs["max_chars"]
        if sync_status != 1 or caller_depth < 0 or callee_depth < 0 or not output_file_path or not xref_types:
            with g_dump_lock:
                g_dump_in_progress.discard(start_func_ea)
            return 1
        task_thread = threading.Thread(target=dump_task, args=(set([start_func_ea]), caller_depth, callee_depth, output_file_path, 'code', xref_types, max_chars))
        task_thread.start()
        return 1
    def update(self, ctx):
        if ctx.widget_type == ida_kernwin.BWN_PSEUDOCODE:
            vu = ida_hexrays.get_widget_vdui(ctx.widget)
            if vu and vu.cfunc:
                return ida_kernwin.AST_ENABLE_FOR_WIDGET
        return ida_kernwin.AST_DISABLE_FOR_WIDGET

class DumpDotCtxActionHandler(ida_kernwin.action_handler_t):
    def activate(self, ctx):
        global g_dump_in_progress, g_multi_dump_active
        widget = ctx.widget
        widget_type = ida_kernwin.get_widget_type(widget)
        if widget_type != ida_kernwin.BWN_PSEUDOCODE:
            return 1
        vu = ida_hexrays.get_widget_vdui(widget)
        if not vu or not vu.cfunc:
            ida_kernwin.warning(f"{PLUGIN_NAME}: Not available for this function.")
            return 1
        start_func_ea = vu.cfunc.entry_ea
        start_func_name = ida_funcs.get_func_name(start_func_ea) or f"sub_{start_func_ea:X}"
        with g_dump_lock:
            if start_func_ea in g_dump_in_progress:
                ida_kernwin.warning(f"{PLUGIN_NAME}: Operation already running for {start_func_name}.")
                return 1
            if g_multi_dump_active:
                ida_kernwin.warning(f"{PLUGIN_NAME}: A multi-function operation is currently running.")
                return 1
            g_dump_in_progress.add(start_func_ea)

        input_results = {"caller_depth": -1, "callee_depth": -1, "output_file": None, "xref_types": None, "max_chars": 0}
        input_container = [input_results]
        def get_inputs_main(container):
            c_depth = ida_kernwin.ask_long(0, "Enter Caller Depth (e.g., 0, 1, 2)")
            if c_depth is None: return 0
            container[0]["caller_depth"] = int(c_depth) if c_depth >= 0 else 0
            ca_depth = ida_kernwin.ask_long(1, "Enter Callee/Ref Depth (e.g., 0, 1, 2)")
            if ca_depth is None: return 0
            container[0]["callee_depth"] = int(ca_depth) if c_depth >= 0 else 0
            xref_types_str = ida_kernwin.ask_str("all", 0, "Enter comma-separated xref types to include (or 'all'):\n"
                                                         "direct_call,indirect_call,data_ref,immediate_ref,tail_call_push_ret,virtual_call,jump_table")
            if xref_types_str is None: return 0
            if xref_types_str.strip().lower() == 'all':
                container[0]["xref_types"] = set(['direct_call', 'indirect_call', 'data_ref', 'immediate_ref', 'tail_call_push_ret', 'virtual_call', 'jump_table'])
            else:
                container[0]["xref_types"] = set([t.strip() for t in xref_types_str.split(',') if t.strip()])
            m_chars = ida_kernwin.ask_long(0, "Enter maximum characters for the output file (0 for no limit)")
            if m_chars is None: return 0
            container[0]["max_chars"] = int(m_chars) if m_chars >= 0 else 0
            default_filename = re.sub(r'[<>:"/\\|?*]', '_', f"{start_func_name}_graph_callers{c_depth}_callees{ca_depth}.dot")
            output_file = ida_kernwin.ask_file(True, default_filename, "Select Output DOT File")
            if not output_file: return 0
            container[0]["output_file"] = output_file
            return 1
        sync_status = ida_kernwin.execute_sync(lambda: get_inputs_main(input_container), ida_kernwin.MFF_WRITE)
        final_inputs = input_container[0]
        caller_depth = final_inputs["caller_depth"]
        callee_depth = final_inputs["callee_depth"]
        output_file_path = final_inputs["output_file"]
        xref_types = final_inputs["xref_types"]
        max_chars = final_inputs["max_chars"]
        if sync_status != 1 or caller_depth < 0 or callee_depth < 0 or not output_file_path or not xref_types:
            with g_dump_lock:
                g_dump_in_progress.discard(start_func_ea)
            return 1
        task_thread = threading.Thread(target=dump_task, args=(set([start_func_ea]), caller_depth, callee_depth, output_file_path, 'graph', xref_types, max_chars))
        task_thread.start()
        return 1
    def update(self, ctx):
        if ctx.widget_type == ida_kernwin.BWN_PSEUDOCODE:
            vu = ida_hexrays.get_widget_vdui(ctx.widget)
            if vu and vu.cfunc:
                return ida_kernwin.AST_ENABLE_FOR_WIDGET
        return ida_kernwin.AST_DISABLE_FOR_WIDGET

class DumpPTNCtxActionHandler(ida_kernwin.action_handler_t):
    def activate(self, ctx):
        global g_dump_in_progress, g_multi_dump_active
        widget = ctx.widget
        widget_type = ida_kernwin.get_widget_type(widget)
        if widget_type != ida_kernwin.BWN_PSEUDOCODE:
            return 1
        vu = ida_hexrays.get_widget_vdui(widget)
        if not vu or not vu.cfunc:
            ida_kernwin.warning(f"{PLUGIN_NAME}: Not available for this function.")
            return 1
        start_func_ea = vu.cfunc.entry_ea
        start_func_name = ida_funcs.get_func_name(start_func_ea) or f"sub_{start_func_ea:X}"
        with g_dump_lock:
            if start_func_ea in g_dump_in_progress:
                ida_kernwin.warning(f"{PLUGIN_NAME}: Operation already running for {start_func_name}.")
                return 1
            if g_multi_dump_active:
                ida_kernwin.warning(f"{PLUGIN_NAME}: A multi-function operation is currently running.")
                return 1
            g_dump_in_progress.add(start_func_ea)

        input_results = {"caller_depth": -1, "callee_depth": -1, "output_file": None}
        input_container = [input_results]
        def get_inputs_main(container):
            ca_depth = ida_kernwin.ask_long(1, "Enter Callee/Ref Depth for PTN (e.g., 1, 2)")
            if ca_depth is None: return 0
            container[0]["callee_depth"] = int(ca_depth) if ca_depth >= 1 else 1
            default_filename = re.sub(r'[<>:"/\\|?*]', '_', f"{start_func_name}_provenance.ptn")
            output_file = ida_kernwin.ask_file(True, default_filename, "Select Output PTN File (.ptn or .json)")
            if not output_file: return 0
            container[0]["output_file"] = output_file
            container[0]["caller_depth"] = 0
            return 1
        sync_status = ida_kernwin.execute_sync(lambda: get_inputs_main(input_container), ida_kernwin.MFF_WRITE)
        final_inputs = input_container[0]
        callee_depth = final_inputs["callee_depth"]
        output_file_path = final_inputs["output_file"]
        if sync_status != 1 or callee_depth < 1 or not output_file_path:
            with g_dump_lock:
                g_dump_in_progress.discard(start_func_ea)
            return 1
        task_thread = threading.Thread(target=dump_task, args=(set([start_func_ea]), 0, callee_depth, output_file_path, 'ptn', set(), 0))
        task_thread.start()
        return 1
    def update(self, ctx):
        if ctx.widget_type == ida_kernwin.BWN_PSEUDOCODE:
            vu = ida_hexrays.get_widget_vdui(ctx.widget)
            if vu and vu.cfunc:
                return ida_kernwin.AST_ENABLE_FOR_WIDGET
        return ida_kernwin.AST_DISABLE_FOR_WIDGET

class CopyPTNVarCtxActionHandler(ida_kernwin.action_handler_t):
    def activate(self, ctx):
        widget = ctx.widget
        if ida_kernwin.get_widget_type(widget) != ida_kernwin.BWN_PSEUDOCODE:
            return 1
        vu = ida_hexrays.get_widget_vdui(widget)
        if not vu or not vu.cfunc:
            ida_kernwin.warning(f"{PLUGIN_NAME}: Not available for this function.")
            return 1
        func_ea = vu.cfunc.entry_ea
        def run_collect_current_fs():
            try:
                return analyze_functions_ctree([func_ea]).get(func_ea)
            except Exception:
                traceback.print_exc()
                return None
        fs = None
        ida_kernwin.execute_sync(lambda: None, ida_kernwin.MFF_READ)
        fs = run_collect_current_fs()
        if not fs:
            ida_kernwin.warning(f"{PLUGIN_NAME}: Could not compute provenance for current function.")
            return 1
        ident = ""
        try:
            t = ida_kernwin.get_highlight(widget)
            if t and t[0]:
                ident = t[0]
        except Exception:
            ident = ""
        from ptn_utils import PTNEmitter  # local import
        emitter = PTNEmitter({func_ea: fs})
        ann = emitter.per_function_annotations(callee_depth=2).get(func_ea, "")
        relevant_lines = []
        if ident:
            for line in ann.splitlines():
                if ident in line:
                    relevant_lines.append(line)
        if not relevant_lines:
            relevant_lines = ann.splitlines()
        text = "\n".join(relevant_lines) + ("\n" if relevant_lines else "")
        try:
            ida_kernwin.set_clipboard(text)
            ida_kernwin.info(f"{PLUGIN_NAME}: Copied PTN lines to clipboard.")
        except Exception:
            ida_kernwin.warning(f"{PLUGIN_NAME}: Could not set clipboard; showing in a dialog.")
            ida_kernwin.info(text)
        return 1
    def update(self, ctx):
        if ctx.widget_type == ida_kernwin.BWN_PSEUDOCODE:
            return ida_kernwin.AST_ENABLE_FOR_WIDGET
        return ida_kernwin.AST_DISABLE_FOR_WIDGET

class DumpAsmCtxActionHandler(ida_kernwin.action_handler_t):
    def activate(self, ctx):
        global g_dump_in_progress, g_multi_dump_active
        widget = ctx.widget
        widget_type = ida_kernwin.get_widget_type(widget)
        if widget_type != ida_kernwin.BWN_PSEUDOCODE:
            return 1
        vu = ida_hexrays.get_widget_vdui(widget)
        if not vu or not vu.cfunc:
            ida_kernwin.warning(f"{PLUGIN_NAME}: Not available for this function.")
            return 1
        start_func_ea = vu.cfunc.entry_ea
        start_func_name = ida_funcs.get_func_name(start_func_ea) or f"sub_{start_func_ea:X}"
        with g_dump_lock:
            if start_func_ea in g_dump_in_progress:
                ida_kernwin.warning(f"{PLUGIN_NAME}: Operation already running for {start_func_name}.")
                return 1
            if g_multi_dump_active:
                ida_kernwin.warning(f"{PLUGIN_NAME}: A multi-function operation is currently running.")
                return 1
            g_dump_in_progress.add(start_func_ea)

        input_results = {"caller_depth": -1, "callee_depth": -1, "output_file": None, "xref_types": None, "max_chars": 0}
        input_container = [input_results]
        def get_inputs_main(container):
            c_depth = ida_kernwin.ask_long(0, "Enter Caller Depth (e.g., 0, 1, 2)")
            if c_depth is None: return 0
            container[0]["caller_depth"] = int(c_depth) if c_depth >= 0 else 0
            ca_depth = ida_kernwin.ask_long(1, "Enter Callee/Ref Depth (e.g., 0, 1, 2)")
            if ca_depth is None: return 0
            container[0]["callee_depth"] = int(ca_depth) if ca_depth >= 0 else 0
            xref_types_str = ida_kernwin.ask_str("all", 0, "Enter comma-separated xref types to include (or 'all'):\n"
                                                         "direct_call,indirect_call,data_ref,immediate_ref,tail_call_push_ret,virtual_call,jump_table")
            if xref_types_str is None: return 0
            if xref_types_str.strip().lower() == 'all':
                container[0]["xref_types"] = set(['direct_call', 'indirect_call', 'data_ref', 'immediate_ref', 'tail_call_push_ret', 'virtual_call', 'jump_table'])
            else:
                container[0]["xref_types"] = set([t.strip() for t in xref_types_str.split(',') if t.strip()])
            m_chars = ida_kernwin.ask_long(0, "Enter maximum characters for the output file (0 for no limit)")
            if m_chars is None: return 0
            container[0]["max_chars"] = int(m_chars) if m_chars >= 0 else 0
            default_filename = re.sub(r'[<>:"/\\|?*]', '_', f"{start_func_name}_asm_callers{c_depth}_callees{ca_depth}.asm")
            output_file = ida_kernwin.ask_file(True, default_filename, "Select Output ASM File")
            if not output_file: return 0
            container[0]["output_file"] = output_file
            return 1
        sync_status = ida_kernwin.execute_sync(lambda: get_inputs_main(input_container), ida_kernwin.MFF_WRITE)
        final_inputs = input_container[0]
        caller_depth = final_inputs["caller_depth"]
        callee_depth = final_inputs["callee_depth"]
        output_file_path = final_inputs["output_file"]
        xref_types = final_inputs["xref_types"]
        max_chars = final_inputs["max_chars"]
        if sync_status != 1 or caller_depth < 0 or callee_depth < 0 or not output_file_path or not xref_types:
            with g_dump_lock:
                g_dump_in_progress.discard(start_func_ea)
            return 1
        task_thread = threading.Thread(target=dump_task, args=(set([start_func_ea]), caller_depth, callee_depth, output_file_path, 'asm', xref_types, max_chars))
        task_thread.start()
        return 1
    def update(self, ctx):
        if ctx.widget_type == ida_kernwin.BWN_PSEUDOCODE:
            vu = ida_hexrays.get_widget_vdui(ctx.widget)
            if vu and vu.cfunc:
                return ida_kernwin.AST_ENABLE_FOR_WIDGET
        return ida_kernwin.AST_DISABLE_FOR_WIDGET

def perform_multi_dump(mode):
    global g_dump_in_progress, g_multi_dump_active
    with g_dump_lock:
        if g_multi_dump_active:
            ida_kernwin.warning(f"{PLUGIN_NAME}: A multi-function operation is already running.")
            return
        if g_dump_in_progress:
            ida_kernwin.warning(f"{PLUGIN_NAME}: One or more single function operations are running.")
            return
        g_multi_dump_active = True

    input_results = {"start_eas": set(), "caller_depth": -1, "callee_depth": -1, "output_file": None, "xref_types": None, "max_chars": 0}
    input_container = [input_results]

    def get_multi_inputs_main(container, mode):
        func_list_str = ida_kernwin.ask_str("", 0, "Enter comma-separated function names or addresses (e.g., sub_123, 0x401000, MyFunc)")
        if not func_list_str:
            return 0
        start_eas = set()
        unresolved = []
        items = [item.strip() for item in func_list_str.split(',') if item.strip()]
        if not items:
            ida_kernwin.warning(f"{PLUGIN_NAME}: No function names or addresses provided.")
            return 0
        for item in items:
            ea = idaapi.BADADDR
            if item.lower().startswith("0x"):
                try:
                    ea = int(item, 16)
                except ValueError:
                    pass
            elif item.isdigit():
                try:
                    ea = int(item)
                except ValueError:
                    pass
            if ea == idaapi.BADADDR:
                ea = ida_name.get_name_ea(idaapi.BADADDR, item)
            if ea != idaapi.BADADDR and ida_funcs.get_func(ea):
                start_eas.add(ea)
            else:
                unresolved.append(item)
        if unresolved:
            ida_kernwin.warning(f"{PLUGIN_NAME}: Could not resolve or find functions:\n" + "\n".join(unresolved))
        if not start_eas:
            ida_kernwin.warning(f"{PLUGIN_NAME}: No valid functions found.")
            return 0
        container[0]["start_eas"] = start_eas
        c_depth = ida_kernwin.ask_long(0, "Enter Caller Depth (e.g., 0, 1, 2)")
        if c_depth is None: return 0
        container[0]["caller_depth"] = int(c_depth) if c_depth >= 0 else 0
        ca_depth = ida_kernwin.ask_long(1, "Enter Callee/Ref Depth (e.g., 0, 1, 2)")
        if ca_depth is None: return 0
        container[0]["callee_depth"] = int(ca_depth) if c_depth >= 0 else 0
        xref_types_str = ida_kernwin.ask_str("all", 0, "Enter comma-separated xref types to include (or 'all'):\n"
                                                     "direct_call,indirect_call,data_ref,immediate_ref,tail_call_push_ret,virtual_call,jump_table")
        if xref_types_str is None:
            return 0
        if xref_types_str.strip().lower() == 'all':
            container[0]["xref_types"] = set(['direct_call', 'indirect_call', 'data_ref', 'immediate_ref', 'tail_call_push_ret', 'virtual_call', 'jump_table'])
        else:
            container[0]["xref_types"] = set([t.strip() for t in xref_types_str.split(',') if t.strip()])
        m_chars = ida_kernwin.ask_long(0, "Enter maximum characters for the output file (0 for no limit)")
        if m_chars is None: return 0
        container[0]["max_chars"] = int(m_chars) if m_chars >= 0 else 0
        first_func_ea = sorted(list(start_eas))[0]
        first_func_name = ida_funcs.get_func_name(first_func_ea) or f"sub_{first_func_ea:X}"
        if mode == 'code':
            default_filename = f"multi_dump_{first_func_name}_etc_callers{c_depth}_callees{ca_depth}.c"
            title = "Select Output C File"
        elif mode == 'ptn':
            default_filename = f"multi_ptn_{first_func_name}_etc_callers{c_depth}_callees{ca_depth}.ptn"
            title = "Select Output PTN File"
        elif mode == 'asm':
            default_filename = f"multi_asm_{first_func_name}_etc_callers{c_depth}_callees{ca_depth}.asm"
            title = "Select Output ASM File"
        else:
            default_filename = f"multi_graph_{first_func_name}_etc_callers{c_depth}_callees{ca_depth}.dot"
            title = "Select Output DOT File"
        default_filename = re.sub(r'[<>:"/\\|?*]', '_', default_filename)
        output_file = ida_kernwin.ask_file(True, default_filename, title)
        if not output_file: return 0
        container[0]["output_file"] = output_file
        return 1

    sync_status = ida_kernwin.execute_sync(lambda: get_multi_inputs_main(input_container, mode), ida_kernwin.MFF_WRITE)
    final_inputs = input_container[0]
    start_eas = final_inputs["start_eas"]
    caller_depth = final_inputs["caller_depth"]
    callee_depth = final_inputs["callee_depth"]
    output_file_path = final_inputs["output_file"]
    xref_types = final_inputs["xref_types"]
    max_chars = final_inputs["max_chars"]
    if sync_status != 1 or not start_eas or caller_depth < 0 or callee_depth < 0 or not output_file_path or (mode != 'ptn' and not xref_types):
        with g_dump_lock:
            g_multi_dump_active = False
        return
    task_thread = threading.Thread(target=dump_task, args=(start_eas, caller_depth, callee_depth, output_file_path, mode, xref_types or set(), max_chars))
    task_thread.start()

class DumpCodeMultiActionHandler(ida_kernwin.action_handler_t):
    def activate(self, ctx):
        perform_multi_dump('code')
        return 1
    def update(self, ctx):
        return ida_kernwin.AST_ENABLE_ALWAYS

class DumpDotMultiActionHandler(ida_kernwin.action_handler_t):
    def activate(self, ctx):
        perform_multi_dump('graph')
        return 1
    def update(self, ctx):
        return ida_kernwin.AST_ENABLE_ALWAYS

class DumpPTNMultiActionHandler(ida_kernwin.action_handler_t):
    def activate(self, ctx):
        perform_multi_dump('ptn')
        return 1
    def update(self, ctx):
        return ida_kernwin.AST_ENABLE_ALWAYS

class DumpAsmMultiActionHandler(ida_kernwin.action_handler_t):
    def activate(self, ctx):
        perform_multi_dump('asm')
        return 1
    def update(self, ctx):
        return ida_kernwin.AST_ENABLE_ALWAYS

class DumpHooks(ida_kernwin.UI_Hooks):
    def finish_populating_widget_popup(self, widget, popup_handle, ctx=None):
        widget_type = ida_kernwin.get_widget_type(widget)
        if widget_type == ida_kernwin.BWN_PSEUDOCODE:
            try:
                ida_kernwin.attach_action_to_popup(widget, popup_handle, ACTION_ID_CTX, "Dump code/", ida_kernwin.SETMENU_INS)
                ida_kernwin.attach_action_to_popup(widget, popup_handle, ACTION_ID_DOT_CTX, "Dump code/", ida_kernwin.SETMENU_INS)
                ida_kernwin.attach_action_to_popup(widget, popup_handle, ACTION_ID_PTN_CTX, "Dump code/", ida_kernwin.SETMENU_INS)
                ida_kernwin.attach_action_to_popup(widget, popup_handle, ACTION_ID_PTN_COPY_CTX, "Dump code/", ida_kernwin.SETMENU_INS)
                ida_kernwin.attach_action_to_popup(widget, popup_handle, ACTION_ID_ASM_CTX, "Dump code/", ida_kernwin.SETMENU_INS)
            except Exception:
                traceback.print_exc()

class CodeDumperPlugin(idaapi.plugin_t):
    flags = idaapi.PLUGIN_PROC | idaapi.PLUGIN_FIX
    comment = "Dumps decompiled code, DOT graphs, PTN provenance, and assembly"
    help = "Use Edit->Plugins->CodeDumper, or right-click in Pseudocode view"
    wanted_name = PLUGIN_NAME
    wanted_hotkey = ""
    hooks = None

    def init(self):
        if not ida_hexrays.init_hexrays_plugin():
            return idaapi.PLUGIN_SKIP
        action_desc_ctx = ida_kernwin.action_desc_t(ACTION_ID_CTX, ACTION_LABEL_CTX, DumpCtxActionHandler(), self.wanted_hotkey, ACTION_TOOLTIP_CTX, 199)
        if not ida_kernwin.register_action(action_desc_ctx):
            return idaapi.PLUGIN_SKIP
        action_desc_dot_ctx = ida_kernwin.action_desc_t(ACTION_ID_DOT_CTX, ACTION_LABEL_DOT_CTX, DumpDotCtxActionHandler(), self.wanted_hotkey, ACTION_TOOLTIP_DOT_CTX, 199)
        if not ida_kernwin.register_action(action_desc_dot_ctx):
            ida_kernwin.unregister_action(ACTION_ID_CTX)
            return idaapi.PLUGIN_SKIP
        action_desc_ptn_ctx = ida_kernwin.action_desc_t(ACTION_ID_PTN_CTX, ACTION_LABEL_PTN_CTX, DumpPTNCtxActionHandler(), self.wanted_hotkey, ACTION_TOOLTIP_PTN_CTX, 199)
        if not ida_kernwin.register_action(action_desc_ptn_ctx):
            ida_kernwin.unregister_action(ACTION_ID_CTX); ida_kernwin.unregister_action(ACTION_ID_DOT_CTX)
            return idaapi.PLUGIN_SKIP
        action_desc_ptn_copy_ctx = ida_kernwin.action_desc_t(ACTION_ID_PTN_COPY_CTX, ACTION_LABEL_PTN_COPY_CTX, CopyPTNVarCtxActionHandler(), self.wanted_hotkey, ACTION_TOOLTIP_PTN_COPY_CTX, 199)
        if not ida_kernwin.register_action(action_desc_ptn_copy_ctx):
            ida_kernwin.unregister_action(ACTION_ID_CTX); ida_kernwin.unregister_action(ACTION_ID_DOT_CTX); ida_kernwin.unregister_action(ACTION_ID_PTN_CTX)
            return idaapi.PLUGIN_SKIP
        action_desc_asm_ctx = ida_kernwin.action_desc_t(ACTION_ID_ASM_CTX, ACTION_LABEL_ASM_CTX, DumpAsmCtxActionHandler(), self.wanted_hotkey, ACTION_TOOLTIP_ASM_CTX, 199)
        if not ida_kernwin.register_action(action_desc_asm_ctx):
            ida_kernwin.unregister_action(ACTION_ID_CTX); ida_kernwin.unregister_action(ACTION_ID_DOT_CTX); ida_kernwin.unregister_action(ACTION_ID_PTN_CTX); ida_kernwin.unregister_action(ACTION_ID_PTN_COPY_CTX)
            return idaapi.PLUGIN_SKIP

        action_desc_code_multi = ida_kernwin.action_desc_t(ACTION_ID_CODE_MULTI, ACTION_LABEL_CODE_MULTI, DumpCodeMultiActionHandler(), None, ACTION_TOOLTIP_CODE_MULTI, 199)
        if not ida_kernwin.register_action(action_desc_code_multi):
            ida_kernwin.unregister_action(ACTION_ID_CTX); ida_kernwin.unregister_action(ACTION_ID_DOT_CTX)
            ida_kernwin.unregister_action(ACTION_ID_PTN_CTX); ida_kernwin.unregister_action(ACTION_ID_PTN_COPY_CTX); ida_kernwin.unregister_action(ACTION_ID_ASM_CTX)
            return idaapi.PLUGIN_SKIP

        action_desc_dot_multi = ida_kernwin.action_desc_t(ACTION_ID_DOT_MULTI, ACTION_LABEL_DOT_MULTI, DumpDotMultiActionHandler(), None, ACTION_TOOLTIP_DOT_MULTI, 199)
        if not ida_kernwin.register_action(action_desc_dot_multi):
            ida_kernwin.unregister_action(ACTION_ID_CTX); ida_kernwin.unregister_action(ACTION_ID_DOT_CTX)
            ida_kernwin.unregister_action(ACTION_ID_PTN_CTX); ida_kernwin.unregister_action(ACTION_ID_PTN_COPY_CTX)
            ida_kernwin.unregister_action(ACTION_ID_CODE_MULTI); ida_kernwin.unregister_action(ACTION_ID_ASM_CTX)
            return idaapi.PLUGIN_SKIP

        action_desc_ptn_multi = ida_kernwin.action_desc_t(ACTION_ID_PTN_MULTI, ACTION_LABEL_PTN_MULTI, DumpPTNMultiActionHandler(), None, ACTION_TOOLTIP_PTN_MULTI, 199)
        if not ida_kernwin.register_action(action_desc_ptn_multi):
            ida_kernwin.unregister_action(ACTION_ID_CTX); ida_kernwin.unregister_action(ACTION_ID_DOT_CTX)
            ida_kernwin.unregister_action(ACTION_ID_PTN_CTX); ida_kernwin.unregister_action(ACTION_ID_PTN_COPY_CTX)
            ida_kernwin.unregister_action(ACTION_ID_CODE_MULTI); ida_kernwin.unregister_action(ACTION_ID_DOT_MULTI); ida_kernwin.unregister_action(ACTION_ID_ASM_CTX)
            return idaapi.PLUGIN_SKIP

        action_desc_asm_multi = ida_kernwin.action_desc_t(ACTION_ID_ASM_MULTI, ACTION_LABEL_ASM_MULTI, DumpAsmMultiActionHandler(), None, ACTION_TOOLTIP_ASM_MULTI, 199)
        if not ida_kernwin.register_action(action_desc_asm_multi):
            ida_kernwin.unregister_action(ACTION_ID_CTX); ida_kernwin.unregister_action(ACTION_ID_DOT_CTX)
            ida_kernwin.unregister_action(ACTION_ID_PTN_CTX); ida_kernwin.unregister_action(ACTION_ID_PTN_COPY_CTX)
            ida_kernwin.unregister_action(ACTION_ID_CODE_MULTI); ida_kernwin.unregister_action(ACTION_ID_DOT_MULTI); ida_kernwin.unregister_action(ACTION_ID_PTN_MULTI); ida_kernwin.unregister_action(ACTION_ID_ASM_CTX)
            return idaapi.PLUGIN_SKIP

        ida_kernwin.attach_action_to_menu(MENU_PATH_MULTI, ACTION_ID_CODE_MULTI, ida_kernwin.SETMENU_APP)
        ida_kernwin.attach_action_to_menu(MENU_PATH_MULTI, ACTION_ID_DOT_MULTI, ida_kernwin.SETMENU_APP)
        ida_kernwin.attach_action_to_menu(MENU_PATH_MULTI, ACTION_ID_PTN_MULTI, ida_kernwin.SETMENU_APP)
        ida_kernwin.attach_action_to_menu(MENU_PATH_MULTI, ACTION_ID_ASM_MULTI, ida_kernwin.SETMENU_APP)

        self.hooks = DumpHooks()
        if not self.hooks.hook():
            ida_kernwin.unregister_action(ACTION_ID_CTX); ida_kernwin.unregister_action(ACTION_ID_DOT_CTX)
            ida_kernwin.unregister_action(ACTION_ID_PTN_CTX); ida_kernwin.unregister_action(ACTION_ID_PTN_COPY_CTX)
            ida_kernwin.unregister_action(ACTION_ID_CODE_MULTI); ida_kernwin.unregister_action(ACTION_ID_DOT_MULTI); ida_kernwin.unregister_action(ACTION_ID_PTN_MULTI); ida_kernwin.unregister_action(ACTION_ID_ASM_MULTI); ida_kernwin.unregister_action(ACTION_ID_ASM_CTX)
            self.hooks = None
            return idaapi.PLUGIN_SKIP
        return idaapi.PLUGIN_KEEP

    def run(self, arg):
        pass

    def term(self):
        if self.hooks:
            try:
                self.hooks.unhook()
            except Exception:
                pass
            self.hooks = None
        try: ida_kernwin.detach_action_from_menu(MENU_PATH_MULTI, ACTION_ID_CODE_MULTI)
        except Exception: pass
        try: ida_kernwin.detach_action_from_menu(MENU_PATH_MULTI, ACTION_ID_DOT_MULTI)
        except Exception: pass
        try: ida_kernwin.detach_action_from_menu(MENU_PATH_MULTI, ACTION_ID_PTN_MULTI)
        except Exception: pass
        try: ida_kernwin.detach_action_from_menu(MENU_PATH_MULTI, ACTION_ID_ASM_MULTI)
        except Exception: pass
        for act in [ACTION_ID_CTX, ACTION_ID_DOT_CTX, ACTION_ID_PTN_CTX, ACTION_ID_PTN_COPY_CTX, ACTION_ID_CODE_MULTI, ACTION_ID_DOT_MULTI, ACTION_ID_PTN_MULTI, ACTION_ID_ASM_CTX, ACTION_ID_ASM_MULTI]:
            try: ida_kernwin.unregister_action(act)
            except Exception: pass
        with g_dump_lock:
            g_dump_in_progress.clear()
            global g_multi_dump_active
            g_multi_dump_active = False

def PLUGIN_ENTRY():
    return CodeDumperPlugin()

```

`ida-plugin.json`:

```json
{
  "IDAMetadataDescriptorVersion": 1,
  "plugin": {
    "name": "semray",
    "entryPoint": "semray.py"
  }
}

```

`micro-analyzer.py`:

```py
# -*- coding: utf-8 -*-
from __future__ import annotations

import ida_hexrays
import ida_funcs
import idaapi
import ida_kernwin
import ida_nalt
import idautils
import idc
import ida_name

from typing import Dict, List, Optional, Tuple
from ptn_utils import FunctionSummary, ArgUse, GlobalAccess, Alias

# Intraprocedural provenance extraction based primarily on ctree with defensive fallbacks.
# This module must run in the IDA main thread.

def _get_func_name(ea: int) -> str:
    try:
        n = ida_funcs.get_func_name(ea)
        if n:
            return n
    except Exception:
        pass
    return f"sub_{ea:X}"

def _type_size_bytes(t) -> Optional[int]:
    try:
        if t and t.get_size() > 0:
            return int(t.get_size())
    except Exception:
        pass
    return None

def _ptr_pointee_size_bytes(t) -> Optional[int]:
    try:
        if t and t.is_ptr():
            pt = t.get_pointed_object()
            if pt:
                return _type_size_bytes(pt)
    except Exception:
        pass
    return None

def _num_value(e) -> Optional[int]:
    try:
        if e.op == ida_hexrays.cot_num:
            return int(e.numval())
    except Exception:
        pass
    return None

def _unwrap_casts(e):
    while e and e.op == ida_hexrays.cot_cast:
        e = e.x
    return e

def _normalize_expr_origin(cfunc, e) -> Tuple[str, int, str, Optional[int], Optional[int], Optional[str], str]:
    """
    Returns (base_kind, base_id, base_name, off, length, cast, mode)
    base_kind: 'L' | 'P' | 'G' | 'U'
    base_id: lidx | pidx | global_ea | -1
    base_name: textual name for humans/LLMs when index is -1
    off: byte offset if known
    length: byte length if known
    cast: textual cast type if present
    mode: '', '&', or '*'
    """
    mode = ""
    off = 0
    length = None
    cast_txt = None
    base_kind = "U"
    base_id = -1
    base_name = ""

    def peel(expr):
        nonlocal mode, off, cast_txt
        cur = expr
        while True:
            if cur is None:
                return None
            if cur.op == ida_hexrays.cot_cast:
                try:
                    cast_txt = str(cur.type)
                except Exception:
                    cast_txt = None
                cur = cur.x
                continue
            if cur.op == ida_hexrays.cot_ref:
                mode = "&"
                cur = cur.x
                continue
            if cur.op == ida_hexrays.cot_memref:
                mode = "*"
                cur = cur.x
                continue
            if cur.op == ida_hexrays.cot_memptr:
                mode = "*"
                try:
                    off += int(cur.m)
                except Exception:
                    pass
                cur = cur.x
                continue
            if cur.op == ida_hexrays.cot_idx:
                idxv = _num_value(cur.y)
                stride = _ptr_pointee_size_bytes(cur.x.type) or _type_size_bytes(cur.type)
                if idxv is not None and stride:
                    off += idxv * stride
                cur = cur.x
                continue
            if cur.op == ida_hexrays.cot_add:
                c1 = _num_value(cur.y)
                c0 = _num_value(cur.x)
                if c1 is not None:
                    off += c1
                    cur = cur.x
                    continue
                if c0 is not None:
                    off += c0
                    cur = cur.y
                    continue
            break
        return cur

    base = peel(_unwrap_casts(e))
    if base is None:
        return ("U", -1, "", None, None, cast_txt, mode)

    try:
        if base.op == ida_hexrays.cot_var:
            lv = base.v
            pidx = -1
            lidx = -1
            try:
                if getattr(lv, "is_arg_var", False):
                    pidx = getattr(lv, "argidx", -1)
                    base_kind = "P"
                    base_id = int(pidx) if isinstance(pidx, int) else -1
                else:
                    base_kind = "L"
                    lidx = getattr(lv, "idx", -1)
                    base_id = int(lidx) if isinstance(lidx, int) else -1
            except Exception:
                base_kind = "L"
                base_id = -1
            base_name = getattr(lv, "name", "")
            if mode == "&":
                length = _ptr_pointee_size_bytes(e.type) or _ptr_pointee_size_bytes(base.type)
            else:
                length = _type_size_bytes(e.type)
        elif base.op == ida_hexrays.cot_obj:
            base_kind = "G"
            base_id = int(base.obj_ea)
            base_name = ""
            length = _type_size_bytes(e.type)
        else:
            base_kind = "U"
            base_id = -1
        off_val = off if off != 0 else None
        return (base_kind, base_id, base_name, off_val, length, cast_txt, mode)
    except Exception:
        return ("U", -1, "", None, None, cast_txt, mode)

class _ProvCollector(ida_hexrays.ctree_visitor_t):
    def __init__(self, cfunc):
        super().__init__(ida_hexrays.CV_FAST)
        self.cfunc = cfunc
        self.fs = FunctionSummary(func_ea=cfunc.entry_ea,
                                  func_name=_get_func_name(cfunc.entry_ea))
        try:
            lvars = list(cfunc.get_lvars())
            for lv in lvars:
                nm = getattr(lv, "name", "")
                if getattr(lv, "is_arg_var", False):
                    pidx = getattr(lv, "argidx", -1)
                    self.fs.params[int(pidx) if isinstance(pidx, int) else -1] = nm
                else:
                    lidx = getattr(lv, "idx", -1)
                    self.fs.locals[int(lidx) if isinstance(lidx, int) else -1] = nm
        except Exception:
            pass

    def _record_arguse(self, call_ea: int, callee_ea: Optional[int], arg_index: int, e):
        bk, bid, bname, off, length, cast, mode = _normalize_expr_origin(self.cfunc, e)
        conf = "high" if bk in ("L", "P", "G") else "low"
        self.fs.arguses.append(ArgUse(
            cs_ea=call_ea or 0,
            callee_ea=callee_ea,
            arg_index=arg_index,
            base_kind=bk,
            base_id=bid if isinstance(bid, int) else -1,
            base_name=bname or "",
            off=off, length=length, mode=mode, cast=cast, conf=conf
        ))

    def _record_alias(self, lhs, rhs):
        dst_kind, dst_id, dst_name = "U", -1, ""
        try:
            if lhs.op == ida_hexrays.cot_var:
                lv = lhs.v
                dst_name = getattr(lv, "name", "")
                if getattr(lv, "is_arg_var", False):
                    dst_kind = "P"
                    dst_id = getattr(lv, "argidx", -1)
                else:
                    dst_kind = "L"
                    dst_id = getattr(lv, "idx", -1)
        except Exception:
            return
        bk, bid, bname, off, length, cast, mode = _normalize_expr_origin(self.cfunc, rhs)
        if bk in ("L", "P", "G") and mode in ("&", "*", ""):
            self.fs.aliases.append(Alias(
                dst_kind=dst_kind, dst_id=dst_id if isinstance(dst_id, int) else -1, dst_name=dst_name or "",
                src_kind=bk, src_id=bid if isinstance(bid, int) else -1, src_name=bname or "",
                off=off, length=length, mode=mode or "&", cast=cast, conf="med"
            ))

    def _record_global_write_from_lvalue(self, lhs, cs_ea: int):
        cur = lhs
        off = 0
        try:
            while cur:
                if cur.op == ida_hexrays.cot_obj:
                    gea = int(cur.obj_ea)
                    self.fs.globals.append(GlobalAccess(ea=gea, off=(off if off else None), length=None, kind="W", cs_ea=cs_ea or 0))
                    return
                if cur.op == ida_hexrays.cot_memptr:
                    off += int(cur.m)
                    cur = cur.x
                    continue
                if cur.op == ida_hexrays.cot_memref:
                    cur = cur.x
                    continue
                if cur.op == ida_hexrays.cot_cast:
                    cur = cur.x
                    continue
                break
        except Exception:
            return

    def _record_global_read_from_expr(self, e, cs_ea: int):
        cur = e
        seen = set()
        stack = [cur]
        try:
            while stack:
                cur = stack.pop()
                if not cur or id(cur) in seen:
                    continue
                seen.add(id(cur))
                if cur.op == ida_hexrays.cot_obj:
                    gea = int(cur.obj_ea)
                    self.fs.globals.append(GlobalAccess(ea=gea, off=None, length=None, kind="R", cs_ea=cs_ea or 0))
                for ch in (getattr(cur, "x", None), getattr(cur, "y", None), getattr(cur, "z", None)):
                    if ch is not None:
                        stack.append(ch)
        except Exception:
            return

    def visit_expr(self, e):
        try:
            if e.op == ida_hexrays.cot_call:
                call_ea = int(e.ea) if e.ea else 0
                callee_ea = self._extract_callee_ea(e.x)
                argc = e.a.size()
                for k in range(argc):
                    arg = e.a[k]
                    self._record_arguse(call_ea, callee_ea, k, arg)
                self._record_global_read_from_expr(e, call_ea)
                return 0
            if e.op == ida_hexrays.cot_asg:
                a_ea = int(e.ea) if e.ea else 0
                self._record_global_write_from_lvalue(e.x, a_ea)
                self._record_alias(e.x, e.y)
                self._record_global_read_from_expr(e.y, a_ea)
                return 0
            eea = int(e.ea) if e.ea else 0
            self._record_global_read_from_expr(e, eea)
        except Exception:
            pass
        return 0

    def _extract_callee_ea(self, x) -> Optional[int]:
        try:
            y = x
            while y and y.op == ida_hexrays.cot_cast:
                y = y.x
            if not y:
                return None
            if y.op == ida_hexrays.cot_obj:
                return int(y.obj_ea)
            if y.op == ida_hexrays.cot_helper:
                h = getattr(y, "helper", None)
                if h:
                    ea = ida_name.get_name_ea(idaapi.BADADDR, h)
                    if ea != idaapi.BADADDR:
                        return int(ea)
                return None
            return None
        except Exception:
            return None

def analyze_functions_ctree(func_eas) -> Dict[int, FunctionSummary]:
    out: Dict[int, FunctionSummary] = {}
    for ea in func_eas:
        cfunc = None
        try:
            cfunc = ida_hexrays.decompile(ea)
        except ida_hexrays.DecompilationFailure:
            cfunc = None
        except Exception:
            cfunc = None
        if not cfunc:
            out[ea] = FunctionSummary(func_ea=ea, func_name=_get_func_name(ea))
            continue
        v = _ProvCollector(cfunc)
        try:
            v.apply_to(cfunc.body, None)
        except Exception:
            try:
                cfunc.body.visit_exprs(v)
            except Exception:
                pass
        out[ea] = v.fs
    return out

```

`ptn_utils.py`:

```py
# -*- coding: utf-8 -*-
from __future__ import annotations

import json
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Tuple, Set

ConfT = str  # 'low' | 'med' | 'high'

@dataclass
class ArgUse:
    cs_ea: int
    callee_ea: Optional[int]
    arg_index: int
    base_kind: str                 # 'L' | 'P' | 'G' | 'U' (unknown)
    base_id: int                   # lvar_idx | param_idx | global_ea | -1
    base_name: str = ""
    off: Optional[int] = None      # bytes
    length: Optional[int] = None   # bytes
    mode: str = ""                 # '', '&', '*'
    cast: Optional[str] = None
    conf: ConfT = "med"

@dataclass
class Alias:
    dst_kind: str                  # 'L' or 'P'
    dst_id: int
    dst_name: str
    src_kind: str                  # 'L' | 'P' | 'G' | 'U'
    src_id: int
    src_name: str = ""
    off: Optional[int] = None
    length: Optional[int] = None
    mode: str = "&"
    cast: Optional[str] = None
    conf: ConfT = "med"

@dataclass
class GlobalAccess:
    ea: int                        # global base EA
    off: Optional[int]             # byte offset into global, if known
    length: Optional[int]          # byte length, if known
    kind: str                      # 'R' or 'W'
    cs_ea: int = 0                 # code-site EA for this access (per-instruction correlation)

@dataclass
class FunctionSummary:
    func_ea: int
    func_name: str
    params: Dict[int, str] = field(default_factory=dict)  # pidx -> name
    locals: Dict[int, str] = field(default_factory=dict)  # lidx -> name
    arguses: List[ArgUse] = field(default_factory=list)
    aliases: List[Alias] = field(default_factory=list)
    globals: List[GlobalAccess] = field(default_factory=list)

class PTNEmitter:
    def __init__(self, summaries: Dict[int, FunctionSummary]):
        self.summaries = summaries
        self._fid_by_ea: Dict[int, str] = {}
        self._ea_by_fid: Dict[str, int] = {}
        self._name_by_ea: Dict[int, str] = {ea: fs.func_name for ea, fs in summaries.items()}
        self._assign_fids()

    def _assign_fids(self) -> None:
        for n, ea in enumerate(sorted(self.summaries.keys())):
            fid = f"F{n+1}"
            self._fid_by_ea[ea] = fid
            self._ea_by_fid[fid] = ea

    def _fid(self, ea: int) -> str:
        return self._fid_by_ea.get(ea, f"F?")

    @staticmethod
    def _fmt_slice(off: Optional[int], length: Optional[int]) -> str:
        if off is None and length is None:
            return ""
        if off is None and length is not None:
            return f"@[?:0x{length:X}]"
        if off is not None and length is None:
            return f"@[0x{off:X}:?]"
        return f"@[0x{off:X}:0x{length:X}]"

    @staticmethod
    def _fmt_meta(meta: Dict[str, object]) -> str:
        if not meta:
            return ""
        parts = []
        for k, v in meta.items():
            if isinstance(v, int):
                if k in ("cs",):
                    parts.append(f"{k}=0x{v:X}")
                else:
                    parts.append(f"{k}={v}")
            else:
                parts.append(f"{k}={v}")
        return " {" + ",".join(parts) + "}"

    def _fmt_node_L(self, fid: str, lidx: int, off: Optional[int], length: Optional[int],
                    mode: str, cast: Optional[str], name: str = "", meta: Optional[Dict[str, object]] = None) -> str:
        s = f"L({fid},{lidx}){self._fmt_slice(off, length)}{mode}"
        if cast:
            s += f":({cast})"
        if meta:
            s += self._fmt_meta(meta)
        return s

    def _fmt_node_P(self, fid: str, pidx: int, off: Optional[int], length: Optional[int],
                    mode: str, cast: Optional[str], meta: Optional[Dict[str, object]] = None) -> str:
        s = f"P({fid},{pidx}){self._fmt_slice(off, length)}{mode}"
        if cast:
            s += f":({cast})"
        if meta:
            s += self._fmt_meta(meta)
        return s

    def _fmt_node_A(self, fid: str, arg_index: int, meta: Optional[Dict[str, object]] = None) -> str:
        s = f"A({fid},{arg_index})"
        if meta:
            s += self._fmt_meta(meta)
        return s

    def _fmt_node_G(self, ea: int, off: Optional[int], length: Optional[int], meta: Optional[Dict[str, object]] = None) -> str:
        s = f"G(0x{ea:X}){self._fmt_slice(off, length)}"
        if meta:
            s += self._fmt_meta(meta)
        return s

    def _fmt_node_F(self, fid: str, meta: Optional[Dict[str, object]] = None) -> str:
        s = f"F({fid})"
        if meta:
            s += self._fmt_meta(meta)
        return s

    def _dict_header(self, restrict_eas: Optional[Set[int]] = None) -> str:
        eas = sorted((restrict_eas or set(self.summaries.keys())))
        parts = []
        for ea in eas:
            fid = self._fid(ea)
            name = self._name_by_ea.get(ea, "")
            if name:
                parts.append(f"{fid}=0x{ea:X},{name}")
            else:
                parts.append(f"{fid}=0x{ea:X}")
        return "D:" + ";".join(parts)

    def _build_param_forward(self) -> Dict[Tuple[int, int], List[Tuple[int, int, Dict[str, object]]]]:
        fwd: Dict[Tuple[int, int], List[Tuple[int, int, Dict[str, object]]]] = {}
        for fea, fs in self.summaries.items():
            for au in fs.arguses:
                if au.base_kind == "P" and au.callee_ea is not None:
                    key = (fea, au.base_id)
                    lst = fwd.setdefault(key, [])
                    meta = {}
                    if au.off is not None:
                        meta["off"] = au.off
                    if au.length is not None:
                        meta["len"] = au.length
                    if au.mode:
                        meta["mode"] = au.mode
                    if au.cs_ea:
                        meta["cs"] = au.cs_ea
                    if au.conf:
                        meta["conf"] = au.conf
                    lst.append((au.callee_ea, au.arg_index, meta))
        return fwd

    def _build_incoming_map(self) -> Dict[Tuple[int, int], List[Dict[str, object]]]:
        inc: Dict[Tuple[int, int], List[Dict[str, object]]] = {}
        for caller_ea, fs in self.summaries.items():
            for au in fs.arguses:
                if au.callee_ea is None:
                    continue
                key = (au.callee_ea, au.arg_index)
                lst = inc.setdefault(key, [])
                lst.append({
                    "caller_ea": caller_ea,
                    "origin_kind": au.base_kind,
                    "origin_id": au.base_id,
                    "origin_name": au.base_name,
                    "off": au.off,
                    "length": au.length,
                    "mode": au.mode,
                    "cast": au.cast,
                    "conf": au.conf,
                    "cs_ea": au.cs_ea,
                })
        return inc

    def emit_ptn(self, start_eas: Set[int], callee_depth: int, restrict_eas: Optional[Set[int]] = None) -> str:
        lines: List[str] = []
        target_set = restrict_eas or start_eas or set(self.summaries.keys())
        lines.append("#PTN v0")
        lines.append(self._dict_header(target_set))

        param_forward = self._build_param_forward()
        incoming_map = self._build_incoming_map()
        visited_line_keys: Set[str] = set()

        def add_line(s: str) -> None:
            if s not in visited_line_keys:
                visited_line_keys.add(s)
                lines.append(s)

        for fea in sorted(target_set):
            fs = self.summaries.get(fea)
            if not fs:
                continue
            fid = self._fid(fea)
            add_line(f"D:{fid}=0x{fea:X},{fs.func_name}")
            for al in fs.aliases:
                dst = f"{al.dst_kind}({fid},{al.dst_id})"
                src = self._fmt_origin(al.src_kind, fea, al.src_id, al.src_name, al.off, al.length, al.mode, al.cast, {"conf": al.conf})
                add_line(f"A:{dst}:={src}")

        for (callee_ea, pidx), entries in incoming_map.items():
            if callee_ea not in target_set:
                continue
            callee_fid = self._fid(callee_ea)
            for ent in entries:
                caller_ea = ent["caller_ea"]
                origin = self._fmt_origin(ent["origin_kind"], caller_ea, ent["origin_id"], ent["origin_name"],
                                          ent["off"], ent["length"], ent["mode"], ent["cast"],
                                          {"conf": ent["conf"], "cs": ent["cs_ea"], "caller": self._fid(caller_ea)})
                dst = self._fmt_node_P(callee_fid, pidx, None, None, "", None, None)
                add_line(f"I:{origin} -> {dst}")

        by_func: Dict[int, List[ArgUse]] = {}
        for fea, fs in self.summaries.items():
            by_func.setdefault(fea, []).extend(fs.arguses)

        for fea in sorted(target_set):
            uses = by_func.get(fea, [])
            for au in uses:
                if au.callee_ea is None:
                    continue
                origin = self._fmt_origin(au.base_kind, fea, au.base_id, au.base_name, au.off, au.length, au.mode, au.cast,
                                          {"conf": au.conf, "cs": au.cs_ea} if au.cs_ea else {"conf": au.conf})
                fid_to = self._fid(au.callee_ea)
                add_line(f"E:{origin} -> {self._fmt_node_A(fid_to, au.arg_index)}")

                frontier: List[Tuple[int, int, int]] = []
                if au.base_kind in ("L", "P"):
                    frontier.append((au.callee_ea, au.arg_index, 1))
                depth_seen: Set[Tuple[int, int]] = set()
                while frontier:
                    cur_fea, pidx, depth = frontier.pop()
                    if depth >= callee_depth:
                        continue
                    key = (cur_fea, pidx)
                    if key in depth_seen:
                        continue
                    depth_seen.add(key)
                    for (next_callee_ea, next_argk, meta) in param_forward.get(key, []):
                        fid_mid = self._fid(cur_fea)
                        fid_next = self._fid(next_callee_ea)
                        add_line(f"E:{origin} -> A({fid_mid},{pidx}) -> A({fid_next},{next_argk})")
                        frontier.append((next_callee_ea, next_argk, depth + 1))

        writers: Dict[int, Set[int]] = {}
        readers: Dict[int, Set[int]] = {}
        for fea, fs in self.summaries.items():
            for ga in fs.globals:
                if ga.kind == "W":
                    writers.setdefault(ga.ea, set()).add(fea)
                elif ga.kind == "R":
                    readers.setdefault(ga.ea, set()).add(fea)
        for gea, ws in writers.items():
            rs = readers.get(gea, set())
            for fw in sorted(ws):
                for fr in sorted(rs):
                    if fw in target_set or fr in target_set:
                        lines.append("G:" + self._fmt_node_F(self._fid(fw)) + " -> " +
                                     self._fmt_node_G(gea, None, None, {}) + " -> " +
                                     self._fmt_node_F(self._fid(fr)))

        return "\
".join(lines) + "\
"

    def _fmt_origin(self, kind: str, fea: int, idx: int, name: str,
                    off: Optional[int], length: Optional[int], mode: str, cast: Optional[str],
                    meta: Dict[str, object]) -> str:
        fid = self._fid(fea)
        m = dict(meta)
        if name:
            m["name"] = name
        if kind == "L":
            return self._fmt_node_L(fid, max(idx, -1), off, length, mode, cast, name, m)
        if kind == "P":
            return self._fmt_node_P(fid, max(idx, -1), off, length, mode, cast, m)
        if kind == "G":
            return self._fmt_node_G(idx, off, length, m)
        return "U" + self._fmt_meta(m)

    def per_function_annotations(self, callee_depth: int) -> Dict[int, str]:
        param_forward = self._build_param_forward()
        incoming_map = self._build_incoming_map()
        out: Dict[int, str] = {}
        for fea, fs in self.summaries.items():
            fid = self._fid(fea)
            lines: List[str] = []
            lines.append(f"// @PTN D:{fid}=0x{fea:X},{fs.func_name}")
            for al in fs.aliases:
                dst = f"{al.dst_kind}({fid},{al.dst_id})"
                src = self._fmt_origin(al.src_kind, fea, al.src_id, al.src_name, al.off, al.length, al.mode, al.cast, {"conf": al.conf})
                lines.append(f"// @PTN A:{dst}:={src}")
            for (callee_ea, pidx), entries in incoming_map.items():
                if callee_ea != fea:
                    continue
                for ent in entries:
                    caller_ea = ent["caller_ea"]
                    origin = self._fmt_origin(ent["origin_kind"], caller_ea, ent["origin_id"], ent["origin_name"],
                                              ent["off"], ent["length"], ent["mode"], ent["cast"],
                                              {"conf": ent["conf"], "cs": ent["cs_ea"], "caller": self._fid(caller_ea)})
                    dst = self._fmt_node_P(fid, pidx, None, None, "", None, None)
                    lines.append(f"// @PTN I:{origin} -> {dst}")
            for au in fs.arguses:
                if au.callee_ea is None:
                    continue
                origin = self._fmt_origin(au.base_kind, fea, au.base_id, au.base_name, au.off, au.length, au.mode, au.cast,
                                          {"conf": au.conf, "cs": au.cs_ea} if au.cs_ea else {"conf": au.conf})
                lines.append(f"// @PTN E:{origin} -> {self._fmt_node_A(self._fid(au.callee_ea), au.arg_index)}")
                if callee_depth > 1 and au.base_kind in ("L", "P"):
                    key = (au.callee_ea, au.arg_index)
                    for (nc_ea, narg, meta) in param_forward.get(key, []):
                        lines.append(f"// @PTN E:{origin} -> A({self._fid(au.callee_ea)},{au.arg_index}) -> A({self._fid(nc_ea)},{narg})")
            for ga in fs.globals:
                if ga.kind == "W":
                    lines.append(f"// @PTN G:{self._fmt_node_F(fid)} -> {self._fmt_node_G(ga.ea, ga.off, ga.length)}")
                elif ga.kind == "R":
                    lines.append(f"// @PTN G:{self._fmt_node_G(ga.ea, ga.off, ga.length)} -> {self._fmt_node_F(fid)}")
            out[fea] = "\
".join(lines) + ("\
" if lines else "")
        return out

    def per_instruction_hints(self, callee_depth: int = 1) -> Dict[int, Dict[int, List[str]]]:
        hints: Dict[int, Dict[int, List[str]]] = {}
        param_forward = self._build_param_forward()
        for fea, fs in self.summaries.items():
            for au in fs.arguses:
                if not au.cs_ea or au.callee_ea is None:
                    continue
                origin = self._fmt_origin(au.base_kind, fea, au.base_id, au.base_name, au.off, au.length, au.mode, au.cast,
                                          {"conf": au.conf})
                fid_to = self._fid(au.callee_ea)
                line0 = f"@PTN E:{origin} -> {self._fmt_node_A(fid_to, au.arg_index)}"
                hints.setdefault(fea, {}).setdefault(au.cs_ea, []).append(line0)

                if callee_depth > 1 and au.base_kind in ("L", "P"):
                    frontier: List[Tuple[int, int, int]] = [(au.callee_ea, au.arg_index, 1)]
                    depth_seen: Set[Tuple[int, int]] = set()
                    while frontier:
                        cur_fea, pidx, depth = frontier.pop()
                        if depth >= callee_depth:
                            continue
                        key = (cur_fea, pidx)
                        if key in depth_seen:
                            continue
                        depth_seen.add(key)
                        for (next_callee_ea, next_argk, meta) in param_forward.get(key, []):
                            fid_mid = self._fid(cur_fea)
                            fid_next = self._fid(next_callee_ea)
                            hints.setdefault(fea, {}).setdefault(au.cs_ea, []).append(
                                f"@PTN E:{origin} -> A({fid_mid},{pidx}) -> A({fid_next},{next_argk})"
                            )
                            frontier.append((next_callee_ea, next_argk, depth + 1))
        for fea, fs in self.summaries.items():
            fid = self._fid(fea)
            for ga in fs.globals:
                if not ga.cs_ea:
                    continue
                if ga.kind == "W":
                    line = f"@PTN G:{self._fmt_node_F(fid)} -> {self._fmt_node_G(ga.ea, ga.off, ga.length)}"
                else:
                    line = f"@PTN G:{self._fmt_node_G(ga.ea, ga.off, ga.length)} -> {self._fmt_node_F(fid)}"
                hints.setdefault(fea, {}).setdefault(ga.cs_ea, []).append(line)
        return hints

    def emit_ptn_json(self, start_eas: Set[int], callee_depth: int, restrict_eas: Optional[Set[int]] = None) -> str:
        target_set = sorted(list(restrict_eas or start_eas or set(self.summaries.keys())))
        param_forward = self._build_param_forward()
        incoming_map = self._build_incoming_map()

        obj: Dict[str, object] = {
            "version": "0",
            "dict": [{"fid": self._fid(ea), "ea": f"0x{ea:X}", "name": self._name_by_ea.get(ea, "")} for ea in target_set],
            "aliases": [],
            "calls": [],
            "globals": [],
            "inbound": []
        }

        for fea in target_set:
            fs = self.summaries.get(fea)
            if not fs:
                continue
            fid = self._fid(fea)
            for al in fs.aliases:
                obj["aliases"].append({
                    "func": {"fid": fid, "ea": f"0x{fea:X}"},
                    "dst": {"kind": al.dst_kind, "id": al.dst_id, "name": al.dst_name},
                    "src": {"kind": al.src_kind, "id": al.src_id, "name": al.src_name,
                            "off": al.off, "len": al.length, "mode": al.mode, "cast": al.cast},
                    "conf": al.conf
                })

        for fea in target_set:
            fs = self.summaries.get(fea)
            if not fs:
                continue
            for au in fs.arguses:
                if au.callee_ea is None:
                    continue
                obj["calls"].append({
                    "caller": {"fid": self._fid(fea), "ea": f"0x{fea:X}"},
                    "cs_ea": f"0x{au.cs_ea:X}" if au.cs_ea else None,
                    "origin": {"kind": au.base_kind, "id": au.base_id, "name": au.base_name,
                               "off": au.off, "len": au.length, "mode": au.mode, "cast": au.cast, "conf": au.conf},
                    "callee": {"fid": self._fid(au.callee_ea), "ea": f"0x{au.callee_ea:X}"},
                    "arg_index": au.arg_index
                })

        for fea in target_set:
            fs = self.summaries.get(fea)
            if not fs:
                continue
            for ga in fs.globals:
                obj["globals"].append({
                    "func": {"fid": self._fid(fea), "ea": f"0x{fea:X}"},
                    "op": ga.kind,
                    "global_ea": f"0x{ga.ea:X}",
                    "off": ga.off, "len": ga.length,
                    "cs_ea": f"0x{ga.cs_ea:X}" if ga.cs_ea else None
                })

        for (callee_ea, pidx), entries in incoming_map.items():
            if callee_ea not in target_set:
                continue
            for ent in entries:
                obj["inbound"].append({
                    "to": {"fid": self._fid(callee_ea), "ea": f"0x{callee_ea:X}", "param": pidx},
                    "from": {"fid": self._fid(ent["caller_ea"]), "ea": f"0x{ent['caller_ea']:X}"},
                    "origin": {"kind": ent["origin_kind"], "id": ent["origin_id"], "name": ent["origin_name"],
                               "off": ent["off"], "len": ent["length"], "mode": ent["mode"], "cast": ent["cast"], "conf": ent["conf"]},
                    "cs_ea": f"0x{ent['cs_ea']:X}" if ent["cs_ea"] else None
                })

        return json.dumps(obj, indent=2) + "\
"

```

`semray.py`:

```py
# -*- coding: utf-8 -*-
"""
summary: High-performance, AI-driven semantic analysis for the IDA Pro decompiler.

description:
  This plugin, SemRay, integrates with Google's Generative AI API (Gemini) to
  provide suggestions for function names, comments, and local variable renames.

  This final, merged version combines the best features of previous implementations:
  • ROBUSTNESS: Gracefully falls back to basic IDA API calls if the 'codedump'
    plugin is not available, ensuring functionality in all environments.
  • MODULARITY: A clean, refactored architecture for better readability and maintenance.
  • NO CODE DUPLICATION: Adheres to the DRY principle by importing shared logic
    from 'codedump' when available, rather than duplicating it.
  • ENHANCED CONTEXT: When 'codedump' is present, it leverages its advanced context
    discovery (virtual calls, jump tables, detailed xref reasons) and optional PTN
    provenance annotations for richer semantic input to the LLM.
  • FLEXIBILITY: Allows the user to select either Hex-Rays decompilation or raw
    disassembly as the content for analysis.
  • USABILITY: Can be invoked from context menus in both the Pseudocode and
    Disassembly views, with clear dialogs for user input.

  Requires:
  - IDA Pro 7.6+ (with Python 3 and PyQt5 support)
  - Hex-Rays Decompiler (for decompilation mode and PTN analysis)
  - google-genai library (`pip install google-genai`)
  - pydantic library (`pip install pydantic`)
  - A Google AI API Key set in the environment variable `GOOGLE_API_KEY`.
"""

# --- Imports ---
import ida_kernwin
import ida_hexrays
import ida_funcs
import ida_name
import ida_bytes
import idaapi
import idautils
import idc
import ida_xref
import ida_typeinf
import ida_nalt
import ida_ua
import ida_idp
import ida_search

import threading
import json
import textwrap
import os
import sys
import traceback
import time
import re
from collections import deque, defaultdict
from functools import partial
from typing import Dict, List, Set, Optional, Tuple

# Ensure sibling plugin directories are importable (allow importing 'codedump.*')
try:
    _THIS_DIR = os.path.dirname(__file__)
    _PARENT = os.path.abspath(os.path.join(_THIS_DIR, ".."))
    if _PARENT not in sys.path:
        sys.path.append(_PARENT)
except Exception:
    pass

# --- Optional CodeDumper integration imports ---
CODEDUMP_AVAILABLE = False
try:
    from codedump import (
        find_callers_recursive as cd_find_callers_recursive,
        find_callees_recursive as cd_find_callees_recursive,
        decompile_functions_main as cd_decompile_functions_main,
        disassemble_functions_main as cd_disassemble_functions_main,
        find_vtables as cd_find_vtables,
    )
    from micro_analyzer import analyze_functions_ctree as cd_analyze_functions_ctree
    from ptn_utils import PTNEmitter as CD_PTNEmitter

    CODEDUMP_AVAILABLE = True
    print("SemRay DEBUG: CodeDumper integration available.")
except Exception as _e:
    CODEDUMP_AVAILABLE = False
    print(f"SemRay WARNING: CodeDumper not available ({_e}). Falling back to internal context logic.")

# Third-party libraries
try:
    from PyQt5 import QtCore, QtGui, QtWidgets
    from PyQt5.QtWidgets import (QApplication, QMainWindow, QWidget, QScrollArea,
                                 QLabel, QVBoxLayout, QHBoxLayout, QGridLayout,
                                 QGroupBox, QCheckBox, QPushButton, QFrame,
                                 QTabWidget)

    print("SemRay DEBUG: PyQt5 imported successfully.")
except ImportError:
    print("SemRay Error: PyQt5 not found. Please ensure it's installed in IDA's Python environment.")

try:
    from pydantic import BaseModel, Field

    print("SemRay DEBUG: pydantic imported successfully.")
except ImportError:
    print("SemRay Error: pydantic not found. Please install it: pip install pydantic")

try:
    from google import genai
    from google.genai import types
    from google.genai import errors as google_genai_errors

    print("SemRay DEBUG: google-genai imported successfully.")
except ImportError:
    print("SemRay Error: google-genai not found. Please install it: pip install google-genai")

# --- Configuration ---
PLUGIN_NAME = "SemRay (Google AI Semantic Analysis)"
ACTION_ID_CTX_PREFIX_MULTI = "semray:googleai:ctx:multi:"
ACTION_ID_CTX_PREFIX_SINGLE = "semray:googleai:ctx:single:"
ACTION_ID_CTX_PREFIX_DEPTH = "semray:googleai:ctx:depth:"
MENU_PATH_CTX = "SemRay Analysis/"

# Google AI Configuration
GOOGLE_AI_API_KEY = os.environ.get("GOOGLE_API_KEY")
DEFAULT_GEMINI_MODEL = "gemini-flash-latest"
MODELS_TO_REGISTER = [DEFAULT_GEMINI_MODEL]

# Safety settings
try:
    DEFAULT_SAFETY_SETTINGS = [
        types.SafetySetting(category='HARM_CATEGORY_HATE_SPEECH', threshold='BLOCK_NONE'),
        types.SafetySetting(category='HARM_CATEGORY_DANGEROUS_CONTENT', threshold='BLOCK_NONE'),
        types.SafetySetting(category='HARM_CATEGORY_HARASSMENT', threshold='BLOCK_NONE'),
        types.SafetySetting(category='HARM_CATEGORY_SEXUALLY_EXPLICIT', threshold='BLOCK_NONE'),
        types.SafetySetting(category='HARM_CATEGORY_CIVIC_INTEGRITY', threshold='BLOCK_NONE'),
    ]
    print("SemRay DEBUG: Default safety settings configured.")
except Exception:
    DEFAULT_SAFETY_SETTINGS = []

# Default depths
DEFAULT_CONTEXT_CALLER_DEPTH = 1
DEFAULT_CONTEXT_CALLEE_DEPTH = 1
DEFAULT_ANALYSIS_DEPTH = 1

# Content mode for LLM
CONTENT_MODE_DECOMP = "decomp"
CONTENT_MODE_ASM = "asm"
DEFAULT_CONTENT_MODE = CONTENT_MODE_DECOMP

# Allowed xref types (used with CodeDumper)
DEFAULT_XREF_TYPES = {'direct_call', 'indirect_call', 'data_ref', 'immediate_ref', 'tail_call_push_ret', 'virtual_call',
                      'jump_table'}

# --- Concurrency Control ---
g_analysis_in_progress = set()
g_multi_analysis_active = False
g_analysis_lock = threading.Lock()
print("SemRay DEBUG: Concurrency control initialized.")

# -----------------------------------------------------------------------------
# 1.  DATA MODELS
# -----------------------------------------------------------------------------
_BAD_NAME_RE = re.compile(r"\\b(var\\d+|v\\d+|tmp|foo|bar|helper|unused)\\b", re.I)


def _lint_name(name: str) -> bool:
    return _BAD_NAME_RE.search(name) is None


class VariableRename(BaseModel):
    original_name: str = Field(..., description="The original variable/argument name as seen in pseudocode.")
    new_name: str = Field(..., description="The suggested descriptive name.")
    rename_reason: str = Field(..., description="Why this rename clarifies semantics.")
    rename_reason_findings: str = Field(..., description="Evidence or observations that justify the rename.")


class SingleFunctionAnalysis(BaseModel):
    original_function_name: str = Field(..., description="Exactly as in the '// === Function:' header.")
    function_name: str = Field(..., description="IDA‑style concise descriptive name.")
    comment: str = Field(..., description="Multi‑line C‑style block comment (without /* */).")
    variables: List[VariableRename] = Field(..., description="Suggested variable/argument renames for this function.")
    observations: List[dict] = Field(..., description="Notable observations influencing interpretation.")
    function_name_reason: str = Field(..., description="Rationale for the chosen function name.")
    function_name_reason_findings: str = Field(..., description="Evidence backing the chosen function name.")
    comment_reason: str = Field(..., description="Rationale for the comment block.")
    comment_reason_findings: str = Field(..., description="Evidence backing the comment block.")


class MultiFunctionAnalysisResult(BaseModel):
    function_analyses: List[SingleFunctionAnalysis]


# -----------------------------------------------------------------------------
# 2.  JSON SCHEMA
# -----------------------------------------------------------------------------
explicit_multi_function_analysis_schema: Dict = {
    "type": "object",
    "properties": {
        "function_analyses": {
            "type": "array",
            "description": "Per‑function analysis results.",
            "items": {
                "type": "object",
                "properties": {
                    "original_function_name": {"type": "string"},
                    "observations": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "properties": {
                                "observation": {"type": "string"},
                                "observation_impact": {"type": "string"},
                            },
                            "required": ["observation", "observation_impact"],
                        },
                    },
                    "function_name_reason": {"type": "string"},
                    "function_name_reason_findings": {"type": "string"},
                    "function_name": {"type": "string"},
                    "comment_reason": {"type": "string"},
                    "comment_reason_findings": {"type": "string"},
                    "comment": {"type": "string"},
                    "variables": {
                        "type": "array",
                        "items": {
                            "type": "object",
                            "properties": {
                                "rename_reason": {"type": "string"},
                                "rename_reason_findings": {"type": "string"},
                                "original_name": {"type": "string"},
                                "new_name": {"type": "string"},
                            },
                            "required": ["rename_reason", "rename_reason_findings", "original_name", "new_name"],
                        },
                    },
                },
                "required": [
                    "original_function_name", "observations", "function_name_reason",
                    "function_name_reason_findings", "function_name", "comment_reason",
                    "comment_reason_findings", "comment", "variables"
                ],
            },
        }
    },
    "required": ["function_analyses"],
}


# -----------------------------------------------------------------------------
# 3.  Helper utilities
# -----------------------------------------------------------------------------
def get_function_prototype(ea: int) -> Optional[str]:
    try:
        return idc.get_type(ea) or ida_typeinf.idc_get_type(ea)
    except Exception:
        return None


def _gather_literals_main(ea: int, out: list) -> int:
    func = ida_funcs.get_func(ea)
    if not func:
        out.append([])
        return 1
    literals: list[str] = []
    it = func.start_ea
    while it < func.end_ea:
        flags = ida_bytes.get_full_flags(it)
        if ida_bytes.is_strlit(flags):
            s = ida_bytes.get_strlit_contents(it, -1, ida_nalt.get_str_type(it))
            if s:
                head = s[:40].decode("utf-8", "ignore") if isinstance(s, bytes) else str(s)[:40]
                literals.append(f'string:"{head}"')
        it = ida_bytes.next_head(it, func.end_ea)
    insn = ida_ua.insn_t()
    it = func.start_ea
    while it < func.end_ea:
        ilen = ida_ua.decode_insn(insn, it)
        if ilen == 0:
            it = idc.next_head(it, func.end_ea)
            continue
        for op in insn.ops:
            if op.type == idaapi.o_imm and op.value > 0xFFFF:
                literals.append(f"const:0x{op.value:X}")
        it += ilen
    out.append(literals)
    return 1


def gather_literals(ea: int) -> List[str]:
    holder: list = []
    ida_kernwin.execute_sync(lambda: _gather_literals_main(ea, holder), ida_kernwin.MFF_READ)
    return holder[0] if holder else []


# -----------------------------------------------------------------------------
# 4.  Context Builder (CodeDumper-aware with fallbacks)
# -----------------------------------------------------------------------------
def _format_asm_block(func_ea: int, func_name: str, items: List[Tuple[str, int, str]]) -> str:
    lines_out = [f"// --- ASM Function: {func_name} (0x{func_ea:X}) ---"]
    for kind, ea, text in items:
        lines_out.append(text if kind == "label" else f"0x{ea:X}: {text}")
    lines_out.append(f"// --- End ASM Function: {func_name} (0x{func_ea:X}) ---")
    return "\n".join(lines_out)


def _edges_to_strings(edges: Dict[int, Dict[int, Set[str]]], name_map: Dict[int, str]) -> List[str]:
    lines = []
    for src in sorted(edges.keys()):
        dsts = edges.get(src)
        if not dsts: continue
        parts = [f"{name_map.get(dst, f'sub_{dst:X}')} [{'/'.join(sorted(reasons))}]"
                 for dst, reasons in sorted(dsts.items())]
        if parts:
            lines.append(f"{name_map.get(src, f'sub_{src:X}')} -> {', '.join(parts)}")
    return lines


def _fallback_decompile_functions_main(eas_to_decompile: Set[int]) -> Dict[int, str]:
    results: Dict[int, str] = {}
    if not ida_hexrays.init_hexrays_plugin():
        return {ea: f"// Decompilation FAILED - Hex-Rays unavailable" for ea in eas_to_decompile}
    for func_ea in sorted(list(eas_to_decompile)):
        func_name = ida_name.get_name(func_ea) or f"sub_{func_ea:X}"
        try:
            cfunc = ida_hexrays.decompile(func_ea)
            results[func_ea] = str(cfunc) if cfunc else f"// Decompilation FAILED for {func_name}"
        except ida_hexrays.DecompilationFailure as e:
            results[func_ea] = f"// Decompilation ERROR for {func_name}: {e}"
    return results


def build_context_material(start_eas: Set[int],
                           caller_depth: int,
                           callee_depth: int,
                           content_mode: str) -> Tuple[Dict[int, str],
Dict[int, str],
Dict[int, Dict[int, Set[str]]],
Dict[int, str]]:
    """Must run in the IDA main thread."""
    print(f"SemRay DEBUG: Building context (callers={caller_depth}, callees={callee_depth}, mode={content_mode})")
    all_nodes: Set[int] = set(start_eas)
    edges: Dict[int, Dict[int, Set[str]]] = defaultdict(lambda: defaultdict(set))

    # --- Collect Callers ---
    if caller_depth > 0:
        visited_callers: Set[int] = set()
        if CODEDUMP_AVAILABLE:
            for ea in start_eas:
                all_nodes.update(cd_find_callers_recursive(ea, 1, caller_depth, visited_callers, edges=edges,
                                                           allowed_types=DEFAULT_XREF_TYPES))
        else:  # Fallback
            q = deque([(ea, 0) for ea in start_eas])
            visited = set(start_eas)
            while q:
                cur, d = q.popleft()
                if d >= caller_depth: continue
                ref = ida_xref.get_first_cref_to(cur)
                while ref != idaapi.BADADDR:
                    f = ida_funcs.get_func(ref)
                    if f and f.start_ea not in visited:
                        all_nodes.add(f.start_ea)
                        edges[f.start_ea][cur].add('direct_call')
                        visited.add(f.start_ea)
                        q.append((f.start_ea, d + 1))
                    ref = ida_xref.get_next_cref_to(cur, ref)

    # --- Collect Callees/Refs ---
    if callee_depth > 0:
        visited_callees: Set[int] = set()
        if CODEDUMP_AVAILABLE:
            vtables = cd_find_vtables()
            for ea in start_eas:
                all_nodes.update(
                    cd_find_callees_recursive(ea, 1, callee_depth, visited_callees, edges=edges, vtables=vtables,
                                              allowed_types=DEFAULT_XREF_TYPES))
        else:  # Fallback
            q = deque([(ea, 0) for ea in start_eas])
            visited = set(start_eas)
            while q:
                cur, d = q.popleft()
                if d >= callee_depth: continue
                f = ida_funcs.get_func(cur)
                if not f: continue
                for item_ea in idautils.FuncItems(cur):
                    for ref_ea in idautils.CodeRefsFrom(item_ea, 1):
                        ref_f = ida_funcs.get_func(ref_ea)
                        if ref_f and ref_f.start_ea not in visited:
                            all_nodes.add(ref_f.start_ea)
                            edges[cur][ref_f.start_ea].add('direct_call')
                            visited.add(ref_f.start_ea)
                            q.append((ref_f.start_ea, d + 1))

    # --- Name Map ---
    name_map = {ea: (ida_funcs.get_func_name(ea) or f"sub_{ea:X}") for ea in all_nodes}

    # --- Materialize Code Blocks ---
    codes_by_ea: Dict[int, str] = {}
    if content_mode == CONTENT_MODE_ASM:
        if CODEDUMP_AVAILABLE:
            asm_dict = cd_disassemble_functions_main(all_nodes)
        else:  # Fallback
            asm_dict = {}
            for fea in all_nodes:
                items = [("label", fea, f"{name_map[fea]}:")]
                items.extend(("inst", i_ea, idc.GetDisasm(i_ea) or "") for i_ea in idautils.FuncItems(fea))
                asm_dict[fea] = items
        for fea, items in asm_dict.items():
            codes_by_ea[fea] = _format_asm_block(fea, name_map[fea], items)
    else:  # Decompilation
        if CODEDUMP_AVAILABLE:
            codes_by_ea = cd_decompile_functions_main(all_nodes)
        else:  # Fallback
            codes_by_ea = _fallback_decompile_functions_main(all_nodes)

    # --- PTN Annotations (only if CodeDumper is available) ---
    ptn_ann: Dict[int, str] = {}
    if CODEDUMP_AVAILABLE and ida_hexrays.init_hexrays_plugin():
        try:
            fsums = cd_analyze_functions_ctree(all_nodes)
            emitter = CD_PTNEmitter(fsums)
            ptn_ann = emitter.per_function_annotations(max(1, callee_depth))
        except Exception as e:
            print(f"SemRay WARNING: PTN analysis failed: {e}")

    print(f"SemRay DEBUG: Context built. Nodes={len(all_nodes)}, Codes={len(codes_by_ea)}")
    return codes_by_ea, name_map, edges, ptn_ann


# -----------------------------------------------------------------------------
# 5.  Main async_call
# -----------------------------------------------------------------------------
def async_call(
        start_eas: Set[int],
        context_caller_depth: int,
        context_callee_depth: int,
        model_name: str,
        analysis_mode: str,
        analysis_depth: int = 0,
        extra_context: Optional[str] = None,
        content_mode: str = DEFAULT_CONTENT_MODE,
):
    if not start_eas: return
    primary_ea = min(start_eas)

    # Phase 1: Build context (MAIN THREAD)
    mat_holder: list = [None]

    def _collect_ctx_material(holder):
        ida_kernwin.show_wait_box(
            f"Collecting context (Callers={context_caller_depth}, Callees={context_callee_depth})...")
        try:
            holder.append(build_context_material(start_eas, context_caller_depth, context_callee_depth, content_mode))
            return 1
        finally:
            ida_kernwin.hide_wait_box()

    if ida_kernwin.execute_sync(lambda: _collect_ctx_material(mat_holder), ida_kernwin.MFF_READ) != 1 or not mat_holder[
        1]:
        print("SemRay Error: failed to build context.")
        return
    all_codes, ea_to_name, edges, ptn_ann = mat_holder[1]

    # Phase 2: Determine analysis targets
    target_analysis_eas: Set[int]
    if analysis_mode == 'current':
        target_analysis_eas = start_eas.intersection(all_codes.keys())
    elif analysis_mode == 'all':
        target_analysis_eas = set(all_codes.keys())
    elif analysis_mode == 'depth_limited':
        target_container: list = [None]
        ida_kernwin.execute_sync(
            lambda: target_container.append(find_functions_within_depth(start_eas, analysis_depth)),
            ida_kernwin.MFF_READ)
        target_analysis_eas = (target_container[1] or start_eas).intersection(all_codes.keys())
    else:
        target_analysis_eas = start_eas.intersection(all_codes.keys())
    if not target_analysis_eas:
        print("SemRay Error: No target functions after filtering.")
        return

    # Phase 3: Build prompt
    code_blocks = []
    for ea in sorted(all_codes):
        header = f"// === Function: {ea_to_name.get(ea, f'sub_{ea:X}')} (0x{ea:X}) ==="
        proto = get_function_prototype(ea)
        proto_hdr = f"// prototype: {proto}" if proto and content_mode == CONTENT_MODE_DECOMP else ""
        body = all_codes[ea]
        code_blocks.append("\n".join(filter(None, [header, proto_hdr, body])))

    call_edges_lines = _edges_to_strings(edges, ea_to_name)
    semantic_tags = [f"{ea_to_name[ea]} tags: {', '.join(gather_literals(ea))}" for ea in start_eas if
                     ea in ea_to_name and gather_literals(ea)]
    ptn_lines = [ptn_ann[ea] for ea in sorted(ptn_ann.keys()) if ea in target_analysis_eas]

    persona_block = f"You are an expert reverse engineer. The input is {content_mode} from IDA Pro."
    target_func_names = sorted([ea_to_name[ea] for ea in target_analysis_eas if ea in ea_to_name])
    scope_instr = (f"Analyze ONLY the following function(s): {', '.join(target_func_names)}. "
                   "Use other functions for background context only.") if analysis_mode != 'all' else "Analyze EVERY function provided."

    prompt_content = "\
\
".join(filter(None, [
        persona_block,
        "### NAMING CONTRACT\n- Encode role and domain (e.g., crc32_checksum).\n- Placeholders like `tmp`, `v5` are forbidden.",
        "Respond with pure JSON adhering to the supplied schema. Field `original_function_name` must match the header exactly.",
        scope_instr,
        "### CALLGRAPH\
" + ("\n".join(call_edges_lines) if call_edges_lines else "(none)"),
        "### PTN SEMANTICS (for analyzed targets)\
" + ("\n".join(ptn_lines) if ptn_lines else "(none)"),
        "### SEMANTICS (Primary Functions)\
" + ("\n".join(semantic_tags) if semantic_tags else "(none)"),
        "### START CODE CONTEXT\
" + "\
\
/* --- */\
\
".join(code_blocks) + "\
### END CODE CONTEXT",
        "### SELF‑REVIEW (mandatory, ≤ 120 words)\nAfter the JSON, list any generic identifiers left and explain why."
    ]))

    # Phase 4: Query LLM
    ida_kernwin.execute_ui_requests([lambda: ida_kernwin.show_wait_box("HIDECANCEL\nQuerying LLM...")])
    result_holder, exc_holder = [None], [None]

    def _llm_worker():
        try:
            result_holder[0] = do_google_ai_analysis(prompt_content, model_name)
        except Exception as e:
            exc_holder[0] = e

    t = threading.Thread(target=_llm_worker)
    t.start()
    try:
        while t.is_alive():
            if ida_kernwin.user_cancelled(): break
            time.sleep(0.1)
        t.join()
    finally:
        ida_kernwin.execute_ui_requests([ida_kernwin.hide_wait_box])

    if ida_kernwin.user_cancelled() or exc_holder[0] or not result_holder[0]:
        if exc_holder[0]: print(f"SemRay Error: LLM call failed: {exc_holder[0]}")
        return

    # Phase 5: Map and lint results
    name_to_ea = {v: k for k, v in ea_to_name.items()}
    mapped = []
    for ana in result_holder[0]:
        oname = ana.get("original_function_name")
        if not oname or oname not in name_to_ea: continue
        ea = name_to_ea[oname]
        if ea not in target_analysis_eas: continue
        if not ana.get("function_name") or not _lint_name(ana["function_name"]): continue
        if any(not v.get("new_name") or not _lint_name(v["new_name"]) for v in ana.get("variables", [])): continue
        ana["function_ea"] = ea
        mapped.append(ana)

    # Phase 6: Update UI
    if mapped:
        ida_kernwin.execute_ui_requests([partial(do_show_ui, mapped, primary_ea)])
    else:
        ida_kernwin.warning("SemRay: No valid analysis results after filtering.")


# --- UI Widgets (unchanged logic) ---
class FunctionNameWidget(QWidget):
    accepted = True

    def __init__(self, function_name):
        super(FunctionNameWidget, self).__init__()
        layout = QHBoxLayout()
        self.checkbox = QCheckBox()
        self.checkbox.setCheckState(QtCore.Qt.Checked)
        self.checkbox.stateChanged.connect(lambda s: setattr(self, 'accepted', s == QtCore.Qt.Checked))
        self.name_label = QLabel(function_name)
        layout.addWidget(self.checkbox)
        layout.addWidget(self.name_label)
        group_box = QGroupBox("Suggested Function Name")
        group_box.setLayout(layout)
        main_layout = QVBoxLayout()
        main_layout.addWidget(group_box)
        self.setLayout(main_layout)


class CommentWidget(QWidget):
    accepted = True

    def __init__(self, comment):
        super(CommentWidget, self).__init__()
        layout = QHBoxLayout()
        self.checkbox = QCheckBox()
        self.checkbox.setCheckState(QtCore.Qt.Checked)
        self.checkbox.stateChanged.connect(lambda s: setattr(self, 'accepted', s == QtCore.Qt.Checked))
        self.comment_area = QLabel(comment)
        self.comment_area.setWordWrap(True)
        self.comment_area.setTextInteractionFlags(QtCore.Qt.TextSelectableByMouse)
        layout.addWidget(self.checkbox)
        layout.addWidget(self.comment_area)
        group_box = QGroupBox("Suggested Comment")
        group_box.setLayout(layout)
        main_layout = QVBoxLayout()
        main_layout.addWidget(group_box)
        self.setLayout(main_layout)


class VariableWidget(QWidget):
    def __init__(self, variables):
        super(VariableWidget, self).__init__()
        group_layout = QGridLayout()
        group_layout.setColumnStretch(1, 1)
        group_layout.setColumnStretch(3, 1)
        self.checkboxes = []
        self.variable_data = variables
        for i, var_data in enumerate(variables):
            row, col_base = i // 2, (i % 2) * 4
            checkbox = QCheckBox()
            checkbox.setCheckState(QtCore.Qt.Checked)
            self.checkboxes.append(checkbox)
            group_layout.addWidget(checkbox, row, col_base + 0)
            group_layout.addWidget(QLabel(var_data.get('original_name', 'N/A')), row, col_base + 1)
            group_layout.addWidget(QLabel("→"), row, col_base + 2, QtCore.Qt.AlignCenter)
            group_layout.addWidget(QLabel(var_data.get('new_name', 'N/A')), row, col_base + 3)
        group_box = QGroupBox("Suggested Variable Renames")
        group_box.setLayout(group_layout)
        main_layout = QVBoxLayout()
        main_layout.addWidget(group_box)
        self.setLayout(main_layout)

    def get_selected_variables(self):
        return [self.variable_data[i] for i, cb in enumerate(self.checkboxes) if cb.isChecked()]


class SemRayUIForm(ida_kernwin.PluginForm):
    def __init__(self, analysis_results_list, primary_trigger_ea):
        super(SemRayUIForm, self).__init__()
        self.analysis_results = analysis_results_list or []
        self.primary_trigger_ea = primary_trigger_ea
        self.widgets_by_ea = {}
        self.parent_widget = None

    def OnCreate(self, form):
        self.parent_widget = self.FormToPyQtWidget(form)
        self.PopulateForm()

    def PopulateForm(self):
        main_layout = QVBoxLayout()
        tab_widget = QTabWidget()
        sorted_results = sorted(self.analysis_results, key=lambda r: r.get('function_ea', 0))
        for result_data in sorted_results:
            func_ea = result_data.get('function_ea')
            if func_ea is None: continue
            func_name_ida = ida_funcs.get_func_name(func_ea) or f"sub_{func_ea:X}"
            tab_title = f"{func_name_ida} (0x{func_ea:X})"
            tab_content_widget = QWidget()
            tab_layout = QVBoxLayout(tab_content_widget)
            name_widget = FunctionNameWidget(result_data.get('function_name', 'N/A'))
            comment_widget = CommentWidget(result_data.get('comment', 'No comment.'))
            variable_widget = VariableWidget(result_data.get('variables', [])) if result_data.get('variables') else None
            tab_layout.addWidget(name_widget)
            tab_layout.addWidget(comment_widget)
            if variable_widget: tab_layout.addWidget(variable_widget)
            tab_layout.addStretch(1)
            scroll_area = QScrollArea()
            scroll_area.setWidgetResizable(True)
            scroll_area.setWidget(tab_content_widget)
            tab_widget.addTab(scroll_area, tab_title)
            self.widgets_by_ea[func_ea] = {'name': name_widget, 'comment': comment_widget, 'vars': variable_widget,
                                           'data': result_data}
        main_layout.addWidget(tab_widget)
        accept_button = QPushButton("Apply Selected")
        accept_button.clicked.connect(self.on_accept_clicked)
        cancel_button = QPushButton("Close")
        cancel_button.clicked.connect(self.Close)
        button_layout = QHBoxLayout()
        button_layout.addStretch()
        button_layout.addWidget(accept_button)
        button_layout.addWidget(cancel_button)
        main_layout.addLayout(button_layout)
        self.parent_widget.setLayout(main_layout)
        self.parent_widget.setMinimumSize(600, 500)

    def on_accept_clicked(self):
        changes_by_ea = {}
        for func_ea, widgets in self.widgets_by_ea.items():
            data = widgets['data']
            changes = {
                'function_name': data.get('function_name') if widgets['name'].accepted else None,
                'comment': data.get('comment') if widgets['comment'].accepted else None,
                'variables': widgets['vars'].get_selected_variables() if widgets['vars'] else []
            }
            if any(changes.values()):
                changes_by_ea[func_ea] = changes
        if changes_by_ea:
            ida_kernwin.execute_sync(lambda: self._perform_ida_updates(changes_by_ea), ida_kernwin.MFF_WRITE)
        self.Close(0)

    def _rename_lvar(self, func_ea: int, cfunc, lv, new_name: str) -> bool:
        if hasattr(cfunc, "set_lvar_name"):
            try:
                return cfunc.set_lvar_name(lv, new_name)
            except Exception:
                pass
        if hasattr(cfunc, "rename_lvar"):
            try:
                return cfunc.rename_lvar(lv, new_name)
            except Exception:
                pass
        try:
            return ida_hexrays.rename_lvar(func_ea, lv.name, new_name)
        except Exception:
            return False

    def _perform_ida_updates(self, changes_by_ea: Dict[int, dict]) -> bool:
        overall_success = True
        refresh_needed = False
        vdui_refreshed = set()

        for func_ea, changes in changes_by_ea.items():
            func_t = ida_funcs.get_func(func_ea)
            if changes.get('comment') and func_t:
                wrapped = "\n".join(textwrap.wrap(changes['comment'], width=80))
                if not ida_funcs.set_func_cmt(func_t, wrapped, False):
                    overall_success = False
                else:
                    refresh_needed = True
            if changes.get('function_name'):
                if not ida_name.set_name(func_ea, changes['function_name'], ida_name.SN_CHECK | ida_name.SN_FORCE):
                    overall_success = False
                else:
                    refresh_needed = True
            if changes.get('variables'):
                try:
                    cfunc = ida_hexrays.decompile(func_ea)
                    if cfunc:
                        lvars_map = {lv.name: lv for lv in cfunc.get_lvars()}
                        renamed_any = False
                        for item in changes['variables']:
                            if item['original_name'] in lvars_map:
                                if self._rename_lvar(func_ea, cfunc, lvars_map[item['original_name']],
                                                     item['new_name']):
                                    renamed_any = True
                        if renamed_any:
                            ida_hexrays.mark_cfunc_dirty(func_ea)
                            refresh_needed = True
                except ida_hexrays.DecompilationFailure:
                    overall_success = False

            if refresh_needed and func_ea not in vdui_refreshed:
                widget = ida_kernwin.find_widget(f"Pseudocode-A:{func_ea:X}")
                if widget:
                    vdui = ida_hexrays.get_widget_vdui(widget)
                    if vdui:
                        vdui.refresh_view(True)
                        vdui_refreshed.add(func_ea)

        if refresh_needed:
            ida_kernwin.refresh_idaview_anyway()

        return overall_success

    def OnClose(self, form):
        SemRayUI.open_forms.pop(self.primary_trigger_ea, None)


class SemRayUI:
    open_forms = {}

    def __init__(self, analysis_results_list, primary_trigger_ea):
        if primary_trigger_ea in self.open_forms:
            try:
                self.open_forms[primary_trigger_ea].GetWidget().activateWindow()
            except:  # Window may have been closed
                self.open_forms.pop(primary_trigger_ea, None)
                self.__init__(analysis_results_list, primary_trigger_ea)  # Recurse
            return
        form = SemRayUIForm(analysis_results_list, primary_trigger_ea)
        self.open_forms[primary_trigger_ea] = form
        func_name = ida_funcs.get_func_name(primary_trigger_ea) or f"sub_{primary_trigger_ea:X}"
        form.Show(f"SemRay Suggestions: {func_name} Context", ida_kernwin.WOPN_PERSIST | ida_kernwin.WOPN_RESTORE)


def do_show_ui(results_list, primary_trigger_ea):
    SemRayUI(results_list, primary_trigger_ea)


# --- Action Handlers & Plugin Class ---
def find_functions_within_depth(start_eas: Set[int], max_depth: int) -> Set[int]:
    if max_depth <= 0: return start_eas
    q, visited = deque([(ea, 0) for ea in start_eas]), set(start_eas)
    while q:
        ea, depth = q.popleft()
        if depth >= max_depth: continue
        # Callers
        for ref in idautils.CodeRefsTo(ea, 1):
            f = ida_funcs.get_func(ref)
            if f and f.start_ea not in visited:
                visited.add(f.start_ea)
                q.append((f.start_ea, depth + 1))
        # Callees
        f = ida_funcs.get_func(ea)
        if f:
            for item_ea in idautils.FuncItems(ea):
                for ref in idautils.CodeRefsFrom(item_ea, 1):
                    callee_f = ida_funcs.get_func(ref)
                    if callee_f and callee_f.start_ea not in visited:
                        visited.add(callee_f.start_ea)
                        q.append((callee_f.start_ea, depth + 1))
    return visited


def do_google_ai_analysis(code_prompt, model_name):
    if not GOOGLE_AI_API_KEY:
        ida_kernwin.warning("SemRay Error: Google AI API Key not configured.")
        return None
    try:
        client = genai.Client(api_key=GOOGLE_AI_API_KEY)
        generation_config = types.GenerateContentConfig(
            response_mime_type="application/json",
            response_schema=explicit_multi_function_analysis_schema,
            temperature=0.0,
            thinking_config=types.ThinkingConfig(thinking_budget=24576),
            safety_settings=DEFAULT_SAFETY_SETTINGS
        )
        response = client.models.generate_content(
            model=f'models/{model_name}', contents=code_prompt, config=generation_config
        )
        if not hasattr(response, 'text') or not response.text:
            ida_kernwin.warning(f"SemRay: Google AI response was empty or blocked.")
            return None
        raw_text = response.text
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', raw_text, re.DOTALL)
        json_text = json_match.group(1) if json_match else raw_text
        parsed = json.loads(json_text)
        return parsed.get("function_analyses", [])
    except Exception as e:
        ida_kernwin.warning(f"SemRay: AI interaction error: {e}")
        traceback.print_exc()
        return None


def single_analysis_task_wrapper(primary_func_ea, context_caller_depth, context_callee_depth, model, analysis_mode,
                                 analysis_depth, context, content_mode):
    try:
        async_call(
            start_eas={primary_func_ea}, context_caller_depth=context_caller_depth,
            context_callee_depth=context_callee_depth, model_name=model,
            analysis_mode=analysis_mode, analysis_depth=analysis_depth,
            extra_context=context, content_mode=content_mode
        )
    finally:
        with g_analysis_lock:
            g_analysis_in_progress.discard(primary_func_ea)


def multi_analysis_task_wrapper(start_eas, caller_depth, callee_depth, model, context, content_mode):
    global g_multi_analysis_active
    try:
        async_call(
            start_eas=start_eas, context_caller_depth=caller_depth,
            context_callee_depth=callee_depth, model_name=model,
            analysis_mode='all', analysis_depth=0,
            extra_context=context, content_mode=content_mode
        )
    finally:
        with g_analysis_lock:
            g_multi_analysis_active = False


class CtxActionHandler(ida_kernwin.action_handler_t):
    def __init__(self, model_name, analysis_mode='all'):
        self.model, self.analysis_mode = model_name, analysis_mode
        super().__init__()

    def activate(self, ctx):
        global g_analysis_in_progress, g_multi_analysis_active

        ea = idaapi.BADADDR
        try:
            if ctx.widget_type == ida_kernwin.BWN_DISASM:
                ea = ctx.cur_ea
            elif ctx.widget_type == ida_kernwin.BWN_PSEUDOCODE:
                vu = ida_hexrays.get_widget_vdui(ctx.widget)
                if vu and vu.cfunc:
                    ea = vu.cfunc.entry_ea
        except Exception:
            ea = ida_kernwin.get_screen_ea()

        f = ida_funcs.get_func(ea)
        if not f:
            ida_kernwin.warning("SemRay: Could not determine current function.")
            return 1

        primary_func_ea = f.start_ea
        with g_analysis_lock:
            if primary_func_ea in g_analysis_in_progress or g_multi_analysis_active:
                ida_kernwin.warning("SemRay: An analysis is already in progress.")
                return 1
            g_analysis_in_progress.add(primary_func_ea)

        content_choice = ida_kernwin.ask_buttons("Decompiled", "Assembly", "Cancel", 1, "Select content for LLM:")
        if content_choice == -1:  # Cancel
            with g_analysis_lock: g_analysis_in_progress.discard(primary_func_ea)
            return 1
        content_mode = CONTENT_MODE_DECOMP if content_choice == 1 else CONTENT_MODE_ASM

        a_depth = ida_kernwin.ask_long(DEFAULT_ANALYSIS_DEPTH,
                                       "Analysis Depth") if self.analysis_mode == 'depth_limited' else 0
        c_depth = ida_kernwin.ask_long(DEFAULT_CONTEXT_CALLER_DEPTH, "Context Caller Depth")
        ca_depth = ida_kernwin.ask_long(DEFAULT_CONTEXT_CALLEE_DEPTH, "Context Callee/Ref Depth")
        if c_depth is None or ca_depth is None or a_depth is None:
            with g_analysis_lock: g_analysis_in_progress.discard(primary_func_ea)
            return 1

        threading.Thread(target=single_analysis_task_wrapper, args=(
            primary_func_ea, c_depth, ca_depth, self.model, self.analysis_mode, a_depth, None, content_mode
        )).start()
        return 1

    def update(self, ctx):
        return ida_kernwin.AST_ENABLE_FOR_WIDGET if ctx.widget_type in (ida_kernwin.BWN_PSEUDOCODE,
                                                                        ida_kernwin.BWN_DISASM) else ida_kernwin.AST_DISABLE_FOR_WIDGET


class Hooks(ida_kernwin.UI_Hooks):
    def finish_populating_widget_popup(self, widget, popup_handle, ctx=None):
        if ida_kernwin.get_widget_type(widget) in (ida_kernwin.BWN_PSEUDOCODE, ida_kernwin.BWN_DISASM):
            for model in MODELS_TO_REGISTER:
                ida_kernwin.attach_action_to_popup(widget, popup_handle, f"{ACTION_ID_CTX_PREFIX_MULTI}{model}",
                                                   f"{MENU_PATH_CTX}", ida_kernwin.SETMENU_INS)
                ida_kernwin.attach_action_to_popup(widget, popup_handle, f"{ACTION_ID_CTX_PREFIX_SINGLE}{model}",
                                                   f"{MENU_PATH_CTX}", ida_kernwin.SETMENU_INS)
                ida_kernwin.attach_action_to_popup(widget, popup_handle, f"{ACTION_ID_CTX_PREFIX_DEPTH}{model}",
                                                   f"{MENU_PATH_CTX}", ida_kernwin.SETMENU_INS)


class semray_t(idaapi.plugin_t):
    flags, comment, help, wanted_name = idaapi.PLUGIN_PROC | idaapi.PLUGIN_FIX, PLUGIN_NAME, "Google AI assistance", PLUGIN_NAME
    hooks, registered_actions = None, []

    def init(self):
        for model in MODELS_TO_REGISTER:
            for mode, label in [('all', 'Analyze ALL Funcs in Context'), ('current', 'Analyze CURRENT Func Only'),
                                ('depth_limited', 'Analyze Current + N Levels')]:
                prefix = {'all': ACTION_ID_CTX_PREFIX_MULTI, 'current': ACTION_ID_CTX_PREFIX_SINGLE,
                          'depth_limited': ACTION_ID_CTX_PREFIX_DEPTH}[mode]
                action_id = f"{prefix}{model}"
                desc = ida_kernwin.action_desc_t(action_id, f"{label} ({model})", CtxActionHandler(model, mode), None,
                                                 None, 199)
                if ida_kernwin.register_action(desc): self.registered_actions.append(action_id)
        self.hooks = Hooks()
        self.hooks.hook()
        return idaapi.PLUGIN_KEEP

    def run(self, arg):
        global g_multi_analysis_active
        with g_analysis_lock:
            if g_multi_analysis_active: return
            g_multi_analysis_active = True

        func_list_str = ida_kernwin.ask_str("", 0, "Enter comma-separated function names or addresses")
        if not func_list_str:
            with g_analysis_lock: g_multi_analysis_active = False
            return

        start_eas = set()
        for item in func_list_str.split(','):
            item_strip = item.strip()
            if not item_strip: continue
            ea = ida_name.get_name_ea(idaapi.BADADDR, item_strip)
            if ea == idaapi.BADADDR:
                try:
                    ea = int(item_strip, 0)
                except ValueError:
                    continue
            if ida_funcs.get_func(ea): start_eas.add(ea)

        if not start_eas:
            ida_kernwin.warning("SemRay: No valid functions found from input.")
            with g_analysis_lock: g_multi_analysis_active = False
            return

        content_choice = ida_kernwin.ask_buttons("Decompiled", "Assembly", "Cancel", 1, "Select content for LLM:")
        if content_choice == -1:
            with g_analysis_lock: g_multi_analysis_active = False
            return
        content_mode = CONTENT_MODE_DECOMP if content_choice == 1 else CONTENT_MODE_ASM

        c_depth = ida_kernwin.ask_long(DEFAULT_CONTEXT_CALLER_DEPTH, "Context Caller Depth")
        ca_depth = ida_kernwin.ask_long(DEFAULT_CONTEXT_CALLEE_DEPTH, "Context Callee/Ref Depth")
        if c_depth is None or ca_depth is None:
            with g_analysis_lock: g_multi_analysis_active = False
            return

        threading.Thread(target=multi_analysis_task_wrapper,
                         args=(start_eas, c_depth, ca_depth, DEFAULT_GEMINI_MODEL, None, content_mode)).start()

    def term(self):
        if self.hooks: self.hooks.unhook()
        for action in self.registered_actions: ida_kernwin.unregister_action(action)
        for form in list(SemRayUI.open_forms.values()): form.Close(0)


def PLUGIN_ENTRY():
    return semray_t()

```