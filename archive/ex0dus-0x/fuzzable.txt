Project Path: arc_ex0dus-0x_fuzzable_y_poamsl

Source Tree:

```txt
arc_ex0dus-0x_fuzzable_y_poamsl
├── CODE_OF_CONDUCT.md
├── Dockerfile
├── LICENSE.md
├── README.md
├── __init__.py
├── docs
│   ├── docs
│   │   └── index.md
│   └── mkdocs.yml
├── examples
│   ├── binaries
│   │   ├── libbasic.so
│   │   └── libyara.so
│   └── source
│       ├── callgraph.c
│       ├── libbasic.c
│       └── libyaml
├── extras
│   ├── binja.png
│   └── cli.png
├── fuzzable
│   ├── __init__.py
│   ├── __main__.py
│   ├── analysis
│   │   ├── __init__.py
│   │   ├── angr.py
│   │   ├── ast.py
│   │   └── binja.py
│   ├── cli.py
│   ├── config.py
│   ├── generate.py
│   ├── log.py
│   └── metrics.py
├── plugin.json
├── poetry.lock
├── pyproject.toml
├── requirements.txt
├── templates
│   ├── linux_closed_source_harness.cpp
│   └── linux_source_harness.cpp
├── tests
│   ├── __init__.py
│   ├── analysis
│   │   └── test_angr.py
│   ├── test_generate.py
│   └── test_main.py
└── third_party
    ├── tree-sitter-c
    └── tree-sitter-cpp

```

`CODE_OF_CONDUCT.md`:

```md
# Contributor Covenant Code of Conduct

## Our Pledge

We as members, contributors, and leaders pledge to make participation in our
community a harassment-free experience for everyone, regardless of age, body
size, visible or invisible disability, ethnicity, sex characteristics, gender
identity and expression, level of experience, education, socio-economic status,
nationality, personal appearance, race, religion, or sexual identity
and orientation.

We pledge to act and interact in ways that contribute to an open, welcoming,
diverse, inclusive, and healthy community.

## Our Standards

Examples of behavior that contributes to a positive environment for our
community include:

* Demonstrating empathy and kindness toward other people
* Being respectful of differing opinions, viewpoints, and experiences
* Giving and gracefully accepting constructive feedback
* Accepting responsibility and apologizing to those affected by our mistakes,
  and learning from the experience
* Focusing on what is best not just for us as individuals, but for the
  overall community

Examples of unacceptable behavior include:

* The use of sexualized language or imagery, and sexual attention or
  advances of any kind
* Trolling, insulting or derogatory comments, and personal or political attacks
* Public or private harassment
* Publishing others' private information, such as a physical or email
  address, without their explicit permission
* Other conduct which could reasonably be considered inappropriate in a
  professional setting

## Enforcement Responsibilities

Community leaders are responsible for clarifying and enforcing our standards of
acceptable behavior and will take appropriate and fair corrective action in
response to any behavior that they deem inappropriate, threatening, offensive,
or harmful.

Community leaders have the right and responsibility to remove, edit, or reject
comments, commits, code, wiki edits, issues, and other contributions that are
not aligned to this Code of Conduct, and will communicate reasons for moderation
decisions when appropriate.

## Scope

This Code of Conduct applies within all community spaces, and also applies when
an individual is officially representing the community in public spaces.
Examples of representing our community include using an official e-mail address,
posting via an official social media account, or acting as an appointed
representative at an online or offline event.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported to the community leaders responsible for enforcement at
ex0dus@codemuch.tech.
All complaints will be reviewed and investigated promptly and fairly.

All community leaders are obligated to respect the privacy and security of the
reporter of any incident.

## Enforcement Guidelines

Community leaders will follow these Community Impact Guidelines in determining
the consequences for any action they deem in violation of this Code of Conduct:

### 1. Correction

**Community Impact**: Use of inappropriate language or other behavior deemed
unprofessional or unwelcome in the community.

**Consequence**: A private, written warning from community leaders, providing
clarity around the nature of the violation and an explanation of why the
behavior was inappropriate. A public apology may be requested.

### 2. Warning

**Community Impact**: A violation through a single incident or series
of actions.

**Consequence**: A warning with consequences for continued behavior. No
interaction with the people involved, including unsolicited interaction with
those enforcing the Code of Conduct, for a specified period of time. This
includes avoiding interactions in community spaces as well as external channels
like social media. Violating these terms may lead to a temporary or
permanent ban.

### 3. Temporary Ban

**Community Impact**: A serious violation of community standards, including
sustained inappropriate behavior.

**Consequence**: A temporary ban from any sort of interaction or public
communication with the community for a specified period of time. No public or
private interaction with the people involved, including unsolicited interaction
with those enforcing the Code of Conduct, is allowed during this period.
Violating these terms may lead to a permanent ban.

### 4. Permanent Ban

**Community Impact**: Demonstrating a pattern of violation of community
standards, including sustained inappropriate behavior,  harassment of an
individual, or aggression toward or disparagement of classes of individuals.

**Consequence**: A permanent ban from any sort of public interaction within
the community.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage],
version 2.0, available at
https://www.contributor-covenant.org/version/2/0/code_of_conduct.html.

Community Impact Guidelines were inspired by [Mozilla's code of conduct
enforcement ladder](https://github.com/mozilla/diversity).

[homepage]: https://www.contributor-covenant.org

For answers to common questions about this code of conduct, see the FAQ at
https://www.contributor-covenant.org/faq. Translations are available at
https://www.contributor-covenant.org/translations.

```

`Dockerfile`:

```
FROM ubuntu:20.04

LABEL name=fuzzable
LABEL src="https://github.com/ex0dus-0x/fuzzable"

ENV LANG C.UTF-8

RUN apt-get -y update && DEBIAN_FRONTEND=noninteractive apt-get -y install python3 python3-dev python3-pip git wget
RUN python3 -m pip install -U pip

ADD . /fuzzable
RUN cd /fuzzable && python3 -m pip install .

CMD ["/bin/sh"]

```

`LICENSE.md`:

```md
Copyright 2022 ex0dus-0x

Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the "Software"), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.


```

`README.md`:

```md
# Fuzzable

[![Build Status](https://github.com/ex0dus-0x/fuzzable/actions/workflows/main.yml/badge.svg)](https://github.com/ex0dus-0x/fuzzable/actions)
[![PyPI version](https://badge.fury.io/py/fuzzable.svg)](https://badge.fury.io/py/fuzzable)
[![Blackhat](https://raw.githubusercontent.com/toolswatch/badges/master/arsenal/usa/2022.svg)](https://raw.githubusercontent.com/toolswatch/badges/master/arsenal/usa/2022.svg)

Framework for Automating _Fuzzable_ Target Discovery with Static Analysis

![example](https://raw.githubusercontent.com/ex0dus-0x/fuzzable/main/extras/cli.png "CLI Example")

## Introduction

Vulnerability researchers conducting security assessments on software will often harness the capabilities of coverage-guided fuzzing through powerful tools like AFL++ and libFuzzer. This is important as it automates the bughunting process and reveals exploitable conditions in targets quickly. However, when encountering large and complex codebases or closed-source binaries, researchers have to painstakingly dedicate time to manually audit and reverse engineer them to identify functions where fuzzing-based exploration can be useful.

__Fuzzable__ is a framework that integrates both with C/C++ source code and binaries to assist vulnerability researchers in identifying function targets that are viable for fuzzing. This is done by applying several static analysis-based heuristics to pinpoint risky behaviors in the software and the functions that executes them. Researchers can then utilize the framework to generate basic harness templates, which can then be used to hunt for vulnerabilities, or to be integrated as part of a continuous fuzzing pipeline, such as Google's [oss-fuzz](https://github.com/google/oss-fuzz) project.

In addition to running as a standalone tool, Fuzzable is also integrated as a plugin for the [Binary Ninja ](https://binary.ninja) disassembler, with support for other disassembly backends being developed.

Check out the original blog post detailing the tool [here](https://codemuch.tech/2021/06/07/fuzzabble/), which highlights the technical specifications of the static analysis heuristics and how this tool came about. This tool is also featured at [Black Hat Arsenal USA 2022](https://www.blackhat.com/us-22/arsenal/schedule/index.html#automating-fuzzable-target-discovery-with-static-analysis-26726).

## Features

* Supports analyzing __binaries__ (with [Angr](https://angr.io) and [Binary Ninja](https://binary.ninja)) and
__source code__ artifacts (with [tree-sitter](https://tree-sitter.github.io/tree-sitter/)).
* Run static analysis both as a __standalone CLI tool__ or a __Binary Ninja plugin__.
* __Harness generation__ to ramp up on creating fuzzing campaigns quickly.

## Installation

Some binary targets may require some sanitizing (ie. signature matching, or identifying functions from inlining), and therefore 
__fuzzable__ primarily uses Binary Ninja as a disassembly backend because of it's ability to effectively solve these problems. Therefore, it can be utilized both as a standalone tool and plugin.

Since Binary Ninja isn't accessible to all and there may be a demand to utilize for security assessments and potentially scaling up in the cloud, an [angr](https://github.com/angr/angr)
_fallback_ backend is also supported. I anticipate to incorporate other disassemblers down the road as well (priority: Ghidra).

### Command Line (Standalone)

If you have Binary Ninja Commercial, be sure to install the API for standalone headless usage:

```
$ python3 /Applications/Binary\ Ninja.app/Contents/Resources/scripts/install_api.py
```

Install with `pip`:

```
$ pip install fuzzable
```

### Manual/Development Build

We use [poetry](https://python-poetry.org) for dependency management and building. To do a manual build, clone the repository with the third-party modules:

```
$ git clone --recursive https://github.com/ex0dus-0x/fuzzable
```

To install manually:

```
$ cd fuzzable/

# without poetry
$ pip install .

# with poetry
$ poetry install

# with poetry for a development virtualenv
$ poetry shell
```

You can now analyze binaries and/or source code with the tool!

```
# analyzing a single shared object library binary
$ fuzzable analyze examples/binaries/libbasic.so

# analyzing a single C source file
$ fuzzable analyze examples/source/libbasic.c

# analyzing a workspace with multiple C/C++ files and headers
$ fuzzable analyze examples/source/source_bundle/
```

### Binary Ninja Plugin

__fuzzable__ can be easily installed through the Binary Ninja plugin marketplace by going to `Binary Ninja > Manage Plugins` and searching for it. Here is an example of the __fuzzable__ plugin running,
accuracy identifying targets for fuzzing and further vulnerability assessment:

![binja_example](/extras/binja.png "Binary Ninja Example")

## Usage

__fuzzable__ comes with various options to help better tune your analysis. More will be supported in future plans and any feature requests made. 

### Static Analysis Heuristics

To determine fuzzability, __fuzzable__ utilize several heuristics to determine which targets are the most viable to target for dynamic analysis. These heuristics are all weighted differently using the [scikit-criteria](https://scikit-criteria.quatrope.org/en/latest/tutorial/quickstart.html) library, which utilizes _multi-criteria decision analysis_ to determine the best candidates. These metrics and are there weights can be seen here:

| Heuristic             | Description                                                 | Weight |
|-----------------------|-------------------------------------------------------------|--------|
| Fuzz Friendly Name    | Symbol name implies behavior that ingests file/buffer input | 0.3    |
| Risky Sinks           | Arguments that flow into risky calls (ie memcpy)            | 0.3    |
| Natural Loops         | Number of loops detected with the dominance frontier        | 0.05   |
| Cyclomatic Complexity | Complexity of function target based on edges + nodes        | 0.05   |
| Coverage Depth        | Number of callees the target traverses into                 | 0.3    |

> As mentioned, check out the [technical blog post](https://codemuch.tech/2021/06/07/fuzzabble/) for a more in-depth look into why and how these metrics are utilized.

Many metrics were largely inspired by [Vincenzo Iozzo's original work in 0-knowledge fuzzing](https://resources.sei.cmu.edu/asset_files/WhitePaper/2010_019_001_53555.pdf).

Every targets you want to analyze is diverse, and __fuzzable__ will not be able to account for every edge case behavior in the program target. Thus, it may be important during analysis to _tune_ these weights appropriately to see if different results make more sense for your use case. To tune these weights in the CLI, simply specify the `--score-weights` argument:

```
$ fuzzable analyze <TARGET> --score-weights=0.2,0.2,0.2,0.2,0.2
```

### Analysis Filtering

By default, __fuzzable__ will filter out function targets based on the following criteria:

* __Top-level entry calls__ - functions that aren't called by any other calls in the target. These are ideal entry points that have potentially very high coverage.
* __Static calls__ - _(source only)_ functions that are `static` and aren't exposed through headers.
* __Imports__ - _(binary only)_ other library dependencies being used by the target's implementations.

To see calls that got filtered out by __fuzzable__, set the `--list_ignored` flag:

```
$ fuzzable analyze --list-ignored <TARGET>
```

In Binary Ninja, you can turn this setting in `Settings > Fuzzable > List Ignored Calls`.

In the case that __fuzzable__ falsely filters out important calls that should be analyzed, it is recommended to use `--include-*` arguments
to include them during the run:

```
# include ALL non top-level calls that were filtered out
$ fuzzable analyze --include-nontop <TARGET>

# include specific symbols that were filtered out
$ fuzzable analyze --include-sym <SYM> <TARGET>
```

In Binary Ninja, this is supported through `Settings > Fuzzable > Include non-top level calls` and `Symbols to Exclude`.

### Harness Generation

Now that you have found your ideal candidates to fuzz, __fuzzable__ will also help you generate fuzzing harnesses that are (almost) ready to instrument and compile for use with either a file-based fuzzer (ie. AFL++, Honggfuzz) or in-memory fuzzer (libFuzzer). To do so in the CLI:

```
# generate harness from a candidate
$ fuzzable create-harness target --symbol-name=some_unsafe_call

# make minimal and necessary modifications to the harness
$ vim target_some_unsafe_call_harness.cpp

# example compilation for AFL-QEMU, which is specified in the comments of the generated harness
$ clang target_some_unsafe_call_harness.cpp -no-pie -o target_some_unsafe_call_harness -ldl

# create your base seeds, ideally should be more well-formed for input
$ mkdir in/
$ echo "seed" >> in/seed

# start black box fuzzing
$ afl-fuzz -Q -m none -i in/ -o out/ -- ./target_some_unsafe_call_harness
```

If this target is a source codebase, the [generic source template](/templates/linux_source_harness.cpp) will be used. 

If the target is a binary, the [generic black-box template](/templates/linux_closed_source_harness.cpp) will be used, which ideally can be used with a fuzzing emulation mode like [AFL-QEMU](https://github.com/mirrorer/afl/blob/master/qemu_mode/README.qemu). A copy of the binary will also be created as a shared object if the symbol isn't exported directly to be `dlopen`ed using [LIEF](https://lief-project.github.io).

At the moment, this feature is quite rudimentary, as it simply will create a standalone C++ harness populated with the appropriate parameters, and will not auto-generate code that is needed for any runtime behaviors (ie. instantiating and freeing structures). However, the templates created for __fuzzable__ should get still get you running quickly. Here are some ambitious features I would like to implement down the road:

* Full harness synthesis - harnesses will work directly with absolutely no manual changes needed.
* Synthesis from potential unit tests using the [DeepState](https://github.com/trailofbits/deepstate) framework _(Source only)_.
* Immediate deployment to a managed continuous fuzzing fleet.

### Exporting Reports

__fuzzable__ supports generating reports in various formats. The current ones that are supported are JSON, CSV and Markdown. This can be useful if you are utilizing this as part of automation where you would like to
ingest the output in a serializable format.

In the CLI, simply pass the `--export` argument with a filename with the appropriate extension:

```
$ fuzzable analyze --export=report.json <TARGET>
```

In Binary Ninja, go to `Plugins > Fuzzable > Export Fuzzability Report > ...` and select the format you want to
export to and the path you want to write it to.

## Contributing

This tool will be continuously developed, and any help from external mantainers are appreciated!

* Create an [issue](https://github.com/ex0dus-0x/fuzzable/issues) for feature requests or bugs that you have come across.
* Submit a [pull request](https://github.com/ex0dus-0x/fuzzable/pulls) for fixes and enhancements that you would like to see contributed to this tool.

## License

Fuzzable is licensed under the [MIT License](https://codemuch.tech/license.txt).

```

`__init__.py`:

```py
#!/usr/bin/env python3
"""
__init__.py

    Plugin module used for Binary Ninja
"""
import dataclasses

from binaryninja.plugin import PluginCommand
from binaryninja.settings import Settings

from .fuzzable.analysis import binja, DEFAULT_SCORE_WEIGHTS
from .fuzzable.config import AnalysisKnobs

# TODO register settings from a config of analysis flags

Settings().register_group("fuzzable", "Fuzzable")
Settings().register_setting(
    "fuzzable.list_ignored",
    """
    {
        "title"         : "List Ignored Symbols",
        "description"   : "If set, will also additionally output and/or export ignored symbols.",
        "type"          : "boolean",
        "default"       : false
    }
""",
)
Settings().register_setting(
    "fuzzable.include_sym",
    """
    {
        "title"         : "Symbols to Include",
        "description"   : "Comma-seperated list of symbols to absolutely be considered for analysis.",
        "type"          : "array",
        "elementType"   : "string",
        "default"       : []
    }
""",
)

Settings().register_setting(
    "fuzzable.include_nontop",
    """
    {
        "title"         : "Include non-top level calls",
        "description"   : "If set, won't filter out only on top-level function definitions.",
        "type"          : "boolean",
        "default"       : false
    }
""",
)

Settings().register_setting(
    "fuzzable.skip_sym",
    """
    {
        "title"         : "Symbols to Exclude",
        "description"   : "Exclude symbols from being considered for analysis.",
        "type"          : "array",
        "elementType"   : "string",
        "default"       : []
    }
""",
)

Settings().register_setting(
    "fuzzable.skip_stripped",
    """
    {
        "title"         : "Skip Stripped Symbols",
        "description"   : "Ignore stripped symbols.",
        "type"          : "boolean",
        "default"       : false
    }
""",
)

Settings().register_setting(
    "fuzzable.ignore_metrics",
    """
    {
        "title"         : "Ignoring Displaying Metrics",
        "description"   : "If set, include individual metrics' scores for each function target analyzed.",
        "type"          : "boolean",
        "default"       : true
    }
""",
)

Settings().register_setting(
    "fuzzable.score_weights",
    """
    {{
        "title"         : "Override Score Weights",
        "description"   : "Change default score weights for each metric.",
        "type"          : "array",
        "elementType"   : "string",
        "default"       : {}
    }}
""".format(
        DEFAULT_SCORE_WEIGHTS
    ),
)

PluginCommand.register(
    "Fuzzable\\Analyze and Rank Functions",
    "List out functions we've determined to be the best candidates for fuzzing."
    "This will exclude functions that is determined to not be directly usable for a harness.",
    binja.run_fuzzable,
)

PluginCommand.register(
    "Fuzzable\\Export Fuzzability Report\\CSV (.csv)",
    "Identify and generate targets for fuzzing",
    binja.run_export_csv,
)

PluginCommand.register(
    "Fuzzable\\Export Fuzzability Report\\JSON (.json)",
    "Identify and generate targets for fuzzing",
    binja.run_export_json,
)

PluginCommand.register(
    "Fuzzable\\Export Fuzzability Report\\Markdown (.md)",
    "Identify and generate targets for fuzzing",
    binja.run_export_md,
)

PluginCommand.register_for_function(
    "Fuzzable\\Harness Generation\\Generate binary fuzzing harness (Linux ONLY at the moment)",
    "For a target function, generate a AFL-QEMU/libFuzzer C++ harness",
    binja.run_harness_generation,
)

```

`docs/docs/index.md`:

```md
# Welcome to MkDocs

For full documentation visit [mkdocs.org](https://www.mkdocs.org).

## Commands

* `mkdocs new [dir-name]` - Create a new project.
* `mkdocs serve` - Start the live-reloading docs server.
* `mkdocs build` - Build the documentation site.
* `mkdocs -h` - Print help message and exit.

## Project layout

    mkdocs.yml    # The configuration file.
    docs/
        index.md  # The documentation homepage.
        ...       # Other markdown pages, images and other files.

```

`docs/mkdocs.yml`:

```yml
site_name: Fuzzable
theme:
  name: material

```

`examples/source/callgraph.c`:

```c
#include <stdlib.h>

int func(void) {
    func1();
    func2();
    return 0;
}

static int func1() {
    return 0;
}

void func2() {
    return 0;
}
```

`examples/source/libbasic.c`:

```c
/*
 * libbasic.c
 *
 *      Basic sanity example for identifying fuzzable targets.
 */

#include <stdio.h>
#include <stdlib.h>
#include <string.h>

#define SIZE 2048

typedef struct {
    int identifier;
    char contents[SIZE];
} obj_t;

// 1. We're consuming a buffer
// 2. That buffer flows into an unsafe call with memcpy
// 3. We do branch and that attributes to complexity
obj_t* vulnerable_parse_buf(char* buf, size_t size) {
    obj_t* obj = (obj_t *) malloc(sizeof(obj_t));
    if (obj == NULL) {
        return NULL;
    }
    obj->identifier = 100;

    // Hmmm....
    memcpy(obj->contents, buf, size);
    return obj;
}

void free_obj(obj_t* obj) {
    free(obj);
}

int not_so_vulnerable(obj_t* obj, int inc) {
    obj->identifier += inc;
    return 0;
}



```

`fuzzable/__main__.py`:

```py
#!/usr/bin/env python3
"""
__main__.py

    Command line entry point for launching the standalone CLI executable.
"""
import os
import logging
import typing as t
import typer

from rich import print

from fuzzable import generate
from fuzzable.config import SOURCE_FILE_EXTS
from fuzzable.cli import print_table, error, export_results
from fuzzable.analysis import AnalysisBackend, DEFAULT_SCORE_WEIGHTS
from fuzzable.analysis.ast import AstAnalysis
from fuzzable.log import log

from pathlib import Path

app = typer.Typer(
    help="Framework for Automating Fuzzable Target Discovery with Static Analysis",
    no_args_is_help=True,
    context_settings=dict(help_option_names=["-h", "--help"]),
    add_completion=False,
)


@app.callback()
def global_args(
    verbosity: int = typer.Option(
        0,
        "-v",
        "--verbosity",
        help="Sets logging level (2 = debug, 1 = info, 0 = output).",
    ),
):
    """Handles global flags for all commands."""
    if verbosity == 1:
        log.setLevel(logging.INFO)
    elif verbosity == 2:
        log.setLevel(logging.DEBUG)


@app.command()
def analyze(
    target: Path,
    export: t.Optional[Path] = typer.Option(
        None,
        "-e",
        "--export",
        help="Export the fuzzability report to a path based on the file extension."
        "Fuzzable supports exporting to `json`, `csv`, or `md`.",
    ),
    list_ignored: bool = typer.Option(
        False,
        help="If set, will also additionally output and/or export ignored symbols.",
    ),
    include_sym: t.Optional[str] = typer.Option(
        None,
        help="Comma-seperated list of symbols to absolutely be considered for analysis.",
    ),
    include_nontop: bool = typer.Option(
        False, help="If set, won't filter out only on top-level function definitions."
    ),
    skip_sym: t.Optional[str] = typer.Option(
        None, help="Comma-seperated list of symbols to skip during analysis."
    ),
    skip_stripped: bool = typer.Option(
        False,
        help="If set, ignore symbols that are stripped in binary analysis."
        "Will be ignored if fuzzability analysis is done on source code.",
    ),
    ignore_metrics: bool = typer.Option(
        True,
        help="If set, include individual metrics' scores for each function target analyzed.",
    ),
    score_weights: t.Optional[str] = typer.Option(
        None,
        "-w",
        "--score-weights",
        help="Comma-seperated list of reconfigured weights for multi-criteria decision analysis when determining fuzzability.",
    ),
):
    """
    Run fuzzable analysis on a single or workspace of C/C++ source files, or a compiled binary.
    """
    if not target.is_file() and not target.is_dir():
        error(f"Target path `{target}` does not exist.")

    # parse custom weights and run checks
    if score_weights:
        log.debug("Reconfiguring score weights for MCDA")
        score_weights = [float(weight) for weight in score_weights.split(",")]
        num_weights = len(DEFAULT_SCORE_WEIGHTS)
        if len(score_weights) != num_weights:
            error(f"--score-weights must contain {num_weights}")

        if sum(score_weights) != 1.0:
            error(f"--score-weights must sum up to 1.0")
    else:
        score_weights = DEFAULT_SCORE_WEIGHTS

    # export file format checking
    if export is not None:
        ext = export.suffix.lower()[1:]
        if ext not in ["json", "csv", "md"]:
            error("--export value must either have `json`, `csv`, or `md` extensions.")

    # parse symbols to explicitly include for analysis
    if include_sym:
        include_sym = [sym for sym in include_sym.split(",")]
        if len(include_sym) == 0:
            error(f"--include-sym must include at least one valid function symbol")

        log.debug(f"Parsed symbols to explicitly include for analysis {include_sym}")
    else:
        include_sym = []

    # parse symbols to explicitly exclude from analysis
    if skip_sym:
        skip_sym = [sym for sym in skip_sym.split(",")]
        if len(skip_sym) == 0:
            error(f"--skip-sym must specify a valid function symbol")

        log.debug(f"Parsed symbols to explicitly include for analysis {skip_sym}")
    else:
        skip_sym = []

    # check if overlapping symbols
    if set(skip_sym) & set(include_sym):
        error(f"Cannot have same symbols in both --include-sym and --skip-sym.")

    log.info(f"Running fuzzability analysis on {target}")
    if target.is_file():
        run_on_file(
            target,
            export,
            list_ignored,
            include_sym,
            include_nontop,
            skip_sym,
            skip_stripped,
            ignore_metrics,
            score_weights,
        )
    elif target.is_dir():
        run_on_workspace(
            target,
            export,
            list_ignored,
            include_sym,
            include_nontop,
            skip_sym,
            skip_stripped,
            ignore_metrics,
            score_weights,
        )


def run_on_file(
    target: Path,
    export: t.Optional[Path],
    list_ignored: bool,
    include_sym: t.List[str],
    include_nontop: bool,
    skip_sym: t.List[str],
    skip_stripped: bool,
    ignore_metrics: bool,
    score_weights: t.List[float],
) -> None:
    """Runs analysis on a single source code file or binary file."""
    analyzer: t.TypeVar[AnalysisBackend]

    extension = target.suffix
    if extension in SOURCE_FILE_EXTS:
        analyzer = AstAnalysis(
            [target],
            include_sym=include_sym,
            include_nontop=include_nontop,
            score_weights=score_weights,
        )
    else:
        # Prioritize loading binja as a backend, this will not
        # work if the license is personal/student.
        try:
            import sys

            sys.tracebacklimit = 0

            from binaryninja.binaryview import BinaryViewType

            bv = BinaryViewType.get_view_of_file(target)
            bv.update_analysis_and_wait()

            from fuzzable.analysis.binja import BinjaAnalysis

            analyzer = BinjaAnalysis(
                bv,
                include_sym=include_sym,
                include_nontop=include_nontop,
                skip_sym=skip_sym,
                skip_stripped=skip_stripped,
                score_weights=score_weights,
                headless=True,
            )

        # didn't work, try to load angr as a fallback instead
        except (RuntimeError, ModuleNotFoundError, ImportError):
            log.warning(
                f"Cannot load Binary Ninja as a backend. Attempting to load angr instead."
            )
            try:
                from fuzzable.analysis.angr import AngrAnalysis

                analyzer = AngrAnalysis(
                    target,
                    include_sym=include_sym,
                    include_nontop=include_nontop,
                    skip_sym=skip_sym,
                    skip_stripped=skip_stripped,
                    score_weights=score_weights,
                )
            except ModuleNotFoundError as err:
                error(f"Unsupported target {target}. Reason: {err}")

    log.info(f"Running fuzzable analysis with the {str(analyzer)} analyzer")
    results = analyzer.run()
    print_table(target, results, analyzer.skipped, ignore_metrics, list_ignored)
    if export:
        export_results(export, results)


def run_on_workspace(
    target: Path,
    export: t.Optional[Path],
    list_ignored: bool,
    include_sym: t.List[str],
    include_nontop: bool,
    skip_sym: t.List[str],
    skip_stripped: bool,  # not used, maybe until we support multiple binaries
    ignore_metrics: bool,
    score_weights: t.List[float],
) -> None:
    """
    Given a workspace, recursively iterate and parse out all of the source code files
    that are present. This is not currently supported on workspaces of binaries/libraries.
    """
    source_files = []
    for subdir, _, files in os.walk(target):
        for file in files:
            if Path(file).suffix in SOURCE_FILE_EXTS:
                log.info(f"Adding {file} to set of source code to analyze")
                source_files += [Path(os.path.join(subdir, file))]

    if len(source_files) == 0:
        error(
            "No C/C++ source code found in the workspace. fuzzable currently does not support parsing on workspaces with multiple binaries."
        )

    analyzer = AstAnalysis(
        source_files,
        include_sym=include_sym,
        include_nontop=include_nontop,
        skip_sym=skip_sym,
        score_weights=score_weights,
        basedir=target,
    )
    log.info(f"Running fuzzable analysis with the {str(analyzer)} analyzer")
    results = analyzer.run()
    print_table(target, results, analyzer.skipped, ignore_metrics, list_ignored)
    if export:
        export_results(export, results)


@app.command()
def create_harness(
    target: Path,
    symbol_name: str = typer.Option(
        ...,
        "-n",
        "--symbol_name",
        help="Names of function symbol to create a fuzzing harness to target. Source not supported yet.",
    ),
    out_so_name: t.Optional[Path] = typer.Option(
        None,
        "-s",
        "--out_so_name",
        help="Specify to set output `.so` path of a transformed ELF binary for binary targets.",
    ),
    out_harness: t.Optional[Path] = typer.Option(
        None,
        "-o",
        "--out_harness",
        help="Specify to set output harness template file path.",
    ),
):
    """Synthesize a AFL++/libFuzzer harness for a given symbol in a binary target."""

    if not target.is_file():
        error(f"Target path `{target}` does not exist.")

    try:
        import lief
    except (RuntimeError, ModuleNotFoundError, ImportError):
        error("Could not import LIEF library to parse binary.")

    # if a binary, check if executable or library. if executable, use LIEF to
    # copy, export the symbol and transform to shared object.
    binary = lief.parse(str(target))
    if binary is None:
        error(
            "Wrong filetype, or does not support synthesizing harnesses for C/C++ source code yet."
        )

    # resolve paths appropriately
    if out_so_name:
        out_so_name = out_so_name.expanduser()

    if out_harness:
        out_harness = out_harness.expanduser()

    log.info(f"Running harness generation for `{target}` on symbol `{symbol_name}`.")
    shared_obj = generate.transform_elf_to_so(target, binary, symbol_name, out_so_name)
    generate.generate_harness(shared_obj, symbol_name, output=out_harness)

    log.info("Done!")

```

`fuzzable/analysis/__init__.py`:

```py
"""
__init__.py

    Implements the base class and exception for different static analysis backends.
"""

import abc
import typing as t

# skc has dep problems (e.g in numpy). Set a flag that can be reused to warn the user that
# the module is not used, and a basic fuzzability calculation will be performed instead.
BASIC_FUZZABLE_ERROR: t.Optional[str] = None
try:
    import skcriteria as skc
    from skcriteria.madm import simple
except ImportError as err:
    BASIC_FUZZABLE_ERROR = f"Cannot import scikit-criteria, using basic ranking method instead. Reason: {repr(err)}"


from ..metrics import CallScore, METRICS
from ..config import GLOBAL_IGNORES, INTERESTING_PATTERNS, RISKY_GLIBC_CALL_PATTERNS
from ..log import log

# Type sig for a finalized list
Fuzzability = t.OrderedDict[str, CallScore]

# Default weights for fuzzability
DEFAULT_SCORE_WEIGHTS: t.List[float] = [0.3, 0.3, 0.05, 0.05, 0.3]


class AnalysisException(Exception):
    """Raised when an analysis fails to succeed."""


class AnalysisBackend(abc.ABC):
    """Base class for analysis backends to implement and detect fuzzable targets."""

    def __init__(
        self,
        target: t.Any,
        include_sym: t.List[str] = [],
        include_nontop: bool = False,
        skip_sym: t.List[str] = [],
        skip_stripped: bool = False,
        score_weights: t.List[float] = DEFAULT_SCORE_WEIGHTS,
    ):
        self.target = target

        # configures inclusion
        self.include_sym: t.List[str] = include_sym
        self.include_nontop: bool = include_nontop

        # configures exclusion
        self.skip_sym: t.List[str] = skip_sym
        self.skip_stripped: bool = skip_stripped

        # weights of each feature for MCDA
        self.score_weights: t.List[float] = score_weights

        # mapping of functions + locations we've chosen to skipped
        self.skipped: t.Dict[str, str] = {}

        # stores all the scores we've measured from the functions
        self.scores: t.List[t.Any] = []

        # caches names of calls we've visited already to skip repeats
        self.visited: t.List[t.Any] = []

    @abc.abstractmethod
    def __str__(self) -> str:
        ...

    @abc.abstractmethod
    def run(self) -> Fuzzability:
        """
        Determine the fuzzability of each function in the binary or source targets.
        """
        ...

    def _rank_fuzzability(self, unranked: t.List[CallScore]) -> Fuzzability:
        """
        After analyzing each function call, use scikit-criteria to rank based on the call score
        using a simple weighted-sum model.

        This should be the tail call for run(), as it produces the finalized results.
        """

        # sanity-check number of symbols parsed out
        if len(unranked) == 0:
            raise AnalysisException(
                "no function targets parsed for fuzzability ranking"
            )
        if len(unranked) == 1:
            raise AnalysisException(
                "only one function symbol parsed for fuzzability ranking"
            )

        if BASIC_FUZZABLE_ERROR:
            log.warning(BASIC_FUZZABLE_ERROR)
            return AnalysisBackend._rank_simple_fuzzability(unranked)

        log.debug("Normalizing static analysis metric values")
        nl_normalized = AnalysisBackend._normalize(
            [score.natural_loops for score in unranked]
        )
        for score, new_nl in zip(unranked, nl_normalized):
            score.natural_loops = new_nl

        cc_normalized = AnalysisBackend._normalize(
            [score.cyclomatic_complexity for score in unranked]
        )
        for score, new_cc in zip(unranked, cc_normalized):
            score.cyclomatic_complexity = new_cc

        log.debug("Constructing decision matrix")
        decision_matrix = skc.mkdm(
            [score.matrix_row for score in unranked],
            [max, max, max, max, max],
            weights=self.score_weights,
            alternatives=[score.name for score in unranked],
            criteria=[metric.identifier for metric in METRICS[3:8]],
        )

        log.info("Ranking symbols by fuzzability")
        dec = simple.WeightedSumModel()
        rank = dec.evaluate(decision_matrix)

        log.debug("Finalizing CallScores by setting calculated scores and ranks")
        scores = rank.e_.score
        ranks = list(rank.rank_)
        new_unranked = []
        for rank, score, entry in zip(ranks, scores, unranked):
            entry.rank = rank
            entry.score = score
            new_unranked += [entry]

        log.debug("Sorting finalized list by ranks")
        sorted_results = [y for _, y in sorted(zip(ranks, new_unranked))]
        return sorted_results

    @staticmethod
    def _rank_simple_fuzzability(unranked: t.List[CallScore]) -> Fuzzability:
        """To be deprecated."""
        return sorted(unranked, key=lambda obj: obj.simple_fuzzability, reverse=True)

    @staticmethod
    def _normalize(lst: t.List[int]) -> t.List[int]:
        """Normalize values in a list based on upper and lower bounds"""
        xmin = min(lst)
        xmax = max(lst)
        for i, val in enumerate(lst):
            if (xmax - xmin) != 0:
                lst[i] = (val - xmin) / (xmax - xmin)

        return lst

    @abc.abstractmethod
    def analyze_call(self, name: str, func: t.Any) -> CallScore:
        """
        Runs heuristics we declare below on an individual function call, and
        return a `CallScore` describing heuristics matched.
        """
        ...

    @abc.abstractmethod
    def skip_analysis(self, name: str) -> bool:
        """
        Helper to determine if a parsed function should be skipped
        for analysis based on certain criteria for the analysis backend.
        """
        # explicitly specified to run
        if name in self.include_sym:
            return False

        # explicitly specified to not run
        if name in self.skip_sym:
            return True

        # stripped sym, and skip_stripped is set
        if "sub_" in name and self.skip_stripped:
            return True

        # reserved calls that shouldn't be analyzed
        if name in GLOBAL_IGNORES:
            return True

        # ignore instrumentation
        if name.startswith("__"):
            return True

        return False

    @abc.abstractmethod
    def is_toplevel_call(self, target: t.Any) -> bool:
        """
        Checks to see if the function is top-level, aka is not invoked by any other function
        in the current binary/codebase context.
        """
        ...

    @staticmethod
    def is_fuzz_friendly(symbol_name: str) -> int:
        """
        FUZZABILITY HEURISTIC

        Analyze the function's name to see if it is "fuzzer entry friendly". This denotes
        a function that can easily be called to consume a buffer filled by the fuzzer, or
        a string pointing to a filename, which can also be supplied through a file fuzzer.
        """
        return [
            pattern in symbol_name.lower() for pattern in INTERESTING_PATTERNS
        ].count(True)

    @abc.abstractmethod
    def risky_sinks(self, func: t.Any) -> int:
        """
        FUZZABILITY HEURISTIC

        Checks to see if one or more of the function's arguments is potentially user-controlled,
        and flows into a risky call. Will treat the function under test under an intraprocedural analysis.
        """
        ...

    @staticmethod
    def _is_risky_call(name: str) -> bool:
        """Helper to see if a function call deems potentially risky behaviors."""
        return any([pattern in name.lower() for pattern in RISKY_GLIBC_CALL_PATTERNS])

    @abc.abstractmethod
    def get_coverage_depth(self, func: t.Any) -> int:
        """
        FUZZABILITY HEURISTIC

        Calculates and returns a `CoverageReport` that highlights how much
        a fuzzer would ideally explore at different granularities.
        """
        ...

    @abc.abstractmethod
    def natural_loops(self, func: t.Any) -> int:
        """
        FUZZABILITY HEURISTIC

        Detection of loops is at a basic block level by checking the dominance frontier,
        which denotes the next successor the current block node will definitely reach. If the
        same basic block exists in the dominance frontier set, then that means the block will
        loop back to itself at some point in execution.
        """
        ...

    @abc.abstractmethod
    def get_cyclomatic_complexity(self) -> int:
        """
        FUZZABILITY HEURISTIC

        Calculates the complexity of a given function using McCabe's metric. We do not
        account for connected components since we assume that the target is a singular
        connected component.

        CC = Edges − Nodes/Blocks + 2
        """
        ...

```

`fuzzable/analysis/angr.py`:

```py
"""
angr.py

    Fallback disassembly backend with angr, most likely for headless analysis.
"""
import typing as t

import angr
from angr.analyses.reaching_definitions.dep_graph import DepGraph
from angr.knowledge_plugins.functions.function import Function
from angr.procedures.definitions.glibc import _libc_decls

from pathlib import Path

from . import AnalysisBackend, AnalysisException, Fuzzability, DEFAULT_SCORE_WEIGHTS
from ..metrics import CallScore
from ..log import log


class AngrAnalysis(AnalysisBackend):
    def __init__(
        self,
        target: Path,
        include_sym: t.List[str] = [],
        include_nontop: bool = False,
        skip_sym: t.List[str] = [],
        skip_stripped: bool = False,
        score_weights: t.List[float] = DEFAULT_SCORE_WEIGHTS,
    ):
        project = angr.Project(target, load_options={"auto_load_libs": False})
        super().__init__(
            project, include_sym, include_nontop, skip_sym, skip_stripped, score_weights
        )

        log.debug("Doing initial CFG analysis on target")
        self.cfg = self.target.analyses.CFG(
            resolve_indirect_jumps=True,
            cross_references=True,
            force_complete_scan=False,
            normalize=True,
            symbols=True,
        )

    def __str__(self) -> str:
        return "angr"

    def run(self) -> Fuzzability:
        log.debug("Iterating over functions")
        for func in self.cfg.functions.values():
            name = func.name
            addr = str(hex(func.addr))

            # just in case repeats show up again
            if name in self.visited:
                continue
            self.visited += [name]

            log.debug(f"Checking if we should ignore {name}")
            if self.skip_analysis(func):
                log.warning(f"Skipping {name} from fuzzability analysis.")
                self.skipped[name] = addr
                continue

            log.debug(f"Checking if {name} is a top-level call")
            if not self.include_nontop and not self.is_toplevel_call(func):
                log.warning(
                    f"Skipping {name} (not top-level) from fuzzability analysis."
                )
                self.skipped[name] = addr
                continue

            log.info(f"Starting analysis for function {name}")
            score = self.analyze_call(name, func)
            self.scores += [score]

        if len(self.scores) == 0:
            raise AnalysisException(
                "No suitable function symbols filtered for analysis."
            )

        return super()._rank_fuzzability(self.scores)

    def analyze_call(self, name: str, func: Function) -> CallScore:
        stripped = "sub_" in name
        addr = str(hex(func.addr))

        # no need to check if no name available
        # TODO: maybe we should run this if a signature was recovered
        fuzz_friendly = 0
        if not stripped:
            log.debug(f"{name} - checking if fuzz friendly")
            fuzz_friendly = AngrAnalysis.is_fuzz_friendly(name)

        return CallScore(
            name=name,
            loc=addr,
            toplevel=self.is_toplevel_call(func),
            fuzz_friendly=fuzz_friendly,
            risky_sinks=self.risky_sinks(func),
            natural_loops=self.natural_loops(func),
            coverage_depth=self.get_coverage_depth(func),
            cyclomatic_complexity=self.get_cyclomatic_complexity(func),
            stripped=stripped,
        )

    def skip_analysis(self, func: Function) -> bool:
        name = func.name

        if super().skip_analysis(name):
            return True

        # ignore imported functions or syscalls
        if func.is_syscall:
            return True

        # ignore common glibc calls
        if name in _libc_decls:
            return True

        # if set, ignore all stripped functions for faster analysis
        if "Unresolvable" in name:
            return True

        return False

    def is_toplevel_call(self, target: Function) -> bool:
        return (
            len(set(target._function_manager.callgraph.predecessors(target.addr))) == 0
        )

    def risky_sinks(self, func: Function) -> int:
        log.debug(f"{func.name} - checking for risky sinks")

        """
        # TODO: do an interprocedural analysis starting from the function
        func_cfg = self.target.analyses.CFGFast(
            start_at_entry=False,
            function_starts=[func.addr]
        )
        """

        risky_sinks = 0
        for cs in func.get_call_sites():
            insn = func.get_call_target(cs)
            call_site = self.cfg.kb.functions.function(addr=insn)

            # TODO: should we traverse further if not a imported func
            if AngrAnalysis._is_risky_call(call_site.name):
                risky_sinks += 1

            """
            rd = self.target.analyses.ReachingDefinitions(
                subject=func,
                func_graph=func.graph,
                cc=func.calling_convention,
                observation_points=[
                    (
                        "insn",
                        insn,
                        0,
                    )
                ],
                dep_graph=DepGraph(),
            )
            """

        return risky_sinks

    def get_coverage_depth(self, target: Function) -> int:
        """
        Calculates coverage depth by doing a depth first search on function call graph,
        and return a final depth and flag denoting recursive implementation.
        """
        log.debug(f"{target.name} - getting coverage depth")
        depth = 0

        # as we iterate over callees, add to a callstack and iterate over callees
        # for those as well, adding to the callgraph until we're done with all
        callstack = [target]
        while callstack:
            # increase depth as we finish iterating over callees for another func
            func = callstack.pop()
            depth += 1

            # add all childs to callgraph, and add those we haven't recursed into callstack
            for call in func.functions_called():
                if call.name not in self.visited:
                    callstack += [call]

                self.visited += [call.name]

        return depth

    def natural_loops(self, func: Function) -> int:
        log.debug(f"{func.name} - getting number of natural loops")
        dominance_frontier = self.target.analyses.DominanceFrontier(func)
        if dominance_frontier.frontiers:
            return len(dominance_frontier.frontiers)

        return 0

    def get_cyclomatic_complexity(self, func: Function) -> int:
        log.debug(f"{func.name} - calculating cyclomatic complexity")
        num_blocks = 0
        for _ in func.blocks:
            num_blocks += 1

        # do a CFG analysis starting at the func address
        cfg = self.target.analyses.CFGFast(
            force_complete_scan=False, start_at_entry=hex(func.addr)
        )
        num_edges = len(cfg.graph.edges())
        return num_edges - num_blocks + 2

```

`fuzzable/analysis/ast.py`:

```py
"""
ast.py

    Fuzzable analysis support for C/C++ code by through query on top of tree-sitter ASTs.

"""
import os
import typing as t

from pathlib import Path
from tree_sitter import Language, Node, Parser

from . import AnalysisBackend, Fuzzability, DEFAULT_SCORE_WEIGHTS
from ..metrics import CallScore
from ..log import log
from ..config import get_project_root, SOURCE_FILE_EXTS

# Compiled shared object for language support
BUILD_PATH = os.path.join(get_project_root(), "build/lang.so")


class AstAnalysis(AnalysisBackend):
    """Derived class to support parsing C/C++ ASTs with tree-sitter"""

    def __init__(
        self,
        target: t.List[str],
        include_sym: t.List[str] = [],
        include_nontop: bool = False,
        skip_sym: t.List[str] = [],
        score_weights: t.List[float] = DEFAULT_SCORE_WEIGHTS,
        basedir: t.Optional[Path] = None,
    ):
        super().__init__(target, include_sym, include_nontop, skip_sym, score_weights)

        log.debug("Building third-party tree-sitter libraries for C/C++ languages")
        Language.build_library(
            BUILD_PATH,
            [
                os.path.join(get_project_root(), "third_party/tree-sitter-c"),
                os.path.join(get_project_root(), "third_party/tree-sitter-cpp"),
            ],
        )
        self.language = Language(BUILD_PATH, "c")
        self.parser = Parser()

        # workplace to eventually strip from location
        self.basedir: t.Optional[Path] = basedir

        # store mapping between filenames and their raw contents and function AST node
        self.parsed_symbols: t.Dict[str, t.Tuple[Node, bytes]] = {}

        # cache if top level call
        self.is_top_level: bool = False

    def __str__(self) -> str:
        return "tree-sitter"

    def run(self) -> Fuzzability:
        """
        This runs on two passes:

            - an initial run to parse and map every single function AST object
            from the source codebase to their appropriate files
            - the actual run to conduct static analysis on each function's AST
        """

        # first collect ASTs for every function
        log.info("Collecting and parsing ASTs for each function call")
        for filename in self.target:
            self._parse_symbols(filename)

        # now analyze each function_definition node
        log.info("Statically analyzing and calculating fuzzability for each call")
        for filename, entry in self.parsed_symbols.items():
            nodes = entry[0]
            contents = entry[1]
            for node in nodes:
                path = f"{filename}:{node.start_point[0]}"

                log.debug(
                    f"Attempting to capture function symbol name for the current node AST at {path}"
                )
                query = self.language.query(
                    """
                (identifier) @capture
                """
                )

                # TODO make this query better, match more specifically
                try:
                    identifier = query.captures(node)[0][0]
                    name = contents[identifier.start_byte : identifier.end_byte].decode(
                        "utf8"
                    )
                except Exception as err:
                    log.warning(
                        f"Parsing failed for {node} in {filename}, reason: {err}"
                    )
                    self.skipped[name] = path
                    continue

                if name in self.visited:
                    log.debug(f"{node} - already analyzed previously")
                    continue
                self.visited += [name]

                log.debug(f"Checking if we should ignore {name}")
                if self.skip_analysis(name):
                    self.skipped[name] = path
                    log.warning(f"Skipping {name} from fuzzability analysis.")
                    continue

                log.debug(f"Checking if {name} is a top-level call")
                self.is_top_level = self.is_toplevel_call(name, node)
                if not self.include_nontop and not self.is_top_level:
                    log.warning(
                        f"Skipping {name} (not top-level) from fuzzability analysis."
                    )
                    self.skipped[name] = path
                    continue

                log.info(f"Starting analysis for function {name}")
                self.scores += [self.analyze_call(name, node, filename, contents)]

        return super()._rank_fuzzability(self.scores)

    def _parse_symbols(self, filename: Path) -> None:
        """Helper to recover all function implementations from a source target"""

        # fix up path if a basedir is present
        if self.basedir:
            filepath = filename.relative_to(self.basedir)
        else:
            filepath = filename

        # ignore all unit tests (TODO: enable)
        if "test" in str(filepath).lower():
            log.info(f"{filepath} - skipping as it's a potential unit test file")
            return None

        # switch over language if different language detected
        extension = filepath.suffix
        if extension in SOURCE_FILE_EXTS[1:]:
            self.language = Language(BUILD_PATH, "cpp")
        else:
            self.language = Language(BUILD_PATH, "c")

        self.parser.set_language(self.language)

        with open(filename, "rb") as source_file:
            contents = source_file.read()

        tree = self.parser.parse(contents)
        # log.debug(tree.root_node.sexp())

        log.debug(f"Grabbing function definitions in {filepath}")
        query = self.language.query(
            """
        (function_definition) @capture
        """
        )

        log.debug(f"Aggregating definition captures in {filepath}")

        # store function definition mappings for the file
        captures = [node for (node, _) in query.captures(tree.root_node)]
        self.parsed_symbols[filepath] = (captures, contents)

    def analyze_call(
        self, name: str, func: Node, filename: str, contents: bytes
    ) -> CallScore:
        return CallScore(
            name=name,
            loc=f"{filename}:{func.start_point[0]}",
            toplevel=self.is_top_level,
            fuzz_friendly=self.is_fuzz_friendly(name),
            risky_sinks=self.risky_sinks(func, contents),
            natural_loops=self.natural_loops(func),
            coverage_depth=self.get_coverage_depth(func),
            cyclomatic_complexity=self.get_cyclomatic_complexity(func),
            stripped=False,
        )

    def skip_analysis(self, name: str) -> bool:
        """Handles parsing edge cases that yield weird function nodes"""
        if super().skip_analysis(name):
            return True

        # name parsed is primitive type, skip
        if name in ["void", "int", "char"]:
            return True

        # TODO: might be type, make this check better tho
        if name.isupper() or name.endswith("_t") or "*" in name:
            return True

        return False

    def is_toplevel_call(self, name: str, node: Node) -> bool:
        """
        Function implementation should not be static, and has no parent
        callers.
        """

        # ignore if static function
        # TODO: deal with other edge cases and potential macro aliases
        if node.children[0].type == "storage_class_specifier":
            return False

        # get call_expressions for each function name
        for _, entry in self.parsed_symbols.items():
            nodes = entry[0]
            contents = entry[1]
            for node in nodes:
                query = self.language.query(
                    """
                (call_expression) @capture
                """
                )

                # get captured nodes and retrieve name for calls, determine if our current
                # target is a top-level call
                captures = [n for (n, _) in query.captures(node)]
                for capture in captures:
                    call_name = contents[capture.start_byte : capture.end_byte].decode(
                        "utf8"
                    )
                    if call_name == name:
                        return False

        return True

    def risky_sinks(self, func: Node, contents: bytes) -> int:
        """
        Parse the parameter list of the function AST, grab the callees, and
        check to see if the parameters flow into risky callees.

        TODO: this dataflow analysis is quite rudimentary and doesn't account
        for reassignments
        """
        log.debug(f"{func} - checking for risky sinks")

        # number of times an argument flows into a risky call
        instances = 0

        # grab the parameter list and parse the parameters on our own,
        # ignore if we don't have any parameters
        query = self.language.query(
            """
        (parameter_list) @capture
        """
        )
        captures = query.captures(func)
        if len(captures) == 0:
            return instances

        capture = [n for (n, _) in captures][0]
        param_list = contents[capture.start_byte + 1 : capture.end_byte - 1].decode(
            "utf8"
        )

        # recover only the param name
        # TODO: include types and make this better
        params = param_list.split(", ")

        # TODO: deal with no-name arguments betters
        try:
            params = [p.split(" ")[1].replace("*", "") for p in params]
        except IndexError:
            log.warning(
                f"{func} - cannot get risky sinks because fuzzable cannot parse the parameters"
            )
            return instances

        # TODO: should we add a configuration knob that supports just checking
        # for risky calls even if no arguments flow through them?
        if len(params) == 0:
            return instances

        # now get all callees in the function and check if parameters flow into them
        query = self.language.query(
            """
        (call_expression) @capture
        """
        )
        captures = [n for (n, _) in query.captures(func)]
        for callee in captures:
            call_name = contents[callee.start_byte : callee.end_byte].decode("utf8")
            if not AstAnalysis._is_risky_call(call_name):
                continue

            # grab and parse the argument list
            query = self.language.query(
                """
            (argument_list) @capture
            """
            )
            capture = [n for (n, _) in query.captures(callee)][0]
            arg_list = contents[capture.start_byte + 1 : capture.end_byte - 1].decode(
                "utf8"
            )
            args = arg_list.split(", ")

            # this should be unreachable
            if len(args) == 0:
                continue

            param_flows_to_arg = all(item in args for item in params)
            if param_flows_to_arg:
                instances += 1

        return instances

    def get_coverage_depth(self, func: Node) -> int:
        """
        TODO: make this traverse
        """
        log.debug(f"{func} - getting callgraph depth")
        call_query = self.language.query(
            """
        (call_expression) @capture
        """
        )
        return len([n for (n, _) in call_query.captures(func)])

    def natural_loops(self, func: Node) -> int:
        log.debug(f"{func} - getting number of natural loops")
        looping_nodes = [
            "do_statement",
            "for_range_loop",
            "for_statement",
            "while_statement",
        ]
        return self._visit_node(func, looping_nodes)

    def get_cyclomatic_complexity(self, func: Node) -> int:
        """
        M = E − N + 2P
        """
        log.debug(f"{func} - getting cyclomatic complexity")
        branching_nodes = [
            "if_statement",
            "case_statement",
            "do_statement",
            "for_range_loop",
            "for_statement",
            "goto_statement",
            "function_declarator",
            "pointer_declarator",
            "struct_specifier",
            "preproc_elif",
            "while_statement",
            "switch_statement",
            "&&",
            "||",
        ]
        return self._visit_node(func, branching_nodes)

    def _visit_node(self, node: Node, checklist: t.List[str]) -> int:
        count = 0
        if node.type in checklist:
            count += 1
        for child in node.children:
            count += self._visit_node(child, checklist)
        return count

```

`fuzzable/analysis/binja.py`:

```py
"""
binja.py

    Fuzzable analysis support for the Binary Ninja disassembler. Can be invoked both through 
    registered plugin handlers, and through a headless standalone CLI.

"""
import dataclasses
import os
import json
import pickle
import typing as t
import lief

from pathlib import Path

import binaryninja
import binaryninja.interaction as interaction
import binaryninja.demangle as demangle

from binaryninja import BinaryView
from binaryninja.log import Logger
from binaryninja.function import Function
from binaryninja.lowlevelil import LowLevelILReg
from binaryninja.enums import LowLevelILOperation, SymbolType
from binaryninja.plugin import BackgroundTaskThread
from binaryninja.settings import Settings

from .. import generate
from . import AnalysisBackend, Fuzzability, DEFAULT_SCORE_WEIGHTS, BASIC_FUZZABLE_ERROR
from ..metrics import CallScore, METRICS

log = Logger(0, "Fuzzable")


class _BinjaAnalysisMeta(type(AnalysisBackend), type(BackgroundTaskThread)):
    pass


class BinjaAnalysis(
    AnalysisBackend, BackgroundTaskThread, metaclass=_BinjaAnalysisMeta
):
    """Derived class to support Binary Ninja, and can be dispatched as a task from the plugin."""

    def __init__(
        self,
        target: BinaryView,
        include_sym: t.List[str] = [],
        include_nontop: bool = False,
        skip_sym: t.List[str] = [],
        skip_stripped: bool = False,
        score_weights: t.List[float] = DEFAULT_SCORE_WEIGHTS,
        headless: bool = False,
    ):
        AnalysisBackend.__init__(
            self,
            target,
            include_sym,
            include_nontop,
            skip_sym,
            skip_stripped,
            score_weights,
        )
        BackgroundTaskThread.__init__(
            self, "Finding fuzzable targets in current binary view"
        )
        self.view: BinaryView = target
        self.headless: bool = headless

    def __str__(self) -> str:
        return "Binary Ninja"

    def run(self) -> t.Optional[Fuzzability]:
        # interaction box before running to signal MCDA library is not available.
        # not needed for CLI since traditional logging will display the warning
        if BASIC_FUZZABLE_ERROR:
            interaction.show_message_box("Warning", BASIC_FUZZABLE_ERROR)

        self.view.update_analysis_and_wait()
        funcs = self.view.functions

        log.log_info(f"Starting fuzzable analysis over {len(funcs)} symbols in binary")
        for func in funcs:
            # demangle the symbol name
            name = demangle.simplify_name_to_string(func.name)
            addr = str(hex(func.address_ranges[0].start))

            log.log_debug(f"Checking if we should ignore {name}")
            if self.skip_analysis(func):
                log.log_warn(f"Skipping {name} from fuzzability analysis.")
                self.skipped[name] = addr
                continue

            log.log_debug(f"Checking if {name} is a top-level call")
            if not self.include_nontop and not self.is_toplevel_call(func):
                log.log_warn(
                    f"Skipping {name} (not top-level) from fuzzability analysis."
                )
                self.skipped[name] = addr
                continue

            log.log_info(f"Starting analysis for function {name}")
            score = self.analyze_call(name, func)
            self.scores += [score]

        log.log_info("Done, ranking the analyzed calls for reporting")
        ranked = super()._rank_fuzzability(self.scores)

        # if headless, handle displaying results back
        if not self.headless:
            return self._display_report(ranked)
        else:
            return ranked

    def _display_report(self, ranked: Fuzzability) -> None:
        """Helper to generate markdown report and create separate display"""

        # after successful analysis save/overwrite state first
        self.view.store_metadata("ranked", pickle.dumps(ranked))

        # TODO: reuse rich for markdown
        markdown_result = f"""# Fuzzable Targets

This is a generated report that ranks fuzzability of every parsed symbol that was recovered in this binary. If you feel that the results
are incomplete, wait for Binary Ninja's initial analysis to finalize and re-run this feature in the plugin.

__Number of Symbols Analyzed:__ {len(ranked)}

__Number of Symbols Skipped:__ {len(self.skipped)}

__Top Fuzzing Contender:__ [{ranked[0].name}](binaryninja://?expr={ranked[0].name})

## Ranked Functions

| Function Signature | Location          | Fuzzability Score | Fuzz-Friendly Name | Risky Data Sinks | Natural Loops | Cyclomatic Complexity | Coverage Depth |
|--------------------|-------------------|-------------------|--------------------|------------------|---------------|-----------------------|----------------|
"""
        for score in ranked:
            markdown_result += score.binja_markdown_row

        # save metadata string for potential exporting
        self.view.store_metadata("string", markdown_result)

        # if set include list of ignored symbols
        if Settings().get_bool("fuzzable.list_ignored"):
            markdown_result += "\n## Ignored Symbols\n"
            for name, loc in self.skipped.items():
                markdown_result += f"* [{name}](binaryninja://?expr={loc})"

        log.log_info("Displaying finalized results...")
        self.view.show_markdown_report("Fuzzable targets", markdown_result)

    def analyze_call(self, name: str, func: Function) -> CallScore:
        stripped = "sub_" in name

        # no need to check if no name available
        # TODO: maybe we should run this if a signature was recovered
        fuzz_friendly = 0
        if not stripped:
            fuzz_friendly = BinjaAnalysis.is_fuzz_friendly(name)

        return CallScore(
            name=name,
            loc=str(hex(func.address_ranges[0].start)),
            toplevel=self.is_toplevel_call(func),
            fuzz_friendly=fuzz_friendly,
            risky_sinks=self.risky_sinks(func),
            natural_loops=self.natural_loops(func),
            coverage_depth=self.get_coverage_depth(func),
            cyclomatic_complexity=self.get_cyclomatic_complexity(func),
            stripped=stripped,
        )

    def skip_analysis(self, func: Function) -> bool:
        name = func.name
        symbol = func.symbol.type
        log.log_debug(f"Checking if we should skip {name} ({symbol})")

        if super().skip_analysis(name):
            return True

        # ignore imported functions from other libraries, ie glibc or win32api
        if symbol in [
            SymbolType.ImportedFunctionSymbol,
            SymbolType.LibraryFunctionSymbol,
            SymbolType.ImportAddressSymbol,
            SymbolType.ImportedFunctionSymbol,
            SymbolType.ImportedDataSymbol,
        ]:
            log.log_debug(f"{name} is an import, skipping")
            return True

        return False

    def is_toplevel_call(self, target: Function) -> bool:
        return len(target.callers) == 0

    def risky_sinks(self, func: Function) -> int:
        """
        Find references of known insecure/risky calls, and check to see if there is an
        argument in the function call that flows into it. Will treat the current function
        target under an interprocedural analysis.
        """

        risky_sinks = 0
        visited = []

        # visit all other calls with depth-first search until we reach a risky sink
        callstack = [func]
        while callstack:
            func = callstack.pop()

            # Iterate over each argument and check for taint sinks
            for arg in func.parameter_vars:
                # if arg.type != "char*":
                #    continue

                arg_refs = func.get_hlil_var_refs(arg)

                log.log_debug(f"{func.name}: {arg_refs}")
                for ref in arg_refs:
                    insn = ref.arch.get_instruction_low_level_il_instruction(
                        self.view, ref.address
                    )

                    log.log_debug(f"{insn} - {insn.operation}")

                    # if call instruction, check out for risky pattern
                    if insn.operation in [
                        LowLevelILOperation.LLIL_CALL,
                        LowLevelILOperation.LLIL_JUMP,
                    ]:
                        # TODO deal with registers with addrs
                        if isinstance(insn.dest, LowLevelILReg):
                            continue

                        try:
                            callee = self.view.get_function_at(int(insn.dest))
                            call = callee.name
                        except Exception:
                            continue

                        # TODO: should we traverse further if not a imported func
                        if BinjaAnalysis._is_risky_call(call):
                            risky_sinks += 1

                        # otherwise add to callstack and continue to trace arguments
                        elif callee.name not in visited:
                            callstack += [callee]

                        visited += [callee.name]

        return risky_sinks

    def get_coverage_depth(self, target: Function) -> int:
        """
        Calculates coverage depth by doing a depth first search on function call graph,
        and return a final depth and flag denoting recursive implementation.
        """

        depth = 0

        # as we iterate over callees, add to a callstack and iterate over callees
        # for those as well, adding to the callgraph until we're done with all
        callstack = [target]
        while callstack:
            # increase depth as we finish iterating over callees for another func
            func = callstack.pop()
            depth += 1

            # add all childs to callgraph, and add those we haven't recursed into callstack
            for child in func.callees:
                # ignore recursive calls
                if child.name == target.name:
                    continue

                # if address attempt to resolve call
                if child.name not in self.visited:
                    callstack += [child]

            self.visited += [func.name]

        return depth

    def natural_loops(self, target: Function) -> int:
        return len([bb in bb.dominance_frontier for bb in target.basic_blocks])

    def get_cyclomatic_complexity(self, func: Function) -> int:
        num_blocks = len(func.basic_blocks)
        num_edges = sum([len(b.outgoing_edges) for b in func.basic_blocks])
        return num_edges - num_blocks + 2


def run_fuzzable(view: BinaryView) -> None:
    """Run analysis with default or globally configured fuzzable settings."""

    settings = Settings()
    task = BinjaAnalysis(
        view,
        include_sym=settings.get_string_list("fuzzable.include_sym"),
        include_nontop=settings.get_bool("fuzzable.include_nontop"),
        skip_sym=settings.get_string_list("fuzzable.skip_sym"),
        skip_stripped=settings.get_bool("fuzzable.skip_stripped"),
        score_weights=settings.get_string_list("fuzzable.score_weights"),
    )
    task.start()


def analysis_first(cb: t.Callable):
    """Decorator to ensure export functionality doesn't run without analysis first."""

    def inner(view: BinaryView):
        try:
            ranked = view.query_metadata("ranked")
        except KeyError:
            interaction.show_message_box(
                "Error", "Cannot export without running an analysis first."
            )
            return

        return cb(view, pickle.loads(ranked))

    return inner


@analysis_first
def run_export_csv(_: BinaryView, ranked: Fuzzability) -> None:
    """Generate a CSV report from a previous analysis"""

    log.log_debug(f"Generating CSV output from ranked functions")

    columns = [metric.friendly_name for metric in METRICS]
    csv_result = ",".join([f'"{column}"' for column in columns])
    csv_result += "\n"
    for score in ranked:
        csv_result += score.csv_row

    _export_interaction(csv_result, "csv")


@analysis_first
def run_export_json(_: BinaryView, ranked: Fuzzability) -> None:
    """Generate a JSON report from a previous analysis"""

    log.log_debug(f"Generating JSON output from ranked functions")
    json_result = json.dumps([dataclasses.asdict(score) for score in ranked])

    _export_interaction(json_result, "json")


@analysis_first
def run_export_md(view: BinaryView, _: Fuzzability) -> None:
    """Generate a markdown report from a previous analysis"""

    log.log_debug(f"Grabbing cached markdown report for export")
    try:
        markdown_output = view.query_metadata("md")
    except KeyError:
        interaction.show_message_box(
            "Error", "Cannot export without running an analysis first."
        )

    _export_interaction(markdown_output, "md")


def _export_interaction(contents: t.Any, extension: str) -> None:
    """Helper to grab filename input and write output to filesystem."""

    path = interaction.get_save_filename_input("Filename to export as?", extension)
    if path:
        path = path + "." + extension
    else:
        interaction.show_message_box(
            "Error", "Did not get required path name for export."
        )
        return

    # parse out template based on executable format, and start replacing
    with open(path, "w+", encoding="utf-8") as file:
        file.write(contents)

    interaction.show_message_box("Success", f"Done, exported to {path}")


def run_harness_generation(view, func: Function) -> None:
    """Experimental automatic fuzzer harness generation support"""

    log.log_debug("Grabbing closed-source template from project folder")
    template_file = os.path.join(
        binaryninja.user_plugin_path(),
        "fuzzable/templates/linux_closed_source_harness.cpp",
    )

    path = view.file.filename
    binary = lief.parse(path)

    # if stripped, get the address instead as the symbol
    symbol = func.name
    if "sub_" in symbol:
        symbol = hex(func.address_ranges[0].start)

    params: t.List[str] = [f"{param.type}" for param in func.parameter_vars.vars]
    return_type = str(func.return_type)

    log.log_debug("Getting filename to write to")
    harness = interaction.get_save_filename_input(
        "Harness path to write to?", "cpp", ""
    )
    if harness:
        harness = harness + ".cpp"
    else:
        interaction.show_message_box(
            "Error", "Did not get required C/C++ harness path."
        )
        return

    log.log_debug("Getting override shared object to write to")
    override_path = interaction.get_save_filename_input(
        "New shared object to write to?", "so", ""
    )

    if override_path:
        override_path = override_path + ".so"

    log.log_info("Generating harness from template")
    shared_obj = generate.transform_elf_to_so(Path(path), binary, symbol, override_path)
    generate.generate_harness(
        shared_obj,
        symbol,
        return_type=return_type,
        params=params,
        harness_path=template_file,
        output=harness,
    )

    interaction.show_message_box("Success", f"Done, wrote fuzzer harness to {harness}")

```

`fuzzable/cli.py`:

```py
"""
cli.py

    Utilities for printing things to the UI
"""
import sys
import json
import typer
import typing as t

from rich.console import Console
from rich.table import Table

from .analysis import Fuzzability, CallScore
from .metrics import METRICS
from .log import log

from io import StringIO
from pathlib import Path

ERROR_START = typer.style(
    "fuzzable error:",
    fg=typer.colors.WHITE,
    bg=typer.colors.RED,
)


def error(string: str) -> None:
    """Pretty-prints an error message and exits"""
    exception = typer.style(
        string,
        fg=typer.colors.RED,
    )
    typer.echo(f"{ERROR_START} {exception}")
    sys.exit(1)


def generate_table(target: Path, fuzzability: Fuzzability, ignore_metrics: bool):
    """Create a table from fuzzability results"""
    table = Table(
        title=f"Fuzzable Report for Target `{target}`",
        expand=True,
        safe_box=True,
    )

    # iterate over each field if flag is set, otherwise only first 3 pieces of info
    if not ignore_metrics:
        miter = METRICS
    else:
        miter = METRICS[0:3]

    for column in [metric.friendly_name for metric in miter]:
        table.add_column(column, style="magenta")

    for row in fuzzability:
        row_args = [str(getattr(row, metric.identifier)) for metric in miter]
        table.add_row(*row_args)

    return table


def print_table(
    target: Path,
    fuzzability: Fuzzability,
    skipped: t.Dict[str, str],
    ignore_metrics: bool,
    list_ignored: bool,
    table_export: bool = False,  # set by binja or another disassembler
) -> None:
    """Pretty-prints fuzzability results for the CLI"""

    table = generate_table(target, fuzzability, ignore_metrics)

    # console output is in-memory if table_export
    if table_export:
        console = Console(file=StringIO())
    else:
        console = Console(record=True)

    rprint = console.print
    rprint("\n")
    rprint(table)
    rprint("\n[bold red]ADDITIONAL METADATA[/bold red]\n")
    rprint(f"[underline]Number of Symbols Analyzed[/underline]: \t\t{len(fuzzability)}")
    rprint(f"[underline]Number of Symbols Skipped[/underline]: \t\t{len(skipped)}")
    rprint(f"[underline]Top Fuzzing Contender[/underline]: \t\t{fuzzability[0].name}\n")

    if list_ignored:
        rprint("\n[bold red]SKIPPED SYMBOLS[/bold red]\n")
        for name, loc in skipped.items():
            rprint(f"* {name} ({loc})")
        rprint("\n")

    # if argument is set, return the captured output
    if table_export:
        return console.file.getvalue()
    else:
        return None


def export_results(export: Path, results: t.List[CallScore]) -> None:
    """Given a file format and generated results, write to path."""
    writer = open(export, "w")
    ext = export.suffix
    if ext == ".json":
        writer.write(json.dumps([res.asdict() for res in results]))
    elif ext == ".csv":
        csv_header = ",".join([metric.identifier for metric in METRICS])
        writer.write(csv_header + "\n")
        for res in results:
            writer.write(res.csv_row)
    elif ext == ".md":
        pass

    log.info(f"Written fuzzability results to `{export}`!")
    writer.close()

```

`fuzzable/config.py`:

```py
"""
config.py

    Defines configuration knobs that can be universally configured by
    any fuzzable client
"""
import typing as t

import typer

from dataclasses import dataclass
from pathlib import Path


def get_project_root() -> Path:
    """Utility for getting root directory of this project"""
    return Path(__file__).parent.parent


@dataclass
class AnalysisKnobs:
    export: t.Optional[Path] = (
        typer.Option(
            None,
            "-e",
            "--export",
            help="Export the fuzzability report to a path based on the file extension."
            "Fuzzable supports exporting to `json`, `csv`, or `md`.",
        ),
    )
    list_ignored: bool = (
        typer.Option(
            False,
            help="If set, will also additionally output and/or export ignored symbols.",
        ),
    )
    include_sym: t.Optional[str] = (
        typer.Option(
            None,
            help="Comma-seperated list of symbols to absolutely be considered for analysis.",
        ),
    )
    include_nontop: bool = (
        typer.Option(
            False,
            help="If set, won't filter out only on top-level function definitions.",
        ),
    )
    skip_sym: t.Optional[str] = (
        typer.Option(
            None, help="Comma-seperated list of symbols to skip during analysis."
        ),
    )
    skip_stripped: bool = (
        typer.Option(
            False,
            help="If set, ignore symbols that are stripped in binary analysis."
            "Will be ignored if fuzzability analysis is done on source code.",
        ),
    )
    ignore_metrics: bool = (
        typer.Option(
            True,
            help="If set, include individual metrics' scores for each function target analyzed.",
        ),
    )
    score_weights: t.Optional[str] = (
        typer.Option(
            None,
            "-w",
            "--score-weights",
            help="Comma-seperated list of reconfigured weights for multi-criteria decision analysis when determining fuzzability.",
        ),
    )


# Supported C/C++ source code extensions
# TODO: we should do a very initial parse on the file to determine if it is C++ source
SOURCE_FILE_EXTS: t.List[str] = [".c", ".cpp", ".cc", ".cp" ".cxx", ".h", ".hpp", ".hh"]

GLOBAL_IGNORES: t.List[str] = [
    "__cxa_finalize",
    "__gmon_start__",
    "_init",
    "_fini",
    "frame_dummy",
    "call_weak_fn",
    "register_tm_clones",
    "$x",
]

# Interesting symbol name patterns to check for fuzzable
INTERESTING_PATTERNS: t.List[str] = [
    # Consuming Inputs
    "parse",
    "read",
    "buf",
    "file",
    "input",
    "str",
    # Decryption Routines
    "encode",
    "decode",
    # Other stuff
    "draw",
    "image",
    "img",
    "load",
    "url",
]

# Function name patterns that include INTERESTING_PATTERNS but
# may not be very useful/interesting to us
FALSE_POSITIVE_SIMILARS: t.List[str] = [
    # str
    "destroy"
]

# Data sink call names that should be deemed risky
# TODO: dataset of risky function calls
RISKY_GLIBC_CALL_PATTERNS: t.List[str] = [
    "cmp",
    "cpy",
    "alloc",
    "create",
]

```

`fuzzable/generate.py`:

```py
"""
generate.py

    Creates template harnesses for a given target.
"""
import os
import typing as t

import lief
from lief import ELF

from pathlib import Path

from .log import log
from .config import get_project_root


def generate_harness(
    target_path: str,
    function_name: str,
    return_type: t.Optional[str] = None,
    params: t.Optional[t.List[str]] = None,
    harness_path: t.Optional[str] = None,
    output: t.Optional[str] = None,
) -> None:
    """
    Populate a harness template with given parameters and generate harness to path.
    """

    abspath = os.path.basename(target_path)
    name = abspath.split(".")[0]

    # override template if set
    template_path = get_project_root() / "templates" / "linux_closed_source_harness.cpp"
    if harness_path:
        template_path = harness_path

    log.debug("Reading harness template")
    with open(template_path, "r", encoding="utf-8") as template_file:
        template = template_file.read()

    log.debug("Replacing parameters in template")
    template = template.replace("{NAME}", name)
    template = template.replace("{path}", abspath)
    template = template.replace("{function_name}", function_name)

    # these are optional and can be populated by the user
    if return_type:
        template = template.replace("{return_type}", return_type)
    if params:
        if len(params) != 0:
            template = template.replace("{type_args}", ",".join(params))

    # override harness output if set
    harness = f"{name}_{function_name}_harness.cpp"
    if output is not None:
        harness = output

    log.debug(f"Writing harness to path {harness}")
    with open(harness, "w", encoding="utf-8") as template_file:
        template_file.write(template)


def transform_elf_to_so(
    path: Path,
    lib: lief.Binary,
    export: t.Union[str, int],
    override_path: t.Optional[Path],
) -> t.Optional[Path]:
    """
    Helper that uses LIEF to check if an ELF executable can be transformed into a shared object
    with exported symbols for fuzzing.
    """

    # check if shared object or PIE binary
    # TODO: stronger checks for shared object
    log.info(f"Checking if {path} needs to be transformed into a shared object")
    if lib.header.file_type is not ELF.E_TYPE.DYNAMIC and ".so" in path.suffix:
        log.info("No need to transform binary into a shared object")
        return path

    log.info(f"Attempting to export the symbol in binary {export}")

    # if hex addr specified, export address directly and set name
    if isinstance(export, int):
        lib.add_exported_function(export, f"sub_{export}")

    # otherwise find the address of the symbol name and export it
    else:
        addr = lib.get_function_address(export)
        lib.add_exported_function(addr, export)

    # override the generated shared object to write to if set
    path = path.name.split(".")[0] + ".so"
    if override_path:
        path = str(override_path)

    log.info(
        f"Writing the ELF binary into a shared object for harness genaration at {path}"
    )
    lib.write(path)
    return Path(path)

```

`fuzzable/log.py`:

```py
"""
log.py
"""
import logging
from rich.logging import RichHandler

# hacky way to turn off angr verbosity
for log in ["angr", "pyvex", "claripy", "cle"]:
    logger = logging.getLogger(log)
    logger.disabled = True
    logger.propagate = False

FORMAT = "%(message)s"
logging.basicConfig(
    level=logging.WARNING, format=FORMAT, datefmt="[%X]", handlers=[RichHandler()]
)
log = logging.getLogger("fuzzable")

```

`fuzzable/metrics.py`:

```py
"""
metrics.py

    Dataclass definitions for various metrics collected during qthe risk analysis.
"""
import functools
import typing as t

from dataclasses import dataclass, field, asdict


@dataclass
class MetricSchema:
    # shorthand name
    identifier: str

    # how is displayed in the CLI/disassembly frontend
    friendly_name: str


# Stores all the static analysis metrics that fuzzable currently supports.
# This list should be expanded if additional metrics are to be introduced,
# alongside a new base method in the AnalysisBackend
METRICS: t.List[MetricSchema] = [
    MetricSchema(identifier="name", friendly_name="Function Signature"),
    MetricSchema(identifier="loc", friendly_name="Location"),
    MetricSchema(identifier="score", friendly_name="Fuzzability Score"),
    MetricSchema(identifier="fuzz_friendly", friendly_name="Fuzz-Friendly Name"),
    MetricSchema(identifier="risky_sinks", friendly_name="Risky Data Sinks"),
    MetricSchema(identifier="natural_loops", friendly_name="Natural Loops"),
    MetricSchema(
        identifier="cyclomatic_complexity", friendly_name="Cyclomatic Complexity"
    ),
    MetricSchema(identifier="coverage_depth", friendly_name="Coverage Depth"),
]


@dataclass
class CoverageReport:
    """TODO"""

    bb_depth: int
    function_depth: int
    ins_depth: int


@dataclass
class CallScore:
    """Assigned fuzzability score for an individual function target."""

    name: str
    loc: str

    # does not attribute to rank, but helps with determining what to filter
    toplevel: bool

    # does not attribute to rank, but helps with binary analysis
    stripped: t.Optional[bool]

    # quantifies the number of fuzzer friendly words that exist in the target's name
    fuzz_friendly: int

    # quantifies the number of fuzzer arguments that flow into
    risky_sinks: int

    # quantifies the number of natural loops in the BB graph
    natural_loops: int

    # quantifies complexity based on edges and nodes present
    cyclomatic_complexity: int

    # represents coverage by different granularities
    # coverage_depth: CoverageReport
    coverage_depth: int

    # mutable values that are to be set after analysis
    _final_rank: int = field(init=False, repr=False)
    _final_score: float = field(init=False, repr=False)

    """
    Getters and setters for calculated rank and score
    """

    @property
    def rank(self) -> int:
        """Rank of an individual function in a list of parsed functions"""
        return self._final_rank

    @rank.setter
    def rank(self, to_set: int) -> None:
        """Call to set the rank after analysis and ranking"""
        self._final_rank = float(to_set)

    @property
    def score(self) -> float:
        """Final calculated fuzzability score based on metrics"""
        return self._final_score

    @score.setter
    def score(self, to_set: float) -> None:
        """Call to set the fuzzability score after analysis and calculation"""
        self._final_score = float(to_set)

    """
    Overloaded operators for sorting
    """

    def __eq__(self, other):
        self._final_rank == other._final_rank

    def __lt__(self, other):
        self._final_rank < other._final_rank

    def __gt__(self, other):
        self._final_rank > other._final_rank

    """
    Properties to export score into flat structures
    """

    def asdict(self) -> t.Dict[str, t.Any]:
        return asdict(self)

    @property
    def matrix_row(self) -> t.List[int]:
        """Transforms attributes into a list of integers for a matrix"""
        return [
            self.fuzz_friendly,
            self.risky_sinks,
            self.natural_loops,
            self.coverage_depth,
            self.cyclomatic_complexity,
        ]

    @property
    def binja_markdown_row(self) -> str:
        """Output as a markdown/ascii table row when displaying back to user"""
        return f"| [{self.name}](binaryninja://?expr={self.name}) | {self.loc} | {self.score} | {self.fuzz_friendly} | {self.risky_sinks} | {self.natural_loops} | {self.cyclomatic_complexity} | {self.coverage_depth} | \n"

    @property
    def csv_row(self) -> str:
        """Generate a CSV row for exporting to file"""
        return f"{self.name},{self.loc},{self.stripped},{self.fuzz_friendly},{self.risky_sinks},{self.natural_loops},{self.cyclomatic_complexity},{self.coverage_depth},{self.score}\n"

    @functools.cached_property
    def simple_fuzzability(self) -> int:
        """Simple fuzzability"""
        self._final_score = sum(self.matrix_row)
        return self._final_score

```

`plugin.json`:

```json
{
    "pluginmetadataversion": 2,
    "name": "Fuzzable",
    "author": "ex0dus-0x",
    "type": [
        "ui"
    ],
    "api": [
        "python3"
    ],
    "description": "Framework for Automating Fuzzable Target Discovery with Static Analysis",
    "longdescription": "This is a helper Binary Ninja plugin to assist in identifying functions that are optimal targets for fuzzing and dynamic analysis. This is useful for vulnerability researchers wanting to fuzz executables or libraries without manual reverse engineering, and need some fast insight about what functions are potential targets to extrapolate for their harnesses.",
    "license": {
        "name": "MIT",
        "text": "Copyright 2022 @ex0dus-0x Permission is hereby granted, free of charge, to any person obtaining a copy of this software and associated documentation files (the 'Software'), to deal in the Software without restriction, including without limitation the rights to use, copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software, and to permit persons to whom the Software is furnished to do so, subject to the following conditions: The above copyright notice and this permission notice shall be included in all copies or substantial portions of the Software. THE SOFTWARE IS PROVIDED 'AS IS', WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE SOFTWARE."
    },
    "platforms": [
        "Darwin",
        "Windows",
        "Linux"
   ],
   "installinstructions": {
       "Darwin": "",
       "Windows": "",
       "Linux": ""
   },
   "version": "2.0.6",
   "minimumbinaryninjaversion": 1500
}

```

`poetry.lock`:

```lock
[[package]]
name = "ailment"
version = "9.2.43"
description = "The angr intermediate language."
category = "main"
optional = false
python-versions = ">=3.8"

[package.extras]
docs = ["furo", "myst-parser", "sphinx", "sphinx-autodoc-typehints"]

[[package]]
name = "angr"
version = "9.2.43"
description = "A multi-architecture binary analysis toolkit, with the ability to perform dynamic symbolic execution and various static analyses on binaries"
category = "main"
optional = false
python-versions = ">=3.8"

[package.dependencies]
ailment = "9.2.43"
archinfo = "9.2.43"
cachetools = "*"
capstone = ">=3.0.5rc2,<5.0.0rc2 || >5.0.0rc2"
cffi = ">=1.14.0"
claripy = "9.2.43"
cle = "9.2.43"
colorama = {version = "*", markers = "platform_system == \"Windows\""}
CppHeaderParser = "*"
dpkt = "*"
GitPython = "*"
itanium-demangler = "*"
mulpyplexer = "*"
nampa = "*"
networkx = ">=2.0,<2.8.1 || >2.8.1"
progressbar2 = ">=3"
protobuf = ">=3.19.0"
psutil = "*"
pycparser = ">=2.18"
pyvex = "9.2.43"
rpyc = "*"
sortedcontainers = "*"
sympy = "*"
unicorn = "2.0.1.post1"

[package.extras]
angrdb = ["sqlalchemy"]
docs = ["furo", "myst-parser", "sphinx", "sphinx-autodoc-typehints"]
pcode = ["pypcode (>=1.1)"]

[[package]]
name = "archinfo"
version = "9.2.43"
description = "Classes with architecture-specific information useful to other projects."
category = "main"
optional = false
python-versions = ">=3.8"

[package.extras]
docs = ["furo", "myst-parser", "sphinx", "sphinx-autodoc-typehints"]
pcode = ["pypcode (>=1.1)"]

[[package]]
name = "astroid"
version = "2.15.0"
description = "An abstract syntax tree for Python with inference support."
category = "dev"
optional = false
python-versions = ">=3.7.2"

[package.dependencies]
lazy-object-proxy = ">=1.4.0"
typing-extensions = {version = ">=4.0.0", markers = "python_version < \"3.11\""}
wrapt = [
    {version = ">=1.11,<2", markers = "python_version < \"3.11\""},
    {version = ">=1.14,<2", markers = "python_version >= \"3.11\""},
]

[[package]]
name = "attrs"
version = "22.2.0"
description = "Classes Without Boilerplate"
category = "dev"
optional = false
python-versions = ">=3.6"

[package.extras]
cov = ["attrs", "coverage-enable-subprocess", "coverage[toml] (>=5.3)"]
dev = ["attrs"]
docs = ["furo", "sphinx", "myst-parser", "zope.interface", "sphinx-notfound-page", "sphinxcontrib-towncrier", "towncrier"]
tests = ["attrs", "zope.interface"]
tests-no-zope = ["hypothesis", "pympler", "pytest (>=4.3.0)", "pytest-xdist", "cloudpickle", "mypy (>=0.971,<0.990)", "pytest-mypy-plugins"]
tests_no_zope = ["hypothesis", "pympler", "pytest (>=4.3.0)", "pytest-xdist", "cloudpickle", "mypy (>=0.971,<0.990)", "pytest-mypy-plugins"]

[[package]]
name = "backoff"
version = "2.1.2"
description = "Function decoration for backoff and retry"
category = "dev"
optional = false
python-versions = ">=3.7,<4.0"

[[package]]
name = "bitstring"
version = "4.0.1"
description = "Simple construction, analysis and modification of binary data."
category = "main"
optional = false
python-versions = ">=3.7"

[[package]]
name = "black"
version = "22.12.0"
description = "The uncompromising code formatter."
category = "dev"
optional = false
python-versions = ">=3.7"

[package.dependencies]
click = ">=8.0.0"
mypy-extensions = ">=0.4.3"
pathspec = ">=0.9.0"
platformdirs = ">=2"
tomli = {version = ">=1.1.0", markers = "python_full_version < \"3.11.0a7\""}
typing-extensions = {version = ">=3.10.0.0", markers = "python_version < \"3.10\""}

[package.extras]
colorama = ["colorama (>=0.4.3)"]
d = ["aiohttp (>=3.7.4)"]
jupyter = ["ipython (>=7.8.0)", "tokenize-rt (>=3.2.0)"]
uvloop = ["uvloop (>=0.15.2)"]

[[package]]
name = "cachetools"
version = "5.3.0"
description = "Extensible memoizing collections and decorators"
category = "main"
optional = false
python-versions = "~=3.7"

[[package]]
name = "capstone"
version = "5.0.0"
description = "Capstone disassembly engine"
category = "main"
optional = false
python-versions = ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*"

[[package]]
name = "certifi"
version = "2022.12.7"
description = "Python package for providing Mozilla's CA Bundle."
category = "dev"
optional = false
python-versions = ">=3.6"

[[package]]
name = "cffi"
version = "1.15.1"
description = "Foreign Function Interface for Python calling C code."
category = "main"
optional = false
python-versions = "*"

[package.dependencies]
pycparser = "*"

[[package]]
name = "charset-normalizer"
version = "3.1.0"
description = "The Real First Universal Charset Detector. Open, modern and actively maintained alternative to Chardet."
category = "dev"
optional = false
python-versions = ">=3.7.0"

[[package]]
name = "claripy"
version = "9.2.43"
description = "An abstraction layer for constraint solvers"
category = "main"
optional = false
python-versions = ">=3.8"

[package.dependencies]
cachetools = "*"
decorator = "*"
pysmt = ">=0.9.5"
z3-solver = "4.10.2.0"

[package.extras]
cvc4_solver = ["cvc4-solver"]
docs = ["furo", "myst-parser", "sphinx", "sphinx-autodoc-typehints"]

[[package]]
name = "cle"
version = "9.2.43"
description = "|"
category = "main"
optional = false
python-versions = ">=3.8"

[package.dependencies]
pefile = "*"
pyelftools = ">=0.27"
pyvex = "9.2.43"
sortedcontainers = ">=2.0"

[package.extras]
ar = ["arpy (==1.1.1)"]
docs = ["furo", "myst-parser", "sphinx", "sphinx-autodoc-typehints"]
minidump = ["minidump (>=0.0.10)"]
pcode = ["pypcode (>=1.1)"]
testing = ["cffi"]
xbe = ["pyxbe (==0.0.4)"]

[[package]]
name = "click"
version = "8.1.3"
description = "Composable command line interface toolkit"
category = "main"
optional = false
python-versions = ">=3.7"

[package.dependencies]
colorama = {version = "*", markers = "platform_system == \"Windows\""}

[[package]]
name = "colorama"
version = "0.4.6"
description = "Cross-platform colored terminal text."
category = "main"
optional = false
python-versions = "!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,!=3.5.*,!=3.6.*,>=2.7"

[[package]]
name = "commonmark"
version = "0.9.1"
description = "Python parser for the CommonMark Markdown spec"
category = "main"
optional = false
python-versions = "*"

[package.extras]
test = ["flake8 (==3.7.8)", "hypothesis (==3.55.3)"]

[[package]]
name = "contourpy"
version = "1.0.7"
description = "Python library for calculating contours of 2D quadrilateral grids"
category = "main"
optional = false
python-versions = ">=3.8"

[package.dependencies]
numpy = ">=1.16"

[package.extras]
bokeh = ["bokeh", "chromedriver", "selenium"]
docs = ["furo", "sphinx-copybutton"]
mypy = ["contourpy", "docutils-stubs", "mypy (==0.991)", "types-pillow"]
test = ["matplotlib", "pillow", "pytest"]
test-no-images = ["pytest"]

[[package]]
name = "cppheaderparser"
version = "2.7.4"
description = "Parse C++ header files and generate a data structure representing the class"
category = "main"
optional = false
python-versions = "*"

[package.dependencies]
ply = "*"

[[package]]
name = "cssselect"
version = "1.2.0"
description = "cssselect parses CSS3 Selectors and translates them to XPath 1.0"
category = "main"
optional = false
python-versions = ">=3.7"

[[package]]
name = "custom-inherit"
version = "2.4.1"
description = "A Python package that provides customized docstring inheritance       schemes between derived classes and their parents."
category = "main"
optional = false
python-versions = "*"

[[package]]
name = "cycler"
version = "0.11.0"
description = "Composable style cycles"
category = "main"
optional = false
python-versions = ">=3.6"

[[package]]
name = "decorator"
version = "5.1.1"
description = "Decorators for Humans"
category = "main"
optional = false
python-versions = ">=3.5"

[[package]]
name = "deprecated"
version = "1.2.13"
description = "Python @deprecated decorator to deprecate old python classes, functions or methods."
category = "main"
optional = false
python-versions = ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*"

[package.dependencies]
wrapt = ">=1.10,<2"

[package.extras]
dev = ["tox", "bump2version (<1)", "sphinx (<2)", "importlib-metadata (<3)", "importlib-resources (<4)", "configparser (<5)", "sphinxcontrib-websupport (<2)", "zipp (<2)", "PyTest (<5)", "PyTest-Cov (<2.6)", "pytest", "pytest-cov"]

[[package]]
name = "dill"
version = "0.3.6"
description = "serialize all of python"
category = "dev"
optional = false
python-versions = ">=3.7"

[package.extras]
graph = ["objgraph (>=1.7.2)"]

[[package]]
name = "dpkt"
version = "1.9.8"
description = "fast, simple packet creation / parsing, with definitions for the basic TCP/IP protocols"
category = "main"
optional = false
python-versions = "*"

[[package]]
name = "exceptiongroup"
version = "1.1.1"
description = "Backport of PEP 654 (exception groups)"
category = "dev"
optional = false
python-versions = ">=3.7"

[package.extras]
test = ["pytest (>=6)"]

[[package]]
name = "fonttools"
version = "4.39.2"
description = "Tools to manipulate font files"
category = "main"
optional = false
python-versions = ">=3.8"

[package.extras]
all = ["fs (>=2.2.0,<3)", "lxml (>=4.0,<5)", "zopfli (>=0.1.4)", "lz4 (>=1.7.4.2)", "matplotlib", "sympy", "skia-pathops (>=0.5.0)", "uharfbuzz (>=0.23.0)", "brotlicffi (>=0.8.0)", "scipy", "brotli (>=1.0.1)", "munkres", "unicodedata2 (>=15.0.0)", "xattr"]
graphite = ["lz4 (>=1.7.4.2)"]
interpolatable = ["scipy", "munkres"]
lxml = ["lxml (>=4.0,<5)"]
pathops = ["skia-pathops (>=0.5.0)"]
plot = ["matplotlib"]
repacker = ["uharfbuzz (>=0.23.0)"]
symfont = ["sympy"]
type1 = ["xattr"]
ufo = ["fs (>=2.2.0,<3)"]
unicode = ["unicodedata2 (>=15.0.0)"]
woff = ["zopfli (>=0.1.4)", "brotlicffi (>=0.8.0)", "brotli (>=1.0.1)"]

[[package]]
name = "future"
version = "0.18.3"
description = "Clean single-source support for Python 3 and 2"
category = "main"
optional = false
python-versions = ">=2.6, !=3.0.*, !=3.1.*, !=3.2.*"

[[package]]
name = "gitdb"
version = "4.0.10"
description = "Git Object Database"
category = "main"
optional = false
python-versions = ">=3.7"

[package.dependencies]
smmap = ">=3.0.1,<6"

[[package]]
name = "githubrelease"
version = "1.5.9"
description = "githubrelease is a CLI to easily manage GitHub releases, assets and references"
category = "dev"
optional = false
python-versions = "*"

[package.dependencies]
backoff = ">=2.1.2,<2.2.0"
click = "*"
linkheader = "*"
requests = "*"

[[package]]
name = "gitpython"
version = "3.1.31"
description = "GitPython is a Python library used to interact with Git repositories"
category = "main"
optional = false
python-versions = ">=3.7"

[package.dependencies]
gitdb = ">=4.0.1,<5"

[[package]]
name = "idna"
version = "3.4"
description = "Internationalized Domain Names in Applications (IDNA)"
category = "dev"
optional = false
python-versions = ">=3.5"

[[package]]
name = "importlib-resources"
version = "5.12.0"
description = "Read resources from Python packages"
category = "main"
optional = false
python-versions = ">=3.7"

[package.dependencies]
zipp = {version = ">=3.1.0", markers = "python_version < \"3.10\""}

[package.extras]
docs = ["sphinx (>=3.5)", "jaraco.packaging (>=9)", "rst.linker (>=1.9)", "furo", "sphinx-lint", "jaraco.tidelift (>=1.4)"]
testing = ["pytest (>=6)", "pytest-checkdocs (>=2.4)", "flake8 (<5)", "pytest-cov", "pytest-enabler (>=1.3)", "pytest-black (>=0.3.7)", "pytest-mypy (>=0.9.1)", "pytest-flake8"]

[[package]]
name = "iniconfig"
version = "2.0.0"
description = "brain-dead simple config-ini parsing"
category = "dev"
optional = false
python-versions = ">=3.7"

[[package]]
name = "isort"
version = "5.12.0"
description = "A Python utility / library to sort Python imports."
category = "dev"
optional = false
python-versions = ">=3.8.0"

[package.extras]
colors = ["colorama (>=0.4.3)"]
requirements-deprecated-finder = ["pip-api", "pipreqs"]
pipfile-deprecated-finder = ["pip-shims (>=0.5.2)", "pipreqs", "requirementslib"]
plugins = ["setuptools"]

[[package]]
name = "itanium-demangler"
version = "1.1"
description = "Pure Python parser for mangled itanium symbols"
category = "main"
optional = false
python-versions = "*"

[[package]]
name = "jinja2"
version = "3.1.2"
description = "A very fast and expressive template engine."
category = "main"
optional = false
python-versions = ">=3.7"

[package.dependencies]
MarkupSafe = ">=2.0"

[package.extras]
i18n = ["Babel (>=2.7)"]

[[package]]
name = "kiwisolver"
version = "1.4.4"
description = "A fast implementation of the Cassowary constraint solver"
category = "main"
optional = false
python-versions = ">=3.7"

[[package]]
name = "lazy-object-proxy"
version = "1.9.0"
description = "A fast and thorough lazy object proxy."
category = "dev"
optional = false
python-versions = ">=3.7"

[[package]]
name = "lief"
version = "0.12.3"
description = "Library to instrument executable formats"
category = "main"
optional = false
python-versions = ">=3.6"

[[package]]
name = "linkheader"
version = "0.4.3"
description = "Parse and format link headers according to RFC 5988 \"Web Linking\""
category = "dev"
optional = false
python-versions = "*"

[[package]]
name = "lxml"
version = "4.9.2"
description = "Powerful and Pythonic XML processing library combining libxml2/libxslt with the ElementTree API."
category = "main"
optional = false
python-versions = ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, != 3.4.*"

[package.extras]
cssselect = ["cssselect (>=0.7)"]
html5 = ["html5lib"]
htmlsoup = ["beautifulsoup4"]
source = ["Cython (>=0.29.7)"]

[[package]]
name = "markupsafe"
version = "2.1.2"
description = "Safely add untrusted strings to HTML/XML markup."
category = "main"
optional = false
python-versions = ">=3.7"

[[package]]
name = "matplotlib"
version = "3.7.1"
description = "Python plotting package"
category = "main"
optional = false
python-versions = ">=3.8"

[package.dependencies]
contourpy = ">=1.0.1"
cycler = ">=0.10"
fonttools = ">=4.22.0"
importlib-resources = {version = ">=3.2.0", markers = "python_version < \"3.10\""}
kiwisolver = ">=1.0.1"
numpy = ">=1.20"
packaging = ">=20.0"
pillow = ">=6.2.0"
pyparsing = ">=2.3.1"
python-dateutil = ">=2.7"
setuptools_scm = ">=7"

[[package]]
name = "mccabe"
version = "0.7.0"
description = "McCabe checker, plugin for flake8"
category = "dev"
optional = false
python-versions = ">=3.6"

[[package]]
name = "mpmath"
version = "1.3.0"
description = "Python library for arbitrary-precision floating-point arithmetic"
category = "main"
optional = false
python-versions = "*"

[package.extras]
develop = ["pytest (>=4.6)", "pycodestyle", "pytest-cov", "codecov", "wheel"]
docs = ["sphinx"]
gmpy = ["gmpy2 (>=2.1.0a4)"]
tests = ["pytest (>=4.6)"]

[[package]]
name = "mulpyplexer"
version = "0.09"
description = "A module that multiplexes interactions with lists of python objects."
category = "main"
optional = false
python-versions = "*"

[[package]]
name = "mypy"
version = "0.961"
description = "Optional static typing for Python"
category = "dev"
optional = false
python-versions = ">=3.6"

[package.dependencies]
mypy-extensions = ">=0.4.3"
tomli = {version = ">=1.1.0", markers = "python_version < \"3.11\""}
typing-extensions = ">=3.10"

[package.extras]
dmypy = ["psutil (>=4.0)"]
python2 = ["typed-ast (>=1.4.0,<2)"]
reports = ["lxml"]

[[package]]
name = "mypy-extensions"
version = "1.0.0"
description = "Type system extensions for programs checked with the mypy type checker."
category = "dev"
optional = false
python-versions = ">=3.5"

[[package]]
name = "nampa"
version = "0.1.1"
description = "FLIRT signatures for python"
category = "main"
optional = false
python-versions = "*"

[package.dependencies]
future = "*"

[[package]]
name = "networkx"
version = "3.0"
description = "Python package for creating and manipulating graphs and networks"
category = "main"
optional = false
python-versions = ">=3.8"

[package.extras]
default = ["numpy (>=1.20)", "scipy (>=1.8)", "matplotlib (>=3.4)", "pandas (>=1.3)"]
developer = ["pre-commit (>=2.20)", "mypy (>=0.991)"]
doc = ["sphinx (==5.2.3)", "pydata-sphinx-theme (>=0.11)", "sphinx-gallery (>=0.11)", "numpydoc (>=1.5)", "pillow (>=9.2)", "nb2plots (>=0.6)", "texext (>=0.6.7)"]
extra = ["lxml (>=4.6)", "pygraphviz (>=1.10)", "pydot (>=1.4.2)", "sympy (>=1.10)"]
test = ["pytest (>=7.2)", "pytest-cov (>=4.0)", "codecov (>=2.1)"]

[[package]]
name = "numpy"
version = "1.24.2"
description = "Fundamental package for array computing in Python"
category = "main"
optional = false
python-versions = ">=3.8"

[[package]]
name = "packaging"
version = "23.0"
description = "Core utilities for Python packages"
category = "main"
optional = false
python-versions = ">=3.7"

[[package]]
name = "pandas"
version = "1.5.3"
description = "Powerful data structures for data analysis, time series, and statistics"
category = "main"
optional = false
python-versions = ">=3.8"

[package.dependencies]
numpy = [
    {version = ">=1.20.3", markers = "python_version < \"3.10\""},
    {version = ">=1.21.0", markers = "python_version >= \"3.10\""},
    {version = ">=1.23.2", markers = "python_version >= \"3.11\""},
]
python-dateutil = ">=2.8.1"
pytz = ">=2020.1"

[package.extras]
test = ["hypothesis (>=5.5.3)", "pytest (>=6.0)", "pytest-xdist (>=1.31)"]

[[package]]
name = "pathspec"
version = "0.11.1"
description = "Utility library for gitignore style pattern matching of file paths."
category = "dev"
optional = false
python-versions = ">=3.7"

[[package]]
name = "pefile"
version = "2023.2.7"
description = "Python PE parsing module"
category = "main"
optional = false
python-versions = ">=3.6.0"

[[package]]
name = "pillow"
version = "9.4.0"
description = "Python Imaging Library (Fork)"
category = "main"
optional = false
python-versions = ">=3.7"

[package.extras]
docs = ["furo", "olefile", "sphinx (>=2.4)", "sphinx-copybutton", "sphinx-inline-tabs", "sphinx-issues (>=3.0.1)", "sphinx-removed-in", "sphinxext-opengraph"]
tests = ["check-manifest", "coverage", "defusedxml", "markdown2", "olefile", "packaging", "pyroma", "pytest", "pytest-cov", "pytest-timeout"]

[[package]]
name = "platformdirs"
version = "3.1.1"
description = "A small Python package for determining appropriate platform-specific dirs, e.g. a \"user data dir\"."
category = "dev"
optional = false
python-versions = ">=3.7"

[package.extras]
docs = ["furo (>=2022.12.7)", "proselint (>=0.13)", "sphinx-autodoc-typehints (>=1.22,!=1.23.4)", "sphinx (>=6.1.3)"]
test = ["appdirs (==1.4.4)", "covdefaults (>=2.2.2)", "pytest-cov (>=4)", "pytest-mock (>=3.10)", "pytest (>=7.2.1)"]

[[package]]
name = "pluggy"
version = "1.0.0"
description = "plugin and hook calling mechanisms for python"
category = "dev"
optional = false
python-versions = ">=3.6"

[package.extras]
dev = ["pre-commit", "tox"]
testing = ["pytest", "pytest-benchmark"]

[[package]]
name = "plumbum"
version = "1.8.1"
description = "Plumbum: shell combinators library"
category = "main"
optional = false
python-versions = ">=3.6"

[package.dependencies]
pywin32 = {version = "*", markers = "platform_system == \"Windows\" and platform_python_implementation != \"PyPy\""}

[package.extras]
dev = ["paramiko", "psutil", "pytest-cov", "pytest-mock", "pytest-timeout", "pytest (>=6.0)"]
docs = ["sphinx-rtd-theme (>=1.0.0)", "sphinx (>=4.0.0)"]
ssh = ["paramiko"]

[[package]]
name = "ply"
version = "3.11"
description = "Python Lex & Yacc"
category = "main"
optional = false
python-versions = "*"

[[package]]
name = "progressbar2"
version = "4.2.0"
description = "A Python Progressbar library to provide visual (yet text based) progress to long running operations."
category = "main"
optional = false
python-versions = ">=3.7.0"

[package.dependencies]
python-utils = ">=3.0.0"

[package.extras]
docs = ["sphinx (>=1.8.5)"]
tests = ["flake8 (>=3.7.7)", "pytest (>=4.6.9)", "pytest-cov (>=2.6.1)", "pytest-mypy", "freezegun (>=0.3.11)", "sphinx (>=1.8.5)"]

[[package]]
name = "protobuf"
version = "4.22.1"
description = ""
category = "main"
optional = false
python-versions = ">=3.7"

[[package]]
name = "psutil"
version = "5.9.4"
description = "Cross-platform lib for process and system monitoring in Python."
category = "main"
optional = false
python-versions = ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*"

[package.extras]
test = ["ipaddress", "mock", "enum34", "pywin32", "wmi"]

[[package]]
name = "pulp"
version = "2.7.0"
description = "PuLP is an LP modeler written in python. PuLP can generate MPS or LP files and call GLPK, COIN CLP/CBC, CPLEX, and GUROBI to solve linear problems."
category = "main"
optional = false
python-versions = "*"

[[package]]
name = "pycparser"
version = "2.21"
description = "C parser in Python"
category = "main"
optional = false
python-versions = ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*"

[[package]]
name = "pyelftools"
version = "0.29"
description = "Library for analyzing ELF files and DWARF debugging information"
category = "main"
optional = false
python-versions = "*"

[[package]]
name = "pygments"
version = "2.14.0"
description = "Pygments is a syntax highlighting package written in Python."
category = "main"
optional = false
python-versions = ">=3.6"

[package.extras]
plugins = ["importlib-metadata"]

[[package]]
name = "pylint"
version = "2.17.1"
description = "python code static checker"
category = "dev"
optional = false
python-versions = ">=3.7.2"

[package.dependencies]
astroid = ">=2.15.0,<=2.17.0-dev0"
colorama = {version = ">=0.4.5", markers = "sys_platform == \"win32\""}
dill = [
    {version = ">=0.2", markers = "python_version < \"3.11\""},
    {version = ">=0.3.6", markers = "python_version >= \"3.11\""},
]
isort = ">=4.2.5,<6"
mccabe = ">=0.6,<0.8"
platformdirs = ">=2.2.0"
tomli = {version = ">=1.1.0", markers = "python_version < \"3.11\""}
tomlkit = ">=0.10.1"
typing-extensions = {version = ">=3.10.0", markers = "python_version < \"3.10\""}

[package.extras]
spelling = ["pyenchant (>=3.2,<4.0)"]
testutils = ["gitpython (>3)"]

[[package]]
name = "pyparsing"
version = "3.0.9"
description = "pyparsing module - Classes and methods to define and execute parsing grammars"
category = "main"
optional = false
python-versions = ">=3.6.8"

[package.extras]
diagrams = ["railroad-diagrams", "jinja2"]

[[package]]
name = "pyquery"
version = "2.0.0"
description = "A jquery-like library for python"
category = "main"
optional = false
python-versions = "*"

[package.dependencies]
cssselect = ">=1.2.0"
lxml = ">=2.1"

[package.extras]
test = ["requests", "webob", "webtest", "pytest", "pytest-cov"]

[[package]]
name = "pysmt"
version = "0.9.5"
description = "A solver-agnostic library for SMT Formulae manipulation and solving"
category = "main"
optional = false
python-versions = "*"

[[package]]
name = "pytest"
version = "7.2.2"
description = "pytest: simple powerful testing with Python"
category = "dev"
optional = false
python-versions = ">=3.7"

[package.dependencies]
attrs = ">=19.2.0"
colorama = {version = "*", markers = "sys_platform == \"win32\""}
exceptiongroup = {version = ">=1.0.0rc8", markers = "python_version < \"3.11\""}
iniconfig = "*"
packaging = "*"
pluggy = ">=0.12,<2.0"
tomli = {version = ">=1.0.0", markers = "python_version < \"3.11\""}

[package.extras]
testing = ["argcomplete", "hypothesis (>=3.56)", "mock", "nose", "pygments (>=2.7.2)", "requests", "xmlschema"]

[[package]]
name = "python-dateutil"
version = "2.8.2"
description = "Extensions to the standard Python datetime module"
category = "main"
optional = false
python-versions = "!=3.0.*,!=3.1.*,!=3.2.*,>=2.7"

[package.dependencies]
six = ">=1.5"

[[package]]
name = "python-utils"
version = "3.5.2"
description = "Python Utils is a module with some convenient utilities not included with the standard Python install"
category = "main"
optional = false
python-versions = ">3.6.0"

[package.extras]
docs = ["mock", "sphinx", "python-utils"]
loguru = ["loguru"]
tests = ["flake8", "pytest", "pytest-cov", "pytest-mypy", "pytest-asyncio", "sphinx", "types-setuptools", "loguru"]

[[package]]
name = "pytz"
version = "2023.2"
description = "World timezone definitions, modern and historical"
category = "main"
optional = false
python-versions = "*"

[[package]]
name = "pyvex"
version = "9.2.43"
description = "A Python interface to libVEX and VEX IR"
category = "main"
optional = false
python-versions = ">=3.8"

[package.dependencies]
archinfo = "9.2.43"
bitstring = "*"
cffi = {version = ">=1.0.3", markers = "implementation_name == \"cpython\""}

[package.extras]
docs = ["furo", "myst-parser", "sphinx", "sphinx-autodoc-typehints"]

[[package]]
name = "pywin32"
version = "305"
description = "Python for Window Extensions"
category = "main"
optional = false
python-versions = "*"

[[package]]
name = "requests"
version = "2.28.2"
description = "Python HTTP for Humans."
category = "dev"
optional = false
python-versions = ">=3.7, <4"

[package.dependencies]
certifi = ">=2017.4.17"
charset-normalizer = ">=2,<4"
idna = ">=2.5,<4"
urllib3 = ">=1.21.1,<1.27"

[package.extras]
socks = ["PySocks (>=1.5.6,!=1.5.7)"]
use_chardet_on_py3 = ["chardet (>=3.0.2,<6)"]

[[package]]
name = "rich"
version = "12.6.0"
description = "Render rich text, tables, progress bars, syntax highlighting, markdown and more to the terminal"
category = "main"
optional = false
python-versions = ">=3.6.3,<4.0.0"

[package.dependencies]
commonmark = ">=0.9.0,<0.10.0"
pygments = ">=2.6.0,<3.0.0"
typing-extensions = {version = ">=4.0.0,<5.0", markers = "python_version < \"3.9\""}

[package.extras]
jupyter = ["ipywidgets (>=7.5.1,<8.0.0)"]

[[package]]
name = "rpyc"
version = "5.3.1"
description = "Remote Python Call (RPyC) is a transparent and symmetric distributed computing library"
category = "main"
optional = false
python-versions = ">=3.7"

[package.dependencies]
plumbum = "*"

[[package]]
name = "scikit-criteria"
version = "0.7"
description = "Scikit-Criteria is a collections of algorithms, methods and techniques for multiple-criteria decision analysis."
category = "main"
optional = false
python-versions = "*"

[package.dependencies]
custom_inherit = "*"
Deprecated = "*"
jinja2 = "*"
numpy = "*"
pandas = "*"
pulp = "*"
pyquery = "*"
scipy = "*"
seaborn = "*"

[[package]]
name = "scipy"
version = "1.9.3"
description = "Fundamental algorithms for scientific computing in Python"
category = "main"
optional = false
python-versions = ">=3.8"

[package.dependencies]
numpy = ">=1.18.5,<1.26.0"

[package.extras]
test = ["pytest", "pytest-cov", "pytest-xdist", "asv", "mpmath", "gmpy2", "threadpoolctl", "scikit-umfpack"]
doc = ["sphinx (!=4.1.0)", "pydata-sphinx-theme (==0.9.0)", "sphinx-panels (>=0.5.2)", "matplotlib (>2)", "numpydoc", "sphinx-tabs"]
dev = ["mypy", "typing-extensions", "pycodestyle", "flake8"]

[[package]]
name = "seaborn"
version = "0.12.2"
description = "Statistical data visualization"
category = "main"
optional = false
python-versions = ">=3.7"

[package.dependencies]
matplotlib = ">=3.1,<3.6.1 || >3.6.1"
numpy = ">=1.17,<1.24.0 || >1.24.0"
pandas = ">=0.25"

[package.extras]
dev = ["pytest", "pytest-cov", "pytest-xdist", "flake8", "mypy", "pandas-stubs", "pre-commit", "flit"]
docs = ["numpydoc", "nbconvert", "ipykernel", "sphinx-copybutton", "sphinx-issues", "sphinx-design", "pyyaml", "pydata_sphinx_theme (==0.10.0rc2)"]
stats = ["scipy (>=1.3)", "statsmodels (>=0.10)"]

[[package]]
name = "setuptools-scm"
version = "7.1.0"
description = "the blessed package to manage your versions by scm tags"
category = "main"
optional = false
python-versions = ">=3.7"

[package.dependencies]
packaging = ">=20.0"
tomli = {version = ">=1.0.0", markers = "python_version < \"3.11\""}
typing-extensions = "*"

[package.extras]
test = ["pytest (>=6.2)", "virtualenv (>20)"]
toml = ["setuptools (>=42)"]

[[package]]
name = "shellingham"
version = "1.5.1"
description = "Tool to Detect Surrounding Shell"
category = "main"
optional = false
python-versions = ">=3.7"

[[package]]
name = "six"
version = "1.16.0"
description = "Python 2 and 3 compatibility utilities"
category = "main"
optional = false
python-versions = ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*"

[[package]]
name = "smmap"
version = "5.0.0"
description = "A pure Python implementation of a sliding window memory map manager"
category = "main"
optional = false
python-versions = ">=3.6"

[[package]]
name = "sortedcontainers"
version = "2.4.0"
description = "Sorted Containers -- Sorted List, Sorted Dict, Sorted Set"
category = "main"
optional = false
python-versions = "*"

[[package]]
name = "sympy"
version = "1.11.1"
description = "Computer algebra system (CAS) in Python"
category = "main"
optional = false
python-versions = ">=3.8"

[package.dependencies]
mpmath = ">=0.19"

[[package]]
name = "tomli"
version = "2.0.1"
description = "A lil' TOML parser"
category = "main"
optional = false
python-versions = ">=3.7"

[[package]]
name = "tomlkit"
version = "0.11.6"
description = "Style preserving TOML library"
category = "dev"
optional = false
python-versions = ">=3.6"

[[package]]
name = "tree-sitter"
version = "0.20.1"
description = "Python bindings to the Tree-sitter parsing library"
category = "main"
optional = false
python-versions = ">=3.3"

[[package]]
name = "typer"
version = "0.6.1"
description = "Typer, build great CLIs. Easy to code. Based on Python type hints."
category = "main"
optional = false
python-versions = ">=3.6"

[package.dependencies]
click = ">=7.1.1,<9.0.0"
colorama = {version = ">=0.4.3,<0.5.0", optional = true, markers = "extra == \"all\""}
rich = {version = ">=10.11.0,<13.0.0", optional = true, markers = "extra == \"all\""}
shellingham = {version = ">=1.3.0,<2.0.0", optional = true, markers = "extra == \"all\""}

[package.extras]
all = ["colorama (>=0.4.3,<0.5.0)", "shellingham (>=1.3.0,<2.0.0)", "rich (>=10.11.0,<13.0.0)"]
dev = ["autoflake (>=1.3.1,<2.0.0)", "flake8 (>=3.8.3,<4.0.0)", "pre-commit (>=2.17.0,<3.0.0)"]
doc = ["mkdocs (>=1.1.2,<2.0.0)", "mkdocs-material (>=8.1.4,<9.0.0)", "mdx-include (>=1.4.1,<2.0.0)"]
test = ["shellingham (>=1.3.0,<2.0.0)", "pytest (>=4.4.0,<5.4.0)", "pytest-cov (>=2.10.0,<3.0.0)", "coverage (>=5.2,<6.0)", "pytest-xdist (>=1.32.0,<2.0.0)", "pytest-sugar (>=0.9.4,<0.10.0)", "mypy (==0.910)", "black (>=22.3.0,<23.0.0)", "isort (>=5.0.6,<6.0.0)", "rich (>=10.11.0,<13.0.0)"]

[[package]]
name = "typing-extensions"
version = "4.5.0"
description = "Backported and Experimental Type Hints for Python 3.7+"
category = "main"
optional = false
python-versions = ">=3.7"

[[package]]
name = "unicorn"
version = "2.0.1.post1"
description = "Unicorn CPU emulator engine"
category = "main"
optional = false
python-versions = "*"

[[package]]
name = "urllib3"
version = "1.26.15"
description = "HTTP library with thread-safe connection pooling, file post, and more."
category = "dev"
optional = false
python-versions = ">=2.7, !=3.0.*, !=3.1.*, !=3.2.*, !=3.3.*, !=3.4.*, !=3.5.*"

[package.extras]
brotli = ["brotlicffi (>=0.8.0)", "brotli (>=1.0.9)", "brotlipy (>=0.6.0)"]
secure = ["pyOpenSSL (>=0.14)", "cryptography (>=1.3.4)", "idna (>=2.0.0)", "certifi", "urllib3-secure-extra", "ipaddress"]
socks = ["PySocks (>=1.5.6,!=1.5.7,<2.0)"]

[[package]]
name = "wrapt"
version = "1.15.0"
description = "Module for decorators, wrappers and monkey patching."
category = "main"
optional = false
python-versions = "!=3.0.*,!=3.1.*,!=3.2.*,!=3.3.*,!=3.4.*,>=2.7"

[[package]]
name = "z3-solver"
version = "4.10.2.0"
description = "an efficient SMT solver library"
category = "main"
optional = false
python-versions = "*"

[[package]]
name = "zipp"
version = "3.15.0"
description = "Backport of pathlib-compatible object wrapper for zip files"
category = "main"
optional = false
python-versions = ">=3.7"

[package.extras]
docs = ["sphinx (>=3.5)", "jaraco.packaging (>=9)", "rst.linker (>=1.9)", "furo", "sphinx-lint", "jaraco.tidelift (>=1.4)"]
testing = ["pytest (>=6)", "pytest-checkdocs (>=2.4)", "flake8 (<5)", "pytest-cov", "pytest-enabler (>=1.3)", "jaraco.itertools", "jaraco.functools", "more-itertools", "big-o", "pytest-black (>=0.3.7)", "pytest-mypy (>=0.9.1)", "pytest-flake8"]

[metadata]
lock-version = "1.1"
python-versions = "^3.8"
content-hash = "4bc479c98cb8454158750032b085a5f890dd45c90c6337672b3f0797acc9d83b"

[metadata.files]
ailment = []
angr = []
archinfo = []
astroid = []
attrs = []
backoff = []
bitstring = []
black = []
cachetools = []
capstone = []
certifi = []
cffi = []
charset-normalizer = []
claripy = []
cle = []
click = []
colorama = []
commonmark = []
contourpy = []
cppheaderparser = []
cssselect = []
custom-inherit = []
cycler = []
decorator = []
deprecated = []
dill = []
dpkt = []
exceptiongroup = []
fonttools = []
future = []
gitdb = []
githubrelease = []
gitpython = []
idna = []
importlib-resources = []
iniconfig = []
isort = []
itanium-demangler = []
jinja2 = []
kiwisolver = []
lazy-object-proxy = []
lief = []
linkheader = []
lxml = []
markupsafe = []
matplotlib = []
mccabe = []
mpmath = []
mulpyplexer = []
mypy = []
mypy-extensions = []
nampa = []
networkx = []
numpy = []
packaging = []
pandas = []
pathspec = []
pefile = []
pillow = []
platformdirs = []
pluggy = []
plumbum = []
ply = []
progressbar2 = []
protobuf = []
psutil = []
pulp = []
pycparser = []
pyelftools = []
pygments = []
pylint = []
pyparsing = []
pyquery = []
pysmt = []
pytest = []
python-dateutil = []
python-utils = []
pytz = []
pyvex = []
pywin32 = []
requests = []
rich = []
rpyc = []
scikit-criteria = []
scipy = []
seaborn = []
setuptools-scm = []
shellingham = []
six = []
smmap = []
sortedcontainers = []
sympy = []
tomli = []
tomlkit = []
tree-sitter = []
typer = []
typing-extensions = []
unicorn = []
urllib3 = []
wrapt = []
z3-solver = []
zipp = []

```

`pyproject.toml`:

```toml
[tool.poetry]
name = "fuzzable"
version = "2.0.6"
description = "Framework for Automating Fuzzable Target Discovery with Static Analysis"
authors = [
    "ex0dus <ex0dus@codemuch.tech>"
]
license = "MIT"
readme = "README.md"

homepage = "https://codemuch.tech/fuzzable"
repository = "https://github.com/ex0dus-0x/fuzzable"
documentation = "https://github.com/ex0dus-0x/fuzzable/wiki"

keywords = ["security", "fuzzing", "vulnerability-research", "binary-analysis"]

[tool.poetry.dependencies]
python = "^3.8"
typer = {extras = ["all"], version = "^0.6.1"}
angr = "^9.2.8"
lief = "^0.12.1"
tree-sitter = "^0.20.0"
scikit-criteria = "^0.7"

[tool.poetry.dev-dependencies]
pytest = "^7.1.2"
black = { version = "^22.6.0", python = "^3.9" }
mypy = "^0.961"
pylint = "^2.14.5"
githubrelease = "^1.5.9"
GitPython = "^3.1.27"

[tool.poetry.scripts]
fuzzable = "fuzzable.__main__:app"

[build-system]
requires = ["poetry-core>=1.0.0"]
build-backend = "poetry.core.masonry.api"

[tool.black]
line-length = 88
target_version = ['py39']
include = '\.pyi?$'
exclude = '''

(
  /(
      \.eggs         # exclude a few common directories in the
    | \.git          # root of the project
    | \.hg
    | \.mypy_cache
    | \.tox
    | \.venv
    | \.github
    | _build
    | buck-out
    | build
    | docs
    | dist
  )/
  | Dockerfile
)
'''

```

`requirements.txt`:

```txt
ailment==9.2.26; python_version >= "3.8"
angr==9.2.26; python_version >= "3.8"
archinfo==9.2.26; python_version >= "3.8"
bitstring==4.0.1; python_version >= "3.8"
cachetools==5.2.0; python_version >= "3.8" and python_version < "4.0"
capstone==5.0.0; python_version >= "3.8" and python_full_version < "3.0.0" or python_full_version >= "3.4.0" and python_version >= "3.8"
cffi==1.15.1; implementation_name == "cpython" and python_version >= "3.8"
claripy==9.2.26; python_version >= "3.8"
cle==9.2.26; python_version >= "3.8"
click==8.1.3; python_version >= "3.7"
colorama==0.4.6; python_version >= "3.8" and python_full_version < "3.0.0" and platform_system == "Windows" or python_version >= "3.8" and python_full_version >= "3.7.0" and platform_system == "Windows"
commonmark==0.9.1; python_full_version >= "3.6.3" and python_full_version < "4.0.0" and python_version >= "3.6"
contourpy==1.0.6; python_version >= "3.8"
cppheaderparser==2.7.4; python_version >= "3.8"
cssselect==1.2.0; python_version >= "3.7"
custom-inherit==2.4.0
cycler==0.11.0; python_version >= "3.8"
decorator==5.1.1; python_version >= "3.8"
deprecated==1.2.13; python_version >= "2.7" and python_full_version < "3.0.0" or python_full_version >= "3.4.0"
dpkt==1.9.8; python_version >= "3.8"
fonttools==4.38.0; python_version >= "3.8"
future==0.18.2; python_full_version >= "3.6.0" and python_version >= "3.8"
gitdb==4.0.10; python_version >= "3.8"
gitpython==3.1.29; python_version >= "3.7"
itanium-demangler==1.1; python_version >= "3.8"
jinja2==3.1.2; python_version >= "3.7"
kiwisolver==1.4.4; python_version >= "3.8"
lief==0.12.3; python_version >= "3.6"
lxml==4.9.1; python_version >= "2.7" and python_full_version < "3.0.0" or python_full_version >= "3.5.0"
markupsafe==2.1.1; python_version >= "3.7"
matplotlib==3.6.2; python_version >= "3.8"
mpmath==1.2.1; python_version >= "3.8"
mulpyplexer==0.09; python_version >= "3.8"
nampa==0.1.1; python_version >= "3.8"
networkx==2.8.8; python_version >= "3.8"
numpy==1.23.5
packaging==21.3; python_version >= "3.8"
pandas==1.5.2; python_version >= "3.8"
pefile==2022.5.30; python_full_version >= "3.6.0" and python_version >= "3.8"
pillow==9.3.0; python_version >= "3.8"
plumbum==1.8.0; python_version >= "3.8"
ply==3.11; python_version >= "3.8"
progressbar2==4.2.0; python_full_version >= "3.7.0" and python_version >= "3.8"
protobuf==4.21.9; python_version >= "3.8"
psutil==5.9.4; python_version >= "3.8" and python_full_version < "3.0.0" or python_full_version >= "3.4.0" and python_version >= "3.8"
pulp==2.7.0
pycparser==2.21; python_version >= "3.8" and python_full_version < "3.0.0" or python_full_version >= "3.4.0" and python_version >= "3.8"
pyelftools==0.29; python_version >= "3.8"
pygments==2.13.0; python_full_version >= "3.6.3" and python_full_version < "4.0.0" and python_version >= "3.6"
pyparsing==3.0.9; python_full_version >= "3.6.8" and python_version >= "3.8"
pyquery==1.4.3
pysmt==0.9.6.dev21; python_version >= "3.8"
python-dateutil==2.8.2; python_version >= "3.8" and python_full_version < "3.0.0" or python_full_version >= "3.3.0" and python_version >= "3.8"
python-utils==3.4.5; python_full_version >= "3.7.0" and python_version >= "3.8"
pytz==2022.6; python_version >= "3.8"
pyvex==9.2.26; python_version >= "3.8"
pywin32==305; platform_system == "Windows" and platform_python_implementation != "PyPy" and python_version >= "3.8"
rich==12.6.0; python_full_version >= "3.6.3" and python_full_version < "4.0.0" and python_version >= "3.6"
rpyc==5.2.3; python_version >= "3.8"
scikit-criteria==0.7
scipy==1.9.3; python_version >= "3.8"
seaborn==0.12.1; python_version >= "3.7"
setuptools-scm==7.0.5; python_version >= "3.8"
shellingham==1.5.0; python_version >= "3.6"
six==1.16.0; python_version >= "3.8" and python_full_version < "3.0.0" or python_full_version >= "3.3.0" and python_version >= "3.8"
smmap==5.0.0; python_version >= "3.8"
sortedcontainers==2.4.0; python_version >= "3.8"
sympy==1.11.1; python_version >= "3.8"
tomli==2.0.1; python_version >= "3.8"
tree-sitter==0.20.1; python_version >= "3.3"
typer==0.6.1; python_version >= "3.6"
typing-extensions==4.4.0; python_version >= "3.8"
unicorn==2.0.1; python_version >= "3.8"
wrapt==1.14.1; python_version >= "2.7" and python_full_version < "3.0.0" or python_full_version >= "3.5.0"
z3-solver==4.10.2.0; python_version >= "3.8"

```

`templates/linux_closed_source_harness.cpp`:

```cpp
/* 
 * {NAME}_{function_name}_harness.cpp
 * 
 *      Automatically generated fuzzer harness for `{function_name}` in `{NAME}`. Make sure to add in implementation
 *      for any other necessary functionality to make this work.
 * 
 *      Make sure the target binary/shared object is in the same directory!
 *
 *      To build for AFL-QEMU, optimal for black-box and file-based fuzzing:
 *
 *          $ gcc {NAME}_{function_name}_harness.cpp -no-pie -o {NAME}_{function_name}_harness -ldl
 * 
 *          # check out more binary fuzzing strategies at https://aflplus.plus/docs/binaryonly_fuzzing/
 *          $ afl-fuzz -Q -m none -i <SEEDS> -o out/ -- ./{NAME}_{function_name}_harness
 *
 *      To build for libFuzzer, optimal for generative buffer fuzzing:
 *
 *          $ clang -DLIBFUZZER -g -fsanitize=fuzzer,address {NAME}_{function_name}_harness -no-pie -o {NAME}_{function_name}_harness -ldl
 *          $ ./{NAME}_{function_name}_harness
 *
 */

#include <dlfcn.h>
#include <alloca.h>
#include <stdio.h>
#include <stdint.h>
#include <stdlib.h>
#include <unistd.h>
#include <fcntl.h>

#include <sys/types.h>
#include <sys/stat.h>

#define FUZZER_BUF 1024 * 1024
#define TARGET_NAME "{function_name}"

// TODO: Uncomment this if you want to pass files in as inputs to the target
//#define FILE_FUZZING 1

// TODO: Uncomment this if you want to switch on using libFuzzer instead
//#define LIBFUZZER 1

/* alias for function pointer to the target function */
typedef {return_type} (*{function_name})({type_args});

// TODO: Manually add any other aliases here, such as pointers responsible for freeing up resources

void* handle = NULL;

void CloseLibrary(void)
{{
    if (handle)
        dlclose(handle);
    handle = NULL;
}}


#ifdef LIBFUZZER
extern "C"
#endif
int LoadLibrary(void)
{{
    handle = dlopen("./{path}", RTLD_LAZY);
    atexit(CloseLibrary);
    return handle != NULL;
}}

static uint8_t fuzzBuffer[FUZZER_BUF];

#ifdef LIBFUZZER
extern "C" int LLVMFuzzerTestOneInput(const uint8_t* Data, size_t Size)
#else
int main (int argc, char** argv)
#endif
{{
    if (!LoadLibrary()) {{
        printf("%s\n", dlerror());
        return -1;
    }}

    int read_fd = 0;

#ifndef LIBFUZZER
  #ifdef FILE_FUZZING
    if (argc != 2)
        return -1;

    const char* filepath = argv[1];
    read_fd = open(filepath, O_RDONLY);
    if (read_fd < 0)
        return -1;
  #endif

    ssize_t Size = read(read_fd, fuzzBuffer, FUZZER_BUF);
    if (Size < 0)
        return -1;
#endif

    {function_name} target = ({function_name}) dlsym(handle, TARGET_NAME);
    printf("%s=%p\n", TARGET_NAME, target);

    ////////////////////////////
    // FUZZER ENTRY HERE
    ////////////////////////////

    // Harness generation currently assumes that the only arguments
    // are a pointer to the buffer and the size. Make necessary modifications
    // here to ensure the function being called has the right arguments.
    //void *res = target(fuzzBuffer, Size);

    // Introduce other functionality, ie. freeing objects, checking return values.

    return 0;
}}

```

`templates/linux_source_harness.cpp`:

```cpp
/* 
 * {NAME}_{function_name}_harness.cpp
 * 
 *      Automatically generated fuzzer harness for `{function_name}` in `{NAME}`. Make sure to add in implementation
 *      for any other necessary functionality to make this work.
 * 
 *      Make sure the target binary/shared object is in the same directory!
 *
 *      To build for AFL, optimal for black-box and file-based fuzzing:
 *
 *          $ clang {NAME}_{function_name}_harness.cpp -no-pie -o {NAME}_{function_name}_harness -ldl
 * 
 *          # check out more binary fuzzing strategies at https://aflplus.plus/docs/binaryonly_fuzzing/
 *          $ afl-fuzz -Q -m none -i <SEEDS> -o out/ -- ./{NAME}_{function_name}_harness
 *
 *      To build for libFuzzer, optimal for generative buffer fuzzing:
 *
 *          $ clang -DLIBFUZZER -g -fsanitize=fuzzer,address {NAME}_{function_name}_harness -no-pie -o {NAME}_{function_name}_harness -ldl
 *          $ ./{NAME}_{function_name}_harness
 *
 */
#include <stdlib.h>
#include <stdint.h>
#include <unistd.h>
#include <stdio.h>

/* DEPENDENCIES HERE */

#define FUZZER_BUF 1024 * 1024

static uint8_t fuzzBuffer[FUZZER_BUF];

int main(int argc, char** argv) 
{
    ssize_t read_bytes = read(stdin, fuzzBuffer, FUZZER_BUF);

    // setup and initialization calls

    // free memory and close file handles
}
```

`tests/analysis/test_angr.py`:

```py
"""
test_angr.py
"""
import unittest
from pathlib import Path

# from fuzzable.analysis.angr import AngrAnalysis


class TestAngrAnalysis(unittest.TestCase):
    def test_basic(self):
        data = [1, 2, 3]
        result = sum(data)
        self.assertEqual(result, 6)

    # def test_angr_analysis(self):
    #    analyzer = AngrAnalysis()


if __name__ == "__main__":
    unittest.main()

```

`tests/test_generate.py`:

```py
"""
test_generate.py
"""
import unittest
from pathlib import Path

# from fuzzable import generate


class TestHarnessGen(unittest.TestCase):
    def test_basic(self):
        data = [1, 2, 3]
        result = sum(data)
        self.assertEqual(result, 6)

    # def test_transform_elf_to_so(self):
    #    generate.transform_elf_to_so()


if __name__ == "__main__":
    unittest.main()

```

`tests/test_main.py`:

```py
"""
test_main.py

    Tests main functionality, including
"""

import unittest

from pathlib import Path

from fuzzable.analysis.angr import AngrAnalysis
from fuzzable.analysis.ast import AstAnalysis


class TestMain(unittest.TestCase):
    def test_basic(self):
        data = [1, 2, 3]
        result = sum(data)
        self.assertEqual(result, 6)

    def test_analysis_binary(self):
        target = Path("examples/binaries/libbasic.so.1")
        analyzer = AngrAnalysis(target)
        analyzer.run()

    def test_analysis_source_file(self):
        target = Path("examples/source/libbasic.c")
        analyzer = AstAnalysis([target])
        analyzer.run()

    def test_analysis_source_folder(self):
        target = Path("examples/source/libyaml")
        analyzer = AstAnalysis(target)
        analyzer.run()


if __name__ == "__main__":
    unittest.main()

```