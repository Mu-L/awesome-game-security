Project Path: arc_Jackiemin233_Gemini-Genius_7bmqsgva

Source Tree:

```txt
arc_Jackiemin233_Gemini-Genius_7bmqsgva
├── Gemini
│   ├── Embedding_generation.py
│   ├── Gemini_data_1.py
│   ├── Gemini_train_2.py
│   ├── data_process.py
│   ├── raw_graphs.py
│   ├── requirements.txt
│   ├── similarity_inference.py
│   └── verbose_acfg.py
├── Genius
│   ├── batch_run.py
│   ├── cfg_constructor.py
│   ├── discovRe.py
│   ├── func.py
│   ├── graph_analysis_ida.py
│   ├── graph_property.py
│   ├── preprocessing_ida.py
│   ├── raw_graphs.py
│   └── test.py
├── IDA_appendix
│   └── idc_bc695.py
└── README.md

```

`Gemini/Embedding_generation.py`:

```py
import tensorflow as tf
import config
import pickle
import numpy as np
from Gemini_data_1 import zero_padded_adjmat,feature_vector
import os

#model = tf.keras.models.load_model(config.Gemini_model_save_path)
model = tf.keras.models.load_model('/root/autodl-tmp/ACFG/Gemini/Experiment_2')

class StrToBytes:
    def __init__(self, fileobj):
        self.fileobj = fileobj

    def read(self, size):
        return self.fileobj.read(size).encode()

    def readline(self, size=-1):
        return self.fileobj.readline(size).encode()


def read_acfg(filepath, out_path = "dataset/data.acfg"):
    """
    读取IDA从binary中提取到的属性控制流图(ACFG)，并且转化成之后可操作的格式。
    filepath: ACFG的路径
    out_path: 对应输出文件的存储路径
    """
    all_function_dict = {}
    with open(filepath, "rb") as f:
        #picklefile = pickle.load(StrToBytes(f))
        picklefile = pickle.load(f)
    for func in picklefile.raw_graph_list:
        if len(func.g.node) < config.min_nodes_threshold:
            continue
        if all_function_dict.get(func.funcname) == None:
            all_function_dict[func.funcname] = []
        all_function_dict[func.funcname].append(func.g)
    with open(out_path,"wb") as f:
        pickle.dump(all_function_dict,f)



def generate_embeddings(data_path = "dataset/data.acfg"):
    """
    从转换后的ACFG数据文件中，读取每个函数的图属性信息，并使用DL将每个函数转化成一个embedding vector。
    Return:
        embeddings: 词典。 key 为函数名， value为对应的embedding vector。
    Note:
        embeddings的key可能需要根据情况自己设置，比如说，key应当设置为“当前软件名称”+ “exe/dll 文件名称" + ”函数名“。
        本函数实验中，仅使用函数名作为key，但这对于大规模项目来说是不合适，且不利于最后的检索的，请务必进行更改。
    """
    with open(data_path, "rb") as f:
        data = pickle.load(f)
    embeddings = {}
    for funcname, graphs in data.items():
        for i,graph in enumerate(graphs):
            func_id = funcname + "_" + str(i)  ## 请在这里改变key的设置。
            g_adjmat = zero_padded_adjmat(graph, config.max_nodes)
            g_featmat = feature_vector(graph, config.max_nodes)
            g_adjmat = np.expand_dims(g_adjmat,0)
            g_featmat = np.expand_dims(g_featmat,0)
            g_adjmat = tf.convert_to_tensor(g_adjmat)
            g_featmat = tf.convert_to_tensor(g_featmat)
            input = (g_adjmat, g_featmat, g_adjmat, g_featmat)
            sim, g1_embedding, g2_embedding = model(input)
            embeddings[func_id] = np.squeeze(g1_embedding.numpy())
    return embeddings

def save_embeddings(embeddings, save_file = "output/embeddings.txt"):
    """
    将生成得到的embedding存储到一个文件中去，方便之后进行比较。
    """
    with open(save_file, "w") as f:
        for key, value in embeddings.items():
            vector = value.tolist()
            vector_str = " ".join([str(v) for v in vector])
            f.write(key + "|" + vector_str + "\n")
#save_embeddings(embeddings, "output/embeddings.txt")

def load_embedding(file):
    """
    load embedding from a file.
    In the file, the embedding format is:
    func | embedding.

    :param file: filepath
    :return:
    """
    embedding_dict = {}
    with open(file, "r") as f:
        for line in f.readlines():
            if len(line) <= 1:
                continue
            sp = line.strip().split("|")
            funcname = sp[0]
            vector = sp[1:][0]
            vector = [float(v) for v in vector.split()]
            embedding_dict[funcname] = np.array(vector)
    return embedding_dict

def norm(vector):
    """
    l2 norm.
    :param vector:
    :return:
    """
    res = np.sqrt(np.sum(np.square(vector)))
    return vector / res

def infer_similarity(target_embedding, embedding_file):
    """
    根据target函数的embedding，在对应的embedding_file中的embedding寻找相似的函数。
    target_embedding: 你要进行search的函数对应的embedding，在供应链场景中，这里应当为CVE对应的那个函数。
    embedding_file: 存储当前binary所有函数的embedding的文件。
    Return:
        用print输出10个相似性最高的函数。
    """
    my_embeddings =  load_embedding(embedding_file)
    results = {}
    for funcname, embedding in my_embeddings.items():
        sim = np.dot(norm(target_embedding), norm(embedding))
        results[funcname] = sim
    results = sorted(results.items(), key=lambda d: d[1], reverse=True)
    for i in range(10): # 输出排序的前十个结果
        result = results[i]
        key, sim = result
        print(" ".join([key, str(sim)]))

def random_test():
    my_embeddings = load_embedding("output/embeddings.txt")
    target_funcs = np.random.choice(list(my_embeddings.keys()), 10)
    for target_func in target_funcs:
        target_embedding = my_embeddings[target_func]
        infer_similarity(target_embedding, "output/embeddings.txt")
        print("--------------------")


if __name__ == "__main__":
    path = '/root/autodl-tmp/ACFG/acfg_data'
    output_path = '/root/autodl-tmp/ACFG/Gemini/embeddings'
    Acfg_list = os.listdir('/root/autodl-tmp/ACFG/acfg_data')
    for file in Acfg_list:
        embedding_save = os.path.join(output_path,file+'.txt') #Save Path
        file = os.path.join(path,file)
        
        embeddings = generate_embeddings(data_path = file)
        save_embeddings(embeddings,embedding_save)
```

`Gemini/Gemini_data_1.py`:

```py
import tensorflow as tf
from tensorflow.keras import layers
import glob
import pickle
import numpy as np
import networkx as nx
import config


class StrToBytes:
    def __init__(self, fileobj):
        self.fileobj = fileobj

    def read(self, size):
        return self.fileobj.read(size).encode()

    def readline(self, size=-1):
        return self.fileobj.readline(size).encode()


def read_cfg():
    all_function_dict = {}
    counts = []
    for a in config.arch:
        count = 0
        for v in config.version:
            for c in config.compiler:
                for o in config.optimizer:
                    filename = "_".join([v, a, c, o, "openssl"])
                    filepath = config.dir_name + filename+".cfg"
                    with open(filepath, "r") as f:
                        picklefile = pickle.load(StrToBytes(f))
                    for func in picklefile.raw_graph_list:
                        if len(func.g) < config.min_nodes_threshold:
                            continue
                        if all_function_dict.get(func.funcname) == None:
                            all_function_dict[func.funcname] = []
                        all_function_dict[func.funcname].append(func.g)
                        count += 1
        counts.append(count)
    print("for three arch:", counts)

    return all_function_dict


def dataset_split(all_function_dict):
    all_func_num = len(all_function_dict)
    train_func_num = int(all_func_num * 0.8)
    test_func_num = int(all_func_num * 0.1)

    train_name = np.random.choice(
        list(all_function_dict.keys()), size=train_func_num, replace=False)
    train_func = {}
    for func in train_name:
        train_func[func] = all_function_dict[func]
        all_function_dict.pop(func)

    with open("data/Gemini/train", "wb") as f:
        pickle.dump(train_func, f)

    test_func = {}
    test_name = np.random.choice(
        list(all_function_dict.keys()), size=test_func_num, replace=False)
    for func in test_name:
        test_func[func] = all_function_dict[func]
        all_function_dict.pop(func)
    with open("data/Gemini/test", "wb") as f:
        pickle.dump(test_func, f)

    valid_func = all_function_dict
    valid_num = len(all_function_dict)
    with open("data/Gemini/valid", "wb") as f:
        pickle.dump(valid_func, f)

    print("train dataset's num =%s ,valid dataset's num=%s , test dataset's num =%s" % (
        train_func_num, valid_num, test_func_num))


def adjmat(gr):
    return nx.adjacency_matrix(gr).toarray().astype('float32')


def zero_padded_adjmat(graph, size):
    unpadded = adjmat(graph)
    padded = np.zeros((size, size))
    if len(graph) > size:
        padded = unpadded[0:size, 0:size]
    else:
        padded[0:unpadded.shape[0], 0:unpadded.shape[1]] = unpadded
    return padded


def feature_vector(graph, size):
    feature_mat = np.zeros((size, 9))
    for _node in graph.nodes:
        if _node == size:
            break
        feature = np.zeros((1, 9))
        vector = graph.nodes[_node]['v']
        num_const = vector[0]
        if len(num_const) == 1:
            feature[0, 0] = num_const[0]
        elif len(num_const) >= 2:
            feature[0, 0:2] = np.sort(num_const)[::-1][:2]
        feature[0, 2] = len(vector[1])
        feature[0, 3:] = vector[2:]
        feature_mat[_node, :] = feature
    return feature_mat


def generate_pairs(type):
    assert type == b"train" or type == b"test" or type == b"valid", "dataset type error!"
    import os
    filepath = os.path.join(config.Gemini_dataset_dir,type.decode())
    with open(filepath, "rb") as f:
        func_dict = pickle.load(f)
    funcname_list = list(func_dict.keys())
    length = len(funcname_list)
    for funcname in func_dict.keys():
        func_list = func_dict[funcname]
        if len(func_list) < 2:
            continue
        for i, g in enumerate(func_list):
            g_adjmat = zero_padded_adjmat(g, config.max_nodes)
            g_featmat = feature_vector(g, config.max_nodes)
            for j in range(2):
                if j == 0:
                    g1_index = np.random.randint(low=0, high=len(func_list))
                    while g1_index == i:
                        g1_index = np.random.randint(
                            low=0, high=len(func_list))
                    g1 = func_list[g1_index]
                    g1_adjmat = zero_padded_adjmat(g1, config.max_nodes)
                    g1_featmat = feature_vector(g1, config.max_nodes)
                    pair = (g_adjmat, g_featmat, g1_adjmat, g1_featmat, 1)
                else:
                    index = np.random.randint(low=0, high=length)
                    while funcname_list[index] == funcname:
                        index = np.random.randint(low=0, high=length)
                    g2_index = np.random.randint(
                        low=0, high=len(func_dict[funcname_list[index]]))
                    g2 = func_dict[funcname_list[index]][g2_index]
                    g2_adjmat = zero_padded_adjmat(g2, config.max_nodes)
                    g2_featmat = feature_vector(g2, config.max_nodes)
                    pair = (g_adjmat, g_featmat, g2_adjmat, g2_featmat, -1)
                yield pair


def dataset_generation(type="train"):
    data = tf.data.Dataset.from_generator(generate_pairs, output_types=(
        tf.float32, tf.float32, tf.float32, tf.float32, tf.float32), args=[type])
    data = data.repeat()
    data = data.shuffle(buffer_size=config.Buffer_Size)
    data = data.batch(batch_size=config.mini_batch)
    data = data.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)
    return data


if __name__ == '__main__':
    all_func_dict = read_cfg()
    dataset_split(all_func_dict)

```

`Gemini/Gemini_train_2.py`:

```py
import tensorflow as tf
from tensorflow.keras import layers
from Gemini_data_1 import generate_pairs, dataset_generation, zero_padded_adjmat, feature_vector
import config
import matplotlib.pyplot as plt
import numpy as np
from sklearn.metrics import roc_curve, auc

# from Gemini.config import Gemini_model_save_path


class embedding_layer(layers.Layer):
    def __init__(self):
        super(embedding_layer, self).__init__()

    def build(self, input_shape):
        self.theta = self.add_weight(name="layer0", shape=tf.TensorShape(
            [config.embedding_size, config.embedding_size]))
        self.theta1 = self.add_weight(name="layer1", shape=tf.TensorShape(
            [config.embedding_size, config.embedding_size]))
        super(embedding_layer, self).build(input_shape)

    def call(self, input):
        '''
        :param input:shape = (batch,embedding_size,nodes)
        :return:
        '''
        curr_embedding = tf.einsum('ik,akj->aij', self.theta, input)
        curr_embedding = tf.nn.relu(curr_embedding)
        curr_embedding = tf.einsum('ik,akj->aij', self.theta1, curr_embedding)
        # curr_embedding = tf.nn.relu(curr_embedding)
        return curr_embedding

    def compute_output_shape(self, input_shape):
        shape = tf.TensorShape(input_shape)
        return shape


def compute_graph_embedding(adjmat, feature_mat, W1, W2, embed_layer):
    '''
    adjmat: shape = (batch,max_nodes,max_nodes)
    feature_mat: shape = (batch,max_nodes,9)
    W1: shape = (embedding_size,9)
    W2: shape = (embedding_size,embedding_size)
    '''
    feature_mat = tf.einsum(
        'aij->aji', feature_mat)  # shape = (batch,9,max_nodes)

    init_embedding = tf.zeros(shape=(adjmat.shape[1], config.embedding_size))
    # shape = (batch,nodes,embedding_size)
    prev_embedding = tf.einsum('aik,kj->aij', adjmat, init_embedding)
    # shape = (batch,embedding_size,nodes)
    prev_embedding = tf.einsum('aij->aji', prev_embedding)
    for iter in range(config.T):
        # shape = (batch,embedding_size,nodes)
        neighbor_embedding = embed_layer(prev_embedding)
        # shape=(batch,embedding_size,nodes)
        term = tf.einsum('ik,akj->aij', W1, feature_mat)
        curr_embedding = tf.nn.tanh(term + neighbor_embedding)
        # shape=(batch,embedding_size,nodes)
        prev_embedding = curr_embedding
        # shape = (batch,nodes,embedding_size)
        prev_embedding = tf.einsum('aij->aji', prev_embedding)
        # shape = (batch,nodes,embedding_size)
        prev_embedding = tf.einsum('aik,akj->aij', adjmat, prev_embedding)
        # shape =(batch,embedding_size,nodes)
        prev_embedding = tf.einsum('aij->aji', prev_embedding)
    # shape = (batch,embedding_size)
    graph_embedding = tf.reduce_sum(curr_embedding, axis=2)
    graph_embedding = tf.einsum('ij->ji', graph_embedding)
    # shape = (embedding_size,batch)
    graph_embedding = tf.matmul(W2, graph_embedding)
    return graph_embedding


class MyModel(tf.keras.Model):
    def __init__(self):
        super(MyModel, self).__init__()
        self.embed_layer = embedding_layer()
        self.W1 = tf.Variable(tf.random.uniform(
            [config.embedding_size, config.Gemini_feature_size], maxval=0.1, dtype=tf.float32))
        self.W2 = tf.Variable(tf.random.uniform(
            [config.embedding_size, config.embedding_size], maxval=0.2, dtype=tf.float32))

    def call(self, inputs, training=None, mask=None):
        g1_adjmat, g1_feature_mat, g2_adjmat, g2_feature_mat = inputs
        g1_embedding = compute_graph_embedding(
            g1_adjmat, g1_feature_mat, self.W1, self.W2, self.embed_layer)
        g2_embedding = compute_graph_embedding(
            g2_adjmat, g2_feature_mat, self.W1, self.W2, self.embed_layer)
        sim_score = cosine(g1_embedding, g2_embedding)
        return sim_score, g1_embedding, g2_embedding


def cosine(q, a):
    pooled_len_1 = tf.sqrt(tf.reduce_sum(tf.square(q), axis=0))
    pooled_len_2 = tf.sqrt(tf.reduce_sum(tf.square(a), axis=0))
    pooled_mul_12 = tf.reduce_sum(tf.multiply(q, a), axis=0)
    score = tf.divide(pooled_mul_12, pooled_len_1 *
                      pooled_len_2 + 0.0001, name="scores")
    return score


def loss(model, g1_adjmat, g1_featmat, g2_adjmat, g2_featmat, y):
    input = (g1_adjmat, g1_featmat, g2_adjmat, g2_featmat)
    sim, g1_embedding, g2_embedding = model(input)
    if tf.reduce_max(sim) > 1 or tf.reduce_min(sim) < -1:
        sim = sim * 0.999
    loss_value = tf.reduce_sum(tf.square(tf.subtract(sim, y)))
    return loss_value, sim, g1_embedding, g2_embedding


def grad(model, g1_adjmat, g1_featmat, g2_adjmat, g2_featmat, y):
    with tf.GradientTape() as tape:
        loss_value, sim, g1_embedding, g2_embedding = loss(
            model, g1_adjmat, g1_featmat, g2_adjmat, g2_featmat, y)
    return loss_value, tape.gradient(loss_value, model.trainable_variables), sim, g1_embedding, g2_embedding


def valid(model):
    valid_dataset = dataset_generation(type="valid")
    epoch_loss_avg_valid = tf.keras.metrics.Mean()
    epoch_accuracy_avg_valid = tf.keras.metrics.BinaryAccuracy()
    epoch_auc_avg = tf.keras.metrics.AUC()
    step = 0
    print("-------------------------")
    for g1_adjmat, g1_featmat, g2_adjmat, g2_featmat, y in valid_dataset:
        loss_value, grads, sim, _, _ = grad(
            model, g1_adjmat, g1_featmat, g2_adjmat, g2_featmat, y)
        epoch_loss_avg_valid(loss_value)
        epoch_accuracy_avg_valid.update_state(y, sim)
        sim = (sim + 1) / 2
        epoch_auc_avg.update_state(y, sim)

        if step % (config.valid_step_pre_epoch//100) == 0:
            print("valid step {:03d}: Loss: {:.3f}, Accuracy: {:.3%}, AUC: {:.3f}".format(step, epoch_loss_avg_valid.result(),
                                                                                          epoch_accuracy_avg_valid.result(), epoch_auc_avg.result()))
            if step == config.valid_step_pre_epoch:
                break
        step += 1
    print("----------------------------")
    return epoch_loss_avg_valid.result(), epoch_accuracy_avg_valid.result(), epoch_auc_avg.result()


def test(model):
    epoch_loss_avg_test = tf.keras.metrics.Mean()
    epoch_accuracy_avg_test = tf.keras.metrics.BinaryAccuracy()
    epoch_auc_sim = []
    epoch_auc_ytrue = []
    test_dataset = dataset_generation(type="test")
    step = 0
    for g1_adjmat, g1_featmat, g2_adjmat, g2_featmat, y in test_dataset:
        loss_value, grads, sim, _, _ = grad(
            model, g1_adjmat, g1_featmat, g2_adjmat, g2_featmat, y)
        epoch_loss_avg_test(loss_value)
        epoch_accuracy_avg_test.update_state(y, sim)

        epoch_auc_sim = np.concatenate((epoch_auc_sim, sim))
        epoch_auc_ytrue = np.concatenate((epoch_auc_ytrue, y))
        fpr, tpr, thres = roc_curve(
            epoch_auc_ytrue, epoch_auc_sim, pos_label=1)
        auc_score = auc(fpr, tpr)
        if step % (config.test_step_pre_epoch//100) == 0:
            print("test step {:03d}: Loss: {:.3f}, Accuracy: {:.3%}, AUC: {:.3f}".format(
                step, epoch_loss_avg_test.result(), epoch_accuracy_avg_test.result(), auc_score))
            if step == config.test_step_pre_epoch:
                break
        step += 1
    plt.figure(figsize=(5, 4))
    plt.plot(fpr, tpr)
    plt.xlabel("fpr")
    plt.ylabel("tpr")
    plt.show()
    print("----------------------------")


def train():
    optimizer = tf.optimizers.Adam(config.learning_rate)
    model = MyModel()
    model.build([(None, config.max_nodes, config.max_nodes), (None, config.max_nodes, config.Gemini_feature_size),
                (None, config.max_nodes, config.max_nodes), (None, config.max_nodes, config.Gemini_feature_size)])
    model.summary()
    max_auc = 0
    train_loss = []
    valid_loss = []
    train_auc = []
    valid_auc = []
    train_accuracy = []
    valid_accuracy = []
    for epoch in range(config.epochs):
        train_dataset = dataset_generation()
        epoch_loss_avg = tf.keras.metrics.Mean()
        epoch_accuracy_avg = tf.keras.metrics.BinaryAccuracy(threshold=0.8)
        epoch_auc_avg = tf.keras.metrics.AUC()
        step = 0
        for g1_adjmat, g1_featmat, g2_adjmat, g2_featmat, y in train_dataset:
            loss_value, grads, sim, _, _ = grad(
                model, g1_adjmat, g1_featmat, g2_adjmat, g2_featmat, y)
            optimizer.apply_gradients(zip(grads, model.trainable_variables))

            epoch_loss_avg(loss_value)
            y_pred = (sim+1)/2
            y = (y+1)/2
            epoch_accuracy_avg.update_state(y, y_pred)
            epoch_auc_avg.update_state(y, y_pred)
            if step % (config.step_per_epoch//100) == 0:
                print("step {:03d}: Loss: {:.3f}, Accuracy: {:.3%}, AUC: {:.3f}".format(
                    step, epoch_loss_avg.result(), epoch_accuracy_avg.result(), epoch_auc_avg.result()))
                if step == config.step_per_epoch:
                    break
            step += 1
        train_loss.append(epoch_loss_avg.result())
        train_accuracy.append(epoch_accuracy_avg.result())
        train_auc.append(epoch_auc_avg.result())
        print("Epoch {:03d}: Loss: {:.3f}, Accuracy: {:.3%}, AUC: {:.3f}".format(
            epoch, epoch_loss_avg.result(), epoch_accuracy_avg.result(), epoch_auc_avg.result()))
        v_loss, v_accuracy, v_auc = valid(model)
        valid_loss.append(v_loss)
        valid_accuracy.append(v_accuracy)
        valid_auc.append(v_auc)
        if v_auc > max_auc:
            model.save(config.Gemini_model_save_path, save_format='tf')
            max_auc = v_auc
    test(model)
    plt.figure(figsize=(5, 4))
    plt.title("Loss curve")
    x = range(config.epochs)
    plt.plot(x, train_loss, label="train_loss")
    plt.plot(x, valid_loss, label="valid_loss")
    plt.xlabel("epochs")
    plt.ylabel("loss")
    plt.legend()
    plt.savefig(config.Gemini_fig_save_path+"loss.png")

    plt.figure(figsize=(5, 4))
    plt.title("Accuracy curve")
    plt.plot(x, train_accuracy, label="train_accuracy")
    plt.plot(x, valid_accuracy, label="valid_accuracy")
    plt.xlabel("epochs")
    plt.ylabel("accuracy")
    plt.legend()
    plt.savefig(config.Gemini_fig_save_path + "accuracy.png")

    plt.figure(figsize=(5, 4))
    plt.title("AUC curve")
    plt.plot(x, train_auc, label="train_auc")
    plt.plot(x, valid_auc, label="valid_auc")
    plt.xlabel("epochs")
    plt.ylabel("AUC")
    plt.legend()
    plt.savefig(config.Gemini_figure_save_path + "auc.png")


if __name__ == "__main__":
    train()
    # model = tf.keras.models.load_model(config.Gemini_model_save_path)
    # test(model)

```

`Gemini/data_process.py`:

```py
import os
import pickle
import config
import os

def file_search(data_path):
    file_list = []
    for home, dirs, files in os.walk(data_path):
        for f in files:
            if f.endswith('.cfg'):
                file_list.append(os.path.join(home,f))
            else:
                pass
    return file_list

def read_acfg(filepath, out_path = "dataset/data.acfg"):
    all_function_dict = {}
    with open(filepath, "rb") as f: #load i64
        picklefile = pickle.load(f)
    for func in picklefile.raw_graph_list: #read
        # if len(func.g.node) < config.min_nodes_threshold:
        #     continue
        if all_function_dict.get(func.funcname) == None:
            all_function_dict[func.funcname] = []
        all_function_dict[func.funcname].append(func.g)
    with open(out_path,"wb") as f:
        pickle.dump(all_function_dict,f)

if __name__ == '__main__':
    data_path = '/root/autodl-tmp/ACFG/Gemini/extract'
    output_path = '/root/autodl-tmp/ACFG/acfg_data'
    file_list = file_search(data_path)
    for file in file_list:
        file_name,suffix = os.path.splitext(file.split('/')[-1])
        file_name = file_name+'.acfg'#.acfg
        file_name = os.path.join(output_path,file_name) #filename
        read_acfg(filepath=file,out_path = file_name)   #preprocess
```

`Gemini/raw_graphs.py`:

```py
#coding:utf-8
import itertools
import sys
sys.path.insert(0, '/usr/local/lib/python2.7/dist-packages/')
import networkx as nx
#import numpy as np
from subprocess import Popen, PIPE
import pdb
import os
import re,mmap
#from graph_edit_new import *

class raw_graph:
	def __init__(self, funcname, g, func_f):
		'''
		funcname:函数名
		g: Genius的ACFG
		func_f:DiscovRe的特征
		'''
		self.funcname = funcname
		self.old_g = g[0]
		self.g = nx.DiGraph()
		self.entry = g[1]
		self.fun_features = func_f
		self.attributing()


class raw_graphs:  # 二进制文件内的所有原生控制流图
	def __init__(self, binary_name):
		self.binary_name = binary_name
		self.raw_graph_list = []

	def append(self, raw_g):
		self.raw_graph_list.append(raw_g)

	def __len__(self):
		return len(self.raw_graph_list)

```

`Gemini/requirements.txt`:

```txt
tensorflow
scikit-learn
numpy
matplotlab
networkx
```

`Gemini/similarity_inference.py`:

```py
import tensorflow as tf
import config
import pickle
import numpy as np
import random
from Gemini_data_1 import zero_padded_adjmat,feature_vector

#model = tf.keras.models.load_model(config.Gemini_model_save_path)
model = tf.keras.models.load_model(config.Gemini_model_save_path)

class StrToBytes:
    def __init__(self, fileobj):
        self.fileobj = fileobj

    def read(self, size):
        return self.fileobj.read(size).encode()

    def readline(self, size=-1):
        return self.fileobj.readline(size).encode()


def read_acfg(filepath, out_path = "dataset/data.acfg"):
    """
    读取IDA从binary中提取到的属性控制流图(ACFG)，并且转化成之后可操作的格式。
    filepath: ACFG的路径
    out_path: 对应输出文件的存储路径
    """
    all_function_dict = {}
    with open(filepath, "rb") as f:
        #picklefile = pickle.load(StrToBytes(f))
        picklefile = pickle.load(f)
    for func in picklefile.raw_graph_list:
        if len(func.g.node) < config.min_nodes_threshold:
            continue
        if all_function_dict.get(func.funcname) == None:
            all_function_dict[func.funcname] = []
        all_function_dict[func.funcname].append(func.g)
    with open(out_path,"wb") as f:
        pickle.dump(all_function_dict,f)



def generate_embeddings(data_path = "dataset/data.acfg"):
    """
    从转换后的ACFG数据文件中，读取每个函数的图属性信息，并使用DL将每个函数转化成一个embedding vector。
    Return:
        embeddings: 词典。 key 为函数名， value为对应的embedding vector。
    Note:
        embeddings的key可能需要根据情况自己设置，比如说，key应当设置为“当前软件名称”+ “exe/dll 文件名称" + ”函数名“。
        本函数实验中，仅使用函数名作为key，但这对于大规模项目来说是不合适，且不利于最后的检索的，请务必进行更改。
    """
    with open(data_path, "rb") as f:
        data = pickle.load(f)
    embeddings = {}
    for funcname, graphs in data.items():
        for i,graph in enumerate(graphs):
            func_id = funcname + "_" + str(i)  ## 请在这里改变key的设置。
            g_adjmat = zero_padded_adjmat(graph, config.max_nodes)
            g_featmat = feature_vector(graph, config.max_nodes)
            g_adjmat = np.expand_dims(g_adjmat,0)
            g_featmat = np.expand_dims(g_featmat,0)
            g_adjmat = tf.convert_to_tensor(g_adjmat)
            g_featmat = tf.convert_to_tensor(g_featmat)
            input = (g_adjmat, g_featmat, g_adjmat, g_featmat)
            sim, g1_embedding, g2_embedding = model(input)
            embeddings[func_id] = np.squeeze(g1_embedding.numpy())
    return embeddings

def save_embeddings(embeddings, save_file = "output/embeddings.txt"):
    """
    将生成得到的embedding存储到一个文件中去，方便之后进行比较。
    """
    with open(save_file, "w") as f:
        for key, value in embeddings.items():
            vector = value.tolist()
            vector_str = " ".join([str(v) for v in vector])
            f.write(key + "|" + vector_str + "\n")
#save_embeddings(embeddings, "output/embeddings.txt")

def load_embedding(file):
    """
    load embedding from a file.
    In the file, the embedding format is:
    func | embedding.

    :param file: filepath
    :return:
    """
    embedding_dict = {}
    with open(file, "r") as f:
        for line in f.readlines():
            if len(line) <= 1:
                continue
            sp = line.strip().split("|")
            funcname = sp[0]
            vector = sp[1:][0]
            vector = [float(v) for v in vector.split()]
            embedding_dict[funcname] = np.array(vector)
    return embedding_dict

def norm(vector):
    """
    l2 norm.
    :param vector:
    :return:
    """
    res = np.sqrt(np.sum(np.square(vector)))
    return vector / res

def infer_similarity(target_embedding, embedding_file):
    """
    根据target函数的embedding，在对应的embedding_file中的embedding寻找相似的函数。
    target_embedding: 你要进行search的函数对应的embedding，在供应链场景中，这里应当为CVE对应的那个函数。
    embedding_file: 存储当前binary所有函数的embedding的文件。
    Return:
        用print输出10个相似性最高的函数。
    """
    my_embeddings =  load_embedding(embedding_file)
    results = {}
    for funcname, embedding in my_embeddings.items():
        sim = np.dot(norm(target_embedding), norm(embedding))
        results[funcname] = sim
    results = sorted(results.items(), key=lambda d: d[1], reverse=True)
    for i in range(10): # 输出排序的前十个结果
        result = results[i]
        key, sim = result
        print(" ".join([key, str(sim)]))

def random_test():
    my_embeddings = load_embedding("output/embeddings.txt")
    target_funcs = np.random.choice(list(my_embeddings.keys()), 10)
    for target_func in target_funcs:
        target_embedding = my_embeddings[target_func]
        infer_similarity(target_embedding, "output/embeddings.txt")
        print("--------------------")


if __name__ == "__main__":
    #random_test()
    read_acfg("../dataset/dbghelp_w32.dll.cfg")
    generate_embeddings()


```

`Gemini/verbose_acfg.py`:

```py
from config import *
import pickle
import tensorflow as tf
import os
import glob
import csv
import networkx as nx
import numpy as np

with open(Gemini_dataset_dir+"train", "rb") as f:
    picklefile = pickle.load(f)
print(picklefile[0])

```

`Genius/batch_run.py`:

```py
#coding:utf-8
import os
import subprocess
import glob
import time

IDA_PATH = "D:\\Downloads\\Genius-master\\Genius-master\\raw-feature-extractor_py3_ida7.7\\IDA_Pro_7.7\\ida64.exe"
PLUGIN_PATH = "D:\\Downloads\\Genius-master\\Genius-master\\raw-feature-extractor_py3_ida7.7\\preprocessing_ida.py"  #必须绝对路径

# 获取所有需要分析的二进制文件路径
ELF_PATH = "D:\\Downloads\\Genius-master\\Genius-master\\raw-feature-extractor_py3_ida7.7\\data\\glibc"
print(ELF_PATH)
DST_path = "D:\\Downloads\\Genius-master\\Genius-master\\raw-feature-extractor_py3_ida7.7\\extract"


#Get all the compiled files(.o) in the data folder
def file_search(data_path):
    file_list = []
    for home, dirs, files in os.walk(data_path):
        for f in files:
            if f.endswith('.o'):
                file_list.append(os.path.join(home,f))
            else:
                pass
    return file_list

if __name__ == '__main__':
    core_num = 2  ##并行的个数，或者电脑有几个核心
    start = 0
    file_list = file_search(ELF_PATH)
    for elf in file_list:
        print(elf)
        cmd = IDA_PATH + " -c -S" + PLUGIN_PATH + " " + elf
        print(cmd)
        if start >= core_num:
            finish = len(os.listdir(DST_path))
            while start-core_num >= finish:
                time.sleep(5)
                finish = len(os.listdir(DST_path))
                print(start, finish)

        subprocess.Popen(cmd)
        start += 1


```

`Genius/cfg_constructor.py`:

```py
#coding:utf-8

import copy
import networkx as nx
from idautils import *
import idaapi
from idc import *
from idc_bc695 import *
from graph_analysis_ida import *


def getCfg(func, externs_eas, ea_externs):
	func_start = func.start_ea
	func_end = func.end_ea
	cfg = nx.DiGraph()
	control_blocks, main_blocks = obtain_block_sequence(func)
	i = 0
	visited = {}
	start_node = None
	for bl in control_blocks:
		start = control_blocks[bl][0]
		end = control_blocks[bl][1]
		src_node = (start, end)
		if src_node not in visited:
			src_id = len(cfg)
			visited[src_node] = src_id
			cfg.add_node(src_id)
			cfg.nodes[src_id]['label'] = src_node

		else:
			src_id = visited[src_node]

		#if end in seq_blocks and GetMnem(prev_head(end)) != 'jmp':
		if start == func_start:
			cfg.nodes[src_id]['c'] = "start"
			start_node = src_node
		if end == func_end:
			cfg.nodes[src_id]['c'] = "end"
		#print control_ea, 1
		refs = CodeRefsTo(start, 0)
		for ref in refs:
			if ref in control_blocks:
				dst_node = control_blocks[ref]
				if dst_node not in visited:
					visited[dst_node] = len(cfg)
				dst_id = visited[dst_node]
				cfg.add_edge(dst_id, src_id)
				cfg.nodes[dst_id]['label'] = dst_node
		#print control_ea, 1
		refs = CodeRefsTo(start, 1)  #除了跳转Flow，将正常FLOW也算上
		for ref in refs:
			if ref in control_blocks:
				dst_node = control_blocks[ref]
				if dst_node not in visited:
					visited[dst_node] = len(cfg)
				dst_id = visited[dst_node]
				cfg.add_edge(dst_id, src_id)
				cfg.nodes[dst_id]['label'] = dst_node
	#print "attributing"
	cfg = attributingRe(cfg, externs_eas, ea_externs)
	# removing deadnodes
	#old_cfg = copy.deepcopy(cfg)
	#transform(cfg)
	return cfg

def transform(cfg):
	merging(cfg)
	filtering(cfg)

def merging(cfg):
	bb_ids = cfg.nodes()
	for bb_id in bb_ids:
		try:
			bb = cfg.nodes[bb_id]['label']
			bb_start = bb[0]
			bb_end = bb[1]
			succs = cfg.successors(bb_id)
			#preds = cfg.predecessors(bb_id)
			if len(succs) == 1:
				preds = cfg.predecessors(succs[0])
				if len(preds) == 1:
					domerge(cfg, bb_id, succs[0])
		except:
			pass

def domerge(cfg, bb_id, suc_node):
	suc_nodes = cfg.successors(suc_node)
	for node in suc_nodes:
		cfg.add_edge(bb_id, node)
	cfg.remove_node(suc_node)


def filtering(cfg):
	rm_sets = []
	for bb_id in cfg:
		bb = cfg.nodes[bb_id]['label']
		bb_start = bb[0]
		bb_end = bb[1]
		re = remove(bb_start, bb_end)
		print(bb_id, re, bb_start, bb_end)
		if re:
			print(re, bb_id)
			rm_sets.append(bb_id)
	print(rm_sets)
	for bb_id in rm_sets:
		cfg.remove_node(bb_id)

def remove(bb_start, bb_end):
	seqs = getSequences(bb_start, bb_end)
	if matchseq(seqs):
		return True
	return False

def matchseq(seqs):
	mips = set(['lw', "jr", "addiu"])
	x86 = set(['add', 'pop', 'retn'])
	b_mips = set(['b', ('move','$v0')])
	b_x86 = set(['b', ('mov','$eax')])
	re_mips = set([('move','$v0')])
	re_x86 = set([('mov','$eax')])
	diff_mips = set(seqs).difference(set(mips))
	if len(diff_mips) == 0:
		return True
	diff_x86 = set(seqs).difference(set(x86))
	if len(diff_x86) == 0:
		return True
	if set(seqs) == b_mips:
		return True
	if set(seqs) == b_x86:
		return True
	if set(seqs) == re_mips:
		return True
	if set(seqs) == re_x86:
		return True
	return False

def attributingRe(cfg, externs_eas, ea_externs):  #为每个基本块生成自定义的属性
	for node_id in cfg:
		bl = cfg.nodes[node_id]['label']
		numIns = calInsts(bl)  # No. of Instruction
		cfg.nodes[node_id]['numIns'] = numIns
		numCalls = calCalls(bl) # No. of Calls
		cfg.nodes[node_id]['numCalls'] = numCalls
		numLIs = calLogicInstructions(bl)  # 这个不再Genius的范围内
		cfg.nodes[node_id]['numLIs'] = numLIs
		numAs = calArithmeticIns(bl) # No. of Arithmetic Instructions
		cfg.nodes[node_id]['numAs'] = numAs
		strings, consts = getBBconsts(bl)  # String and numeric constants
		cfg.nodes[node_id]['numNc'] = len(strings) + len(consts)
		cfg.nodes[node_id]['consts'] = consts
		cfg.nodes[node_id]['strings'] = strings
		externs = retrieveExterns(bl, ea_externs)
		cfg.nodes[node_id]['externs'] = externs
		numTIs = calTransferIns(bl) # No. of Transfer Instruction
		cfg.nodes[node_id]['numTIs'] = numTIs
	return cfg



def attributing(cfg):
	ga = graph_analysis()
	ga.gwithoffspring(cfg)
	print("finishing offspring")
	for node in cfg:
		stmt_num = getStmtNum(node)
		binary_value = getBinaryValue(node)
		cfg.nodes[node]['stmt_num'] = stmt_num
		cfg.nodes[node]['binary_value'] = binary_value
	ga.domChecking(cfg)
	print("finishing domChecking")
	ga.loopChecking(cfg)
	print("finishing loopChecking")


def getStmtNum(node):
	start = node[0]
	end = node[1]
	stmt_num = 0
	inst_addr = start
	while inst_addr < end:
		inst_addr = next_head(inst_addr)
		stmt_num += 1
	return stmt_num

def getBinaryValue(node):
	start = node[0]
	inst_addr = next_head(start)
	value = 0
	addr = 0
	for x in range((inst_addr - start)-1):
		addr = start + x
		y = GetOriginalByte(addr)
		print(value, addr, y)
		value = value | y
		value = value << 8
		print(value)

	addr = inst_addr - 1
	y = GetOriginalByte(addr)
	print(value, addr, y)
	value = value | y
	print(node)
	print(bin(value))
	return value


def cfg_construct(func):
	func_start = func.start_ea
	func_end = func.end_ea
	cfg = nx.DiGraph()
	seq_blocks, main_blocks = obtain_block_sequence(func)
	i = 0
	visited = {}
	for bl in seq_blocks:
		start = seq_blocks[bl][0]
		end = seq_blocks[bl][1]
		src_node = (start, end)
		if end in seq_blocks and GetMnem(prev_head(end)) != 'jmp':
						next_start = seq_blocks[end][0]
						next_end = seq_blocks[end][1]
						next_node = (next_start, next_end)
						cfg.add_edge(src_node, next_node)
		if start == func_start:
			cfg.add_node(src_node, c='start')
			start_node = src_node
		if end == func_end:
			cfg.add_node(src_node, c='end')
		refs = CodeRefsFrom(prev_head(end), 0)
		
		for ref in refs:
						#print ref
						if ref in seq_blocks:
								dst_node = (seq_blocks[ref][0], seq_blocks[ref][1])
								cfg.add_edge(src_node, dst_node)
	return cfg, start_node


def obtain_allpaths( cfg, node, path, allpaths):
	path.append(node)
	if 'c' in cfg.nodes[node] and cfg.nodes[node]['c'] == 'end':
		allpaths.append(path)
		return
	else:
		for suc in cfg.successors(node):
						if suc not in path:
								path_copy = copy.copy(path)
								obtain_allpaths(cfg, suc, path_copy, allpaths)


def obtain_block_sequence(func):
	control_blocks = {}
	main_blocks = {}
	blocks = [(v.start_ea, v.end_ea) for v in idaapi.FlowChart(func)]  # 返回该函数所有的basicblock
	for bl in blocks:
		base = bl[0]
		end = prev_head(bl[1])
		control_ea = checkCB(bl)
		control_blocks[control_ea] = bl
		control_blocks[end] = bl
		if func.start_ea <= base <= func.end_ea:
						main_blocks[base] = bl
		x = sorted(main_blocks)
	return control_blocks, x

def checkCB(bl): # 检查基本块的正确性
	start = bl[0]
	end = bl[1]
	ea = start
	while ea < end:
		if checkCondition(ea):
			return ea
		ea = next_head(ea)

	return prev_head(end)

def checkCondition(ea): # check是否是跳转指令
	mips_branch = {"beqz":1, "beq":1, "bne":1, "bgez":1, "b":1, "bnez":1, "bgtz":1, "bltz":1, "blez":1, "bgt":1, "bge":1, "blt":1, "ble":1, "bgtu":1, "bgeu":1, "bltu":1, "bleu":1}
	x86_branch = {"jz":1, "jnb":1, "jne":1, "je":1, "jg":1, "jle":1, "jl":1, "jge":1, "ja":1, "jae":1, "jb":1, "jbe":1, "jo":1, "jno":1, "js":1, "jns":1}
	arm_branch = {"B":1, "BAL":1, "BNE":1, "BEQ":1, "BPL":1, "BMI":1, "BCC":1, "BLO":1, "BCS":1, "BHS":1, "BVC":1, "BVS":1, "BGT":1, "BGE":1, "BLT":1, "BLE":1, "BHI":1 ,"BLS":1 }
	conds = {}
	conds.update(mips_branch)
	conds.update(x86_branch)
	opcode = GetMnem(ea)
	if opcode in conds:
		return True
	return False
```

`Genius/discovRe.py`:

```py
#coding:utf-8
#
# Reference Lister
#
# List all functions and all references to them in the current section.
#
# Implemented with the idautils module
#
import networkx as nx
# import cPickle as pickle
import _pickle as pickle
import pdb
from graph_analysis_ida import *
from graph_property import *
from idc_bc695 import *
#import wingdbstub
#wingdbstub.Ensure()

def get_funcs(ea):
	funcs = {}
		# Get current ea
		# Loop from start to end in the current segment
	for funcea in Functions(SegStart(ea)):
		funcname = GetFunctionName(funcea)
		func = get_func(funcea)
		blocks = FlowChart(func)
		funcs[funcname] = []
		for bl in blocks:
				start = bl.start_ea
				end = bl.end_ea
				funcs[funcname].append((start, end))
		return funcs

def get_funcs_for_discoverRe(ea):
	features = {}
	for funcea in Functions(SegStart(ea)):
		funcname = GetFunctionName(funcea)
		print(funcname)
		func = get_func(funcea)
		feature = get_discoverRe_feature(func)
		features[funcname] = feature
	return features

def get_discoverRe_feature(func, icfg):
	start = func.start_ea
	end = func.end_ea
	features = []
	FunctionCalls = getFuncCalls(func)
	#1
	features.append(FunctionCalls)
	LogicInstr = getLogicInsts(func)
	#2
	features.append(LogicInstr)
	Transfer = getTransferInsts(func)
	#3
	features.append(Transfer)
	Locals = getLocalVariables(func)
	#4
	features.append(Locals)
	BB = getBasicBlocks(func)
	#5
	features.append(BB)
	Edges = len(icfg.edges())
	#6
	features.append(Edges)
	Incoming = getIncommingCalls(func)
	#7
	features.append(Incoming)
	#8
	Instrs = getIntrs(func)
	features.append(Instrs)
	between = retrieveGP(icfg)
	#9
	features.append(between)

	strings, consts = getfunc_consts(func)
	features.append(strings)
	features.append(consts)
	return features

def get_func_names(ea):
	funcs = {}
	for funcea in Functions(SegStart(ea)):
		funcname = GetFunctionName(funcea)
		funcs[funcname] = funcea
	return funcs

def get_func_bases(ea):
	funcs = {}
	for funcea in Functions(SegStart(ea)):
		funcname = GetFunctionName(funcea)
		funcs[funcea] = funcname
	return funcs

def get_func_range(ea):
	funcs = {}
	for funcea in Functions(SegStart(ea)):
		funcname = GetFunctionName(funcea)
		func = get_func(funcea)
		funcs[funcname] = (func.start_ea, func.end_ea)
	return funcs

def get_func_sequences(ea):
	funcs_bodylist = {}
	funcs = get_funcs(ea)
	for funcname in funcs:
		if funcname not in funcs_bodylist:
			funcs_bodylist[funcname] = []
		for start, end in funcs[funcname]:
			inst_addr = start
			while inst_addr <= end:
				opcode = GetMnem(inst_addr)
				funcs_bodylist[funcname].append(opcode)
				inst_addr = NextHead(inst_addr)
		return funcs_bodylist

def get_func_cfgs(ea):
	func_cfglist = {}
	i = 0
	start, end = get_section('LOAD')
	#print start, end
	for funcea in Functions(SegStart(ea)):
		if start <= funcea <= end:
			funcname = GetFunctionName(funcea)
			func = get_func(funcea)
			print(i)
			i += 1
			try:
				icfg = cfg.cfg_construct(func)
				func_cfglist[funcname] = icfg
			except:
				pass

	return func_cfglist

def get_section(t):
	base = SegByName(t)
	start = SegByBase(base)
	end = SegEnd(start)
	return start, end


def get_func_cfg_sequences(func_cfglist):
	func_cfg_seqlist = {}
	for funcname in func_cfglist:
		func_cfg_seqlist[funcname] = {}
		cfg = func_cfglist[funcname][0]
		for start, end in cfg:
			codesq = get_sequences(start, end)
			func_cfg_seqlist[funcname][(start,end)] = codesq

	return func_cfg_seqlist


def get_sequences(start, end):
	seq = []
	inst_addr = start
	while inst_addr <= end:
		opcode = GetMnem(inst_addr)
		seq.append(opcode)
		inst_addr = NextHead(inst_addr)
	return seq

def get_stack_arg(func_addr):
	print(func_addr)
	args = []
	stack = GetFrame(func_addr)
	if not stack:
			return []
	firstM = GetFirstMember(stack)
	lastM = GetLastMember(stack)
	i = firstM
	while i <=lastM:
		mName = GetMemberName(stack,i)
		mSize = GetMemberSize(stack,i)
		if mSize:
				i = i + mSize
		else:
				i = i+4
		if mName not in args and mName and ' s' not in mName and ' r' not in mName:
			args.append(mName)
	return args

		#pickle.dump(funcs, open('C:/Documents and Settings/Administrator/Desktop/funcs','w'))

def processDataSegs():
	funcdata = {}
	datafunc = {}
	for n in xrange(idaapi.get_segm_qty()):
		seg = idaapi.getnseg(n)
		ea = seg.start_ea
		segtype = idc.GetSegmentAttr(ea, idc.SEGATTR_TYPE)
		if segtype in [idc.SEG_DATA, idc.SEG_BSS]:
			start = idc.SegStart(ea)
			end = idc.SegEnd(ea)
			cur = start
			while cur <= end:
				refs = [v for v in DataRefsTo(cur)]
				for fea in refs:
					name = GetFunctionName(fea)
					if len(name)== 0:
						continue
					if name not in funcdata:
						funcdata[name] = [cur]
					else:
						funcdata[name].append(cur)
					if cur not in datafunc:
						datafunc[cur] = [name]
					else:
						datafunc[cur].append(name)
				cur = NextHead(cur)
	return funcdata, datafunc

def obtainDataRefs(callgraph):
	datarefs = {}
	funcdata, datafunc = processDataSegs()
	for node in callgraph:
		if node in funcdata:
			datas = funcdata[node]
			for dd in datas:
				refs = datafunc[dd]
				refs = list(set(refs))
				if node in datarefs:
					print(refs)
					datarefs[node] += refs
					datarefs[node] = list(set(datarefs[node]))
				else:
					datarefs[node] = refs
	return datarefs


```

`Genius/func.py`:

```py
#coding:utf-8
#
# Reference Lister
#
# List all functions and all references to them in the current section.
#
# Implemented with the idautils module
#
from idautils import *
from idaapi import *
from idc import *
from idc_bc695 import *
import networkx as nx
import cfg_constructor as cfg
# import cPickle as pickle # in py3 there is no cPickle
import _pickle as pickle
import pdb
from raw_graphs import *
#from discovRe_feature.discovRe import *
from discovRe import *
#import wingdbstub
#wingdbstub.Ensure()
def gt_funcNames(ea):
	funcs = []
	plt_func, plt_data = processpltSegs()
	for funcea in Functions(seg_start(ea)):
			funcname = get_unified_funcname(funcea)
			if funcname in plt_func:
				print(funcname)
				continue
			funcs.append(funcname)
	return funcs

def get_funcs(ea):
	funcs = {}
		# Get current ea
		# Loop from start to end in the current segment
	plt_func, plt_data = processpltSegs()
	for funcea in Functions(seg_start(ea)):
		funcname = get_unified_funcname(funcea)
		if funcname in plt_func:
			continue
		func = get_func(funcea)
		blocks = FlowChart(func)
		funcs[funcname] = []
		for bl in blocks:
				start = bl.start_ea
				end = bl.end_ea
				funcs[funcname].append((start, end))
	return funcs

# used for the callgraph generation.
def get_func_namesWithoutE(ea):
	funcs = {}
	plt_func, plt_data = processpltSegs()
	for funcea in Functions(seg_start(ea)):
			funcname = get_unified_funcname(funcea)
			if 'close' in funcname:
				print(funcea)
			if funcname in plt_func:
				print(funcname)
				continue
			funcs[funcname] = funcea
	return funcs

# used for the callgraph generation.
def get_func_names(ea):
	funcs = {}
	for funcea in Functions(seg_start(ea)):
			funcname = get_unified_funcname(funcea)
			funcs[funcname] = funcea
	return funcs

def get_func_bases(ea):
		funcs = {}
		plt_func, plt_data = processpltSegs()
		for funcea in Functions(seg_start(ea)):
				funcname = get_unified_funcname(funcea)
				if funcname in plt_func:
					continue
				funcs[funcea] = funcname
		return funcs

def get_func_range(ea):
		funcs = {}
		for funcea in Functions(seg_start(ea)):
				funcname = get_unified_funcname(funcea)
		func = get_func(funcea)
		funcs[funcname] = (func.start_ea, func.end_ea)
		return funcs

def get_unified_funcname(ea): # 得到统一形式的functionName
	funcname = GetFunctionName(ea)
	if len(funcname) > 0:
		if '.' == funcname[0]:
			funcname = funcname[1:]
	return funcname

def get_func_sequences(ea):
	funcs_bodylist = {}
	funcs = get_funcs(ea)
	for funcname in funcs:
		if funcname not in funcs_bodylist:
			funcs_bodylist[funcname] = []
		for start, end in funcs[funcname]:
			inst_addr = start
			while inst_addr <= end:
				opcode = GetMnem(inst_addr)
				funcs_bodylist[funcname].append(opcode)
				inst_addr = next_head(inst_addr)
	return funcs_bodylist

def get_func_cfgs_c(ea):
	'''
	ea:binary的起始地址
	return: 每个函数的原生属性控制流图（未向量化）的列表
	'''
	# binary_name = GetInputFile()
	binary_name = idc.get_root_filename()
	print("+_+_+_+_+_+_+_+_+_")
	print(binary_name, type(binary_name))
	print("+_+_+_+_+_+_+_+_+_")
	raw_cfgs = raw_graphs(binary_name)
	externs_eas, ea_externs = processpltSegs()
	i = 0
	segm = get_segm_by_name(".text")
	for funcea in Functions(segm.start_ea,segm.end_ea):
		funcname = get_unified_funcname(funcea)
		func = get_func(funcea) # 得到func这个类对象
		#print i
		i += 1
		icfg = cfg.getCfg(func, externs_eas, ea_externs)  # 为每个函数构建Genius 的ACFG
		func_f = get_discoverRe_feature(func, icfg)  # 生成DiscoverRe中的函数特征
		raw_g = raw_graph(funcname, icfg, func_f)
		raw_cfgs.append(raw_g)

	return raw_cfgs

def get_func_cfgs_ctest(ea):
	# binary_name = idc.GetInputFile()
	binary_name = idc.get_input_file_path
	raw_cfgs = raw_graphs(binary_name)
	externs_eas, ea_externs = processpltSegs()
	i = 0
	diffs = {}
	for funcea in Functions(seg_start(ea)):
		funcname = get_unified_funcname(funcea)
		func = get_func(funcea)
		print(i)
		i += 1
		icfg, old_cfg = cfg.getCfg(func, externs_eas, ea_externs)
		diffs[funcname] = (icfg, old_cfg)
		#raw_g = raw_graph(funcname, icfg)
		#raw_cfgs.append(raw_g)
			
	return diffs

def get_func_cfgs(ea):
	func_cfglist = {}
	i = 0
	for funcea in Functions(seg_start(ea)):
		funcname = get_unified_funcname(funcea)
		func = get_func(funcea)
		print(i)
		i += 1
		try:
			icfg = cfg.getCfg(func)
			func_cfglist[funcname] = icfg
		except:
			pass
			
	return func_cfglist

def get_func_cfg_sequences(func_cfglist):
	func_cfg_seqlist = {}
	for funcname in func_cfglist:
		func_cfg_seqlist[funcname] = {}
		cfg = func_cfglist[funcname][0]
		for start, end in cfg:
			codesq = get_sequences(start, end)
			func_cfg_seqlist[funcname][(start,end)] = codesq

	return func_cfg_seqlist


def get_sequences(start, end):
	seq = []
	inst_addr = start
	while inst_addr <= end:
		opcode = GetMnem(inst_addr)
		seq.append(opcode)
		inst_addr = next_head(inst_addr)
	return seq

def get_stack_arg(func_addr):
	print(func_addr)
	args = []
	stack = GetFrame(func_addr)
	if not stack:
			return []
	firstM = GetFirstMember(stack)
	lastM = GetLastMember(stack)
	i = firstM
	while i <=lastM:
		mName = GetMemberName(stack,i)
		mSize = GetMemberSize(stack,i)
		if mSize:
				i = i + mSize
		else:
				i = i+4
		if mName not in args and mName and ' s' not in mName and ' r' not in mName:
			args.append(mName)
	return args

		#pickle.dump(funcs, open('C:/Documents and Settings/Administrator/Desktop/funcs','w'))

def processExternalSegs():
	funcdata = {}
	datafunc = {}
	for n in range(get_segm_qty()):
		seg =getnseg(n)
		ea = seg.start_ea
		segtype = idc.GetSegmentAttr(ea, idc.SEGATTR_TYPE)
		if segtype in [idc.SEG_XTRN]:
			start = idc.seg_start(ea)
			end = idc.SegEnd(ea)
			cur = start
			while cur <= end:
				name = get_unified_funcname(cur)
				funcdata[name] = hex(cur)
				cur = next_head(cur)
	return funcdata

def processpltSegs(): # 得到所有函数对应的起始指令地址，和得到所有函数起始地址对应的函数名
	funcdata = {}
	datafunc = {}
	for n in range(get_segm_qty()): #Segment总数
		seg = getnseg(n)
		# ea = seg.start_ea
		ea = seg.start_ea
		segname = SegName(ea)
		if segname in ['.plt', 'extern', '.MIPS.stubs']:
			start = seg.start_ea
			end = seg.end_ea
			cur = start
			while cur < end:
				name = get_unified_funcname(cur)
				funcdata[name] = hex(cur)
				datafunc[cur]= name
				cur = next_head(cur)
	return funcdata, datafunc

		
def processDataSegs():
	funcdata = {}
	datafunc = {}
	for n in range(get_segm_qty()):
		seg = getnseg(n)
		ea = seg.start_ea
		segtype = idc.GetSegmentAttr(ea, idc.SEGATTR_TYPE)
		if segtype in [idc.SEG_DATA, idc.SEG_BSS]:
			start = idc.seg_start(ea)
			end = idc.SegEnd(ea)
			cur = start
			while cur <= end:
				refs = [v for v in DataRefsTo(cur)]
				for fea in refs:
					name = get_unified_funcname(fea)
					if len(name)== 0:
						continue
					if name not in funcdata:
						funcdata[name] = [cur]
					else:
						funcdata[name].append(cur)
					if cur not in datafunc:
						datafunc[cur] = [name]
					else:
						datafunc[cur].append(name)
				cur = next_head(cur)
	return funcdata, datafunc

def obtainDataRefs(callgraph):
	datarefs = {}
	funcdata, datafunc = processDataSegs()
	for node in callgraph:
		if node in funcdata:
			datas = funcdata[node]
			for dd in datas:
				refs = datafunc[dd]
				refs = list(set(refs))
				if node in datarefs:
					print(refs)
					datarefs[node] += refs
					datarefs[node] = list(set(datarefs[node]))
				else:
					datarefs[node] = refs
	return datarefs


```

`Genius/graph_analysis_ida.py`:

```py
#coding:utf-8
from idautils import *
from idaapi import *
from idc import *
from idc_bc695 import *

def getfunc_consts(func):
	strings = []
	consts = []
	blocks = [(v.start_ea, v.end_ea) for v in FlowChart(func)]
	for bl in blocks:
		strs, conts = getBBconsts(bl)
		strings += strs
		consts += conts
	return strings, consts

def getConst(ea, offset):
	strings = []
	consts = []
	optype1 = GetOpType(ea, offset)
	if optype1 == o_imm:
		imm_value = GetOperandValue(ea, offset)
		if 0<= imm_value <= 10:
			consts.append(imm_value)
		else:
			if isLoaded(imm_value) and getseg(imm_value):
				# str_value = GetString(imm_value)
				str_value =	idc.get_strlit_contents(imm_value)
				if str_value is None:
					# str_value = GetString(imm_value+0x40000)
					str_value =	idc.get_strlit_contents(imm_value+0x40000)
					if str_value is None:
						consts.append(imm_value)
					else:
						# re = all(40 <= ord(c) < 128 for c in str_value)
						re = all(40 <= c < 128 for c in str_value)
						if re:
							strings.append(str_value)
						else:
							consts.append(imm_value)
				else:
					# re = all(40 <= ord(c) < 128 for c in str_value)
					re = all(40 <= c < 128 for c in str_value)
					if re:
						strings.append(str_value)
					else:
						consts.append(imm_value)
			else:
				consts.append(imm_value)
	return strings, consts

def getBBconsts(bl):
	strings = []
	consts = []
	start = bl[0]
	end = bl[1]
	invoke_num = 0
	inst_addr = start
	while inst_addr < end:
		opcode = GetMnem(inst_addr)
		if opcode in ['la','jalr','call', 'jal']:
			inst_addr = next_head(inst_addr)
			continue
		strings_src, consts_src = getConst(inst_addr, 0)
		strings_dst, consts_dst = getConst(inst_addr, 1)
		strings += strings_src
		strings += strings_dst
		consts += consts_src
		consts += consts_dst
		try:
			strings_dst, consts_dst = getConst(inst_addr, 2)
			consts += consts_dst
			strings += strings_dst
		except:
			pass

		inst_addr = next_head(inst_addr)
	return strings, consts

def getFuncCalls(func):
	blocks = [(v.start_ea, v.end_ea) for v in FlowChart(func)]
	sumcalls = 0
	for bl in blocks:
		callnum = calCalls(bl)
		sumcalls += callnum
	return sumcalls

def getLogicInsts(func):
	blocks = [(v.start_ea, v.end_ea) for v in FlowChart(func)]
	sumcalls = 0
	for bl in blocks:
		callnum = calLogicInstructions(bl)
		sumcalls += callnum
	return sumcalls

def getTransferInsts(func):
	blocks = [(v.start_ea, v.end_ea) for v in FlowChart(func)]
	sumcalls = 0
	for bl in blocks:
		callnum = calTransferIns(bl)
		sumcalls += callnum
	return sumcalls

def getIntrs(func):
	blocks = [(v.start_ea, v.end_ea) for v in FlowChart(func)]
	sumcalls = 0
	for bl in blocks:
		callnum = calInsts(bl)
		sumcalls += callnum
	return sumcalls	

def getLocalVariables(func):
	args_num = get_stackVariables(func.start_ea)
	return args_num

def getBasicBlocks(func):
	blocks = [(v.start_ea, v.end_ea) for v in FlowChart(func)]
	return len(blocks)

def getIncommingCalls(func):
	refs = CodeRefsTo(func.start_ea, 0)
	re = len([v for v in refs])
	return re


def get_stackVariables(func_addr):
    #print func_addr
    args = []
    stack = GetFrame(func_addr)
    if not stack:
            return 0
    firstM = GetFirstMember(stack)
    lastM = GetLastMember(stack)
    i = firstM
    while i <=lastM:
        mName = GetMemberName(stack,i)
        mSize = GetMemberSize(stack,i)
        if mSize:
                i = i + mSize
        else:
                i = i+4
        if mName not in args and mName and 'var_' in mName:
            args.append(mName)
    return len(args)



def calArithmeticIns(bl):
	x86_AI = {'add':1, 'sub':1, 'div':1, 'imul':1, 'idiv':1, 'mul':1, 'shl':1, 'dec':1, 'inc':1}
	mips_AI = {'add':1, 'addu':1, 'addi':1, 'addiu':1, 'mult':1, 'multu':1, 'div':1, 'divu':1}
	calls = {}
	calls.update(x86_AI)
	calls.update(mips_AI)
	start = bl[0]
	end = bl[1]
	invoke_num = 0
	inst_addr = start
	while inst_addr < end:
		opcode = GetMnem(inst_addr)
		if opcode in calls:
			invoke_num += 1
		inst_addr = next_head(inst_addr)
	return invoke_num

def calCalls(bl):
	calls = {'call':1, 'jal':1, 'jalr':1}
	start = bl[0]
	end = bl[1]
	invoke_num = 0
	inst_addr = start
	while inst_addr < end:
		opcode = GetMnem(inst_addr)
		if opcode in calls:
			invoke_num += 1
		inst_addr = next_head(inst_addr)
	return invoke_num

def calInsts(bl):
	start = bl[0]
	end = bl[1]
	ea = start
	num = 0
	while ea < end:
		num += 1
		ea = next_head(ea)
	return num

def calLogicInstructions(bl):
	x86_LI = {'and':1, 'andn':1, 'andnpd':1, 'andpd':1, 'andps':1, 'andnps':1, 'test':1, 'xor':1, 'xorpd':1, 'pslld':1}
	mips_LI = {'and':1, 'andi':1, 'or':1, 'ori':1, 'xor':1, 'nor':1, 'slt':1, 'slti':1, 'sltu':1}
	calls = {}
	calls.update(x86_LI)
	calls.update(mips_LI)
	start = bl[0]
	end = bl[1]
	invoke_num = 0
	inst_addr = start
	while inst_addr < end:
		opcode = GetMnem(inst_addr)
		if opcode in calls:
			invoke_num += 1
		inst_addr = next_head(inst_addr)
	return invoke_num

def calSconstants(bl):
	start = bl[0]
	end = bl[1]
	invoke_num = 0
	inst_addr = start
	while inst_addr < end:
		opcode = GetMnem(inst_addr)
		if opcode in calls:
			invoke_num += 1
		inst_addr = next_head(inst_addr)
	return invoke_num


def calNconstants(bl):
	start = bl[0]
	end = bl[1]
	invoke_num = 0
	inst_addr = start
	while inst_addr < end:
		optype1 = GetOpType(inst_addr, 0)
		optype2 = GetOpType(inst_addr, 1)
		if optype1 == 5 or optype2 == 5:
			invoke_num += 1
		inst_addr = next_head(inst_addr)
	return invoke_num

def retrieveExterns(bl, ea_externs):
	externs = []
	start = bl[0]
	end = bl[1]
	inst_addr = start
	while inst_addr < end:
		refs = CodeRefsFrom(inst_addr, 1)
		try:
			ea = [v for v in refs if v in ea_externs][0]
			externs.append(ea_externs[ea])
		except:
			pass
		inst_addr = next_head(inst_addr)
	return externs

def calTransferIns(bl):
	x86_TI = {'jmp':1, 'jz':1, 'jnz':1, 'js':1, 'je':1, 'jne':1, 'jg':1, 'jle':1, 'jge':1, 'ja':1, 'jnc':1, 'call':1}
	mips_TI = {'beq':1, 'bne':1, 'bgtz':1, "bltz":1, "bgez":1, "blez":1, 'j':1, 'jal':1, 'jr':1, 'jalr':1}
	arm_TI = {'MVN':1, "MOV":1}
	calls = {}
	calls.update(x86_TI)
	calls.update(mips_TI)
	start = bl[0]
	end = bl[1]
	invoke_num = 0
	inst_addr = start
	while inst_addr < end:
		opcode = GetMnem(inst_addr)
		re = [v for v in calls if opcode in v]
		if len(re) > 0:
			invoke_num += 1
		inst_addr = next_head(inst_addr)
	return invoke_num
```

`Genius/graph_property.py`:

```py
#coding:utf-8
import networkx as nx
import pdb
def betweeness(g):
	#pdb.set_trace()
	betweenness = nx.betweenness_centrality(g)
	return betweenness

def eigenvector(g):
	centrality = nx.eigenvector_centrality(g)
	return centrality

def closeness_centrality(g):
	closeness = nx.closeness_centrality(g)
	return closeness

def retrieveGP(g):
	bf = betweeness(g)
	#close = closeness_centrality(g)
	#bf_sim = 
	#close_sim = 
	x = sorted(bf.values())
	value = sum(x)/len(x)
	return round(value,5)

```

`Genius/preprocessing_ida.py`:

```py
#coding:utf-8
from func import *
from raw_graphs import *
import idc
import idc_bc695
import idaapi
import idautils
import os
import argparse

print("test if run")


def parse_command():
	parser = argparse.ArgumentParser(description='Process some integers.')
	parser.add_argument("--path", type=str, help="The directory where to store the generated .ida file")
	args = parser.parse_args()
	return args

if __name__ == '__main__':
	# idaapi.autoWait()
	idaapi.auto_wait()
	#args = parse_command()
	#path = args.path

	print("open a new binary")
	# path = "D:\\Code\\python\\binary_search\\Genius\\Gencoding-master\\raw-feature-extractor\\extracted-acfg"
	path = "D:\\Downloads\\Genius-master\\Genius-master\\raw-feature-extractor_py3_ida7.7\\extract"
	analysis_flags = get_inf_attr(idc.INF_AF) # 得到analysis_flags  INF_AF
	analysis_flags &= ~AF_IMMOFF  # AF_IMMOFF ：将32位的指令操作转换为偏移量
	# turn off "automatically make offset" heuristic
	idc.set_inf_attr(INF_AF, analysis_flags) #设置analysis_flags

	# cfgs = get_func_cfgs_c(FirstSeg())
	# get_first_seg()
	cfgs = get_func_cfgs_c(get_first_seg())

	binary_name = GetInputFile() + '.cfg'
	fullpath = os.path.join(path, binary_name)
	print(cfgs)
	print("===================--====================")
	pickle.dump(cfgs, open(fullpath,'wb'))
	print(binary_name)

	ida_pro.qexit(0)

```

`Genius/raw_graphs.py`:

```py
#coding:utf-8
import itertools
import sys
sys.path.insert(0, '/usr/local/lib/python2.7/dist-packages/')
import networkx as nx
#import numpy as np
from subprocess import Popen, PIPE
import pdb
import os
import re,mmap
#from graph_edit_new import *

class raw_graph:
	def __init__(self, funcname, g, func_f):
		'''
		funcname:函数名
		g: Genius的ACFG
		func_f:DiscovRe的特征
		'''
		self.funcname = funcname
		self.old_g = g
		self.g = nx.DiGraph()
		self.discovre_features = func_f
		self.attributing()

	def __len__(self):
		return len(self.g)

	def attributing(self):
		self.obtainOffsprings(self.old_g)
		for node in self.old_g:
			fvector = self.retrieveVec(node, self.old_g)
			self.g.add_node(node)
			self.g.nodes[node]['v'] = fvector

		for edge in self.old_g.edges():
			node1 = edge[0]
			node2 = edge[1]
			self.g.add_edge(node1, node2)

	def obtainOffsprings(self,g):
		nodes = g.nodes()
		for node in nodes:
			offsprings = {}
			self.getOffsprings(g, node, offsprings)
			g.nodes[node]['offs'] = len(offsprings)
		return g

	def getOffsprings(self, g, node, offsprings):
		node_offs = 0
		sucs = g.successors(node)
		for suc in sucs:
			if suc not in offsprings:
				offsprings[suc] = 1
				self.getOffsprings(g, suc, offsprings)

	def retrieveVec(self, id_, g):
		feature_vec = []
		#numC0
		numc = g.nodes[id_]['consts']
		feature_vec.append(numc)
		#nums1
		nums = g.nodes[id_]['strings']
		feature_vec.append(nums)
		#offsprings2
		offs = g.nodes[id_]['offs']
		feature_vec.append(offs)
		#numAs3
		numAs = g.nodes[id_]['numAs']
		feature_vec.append(numAs)
		# of calls4
		calls = g.nodes[id_]['numCalls']
		feature_vec.append(calls)
		# of insts5
		insts = g.nodes[id_]['numIns']
		feature_vec.append(insts)
		# of LIs6
		insts = g.nodes[id_]['numLIs']
		feature_vec.append(insts)
		# of TIs7
		insts = g.nodes[id_]['numTIs']
		feature_vec.append(insts)	
		return feature_vec


	def enumerating(self, n):
		subgs = []
		#pdb.set_trace()
		for sub_nodes in itertools.combinations(self.g.nodes(), n):
			subg = self.g.subgraph(sub_nodes)
			u_subg = subg.to_undirected()
			if nx.is_connected(u_subg):
				subgs.append(subg)
		return subgs


	def genMotifs(self, n):
		motifs = {}
		subgs = self.enumerating(n)
		for subg in subgs:
			if len(motifs) == 0:
				motifs[subg] = [subg]
			else:
				nomatch = True
				for mt in motifs:
					if nx.is_isomorphic(mt, subg):
						motifs[mt].append(subg)
						nomatch = False
				if nomatch:
					motifs[subg] = [subg]
		return motifs

	# def enumerating_efficient(self, n):
	# 	#pdb.set_trace()
	# 	if len(self.g) >= 200:
	# 		return []
	# 	with open('/home/qian/workspace/gEnding/gencoding/encoding/labeled/data/preprocessing/OUTPUT.txt','wb') as f:
	# 		nx.write_edgelist(self.g,f,data=False)
	# 	#pdb.set_trace()
	# 	process = Popen(["/home/qian/workspace/FANMOD-command_line-source/executables/./fanmod_command_line_linux", str(n), "100000", "1", "/home/qian/workspace/gEnding/gencoding/encoding/labeled/data/preprocessing/OUTPUT.txt", "1", "0", "0", "2", "0", "0", "0", "1000", "3", "3", "/home/qian/workspace/gEnding/gencoding/encoding/labeled/data/preprocessing/MotifCount.txt", "0", "1"], stdout=PIPE, stderr=PIPE)
	# 	stdout, stderr = process.communicate()
	# 	if process.returncode >= 0:
	# 	#os.system("/home/qian/software/FANMOD-command_line-source/executables/./fanmod_command_line_linux " +str(n) + " 100000 1 /home/qian/workspace/gEnding/gencoding/encoding/labeled/data/preprocessing/OUTPUT.txt 1 0 0 2 0 0 0 1000 3 3 /home/qian/workspace/gEnding/gencoding/encoding/labeled/data/preprocessing/MotifCount.txt 0 1")
	# 	#pdb.set_trace()
	# 		#pdb.set_trace()
	# 		subgs = self.parseOutput("/home/qian/workspace/gEnding/gencoding/encoding/labeled/data/preprocessing/MotifCount.txt.dump", n)
	# 		#pdb.set_trace()
	# 		os.remove("/home/qian/workspace/gEnding/gencoding/encoding/labeled/data/preprocessing/MotifCount.txt.dump")
	# 		return subgs
	# 	return []

	def parseOutput(self, path, n):
		pattern = re.compile('[0-9]+\,[0-9]+\,[0-9]+\,[0-9]+')
		subgraphs = []
		with open(path,'r') as f:
			data = mmap.mmap(f.fileno(), 0, prot=mmap.PROT_READ)
			mo = re.findall(pattern, data)
			if mo:
				results = [map(int, v.split(',')[1:]) for v in mo]
				subgraphs = self.createGraphDirectly(results)
		return subgraphs

	def parseOutputByconditions(self, path, n):
		pattern = re.compile('[0-9]+\,[0-9]+\,[0-9]+\,[0-9]+')
		subgraphs = []
		with open(path,'r') as f:
			data = mmap.mmap(f.fileno(), 0, prot=mmap.PROT_READ)
			mo = re.findall(pattern, data)
			if mo:
				results = [map(int, v.split(',')[1:]) for v in mo]
				subgraphs = self.create_Graphbycondition_Directly(results)
		return subgraphs

	def create_Graphbycondition_Directly(self, results):
		subgs = []
		for indexes in results:
			tg = template_graph()
			subg = self.g.subgraph(indexes)
			tg.updateG(subg)
			subgs.append(tg)
			del tg
		return subgs

	def createGraphDirectly(self, results):
		#pdb.set_trace()
		#subgs = [self.g.subgraph(indexes) for indexes in results]
		subgs = []
		for indexes in results:
			tg = template_graph()
			subg = self.g.subgraph(indexes)
			tg.updateG(subg)
			subgs.append(tg)
			del tg
		return subgs

	def createGraph(self, results, n):
		binary_value = int(results[0],2)
		indexes = [int(v) for v in results[1:]]
		fang = self.createG(results[0], n)
		if fang:
			tg = template_graph(binary_value)
			tg.updateG(fang, indexes, self.g)
			return tg
		pdb.set_trace()
		print("there is g which is none")

	def createG(self, binary_str, n):
		g = nx.DiGraph()
		l = [int(v) for v in binary_str]
		#pdb.set_trace()
		shape = (n, n)
		data = np.array(l)
		ad_matrix = data.reshape(shape)
		for i in range(n):
			for j in range(n):
				if ad_matrix[i][j] == 1:
					g.add_edge(i, j)
		return g
			


class raw_graphs:  # 二进制文件内的所有原生控制流图
	def __init__(self, binary_name):
		self.binary_name = binary_name
		self.raw_graph_list = []

	def append(self, raw_g):
		self.raw_graph_list.append(raw_g)

	def __len__(self):
		return len(self.raw_graph_list)


class graphlets:
	def __init__(self, funcname):
		self.funcname = funcname
		self.graphlets_list = []
		self.binary_name = None

	def updateBN(self, binary_name):
		self.binary_name = binary_name

	def append(self, subg):
		self.graphlets_list.append(subg)

	def appendSet(self, subgs):
		self.graphlets_list += subgs

	def __len__(self):
		return len(self.graphlets_list)

class template_graph:
	def __init__(self, value=None):
		self.value = value
		self.g = None

	def updateG(self,g):
		self.g = g
	#def updateIndexes(self, indexes):
	#	self.indexes = indexes

	#def updateAttributes(self, pg, indexes, maing):
	#	for id_ in xrange(len(indexes)):
	#		index = indexes[id_]
	#		gnode = self.findNode(index, maing)
	#		self.g.nodes[gnode] = pg.nodes[index]


class template_graphs:
	def __init__(self, size):
		self.size = size
		self.gs = []
		self.bit_len = None

	def enumeratingAll(self):
		subgs = []
		binary_value = self.genBinValue()
		for i in xrange(binary_value):
			if i == 0 :
				continue
			g = self.createG(i)
			if g:
				tg = template_graph(i)
				tg.updateG(g)
				self.gs.append(tg)

	def genBinValue(self):
		n = self.size
		self.bit_len = n*n
		return 2**(self.bit_len)

	def createG(self, i):
		g = nx.DiGraph()
		l = self.genArray(i)
		#pdb.set_trace()
		shape = (self.size, self.size)
		data = np.array(l)
		ad_matrix = data.reshape(shape)
		for i in xrange(self.size):
			for j in xrange(self.size):
				if ad_matrix[i][j] == 1:
					g.add_edge(i, j)
		u_g = g.to_undirected()
		if len(g) == self.size and nx.is_connected(u_g):
			return g
		return False

	def genArray(self, i):
		l = [int(x) for x in bin(i)[2:]]
		x = [0 for v in xrange(self.bit_len - len(l))]
		return x + l
```

`Genius/test.py`:

```py
import pickle
from raw_graphs import *

with open(".\\extracted-acfg\\nbsmtp.cfg", 'rb') as f:
    tmp = pickle.load(f, encoding="bytes")
    print(tmp)
    print(tmp.binary_name)
    print(tmp.raw_graph_list)
    print(tmp.raw_graph_list[0])
    print("==x=x=x=x=xxx")
    print(tmp.raw_graph_list[0].funcname, '\n')
    print(tmp.raw_graph_list[0].g, type(tmp.raw_graph_list[0].g), '\n')
    print(tmp.raw_graph_list[0].discovre_features)


'''
    self.funcname = funcname
    self.old_g = g
    self.g = nx.DiGraph()
    self.discovre_features = func_f
    self.attributing()
'''
```

`IDA_appendix/idc_bc695.py`:

```py
# Autogenerated on: 09/14/17 12:29:31

import ida_bytes
import ida_fixup
import ida_ida
import ida_idaapi
import ida_idp
import ida_kernwin
import ida_nalt
import ida_name
import ida_segment
from idc import *

def Compile(file): return CompileEx(file, 1)
def OpOffset(ea, base): return op_plain_offset(ea, -1, base)
def OpNum(ea): return op_num(ea, -1)
def OpChar(ea): return op_chr(ea, -1)
def OpSegment(ea): return op_seg(ea, -1)
def OpDec(ea): return op_dec(ea, -1)
def OpAlt1(ea, str): return op_man(ea, 0, str)
def OpAlt2(ea, str): return op_man(ea, 1, str)
def StringStp(x): return set_inf_attr(INF_STRLIT_BREAK, x)
def LowVoids(x): return set_inf_attr(INF_LOW_OFF, x)
def HighVoids(x): return set_inf_attr(INF_HIGH_OFF, x)
def TailDepth(x): return set_inf_attr(INF_MAXREF, x)
def Analysis(x): return set_flag(INF_GENFLAGS, INFFL_AUTO, x)
def Comments(x): return set_flag(INF_CMTFLAG, SW_ALLCMT, x)
def Voids(x): return set_flag(INF_OUTFLAGS, OFLG_SHOW_VOID, x)
def XrefShow(x): return set_inf_attr(INF_XREFNUM, x)
def Indent(x): return set_inf_attr(INF_INDENT, x)
def CmtIndent(x): return set_inf_attr(INF_COMMENT, x)
def AutoShow(x): return set_flag(INF_OUTFLAGS, OFLG_SHOW_AUTO, x)
def MinEA(): return get_inf_attr(INF_MIN_EA)
def MaxEA(): return get_inf_attr(INF_MAX_EA)
def StartEA(): return get_inf_attr(INF_START_EA)
def set_start_cs(x): return set_inf_attr(INF_START_CS, x)
def set_start_ip(x): return set_inf_attr(INF_START_IP, x)
def AddConst(enum_id, name, value): return add_enum_member(enum_id, name, value, -1)
def AddStruc(index, name): return add_struc(index, name, 0)
def AddUnion(index, name): return add_struc(index, name, 1)
def OpStroff(ea, n, strid): return op_stroff(ea, n, strid, 0)
def OpEnum(ea, n, enumid): return op_enum(ea, n, enumid, 0)
def DelConst(id, v, mask): return del_enum_member(id, v, 0, mask)
def GetConst(id, v, mask): return get_enum_member(id, v, 0, mask)
def AnalyseRange(sEA, eEA): return plan_and_wait(sEA, eEA)
def AnalyseArea(sEA, eEA): return plan_and_wait(sEA, eEA)
def AnalyzeArea(sEA, eEA): return plan_and_wait(sEA, eEA)
def MakeStruct(ea, name): return create_struct(ea, -1, name)
def Name(ea): return get_name(ea, ida_name.GN_VISIBLE)
def GetTrueName(ea): return get_name(ea)
def MakeName(ea, name): return set_name(ea, name, SN_CHECK)
def GetFrame(ea): return get_func_attr(ea, FUNCATTR_FRAME)
def GetFrameLvarSize(ea): return get_func_attr(ea, FUNCATTR_FRSIZE)
def GetFrameRegsSize(ea): return get_func_attr(ea, FUNCATTR_FRREGS)
def GetFrameArgsSize(ea): return get_func_attr(ea, FUNCATTR_ARGSIZE)
def GetFunctionFlags(ea): return get_func_attr(ea, FUNCATTR_FLAGS)
def SetFunctionFlags(ea, flags): return set_func_attr(ea, FUNCATTR_FLAGS, flags)
def SegCreate(a1, a2, base, use32, align, comb): return AddSeg(a1, a2, base, use32, align, comb)
def SegDelete(ea, flags): return del_segm(ea, flags)
def SegBounds(ea, startea, endea, flags): return set_segment_bounds(ea, startea, endea, flags)
def SegRename(ea, name): return set_segm_name(ea, name)
def SegClass(ea, klass): return set_segm_class(ea, klass)
def SegAddrng(ea, bitness): return set_segm_addressing(ea, bitness)
def SegDefReg(ea, reg, value): return set_default_sreg_value(ea, reg, value)
def Comment(ea): return get_cmt(ea, 0)
def RptCmt(ea): return get_cmt(ea, 1)
def MakeByte(ea): return create_data(ea, FF_BYTE, 1, ida_idaapi.BADADDR)
def MakeWord(ea): return create_data(ea, FF_WORD, 2, ida_idaapi.BADADDR)
def MakeDword(ea): return create_data(ea, FF_DWORD, 4, ida_idaapi.BADADDR)
def MakeQword(ea): return create_data(ea, FF_QWORD, 8, ida_idaapi.BADADDR)
def MakeOword(ea): return create_data(ea, FF_OWORD, 16, ida_idaapi.BADADDR)
def MakeYword(ea): return create_data(ea, FF_YWORD, 32, ida_idaapi.BADADDR)
def MakeFloat(ea): return create_data(ea, FF_FLOAT, 4, ida_idaapi.BADADDR)
def MakeDouble(ea): return create_data(ea, FF_DOUBLE, 8, ida_idaapi.BADADDR)
def MakePackReal(ea): return create_data(ea, FF_PACKREAL, 10, ida_idaapi.BADADDR)
def MakeTbyte(ea): return create_data(ea, FF_TBYTE, 10, ida_idaapi.BADADDR)
def MakeCustomData(ea, size, dtid, fid): return create_data(ea, FF_CUSTOM, size, dtid|((fid)<<16))
def SetReg(ea, reg, value): return split_sreg_range(ea, reg, value, SR_user)
def SegByName(segname): return selector_by_name(segname)
def MK_FP(seg, off): return to_ea(seg, off)
def toEA(seg, off): return to_ea(seg, off)
def MakeCode(ea): return create_insn(ea)
def MakeNameEx(ea, name, flags): return set_name(ea, name, flags)
def MakeArray(ea, nitems): return make_array(ea, nitems)
def MakeData(ea, flags, size, tid): return create_data(ea, flags, size, tid)
def GetRegValue(name): return get_reg_value(name)
def SetRegValue(value, name): return set_reg_value(value, name)
def Byte(ea): return get_wide_byte(ea)
def Word(ea): return get_wide_word(ea)
def Dword(ea): return get_wide_dword(ea)
def Qword(ea): return get_qword(ea)
def LocByName(name): return get_name_ea_simple(name)
def ScreenEA(): return get_screen_ea()
def CleanupAppcall(): return cleanup_appcall()
def GetTinfo(ea): return get_tinfo(ea)
def OpChr(ea, n): return op_chr(ea, n)
def OpSeg(ea, n): return op_seg(ea, n)
def OpNumber(ea, n): return op_num(ea, n)
def OpDecimal(ea, n): return op_dec(ea, n)
def OpOctal(ea, n): return op_oct(ea, n)
def OpBinary(ea, n): return op_bin(ea, n)
def OpHex(ea, n): return op_hex(ea, n)
def OpAlt(ea, n, str): return op_man(ea, n, str)
def OpSign(ea, n): return toggle_sign(ea, n)
def OpNot(ea, n): return toggle_bnot(ea, n)
def OpEnumEx(ea, n, enumid, serial): return op_enum(ea, n, enumid, serial)
def OpStroffEx(ea, n, strid, delta): return op_stroff(ea, n, strid, delta)
def OpStkvar(ea, n): return op_stkvar(ea, n)
def OpFloat(ea, n): return op_flt(ea, n)
def OpOffEx(ea, n, reftype, target, base, tdelta): return op_offset(ea, n, reftype, target, base, tdelta)
def OpOff(ea, n, base): return op_plain_offset(ea, n, base)
def MakeStructEx(ea, size, strname): return create_struct(ea, size, strname)
def MakeStr(ea, endea): return create_strlit(ea, 0 if (endea) == ida_idaapi.BADADDR else endea-ea)
def Jump(ea): return jumpto(ea)
def GenerateFile(type, file_handle, ea1, ea2, flags): return gen_file(type, file_handle, ea1, ea2, flags)
def GenFuncGdl(outfile, title, ea1, ea2, flags): return gen_flow_graph(outfile, title, ea1, ea2, flags)
def GenCallGdl(outfile, title, flags): return gen_simple_call_chart(outfile, title, flags)
def IdbByte(ea): return get_db_byte(ea)
def DbgByte(ea): return read_dbg_byte(ea)
def DbgWord(ea): return read_dbg_word(ea)
def DbgDword(ea): return read_dbg_dword(ea)
def DbgQword(ea): return read_dbg_qword(ea)
def DbgRead(ea, size): return read_dbg_memory(ea, size)
def DbgWrite(ea, data): return write_dbg_memory(ea, data)
def PatchDbgByte(ea, value): return patch_dbg_byte(ea, value)
def PatchByte(ea, value): return patch_byte(ea, value)
def PatchWord(ea, value): return patch_word(ea, value)
def PatchDword(ea, value): return patch_dword(ea, value)
def PatchQword(ea, value): return patch_qword(ea, value)
def SetProcessorType(processor, level): return set_processor_type(processor, level)
def GetProcessorName(): return get_processor_name()
def SetTargetAssembler(asmidx): return set_target_assembler(asmidx)
def Batch(batch): return batch(batch)
def SetSegDefReg(ea, reg, value): return set_default_sreg_value(ea, reg, value)
def GetReg(ea, reg): return get_sreg(ea, reg)
def SetRegEx(ea, reg, value, tag): return split_sreg_range(ea, reg, value, tag)
def AskStr(defval, prompt): return ida_kernwin.ask_str(defval, 0, prompt)
def AskFile(for_saving, mask, prompt): return ida_kernwin.ask_file(for_saving, mask, prompt)
def AskAddr(defval, prompt): return ida_kernwin.ask_addr(defval, prompt)
def AskLong(defval, prompt): return ida_kernwin.ask_long(defval, prompt)
def AskSeg(defval, prompt): return ask_seg(defval, prompt)
def AskIdent(defval, prompt): return ida_kernwin.ask_str(defval, HINT_IDENT, prompt)
def AskYN(defval, prompt): return ask_yn(defval, prompt)
Warning=ida_kernwin.warning
Fatal=ida_kernwin.error
def DeleteAll(): return delete_all_segments()
def AddSegEx(startea, endea, sel, use32, align, comb, flags): return add_segm_ex(startea, endea, sel, use32, align, comb, flags)
def SetSegBounds(ea, startea, endea, flags): return set_segment_bounds(ea, startea, endea, flags)
def RenameSeg(ea, name): return set_segm_name(ea, name)
def SetSegClass(ea, klass): return set_segm_class(ea, klass)
def SetSegAddressing(ea, bitness): return set_segm_addressing(ea, bitness)
def SetSegmentAttr(segea, attr, value): return set_segm_attr(segea, attr, value)
def GetSegmentAttr(segea, attr): return get_segm_attr(segea, attr)
def SetStorageType(startEA, endEA, stt): return set_storage_type(startEA, endEA, stt)
def MoveSegm(ea, to, flags): return move_segm(ea, to, flags)
def RebaseProgram(delta, flags): return rebase_program(delta, flags)
def GetNsecStamp(): return get_nsec_stamp()
def LocByNameEx(From, name): return get_name_ea(From, name)
def SegByBase(base): return get_segm_by_sel(base)
def GetCurrentLine(): return get_curline()
def SelStart(): return read_selection_start()
def SelEnd(): return read_selection_end()
def FirstSeg(): return get_first_seg()
def NextSeg(ea): return get_next_seg(ea)
def SegName(ea): return get_segm_name(ea)
def CommentEx(ea, repeatable): return get_cmt(ea, repeatable)
def AltOp(ea, n): return get_forced_operand(ea, n)
def GetDisasmEx(ea, flags): return generate_disasm_line(ea, flags)
def GetMnem(ea): return print_insn_mnem(ea)
def GetOpType(ea, n): return get_operand_type(ea, n)
def GetOperandValue(ea, n): return get_operand_value(ea, n)
def DecodeInstruction(ea): return decode_insn(ea)
def NextAddr(ea): return next_addr(ea)
def PrevAddr(ea): return prev_addr(ea)
def NextNotTail(ea): return next_not_tail(ea)
def PrevNotTail(ea): return prev_not_tail(ea)
def ItemHead(ea): return get_item_head(ea)
def ItemEnd(ea): return get_item_end(ea)
def ItemSize(ea): return get_item_size(ea)
def AnalyzeRange(sEA, eEA): return plan_and_wait(sEA, eEA)
def ExecIDC(input): return exec_idc(input)
def Eval(expr): return eval(expr)
def Exit(code): return qexit(code)
def Checkpoint(num): return test_checkpoint(num)
def GetTestId(): return get_test_id()
def FindVoid(ea, flag): return find_suspop(ea, flag)
def FindCode(ea, flag): return find_code(ea, flag)
def FindData(ea, flag): return find_data(ea, flag)
def FindUnexplored(ea, flag): return find_unknown(ea, flag)
def FindExplored(ea, flag): return find_defined(ea, flag)
def FindImmediate(ea, flag, value): return find_imm(ea, flag, value)
def FindText(ea, flag, y, x, str): return find_text(ea, flag, y, x, str)
def AddCodeXref(From, To, flowtype): return add_cref(From, To, flowtype)
def DelCodeXref(From, To, undef): return del_cref(From, To, undef)
def Rfirst(From): return get_first_cref_from(From)
def RfirstB(To): return get_first_cref_to(To)
def Rnext(From, current): return get_next_cref_from(From, current)
def RnextB(To, current): return get_next_cref_to(To, current)
def Rfirst0(From): return get_first_fcref_from(From)
def RfirstB0(To): return get_first_fcref_to(To)
def Rnext0(From, current): return get_next_fcref_from(From, current)
def RnextB0(To, current): return get_next_fcref_to(To, current)
def Dfirst(From): return get_first_dref_from(From)
def Dnext(From, current): return get_next_dref_from(From, current)
def DfirstB(To): return get_first_dref_to(To)
def DnextB(To, current): return get_next_dref_to(To, current)
def XrefType(): return get_xref_type()
def AutoUnmark(start, end, queuetype): return auto_unmark(start, end, queuetype)
def AutoMark2(start, end, queuetype): return auto_mark_range(start, end, queuetype)
def SetSelector(sel, value): return set_selector(sel, value)
def AskSelector(sel): return sel2para(sel)
def ask_selector(sel): return sel2para(sel)
def FindSelector(val): return find_selector(val)
def DelSelector(sel): return del_selector(sel)
def MakeFunction(start, end): return add_func(start, end)
def DelFunction(ea): return del_func(ea)
def SetFunctionEnd(ea, end): return set_func_end(ea, end)
def NextFunction(ea): return get_next_func(ea)
def PrevFunction(ea): return get_prev_func(ea)
def GetFunctionAttr(ea, attr): return get_func_attr(ea, attr)
def SetFunctionAttr(ea, attr, value): return set_func_attr(ea, attr, value)
def GetFunctionName(ea): return get_func_name(ea)
def GetFunctionCmt(ea, repeatable): return get_func_cmt(ea, repeatable)
def SetFunctionCmt(ea, cmt, repeatable): return set_func_cmt(ea, cmt, repeatable)
def ChooseFunction(title): return choose_func(title)
def GetFuncOffset(ea): return get_func_off_str(ea)
def MakeLocal(start, end, location, name): return define_local_var(start, end, location, name)
def FindFuncEnd(ea): return find_func_end(ea)
def GetFrameSize(ea): return get_frame_size(ea)
def MakeFrame(ea, lvsize, frregs, argsize): return set_frame_size(ea, lvsize, frregs, argsize)
def GetSpd(ea): return get_spd(ea)
def GetSpDiff(ea): return get_sp_delta(ea)
def DelStkPnt(func_ea, ea): return del_stkpnt(func_ea, ea)
def AddAutoStkPnt2(func_ea, ea, delta): return add_auto_stkpnt(func_ea, ea, delta)
def RecalcSpd(cur_ea): return recalc_spd(cur_ea)
def GetMinSpd(func_ea): return get_min_spd_ea(func_ea)
def GetFchunkAttr(ea, attr): return get_fchunk_attr(ea, attr)
def SetFchunkAttr(ea, attr, value): return set_fchunk_attr(ea, attr, value)
def GetFchunkReferer(ea, idx): return get_fchunk_referer(ea, idx)
def NextFchunk(ea): return get_next_fchunk(ea)
def PrevFchunk(ea): return get_prev_fchunk(ea)
def AppendFchunk(funcea, ea1, ea2): return append_func_tail(funcea, ea1, ea2)
def RemoveFchunk(funcea, tailea): return remove_fchunk(funcea, tailea)
def SetFchunkOwner(tailea, funcea): return set_tail_owner(tailea, funcea)
def FirstFuncFchunk(funcea): return first_func_chunk(funcea)
def NextFuncFchunk(funcea, tailea): return next_func_chunk(funcea, tailea)
def GetEntryPointQty(): return get_entry_qty()
def AddEntryPoint(ordinal, ea, name, makecode): return add_entry(ordinal, ea, name, makecode)
def GetEntryName(ordinal): return get_entry_name(ordinal)
def GetEntryOrdinal(index): return get_entry_ordinal(index)
def GetEntryPoint(ordinal): return get_entry(ordinal)
def RenameEntryPoint(ordinal, name): return rename_entry(ordinal, name)
def GetNextFixupEA(ea): return get_next_fixup_ea(ea)
def GetPrevFixupEA(ea): return get_prev_fixup_ea(ea)
def GetFixupTgtType(ea): return get_fixup_target_type(ea)
def GetFixupTgtFlags(ea): return get_fixup_target_flags(ea)
def GetFixupTgtSel(ea): return get_fixup_target_sel(ea)
def GetFixupTgtOff(ea): return get_fixup_target_off(ea)
def GetFixupTgtDispl(ea): return get_fixup_target_dis(ea)
def SetFixup(ea, type, targetsel, targetoff, displ): return set_fixup(ea, type, targetsel, targetoff, displ)
def DelFixup(ea): return del_fixup(ea)
def MarkPosition(ea, lnnum, x, y, slot, comment): return put_bookmark(ea, lnnum, x, y, slot, comment)
def GetMarkedPos(slot): return get_bookmark(slot)
def GetMarkComment(slot): return get_bookmark_desc(slot)
def GetStrucQty(): return get_struc_qty()
def GetFirstStrucIdx(): return get_first_struc_idx()
def GetLastStrucIdx(): return get_last_struc_idx()
def GetNextStrucIdx(index): return get_next_struc_idx(index)
def GetPrevStrucIdx(index): return get_prev_struc_idx(index)
def GetStrucIdx(id): return get_struc_idx(id)
def GetStrucId(index): return get_struc_by_idx(index)
def GetStrucIdByName(name): return get_struc_id(name)
def GetStrucName(id): return get_struc_name(id)
def GetStrucComment(id, repeatable): return get_struc_cmt(id, repeatable)
def GetStrucSize(id): return get_struc_size(id)
def GetMemberQty(id): return get_member_qty(id)
def GetStrucPrevOff(id, offset): return get_prev_offset(id, offset)
def GetStrucNextOff(id, offset): return get_next_offset(id, offset)
def GetFirstMember(id): return get_first_member(id)
def GetLastMember(id): return get_last_member(id)
def GetMemberOffset(id, member_name): return get_member_offset(id, member_name)
def GetMemberName(id, member_offset): return get_member_name(id, member_offset)
def GetMemberComment(id, member_offset, repeatable): return get_member_cmt(id, member_offset, repeatable)
def GetMemberSize(id, member_offset): return get_member_size(id, member_offset)
def GetMemberFlag(id, member_offset): return get_member_flag(id, member_offset)
def GetMemberStrId(id, member_offset): return get_member_strid(id, member_offset)
def GetMemberId(id, member_offset): return get_member_id(id, member_offset)
def AddStrucEx(index, name, is_union): return add_struc(index, name, is_union)
def IsUnion(id): return is_union(id)
def DelStruc(id): return del_struc(id)
def SetStrucIdx(id, index): return set_struc_idx(id, index)
def SetStrucName(id, name): return set_struc_name(id, name)
def SetStrucComment(id, comment, repeatable): return set_struc_cmt(id, comment, repeatable)
def SetStrucAlign(sid, shift): return set_struc_align(sid, shift)
AddStrucMember=add_struc_member
def DelStrucMember(id, member_offset): return del_struc_member(id, member_offset)
def SetMemberName(id, member_offset, name): return set_member_name(id, member_offset, name)
SetMemberType=set_member_type
def SetMemberComment(id, member_offset, comment, repeatable): return set_member_cmt(id, member_offset, comment, repeatable)
def ExpandStruc(id, offset, delta, recalc): return expand_struc(id, offset, delta, recalc)
def GetVxdFuncName(vxdnum, fnnum): return get_vxd_func_name(vxdnum, fnnum)
def SetLineNumber(ea, lnnum): return set_source_linnum(ea, lnnum)
def GetLineNumber(ea): return get_source_linnum(ea)
def DelLineNumber(ea): return del_source_linnum(ea)
def AddSourceFile(ea1, uea2, filename): return add_sourcefile(ea1, uea2, filename)
def GetSourceFile(ea): return get_sourcefile(ea)
def DelSourceFile(ea): return del_sourcefile(ea)
def CreateArray(name): return create_array(name)
def GetArrayId(name): return get_array_id(name)
def RenameArray(id, newname): return rename_array(id, newname)
def DeleteArray(id): return delete_array(id)
def SetArrayLong(id, idx, value): return set_array_long(id, idx, value)
def SetArrayString(id, idx, str): return set_array_string(id, idx, str)
def GetArrayElement(tag, id, idx): return get_array_element(tag, id, idx)
def DelArrayElement(tag, id, idx): return del_array_element(tag, id, idx)
def GetFirstIndex(tag, id): return get_first_index(tag, id)
def GetNextIndex(tag, id, idx): return get_next_index(tag, id, idx)
def GetLastIndex(tag, id): return get_last_index(tag, id)
def GetPrevIndex(tag, id, idx): return get_prev_index(tag, id, idx)
def SetHashLong(id, idx, value): return set_hash_long(id, idx, value)
def SetHashString(id, idx, value): return set_hash_string(id, idx, value)
def GetHashLong(id, idx): return get_hash_long(id, idx)
def GetHashString(id, idx): return get_hash_string(id, idx)
def DelHashElement(id, idx): return del_hash_string(id, idx)
def GetFirstHashKey(id): return get_first_hash_key(id)
def GetNextHashKey(id, idx): return get_next_hash_key(id, idx)
def GetLastHashKey(id): return get_last_hash_key(id)
def GetPrevHashKey(id, idx): return get_prev_hash_key(id, idx)
def GetEnumQty(): return get_enum_qty()
def GetnEnum(idx): return getn_enum(idx)
def GetEnumIdx(enum_id): return get_enum_idx(enum_id)
def GetEnum(name): return get_enum(name)
def GetEnumName(enum_id): return get_enum_name(enum_id)
def GetEnumCmt(enum_id, repeatable): return get_enum_cmt(enum_id, repeatable)
def GetEnumSize(enum_id): return get_enum_size(enum_id)
def GetEnumWidth(enum_id): return get_enum_width(enum_id)
def GetEnumFlag(enum_id): return get_enum_flag(enum_id)
def GetConstByName(name): return get_enum_member_by_name(name)
def GetConstValue(const_id): return get_enum_member_value(const_id)
def GetConstBmask(const_id): return get_enum_member_bmask(const_id)
def GetConstEnum(const_id): return get_enum_member_enum(const_id)
def GetConstEx(enum_id, value, serial, bmask): return get_enum_member(enum_id, value, serial, bmask)
def GetFirstBmask(enum_id): return get_first_bmask(enum_id)
def GetLastBmask(enum_id): return get_last_bmask(enum_id)
def GetNextBmask(enum_id, value): return get_next_bmask(enum_id, value)
def GetPrevBmask(enum_id, value): return get_prev_bmask(enum_id, value)
def GetFirstConst(enum_id, bmask): return get_first_enum_member(enum_id, bmask)
def GetLastConst(enum_id, bmask): return get_last_enum_member(enum_id, bmask)
def GetNextConst(enum_id, value, bmask): return get_next_enum_member(enum_id, value, bmask)
def GetPrevConst(enum_id, value, bmask): return get_prev_enum_member(enum_id, value, bmask)
def GetConstName(const_id): return get_enum_member_name(const_id)
def GetConstCmt(const_id, repeatable): return get_enum_member_cmt(const_id, repeatable)
def AddEnum(idx, name, flag): return add_enum(idx, name, flag)
def DelEnum(enum_id): return del_enum(enum_id)
def SetEnumIdx(enum_id, idx): return set_enum_idx(enum_id, idx)
def SetEnumName(enum_id, name): return set_enum_name(enum_id, name)
def SetEnumCmt(enum_id, cmt, repeatable): return set_enum_cmt(enum_id, cmt, repeatable)
def SetEnumFlag(enum_id, flag): return set_enum_flag(enum_id, flag)
def SetEnumWidth(enum_id, width): return set_enum_width(enum_id, width)
def SetEnumBf(enum_id, flag): return set_enum_bf(enum_id, flag)
def AddConstEx(enum_id, name, value, bmask): return add_enum_member(enum_id, name, value, bmask)
def DelConstEx(enum_id, value, serial, bmask): return del_enum_member(enum_id, value, serial, bmask)
def SetConstName(const_id, name): return set_enum_member_name(const_id, name)
def SetConstCmt(const_id, cmt, repeatable): return set_enum_member_cmt(const_id, cmt, repeatable)
def IsBitfield(enum_id): return is_bf(enum_id)
def SetBmaskName(enum_id, bmask, name): return set_bmask_name(enum_id, bmask, name)
def GetBmaskName(enum_id, bmask): return get_bmask_name(enum_id, bmask)
def SetBmaskCmt(enum_id, bmask, cmt, repeatable): return set_bmask_cmt(enum_id, bmask, cmt, repeatable)
def GetBmaskCmt(enum_id, bmask, repeatable): return get_bmask_cmt(enum_id, bmask, repeatable)
def GetLongPrm(offset): return get_inf_attr(offset)
def GetShortPrm(offset): return get_inf_attr(offset)
def GetCharPrm(offset): return get_inf_attr(offset)
def SetLongPrm(offset, value): return set_inf_attr(offset, value)
def SetShortPrm(offset, value): return set_inf_attr(offset, value)
def SetCharPrm(offset, value): return set_inf_attr(offset, value)
def ChangeConfig(directive): return process_config_line(directive)
def AddHotkey(hotkey, idcfunc): return add_idc_hotkey(hotkey, idcfunc)
def DelHotkey(hotkey): return del_idc_hotkey(hotkey)
def GetInputFile(): return get_root_filename()
def GetInputFilePath(): return get_input_file_path()
def SetInputFilePath(path): return set_root_filename(path)
def GetInputFileSize(): return retrieve_input_file_size()
def Exec(command): return call_system(command)
def Sleep(milliseconds): return qsleep(milliseconds)
def GetIdaDirectory(): return idadir()
def GetIdbPath(): return get_idb_path()
def GetInputMD5(): return retrieve_input_file_md5()
def GetInputSHA256(): return retrieve_input_file_sha256()
def DelUserInfo(): return del_user_info()
def OpHigh(ea, n, target): return op_offset_high16(ea, n, target)
def MakeAlign(ea, count, align): return create_align(ea, count, align)
def Demangle(name, disable_mask): return demangle_name(name, disable_mask)
def SetManualInsn(ea, insn): return set_manual_insn(ea, insn)
def GetManualInsn(ea): return get_manual_insn(ea)
def SetArrayFormat(ea, flags, litems, align): return set_array_params(ea, flags, litems, align)
def LoadTil(name): return add_default_til(name)
def Til2Idb(idx, type_name): return import_type(idx, type_name)
def GetMaxLocalType(): return get_ordinal_qty()
def SetLocalType(ordinal, input, flags): return set_local_type(ordinal, input, flags)
def GetLocalTinfo(ordinal): return get_local_tinfo(ordinal)
def GetLocalTypeName(ordinal): return get_numbered_type_name(ordinal)
def PrintLocalTypes(ordinals, flags): return print_decls(ordinals, flags)
def SetStatus(status): return set_ida_state(status)
def Refresh(): return refresh_idaview_anyway()
def RefreshLists(): return refresh_choosers()
def RunPlugin(name, arg): return load_and_run_plugin(name, arg)
def ApplySig(name): return plan_to_apply_idasgn(name)
def GetStringType(ea): return get_str_type(ea)
def GetOriginalByte(ea): return get_original_byte(ea)
def GetFpNum(ea, n): return get_fpnum(ea, n)
def HideRange(start, end, description, header, footer, color): return add_hidden_range(start, end, description, header, footer, color)
def SetHiddenRange(ea, visible): return update_hidden_range(ea, visible)
def DelHiddenRange(ea): return del_hidden_range(ea)
def GetType(ea): return get_type(ea)
def GuessType(ea): return guess_type(ea)
def ParseType(input, flags): return parse_decl(input, flags)
def GetColor(ea, what): return get_color(ea, what)
def SetColor(ea, what, color): return set_color(ea, what, color)
def GetBptQty(): return get_bpt_qty()
def GetBptEA(n): return get_bpt_ea(n)
def GetBptAttr(ea, bptattr): return get_bpt_attr(ea, bptattr)
def SetBptAttr(ea, bptattr, value): return set_bpt_attr(ea, bptattr, value)
def SetBptCndEx(ea, cnd, is_lowcnd): return set_bpt_cond(ea, cnd, is_lowcnd)
def SetBptCnd(ea, cnd): return set_bpt_cond(ea, cnd)
def AddBptEx(ea, size, bpttype): return add_bpt(ea, size, bpttype)
def AddBpt(ea): return add_bpt(ea)
def DelBpt(ea): return del_bpt(ea)
def EnableBpt(ea, enable): return enable_bpt(ea, enable)
def CheckBpt(ea): return check_bpt(ea)
def LoadDebugger(dbgname, use_remote): return load_debugger(dbgname, use_remote)
def StartDebugger(path, args, sdir): return start_process(path, args, sdir)
def StopDebugger(): return exit_process()
def PauseProcess(): return suspend_process()
def GetProcessQty(): return get_processes().size
def GetProcessPid(idx): return get_processes()[idx].pid
def GetProcessName(idx): return get_processes()[idx].name
def AttachProcess(pid, event_id): return attach_process(pid, event_id)
def DetachProcess(): return detach_process()
def GetThreadQty(): return get_thread_qty()
def GetThreadId(idx): return getn_thread(idx)
def GetCurrentThreadId(): return get_current_thread()
def SelectThread(tid): return select_thread(tid)
def SuspendThread(tid): return suspend_thread(tid)
def ResumeThread(tid): return resume_thread(tid)
def GetFirstModule(): return get_first_module()
def GetNextModule(base): return get_next_module(base)
def GetModuleName(base): return get_module_name(base)
def GetModuleSize(base): return get_module_size(base)
def StepInto(): return step_into()
def StepOver(): return step_over()
def RunTo(ea): return run_to(ea)
def StepUntilRet(): return step_until_ret()
def GetDebuggerEvent(wfne, timeout): return wait_for_next_event(wfne, timeout)
def GetProcessState(): return get_process_state()
def SetDebuggerOptions(opt): return set_debugger_options(opt)
def SetRemoteDebugger(hostname, password, portnum): return set_remote_debugger(hostname, password, portnum)
def GetDebuggerEventCondition(): return get_debugger_event_cond()
def SetDebuggerEventCondition(condition): return set_debugger_event_cond(condition)
def GetEventId(): return get_event_id()
def GetEventPid(): return get_event_pid()
def GetEventTid(): return get_event_tid()
def GetEventEa(): return get_event_ea()
def IsEventHandled(): return is_event_handled()
def GetEventModuleName(): return get_event_module_name()
def GetEventModuleBase(): return get_event_module_base()
def GetEventModuleSize(): return get_event_module_size()
def GetEventExitCode(): return get_event_exit_code()
def GetEventInfo(): return get_event_info()
def GetEventBptHardwareEa(): return get_event_bpt_hea()
def GetEventExceptionCode(): return get_event_exc_code()
def GetEventExceptionEa(): return get_event_exc_ea()
def GetEventExceptionInfo(): return get_event_exc_info()
def CanExceptionContinue(): return can_exc_continue()
def RefreshDebuggerMemory(): return refresh_debugger_memory()
def TakeMemorySnapshot(only_loader_segs): return take_memory_snapshot(only_loader_segs)
def EnableTracing(trace_level, enable): return enable_tracing(trace_level, enable)
def GetStepTraceOptions(): return get_step_trace_options()
def SetStepTraceOptions(options): return set_step_trace_options(options)
def GetExceptionQty(): return get_exception_qty()
def GetExceptionCode(idx): return get_exception_code(idx)
def GetExceptionName(code): return get_exception_name(code)
def GetExceptionFlags(code): return get_exception_flags(code)
def DefineException(code, name, desc, flags): return define_exception(code, name, desc, flags)
def SetExceptionFlags(code, flags): return set_exception_flags(code, flags)
def ForgetException(code): return forget_exception(code)
def IsString(var): return value_is_string(var)
def IsLong(var): return value_is_long(var)
def IsFloat(var): return value_is_float(var)
def IsObject(var): return value_is_object(var)
def IsFunc(var): return value_is_func(var)
def IsPvoid(var): return value_is_pvoid(var)
def IsInt64(var): return value_is_int64(var)
def GetCustomDataType(name): return find_custom_data_type(name)
def GetCustomDataFormat(name): return find_custom_data_format(name)
def BeginTypeUpdating(utp): return begin_type_updating(utp)
def EndTypeUpdating(utp): return end_type_updating(utp)
def FormatCData(outvec, value, type, options, info): return format_cdata(outvec, value, type, options, info)
def ValidateNames(): return validate_idb_names()
def SegStart(ea): return get_segm_attr(ea, SEGATTR_START)
def SegEnd(ea): return get_segm_attr(ea, SEGATTR_END)
def SegAlign(ea, alignment): return set_segm_attr(ea, SEGATTR_ALIGN, alignment)
def SegComb(ea, comb): return set_segm_attr(ea, SEGATTR_COMB, comb)
def SetSegmentType(ea, type): return set_segm_attr(ea, SEGATTR_TYPE, type)
def MakeComm(ea, cmt): return set_cmt(ea, cmt, 0)
def MakeRptCmt(ea, cmt): return set_cmt(ea, cmt, 1)
def MakeUnkn(ea, flags): return del_items(ea, flags)
def MakeUnknown(ea, size, flags): return del_items(ea, flags, size)
def LineA(ea, n): return get_extra_cmt(ea, E_PREV + n)
def LineB(ea, n): return get_extra_cmt(ea, E_NEXT + n)
def ExtLinA(ea, n, line): return update_extra_cmt(ea, E_PREV + n, line)
def ExtLinB(ea, n, line): return update_extra_cmt(ea, E_NEXT + n, line)
def DelExtLnA(ea, n): return del_extra_cmt(ea, E_PREV + n)
def DelExtLnB(ea, n): return del_extra_cmt(ea, E_NEXT + n)
def SetSpDiff(ea, delta): return add_user_stkpnt(ea, delta)
def AddUserStkPnt(ea, delta): return add_user_stkpnt(ea, delta)
def NameEx(From, ea): return get_name(ea, ida_name.GN_VISIBLE | calc_gtn_flags(From, ea))
def GetTrueNameEx(From, ea): return get_name(ea, calc_gtn_flags(From, ea))
Message=msg
UMessage=msg
def DelSeg(ea, flags): return del_segm(ea, flags)
def Wait(): return auto_wait()
def LoadTraceFile(filename): return load_trace_file(filename)
def SaveTraceFile(filename, description): return save_trace_file(filename, description)
def CheckTraceFile(filename): return is_valid_trace_file(filename)
def DiffTraceFile(filename): return diff_trace_file(filename)
def SetTraceDesc(filename, description): return get_trace_file_desc(filename, description)
def GetTraceDesc(filename): return set_trace_file_desc(filename)
def GetMaxTev(): return get_tev_qty()
def GetTevEa(tev): return get_tev_ea(tev)
def GetTevType(tev): return get_tev_type(tev)
def GetTevTid(tev): return get_tev_tid(tev)
def GetTevRegVal(tev, reg): return get_tev_reg(tev, reg)
def GetTevRegMemQty(tev): return get_tev_mem_qty(tev)
def GetTevRegMem(tev, idx): return get_tev_mem(tev, idx)
def GetTevRegMemEa(tev, idx): return get_tev_mem_ea(tev, idx)
def GetTevCallee(tev): return get_call_tev_callee(tev)
def GetTevReturn(tev): return get_ret_tev_return(tev)
def GetBptTevEa(tev): return get_bpt_tev_ea(tev)
def ArmForceBLJump(ea): return force_bl_jump(ea)
def ArmForceBLCall(ea): return force_bl_call(ea)
def StepBack(): return step_back()
def SetCurrentTev(event): return set_current_tev(event)
def GetCurrentTev(): return get_current_tev()
def BochsCommand(cmd): return send_dbg_command(cmd)
def SendGDBMonitor(cmd): return send_dbg_command(cmd)
def WinDbgCommand(cmd): return send_dbg_command(cmd)
def SetAppcallOptions(x): return set_inf_attr(INF_APPCALL_OPTIONS, x)
def GetAppcallOptions(): return get_inf_attr(INF_APPCALL_OPTIONS)
AF2_ANORET=ida_ida.AF_ANORET
AF2_CHKUNI=ida_ida.AF_CHKUNI
AF2_DATOFF=ida_ida.AF_DATOFF
AF2_DOCODE=ida_ida.AF_DOCODE
AF2_DODATA=ida_ida.AF_DODATA
AF2_FTAIL=ida_ida.AF_FTAIL
AF2_HFLIRT=ida_ida.AF_HFLIRT
AF2_JUMPTBL=ida_ida.AF_JUMPTBL
AF2_PURDAT=ida_ida.AF_PURDAT
AF2_REGARG=ida_ida.AF_REGARG
AF2_SIGCMT=ida_ida.AF_SIGCMT
AF2_SIGMLT=ida_ida.AF_SIGMLT
AF2_STKARG=ida_ida.AF_STKARG
AF2_TRFUNC=ida_ida.AF_TRFUNC
AF2_VERSP=ida_ida.AF_VERSP
AF_ASCII=ida_ida.AF_STRLIT
ASCF_AUTO=ida_ida.STRF_AUTO
ASCF_COMMENT=ida_ida.STRF_COMMENT
ASCF_GEN=ida_ida.STRF_GEN
ASCF_SAVECASE=ida_ida.STRF_SAVECASE
ASCF_SERIAL=ida_ida.STRF_SERIAL
ASCSTR_C=ida_nalt.STRTYPE_C
ASCSTR_LEN2=ida_nalt.STRTYPE_C_16
ASCSTR_LEN4=ida_nalt.STRTYPE_C_32
ASCSTR_PASCAL=ida_nalt.STRTYPE_PASCAL
ASCSTR_TERMCHR=ida_nalt.STRTYPE_TERMCHR
ASCSTR_ULEN2=ida_nalt.STRTYPE_LEN2_16
ASCSTR_ULEN4=ida_nalt.STRTYPE_LEN4_16
ASCSTR_UNICODE=ida_nalt.STRTYPE_C_16
BeginEA=StartEA
DOUNK_SIMPLE=DELIT_SIMPLE
DOUNK_EXPAND=DELIT_EXPAND
DOUNK_DELNAMES=DELIT_DELNAMES
DelHiddenArea=DelHiddenRange
FF_ASCI=FF_STRLIT
FF_DWRD=FF_DWORD
FF_OWRD=FF_OWORD
FF_QWRD=FF_QWORD
FF_STRU=FF_STRUCT
FF_TBYT=FF_TBYTE
FF_VAR=ida_bytes.FF_UNUSED
FIXUP_BYTE=ida_fixup.FIXUP_OFF8
FIXUP_CREATED=ida_fixup.FIXUPF_CREATED
FIXUP_EXTDEF=ida_fixup.FIXUPF_EXTDEF
FIXUP_REL=ida_fixup.FIXUPF_REL
FIXUP_SELFREL=0
FIXUP_UNUSED=ida_fixup.FIXUPF_UNUSED
GetFlags=get_full_flags
HideArea=HideRange
ResumeProcess=resume_process
def isEnabled(ea): return is_mapped(ea)
def hasValue(F): return has_value(F)
def isByte(F): return is_byte(F)
def isWord(F): return is_word(F)
def isDwrd(F): return is_dword(F)
def isQwrd(F): return is_qword(F)
def isOwrd(F): return is_oword(F)
def isTbyt(F): return is_tbyte(F)
def isFloat(F): return is_float(F)
def isDouble(F): return is_double(F)
def isASCII(F): return is_strlit(F)
def isStruct(F): return is_struct(F)
def isAlign(F): return is_align(F)
def isChar0(F): return is_char0(F)
def isChar1(F): return is_char1(F)
def isCode(F): return is_code(F)
def isData(F): return is_data(F)
def isDefArg0(F): return is_defarg0(F)
def isDefArg1(F): return is_defarg1(F)
def isEnum0(F): return is_enum0(F)
def isEnum1(F): return is_enum1(F)
def isFlow(F): return is_flow(F)
def isHead(F): return is_head(F)
def isLoaded(F): return is_loaded(F)
def isOff0(F): return is_off0(F)
def isOff1(F): return is_off1(F)
def isPackReal(F): return is_pack_real(F)
def isSeg0(F): return is_seg0(F)
def isSeg1(F): return is_seg1(F)
def isStkvar0(F): return is_stkvar0(F)
def isStkvar1(F): return is_stkvar1(F)
def isStroff0(F): return is_stroff0(F)
def isStroff1(F): return is_stroff1(F)
def isTail(F): return is_tail(F)
def isUnknown(F): return is_unknown(F)
SEGDEL_KEEP=ida_segment.SEGMOD_KEEP
SEGDEL_PERM=ida_segment.SEGMOD_KILL
SEGDEL_SILENT=ida_segment.SEGMOD_SILENT
SETPROC_ALL=ida_idp.SETPROC_LOADER_NON_FATAL
SETPROC_COMPAT=ida_idp.SETPROC_IDB
SETPROC_FATAL=ida_idp.SETPROC_LOADER
INF_NAMELEN=INF_MAX_AUTONAME_LEN
REF_VHIGH=ida_nalt.V695_REF_VHIGH
REF_VLOW=ida_nalt.V695_REF_VLOW
def GetOpnd(ea, n): return print_operand(ea, n)
def patch_long(ea, value): return patch_dword(ea, value)

```

`README.md`:

```md
# usage

1. Please refer the https://github.com/Yunlongs/Genuis generate the dataset and preprocess it.
```
python Gemini_data_1.py
```

2. Modify the path in config.py and train the model:
```
python Gemini_train_2.py
```

3. Download the IDA Pro 7.7 from the Baidu.

Link：https://pan.baidu.com/s/19PfekgQ1AyElpH0EXZT_Xg?pwd=ex37 
pwd：ex37 

4. After installing the IDA Pro 7.7. Move the /IDA_appendix/idc_bc695.py to path/to/yourIDA/python/3.

5. Modify the PATH in batch_run.py and preprocessing_ida to generate the .cfg file.
```
python batch_run.py
```
6. Refer to APIs in  similarity_inference.py to infer the .acfg file 
(TRUST ME! VERY EASY TO READ AND USE)

Big Thanks to Yunlongs's Contribution!
```