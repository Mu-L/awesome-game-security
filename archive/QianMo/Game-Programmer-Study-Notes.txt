Project Path: arc_QianMo_Game-Programmer-Study-Notes_15lmjthd

Source Tree:

```txt
arc_QianMo_Game-Programmer-Study-Notes_15lmjthd
├── Content
│   ├── 《Effective C# 第二版》读书笔记
│   │   └── README.md
│   ├── 《GPU Gems 1》全书提炼总结
│   │   ├── README.md
│   │   └── media
│   │       ├── 000e7d0e677c5cc7aaa92cbfc28e7b44.jpg
│   │       ├── 01e8c07606f9017e75365b317f9f038b.jpg
│   │       ├── 04726bc725a4925858ee0ec280f7796f.jpg
│   │       ├── 047d2bbfa6ee469f8aeaf51e2fc8d8e7.jpg
│   │       ├── 0a937d9d89e4b5911b2e3217c2e81e1c.jpg
│   │       ├── 0b975daa48ea7ab00e8e82ac74275661.png
│   │       ├── 0c80fe2d09cc2ce0c5a0eb75ee0077e3.jpg
│   │       ├── 0e5096bbb70198af88449e17482a45d6.jpg
│   │       ├── 0eb0473ed541e8547426cf3a35610502.png
│   │       ├── 1870f6f26f6b03d7a51282c3397bc90e.png
│   │       ├── 187a016a73bc8bb10203d34505003b28.jpg
│   │       ├── 1a4894b4e922183b08800bf9c0bba975.jpg
│   │       ├── 1abca2e51d8271166f3dfb2d038028df.jpg
│   │       ├── 1bf6407eb4ca155cdf34acf9ae08fbcb.png
│   │       ├── 1c3686db3992f649486186984097ab07.jpg
│   │       ├── 1f4929be9428a7031b3cbb41fa74d4f5.png
│   │       ├── 2230e081af4283a98249ba60e39e3c12.png
│   │       ├── 287352aae26a0c79bec67e6929f2beeb.jpg
│   │       ├── 2b00f10637fef6861756d4a5669a8296.png
│   │       ├── 2d0acb97f656e9bdd3fdcdff97d4cc3e.jpg
│   │       ├── 2e621ba9c08c3c8d560175f594ab5cd8.jpg
│   │       ├── 345450849611257d2f711c7f1e4e398f.png
│   │       ├── 345e2eb8035e2fe059f78aa4a9301955.png
│   │       ├── 38440d033d85c19ef77ba96890ad4d43.png
│   │       ├── 3931c1f9af121e34b437f98117906fd6.png
│   │       ├── 39b069b84b7fe7a3ffd26d7b73a8be61.jpg
│   │       ├── 3d6cedd8ac77a3af1e3331ba8572e470.jpg
│   │       ├── 3f4d1c5e7cce0f92f219857129034a88.png
│   │       ├── 406e4997427e4959de16ad7676327ca1.png
│   │       ├── 40edd773a01ff958638b09b69399c75d.png
│   │       ├── 4c2fc0ba6e630f18004cebf547673c7a.png
│   │       ├── 4f66cfe65ba506676cdde671bf7da6da.png
│   │       ├── 51e18c386b312e7a349b5cab460a62b8.jpg
│   │       ├── 5561904e298f41f28747bd98b9e7688a.jpg
│   │       ├── 55b2c13bbaece3723db27b76cc5d793e.png
│   │       ├── 56c4ee03d16417d5078b278e89f7507c.png
│   │       ├── 5a62505ea6f9a07ed45da02a56293531.jpg
│   │       ├── 5b090360792e221b034be0c913e5520c.jpg
│   │       ├── 5b51a80706a5ef83e6cc4c200b021624.jpg
│   │       ├── 5c503c8789a7c83da26fcf30a9274004.jpg
│   │       ├── 5de7891126c535535204fa96b36916f3.png
│   │       ├── 5fba5d484376b24ae6010f48bc4239b4.jpg
│   │       ├── 5fd87dcf4ab8ad55149c9c96ef2187c4.png
│   │       ├── 5ff8e22e8afe125e1fd305bf9f6bb89e.jpg
│   │       ├── 60fc76a8681ddc527beb31e71b9f9f62.png
│   │       ├── 62306aa5c58927d62f1c41d7602dabe7.jpg
│   │       ├── 6618fd78de01c723ef6a3dab9608fe0f.jpg
│   │       ├── 66a9323f26da5e154bda269c6618326a.png
│   │       ├── 682310461e6d8b4e23a2984cb2ff34a8.png
│   │       ├── 69c6d71d2ea14454a83640d331bec7b5.png
│   │       ├── 74c6f428004569201c375c02f1713f69.png
│   │       ├── 75eb9a7c7b47bfd883f3d2c15f1b1166.png
│   │       ├── 76bbfaf81bb4cb06992cbcf3c6e9e8b8.png
│   │       ├── 781d1c41c19ffd1ba195f399877c3860.png
│   │       ├── 788fa8515f8f75e2e7ebc3895c6ef222.png
│   │       ├── 79cbf43848e0dd04f05144b858051dad.png
│   │       ├── 7ae7fa8a3f40c0cf23a707d15f8fe87f.jpg
│   │       ├── 7af5b16f7be7621ffc351e939c0146e8.jpg
│   │       ├── 7e696721f9df41a5fb22a9a3615ead03.png
│   │       ├── 80461ef7339665f0405a11e10ce98031.png
│   │       ├── 833078cc9e0f84f92200760ece973265.jpg
│   │       ├── 8574159fe5bab00260dffe12665d7503.png
│   │       ├── 8b704341952a0056d06fe24f02912bef.png
│   │       ├── 8bae93c4dd683d629fa8c1f9a2bb79e6.png
│   │       ├── 8e17437ac71fbaac295f9a4f604f1dec.jpg
│   │       ├── 8e182c0fd90d8b0be6d988bc0b7eea25.png
│   │       ├── 8edddd3f5776ead7d573cdb8bc2eb4ad.png
│   │       ├── 90fc18ee992be370b2d6597d2f70c5b4.jpg
│   │       ├── 9806d02f14c9b03d2f8ddc68859d4b3a.png
│   │       ├── 993d2fe5db403d1fda14bc6b34de7707.png
│   │       ├── 99b219a60f13be87fb1d5c3a5f5c2640.jpg
│   │       ├── 9b0e20d976d449e59dfb54e6a06fada4.png
│   │       ├── 9cf67c7c7f52f853a6cc8bd2dd1485f3.jpg
│   │       ├── 9de8a7fd4e07a2a88ca819c03259db5d.jpg
│   │       ├── a0aabb93a265e9d258848657aefa8228.png
│   │       ├── a2d2867bc9c4d8ef88ab6fa4d2b8edec.jpg
│   │       ├── a68b6c7763c9a93192b5965e8f6de547.png
│   │       ├── a6c9d7add4706057988add72188400ab.jpg
│   │       ├── a78bfaa0fe79b7be546cebed07799194.png
│   │       ├── aab296674959b3b442794016332e3e4a.png
│   │       ├── b261554c6c79c1f2e1675e709d1d16e4.png
│   │       ├── b27d6c11d5181e315ff6570f322709d1.jpg
│   │       ├── b2d6a1dbc10f3a3f6b0b8a24a97df7f2.png
│   │       ├── b4bd512d5067f2981cdff2f780efd503.jpg
│   │       ├── b95941c57ca75f5ad2a48ff7a453376b.png
│   │       ├── ba6a16c60a898c10e8032c9b254e35df.jpg
│   │       ├── be47b90b234000f802e16fa2ee4e509d.jpg
│   │       ├── c19f69f6f4616a11cea94162b17b6428.png
│   │       ├── c4a6025c3644aae9a210213a61285a46.jpg
│   │       ├── cafa26f19c54ca597045c5a047c3bb38.jpg
│   │       ├── ce58e6d0901706ca3cf7f3a49bf0e354.png
│   │       ├── cf872a841af5cb1643e04ed813be7ca3.png
│   │       ├── d01cd3f0054bd4178d7561b61e7c5f01.png
│   │       ├── d3fa2f5dbd2291d8094d263c446db246.png
│   │       ├── d55a3dfa3021ee2bd2b55226425336d8.jpg
│   │       ├── d80656c686f1468e8f8c756d739eaada.jpg
│   │       ├── d96533905192091206ac5345ebee2fda.png
│   │       ├── dbf31636dde49cc423a1b39afd64b7fc.jpg
│   │       ├── dd6d75501f39f36c2eb8c93780683e6f.png
│   │       ├── ddbfa1d5053cb96aa32fa2dbd78fbc4f.jpg
│   │       ├── e044961968eafb19ba340601fb2d3517.png
│   │       ├── ebca3845e4f33120b90c54c7f78f9b32.png
│   │       ├── efab0e56de0f5ff7bec800a5c0517d9b.png
│   │       ├── f37e1d72ea9f280da1e41a0550ab047f.png
│   │       ├── f5774585ef3f0c0e08a869f222368a9f.jpg
│   │       ├── f5f190f91977b41c60c2f5f301e05b25.jpg
│   │       ├── f74d7a2718b91518d938208f750b8b74.png
│   │       ├── fae010bffc77e62249f659f81ee37f09.png
│   │       ├── fb643b85c492b73c4ee4b7994a77ae9e.jpg
│   │       ├── fc07f17a1dc048be84b9d3af4da015c9.jpg
│   │       ├── fc2c00c1db06777ab92c1c859f037e96.jpg
│   │       └── title.jpg
│   ├── 《GPU Gems 2》全书提炼总结
│   │   ├── Part1
│   │   │   ├── README.md
│   │   │   └── media
│   │   │       ├── 04e8e2bee126a22e4ae4fa30fe71a1bf.jpg
│   │   │       ├── 0c3a47c39852e77246b1f98c9fa341d7.jpg
│   │   │       ├── 0c41e91f86197929ea2bfd451333fc88.jpg
│   │   │       ├── 0e6062dc305d7dad328235445e987e3d.jpg
│   │   │       ├── 107f5ac68224623ee428576c95850ca3.jpg
│   │   │       ├── 1322748b3b1719a88e7b97739a688cda.jpg
│   │   │       ├── 1b35dc4e59118fbd172135badb4dfd4e.jpg
│   │   │       ├── 1b92464b7a254a80459eac04f750e68b.png
│   │   │       ├── 1bc80b240f19e0200e0fa47401f7fbb5.png
│   │   │       ├── 2022d4e2e744e14b4b69fed706034cf2.jpg
│   │   │       ├── 32a152dc4d4886903745739c829e4af3.png
│   │   │       ├── 3307436d578e783e77f6935a765fc83b.jpg
│   │   │       ├── 34baace7f0a13911171a220a8609ce34.png
│   │   │       ├── 37fd3656cee608dcb54d05ba2e9879c2.jpg
│   │   │       ├── 3dd03483e84361d405a7570f2df8c088.png
│   │   │       ├── 40f3733de4873b15f5d733bc3445c90f.jpg
│   │   │       ├── 4333a11bdd0cd59f176689ac47e84716.jpg
│   │   │       ├── 49090fe6638902bc41a55a8275982a42.jpg
│   │   │       ├── 4cb9e4f55f54345baf193a7d27e9efff.jpg
│   │   │       ├── 4e41bccf539ae7775743a71915dd858b.png
│   │   │       ├── 502134e527b1074380adb80327e5fe17.jpg
│   │   │       ├── 568e67e4033f0a64316448f2fe5b2714.png
│   │   │       ├── 63f1635a48edb1b4bb6ca456d2d27531.png
│   │   │       ├── 66a82c37040045d0c1c31ae82683e73a.jpg
│   │   │       ├── 76289e9886574d37ab1c686fec6a6e2f.jpg
│   │   │       ├── 793e100cfc7a336d5c367063417968c5.jpg
│   │   │       ├── 797d666a9b58c2d3d47893880e8eca5d.jpg
│   │   │       ├── 82bda2bfc3ebdd3fc3dd1031c69f7f99.jpg
│   │   │       ├── 841bf927d977d170d5f0d84cbc5a8ab3.png
│   │   │       ├── 8544048f8a6586cfbb57ce993dc8df9c.jpg
│   │   │       ├── 884517e8ec7d2aef0b5ad1bd7c8e8503.jpg
│   │   │       ├── 89f9a2729e96f54f189fb6f00ff98822.png
│   │   │       ├── 8cdea6b4c4d2dc48fea0d9326739933d.jpg
│   │   │       ├── 8da1e9a983bce8f97f98d62fd48e4188.png
│   │   │       ├── 8f2f9167f2775cfd70f2c978ce49ad6f.jpg
│   │   │       ├── 93ca6ad54cad71c2042c8bf40669aceb.jpg
│   │   │       ├── 996601e8702197b5eb9a68526eeb1c73.png
│   │   │       ├── 9f4b87b3064801c621bcb3ce2dfe9e76.jpg
│   │   │       ├── a258ae10f30d67c444b8aaad95766e58.jpg
│   │   │       ├── a41e3afc06a8bc473d899e62d9257bbf.jpg
│   │   │       ├── af224ad22b30dbaa0fa4914937ebfb05.png
│   │   │       ├── b2c19e6b54faf091f56980ed4c1091fe.jpg
│   │   │       ├── b673605c54a03f918c8e0d7372587bd3.jpg
│   │   │       ├── b80e73a6bad6f9b460d91e3ef121e6a3.png
│   │   │       ├── b952ace0a5917201fb0c6d551ba468ab.png
│   │   │       ├── c135b4f7854a5a36cc313ca4fbcf8014.jpg
│   │   │       ├── cbacda9eeb278f040ab2984959338d27.jpg
│   │   │       ├── ceb6e7e3a1c2db8d78220b20433a26d5.jpg
│   │   │       ├── cf81c02e293590e733309bcc776c7019.jpg
│   │   │       ├── d3174c6eaeccd2c211a0fb6f18d1af1c.jpg
│   │   │       ├── d398916378dc464ce8113f698a8f9f66.jpg
│   │   │       ├── d6f5fcf758bd46d7c1072ed88c86033e.jpg
│   │   │       ├── d85c811d58e5187cf445614dc8d69988.png
│   │   │       ├── e66658a5ca10fc9b5728471d4ffd6fd5.jpg
│   │   │       ├── e6d39172c6c96651c542230f730d3ddf.jpg
│   │   │       ├── eb9fcfe97c4cba0c610e4d4ea21a3140.png
│   │   │       ├── ed41e45d2906640097c5db3421fe53aa.jpg
│   │   │       ├── efe24840ae08c3808d1f8340319dc0b6.jpg
│   │   │       ├── f41c53f4d8672af808057f9b2d0fe4e6.jpg
│   │   │       └── title.jpg
│   │   └── Part2
│   │       ├── README.md
│   │       └── media
│   │           ├── 00de2d88f9609d8a39ecd22b3a01045d.jpg
│   │           ├── 081c4e549906e1c0393e4e5d9a42618a.jpg
│   │           ├── 08c50752a601cae32563f8bb6237f79a.png
│   │           ├── 0c2737c4173d96953f6157eb2a71682b.jpg
│   │           ├── 1.gif
│   │           ├── 19223f5755726a012c35b8ce340cda7c.jpg
│   │           ├── 262b03440b559661adf9d1be8ebd5ad4.jpg
│   │           ├── 2ad3c092f8e9bc9267235319bf6a33c4.jpg
│   │           ├── 2bdf5cfa1dd9128a7f4b33ffffa23223.jpg
│   │           ├── 30b0ec752eee991f30ffb2b4b69e8cf5.jpg
│   │           ├── 345ebd12e79d64c1f48d9fd75ef2e416.jpg
│   │           ├── 39cbe619e0bfd05f32d10f483957fc3d.jpg
│   │           ├── 3b7bff29e36a872ca8f11291bbe1f482.jpg
│   │           ├── 3d4800850db5960c938aceb3093539a2.png
│   │           ├── 4052d83ee541057dab03a4349d313831.jpg
│   │           ├── 47c6125108e26fc58592a933071a938a.jpg
│   │           ├── 4ca98d3d9a52795483a997a9304b8779.jpg
│   │           ├── 5504321a0537a5f5a44a95fe6bca913b.png
│   │           ├── 5f5aed8ad253dba4f7ba1d492679d53e.jpg
│   │           ├── 6beae192bc08bce1bf49f58be8c35964.jpg
│   │           ├── 6f1792a2a9f48434d51a2363d52f50d8.jpg
│   │           ├── 88624af868602cf53093cf48179b8f9a.jpg
│   │           ├── 8a3ea2ee7d535d5fd67543cb96e0f739.jpg
│   │           ├── b40c8f8fbeabe9381a3165a50001a96d.jpg
│   │           ├── bc62ed5fc450feac5ad3ccff76d70785.jpg
│   │           ├── db0c7e0c76d0663c0b9971c6f934841a.png
│   │           ├── eff130f1711a206311827e1d0d5cb51c.jpg
│   │           ├── f4fb6c813e50c5f92402a06ac3577c08.jpg
│   │           └── title.jpg
│   ├── 《GPU Gems 3》全书提炼总结
│   │   ├── Part1
│   │   │   ├── README.md
│   │   │   └── media
│   │   │       ├── 000.jpg
│   │   │       ├── 006cd6fb948aeb4ea8e8f58d58d95194.jpg
│   │   │       ├── 014dda21a69692b8332f388f9a7421a5.png
│   │   │       ├── 016bf9ddb7c7e6d3e8ef980a6410f3f1.png
│   │   │       ├── 0301cbb05fa6e03642733b201fc38636.jpg
│   │   │       ├── 092aba5726f59db4e9bff787c0be6e50.jpg
│   │   │       ├── 0dd0e3a64d10bda3cef3869eea01f4c7.png
│   │   │       ├── 0e766ab875fc85648f0e14fc0810626c.png
│   │   │       ├── 1241647f87d40cce0da976277b744e25.jpg
│   │   │       ├── 145ff7c80a4788d64cb5f1ac1b144bb7.png
│   │   │       ├── 1673b1f4425e8cbfe07ad773ba25ad98.jpg
│   │   │       ├── 16ca4672e73c981be74b70a14ef467b8.png
│   │   │       ├── 19dcd9f74e4594c0b7245f6195649da3.jpg
│   │   │       ├── 1cfe24ec51b878c93d86b064f44f3869.png
│   │   │       ├── 2496bb4c44c558c2649f55cd0d076ff4.jpg
│   │   │       ├── 288d1679760d30e047aed0aa7b2ff7d6.png
│   │   │       ├── 32ce1d4a8b8fcf5fde31989af3fa2917.jpg
│   │   │       ├── 396bd53b2a4a46632c0db005d326edf9.png
│   │   │       ├── 3d97cf598c2bb107120a97b90fd1f13e.png
│   │   │       ├── 48bce39efd52d7076fe1b7a9cc848fd0.png
│   │   │       ├── 55fb73ab3b61edfda6d489b8ee2592f9.png
│   │   │       ├── 58f644a4a1ad284b5325057592d6480d.png
│   │   │       ├── 601b52ae28bd227b7e3b187cee254caa.png
│   │   │       ├── 6231331540b5c16c85a54606609f6c76.png
│   │   │       ├── 63fbc374696ae300b599bc496eae5d45.png
│   │   │       ├── 68f871f2407cfec9318e6c899c0420e2.jpg
│   │   │       ├── 6911bc9b9d4847b630ff5f049af3e2fb.png
│   │   │       ├── 6beb84faac02d2ffbf68157283b7f480.jpg
│   │   │       ├── 72cc6208b2c5f2355729884ceae5063c.jpg
│   │   │       ├── 753b53763f2b19f6d47ff070a7109bc9.png
│   │   │       ├── 7550d414d75dc36df51d21b1ed51230a.jpg
│   │   │       ├── 764dfcfe79601a3ed3aba86358b9d8d1.png
│   │   │       ├── 7a1aaa9899bce6ff554f8e9a3a902e19.jpg
│   │   │       ├── 7b19dd7a757540e9d538606fe1ab536d.png
│   │   │       ├── 8166f95f4f2af14afacb6fd46bac0117.jpg
│   │   │       ├── 85e555415c5953d9c62f6337802051f8.png
│   │   │       ├── 8b07c0956730dca3dd0c86367cd3446c.png
│   │   │       ├── 92bda77a36da86fa0e619316485bce5a.jpg
│   │   │       ├── 9b1fa8324958687faabd8c33f0ecd3e9.png
│   │   │       ├── 9c31af134fe2e8b31d3170f8a2a53de2.png
│   │   │       ├── 9d44620ec5f7565c1f79fe8dca9461f7.png
│   │   │       ├── 9dd9a42115859b6c7572166f2ea79cd3.jpg
│   │   │       ├── a600e1812796efc81862604328f8a860.jpg
│   │   │       ├── afb687befe1164d6701fd7ee7d91db7c.png
│   │   │       ├── b3c38707fe520888a1908bc11a643b8b.jpg
│   │   │       ├── b5efe2be3abae935b19ae55e56774353.png
│   │   │       ├── b8b926a3f9769073334404ed21726063.png
│   │   │       ├── bf25c2a200a061a9c55615fb958b721c.png
│   │   │       ├── c17c86d58c9e825a7aefe356c32676ab.jpg
│   │   │       ├── d18cbe00b07bf2bff4402d9e5e5ce5ca.jpg
│   │   │       ├── d642a791d8174fa098666f55bdac2c61.jpg
│   │   │       ├── d6fc84df40f2a005b8f83c4e7f3bf367.jpg
│   │   │       ├── dfa95a086579f0f2a9b0c7b84f13e430.jpg
│   │   │       ├── e73677ea1b404446fa842e938109c611.jpg
│   │   │       ├── ec6e9c9cbe1dc4efd19989a69b8cf4d2.png
│   │   │       ├── ee465182af6946df9bd2c7108c0794d2.png
│   │   │       ├── eea37284d9dbeb17b8b487203978b332.png
│   │   │       ├── fae2fad57ffef872a0645e080d5a30db.jpg
│   │   │       ├── title.jpg
│   │   │       └── video
│   │   │           └── Far_Cry_5_-_Character_Vignette__Mary_clip(1)(1).mp4
│   │   └── Part2
│   │       ├── README.md
│   │       └── media
│   │           ├── 03be2d49ee425613b792d00ea12b09af.jpg
│   │           ├── 094eb5c6b39b861d8b395e0a875a6584.jpg
│   │           ├── 0a754fdc0b823495b997af96ab509c53.jpg
│   │           ├── 0b5dae2a69aadbd7bb45c28993d1cca0.jpg
│   │           ├── 0c59fca2969cd395b282c51d43a4b557.jpg
│   │           ├── 0e4354357e59376128172ca07ef1682b.jpg
│   │           ├── 0f3c5e9abd04e726fabdfb47f5c818b0.jpg
│   │           ├── 0f94e5c6635c7cfe2ffb9a9d328bf365.jpg
│   │           ├── 174e23868c1f8f37d73e05979fa15f9b.jpg
│   │           ├── 190c857d39792ff9ab4c3a3e2c439d74.jpg
│   │           ├── 195e0fefa9631a3a0a368dd3e78c48c3.jpg
│   │           ├── 19dcd9f74e4594c0b7245f6195649da3.jpg
│   │           ├── 1a3babb601de0a5191b2c6fd31067c5a.jpg
│   │           ├── 2147135beacf619394059f486b27302f.jpg
│   │           ├── 2457d3852593da2ab9a4974b494a49c2.jpg
│   │           ├── 2c82f47e3a48ad616d658a3963669831.jpg
│   │           ├── 2e65a0aba6dee153fc7a109705b80562.jpg
│   │           ├── 2ed083531c323762c004ac1b8aa26a2a.jpg
│   │           ├── 30590425ddd695dbd196eb584bdf233b.jpg
│   │           ├── 33b8ebd4e3c5a23065c1332bcf896443.jpg
│   │           ├── 35c4b292fc27f3ee2999403d299c2ba1.jpg
│   │           ├── 3904ae8e5f3d943417d7063287764df8.jpg
│   │           ├── 3995354e628efa57d645e3a252bc18f8.jpg
│   │           ├── 3e31023af5f26b3367453961604fec93.jpg
│   │           ├── 3e490b660bdd5988fea97956aadef8ae.jpg
│   │           ├── 423f8ea0cfc58187894b7c7e05319a54.jpg
│   │           ├── 42c203482568ecb633e60fd33b0da2cd.jpg
│   │           ├── 46b6e4c05331af9fe85cd6274d039663.jpg
│   │           ├── 47706ccfd7776590467469733224e666.jpg
│   │           ├── 4c0f97a550e41a889c4bf88089e8f664.jpg
│   │           ├── 507c29ff175a0bf087aa2b6c5760adf1.jpg
│   │           ├── 50c75e857633753d88619a35ff5db407.jpg
│   │           ├── 52718e1e086b3e4211d2c16c092d77ae.jpg
│   │           ├── 53db87caf0f3a5d9b698b1c9fc1ad2f1.jpg
│   │           ├── 58cf1d37a902c881c0f5971aa71acb75.jpg
│   │           ├── 5a6050624c51597793f49889fa1a81ba.png
│   │           ├── 638a91dafc048694023c2d3faa2583f3.jpg
│   │           ├── 642a112d64ade89260eb0c6681f202d4.jpg
│   │           ├── 68a4cb059d731f61f985682bea1e6e39.jpg
│   │           ├── 6d91b46de19d9e16d359ac793f5a22ed.jpg
│   │           ├── 6e9f45b421c32f8a7ab37b317c7895ed.jpg
│   │           ├── 70bfeadf5613b41733fcc2d7c79671fe.gif
│   │           ├── 749a9e34be8332329d81d439f65fee99.jpg
│   │           ├── 7a26d2087a6b13dda162db52b573fc74.jpg
│   │           ├── 7a95ab43db084101df8f23a223def6d3.jpg
│   │           ├── 7dadeebc3a7f17d4ce2a89a9d246fc69.jpg
│   │           ├── 823c6c824b0968fb51379630e44a3893.jpg
│   │           ├── 85de07e552e5d714836605510fb19e52.jpg
│   │           ├── 8cbf4b109edd5f65f473955c03cc4438.jpg
│   │           ├── 8ebd1db2b475b8959e50e093dba13229.jpg
│   │           ├── 8fc8f1bd77cb2d3a04e60d8b5b814e9f.jpg
│   │           ├── 90f2aa48340bc6738eceb2dee50ac68f.jpg
│   │           ├── 9171641e4bd2084409ce728401e93437.jpg
│   │           ├── 91bab10a8173cf05eb174fefeeb093f5.jpg
│   │           ├── 952ea9ad7488e4e0777b4b6230740f54.jpg
│   │           ├── 9755ef5fca5d3326f99b2ceab69de195.jpg
│   │           ├── 975eed2faba219d50391c7f4e516c8ad.jpg
│   │           ├── 9e46973e32bb29a49414fe1f9775f569.jpg
│   │           ├── a13a3b8fa9cfc84d4c1084f044e67240.jpg
│   │           ├── a42c764024d783ef2c7980a86a47d28f.jpg
│   │           ├── a4cde33622cc2ed0f6f5c04688ea3c54.jpg
│   │           ├── ad342e76ca4a97a4a6ea2107e097e3a7.jpg
│   │           ├── b211c883c2fa966569fe46bc42c0c05e.jpg
│   │           ├── b26f5c3cf86c0b775d7052c84035b1ef.jpg
│   │           ├── b52b81a8e3bdfa7a9377e916297cf2a7.jpg
│   │           ├── b65a446e2f584b24dbd2288fa7275c1b.jpg
│   │           ├── b82e124e533cdaaad40f56525a1ea69d.jpg
│   │           ├── b9193c25c7f03efd528d38e0017255bd.jpg
│   │           ├── baebeba920da674057d6d15de53738ae.jpg
│   │           ├── bded4c0dac35b5bce59c4d5af71644e3.jpg
│   │           ├── bf10ba9ed5ec521376afcfa2a72bfd2a.jpg
│   │           ├── bfae6bef8d157f6c8006b210c8846875.jpg
│   │           ├── c1999f7b212b1c30538d244a5879eeac.jpg
│   │           ├── c25fc13e5eb1353538bb1d3ce71f3f0f.jpg
│   │           ├── c58040a2e1ba5707bbecb700d64f1049.jpg
│   │           ├── c6f92f8e2f4219476756a27c680f05f9.jpg
│   │           ├── d51868713d19a9460a1f8171d3fa929f.jpg
│   │           ├── d5d465fa63ee264b8fd9c38097046b77.jpg
│   │           ├── db976cba1f4940d42b73e64a9254fba5.jpg
│   │           ├── dec217d782fce2558879e89c123d47bf.jpg
│   │           ├── e21dd2a0abbb592d418025fc870da011.jpg
│   │           ├── e4e177c4bce95819ed6ea5a09f5042ea.jpg
│   │           ├── e72a0763e0fe712f08b0954aebaea7ab.jpg
│   │           ├── e7bd600ccfd7f938aed80310518d1d0c.png
│   │           ├── ecf4789edef406289e235d5b56244611.jpg
│   │           ├── ee7bfc97c1429c7a0c2f40b16e3c91f4.jpg
│   │           ├── f34011ce1defe75aa4392ddf5b8d938e.jpg
│   │           ├── f4e51841acd31a96df940bf4ffdc8eb2.jpg
│   │           ├── f7e02cc22c01b161f31df3a19e3741ac.jpg
│   │           ├── fc4ee42cabc30ea1a779581f66748ad4.jpg
│   │           ├── fcb126633f6feb29bea24bbef0495303.jpg
│   │           ├── fdc4c89efa2af38eaef589eb11564d83.jpg
│   │           ├── ff0fabd6160adbe2889004b1386a8099.jpg
│   │           ├── struct.png
│   │           ├── title.jpg
│   │           └── video
│   │               ├── GDC_2017_Flash_Forward__'Ghost_Recon_Wildlands'__Terrain_Tools_and_Technology.mp4
│   │               └── Horizon_Zero_Dawn_-_GPU_based_Procedural_Placement_in_Decima_Engine.mp4
│   ├── 《GPU Pro 1》全书提炼总结
│   │   ├── README.md
│   │   └── media
│   │       ├── 007e69cbd0da96706c4a163a201f3c44.png
│   │       ├── 045f3d4f1d5db9bc2d624b24cd5dbf78.png
│   │       ├── 089fbc7afe80d3d50f9be009e77f1912.png
│   │       ├── 0b0a367098df217262a28c29e9502e28.png
│   │       ├── 0e0a560374de76f36e936236ba36e879.jpg
│   │       ├── 11c915b42785aed12338cf882463210f.jpg
│   │       ├── 12558f640a9de6746b368b644c93093b.jpg
│   │       ├── 1418d17ef805f2f67c126551e1fba78f.png
│   │       ├── 1a7051ace54640bd566a5d8f23a49358.jpg
│   │       ├── 262723e5a61ca21ab839fbdf6534329d.jpg
│   │       ├── 2a4baca9e5522da6a9d761020fb81283.png
│   │       ├── 2c9b16a1c95fb8284a498967e6e5e19b.png
│   │       ├── 30099c1363ddb9474a7d78f54bd25ac3.png
│   │       ├── 356f60e324fa8b54011adf4a3065348e.png
│   │       ├── 35cfe05da7330c1802b4cf2bdfb1935e.jpg
│   │       ├── 35e8f5273e7fd46cb0231a8a238a73f6.jpg
│   │       ├── 379bd1804f56e7f478afd38f52fe2652.png
│   │       ├── 38e267d74e73bc8bc3639a7b9fe48458.jpg
│   │       ├── 3a9aa2f3ef677c1efe33fe4ca8307e33.jpg
│   │       ├── 47c584f6c0b089d7c64be5ce26f2fa93.jpg
│   │       ├── 49cf56255f1f35c49c3bb4e0b719b8fa.jpg
│   │       ├── 4cd49abf4519cebc88ce3c40e7aa1b40.jpg
│   │       ├── 51d1539e3fb64bd68b146b421142f974.png
│   │       ├── 550c7bbdfa3b0092d0d739aa418c6392.jpg
│   │       ├── 5805c19c529c4437067ceeb9420b79ee.jpg
│   │       ├── 5b62cbc4a5323e108f039da9e93b7071.png
│   │       ├── 5b80d8287950dd63abd4d51c0e28b170.jpg
│   │       ├── 5dbe0eb8c0cb6c2f658f874a56f05889.jpg
│   │       ├── 6065d242b5fb94811659827213e1d145.jpg
│   │       ├── 620848421a07229f820409740714677c.jpg
│   │       ├── 64b005316a6260bb9fa241d2072b75a1.jpg
│   │       ├── 6bb9df54b962f3cd39d0672319db0ffc.jpg
│   │       ├── 728c736d64bbd6d8d1a5b4245ada9324.jpg
│   │       ├── 7b87efd297e401d47bf14224f0fa0227.png
│   │       ├── 7de17304312d5c3977eaeb3bc01054de.png
│   │       ├── 81d4b415ed7177c48d10b7516144d870.png
│   │       ├── 8b3a9dd264b68e76d4d9421a8b83a214.png
│   │       ├── 8c1f5c8e294d71153c1d505cc6e3e4c6.jpg
│   │       ├── 8c4e3cc814ab179df6bb1f64d47b8838.jpg
│   │       ├── 9197db42270ce9c5c4a422252d4a129d.jpg
│   │       ├── 92e02f49298b69da103f846bc388116f.jpg
│   │       ├── 9961590888343ce5f500bc4dbcf7b442.png
│   │       ├── 9c2b071b069eda2e4df844b060909a87.png
│   │       ├── 9f705cf6b5a91b5fae1b81c1c61603bd.png
│   │       ├── b28e980933f49e44b1d66882beea987f.jpg
│   │       ├── b3fed4591cc69b98184b1b5f8b0a4104.jpg
│   │       ├── b9a8f6f5dec7856785493ee8b0db28a2.jpg
│   │       ├── bb6c02aaed96d06830e23ab69e47f9e9.jpg
│   │       ├── bdb0097479d27279d7402dade7dfe206.jpg
│   │       ├── beba6a37fa84e7ce99d9a614c3c67483.jpg
│   │       ├── c266aa1040c5202e07fe01e096ed5554.png
│   │       ├── c32e665b609fc1b1ceb2b413aac865e4.png
│   │       ├── c4768e8edcdf14450dab6a5ae65e4af7.jpg
│   │       ├── c8625692aaef6f4020e93d430f6e2c1b.jpg
│   │       ├── cb588c524267abdeafc0de518613af95.png
│   │       ├── cf2ff293b62b459a26b503c79036a663.png
│   │       ├── d334dde4b4259dddeb29cad0a92eb953.png
│   │       ├── dd3cc4def672a0a802fd71a30a451544.jpg
│   │       ├── e3b9349a1ba9e4b4bf7abfcbc9df0e60.png
│   │       ├── e60c1736e7712e99c5bc75c52c3f2848.jpg
│   │       ├── e62828ddc53abaa4b53577695ee5b483.jpg
│   │       ├── ec5d226c6e9667bd12bdf5b84ba06230.jpg
│   │       ├── f1c42e08dc4acce2e2229d5f5fae40e8.jpg
│   │       ├── fa42018d66709fbd9879f1ca334d987c.jpg
│   │       ├── fba981a4c3dcfa4ef47d8b70838ed4a6.png
│   │       ├── fccbcccfbcbc250aa592f1fe9a61c395.png
│   │       ├── fe557549ec3c7e0251042e8c6de65d56.jpg
│   │       └── image25.jpg
│   ├── 《GPU 编程与CG 语言之阳春白雪下里巴人》读书笔记
│   │   ├── 01-第一章-绪论
│   │   │   ├── README.md
│   │   │   └── media
│   │   │       └── 3318ab8b7b2ace6b50a7e925bd9816cc.png
│   │   └── README.md
│   ├── 《Real-Time Rendering 3rd》知识网络图谱
│   │   ├── README.md
│   │   └── Real-Time-Rendering-3rd-Knowledge-Diagram.jpg
│   ├── 《Real-Time Rendering 3rd》读书笔记
│   │   ├── Content
│   │   │   ├── BlogPost01
│   │   │   │   ├── README.md
│   │   │   │   └── media
│   │   │   │       ├── 1.jpg
│   │   │   │       ├── 2.png
│   │   │   │       ├── 3.png
│   │   │   │       └── title.jpg
│   │   │   ├── BlogPost02
│   │   │   │   ├── README.md
│   │   │   │   └── media
│   │   │   │       ├── 0.png
│   │   │   │       ├── 1.png
│   │   │   │       ├── 10.png
│   │   │   │       ├── 2.png
│   │   │   │       ├── 2016011945957943.jpg
│   │   │   │       ├── 3.png
│   │   │   │       ├── 4.png
│   │   │   │       ├── 5.png
│   │   │   │       ├── 6.png
│   │   │   │       ├── 7.png
│   │   │   │       ├── 8.png
│   │   │   │       ├── 9.png
│   │   │   │       └── title.jpg
│   │   │   ├── BlogPost03
│   │   │   │   ├── README.md
│   │   │   │   └── media
│   │   │   │       ├── 1.jpg
│   │   │   │       ├── 10x.jpg
│   │   │   │       ├── 11.jpg
│   │   │   │       ├── 2.jpg
│   │   │   │       ├── 3.jpg
│   │   │   │       ├── 4.jpg
│   │   │   │       ├── 5.jpg
│   │   │   │       ├── 6.jpg
│   │   │   │       ├── 6x.jpg
│   │   │   │       ├── 7.jpg
│   │   │   │       ├── 8.jpg
│   │   │   │       ├── 9.jpg
│   │   │   │       └── title.jpg
│   │   │   ├── BlogPost04
│   │   │   │   ├── README.md
│   │   │   │   └── media
│   │   │   │       ├── 051d469c265a92e7a10e704460e4cdf2.jpg
│   │   │   │       ├── 0892632f5ffd5ce75399048b18c515d6.jpg
│   │   │   │       ├── 2c7ffb0dbc09aa290878053e34761d8e.jpg
│   │   │   │       ├── 2da45212f77010f377ca75ae3be80b42.jpg
│   │   │   │       ├── 37b890a30181aa7b3e2d8104bc8ec318.jpg
│   │   │   │       ├── 619a22065d249ffa8747cc7ee56b1941.jpg
│   │   │   │       ├── 8a57b9d65342ddd0e42e615336da597e.jpg
│   │   │   │       ├── 8ba4610d9d3437bf3d6208080a8c1fe7.jpg
│   │   │   │       ├── a540e701e2468109bce90b48d859749a.jpg
│   │   │   │       ├── abbddc86c79d6a7bda9064359f945a64.jpg
│   │   │   │       └── da177d97f6e96b285ab35937a917807b.jpg
│   │   │   ├── BlogPost05
│   │   │   │   ├── README.md
│   │   │   │   └── media
│   │   │   │       ├── 0901f5e80743db1f3726721b18d35f8e.jpg
│   │   │   │       ├── 16216434a77f1675b2787df5a34e65a3.jpg
│   │   │   │       ├── 223f78ee8ab2ecc968be64fbcdd53987.jpg
│   │   │   │       ├── 22da2f6ff8dcb49f33d3d6fc0d79af95.jpg
│   │   │   │       ├── 23e1576a967760aee8def15c7752b4c2.jpg
│   │   │   │       ├── 3a780cc3cfb40bc8d695dec7304b549a.jpg
│   │   │   │       ├── 3f496d9129c865d4aa9242c7b61f75dd.jpg
│   │   │   │       ├── 5328d31a4a96c7dbbb6404e63edd8c60.jpg
│   │   │   │       ├── 56cfe82825fcd9e0a4ae51b55fe2c685.jpg
│   │   │   │       ├── 5db77f3bbf99ddb84653ee9f8a5f050f.jpg
│   │   │   │       ├── 79a41fe0cc8285c3dbc8f131478cec3c.jpg
│   │   │   │       ├── 8c4927fb74b7eefefffaf694165e897f.jpg
│   │   │   │       ├── 91c18142dd3b12f74945cf191ea0ae07.jpg
│   │   │   │       ├── a2212a157a050314a80c12be9d5676a8.jpg
│   │   │   │       ├── acbeebac577de01563a57be7e2c45ed8.jpg
│   │   │   │       ├── b80392a4d895922f5830146cff602441.jpg
│   │   │   │       ├── b963123671d07272fffb9dfccd73a957.jpg
│   │   │   │       ├── be5694fdb910baaee86443c367637baa.jpg
│   │   │   │       ├── ca5b5b1aba93a4396c6c3b733a455bc0.jpg
│   │   │   │       ├── f57596a5bb2148f8507fadf29895771a.jpg
│   │   │   │       └── title.jpg
│   │   │   ├── BlogPost06
│   │   │   │   ├── README.md
│   │   │   │   └── media
│   │   │   │       ├── 10ab01213dba8ed11f44985e84f2683e.jpg
│   │   │   │       ├── 11.jpg
│   │   │   │       ├── 12.jpg
│   │   │   │       ├── 12db40a81c96bfa9d3e553dfba7682a5.jpg
│   │   │   │       ├── 13.jpg
│   │   │   │       ├── 14.jpg
│   │   │   │       ├── 15.jpg
│   │   │   │       ├── 17.jpg
│   │   │   │       ├── 18.jpg
│   │   │   │       ├── 19.1.gif
│   │   │   │       ├── 1cdecce356f6f3f5f39169ea569cad48.jpg
│   │   │   │       ├── 1fb4e0458939444804da12336e640802.jpg
│   │   │   │       ├── 20.jpg
│   │   │   │       ├── 21.jpg
│   │   │   │       ├── 22.1.png
│   │   │   │       ├── 2e4a602140263296a55d7632b69fb4ae.jpg
│   │   │   │       ├── 32.jpg
│   │   │   │       ├── 34.jpg
│   │   │   │       ├── 35.jpg
│   │   │   │       ├── 398183f217f8be62b6cd386243c485ce.jpg
│   │   │   │       ├── 4f72f91f846b5a51b5daf31155dc96be.jpg
│   │   │   │       ├── 5.jpg
│   │   │   │       ├── 51b29f898497fa2e2a7d70bd6545e8b8.jpg
│   │   │   │       ├── 5ff50dbf74077e2f704a812d67473940.jpg
│   │   │   │       ├── 6.jpg
│   │   │   │       ├── 6280ca245be9ddec829da28a51589276.jpg
│   │   │   │       ├── 66e11d2f41165001d2bbb09ae9d4ca15.jpg
│   │   │   │       ├── 7.jpg
│   │   │   │       ├── 8.jpg
│   │   │   │       ├── 86a26c1f917c5730b32f223fa7bf33b9.jpg
│   │   │   │       ├── 897dc5430a09096c357353c16f6672e5.jpg
│   │   │   │       ├── b10e282149a8d128616c43622d591511.jpg
│   │   │   │       ├── bca8b01eb43dacb1beddeeb548b910bb.jpg
│   │   │   │       ├── c1ee1c4ea5e293d9d0ec43ffe6c55c57.jpg
│   │   │   │       ├── c83ab9adf0f18f082e0060fb6ac16afd.jpg
│   │   │   │       ├── d084fcee93a2803cf9565f8519099598.jpg
│   │   │   │       ├── f39d56cb64eab66f423c5098b2509a1d.jpg
│   │   │   │       ├── fae6d41ba5ea0051c455432f2bc05627.jpg
│   │   │   │       └── title.jpg
│   │   │   ├── BlogPost07
│   │   │   │   ├── README.md
│   │   │   │   └── media
│   │   │   │       ├── 0a670145a0202467e3c8ac8bdb945a19.jpg
│   │   │   │       ├── 15ca75231160440b75f7ad60350927e5.jpg
│   │   │   │       ├── 1c1e893c0173146aaa218ed06a625c78.jpg
│   │   │   │       ├── 1fbf3e71d0fd2f4af04f03f4277a5922.jpg
│   │   │   │       ├── 367b8335a4aa1ffa2d1718506cd6f0e7.jpg
│   │   │   │       ├── 5d07fdf2b3d6b96527011a635435f106.jpg
│   │   │   │       ├── 5d5829f27c19b9f24046e64375a99071.jpg
│   │   │   │       ├── 6c018fa5c34e6abda1443b840258cd1e.jpg
│   │   │   │       ├── 73c141e27786370cde96efafea2b7382.jpg
│   │   │   │       ├── 7cd5c2d7a28d2cba9bd7c3f544eef3d3.jpg
│   │   │   │       ├── 7d9a5a8be478fa7408bba69849a72c85.jpg
│   │   │   │       ├── 8fbd6ddfc4a777a3130dae8e0200686b.jpg
│   │   │   │       ├── be8576aa344b7be36f165b2b1376d61b.jpg
│   │   │   │       ├── c166463231683836d1c6f03a482882a3.jpg
│   │   │   │       ├── e08751ab760736c987d758a0d2abb3e1.jpg
│   │   │   │       ├── e80635792cc31c57e58c50e6c066995a.jpg
│   │   │   │       ├── e87c28ee0474e48a59ef0fd39f24be8d.jpg
│   │   │   │       ├── fb3e377c948f34d0f85ee7349c0dc15f.jpg
│   │   │   │       └── title.jpg
│   │   │   ├── BlogPost08
│   │   │   │   ├── README.md
│   │   │   │   └── media
│   │   │   │       ├── 1c43617a918e1c2228cb090212d69285.jpg
│   │   │   │       ├── 22ed587d43cdccff3039835508e2c128.jpg
│   │   │   │       ├── 39a4f7fd5fc78a93ae462b0602ba0160.jpg
│   │   │   │       ├── 3babd983e248f9fb7345b3e70f013ed5.jpg
│   │   │   │       ├── 4b1039e50c02e976e516395ae5f397b2.jpg
│   │   │   │       ├── 5a873c551cc5fa6cd1bb5c60b43c40b4.jpg
│   │   │   │       ├── 65809e8c0955da4e58dad4ee1faa10c2.jpg
│   │   │   │       ├── 6771b60565f233dccf5eef6ff453ba8f.jpg
│   │   │   │       ├── 918941ce9bf2284135d84bb9504797c2.jpg
│   │   │   │       ├── 97d41a8d8936b6d9f9e5ce5958b8497e.jpg
│   │   │   │       ├── a8697cdb5b01ea92007dde448cc677d9.jpg
│   │   │   │       ├── aaf7697564031ec7d4d0b8b849dbd4a7.jpg
│   │   │   │       ├── acd2ad57b7321185d4794f0dbbef3f67.jpg
│   │   │   │       ├── ba89994f09a0dfd898b82dd47a41a7ad.jpg
│   │   │   │       ├── cd533d179c4e179125bbdceb1a8ed714.jpg
│   │   │   │       ├── cdfea7e9bee7a508ffca5eb408659e50.jpg
│   │   │   │       ├── dedad359b08a2f0e2c94c8072b8cf15d.jpg
│   │   │   │       ├── e83d5072a6973b4f7d007c7046aaaff3.jpg
│   │   │   │       ├── e9938f4930bc52626a495073d0437ed3.jpg
│   │   │   │       ├── f052ed6ae5bde9190cfe683862d295ce.jpg
│   │   │   │       ├── f7e25a344906d91e7a2a1e1f43efa36e.jpg
│   │   │   │       └── title08.jpg
│   │   │   ├── BlogPost09
│   │   │   │   ├── README.md
│   │   │   │   └── media
│   │   │   │       ├── 17dcd2984bc58bc515c7454074e116ff.jpg
│   │   │   │       ├── 19a1637a05ee7fad47cf66de36f9a518.jpg
│   │   │   │       ├── 20899c734bcee76bd4c0423a03d6cde4.jpg
│   │   │   │       ├── 28d2610b43aa2418618e26c40353e3bf.jpg
│   │   │   │       ├── 293977d9a4c798a56773f0fa30f80372.jpg
│   │   │   │       ├── 3297ffb6a33be00acbf7723d94f64aa0.jpg
│   │   │   │       ├── 3e72d369cbd6598ebcd44220f3d43805.jpg
│   │   │   │       ├── 45a11667c371090a16b64b25a98d547e.jpg
│   │   │   │       ├── 4621bd1852fc09f6f4d99b7585ac0307.jpg
│   │   │   │       ├── 488ea9626a214483fe33def051bd7f9e.jpg
│   │   │   │       ├── 4ae3528687a1fc8a40cc5dfe86daaa75.jpg
│   │   │   │       ├── 4ca35afecf4f94631818c69e51e784c5.jpg
│   │   │   │       ├── 505fa53c10e94d80d7fc7576695ef371.jpg
│   │   │   │       ├── 514cc3485f7c24b731867d72f60db19a.jpg
│   │   │   │       ├── 5613fec115e5df6af05d5532ca16438e.jpg
│   │   │   │       ├── 58cd5c81df41392b012bd7c0f50b4fa2.jpg
│   │   │   │       ├── 590e3c64bb248e4a5cb872db4ccbde07.jpg
│   │   │   │       ├── 5f056b22719c32235d5aec6bbfaf71c6.jpg
│   │   │   │       ├── 66f25241522b5c020bdcb902f32c38a7.jpg
│   │   │   │       ├── 6ba56f71f53af9b57c93893bd4eec1fd.jpg
│   │   │   │       ├── 6c394a732a5b97f2f9394f961fe622a7.jpg
│   │   │   │       ├── 6d03618e22c195156deff452400dd96f.jpg
│   │   │   │       ├── 7caee45786dddd389ad0d1b16ff34ede.jpg
│   │   │   │       ├── 809914acebf1a9534db788410292b687.jpg
│   │   │   │       ├── 815f9fbd643f59be375a4299c3c1100d.jpg
│   │   │   │       ├── 823f483ac1c39e30ff0215360db67f40.jpg
│   │   │   │       ├── 934fd7b2cd303bd790828a51461d6fd1.jpg
│   │   │   │       ├── 9b534556c434464843bfa4fcf157c4e3.jpg
│   │   │   │       ├── 9cf891288a85bc3614d650550c299cca.jpg
│   │   │   │       ├── ae674686e49a6cec5f7c89741240f4f7.jpg
│   │   │   │       ├── b4b24b0b45244b0c24ed068f6272449c.jpg
│   │   │   │       ├── b9076de4359ad8ae0837d53b8c466877.jpg
│   │   │   │       ├── b9939199295c39ea8e3f14ffde2c64de.jpg
│   │   │   │       ├── bd2a5ee14a908178de09af9a79694e10.jpg
│   │   │   │       ├── c9b5933401c3fc92deefe9e3e619e754.jpg
│   │   │   │       ├── cac499b4a404ec45d94131fb76934f87.jpg
│   │   │   │       ├── d0924ae103676223cc8132512e321a7e.jpg
│   │   │   │       ├── e182a99641e64dd2fe899aa29fadbaa1.jpg
│   │   │   │       ├── e1f3da41e0446f83963d052804080d9b.jpg
│   │   │   │       ├── e3e5e853d751c4608163ccd93806c6f1.jpg
│   │   │   │       ├── e700f076625b74d80de4ba9b512d1256.jpg
│   │   │   │       ├── f29a7a437733a209c4dd0bfd4162f570.jpg
│   │   │   │       ├── fa27b86f970d5806313d4b52ed5a5f5d.jpg
│   │   │   │       ├── fc43c8bcb25d64bb7f5138b1ef27121b.jpg
│   │   │   │       └── title09.jpg
│   │   │   ├── BlogPost10
│   │   │   │   ├── README.md
│   │   │   │   └── media
│   │   │   │       ├── 12b6f54b662f7ec8729e4da53e5177a2.jpg
│   │   │   │       ├── 21df4a296f72cb12ea7fb54f0f77d1d7.jpg
│   │   │   │       ├── 43494acacc169029846e0f63ff308449.png
│   │   │   │       ├── 555c2a10c99f86666bdb84d40d45ff03.jpg
│   │   │   │       ├── 77f97adcad1d1cedb531a104e8e65875.jpg
│   │   │   │       ├── 7ca03ec484d437500961064558096732.jpg
│   │   │   │       ├── 7cd08f44f46b4f8a78538e5a2fc5ebb2.png
│   │   │   │       ├── 87462d3ce18b23d74a87cdf4bd181e37.jpg
│   │   │   │       ├── 8a4df70b2c61e3a745d6fae5bcfb1875.jpg
│   │   │   │       ├── 8f1d2a9fce0a9ea47ae0bba8c89aca3a.jpg
│   │   │   │       ├── 90007e63aacbdd5b1027c6950a44fbad.jpg
│   │   │   │       ├── aa35ec948bfac13ee5e611eda4571878.jpg
│   │   │   │       ├── b2a7f2cc345d999465e89e230cb50c42.jpg
│   │   │   │       ├── b48283a83c3231560729e31869c48c62.jpg
│   │   │   │       ├── b6f46828044ec4370b5556005ef959d3.jpg
│   │   │   │       ├── b9dedc289bed06fa05d21a98fd9c2252.jpg
│   │   │   │       ├── bd2ae2deeb73d6ac98ee4c9833a70f60.jpg
│   │   │   │       ├── ca931107812f4c1200d0ef82395b520e.jpg
│   │   │   │       ├── da3e47df266d222ad6876b1f067e3214.jpg
│   │   │   │       ├── e05abb1ef58fda963600498c4ff1b48f.jpg
│   │   │   │       ├── e353855fcbaefed07d13ea26c40e4a77.jpg
│   │   │   │       ├── f28b20fde96bdfd003bd7b4841bd8167.jpg
│   │   │   │       ├── f6ad5ca770f2aea4296b1db72ce5408b.jpg
│   │   │   │       ├── f89af80f794db7d68576521f3c034c44.jpg
│   │   │   │       ├── f9760de1d46bba49d6f8ba564557a520.jpg
│   │   │   │       ├── fd357e9644f691f239ed99621c2d27ab.jpg
│   │   │   │       └── title10.jpg
│   │   │   ├── BlogPost11
│   │   │   │   ├── README.md
│   │   │   │   └── media
│   │   │   │       ├── 022411ac02ac57056dc035e1185e167f.jpg
│   │   │   │       ├── 02ea46a088b3a7b913ec7a90838f6fa2.jpg
│   │   │   │       ├── 0a2229902ac6a2ff13c93c05af5b588b.jpg
│   │   │   │       ├── 0db8d3f35501190b2e971a3b83b804e1.jpg
│   │   │   │       ├── 1aa78b0e0fff0191b646f331ea3dbd99.jpg
│   │   │   │       ├── 2f73f0749d344b674784d3fb6affd7fd.jpg
│   │   │   │       ├── 45194866e96921a358f78e22a9c4e857.jpg
│   │   │   │       ├── 5bc065899184a23ac95778a586db1651.jpg
│   │   │   │       ├── 5c7e919a94fd6cd8488bbe6d922f68b6.jpg
│   │   │   │       ├── 5e774571032fda2b007c407e068f03f1.jpg
│   │   │   │       ├── 6890224ea8733ab7349ed33ca2b6e62d.jpg
│   │   │   │       ├── 764dd53e3a5c220059b189499b567282.jpg
│   │   │   │       ├── 78f6347269f86aa2dc6abdd8ea1c2bf8.jpg
│   │   │   │       ├── 7c9d18c422565ae2aed50084fa2c3b80.jpg
│   │   │   │       ├── 7d02593bdc15315abc7fba98c8e9f02d.jpg
│   │   │   │       ├── 8ee70b931e79f76fd64713747011c2a0.jpg
│   │   │   │       ├── 966760d5def6a518d9d0b26d1f4a2482.jpg
│   │   │   │       ├── 9a220a6808cb458ce4210fe1948d15eb.jpg
│   │   │   │       ├── 9d3a0bd5ebdd5d3560f27035eb5c8296.jpg
│   │   │   │       ├── 9f4aa1c2805e0cac3b1cb1e60fbbbf06.jpg
│   │   │   │       ├── 9ffd918bb7b1aa7dc46eeab648b48630.jpg
│   │   │   │       ├── b5bb6601996dc236aa103f3ca00dee97.jpg
│   │   │   │       ├── bc7ebc55d67e2fc8b4faef66ecabe3a5.jpg
│   │   │   │       ├── c099e6700c40253bd03081fde57c55de.jpg
│   │   │   │       ├── c6d17a21e8a4ee4d32bcb510f95a2185.jpg
│   │   │   │       ├── cf01ae3d574b79814066f5bc6b1356da.jpg
│   │   │   │       ├── dfcb34e1cd59f4645d21066fcc0ca34f.jpg
│   │   │   │       ├── ecd5347e24a3def949585440c73463b8.jpg
│   │   │   │       ├── f272f89c74a91128b63748fe6600471b.jpg
│   │   │   │       ├── f8c39ee216cc583194906bec4a03aef8.jpg
│   │   │   │       └── title11.jpg
│   │   │   └── BlogPost12
│   │   │       ├── README.md
│   │   │       └── media
│   │   │           ├── 01802dfa57da72a6c6a76161da4b1e04.jpg
│   │   │           ├── 091a575236054ddcde8422a3aa6095d0.jpg
│   │   │           ├── 5.1.png
│   │   │           ├── 5.2.jpg
│   │   │           ├── 764ef0dcbbfd8d6ae91186e3a36d0821.jpg
│   │   │           ├── 82fd0dea9bcaf4fb767fb3eba8075b04.jpg
│   │   │           ├── 92e0d51275b3d869c63559373079f0ce.jpg
│   │   │           ├── ae678cacdd471cb8991658341b2f6e80.jpg
│   │   │           ├── f0613d0d3a05fd00a20e406960b2a066.jpg
│   │   │           ├── fd7d4ea340f5190bfdc4a827230bd2e2.jpg
│   │   │           └── title12.jpg
│   │   └── README.md
│   ├── 《代码整洁之道》读书笔记
│   │   └── README.md
│   ├── 《游戏编程模式》读书笔记
│   │   ├── README.md
│   │   └── media
│   │       ├── 1.png
│   │       └── 2.png
│   ├── 在“绝世武功的目录”RTR4中译版出版前，先奉上“绝世武功秘籍的本体”
│   │   ├── README.md
│   │   └── media
│   │       ├── 01ff59e67675643568627bddaf5df0b3.png
│   │       ├── 4f4aa77da8c51387919325924faf7ed5.png
│   │       ├── End.jpg
│   │       ├── RTR4.gif
│   │       ├── b6280fd2f691a81f61489bc03efa2eff_.jpg
│   │       └── rtr4.jpg
│   ├── 天美跨平台3A大作全球招聘令与RTR4中译版出版时间预告
│   │   ├── README.md
│   │   └── media
│   │       ├── 03559d0cee2b52a51fc73fc5aa492296.jpg
│   │       ├── 1498af9061855e37a71d2a5699631e05.jpg
│   │       ├── 3c2637651e84af5995dde3060e7c79fb.jpg
│   │       ├── 703a0e8ac5a665bb6a1c0af769c23ad4.jpg
│   │       ├── 703a0eXXc5a665bb6a1c0af769c23ad4.jpg
│   │       ├── a464ef290b9e3475943786dd36cd81ae.jpg
│   │       └── e67252da39e9bc8aefa4671ee38be53e.png
│   ├── 实时光线追踪技术：业界发展近况与未来挑战
│   │   ├── README.md
│   │   └── media
│   │       ├── 07a30fa18436871bb8ef37fc18854134.png
│   │       ├── 0f127c5e9b475df59de8b26cc38a5535.png
│   │       ├── 13cbbf71e27aa76dc0cc0fba598d20ac.png
│   │       ├── 14346ab101400f1c0294623f8a6075d9.png
│   │       ├── 1bfbb1ebd9dac568789d60fe97bf4a73.png
│   │       ├── 24e7ce6cb181b6a51544cead794beb61.png
│   │       ├── 262f9353deebc2fe32be88ed9f6bf4e3.png
│   │       ├── 2f9d45d894247fa85c1ae57fcaef9437.png
│   │       ├── 3094e2f8bc0778cd772468b84514e2c8.png
│   │       ├── 30e5f419de063f0911519c3e2ab39e7e.png
│   │       ├── 3cda89bae936e6484d06b0d6cd2c7f8d.png
│   │       ├── 418d624111eafde156257aa25a95d952.png
│   │       ├── 487aa87eac891248f93343e3a1280c8d.png
│   │       ├── 4f43c895e05027e5fff8a419027aadb9.png
│   │       ├── 52991522705906c1c329693d63e72537.png
│   │       ├── 562ea1b425c680866b708d5796c6b884.png
│   │       ├── 5d8a860b3f656936f34d8ae9c5363e17.png
│   │       ├── 6222bcd3fdd9ce2274df2dccac83a722.png
│   │       ├── 65d452ab1ebd1992a8948787786c3584.png
│   │       ├── 7d41d593d56c778b925e76bb79da89e4.png
│   │       ├── 7f1468f7f9b3e2acd55fc8fa2ea56fa3.png
│   │       ├── 944f62c473dcb5f2973fff0ee0d6ce26.png
│   │       ├── 982a99eda74fb19e302378186577b965.png
│   │       ├── a5eed51b8538324d5b641f87344f96c4.png
│   │       ├── a605aca9ebe3090a05f6b495d76eda22.jpg
│   │       ├── a90e6fe178d010d72cccd7c1f7ed7da7.png
│   │       ├── ac2705093a98f633f80ff369dedc4456.png
│   │       ├── b231bac948149c3d66dd68ed70486c47.png
│   │       ├── b5b0247c681f328d57720f432d7ed01a.png
│   │       ├── b68d517b4af89c7532133267bb8990d8.jpg
│   │       ├── b8003c86959b736c2536a34039528fc5.jpg
│   │       ├── c1a8ff13c3cc16958909d45a50137cf0.png
│   │       ├── cef7dedb590971242cdca0e944c93476.png
│   │       ├── d1a46babdee712952fbd4f083e8d6d4c.png
│   │       ├── d939fc61829a5a5328e5382ca24ef583.png
│   │       ├── e1984036e480d9fe2b38e4a6050f2be5.png
│   │       ├── e36c5c9456015553e30791ed1e23c651.jpg
│   │       ├── e7c074eab1399b7114cdd7f1689adbf7.jpg
│   │       ├── ec782554f31f3c05b1c98545880c7e2c.jpg
│   │       ├── ee037b7f8ff1ccd335d4f077b2b33fa6.png
│   │       ├── f9fe0b404cfd2c64c23e63068a80321b.png
│   │       ├── fa05c5d7edfff0dc4a854d405c10684c.png
│   │       └── fb2e0ef799be1f2127e1264c938343e6.png
│   ├── 真实感水体渲染技术总结
│   │   ├── README.md
│   │   └── media
│   │       ├── 0af0355442767919f9aff9876432859f.png
│   │       ├── 0e798671dd9c8cab74310fec756b8947.jpg
│   │       ├── 19d3c94b611257d2077dd4992709586e.jpg
│   │       ├── 1b5cc8c471c19acaf7c14ef464d620a0.gif
│   │       ├── 1b8b68602c4341b0635fb65aec3cbe62.png
│   │       ├── 1cb3d14ab4d525fb3ef01250b0409cc5.png
│   │       ├── 232609b215fcd8e1df5ef26f7cf9cd28.png
│   │       ├── 29afa8cb7c082da59f879920e41148f4.png
│   │       ├── 2f5a16138b7ea35ff97964eb0083b073.gif
│   │       ├── 35071f67896903b9c795a2cd644d477a.png
│   │       ├── 37127e8f88345c7b4603d07bdfcf1169.png
│   │       ├── 3b0b3b1569bd4b0e8cf0aa7edbd32211.jpg
│   │       ├── 3e4204b7bc0bda540dc68d342a365fda.png
│   │       ├── 418aa434032174c42703cabcc28d3e7b.png
│   │       ├── 45bd4e330ee85602305b6c0060318bf1.jpg
│   │       ├── 48b4b55c258d3511bc5ad4adf91d6b2f.png
│   │       ├── 4fcc2a8b1753a1aabeecb8ab6c0735ee.gif
│   │       ├── 51f3fb42fc45bb61f207dc2a981b28b1.jpg
│   │       ├── 5bd61f0f22cc734a250310c204b1799f.png
│   │       ├── 603c2d6acf7a1353f39cc8e84198b0ea.png
│   │       ├── 65a195446da34cbcdf968e25301afe40.gif
│   │       ├── 6706dced4ba808378b30ad6ea07c94ad.jpg
│   │       ├── 6ba7d85f1f61b45f3ea0ed5a1c8c4995.png
│   │       ├── 70a5e66f5a560ceac6063f7e345d4ce4.png
│   │       ├── 74215aad7e2b742784c294f66e1bffca.png
│   │       ├── 769884eccc5f53075cf76f50cbe0a7be.png
│   │       ├── 77d6df448a37393793138e6aed31c453.png
│   │       ├── 7ad644310aae035a960a8ee45d026878.png
│   │       ├── 7b01b4fcfb5692db907e37282d0b19ba.png
│   │       ├── 7e389f8e7b164d003fdf029a97f3848f.jpg
│   │       ├── 89d5f030e13e8a172cb07d6177891e68.png
│   │       ├── 8c1eeab1cf760dcd6b0cd186a81bc58b.gif
│   │       ├── 920ff7f35ceed08b08141e60b84dc228.png
│   │       ├── 93a93b541535bb6ec58c30f2879bb9a9.jpg
│   │       ├── 9897da02e043694cba54f1997172a394.png
│   │       ├── 9f3cc03578fb3319a1dadff2e732ad84.jpg
│   │       ├── AC3-offline-FFT.gif
│   │       ├── BSSRDF.jpg
│   │       ├── Flow-Map-Example.jpg
│   │       ├── Flow-Map-UDK.gif
│   │       ├── Flow-Map.png
│   │       ├── Flow-Map2.png
│   │       ├── Gerstner-wave3.gif
│   │       ├── Houdini-Fluids-Simulation.gif
│   │       ├── SSS.gif
│   │       ├── Water-Rendering-Knowledge-Architecture.png
│   │       ├── Water-Surface-Wavelets.png
│   │       ├── a0baab932bed4ba7dc36d69c2d9e49f7.png
│   │       ├── a1010df7c688043cbe1ea20b91389bca.gif
│   │       ├── a1444c00510cffa25cd85017195f8748.png
│   │       ├── a3a9ad5afe1cb5c5b0d85da93ff6160f.png
│   │       ├── a42f7c3ca6ef1c17b8a70f37478b3fa9.jpg
│   │       ├── b44bd22505708fcbfa7475e2daba3a33.png
│   │       ├── b7edd1c78d459d3da3eef13f12fb4624.png
│   │       ├── b91c64e4c72d492a3a78683cb37e5d07.png
│   │       ├── be9b5771072d9b8f12754dd09572986f.jpg
│   │       ├── c090dbc09e0b566c8a5257421741fa03.png
│   │       ├── c47959a66f114c8dccc845771081a73f.png
│   │       ├── c7efe9490bfecd9b5d181c43734b6abf.jpg
│   │       ├── c84317062f5d4cf06961a0c0418eb5cf.gif
│   │       ├── cc1a37cb528dcc8fd7575fcecd567d28.jpg
│   │       ├── cc7936ce27c4431778fab9b01f64c779.png
│   │       ├── crest-2017-procedural-shape.gif
│   │       ├── d171d460a0a940a73dfcb01d6dbc8697.jpg
│   │       ├── d2bacc53079129f4d49a221444af7ed7.png
│   │       ├── d3da711298b707c03ef27ef2836b7bde.jpg
│   │       ├── d957523662ca2f2c12855c75833458bb.png
│   │       ├── daf43226edfa0f2ac2674cd5ddb6d07b.gif
│   │       ├── dd43a67fd4ab46b150452ed7e864b5de.png
│   │       ├── f9336662004c902ac45c66f56fc1.png
│   │       ├── f9337c818762004c902ac45c66f56fc1.jpg
│   │       ├── fd253aaccef1624e2de81c1e51409452.png
│   │       ├── fft.jpg
│   │       ├── fft_infographic.jpg
│   │       ├── flow-map.gif
│   │       ├── foam.gif
│   │       ├── fornite-flowmap.png
│   │       ├── nVidia-WaveWorks-UnrealEngine-4.15.png
│   │       ├── title.png
│   │       ├── vector-displacement-map.gif
│   │       ├── vector-displacement-map.png
│   │       ├── wave-particle.gif
│   │       └── wave2017-6.gif
│   ├── 高品质后处理：十种图像模糊算法的总结与实现
│   │   ├── README.md
│   │   └── media
│   │       ├── 03872365a0d205fe7d1d9c05cf982709.png
│   │       ├── 06f1d0823ec0a797fe4999778ade5a59.gif
│   │       ├── 072d5a18279fac83dd465dfe20ccbc27.png
│   │       ├── 0aca0e7a74b644d1a1232d7311ae8473.jpg
│   │       ├── 0c68c66628bfa24d6a4a60b291bf364b.gif
│   │       ├── 130ec1a6dbdee035c956306b98b39bcb.jpg
│   │       ├── 1623d27dec6f63ee9790dda63a60b125.jpg
│   │       ├── 1ad248b2a04bfe2d3791a3c89cd88656.png
│   │       ├── 1eda0da557b6d9808c3f966b0f629490.gif
│   │       ├── 28030aa3848315f385c9b9cb06807485.png
│   │       ├── 2ebf4981ecdc7d4c81bf5c2f02edfb31.png
│   │       ├── 2f47eace291ac9e6217c0e124c395b92.png
│   │       ├── 328bcaa82bbb793c5ab72adad9f92bf1.png
│   │       ├── 3386e01c8b105ef7e8bf8427f426155c.png
│   │       ├── 357c5fae13a41a96cabc2c8e5cd27d20.png
│   │       ├── 3aedd63b1819614bb73a76196ceec706.jpg
│   │       ├── 3ce94d027109baba427440e515a99999.png
│   │       ├── 4101dff5d82408c4c404b5d90f6ab22c.png
│   │       ├── 4556f53e98a5ef378e1fa1926bd496cb.jpg
│   │       ├── 45bee7e1482fd0ea1a60ed71c0e5c854.gif
│   │       ├── 4da60429ba567bef2df17b9d38b65585.png
│   │       ├── 513005a757dc352083a8cec5889259f2.png
│   │       ├── 61.1.png
│   │       ├── 6216cbf3cdcb7ba42679545ca664e96a.jpg
│   │       ├── 657a242a1f1beb689df33a82d88b6d5c.png
│   │       ├── 6b40938cfddc691005bb05822a5c398e.jpg
│   │       ├── 6c89d617142422ac6c7b6b9a4129d983.png
│   │       ├── 6e9680adbf5220b3abb9d20bdede07f3.jpg
│   │       ├── 734619e4f5594f567b6009d25ebb7c60.gif
│   │       ├── 736728074657aa9df6a2ec3d00a2a65a.gif
│   │       ├── 7623f49a2849b081d674afffa3201fee.png
│   │       ├── 7c81e8b40e8c86a286003012a2ef7eea.gif
│   │       ├── 7e04eb8d9007d9e91f5f6fe4e7770759.png
│   │       ├── 7f0736f2cb5251bb41477f277d252bee.png
│   │       ├── 7f0e8d10c7e89fddba1ea3249fd2883a.png
│   │       ├── 870224e670b3157d7082d9e37f468c8d.png
│   │       ├── 8833561d489ea70dc3e4a45d54e86c24.png
│   │       ├── 89eb65f434ae50051cb07cc3c802ca7d.jpg
│   │       ├── 8a70626a23b1640b2a0a1ba74304541e.png
│   │       ├── 8bc10ccaba3d1cb963c7c53e4c07ae96.jpg
│   │       ├── 96f4ff7c533d389d523cddea4a62f2e6.jpg
│   │       ├── 9b214c420a347a25ac11f6e4edb236ef.png
│   │       ├── 9b9c38f9730affe157566310955b80a3.gif
│   │       ├── 9baae89bbc953dd6431475a91df4d322.png
│   │       ├── 9d7e3b7a0d89a504390557f88541961e.gif
│   │       ├── 9fe9182c3ccb44b95c4feaf5060307cf.png
│   │       ├── KawaseBlur-1.gif
│   │       ├── KawaseBlur-2.gif
│   │       ├── a5f93c9c118c0b991fc6a988e5a23d9e.png
│   │       ├── a6b05dac4ef3d1d4da0efed0a793baec.jpg
│   │       ├── b05cff0fb8d1036d1972f82d35c4da6f.jpg
│   │       ├── b505f4fd7a72fc5b8b6b7be0b78229c8.png
│   │       ├── b5b10ba32bec1e755e541cc4de8d015e.jpg
│   │       ├── b82ba2aaa60f290da438450a86ccb48f.png
│   │       ├── b86eda5e0fb7b8c0643adf78adf98925.png
│   │       ├── ba1760758cd9f00e7b65d12ecf8b7c8a.jpg
│   │       ├── bcac2c9252b814447e87f5bc88268be8.jpg
│   │       ├── bfc435caf5f6681f35a2bf9718a57c1e.gif
│   │       ├── c995ed9cebd5b0e2760b0556f36b2149.png
│   │       ├── ce27882013b6c4c1c5e2fc6c4e2feaf8.gif
│   │       ├── d6fa04bb9b48e400b803adf63f42416a.jpg
│   │       ├── d920a7ba9b40b5511769db942c469371.gif
│   │       ├── dbd46f6ebbe1a64e080f2667b55cdd8e.png
│   │       ├── dc5b0bb30b61379a55a98b9d2cca8acf.jpg
│   │       ├── de715323002f982405423c77a3692437.png
│   │       ├── e230629ffe1b2da2325caec0a6401b96.jpg
│   │       ├── ea82e6cf88735637243708803e393275.png
│   │       ├── ef3648c8276d045ffcd8b58b7b23e624.gif
│   │       ├── ef8abce69b1e9f7987f0e9d203d9e690.png
│   │       ├── ef952edc96ab383fa45bd443b24d84c4.png
│   │       ├── f07c1990dbfce8bd3da82617de62c8f5.jpg
│   │       ├── f20159279e99b4174740875b9e33a28b.jpg
│   │       └── f5668bf755f6b60c22c596220253d3e8.gif
│   └── 高品质后处理：十种故障艺术（Glitch Art）算法的总结与实现
│       ├── README.md
│       └── media
│           ├── 0e46e833408f134b4e60639f678c6e73.gif
│           ├── 0f012c30e78082558166ceedbfeda729.png
│           ├── 1689ba7c27383f6db417dd35b764cdf3.gif
│           ├── 1791d0b28d6191a45c1235a39463ac5e.gif
│           ├── 17fc92ce4cb3432d31f1abff2060e989.gif
│           ├── 227015cf8d68bade6a90229a8d4bc4c0.gif
│           ├── 295a770f97d3463c20e9358d93891fb3.gif
│           ├── 2e43dee0491aaba8ee822bcf2ee45312.gif
│           ├── 2ef9438939a81cafa257cffbdbe493a9.gif
│           ├── 2f14f66f64bffcbf83a53adce4cdb69e.gif
│           ├── 322623af4b0591fbb81f7082104ef862.png
│           ├── 328ab5b7882dec1251bc96e771be28f7.gif
│           ├── 33fb0f93f870af94fac2e0f944202d54.gif
│           ├── 3532f4a52070b0c1c0ae2640c1ae7801.png
│           ├── 39.1.gif
│           ├── 3d34f30356b1f00abb6b3c93ae2b43dc.png
│           ├── 400d557b63b1d983e7c046704a8f7e1b.png
│           ├── 42ad5db0ab8bdd8c04d349705cdfec70.png
│           ├── 48.gif
│           ├── 48d2fefbedfb9c84975b587d6368824c.gif
│           ├── 496be98975fbb3dfda2acb0ed5e0e15b.gif
│           ├── 4a7aa22e312d1acf94773fd4aa743003.png
│           ├── 4b96ce25c89d300d3bb7245bd8af2eec.gif
│           ├── 4d170f6ed0453120c2f5b3a3b7b4c1a2.gif
│           ├── 53a92c5ea340114cf8c11fb523c02180.gif
│           ├── 62fb4c1cbcb6d8d3599a356152096d85.gif
│           ├── 633fcad89870e8858a2bcdadb33ebde4.gif
│           ├── 644ae2ffbaa0684a5c281c4b99493a0e.gif
│           ├── 65c71e06c52ec28dc71931cd200efd6a.gif
│           ├── 6a76a60269920509dcb706a3c19f1cda.gif
│           ├── 6ece245744961b4423121341b646bfc2.gif
│           ├── 7921e7f2d840a0ab22ffc5c203c5a0f1.png
│           ├── 798217fb92edbd778bca777b1159f860.gif
│           ├── 79dbf132f67246692cb65dfecbea2d37.jpg
│           ├── 7ecedf29afadde2e3f5f41240f835cdb.gif
│           ├── 8274a6410b525ed3240c342671c073c0.png
│           ├── 8ee13659a31cf8b1afff7f223b79ae2e.gif
│           ├── 921033407f4f0713f0d65926908dd8fd.gif
│           ├── 97fa0c1b7f14497c48ae9574e7d7ea8f.gif
│           ├── 989397ce8ae4169220d381b1b6466995.jpg
│           ├── 9a7e15427e747a138b24955e4d8eb07f.gif
│           ├── 9b8e47d4109237a8d500229895b170e3.gif
│           ├── 9c0fad40cdfd5f8a9891274b3c562cc5.gif
│           ├── a0ff7e1c447a3416e1466f75b1ca0a9b.gif
│           ├── a9af498ec017da3e66dec7f71d0883a6.gif
│           ├── b5d768ce574684a71147c32c3d79749d.gif
│           ├── b6445684613f8fd693b8b58005f21cff.png
│           ├── b68c95b411b036f2d3cb19fae39c117b.png
│           ├── c04efc5ac94afa5172c6ce4b0275d1f2.gif
│           ├── c064eeb45ec2b0edf941e941a430e2c1.jpg
│           ├── c51d84acf7377b3166219d313177f50d.gif
│           ├── c555183415acbce177f0b96c3b090d9a.png
│           ├── c7347fc3eab1a6adbdcdcccf1dd0bd51.gif
│           ├── c9c12de9bc072f2cbdcf547207dd49fe.gif
│           ├── ce0f22d2a51d470b499b27bb3da10d3a.gif
│           ├── cf20339e06bc8a52c2c6573dd9261682.gif
│           ├── d1f20ccdcc6028d9eccb1afd8a6b5c0c.jpg
│           ├── d287de98424bf1b8de486bf69ad697a4.gif
│           ├── d6248833de3a7111dbca499cdc955df9.gif
│           ├── debda36941aa6564c6b8b8b38ef9d318.jpg
│           ├── ea3b9abb2228f18b6729dfb7a03727c2.jpg
│           ├── f32cfdbbdde991f9c01a65f2c9939d59.gif
│           └── f6645202c3717b8609086b3e92a3a750.gif
├── Media
│   ├── BooksCover
│   │   ├── GPU-Programming-And-Cg-Language-Primer-1rd-Edition.jpg
│   │   ├── Game Programming Patterns.jpg
│   │   ├── RTR3.jpg
│   │   └── clean-code.jpg
│   ├── cover.jpg
│   └── nature-grass-leaf-green.jpg
├── README.md
└── process.dct

```

`Content/《Effective C# 第二版》读书笔记/README.md`:

```md
《Effective C\# 第二版》读书笔记
============================
<br>

原则1：尽可能地使用属性(property)，而不是可直接访问的数据成员
-------------------------------------------------------------
<br>

## 1. 概述

属性一直是C\#语言的一等公民。自C\#
1.0版本以来，C\#对属性进行了一系列的增强，让其表达能力不断提到。你甚至可以为setter和getter指定不同的访问权限。隐式属性也极大降低了声明属性时的工作量，不会比声明数据成员麻烦多少。

属性是一种全功能的、第一等的语言元素，能够以方法调用的形式访问或修改内部数据。成员函数中可以实现的任何功能都可以在属性中实现。

如果你的类里还有Public的变量，如果你还在手写get and set 方法，可以停下来了。

属性允许将数据成员作为共有接口的一部分暴露出去，同时仍旧提供面向对象环境下所需的封装。属性这个语言元素可以让你像访问数据成员一样使用，但其底层依然是用方法来实现的。

.Net Framework假定你使用Property来让外界访问你类里想让外界访问到的数据成员
。实际上也是这样的，因为.Net的数据绑定只支持Property，而不支持公有数据成员的访问。数据绑定的目的就是把一个对象的属性绑定到一个用户界面的control上。数据绑定是通过反射来实现的，如下例：

	textBoxCity.DataBindings.Add("Text", address, "City");

这段代码就是把textBoxCity的Text Property绑定到address这个对象的City
属性上。公有的数据成员并不推荐使用，因此Framework Class
Library设计器也不支持其实现绑定。这样的设计也保证了我们必须选择合适的面向对象技术。
<br>
<br>

## 2. 使用属性，可以方便地加入检查机制

如果你使用了Property，你可以非常轻松的添加一个检查机制，如下面这段代码:

	public class CustomerEx
	{
	    private string name;
	    public string Name
	    {
	        get { return name; }
	        set
	        {
	            if (string.IsNullOrEmpty(value))
	                throw new ArgumentException(
	                "Name cannot be blank",
	                "Name");
	            name = value;
	        }
	        //...
		}
	}



<br>

## 3. 属性可支持多线程

因为属性是用方法实现的，所以它拥有方法所拥有的一切语言特性。

比如，属性增加多线程的支持是非常方便的。你可以加强 get 和 set 访问器
（accessors）的实现来提供数据访问的同步：
		
	public class Customer
	{
	    private object syncHandle = new object();
	    private string name;
	    public string Name
	    {
	        get
	        {
	            lock (syncHandle)
	                return name;
	        }
	        set
	        {
	            if (string.IsNullOrEmpty(value))
	                throw new ArgumentException(
	                "Name cannot be blank",
	                "Name");
	            lock (syncHandle)
	                name = value;
	        }
	    }
	    // More Elided.
	}



<br>


## 4. 属性可以声明为virtual

同样，因为属性是用方法实现的，所以它拥有方法所拥有的一切语言特性，那么同样，属性可以被定义为virtual:

	public class Customer
	{
	    public virtual string Name
	    {
	        get;
	        set;
	    }
	}

<br>

## 5. 属性可以声明为接口，以及abstract

显而易见，你也可以把Property扩展为abstract，甚至成为interface的一部分：

	public interface INameValuePair
	{
	    object Name
	    {
	        get;
	    }
	    object Value
	    {
	        get;
	        set;
	    }
	}



<br>

## 6. 属性可以使用泛型

你可以用泛型+接口的属性类型：

	public interface INameValuePair<T>
	{
	    T Name
	    {
	        get;
	    }
	    T Value
	    {
	        get;
	        set;
	    }
	}

<br>

## 7. 给get 与set定义不同的访问权限

如前所述，因为属性是用方法实现的，所以它拥有方法所拥有的一切语言特性。

因为实现Property访问的方法get 与set是独立的两个方法，在C\#
2.0之后，你可以给它们定义不同的访问权限，来更好的控制类成员的可见性，如下：

	public class Customer
	{
	    private string _name;
	    public virtual string Name
	    {
	        get
	        {
	            return _name;
	        }
	        protected set
	        {
	            _name = value;
	        }
	    }
	    //...
	}




<br>

## 8. 在属性中使用索引器

想返回序列中的项，创建一个属性是非常不错的做法，如下例：

	public class Customer
	{
	    private int[] _theValues= new int[3] { 1,2,2};
	
	    public int this[int index]
	    {
	        get
	        {
	            return _theValues[index];
	        }
	        set
	        {
	            _theValues[index] = value;
	        }
	    }
	}

	//usage:
	Customer c1 = new Customer();
	c1[1] = 666;
	var cc1 = c1[1];



索引器和单元素Property有着相同的特性，他们都是作为方法实现的，因此可以在索引器内部实现任意的验证或者计算逻辑。索引器也可为虚的或抽象的，可以声明在接口中，可以为只读或读写。一维且使用数字作为参数的索引器也可以参与数据绑定。使用非整数参数的索引器可以用来定义其他的数据结构，如map和dictionary：

	public class AddressEx
	{
	    private Dictionary<int, string> _address = new Dictionary<int, string>();
	    public string this[int name]
	    {
	        get
	        {
	            return _address[name];
	        }
	        set
	        {
	            _address[name] = value;
	        }
	    }
	}

	//usage:
	AddressEx a1 = new AddressEx();
	a1[1] = "New York";
	a1[2] = "Hong Kong";
	var a11 = a1[1];




<br>

## 9. 创建多维索引器

为了和多维数组保持一致，我们可以创建多维索引器，在不同的维度上使用相同或不同类型：

	class ComputeValueClass
	{
	    public int this[int x, int y]
	    {
	        get { return ComputeValue(x, y); }
	    }
	
	    public int this[int x, string name]
	    {
	        get { return ComputeValue(x, name); }
	    }
	
	    private int ComputeValue(int x, int y)
	    {
	        //...
	    }
	
	    private int ComputeValue(int x, string y)
	    {
	        //...
	    }
	
	}


值得注意的是所有索引器必须使用 this 关键字声明。在 C\#
中你不能自己命名索引器。所以一个类型的索引器必须有不同的参数列表来避免歧义。几乎所有的属性的功能都适用索引器。索引器可以是
virtual 或 abstract ；索引器的 setters 和 getters
可以不同的访问限制。不过，你不能像创建隐式属性一样创建隐式索引器。

<br>

## 10. 总结

总而言之，无论什么时候，当你想让你类内部的数据被外界访问到时(无论是public还是protected)，一定要用属性。对于序列和字典，可以使用索引器。

使用Property，你可以得到如下好处：

1．数据绑定的支持

2．对于需求变化有更强的适应性，更方便的修改实现方法。

记住，现在多花1分钟使用Property，会在你修改程序以适应设计变化时，为你节约n小时。

```

`Content/《GPU Gems 1》全书提炼总结/README.md`:

```md



![](media/title.jpg)


# 【GPU精粹与Shader编程】《GPU Gems 1》全书核心内容提炼总结

<br>

题图背景来自《战神4》。


<br>

本文的知乎专栏版本：

上篇：
[https://zhuanlan.zhihu.com/p/35974789](https://zhuanlan.zhihu.com/p/35974789)



下篇：
[https://zhuanlan.zhihu.com/p/36499291](https://zhuanlan.zhihu.com/p/36499291)



 # 快捷导航目录
 
 **PS: 等待网页加载完成后即可顺利进行快速导航跳转。**

<!-- TOC -->

- [【GPU精粹与Shader编程】《GPU Gems 1》全书核心内容提炼总结](#%E3%80%90gpu%E7%B2%BE%E7%B2%B9%E4%B8%8Eshader%E7%BC%96%E7%A8%8B%E3%80%91%E3%80%8Agpu-gems-1%E3%80%8B%E5%85%A8%E4%B9%A6%E6%A0%B8%E5%BF%83%E5%86%85%E5%AE%B9%E6%8F%90%E7%82%BC%E6%80%BB%E7%BB%93)
- [快捷导航目录](#%E5%BF%AB%E6%8D%B7%E5%AF%BC%E8%88%AA%E7%9B%AE%E5%BD%95)
- [系列文章前言](#%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0%E5%89%8D%E8%A8%80)
- [目录 · 核心内容Highlight](#%E7%9B%AE%E5%BD%95-%C2%B7-%E6%A0%B8%E5%BF%83%E5%86%85%E5%AE%B9highlight)
- [《GPU Gems 1》其书](#%E3%80%8Agpu-gems-1%E3%80%8B%E5%85%B6%E4%B9%A6)
- [书本配套资源与源代码下载](#%E4%B9%A6%E6%9C%AC%E9%85%8D%E5%A5%97%E8%B5%84%E6%BA%90%E4%B8%8E%E6%BA%90%E4%BB%A3%E7%A0%81%E4%B8%8B%E8%BD%BD)
- [系列文章风格说明](#%E7%B3%BB%E5%88%97%E6%96%87%E7%AB%A0%E9%A3%8E%E6%A0%BC%E8%AF%B4%E6%98%8E)
- [上篇 · 主核心内容提炼总结](#%E4%B8%8A%E7%AF%87-%C2%B7-%E4%B8%BB%E6%A0%B8%E5%BF%83%E5%86%85%E5%AE%B9%E6%8F%90%E7%82%BC%E6%80%BB%E7%BB%93)
- [一、 用物理模型进行高效的水模拟（Effective Water Simulation from Physical Models）](#%E4%B8%80%E3%80%81-%E7%94%A8%E7%89%A9%E7%90%86%E6%A8%A1%E5%9E%8B%E8%BF%9B%E8%A1%8C%E9%AB%98%E6%95%88%E7%9A%84%E6%B0%B4%E6%A8%A1%E6%8B%9F%EF%BC%88effective-water-simulation-from-physical-models%EF%BC%89)
    - [【内容概览】](#%E3%80%90%E5%86%85%E5%AE%B9%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心内容提炼】](#%E3%80%90%E6%A0%B8%E5%BF%83%E5%86%85%E5%AE%B9%E6%8F%90%E7%82%BC%E3%80%91)
        - [1.1 背景与范围](#11-%E8%83%8C%E6%99%AF%E4%B8%8E%E8%8C%83%E5%9B%B4)
        - [1.2 水体渲染的思路](#12-%E6%B0%B4%E4%BD%93%E6%B8%B2%E6%9F%93%E7%9A%84%E6%80%9D%E8%B7%AF)
            - [1.2.1 波的选择](#121-%E6%B3%A2%E7%9A%84%E9%80%89%E6%8B%A9)
            - [1.2.2 法线与切线](#122-%E6%B3%95%E7%BA%BF%E4%B8%8E%E5%88%87%E7%BA%BF)
        - [1.3 波的几何特征](#13-%E6%B3%A2%E7%9A%84%E5%87%A0%E4%BD%95%E7%89%B9%E5%BE%81)
            - [1.3.2 Gerstner波](#132-gerstner%E6%B3%A2)
            - [1.3.3 波长等参数的选择](#133-%E6%B3%A2%E9%95%BF%E7%AD%89%E5%8F%82%E6%95%B0%E7%9A%84%E9%80%89%E6%8B%A9)
        - [1.4 波的纹理特征](#14-%E6%B3%A2%E7%9A%84%E7%BA%B9%E7%90%86%E7%89%B9%E5%BE%81)
        - [1.5 关于深度](#15-%E5%85%B3%E4%BA%8E%E6%B7%B1%E5%BA%A6)
    - [【核心要点总结】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [二、Dawn Demo中的皮肤渲染（Skin in the Dawn Demo）](#%E4%BA%8C%E3%80%81dawn-demo%E4%B8%AD%E7%9A%84%E7%9A%AE%E8%82%A4%E6%B8%B2%E6%9F%93%EF%BC%88skin-in-the-dawn-demo%EF%BC%89)
    - [十年技术变迁： NVIDIA Dawn Demo](#%E5%8D%81%E5%B9%B4%E6%8A%80%E6%9C%AF%E5%8F%98%E8%BF%81%EF%BC%9A-nvidia-dawn-demo)
    - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心内容提炼】](#%E3%80%90%E6%A0%B8%E5%BF%83%E5%86%85%E5%AE%B9%E6%8F%90%E7%82%BC%E3%80%91)
        - [2.1 关于皮肤着色](#21-%E5%85%B3%E4%BA%8E%E7%9A%AE%E8%82%A4%E7%9D%80%E8%89%B2)
        - [2.2 皮肤如何对光进行响应](#22-%E7%9A%AE%E8%82%A4%E5%A6%82%E4%BD%95%E5%AF%B9%E5%85%89%E8%BF%9B%E8%A1%8C%E5%93%8D%E5%BA%94)
        - [2.3 场景的照明](#23-%E5%9C%BA%E6%99%AF%E7%9A%84%E7%85%A7%E6%98%8E)
        - [2.4 实现](#24-%E5%AE%9E%E7%8E%B0)
    - [【核心要点总结】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [三、无尽波动的草地叶片的渲染（Rendering Countless Blades of Waving Grass）](#%E4%B8%89%E3%80%81%E6%97%A0%E5%B0%BD%E6%B3%A2%E5%8A%A8%E7%9A%84%E8%8D%89%E5%9C%B0%E5%8F%B6%E7%89%87%E7%9A%84%E6%B8%B2%E6%9F%93%EF%BC%88rendering-countless-blades-of-waving-grass%EF%BC%89)
    - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心内容提炼】](#%E3%80%90%E6%A0%B8%E5%BF%83%E5%86%85%E5%AE%B9%E6%8F%90%E7%82%BC%E3%80%91)
        - [3.1 概述](#31-%E6%A6%82%E8%BF%B0)
        - [3.2 草的纹理](#32-%E8%8D%89%E7%9A%84%E7%BA%B9%E7%90%86)
        - [3.3 草体](#33-%E8%8D%89%E4%BD%93)
        - [3.4 草地动画](#34-%E8%8D%89%E5%9C%B0%E5%8A%A8%E7%94%BB)
    - [【核心要点总结】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [四、次表面散射的实时近似（Real-Time Approximations to Subsurface Scattering）](#%E5%9B%9B%E3%80%81%E6%AC%A1%E8%A1%A8%E9%9D%A2%E6%95%A3%E5%B0%84%E7%9A%84%E5%AE%9E%E6%97%B6%E8%BF%91%E4%BC%BC%EF%BC%88real-time-approximations-to-subsurface-scattering%EF%BC%89)
    - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心内容提炼】](#%E3%80%90%E6%A0%B8%E5%BF%83%E5%86%85%E5%AE%B9%E6%8F%90%E7%82%BC%E3%80%91)
        - [4.1 次表面散射的视觉特性（The Visual Effects of Subsurface Scattering）](#41-%E6%AC%A1%E8%A1%A8%E9%9D%A2%E6%95%A3%E5%B0%84%E7%9A%84%E8%A7%86%E8%A7%89%E7%89%B9%E6%80%A7%EF%BC%88the-visual-effects-of-subsurface-scattering%EF%BC%89)
        - [4.2 简单的散射近似（Simple Scattering Approximations）](#42-%E7%AE%80%E5%8D%95%E7%9A%84%E6%95%A3%E5%B0%84%E8%BF%91%E4%BC%BC%EF%BC%88simple-scattering-approximations%EF%BC%89)
        - [4.3 使用深度贴图模拟吸收（Simulating Absorption Using Depth Maps）](#43-%E4%BD%BF%E7%94%A8%E6%B7%B1%E5%BA%A6%E8%B4%B4%E5%9B%BE%E6%A8%A1%E6%8B%9F%E5%90%B8%E6%94%B6%EF%BC%88simulating-absorption-using-depth-maps%EF%BC%89)
        - [4.4 纹理空间的漫反射（Texture-Space Diffusion）](#44-%E7%BA%B9%E7%90%86%E7%A9%BA%E9%97%B4%E7%9A%84%E6%BC%AB%E5%8F%8D%E5%B0%84%EF%BC%88texture-space-diffusion%EF%BC%89)
    - [【核心要点总结】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [五、环境光遮蔽（Ambient Occlusion）](#%E4%BA%94%E3%80%81%E7%8E%AF%E5%A2%83%E5%85%89%E9%81%AE%E8%94%BD%EF%BC%88ambient-occlusion%EF%BC%89)
    - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心内容提炼】](#%E3%80%90%E6%A0%B8%E5%BF%83%E5%86%85%E5%AE%B9%E6%8F%90%E7%82%BC%E3%80%91)
        - [5.3 使用环境光遮蔽贴图进行渲染（Rendering with Ambient Occlusion Maps）](#53-%E4%BD%BF%E7%94%A8%E7%8E%AF%E5%A2%83%E5%85%89%E9%81%AE%E8%94%BD%E8%B4%B4%E5%9B%BE%E8%BF%9B%E8%A1%8C%E6%B8%B2%E6%9F%93%EF%BC%88rendering-with-ambient-occlusion-maps%EF%BC%89)
    - [【核心要点总结】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [六、实时辉光（Real-Time Glow）](#%E5%85%AD%E3%80%81%E5%AE%9E%E6%97%B6%E8%BE%89%E5%85%89%EF%BC%88real-time-glow%EF%BC%89)
    - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心内容提炼】](#%E3%80%90%E6%A0%B8%E5%BF%83%E5%86%85%E5%AE%B9%E6%8F%90%E7%82%BC%E3%80%91)
    - [【核心要点总结】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E6%80%BB%E7%BB%93%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [下篇 · 次核心内容提炼总结](#%E4%B8%8B%E7%AF%87-%C2%B7-%E6%AC%A1%E6%A0%B8%E5%BF%83%E5%86%85%E5%AE%B9%E6%8F%90%E7%82%BC%E6%80%BB%E7%BB%93)
- [七、水焦散的渲染 （Rendering Water Caustics）](#%E4%B8%83%E3%80%81%E6%B0%B4%E7%84%A6%E6%95%A3%E7%9A%84%E6%B8%B2%E6%9F%93-%EF%BC%88rendering-water-caustics%EF%BC%89)
    - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心要点】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [八、 Dawn Demo中的动画（Animation in the "Dawn" Demo）](#%E5%85%AB%E3%80%81-dawn-demo%E4%B8%AD%E7%9A%84%E5%8A%A8%E7%94%BB%EF%BC%88animation-in-the-dawn-demo%EF%BC%89)
    - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心要点】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [九、 改良的Perlin噪声实现（Implementing Improved Perlin Noise）](#%E4%B9%9D%E3%80%81-%E6%94%B9%E8%89%AF%E7%9A%84perlin%E5%99%AA%E5%A3%B0%E5%AE%9E%E7%8E%B0%EF%BC%88implementing-improved-perlin-noise%EF%BC%89)
    - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心要点】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [十、Vulcan Demo中的火焰渲染（Fire in the "Vulcan" Demo）](#%E5%8D%81%E3%80%81vulcan-demo%E4%B8%AD%E7%9A%84%E7%81%AB%E7%84%B0%E6%B8%B2%E6%9F%93%EF%BC%88fire-in-the-vulcan-demo%EF%BC%89)
    - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心要点】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [十一、衍射的模拟（Simulating Diffraction）](#%E5%8D%81%E4%B8%80%E3%80%81%E8%A1%8D%E5%B0%84%E7%9A%84%E6%A8%A1%E6%8B%9F%EF%BC%88simulating-diffraction%EF%BC%89)
    - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心要点】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [十二、高效的阴影体渲染（Efficient Shadow Volume Rendering）](#%E5%8D%81%E4%BA%8C%E3%80%81%E9%AB%98%E6%95%88%E7%9A%84%E9%98%B4%E5%BD%B1%E4%BD%93%E6%B8%B2%E6%9F%93%EF%BC%88efficient-shadow-volume-rendering%EF%BC%89)
    - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心要点】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [十三、电影级光照（Cinematic Lighting）](#%E5%8D%81%E4%B8%89%E3%80%81%E7%94%B5%E5%BD%B1%E7%BA%A7%E5%85%89%E7%85%A7%EF%BC%88cinematic-lighting%EF%BC%89)
    - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心要点】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [十四、阴影贴图抗锯齿（Shadow Map Antialiasing）](#%E5%8D%81%E5%9B%9B%E3%80%81%E9%98%B4%E5%BD%B1%E8%B4%B4%E5%9B%BE%E6%8A%97%E9%94%AF%E9%BD%BF%EF%BC%88shadow-map-antialiasing%EF%BC%89)
    - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心要点】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [十五、全方位阴影贴图（Omnidirectional Shadow Mapping）](#%E5%8D%81%E4%BA%94%E3%80%81%E5%85%A8%E6%96%B9%E4%BD%8D%E9%98%B4%E5%BD%B1%E8%B4%B4%E5%9B%BE%EF%BC%88omnidirectional-shadow-mapping%EF%BC%89)
    - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心要点】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [十六、使用遮挡区间映射产生模糊的阴影（Generating Soft Shadows Using Occlusion Interval Maps）](#%E5%8D%81%E5%85%AD%E3%80%81%E4%BD%BF%E7%94%A8%E9%81%AE%E6%8C%A1%E5%8C%BA%E9%97%B4%E6%98%A0%E5%B0%84%E4%BA%A7%E7%94%9F%E6%A8%A1%E7%B3%8A%E7%9A%84%E9%98%B4%E5%BD%B1%EF%BC%88generating-soft-shadows-using-occlusion-interval-maps%EF%BC%89)
    - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心要点】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [十七、透视阴影贴图（Perspective Shadow Maps: Care and Feeding）](#%E5%8D%81%E4%B8%83%E3%80%81%E9%80%8F%E8%A7%86%E9%98%B4%E5%BD%B1%E8%B4%B4%E5%9B%BE%EF%BC%88perspective-shadow-maps-care-and-feeding%EF%BC%89)
    - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心要点】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [十八、逐像素光照的可见性管理（Managing Visibility for Per-Pixel Lighting）](#%E5%8D%81%E5%85%AB%E3%80%81%E9%80%90%E5%83%8F%E7%B4%A0%E5%85%89%E7%85%A7%E7%9A%84%E5%8F%AF%E8%A7%81%E6%80%A7%E7%AE%A1%E7%90%86%EF%BC%88managing-visibility-for-per-pixel-lighting%EF%BC%89)
    - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心要点】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [十九、空间BRDF（Spatial BRDFs）](#%E5%8D%81%E4%B9%9D%E3%80%81%E7%A9%BA%E9%97%B4brdf%EF%BC%88spatial-brdfs%EF%BC%89)
    - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心要点】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [二十、基于图像的光照（Image-Based Lighting）](#%E4%BA%8C%E5%8D%81%E3%80%81%E5%9F%BA%E4%BA%8E%E5%9B%BE%E5%83%8F%E7%9A%84%E5%85%89%E7%85%A7%EF%BC%88image-based-lighting%EF%BC%89)
        - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
        - [【核心要点】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [二十一、纹理爆炸（Texture Bombing）](#%E4%BA%8C%E5%8D%81%E4%B8%80%E3%80%81%E7%BA%B9%E7%90%86%E7%88%86%E7%82%B8%EF%BC%88texture-bombing%EF%BC%89)
    - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心要点】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [二十二、颜色控制（Color Controls）](#%E4%BA%8C%E5%8D%81%E4%BA%8C%E3%80%81%E9%A2%9C%E8%89%B2%E6%8E%A7%E5%88%B6%EF%BC%88color-controls%EF%BC%89)
    - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心要点】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [二十三、景深 （Depth of Field）](#%E4%BA%8C%E5%8D%81%E4%B8%89%E3%80%81%E6%99%AF%E6%B7%B1-%EF%BC%88depth-of-field%EF%BC%89)
    - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心要点】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [二十四、高品质的图像滤波（High-Quality Filtering）](#%E4%BA%8C%E5%8D%81%E5%9B%9B%E3%80%81%E9%AB%98%E5%93%81%E8%B4%A8%E7%9A%84%E5%9B%BE%E5%83%8F%E6%BB%A4%E6%B3%A2%EF%BC%88high-quality-filtering%EF%BC%89)
    - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心要点】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [二十五、用纹理贴图进行快速滤波宽度的计算（Fast Filter-Width Estimates with Texture Maps）](#%E4%BA%8C%E5%8D%81%E4%BA%94%E3%80%81%E7%94%A8%E7%BA%B9%E7%90%86%E8%B4%B4%E5%9B%BE%E8%BF%9B%E8%A1%8C%E5%BF%AB%E9%80%9F%E6%BB%A4%E6%B3%A2%E5%AE%BD%E5%BA%A6%E7%9A%84%E8%AE%A1%E7%AE%97%EF%BC%88fast-filter-width-estimates-with-texture-maps%EF%BC%89)
    - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心要点】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [二十六、OpenEXR图像文件格式（The OpenEXR Image File Format）](#%E4%BA%8C%E5%8D%81%E5%85%AD%E3%80%81openexr%E5%9B%BE%E5%83%8F%E6%96%87%E4%BB%B6%E6%A0%BC%E5%BC%8F%EF%BC%88the-openexr-image-file-format%EF%BC%89)
    - [【章节概览】](#%E3%80%90%E7%AB%A0%E8%8A%82%E6%A6%82%E8%A7%88%E3%80%91)
    - [【核心要点】](#%E3%80%90%E6%A0%B8%E5%BF%83%E8%A6%81%E7%82%B9%E3%80%91)
    - [【本章配套源代码汇总表】](#%E3%80%90%E6%9C%AC%E7%AB%A0%E9%85%8D%E5%A5%97%E6%BA%90%E4%BB%A3%E7%A0%81%E6%B1%87%E6%80%BB%E8%A1%A8%E3%80%91)
    - [【关键词提炼】](#%E3%80%90%E5%85%B3%E9%94%AE%E8%AF%8D%E6%8F%90%E7%82%BC%E3%80%91)
- [Reference](#reference)

<!-- /TOC -->



<br>


系列文章前言
============



我们知道，《GPU Gems》1 ~ 3  、 《GPU Pro》1 ~ 7  以及《GPU Zen》组成的GPU精粹系列书籍，共11本书，合称“GPU精粹三部曲“，是游戏开发、计算机图形学和渲染领域的业界顶尖大牛们一线经验的精华荟萃，是江湖各大门派武林绝学经典招式的饕餮盛宴，是了解业界各种高阶知识和技法Trick，将自己的游戏开发、图形学与渲染能力提升到下一个高度的捷径。

本文将总结提炼“GPU精粹三部曲“11本书中的第一本《GPU Gems
1》全书的核心内容，是【GPU精粹与Shader编程】系列文章正篇的第一篇，全文共2万9千余字。

核心内容关键词：

-   真实感水体渲染

-   真实感皮肤渲染

-   无尽草地的渲染

-   次表面散射

-   环境光遮蔽的实现


<br>


目录 · 核心内容Highlight
============================

本文将进行重点提炼总结的主核心内容有：

-   一、用物理模型进行高效的水模拟（Effective Water Simulation from Physical Models）

-   二、Dawn Demo中的皮肤渲染（Skin in the Dawn Demo）

-   三、无尽波动的草地叶片的渲染（Rendering Countless Blades of Waving Grass）

-   四、次表面散射的实时近似（Real-Time Approximations to Subsurface Scattering）

-   五、环境光遮蔽（Ambient Occlusion）

-   六、实时辉光（Real-Time Glow）

<br>

本文将进行提炼总结的次核心内容有：

- 七、水焦散的渲染 （Rendering Water Caustics）

- 八、 Dawn Demo中的动画（Animation in the "Dawn" Demo）

- 九、 改良的Perlin噪声实现（Implementing Improved Perlin Noise）

- 十、Vulcan Demo中的火焰渲染（Fire in the "Vulcan" Demo）

- 十一、衍射的模拟（Simulating Diffraction）

- 十二、高效的阴影体渲染（Efficient Shadow Volume Rendering）

- 十三、电影级光照（Cinematic Lighting）

- 十四、阴影贴图抗锯齿（Shadow Map Antialiasing）

- 十五、全方位阴影映射（Omnidirectional Shadow Mapping）

- 十六、使用遮挡区间映射产生模糊的阴影（Generating Soft Shadows Using Occlusion
Interval Maps）

- 十七、透视阴影贴图（Perspective Shadow Maps: Care and Feeding）

- 十八、逐像素光照的可见性管理（Managing Visibility for Per-Pixel Lighting）

- 十九、空间BRDF（Spatial BRDFs）

- 二十、基于图像的光照（Image-Based Lighting）

- 二十一、纹理爆炸（Texture Bombing）



- 二十二、颜色控制（Color Controls）

- 二十三、景深 （Depth of Field）

- 二十四、高品质的图像滤波（High-Quality Filtering）

- 二十五、用纹理贴图进行快速滤波宽度的计算（Fast Filter-Width Estimates with
Texture Maps）

- 二十六、OpenEXR图像文件格式（The OpenEXR Image File Format）


<br>

《GPU Gems 1》其书
==================

《GPU Gems
1》英文原版出版于2004年4月，中文版《GPU精粹1》出版于2006年1月。需要说明的是，书中很多内容放到今天，并不过时，仍然很有研究、学习、运用、实践的价值。尤其是水体渲染，皮肤渲染，次表面散射、阴影渲染、后处理相关的章节。

![](media/9de8a7fd4e07a2a88ca819c03259db5d.jpg)

图 《GPU Gems 1》封面

![](media/b27d6c11d5181e315ff6570f322709d1.jpg)

图 全书内容概览图

<br>

书本配套资源与源代码下载
========================

这里提供了一些，《GPU Gems 1》书本的配套资源，以及源代码的下载地点。

PS:配套的不少工程中不仅包含完整的源码，也直接包含经过编译后的exe执行文件，可以直接运行后查看效果。

-   原书全文的Web版本：

    <https://developer.nvidia.com/gpugems/GPUGems/gpugems_pref01.html>

-   原书配套源代码、工程与资源下载：

    <http://http.download.nvidia.com/developer/GPU_Gems/CD_Image/Index.html>

![](media/8574159fe5bab00260dffe12665d7503.png)

-   也维护了的一个名为“GPU-Gems-CD-Content”的GitHub仓库，以备份这些珍贵的资源：

    <https://github.com/QianMo/GPU-Gems-CD-Content>

<br>

系列文章风格说明
================

为了让每篇文章的干货更足，内容更加详实，本文与后续文章的的写作风格与文章结构，将在系列文章开篇中的规划的写作风格的基础上，做一些微调。

具体是将每篇需要提炼的章节内容分为两大部分：

-   主核心内容

-   次核心内容

其中，主核心内容，将选取大家最感兴趣、最有提炼价值的渲染相关的内容，会用更加详细的篇幅进行提炼总结。每章主核心内容将包含五个部分：

-   【章节概览】

-   【核心内容提炼】

-   【核心要点总结】

-   【本章配套源代码汇总表】

-   【关键词提炼】

而次核心内容，则会用更加精炼的篇幅进行总结。每部分将包含：

-   【章节概览】

-   【核心要点】

-   【本章配套源代码汇总表】

-   【关键词提炼】

<br>

# 上篇 · 主核心内容提炼总结


<br>


# 一、 用物理模型进行高效的水模拟（Effective Water Simulation from Physical Models）


## 【内容概览】

本章介绍了在GPU中模拟和渲染大型水体的一些方法，并且提出了改进反射的一些有用技巧。

文章由计算简单的正弦函数之和来对水面进行近似模拟开始，逐步扩展到更复杂的函数如Gerstner波，也扩展到像素着色器。主要思路是使用周期波的加和，来创建动态的平铺（tiling）凹凸贴图，从而获得优质的水面细节。

这章也集中解释了水体渲染与模拟系统中常用参数的物理意义，说明了用正弦波之和等方法来近似水面的要点。

![](media/7e696721f9df41a5fb22a9a3615ead03.png)

图 基于文中水体技术渲染的Uru:Ages Beyond Myst中的场景

## 【核心内容提炼】

### 1.1 背景与范围

《GPU Gems
1》出版于2004年，在这几年间，实时渲染技术渐渐从离线渲染领域中分离，自成一派。

而《GPU Gems 1》中收录的这篇文章问世期间时，快速傅里叶变换（Fast Fourier
Transform，FFT）库已经能用于顶点和像素着色器中。同时，运行于GPU上的水体模拟的模型也得到了改进。Isidoro等人在2002年提出了在一个顶点着色器中加和4个正弦波以计算水面的高度和方位的思路。另外，Laeuchi在2002年也发表了一个使用3个Gerstner波计算水面高度的着色器。

![](media/7af5b16f7be7621ffc351e939c0146e8.jpg)

图 基于快速傅里叶变换的水体渲染

### 1.2 水体渲染的思路

文中对水体渲染的思路，运行了两个表面模拟：一个用于表面网格的几何波动，另一个是网格上法线图的扰动。这两个模拟本质上是相同的。而水面高度由简单的周期波叠加表示。

正弦函数叠加后得到了一个连续的函数，这个函数描述了水面上所有点的高度和方向。在处理顶点时，基于每个顶点的水平位置对函数取样，使得网格细分形成连续水面。在几何分辨率之下，将该技术继续应用于纹理空间。通过对近似正弦叠加的法线取样，用简单像素着色器渲染到渲染目标纹理（render
target
texture），从而产生表面的法线图。对每帧渲染法线图，允许有限数量的正弦波组相互独立地运动，这大大提高了渲染的逼真度。

而直接叠加正弦波产生的波浪有太多的“簸荡（roll）”，而真实的波峰比较尖，波谷比较宽。事实证明，正弦函数有一个简单的变体，可以很好地控制这个效果。

#### 1.2.1 波的选择

对于每个波的组成，有如下几个参数需要选择：

-   波长Wavelength (L)：世界空间中波峰到波峰之间的距离。波长L与角频率ω的关系为
    ω=2π/L。

-   振幅Amplitude (A)：从水平面到波峰的高度。

-   速度Speed (S)：每秒种波峰移动的距离。为了方便，把速度表示成相位常数 φ=S x
    2π/L。

-   方向Direction (D)：垂直于波峰沿波前进方向的水平矢量。

波的状态定义为水平位置（x，y）和时间（t）的函数：

![](media/f5774585ef3f0c0e08a869f222368a9f.jpg)

![](media/ba6a16c60a898c10e8032c9b254e35df.jpg)

图 单个波函数的参数

而包括所有的波i的总表面是：

![](media/3d6cedd8ac77a3af1e3331ba8572e470.jpg)

为了提供场景动力学的变量，我们将在约束中随机产生这些波的参数，随着时间的变化，我们会不断将某个波淡出，然后再以一组不同的参数将其淡入。且此过程的这些参数是相关联的，必须仔细地产生一套完整的参数组，才能使各个波以可信的方式进行组合。

#### 1.2.2 法线与切线

因为我们的表面有定义明确的函数，所以可以直接计算任意给定点处的曲面方向，而不是依赖于有限差分技术。

副法线（Binormal）B和正切矢量T分别是x和y方向上的偏导数。
对于2D水平面中的任意点（x，y），表面上的三维位置P为：

![](media/5fba5d484376b24ae6010f48bc4239b4.jpg)

求副法线（Binormal）B方向，即对上式对x方向求偏导。而求正切矢量T方向，即对上式对y方向求偏导。

而法线N由副法线B和切线T的叉积给出：

![](media/9cf67c7c7f52f853a6cc8bd2dd1485f3.jpg)

### 1.3 波的几何特征

首先文中将几何波限制为4个，因为添加更多的波并不能增加新的概念，只不过增加更多相同的顶点Shader处理指令和常数而已。

**1.3.1 方向波或圆形波的选择**

需要对下图所示的方向波或圆形波进行选择。

![](media/51e18c386b312e7a349b5cab460a62b8.jpg)

图 方向波和圆形波

对于两种类型的波，视觉特性和复杂性都是由干涉条纹引起的。

方向波需要的顶点shader处理指令较少，但是究竟选择何种波需要取决于模拟的场景。对于大的水体，方向波往往更好，因为它们是风吹动产生的波较好的模型。对于较小的池塘的水，产生波的原因不是由于风，而是诸如例如瀑布，水中的鱼，圆形波则更好一些。对于方向波，波的方向是在风向的一定范围内任意绘制的；对于圆形波，波中心是在某些限定的范围内任意绘制的。

####  1.3.2 Gerstner波

正弦波看起来圆滑，用于渲染平静的，田园诗般的池塘很合适。而对于粗犷的海洋，需要形成较尖的浪头和较宽的浪槽，则可以选择Gerstner波。

Gerstner波早在计算机图形学出现之前就已经被研发了出来，用于物理学基础上为海水建模。Gerstner波可以提供一些表面的微妙运动，虽然不是很明显但是却很可信（具体可以见[Tessendorf
2001]）。

另外，Gerstner波有一种经常被忽略的性质：它将顶点朝着每个浪头顶部移动，从而形成更尖锐的波峰。因为波峰是我们水表面上最锐利的（即最高频率，最主要）特征，所以我们正希望顶点可以集中在此处。

![](media/5fd87dcf4ab8ad55149c9c96ef2187c4.png)

图 Gerstner波

![](media/c19f69f6f4616a11cea94162b17b6428.png)

图 基于Gerstner渲染出的水面 @Unreal Engine 4

####  1.3.3 波长等参数的选择

波长等参数的选择方法：

-   波长的选择，要点是不要追求波在真实世界中的分布，而是要使用现在的少数几个波达到最大效果。对波长相似的波进行叠加可以突显水面的活力。于是文中选择中等的波长，然后从它的1/2至两倍之间产生任意波长。

-   波的速度，通过波长，基于公式即可计算得出。

-   振幅方面，主要是在Shader中指定一个系数，由美术同学对波长指定对应的合适振幅。

-   波的方向，运动方向与其他参数完全独立，因此可以自由选择。

### 1.4 波的纹理特征

加和到纹理中的波也像上文说到的顶点一样需要参数化，但是其具有不同的约束条件。首先，在纹理中得到宽频谱更为重要。其次，在纹理中更容易形成不像天然波纹的图案。第三，对给定波长只有某些波方向能保证全部纹理的平铺（tiling）。也就是说，不像在世界空间中仅仅需要注意距离，在纹素（texel）中要注意所有的量。

文中的思路是在2到4个通道中，使用15个频率和方位不同的波进行处理。虽然4个通道听起来有点多，但是它们是进行256
x
256分辨率的渲染目标纹理的处理，而不是处理主帧的帧缓冲。实际上，生成法线贴图的填充率所造成的影响小到可以忽略不计。

### 1.5 关于深度

首先，把在顶点上的水深度作为一个输入参数，这样，在着色器碰到岸边这样的微妙区域时，便可以自动进行校正。

因为水的高度需要计算，所以顶点位置的z分量就没什么用了。虽然我们可以利用这点来压缩顶点的数据量，但是选择把水深度编码在z分量中，是一个更好的选择。

更确切地说，就是把水体底部的高度放在顶点的z分量中，作为常数带入水的高度表中，这样通过相减，即可得到水深度。而同样，这里假定了一个恒定高度的水位表（constant-height
water table）。

我们也使用水深度来控制水的不透明度、反射强度和几何波振幅。简单来说，即水浅的地方颜色浅，水深的地方颜色深。有了适当的水深度，也就可以去光的传播效果进行更完善的建模。

![](media/c4a6025c3644aae9a210213a61285a46.jpg)

图 真实感水体渲染效果图 @Unreal Engine 4

## 【核心要点总结】

文中提出的水体渲染方法，总结起来有三个要点：

1）使用周期波（正弦波、Gerstner波）的加和

2）创建动态的平铺（tiling）贴图

3）使用凹凸环境映射（Bump-Environment Mapping）

【本章配套源代码汇总表】

文中并没有贴图相关代码，但原书配套CD提供了完整的源代码和项目工程，具体代码和工程可以查看：

[https://github.com/QianMo/GPU-Gems-Book-Source-Code/tree/master/GPU-Gems-1-CD-Content/Natural_Effects/Water_Simulation](https://github.com/QianMo/GPU-Gems-Book-Source-Code/tree/master/GPU-Gems-1-CD-Content/Natural_Effects/Water_Simulation)

## 【关键词提炼】

水的模拟（Water Simulation）

水的渲染（Water Rendering）

正弦函数近似加和（Sum of Sines Approximation）

Gerstner波（Gerstner Waves）

凹凸环境映射（Bump Environment Mapping）

<br>

# 二、Dawn Demo中的皮肤渲染（Skin in the Dawn Demo）


## 十年技术变迁： NVIDIA Dawn Demo

最初的Dawn Demo由NVIDIA于2002年发布，而十年之后的2012年，NVIDIA新发布了“A New
Dawn”技术Demo。

![](media/187a016a73bc8bb10203d34505003b28.jpg)

图 A New Dawn Demo截图

以下是一张新老Demo的对比效果图。

![](media/4c2fc0ba6e630f18004cebf547673c7a.png)

图 Dawn Demo (2002年)

![](media/e044961968eafb19ba340601fb2d3517.png)

图 A New Dawn Demo （2012年）

![](media/8b704341952a0056d06fe24f02912bef.png)

图 技术指标的对比

## 【章节概览】

这章详细介绍了NVIDIA出品的Dawn
Dmoe中对精灵人物的着色技术，主要是皮肤的着色技巧。在当时（2002年）NVIDIA创造的此demo的品质，已经成为照片级真实感渲染和实时渲染的代表。

![](media/fae010bffc77e62249f659f81ee37f09.png)

图 Dawn Demo截图



## 【核心内容提炼】

### 2.1 关于皮肤着色

基于多种原因，在计算机图形中模拟皮肤十分困难。在当时，即使是在电影中用高端产品模拟出来的仿真角色，通常也经不起近距离的观察。因为，人类可以从中获得大量非语言来表达的信息，如重心的移动，走动的特别习惯，面部的表情，甚至有些人的皮肤泛红等等。

虽然很少有人能理解像“次表面散射（Subsurface Scattering）”、“轮廓照明（Rim
Lighting）”这些词汇，但是当把它们渲染错了的时候，几乎任何人都可以指出来。而且除了着色问题外，有时人们会因为皮肤渲染的问题，说皮肤看起来像是塑料做的。

### 2.2 皮肤如何对光进行响应

皮肤不像大多数在计算机渲染中建模的表面，因为它是由半透明的表皮、真皮和皮下组织等数层构成的。这可以用次表面散射来模拟。这种现象很普遍，当在太阳面前向上举起手，就能看到穿过皮肤的桔红色的光。

![](media/39b069b84b7fe7a3ffd26d7b73a8be61.jpg)

  
图 次表面散射-穿过皮肤的桔红色的光

皮肤下的散射在所有的角度上显现皮肤形态，使它具有了柔软的、与众不同的特征。

在这之前有一些小组尝试使用多层纹理贴图来模仿皮肤的复杂性，但一般而言，这个方法比较难管理，美术同学很难通过预想，混合出最终符合预期的效果。

相反，文中使用单张彩色贴图，通过着色程序来增加色彩的变化。

![](media/8e17437ac71fbaac295f9a4f604f1dec.jpg)

图 Dawn头部的前半边的漫反射贴图

另外，皮肤具有一些极细微的变化，会影响其反射特性。这对皮肤外观有微妙的影响，特别是当光线直接与相机位置相反时，皮肤的表现则是存在边缘（Edge）与轮廓光照（Rim
Lighting）,这时，需要皮肤轮廓边缘的光照，或给皮肤边缘加上光晕。

真正的皮肤具有一些细微的特征，比如汗毛和毛孔能捕捉光线。尽管这些细节用于显式地建模是太不明显了，但我们还是希望得到一个合适、整体更逼真的皮肤渲染外观。在特写时，可以增加凹凸贴图，提供一些额外的细节，特别是一些小的皱纹。但需要注意，我们想要的是柔软的皮肤外观，而不是光闪闪的油腻的塑料。另外，凹凸贴图通常只需静距离特写时才可见。

我们可以通过建模来近似这两个着色属性，建模可以是基于表面法线的简单公式，或者是基于光线或视线矢量的简单公式。

通过认识，我们可以将上述两种渲染特性（次表面散射和边缘光照），建模为基于表面法线和照明或观察向量的简单公式，从而近似出两种着色属性。尤其是沿着Dawn的轮廓边缘，对她身后的光线取样，按照观察向量的索引，让“穿过”Dawn的光与她的基础皮肤色调混合，从而创建次表面散射和边缘光照的着色效果。尤其是背景图中更加明亮的区域。如下图。

![](media/01e8c07606f9017e75365b317f9f038b.jpg)

图 Dawn的头部前面的切线空间法线贴图（凹凸贴图）

### 2.3 场景的照明

Dawn Demo中场景的照明使用了基于图像的光照（Image Based Lighting ,
IBL），创建高动态范围(High-Dynamic
Range，HDR）)的全景，使用环境映射贴图（Environment Maps）进行场景的照明。

![](media/345e2eb8035e2fe059f78aa4a9301955.png)

图 立方体环境反射贴图

漫反射环境贴图（Diffuse Environment
Map）也是一个立方体映射贴图，它使用网格表面的法线作为索引。每个像素存储了相应法线与入射光夹角的余弦加权平均值。

![](media/1870f6f26f6b03d7a51282c3397bc90e.png)

图 漫反射环境贴图（Diffuse Environment Map）

镜面高光环境贴图（specular environment
map）同样也是一个立方体映射贴图，使用反射矢量作为索引（类似于立方体映射）。把此镜面高光环境贴图基于粗糙因子进行模糊，目的是模拟对任何表面任何给定点上的法线的改变。

![](media/3f4d1c5e7cce0f92f219857129034a88.png)

图 镜面高光环境贴图（Specular Environment Map）

存在的问题是，漫反射环境贴图（Diffuse Environment
Map）和镜面高光环境贴图（Specular Environment
Map）考虑了来自环境的入射光，但不包含由物体引起的阴影。

要解决这个问题，可以生成一个遮挡项，用来近似表达在每个顶点上半球辐射光中，有多大比率场景中其他物体所遮挡。


### 2.4 实现

Dawn
Demo中，毫无悬念地使用顶点着色器和像素着色器进行光照处理，顶点shader的主要功能是将坐标转换到投影空间，并执行那些不能在像素着色器中执行的数学运算。

采用单通道（one-pass）的光照解决方案，不需要另外其他的通道渲染，或alpha混合来创建皮肤表面。

文中提供了完整的顶点Shader和像素Shader的源代码，这里因为篇幅原因不再赘述，具体可以参考原文（PS:上文有贴出Web版的英文全书原文的链接）。

## 【核心要点总结】

文中采用的皮肤渲染方法，总结起来有三个要点：

1）基于图像的光照（Image Based Lighting
,IBL），采用高动态范围（High-Dynamic-Range , HDR）光照环境映射贴图

2）次表面散射（Subsurface Scattering）

3）对皮肤边缘加上光晕，即轮廓照明/边缘光照（Rim Lighting）

## 【本章配套源代码汇总表】

Example 3-1. 从CPU应用程序接收的每个顶点数据示例代码（The Per-Vertex Data
Received from the CPU Application）

Example 3-2. 输出顶点的数据结构示例代码（The Data Structure of the Output
Vertices）

Example 3-3. Dawn脸部的皮肤渲染顶点着色器示例代码（A Sample Vertex Shader for
Dawn's Face）

Example 3-4. Dawn脸部的皮肤渲染片元着色器代码（The Fragment Shader for Dawn's
Face）

## 【关键词提炼】

皮肤渲染（Skin Rendering）

次表面散射（Subsurface Scattering）

轮廓照明（Rim Lighting）

基于图像的光照（Image Based Lighting ,IBL）

高动态范围（High-Dynamic-Range, HDR）

环境映射贴图（Environment Maps）


<br>

# 三、无尽波动的草地叶片的渲染（Rendering Countless Blades of Waving Grass）


<br>

## 【章节概览】

这章关于巨量自然元素的渲染，特别是对于无尽波动的草地叶片的渲染。作者对Codecreatures
demo中首次成形的技术进行了扩展，使其能够高性能的渲染，以更好地适应游戏引擎的需要。

![](media/000e7d0e677c5cc7aaa92cbfc28e7b44.jpg)

图 Realistic Grass Field @Giovanni Baer

## 【核心内容提炼】

### 3.1 概述

首先，需要意识到，对单个草叶的细节建模意义不大，因为那样大片草地需要的多边形数目会太多。

所以，我们必须建立一个符合以下条件的简单而有用的替代方案：

-   许多草的叶片必须由少数多边形表示。

-   草地必须从不同的视线看起来显得密集。

而要做到让场景不依赖于摄像机的位置和方向，可以把一些草叶组合起来，表示在一个纹理中，并将多个纹理组合起来，且在结果中单个的多边形不应该引起注意。当观察者四处活动时，通过将草体加入混合操作或者移除混合操作，以在距离范围内增加或删去草体，来保证整个草地的渲染效果具有稳定的视觉质量。

### 3.2 草的纹理

草的纹理，应该是一些一簇一簇聚集丛生的草，否则，会出现大片的透明区域。

需在透明的alpha通道上画实体草茎。在彩色通道中，用深浅不同的绿色和黄色，来较好地区别各个单独的叶片，也应该模拟不同情况的草叶：长得好的和长得差的、老的和嫩的，甚至区别叶片的前面与后面。

下图是一个草地纹理的示例。

![fig07-02.jpg](media/75eb9a7c7b47bfd883f3d2c15f1b1166.png)

图 草地纹理的示意图

### 3.3 草体

这一部分将探讨总结如何对多边形进行组合，并用上文提到的草地纹理进行映射，以模拟出茂密的草地，并且不凸显个别多边形。此技术也保证了单个多边形不可见。

因为用户能自由地在场景中游玩，下图所示的结构便不能产生令人信服的效果。

![fig07-03.jpg](media/2e621ba9c08c3c8d560175f594ab5cd8.jpg)

图 线性排布

对于线性排布，如果从垂直于多边形的方向观看场景，就会立刻穿帮，看出草地多边形的结构是线性排布的。另外这种情况下草地会看起来非常稀疏。只有在摄像机自动导航，或者渲染无法到达的远距离草地时，才会考虑这样的排布。

为了保证独立于当前视线的良好视觉质量，我们必须交叉地排布草地多边形。已证明，使用星型结构是非常好的。下图给出了“草体”可能的两种变体。

他们由3个相交的方块构成。我们必须禁用背面剔除来渲染多边形，以保证双面都可见。为了得到合适的照明度，应该让所有顶点的法线方向与多边形的垂直边平行。这保证了位于斜坡上的所有草体都可以得到正确的光照，不会因为地形的亮度而出现差异。

![fig07-04.jpg](media/0e5096bbb70198af88449e17482a45d6.jpg)

图 草体的交叉排布

如果把这些草地物体彼此相当靠近地设置在一个大的区域里，如下图。在运行期间把它们从后向前进行排序，使用alpha混合，并启用Draw
Call中的z-testing/writing，那么就会得到自然而茂密的草地渲染效果。

![fig07-05.jpg](media/a6c9d7add4706057988add72188400ab.jpg)

图 草地的扩展

### 3.4 草地动画

关于草地的动画，基本思想是以三角函数（尤其是正弦和余弦）为基础进行计算，且计算应该考虑到移动的位置和当前时间、风向和强度。

以基本思想为基础，实现起来有几种方法：

1、每草丛草体的动画（Animation per Cluster of Grass Objects）

2、每顶点的动画（Animation per Vertex）

3、每草体的动画（Animation per Grass Object）

三种方法各有优缺点，而文中都给出了具体算法步骤和实现的Shader源码，这里因为篇幅原因，便不展开分析了。

最终可以实现的渲染效果。

![](media/fb643b85c492b73c4ee4b7994a77ae9e.jpg)

图 Realistic Grass


## 【核心要点总结】

1）草的纹理，应选取一簇一簇聚集丛生的草。在透明的alpha通道上画实体草茎。在彩色通道中，用深浅不同的绿色和黄色，区别各个单独的叶片。

2）草体的渲染，适合进行交叉排布，从后向前进行排序，使用alpha混合，并启用Draw
Call中的z-testing/writing，便能得到自然而茂密的草地渲染效果。

3）草地的动画，以三角函数（尤其是正弦和余弦）为基础，且应该考虑到移动的位置和当前时间、风向和强度。实现起来有三种方法：

>   1、每草丛草体的动画（Animation per Cluster of Grass Objects）

>   2、每顶点的动画（Animation per Vertex）

>   3、每草体的动画（Animation per Grass Object）

## 【本章配套源代码汇总表】

Example 7-1. 顶点着色器框架（Framework in the Vertex Shader）

Example 7-2. 对每草丛草体的动画的实现Shader代码（Code for Animation per Cluster
of Grass Objects）

Example 7-3. 每顶点动画实现Shader代码（Code for Animation per Vertex）

Example 7-4. 每草体的动画实现Shader代码（Code for Animation per Grass Object）

## 【关键词提炼】

草地渲染（Grass Rendering）

草地动画（Grass Animation）

草体（Grass Objects）

<br>


# 四、次表面散射的实时近似（Real-Time Approximations to Subsurface Scattering）


## 【章节概览】

次表面散射（Subsurface Scattering），简称SSS，或3S，是光射入非金属材质后在内部发生散射，最后射出物体并进入视野中产生的现象，即光从表面进入物体经过内部散射，然后又通过物体表面的其他顶点出射的光线传递过程。

![](media/99b219a60f13be87fb1d5c3a5f5c2640.jpg)

图 次表面散射原理图示

![](media/5a62505ea6f9a07ed45da02a56293531.jpg)

图 真实环境中的次表面散射

要产生使人信服的皮肤和其他半透明材质的渲染效果，次表面散射（Subsurface Scattering）的渲染效果十分重要。

![](media/1a4894b4e922183b08800bf9c0bba975.jpg)

图 有无次表面散射的渲染对比图（左图：使用次表面散射 \| 右图：无次表面散射）

另外需要提出，在《神秘海域4》中皮肤的渲染效果，很令人惊艳。当然，《神秘海域4》中令人惊艳的，远远不止皮肤的渲染。

![](media/62306aa5c58927d62f1c41d7602dabe7.jpg)

图 基于次表面散射的皮肤渲染 @《神秘海域4》

本章即描述了次表面散射的几种实时近似方法，关于皮肤的渲染，也关于近似地去模拟透明材质的几种不同方法。

## 【核心内容提炼】

### 4.1 次表面散射的视觉特性（The Visual Effects of Subsurface Scattering）

要重现出任何视觉效果，经常的做法是考察这种效果的图像，并把可视的外观分解为其组成要素。在观察半透明物体的相片和图像时，能注意到如下几点，即次表面散射（Subsurface
Scattering）的视觉特性：

1、首先，次表面散射往往使照明的整体效果变得柔和。

2、一个区域的光线往往渗透到表面的周围区域，而小的表面细节变得看不清了。

3、光线传入物体越深，就衰减和散射得越严重。

4、对于皮肤来说，在照亮区到阴影区的衔接处，散射往往会引起微弱的倾向于红色的颜色偏移。这是由于光线照亮表皮并进入皮肤，接着被皮下血管和组织散射和吸收，然后从阴影部分离开。且散射在皮肤薄的部位更加明显，比如鼻孔和耳朵周围。

![](media/1c3686db3992f649486186984097ab07.jpg)

图 次表面散射原理图示

### 4.2 简单的散射近似（Simple Scattering Approximations）

近似散射的比较简单技巧是环绕照明（Wrap
Lighting）。正常情况下，当表面的法线对于光源方向垂直的时候，Lambert漫反射提供的照明度是0。而环绕光照修改漫反射函数，使得光照环绕在物体的周围，越过那些正常时会变黑变暗的点。这减少了漫反射光照明的对比度，从而减少了环境光和所要求的填充光的量。环绕光照是对Oren-Nayar光照模型的一个粗糙的近似。原模型力图更精确地模拟粗糙的不光滑表面（Nayar
and Oren 1995）。

下图和代码片段显示了如何将漫反射光照函数进行改造，使其包含环绕效果。

其中，wrap变量为环绕值，是一个范围为0到1之间的浮点数，用于控制光照环绕物体周围距离。

![](media/5b090360792e221b034be0c913e5520c.jpg)

图 环绕光照函数的图表

    float diffuse = max(0, dot(L, N));

    float wrap_diffuse = max(0, (dot(L, N) + wrap) / (1 + wrap));

为了在片元函数程序中的计算可以更加高效，上述函数可以直接编码到纹理中，用光线矢量和法线的点积为索引。

而在照明度接近0时，可以显示出那种倾向于红的微小颜色漂移，这是模拟皮肤散射的一种廉价方法。而这种偏向于红色的微小颜色漂移，也可以直接加入到此纹理中。

另外也可以在此纹理的alpha通道中加入镜面反射高光光照的功率（power）函数。可以在示例代码Example
16-1中的FX代码展示了如何使用这种技术。对比的图示如下。

![](media/8e182c0fd90d8b0be6d988bc0b7eea25.png)

图 （a）没有环绕光照的球体 （b）有环绕光照明的球体 （c）有环绕光照明和颜色漂移的球体

Example 16-1 摘录纳入了环绕照明的皮肤Shader效果的代码（Excerpt from the Skin
Shader Effect Incorporating Wrap Lighting）


	// 为皮肤着色生成2D查找表（Generate 2D lookup table for skin shading）
    
    float4 GenerateSkinLUT(float2 P : POSITION) : COLOR

    {

	    float wrap = 0.2;
	
	    float scatterWidth = 0.3;
	
	    float4 scatterColor = float4(0.15, 0.0, 0.0, 1.0);
	
	    float shininess = 40.0;
	
	    float NdotL = P.x * 2 - 1; // remap from [0, 1] to [-1, 1]
	
	    float NdotH = P.y * 2 - 1;
	
	    float NdotL_wrap = (NdotL + wrap) / (1 + wrap); // wrap lighting
	
	    float diffuse = max(NdotL_wrap, 0.0);
	
	    // 在从明到暗的转换中添加颜色色调（add color tint at transition from light to
		dark）
	
	    float scatter = smoothstep(0.0, scatterWidth, NdotL_wrap) *
	
	    smoothstep(scatterWidth * 2.0, scatterWidth,
	
	         NdotL_wrap);
	
	    float specular = pow(NdotH, shininess);
	
	    if (NdotL_wrap <= 0) specular = 0;
	
	    float4 C;
	
	    C.rgb = diffuse + scatter * scatterColor;
	
	    C.a = specular;
	
	    return C;
	
	}

	// 使用查找表着色皮肤（Shade skin using lookup table）
	
	half3 ShadeSkin(sampler2D skinLUT,
		
		half3 N,
		
		half3 L,
		
		half3 H,
		
		half3 diffuseColor,
		
		half3 specularColor) : COLOR
	
	{
		
		half2 s;
		
		s.x = dot(N, L);
		
		s.y = dot(N, H);
		
		half4 light = tex2D(skinLUT, s * 0.5 + 0.5);
		
		return diffuseColor * light.rgb + specularColor * light.a;
	
	}

### 4.3 使用深度贴图模拟吸收（Simulating Absorption Using Depth Maps）

吸收（Absorption）是模拟半透明材质的最重要特性之一。光线在物质中传播得越远，它被散射和吸收得就越厉害。为了模拟这种效果，我们需要测量光在物质中传播的距离。而估算这个距离可以使用深度贴图（Depth
Maps）技术[Hery 2002]，此技术非常类似于阴影贴图(Shadow
Mapping)，而且可用于实时渲染。

![](media/047d2bbfa6ee469f8aeaf51e2fc8d8e7.jpg)

图 使用深度贴图计算光在物体中的传播的距离

深度贴图（Depth Maps）技术的思路是：

在第一个通道（first
pass）中，我们从光源的视点处渲染场景，存储从光源到某个纹理的距离。然后使用标准的投射纹理贴图（standard
projective texture mapping），将该图像投射回场景。在渲染通道（rendering
pass）中，给定一个需要着色的点，我们可以查询这个纹理，来获得从光线进入表面的点（d_i）到光源间距离，通过从光线到光线离开表面的距离（d_o）里减去这个值，我们便可以获得光线转过物体内部距离长度的一个估计值（S）。如上图。

原文中详细分析了此方法的实现过程，也附带了完整的Shader源码，具体细节可以查看原文，这里因为篇幅原因就不展开了。

![](media/993d2fe5db403d1fda14bc6b34de7707.png)

图 使用深度贴图去近似散射，物体上薄的部位传输更多的光

也有一些更高端的模型试图更精确地模拟介质内散射的累积效应。

一种模型是单次散射近似（Single Scattering
Approximation），其假设光在材质中只反弹一次，沿着材质内的折射光线，可以计算有多少光子会朝向摄像机散射。当光击中一个粒子的时候，光散射方向的分布用相位函数来描述。而考虑入射点和出射点的菲涅尔效应也很重要。

另一种模型，是近似漫反射（Diffusion
Approximation），其用来模拟高散射介质（如皮肤）的多次散射效果。

### 4.4 纹理空间的漫反射（Texture-Space Diffusion）

次表面散射最明显的视觉特征之一是模糊的光照效果。其实，3D美术时常在屏幕空间中效仿这个现象，通过在Photoshop中执行Gaussian模糊，然后把模糊图像少量地覆盖在原始图像上，这种“辉光”技术使光照变得柔和。

而在纹理空间中模拟漫反射[Borshukov and Lewis
2003]，即纹理空间漫反射（Texture-Space
Diffusion）是可能的，我们可以用顶点程序展开物体的网格，程序使用纹理坐标UV作为顶点的屏幕位置。程序简单地把[0，1]范围的纹理坐标重映射为[-1，1]的规范化的坐标。

另外，为了模拟吸收和散射与波长的相关的事实，可以对每个彩色通道分为地改变滤波权重。

![](media/76bbfaf81bb4cb06992cbcf3c6e9e8b8.png)

图 （a）原始模型 （b）应用了纹理空间漫反射照明的模型，光照变得柔和

![](media/d55a3dfa3021ee2bd2b55226425336d8.jpg)

图 基于纹理空间漫反射照明的效果

同样，原文中详细分析了此方法的实现过程，也附带了完整的Shader源码，具体细节可以查看原文，这里因为篇幅原因就不展开了。

再附几张基于次表面散射的皮肤渲染效果图，结束这一节。

![](media/833078cc9e0f84f92200760ece973265.jpg)

图 基于次表面散射的皮肤渲染

![](media/788fa8515f8f75e2e7ebc3895c6ef222.png)

图 基于次表面散射的皮肤渲染 @Unreal Engine 4

![](media/d80656c686f1468e8f8c756d739eaada.jpg)

图 基于次表面散射的皮肤渲染 @《神秘海域4》

![](media/b4bd512d5067f2981cdff2f780efd503.jpg)

图 基于次表面散射的皮肤渲染 @《神秘海域4》



## 【核心要点总结】

文中提出的次表面散射的实时近似方法，总结起来有三个要点：

1） 基于环绕照明（Wrap Lighting）的简单散射近似，Oren-Nayar光照模型。

2） 使用深度贴图来模拟半透明材质的最重要特性之一——吸收（Absorption）。

3）基于纹理空间中的漫反射模拟（Texture-Space
Diffusion），来模拟次表面散射最明显的视觉特征之一——模糊的光照效果。



## 【本章配套源代码汇总表】

Example 16-1 摘录纳入了环绕照明的皮肤Shader效果的代码（Excerpt from the Skin
Shader Effect Incorporating Wrap Lighting）

Example 16-2 深度Pass的顶点Shader代码（The Vertex Program for the Depth Pass）

Example 16-3　深度Pass的片元Shader代码（The Fragment Program for the Depth
Pass）

Example 16-4　使用深度贴图来计算穿透深度的片元Shader代码（The Fragment Program
Function for Calculating Penetration Depth Using Depth Map）

Example 16-5　用于展开模型和执行漫反射光照的顶点Shader代码（A Vertex Program to
Unwrap a Model and Perform Diffuse Lighting）

Example 16-6 用于漫反射模糊的顶点Shader代码（The Vertex Program for Diffusion
Blur）

Example 16-7 用于漫反射模糊的片元Shader代码（The Fragment Program for Diffusion
Blur）

## 【关键词提炼】

皮肤渲染（Skin Rendering）

次表面散射（Subsurface Scattering）

纹理空间漫反射（Texture-Space Diffusion）

环绕照明（Wrap Lighting）

深度映射（Depth Maps）


# 五、环境光遮蔽（Ambient Occlusion）


## 【章节概览】

在某种意义上，这篇文章属于环境光遮蔽的启蒙式文章。

环境光遮蔽（Ambient
Occlusion），简称AO，是一种用于计算场景中每个点对环境光照的曝光程度的一种着色渲染技术。

本章讲到了如何使用有效的实时环境光遮蔽技术，对物体遮蔽信息及环境进行预处理，综合这些因素给物体创建逼真的光照和阴影。

![](media/40edd773a01ff958638b09b69399c75d.png)

图 有无环境光遮蔽的对比

![](media/55b2c13bbaece3723db27b76cc5d793e.png)

图 有无环境光遮蔽的对比

## 【核心内容提炼】

5.1 概述

首先，本文中讲到，环境光遮蔽（Ambient Occlusion）一般而言有两种理解：

1）将环境光遮蔽视为“智能”的环境光项，其在模型表面的变化取决于在每点可见多少外部环境。

2）将环境光遮蔽视为一个漫反射项，其能有效地支持复杂分布的入射光线。

文中将考虑上述的第二种解释。

其基本思路是，假如预处理一个模型，计算它上面每个点可以看到多少外部环境，可以相反地计算有多少环境被模型的其他部分遮挡，然后在渲染时使用这个信息计算漫反射着色项的值。其结果是模型上的裂缝变暗，而模型的暴露部分会接收更多的光线，因此更明亮。这种效果实质上比使用标准的着色模型更逼真。

另外，这个方法可以扩展为使用环境光作为照明源，用代表各个方向入射光的环境贴图没来决定物体上每个点光的颜色。为了这个特性，除了记录在点上可以看到多少外部环境之外，也记录大部分可以光从哪个方向到达。这两个量有效地定义了从外面进入场景的未被遮挡的方向圆锥体，可以一起用来做为来自环境贴图的极端模糊的查询，模拟着色点上来自感兴趣的方向圆锥体的全部入射照度。

5.2 预处理步骤（The Preprocessing Step）

给定一个任意的着色模型，环境光遮蔽算法需要知道模型上每点的两个信息：

（1）该点的“可到达度（accessibility）”-
即该点上方半球的哪一部分未被模型的其他部分遮挡;

（2）未被遮挡的入射光的平均方向。

通过下图在平面上说明这两个概念。给定在表面上的点P，其法线为N，
P点上半球的2/3被场景中其他几何体遮挡，半球另外的1/3不被遮挡。入射光的平均方向用B表示，其在法线N的右侧。大致来说，在P点的入射光的平均颜色，可以通过求围绕B矢量的未遮挡入射光的圆锥体的平均值得到。

![](media/a2d2867bc9c4d8ef88ab6fa4d2b8edec.jpg)

图 可到达度和平均方向的计算

下面贴出的伪代码显示了我们的基本方法。在每个三角形的中心，我们产生一组以表面法线为中心的半球形光线，跟踪每道光线进入场景，记录哪些光线与模型相交，标志不能从环境接收的光线，以及不被遮挡的光线。接着我们计算不被遮挡的光线的平均方向，这给出了入射光平均方向的近似值。（当然，我们计算的方向实际上可能会被遮挡，但我们选择忽略不计这个问题。）

Example 17-1 计算环境光遮蔽量的基本算法伪代码 （Basic Algorithm for Computing
Ambient Occlusion Quantities）

	For each triangle {
	
		Compute center of triangle
		
		Generate set of rays over the hemisphere there
		
		Vector avgUnoccluded = Vector(0, 0, 0);
		
		int numUnoccluded = 0;
		
		For each ray {
		
			If (ray doesn't intersect anything) {
			
				avgUnoccluded += ray.direction;
				
				++numUnoccluded;
			
			}
	
		}
	
		avgUnoccluded = normalize(avgUnoccluded);
		
		accessibility = numUnoccluded / numRays;
	
	}

生成这些光线的简单方法是使用拒绝采样法（rejection
sampling）：检测在x，y和z为-1到1区间的3D立方体中随机生成的光线，并拒绝不在单位半球中与法线相关的光线。

能通过这次检测的光线方向可视分布理想的光线方向。列表17-2的伪代码表示出了此方法的实现思路。

当然，也可以用更复杂的蒙特卡洛（Monte Carlo）采样法来得到更好的样本方向的分布。

Example 17-2 使用拒绝采样法计算随机方向的算法伪代码（Algorithm for Computing
Random Directions with Rejection Sampling）

	while (true) {
	
		x = RandomFloat(-1, 1); // random float between -1 and 1
		
		y = RandomFloat(-1, 1);
		
		z = RandomFloat(-1, 1);
		
		if (x * x + y * y + z * z > 1) continue; // ignore ones outside unit
		
		// sphere
		
		if (dot(Vector(x, y, z), N) < 0) continue; // ignore "down" dirs
		
		return normalize(Vector(x, y, z)); // success!
	
	}

另外，用图形硬件代替光线追踪软件，有可能加速遮挡信息的计算。

### 5.3 使用环境光遮蔽贴图进行渲染（Rendering with Ambient Occlusion Maps）

使用环境光遮蔽贴图进行着色的基本思想是：
可以直接在着色点处使用之前已计算好的，有多少光线能到达表面的，优质的近似值信息。

影响这个数值的两个因素是：

（1）在此点上方半球的哪个部分不被点和环境贴图之间的几何体遮挡。

（2）沿着这些方向的入射光是什么。

下图显示了两种不同的情况。在左图中，只能看到着色点上面的一小部分分享，由方向矢量B和围绕它的方向圆锥体所表示，该点的可到达度非常低。而在右图中，沿着更大范围的方向有更多的光线到达给定点。

![](media/5c503c8789a7c83da26fcf30a9274004.jpg)

图 不同量的可见度的近似（左图：由于附近的几何体的遮挡比较严重，这点得到的照度较小；右图：沿着更宽方向的圆锥体，更大量的光能到达这点，照度较左图更大）

在预处理中计算的可访问性值告诉我们哪一部分半球可以看到环境贴图，而可见方向的平均值给出一个近似方向，围绕它计算入射光。虽然这个方向可能指向一个实际被遮挡的方向（例如，如果半球的两个独立区域未被遮挡，但其余的部分被遮挡，平均方向可能在这两者之间），但在实践中其通常运行良好。

![](media/04726bc725a4925858ee0ec280f7796f.jpg)

图 使用可到达度信息和环境贴图渲染的光照场景

![](media/1abca2e51d8271166f3dfb2d038028df.jpg)

图 基于此项技术渲染出的对比图

另外需要注意，实时环境光遮蔽的常用廉价方案是预先计算网格表面几个位置的平均可见性值，存储于贴图中，然后将这些值在运行时与图形硬件提供的未遮挡光照相乘。

## 【核心要点总结】

给定一个任意的着色模型，环境光遮蔽算法需要知道模型上每点的两个信息：

1）该点的可到达度（accessibility）。

2）未被遮挡的入射光的平均方向。

文中提出的环境光遮蔽方法，总结起来有三个要点：

-   采用了多种在实践中运行良好的近似方法。

-   主要为预处理操作，将相对昂贵的计算事先准备好，且仅计算在渲染时进行快速着色所需的正确信息。

-   预处理不依赖于光照环境贴图，因此可以轻松使用场景中的动态照明。

## 【本章配套源代码汇总表】

Example 17-1 计算环境光遮蔽量的基本算法伪代码（Basic Algorithm for Computing
Ambient Occlusion Quantities）

Example 17-2 使用拒绝采样法计算随机方向的算法伪代码（Algorithm for Computing
Random Directions with Rejection Sampling）

Example 17-3 使用可到达度和环境映射进行着色的片元Shader（Fragment Shader for
Shading with Accessibility Values and an Environment Map）

Example 17-4 latlong( )函数的定义（The latlong() Function Definition）

Example 17-5 computeBlur( )函数的定义（The computeBlur() Function Definition）

## 【关键词提炼】

环境光遮蔽（Ambient Occlusion）

拒绝采样（Rejection Sampling）

环境光遮蔽贴图（Ambient Occlusion Maps）


# 六、实时辉光（Real-Time Glow）


## 【章节概览】

这章讲到2D光照效果中的辉光（Glow）和光晕（Halo），展示了如何通过图像处理方法完全地改善画面及3D人物的渲染感官。

![](media/0c80fe2d09cc2ce0c5a0eb75ee0077e3.jpg)

图 游戏中的Glow结合Bloom，得到出色的画面效果

![](media/fc07f17a1dc048be84b9d3af4da015c9.jpg)

图 Unreal Engine的logo，即是采用了Glow效果



## 【核心内容提炼】

光源的辉光（Glow）和光晕（Halo）是自然界导出可见的现象，他们提供了亮度和气氛强烈的视觉信息。

![](media/f5f190f91977b41c60c2f5f301e05b25.jpg)

图 给强化后的武器加上Glow效果，该武器显得更加强力 @TERA

![](media/6618fd78de01c723ef6a3dab9608fe0f.jpg)

图 强化武器的Glow效果的演变 @Lineage II

![](media/287352aae26a0c79bec67e6929f2beeb.jpg)

图 Glow效果 @Unreal Engine 4

在观看计算机图形、胶片和印刷品时，到达眼睛的光强度是有限的，因此，辨别光源强度的唯一方法是通过它们周围产生的辉光（Glow）和光晕（Halo），具体可以参考[Nakamae
et al.
1990]。这些辉光可以再现强烈光线的视觉效果，并使观察者感知非常明亮的光源。即使物体周围的微妙光晕也会让人觉得它比没有光辉的物体更亮。

在日常生活中，这些发光和光晕是由大气中或我们眼中的光散射引起的（Spencer 1995）。
使用现代图形硬件，可以通过几个简单的渲染操作来再现这些效果。
这使得我们可以使用明亮而有趣的物体来填满实时渲染的场景，物体会显得更为逼真或更具表现力，并且这是克服图形渲染中传统的低动态范围图形过于平庸的优雅手段之一。

![](media/ebca3845e4f33120b90c54c7f78f9b32.png)

图 有辉光和没有辉光的一个Tron 2.0中的角色对比

有几种方法可以创建场景中的辉光。对于小的类似的点，可以把一个平滑的“辉光”纹理应用到公告牌几何体上，而让公告板几何体在屏幕范围内跟随物体运动。

对于大的辉光源或复杂的辉光形状，要创建辉光，最好对2D场景的渲染进行后处理。这章重点讲到了后处理的实时辉光处理方法。如下图。

![](media/9b0e20d976d449e59dfb54e6a06fada4.png)

图 场景实时辉光的步骤

（a）正常地渲染场景
（b）涂抹所渲染的辉光源，以产生（c）中的一个辉光纹理，将其加到正常的场景画面中，以产生（d）中最终的辉光效果。

渲染后处理辉光的步骤：

Step 1、辉光的指定和渲染（Specifying and Rendering the Sources of Glow）

Step 2、模糊辉光源（Blurring the Glow Sources）

Step 3、适配分步卷积（Adapting the Separable Convolution）

Step 4、在GPU上进行卷积（Convolution on the GPU）

![](media/781d1c41c19ffd1ba195f399877c3860.png)

图 有效地创建模糊的两步分解法

上图展示了如何有效地创建模糊的两步分解法：首先，在一根轴上模糊于（a）中的辉光源的点，产生（b）中所示的中间结果，然后在另一个轴上模糊这个结果，产生显示在（c）中的最终模糊。

![](media/60fc76a8681ddc527beb31e71b9f9f62.png)

图 有辉光和无辉光的Tron 2.0中的英雄 Jet

（a）用标准方法渲染3D模型
（b）为一个由美术同学创建的辉光源纹理的渲染，目的是指定辉光面积的图案和强度（c）为将辉光应用到标准的渲染结果后，得到的富有表现力的英雄角色效果。

另外，在辉光中使用的这个卷积和模糊方法还可以用于多种其他效果。它能用来计算景深效果的不同聚焦度，景深的信息可以用来控制模糊度。它也能用来模糊投影的纹理阴影的边缘，并且累积深度阴影映射的接近百分比过滤（percentage-closer
filtering ）结果。

而大面积的卷积能被应用于一个环境映射，以创建一个近似的辐照度映射，从而得到更逼真的场景照明（Ramamoorthi和Hanrahan
2001有相关论述）。用大面积的卷积也可以实现许多非真实感渲染技术和其他的特别效果。其中包括镀着霜的玻璃、模拟衍射的透镜摇曳，以及渲染皮肤时用的近似次表面散射。

大片的模糊和卷积能有效地在多种图像硬件上实时地计算，而处理和创建这些效果的代码可以容易地封装成几个C++类或一个小库。

总之，屏幕辉光是一种很赞的效果，能够容易地扩展到几乎每一种情形，并且变化多端，通过其还够延伸创建出很多其他的效果。最终的效果虽然细微但却有张力，值得在各种游戏中采用。

![](media/0a937d9d89e4b5911b2e3217c2e81e1c.jpg)

图 Glow效果 @Unreal Engine 4

![](media/2d0acb97f656e9bdd3fdcdff97d4cc3e.jpg)

![](media/5b51a80706a5ef83e6cc4c200b021624.jpg)

图 有了Glow效果的武器，显得更强力

## 【核心要点总结】

渲染后处理辉光的步骤：

Step 1、辉光的指定和渲染（Specifying and Rendering the Sources of Glow）

Step 2、模糊辉光源（Blurring the Glow Sources）

Step 3、适配分步卷积（Adapting the Separable Convolution）

Step 4、在GPU上进行卷积（Convolution on the GPU）

## 【本章配套源代码汇总表】

Example 21-1.设置抽样八个邻居的纹理坐标的Direct3D顶点着色器代码（Direct3D Vertex
Shader to Set Texture Coordinates for Sampling Eight Neighbors）

Example 21-2. 相加八个加权纹理样本的Direct3D像素着色器代码（Direct3D Pixel
Shader to Sum Eight Weighted Texture Samples）

Example 21-3. 建立邻域采样的Direct3D顶点着色器代码（Direct3D Vertex Shader
Program to Establish Neighbor Sampling）

Example 21-4. 建立邻域采样的Direct3D像素着色器代码（Direct3D Pixel Shader
Program to Sum Four Weighted Texture Samples）

## 【关键词提炼】

实时辉光（Real-Time Glow）

光晕（Halo）

后处理（Post-Processing）

图像处理（Image Processing）



# 下篇 · 次核心内容提炼总结

<br>

# 七、水焦散的渲染 （Rendering Water Caustics）


## 【章节概览】

这一章介绍了一种从美学角度出发（aesthetics-driven）来实时渲染水中焦散的方法。

![](media/1bf6407eb4ca155cdf34acf9ae08fbcb.png)

图 水的焦散效果

## 【核心要点】

水的焦散（Water Caustics）的定义：光从弯曲的表面反射或者折射，只聚焦在受光面的某些区域，于是就是产生焦散的现象。

![](media/dbf31636dde49cc423a1b39afd64b7fc.jpg)

图 折射的计算（入射光线（E）从介质η_1进入介质η_2，发生折射，产生折射光线（T））

首先，从模拟的观点出发，焦散其实可以通过正向或逆向光线追踪计算。

正向光线追踪中，要追踪从光线射出并穿过场景的光线，累计其在不断地区的贡献。

而逆向光线追踪，则以相反的过程工作，从海底开始，按照与入射相反的顺序逆向根据光线，计算给定点的所有入射光线总和。

而该文章中，前一节介绍了逆向蒙特卡洛光线追踪的一个简化，并大胆假设一些光线对焦散有贡献，并只计算到达海底光线的一个子集，因此，该方法计算消耗非常少，却产生了尽管在物理上不正确但是非常逼真的焦散图样和效果。由于整个效果看起来非常令人信服，尤其是图像质量，使得这个方法非常值得实现。文中用HLSL和OpenGL都进行了实现，并按照惯例，提供了源码。

该算法的伪代码如下：

	1.  Paint the ocean floor.
	
	2.  For each vertex in the fine mesh:
	
	    1.  Send a vertical ray.
	
	    2.  Collide the ray with the ocean's mesh.
	
	    3.  Compute the refracted ray using Snell's Law in reverse.
	
	    4.  Use the refracted ray to compute texture coordinates for the "Sun" map.
	
	    5.  Apply texture coordinates to vertices in the finer mesh.
	
	3.  Render the ocean surface.



## 【本章配套源代码汇总表】

Example 2-1. 关于波函数、波函数的梯度以及线平面截距方程的代码示例，（Code Sample
for the Wave Function, the Gradient of the Wave Function, and the Line-Plane
Intercept Equation）

Example 2-2. 最终渲染通道代码示例，展示了依赖纹理读取操作 （Code Sample for the
Final Render Pass, Showing the Dependent Texture Read Operations）



## 【关键词提炼】

水焦散渲染（Rendering Water Caustics）

逆向蒙特卡洛光线追踪（backward Monte Carlo ray tracing）

折射（Refraction）


# 八、 Dawn Demo中的动画（Animation in the "Dawn" Demo）


## 【章节概览】

这章主要讲到编程人员如何帮助美术同学对混合形状实行控制，从而创建不同的表情。主要是使用顶点Shader通过索引的蒙皮和变形网格对象（morph
target）来使一个高分辨率网格变形，实现角色表情和动画等效果。也讨论了为实现实时动画而考虑的各种折中方案。

![](media/cafa26f19c54ca597045c5a047c3bb38.jpg)

图 Dawn Demo的实时屏幕截图

## 【核心要点】

使用变形目标（Morph Target）是表现复杂网格变形的常用方法。NVIDIA
Demo团队使用此技术创建的Zoltar等Demo从每秒插值30个网格开始，然后基于累计误差方案（Accumulated
Error
Scheme）去除关键帧。使得我们能够缩小文件并减少存储空间，最多可以将三分之二的原始关键帧，同时几乎不会出现可见的失真。在这种类型的网格插值中，任何给定时间中只有两个插值关键帧处于激活状态，而且他们是连续地执行的。另外，变形目标可以并行使用。

原文也中对变形目标（Morph Target）的具体实现进行了论述。

![](media/2230e081af4283a98249ba60e39e3c12.png)

图 表情的混合对象（混合形状）

而蒙皮（Skinning）是一种网格变形方法，对网格中的每个顶点指定一组带有权重的矩阵（权重最大可增加到1.0）。权重指明矩阵应该如何约束顶点。

为一个网格蒙皮做准备，通常要为网格创建一个中间状态，叫做绑定姿势（Bind
Pose），这个姿势保持胳膊和腿略微分开，并且尽可能避免弯曲。

![](media/90fc18ee992be370b2d6597d2f70c5b4.jpg)

图 Dawn的绑定姿势（Bind Pose）

## 【本章配套源代码汇总表】

Example 4-1 以线性或连续样式运用到变形目标的示例代码（Applying morph targets in
a linear or serial fashion sample code）

Example 4-2 单个"multiply-add"用于每个变形目标的示例代码（Single "multiply-add"
instruction for each morph target sample code）

Example 4-3 变形目标的实现示例代码（Morph Target Implementation sample code）

Example 4-4 使用四根骨头蒙皮的示例代码（Application of four-bone skinning sample
code）

## 【关键词提炼】

面部表情模拟（Facial Expression Simulation）

网格动画（Mesh Animation）

变形目标（Morph Target）

蒙皮（Skinning）

# 九、 改良的Perlin噪声实现（Implementing Improved Perlin Noise）


## 【章节概览】

这章的作者是奥斯卡得主Ken Perlin。他提出的噪声算法（Perlin
Noise）已在实时和离线计算机图形学中得到多方面运用。这篇文章详细阐述了最新进展，纠正了最初的两个缺陷，也提供了有效及稳定的框架结构，用于在现代可编程硬件上执行噪声运算。

## 【核心要点】

首先，噪声函数的目的，是在三维空间中提供一种可以有效率地实现、可重复，伪随机的信号。其信号的能带有限（band-limited），大部分能量集中在一个空间频率附近，而视觉上是各向同性（isotropic）的，统计上不随旋转变化。

一般的想法是创建某种信号，类似于一个完全的随机信号（即白噪声），通过低通滤波后，滤除了所有的空间高频率而变得模糊。有如沙丘你缓慢上升的山包和下落的低谷。

![](media/ce58e6d0901706ca3cf7f3a49bf0e354.png)

图 沙丘与噪声

最初的噪声在1983年实现，1985 (Perlin 1985)发表，思想是使用埃尔米特-样条（Hermite
spline）插值法等方法实现，原文中对此方法的步骤进行了描述。

![](media/5ff8e22e8afe125e1fd305bf9f6bb89e.jpg)

图 使用使用埃尔米特-样条（Hermite spline）插值法，从常规3D格点的八个样本中插值

![](media/7ae7fa8a3f40c0cf23a707d15f8fe87f.jpg)

图 通过噪声函数产生的一个切片样条

这篇文章从两个方面对最初的噪声方法的不足进行了改进：

插值的特性以及伪随机斜率场（field of pseudo-random gradients）的特性。

![](media/9806d02f14c9b03d2f8ddc68859d4b3a.png)

图 四种基于噪声生成的纹理

而另外一个关于噪声的思路是，用体积噪声制造程序式纹理（Procedural texturing using volumetric noise），这样可以不创建显式的纹理图像，来得到自然的材质。这种方法在当年的大片《指环王》中，已经有了广泛应用。

## 【本章配套源代码汇总表】

5-1 假设模型是单位半径球体，实现凹凸模式的示例代码（Assuming the model is a unit-radius sphere, the expressions that implement these bump patterns sample Code）

## 【关键词提炼】

Perlin噪声（Perlin Noise）

噪声函数（Noise function）

伪随机斜率场（Field of Pseudo-Random Gradients）

体积噪声( volumetric noise）

埃尔米特样条（Hermite spline）


<br>

# 十、Vulcan Demo中的火焰渲染（Fire in the "Vulcan" Demo）


## 【章节概览】

这章讲述了GeForce FX 5900上市时的Demo
“Vulcan”中的火焰渲染技术。其中的技术并非真正的物理模拟，而是对当时的工业标准电影《指环王》的离线技术的跟进。通过文中改进，突破了光栅化大量粒子时操作性能的限制，产生了真实可信的火焰图像。

![](media/a68b6c7763c9a93192b5965e8f6de547.png)

图 基于本章方法实现的"Vulcan" Demo的截图

## 【核心要点】

首先文章尝试了两个方案：

完全程序化的火焰（ fully procedural
flames）和屏幕空间基于变形的二维火焰（screen-space 2D distortion-based
flames.），经过试验都未达预期。

于是改采用视频纹理精灵（video-textured
sprites ），最终达到预期，并实现出了逼真的火焰，且占用很少的GPU资源。

![](media/0eb0473ed541e8547426cf3a35610502.png)

图 用于创建火焰效果的连续镜头

其中，烟的生成使用粒子系统创建一个烟雾生成器。而所需的光照可以采用不同的技术达到，如光线投射。

![](media/dd6d75501f39f36c2eb8c93780683e6f.png)

  
图 程序式地产生烟

而火焰和烟的混合，比较常规地使用相加混合（additive blending）。

关于使火焰增加多样性，文中使用了水平和垂直翻转（沿着u和v轴）。而使用任意旋转可以更加具表现力。

![](media/ddbfa1d5053cb96aa32fa2dbd78fbc4f.jpg)

图 由自定义纹理坐标生成的变体

## 【本章配套源代码汇总表】

Example 6-1. 最终的实现Shader代码（The Final Shader）

## 【关键词提炼】

火焰渲染（Fire Rndering）

完全程序化的火焰（fully procedural flames）

屏幕空间基于变形的二维火焰（screen-space 2D distortion-based flames）

视频纹理精灵（video-textured sprites ）

# 十一、衍射的模拟（Simulating Diffraction）


## 【章节概览】

这章讲述了简化的Jos衍射光照模型（最初在SIGGRAPH
1999上发表），此模型以光的物理性质为基础，将光当做波来进行建模，从而创建出多彩的干涉条纹。

## 【核心要点】

什么是衍射（Diffraction）？小尺度的表面细节引起反射波彼此干扰，这个现象就是衍射。

首先，计算机绘图的大多数表面反射模型都忽略自然光的波动效果。当表面的细节比光的波长（约1um）大许多时，不存在问题。但对于小尺寸的细节，例如一个光盘的表面，波效应就不能忽略了。所以，对于小尺度的表面细节引起反射波彼此干扰的现象，即为衍射。

衍射使这些表面的反射光呈现五彩缤纷的图案，由光盘的精细反射可以看到这一现象。

![](media/5561904e298f41f28747bd98b9e7688a.jpg)

图 光盘的衍射

衍射的实现，可以在Shader的顶点着色器上，也可以在片元着色器上，且实现可以在任何网格上进行，只需提供一个“切线向量”，和每顶点的法线及位置。而切线向量提供表面上窄条带的局部方向。对于一个光盘，其为轨道的方向，如下图。

![](media/682310461e6d8b4e23a2984cb2ff34a8.png)

图 光盘的切线向量

对应给定衍射波长的颜色，可以使用简单近似的彩虹贴图。贴图从紫到红排列，而且提供彩虹的大部分颜色，用三个理想凹凸函数（峰值分别在蓝、绿和红的区域）简单混合而成。

![](media/a0aabb93a265e9d258848657aefa8228.png)

图 用于shader的彩虹彩色贴图

而最终的衍射颜色是彩色的衍射图案和各项异性高光的简单相加的和。

![](media/aab296674959b3b442794016332e3e4a.png)

图 光盘衍射实时的3个快照

![](media/2b00f10637fef6861756d4a5669a8296.png)

图 用纹理映射各项异性主要方向表面的3个快照

## 【本章配套源代码汇总表】

Example 8-1. 衍射的顶点着色器代码（The Diffraction Shader Vertex Program）

## 【关键词提炼】

衍射模拟（Simulating Diffraction）

各项异性（Anisotropy）


# 十二、高效的阴影体渲染（Efficient Shadow Volume Rendering）


## 【章节概览】

这章全面讲述了用于实时阴影渲染中常见两种流派之一的阴影体（Shadow
Volumes）技术，又称模板阴影（Stencil
Shadows）技术，重点是得到正确的角度的情形，减少几何图形和填充率的消耗。

## 【核心要点】

当时id software的《Doom 3》就是采用阴影体（Shadow
Volumes）技术来对阴影进行的渲染。具体思想是在模板（stencil）缓冲标记阴影的像素，把像素分为阴影或照明两种类型，接着调节负责光照的像素程序，使阴影像素的照明贡献度为0。

阴影体技术可以为点光源、聚光灯和方向光源创建清晰的、逐像素进度的阴影。单个物体可以被多个光源照亮，而且光有任意颜色和衰减度。阴影从三角形网格投射到深度缓冲区上。这意味着被遮挡的物体，可以是带有深度缓冲区的网格、公告板、粒子系统或预先渲染的场景。

较其他运算相比，阴影体可以更好地处理许多制作困难的阴影场景，如一个插在万圣节南瓜灯内部的光源。

![](media/56c4ee03d16417d5078b278e89f7507c.png)

图 阴影体技术可以很好胜任的渲染场景

阴影体的缺点是对那些没能正确表达自身形状的网格的阴影表达效果并不理想。如一些带透明区域的公告板，粒子系统，或带alpha粗糙度的纹理网格（如一片树叶）。这些投影体基于他们的真实网格产生阴影，阴影与物体的真实形状并不匹配。而阴影体的另一个缺点是对带裂缝的网格支持不太好。文中也表示，当时阴影体运行的理想场景是顶部俯视。

![](media/79cbf43848e0dd04f05144b858051dad.png)

图 模型上的裂缝会让影子穿过空气漏出来

总之，这篇文章对McGuire等人2003年提出的方法进行了很好的描述、分析与实践。而在这篇文章发出之后的若干年，阴影体技术得到了各种进一步地优化与改进。

## 【本章配套源代码汇总表】

Example 9-1 程序结构伪代码（Program Structure Pseudocode）

Example 9-2 glFrustum风格的无限投影矩阵（An Infinite Projection Matrix in the
Style of glFrustum）

Example 9-3 用于从示例光源中“挤”出 w＝0顶点的顶点着色器代码（A Vertex Shader for
Extruding w = 0 Vertices Away from the Example Light）

Example 9-4 （The markShadows Method）

Example 9-5 findBackfaces方法（The findBackfaces Method）

Example 9-6 renderShadowCaps方法（The renderShadowCaps Method）

Example 9-7 renderShadowSides方法（The renderShadowSides Method）

## 【关键词提炼】

阴影渲染（Shadow Rendering）

阴影体（Shadow Volume）/ 模板阴影（Stencil Shadows）

多通道渲染（Multipass Rendering）


# 十三、电影级光照（Cinematic Lighting）


## 【章节概览】

本章中介绍了一个的简化的uberlight（可理解为“全能光照”）实现，此光照shader根据Ronen
Barzel(1997,1999)提出的照明模型编写而成。而该模型的超集已由Pixar动画开发，并应用于《玩具总动员》、《怪物公司》、《海底总动员》等一系列的迪士尼电影中。

本章所对该光照模型的尝试，旨在提供一套全面的光照控制参数，以涵盖灯光美术师日常使用的大部分效果。

![](media/4f66cfe65ba506676cdde671bf7da6da.png)

图 《怪物公司》 中cookies对窗户效果的贡献

## 【核心要点】

首先，该章中呈现的Shader只模拟光照场景光源的形成和控制，不包括如何模拟表面细节和光反射行为的复杂性。

大体上，用于电影产品的照明模型会进行两种操作，类似于显示在这里的伪代码：

	color illuminationModel()

	{

	    Computer the surface characteristic

	    For each light

	    {

			Evaluate the light source （评估光源）

			Compute the surface response（计算表面响应）

	    }

	}

首先，通过这些方式计算表面着色信息：运行各种纹理查找（texture
lookups），在网格上插值（interpolating values over the
mesh），计算程序模式（computing procedural
patterns）等。然后在照明物体的每个光源上循环，计算出它的贡献。我们通过对每个光线计算光的颜色，然后计算表面对照明的响应来进行上述操作。

原文中给出了一个Shader源代码，该Shader用于计算塑料（plastic）材质在只有一个光源贡献的反射模型。，可以很容易将它扩展为更通用的多光源和更多表面的解决方案。

该Shader为美术师提供了各个方面的照明控制：选择（指定物体是否响应接受光照），颜色，形状，阴影和纹理，而阴影选项中包括明暗度、色调、反射、阴影贴图、阴影模糊等参数。

下面两幅图说明了uberlight 的使用效果。照明来自Pixar短片“Geri's
Game”中的人物头部。

![](media/a78bfaa0fe79b7be546cebed07799194.png)

图 （a）Geri
由一个光源照明；（b）改变光的权重，修改反射高光对比度；（c）改变阴影颜色，加强阴影；（d）改变谷仓形状（类似窗户一样的遮挡物），创建更戏剧化的姿态；（e）使用一块模糊的纹理cookie，丰富图像；（f）夸大透射的cookie的对比，创建像外星人一样的效果

![](media/efab0e56de0f5ff7bec800a5c0517d9b.png)

（a）常态 （b）黑色电影（noir）的高反差 （c）柔和的光线

## 【本章配套源代码汇总表】

10-1. The Vertex Program for an Uberlight-Like Shader

10-2. The Fragment Program for an Uberlight-Like Shader

## 【关键词提炼】

电影级光照（Cinematic Lighting）

全能型光照（Uberlight）

照明模型（Lighting Model）

储存于本地的光照数据（Light Cookies）


# 十四、阴影贴图抗锯齿（Shadow Map Antialiasing）


## 【章节概览】

这章介绍了如何通过邻近百分比过滤方法（Percentage-Closer Filtering ,
PCF）有效减少阴影贴图的反走样。

## 【核心要点】

阴影贴图（Shadow
Map，又译作阴影映射）是渲染阴影的常见方法，也是渲染阴影领域的两大流派之一，但是它存在走样的问题。通常使用高分率的阴影贴图和增加阴影贴图的分辨率来反走样，也就是使用Stamminger和Drettakis
2002年提出的“透视阴影贴图（ perspective shadow
maps）”技术。但是，当光与表面接近于平行的时候，使用“透视阴影贴图”技术和增加阴影贴图分辨率就不起作用了，因为放大的倍数接近于无穷大。

高端渲染软件使用“临近的百分比过滤（Percentage-Closer
Filtering,PCF）”技术解决走样问题。最初的PCF算法由Reeves等人1987年提出。其计算的是靠近光源表面的百分比，而不是在阴影中表面的百分比，具体是多次比较阴影贴图的每个像素，求其平均值。

且文中对传统的PCF算法做了改进，不再计算阴影贴图空间中被遮挡的区域，只是简单地在各处使用一个
4 x
4个texel（纹素）的样本块。这个块应该大到能够有效地减少走样，但是不能达到要求大量样本和随机取样的程度。如下图。

![fig11-09a.jpg](media/cf872a841af5cb1643e04ed813be7ca3.png)

图 （a）每像素取1个样本  （b）每像素取4个样本  （c）每像素取16个样本

可以看到3幅图中的显示效果区别很明显，图（c）中每像素取16个样本，效果最为出色，达到了反走样的预期。

## 【本章配套源代码汇总表】

PS:原文中没有对代码片段进行编号，这里的编号为附加。

Example 11-1 暴风(Brute Force)算法16采样版本的片元程序实现代码

Example 11-2 阴影贴图反走样的4采样实现版本代码

## 【关键词提炼】

反走样/抗锯齿（Antialiasing）

邻近百分比过滤（Percentage-Closer Filtering , PCF）

透视阴影贴图（ perspective shadow maps）

<br>


# 十五、全方位阴影贴图（Omnidirectional Shadow Mapping）


## 【章节概览】

在这章中，把阴影贴图的思路扩展到正确处理全方位的（点）光源中，其中包括了实现细节，也涉及到基本硬件能力不足时的低效运行策略。

## 【核心要点】

首先，这篇文章也谈到了在实时计算机图形学中产生可见阴影的两个流行方法是：

-   模板阴影（stencil shadows）/ 阴影体(Shadow Volume)

-   阴影贴图（shadow mapping）

模板阴影（Stencil Shadows，也被称Shadow Volume，阴影体）作在《Doom 3》中有所应用，优点是得到大量的GPU支持、独立于光源的种类、产生的阴影质量很高。但缺点是严重依赖于CPU，只能产生清晰的影子，需要很高的填充率，而且不能与硬件（hardware-tessellated）的表面一起使用。

阴影贴图（Shadow Mapping,也译作阴影映射）由Lance Williams于1978年引入计算机图形学，文章发布当时多数好莱坞电影都在使用这个方法，包括计算机渲染和特效。为了计算阴影，阴影映射在场景几何体上投射特殊的动态创建的纹理。它可以渲染清晰和模糊的影子，以及由不同类型的光源产生的阴影，它还可以与硬件镶嵌的表面以及GPU动画的网格（例如蒙皮网格）一起使用。

该文章主要介绍了全方位阴影贴图（Omnidirectional Shadow
Mapping）方法，该方法有两个主要步骤：

-   创建阴影贴图

-   进行阴影投射

在创建阶段，对所有把阴影投射到阴影贴图纹理上的物体，渲染它们到光源的距离的平方。而在投射结算，渲染所有接受阴影的物体，并比较所渲染的像素到光源的距离的平方。以下为全方位阴影映射算法的伪代码：

	for (iLight = 0; iLight < NumberOfLights; iLight++) 
	
	{
	
	  // Fill the shadow map.
	
	  for (iObject = 0; iObject < NumberOfObjects; iObject++)
	
	 {
	
	    RenderObjectToShadowMap(iLight, iObject);
	
	  }
	
	  // Lighting and shadow mapping.
	
	  for (iObject = 0; iObject < NumberOfObjects; iObject++) 
	
	  {
	
	    LightAndShadeObject (iLight, iObject);
	
	  }
	
	}

![](media/0b975daa48ea7ab00e8e82ac74275661.png)

图 Omnidirectional Shadow Mapping @Merlin3d

## 【本章配套源代码汇总表】

Example 12-1 全方位阴影映射算法的伪代码（Pseudocode for the Omnidirectional
Shadow-Mapping Algorithm）

Example 12-2 仅渲染深度（Depth-Only Rendering）

Example 12-3 产生一个软阴影（Making a Softer Shadow）

## 【关键词提炼】

阴影渲染（Shadow Rendering）

阴影贴图（Shadow Mapping）

模板阴影（stencil shadows）/ 阴影体（Shadow volume）

全方位阴影映射（Omnidirectional Shadow Mapping）

<br>

# 十六、使用遮挡区间映射产生模糊的阴影（Generating Soft Shadows Using Occlusion Interval Maps）


## 【章节概览】

这章介绍了一种渲染软阴影的技术，称为遮挡区间映射（Occlusion Interval
Maps），能够正确地在静态场景中渲染出光源沿着预定路径移动时产生的模糊阴影。之所以叫遮挡区间映射，是因为此算法使用纹理贴图来存储这种光源可见、而本身被遮挡的区间。

## 【核心要点】

对于需现实的加油站的Demo，文章一开始本打算使用一种预计算的可见度技术，例如球谐光照（Spherical
Harmonic Lighting [Sloan et al.
2002]）来实现，但可惜的是无法达到目的，因为球谐光照适用的是非常低频的光照，不适用于像太阳那样小面积的光源。所以后来才开发出遮挡区间映射这种新的预计算可见度的技术，它能够支持实时太阳照射的软阴影。通过把问题简化为在固定轨道上的线性光源来达到目的。

需要注意，遮挡区间映射（Occlusion Interval
Maps）技术有一些局限性，只对沿固定轨道传播的单条光线的静态场景适用。这意味着它对人物和其他动态物体的阴影无效。但是其适用于静态户外场景中的阴影渲染。并且此技术因为遮挡区间映射对每个通道需要8位的进度，纹理压缩将导致视觉效果失真。因此，必须禁用纹理压缩，从而增加了纹理用量。

使用遮挡区间映射（Occlusion Interval
Maps）技术，通过损失一定运行性能来获得在静态场景上实时运行的软阴影算法。遮挡区间映射（Occlusion
Interval
Maps）可以用作静态光照贴图的替代品，从而实现动态效果，可以得到从日出到日落光照明变化的动态效果。如下图。

![](media/5de7891126c535535204fa96b36916f3.png)

图 加油站入口

注意加油站墙上的阴影在图形的左上方有清楚的边界，但是它朝着右下方变得模糊而柔软。这种相联系的清晰和模糊的变化是真实感软阴影的重要性质，而这是由遮挡区间映射得到的。

![](media/8bae93c4dd683d629fa8c1f9a2bb79e6.png)

图 汽车上方的木板在篷布上形成的阴影

上图中汽车篷布上的木板形成了复杂的阴影。这对算法来说是最坏的情况。这些木头条使得篷布上的遮挡区间映射必须存储在5个不同的纹理中，对于场景中的大多数物体，4个纹理就足以取得所有的阴影。

## 【本章配套源代码汇总表】

Example 13-1使用遮挡区间映射计算软阴影的实现函数（Function for Computing Soft
Shadows Using Occlusion Interval Maps）

## 【关键词提炼】

阴影渲染（Shadow Rendering）

软阴影（Soft Shadows ）

遮挡区间映射（Occlusion Interval Maps）



<br>


# 十七、透视阴影贴图（Perspective Shadow Maps: Care and Feeding）


## 【章节概览】

透视阴影贴图（Perspective Shadow Maps, PSMs）是由Stamminger和Drettakis在SIGGRAPH
2002上提出的一种阴影贴图（Shadow Maps）流派的方法。

透视投影贴图方法的基本思想是，为了减少或消除阴影贴图的失真走样，对投射到大像素区域的物体取最大的阴影贴图纹素密度。

这章提出了一种优化透视阴影贴图（Perspective Shadow
Maps）方法的新思路，对其三种缺陷都一一进行了改进。

## 【核心要点】

这章首先讲到动态阴影的创建，目前主要有两个算法流派：

-   阴影体（shadow volumes）/模板阴影（stencil shadows）

-   阴影贴图（Shadow Maps）

阴影体和阴影贴图算法之间的不同之处在于，是涉及到物体空间（object
space）还是图像空间（image space）。

-   阴影体（Shadow Volumes）是物体空间（Object Space）的阴影算法，通过创建表示阴影遮挡的多边形结构来工作，这意味着我们始终具像素精确但较“硬”的阴影。此方法无法处理没有多边形结构的对象，比如经过alpha测试修改的几何图形或经过位移映射的几何体（displacement
mapped geometry）。此外，绘制阴影体需要大量的填充率，这使得很难将它们用于密集场景中的每个对象上，特别是在存在多个灯光时。

-   阴影贴图（Shadow Maps）是图像空间（Image Space）的阴影算法，它可以处理任何物体（如果能够渲染一个物体，就能得到它的阴影），但是存在走样（aliasing，锯齿）的问题。走样时常发生在有较宽或全方位光源的大场景中。问题在于阴影映射中使用的投影变换会改变阴影贴图像素的大小，因此摄像机附近的纹理像素变得非常大。因此，我们必须使用巨大的阴影贴图（四倍于屏幕分辨率或更高）来实现更高的质量。尽管如此，阴影贴图在复杂场景中却比阴影体要快得多。

透视阴影贴图（Perspective Shadow Maps, PSMs）是由Stamminger和Drettakis在SIGGRAPH
2002上提出的一种阴影贴图（Shadow Maps）流派的方法，通过使用在投射后空间（post-projective space）中的阴影贴图来去除其中的走样，而在投射后空间中，所有近处的物体都比远处的大。不幸的是，使用原始算法很困难，因为只有要某些情况下才能正常工作。

以下是透视阴影映射算法的三个主要问题和解决方案：

1、当光源在摄像机后面的时候，有一个虚拟的摄像机锥体。若在锥体内保持所有潜在的阴影投射体，阴影质量就会变得很差。

解决方案：是对光源矩阵使用特别的投射变换，因为投射后空间可以使用某些在通常空的世界空间中不能做的投射技巧。它使我们可以建立特殊的投射矩阵，可以看做“比无限远更远”。

2、光源在摄像机空间中的位置对阴影质量影响很大，对于垂直的方向光，完全没有走样问题，但是当光源朝向摄像机并迎面靠近它时，阴影映射走样就很严重。

解决方案：把整个单位立方体保持在一个阴影贴图纹理中，对于遇到的问题，有两个办法，每个办法仅解决问题的一部分：单位立方体裁剪法，把光源摄像机对准单位立方体的必要部分；立方体映射法，使用多个纹理来存储深度信息。

3、最初的文章没有讨论过偏置（bias）问题。偏置是随透视阴影贴图而带来的问题，因为纹素的面积以不均匀方式分布，这意味着偏置不再是常量，而是与纹素的位置有关。

解决方案：使用在世界空间中的偏置（而且不再分析双投射矩阵的结果），然后把这个世界空间偏置转换到投射后空间。

![](media/80461ef7339665f0405a11e10ce98031.png)

图 得到的阴影实时渲染结果（多边形10w ~ 50w个，分辨率1600x1200）。


## 【本章配套源代码汇总表】

Example 14-1计算立方体阴影纹理坐标（Shader Code for Computing Cube Map Texture
Coordinates）

Example 14-2在顶点Shader中计算偏置（Calculating Bias in a Vertex Shader）

Example 14-3 紧邻百分比过滤的顶点Shader伪代码（Vertex Shader Pseudocode for
PCF）

Example 14-4 用于紧邻百分比过滤的像素Shader伪代码（Pixel Shader Pseudocode for
PCF）

## 【关键词提炼】

阴影渲染（Shadow Rendering）

阴影贴图（Shadow Maps）

透视阴影映射（Perspective Shadow Maps，PSMs）

紧邻百分比过滤（percentage-closer filtering ，PCF）

单位立方体裁剪法（Unit Cube Clipping）

<br>

# 十八、逐像素光照的可见性管理（Managing Visibility for Per-Pixel Lighting）


## 【章节概览】

这章讲到了可见性在逐像素渲染光照场景中的作用，也考虑如何使用可见性减少必须渲染的批次数量，从而改善性能。

## 【核心要点】

如下伪代码说明在一个场景中必须渲染的批次数：

	For each visible object
	
	  For each pass in the ambient shader
	
	    For each visible batch in the object
	
	      Render batch
	
	For each visible light
	
	  For each visible shadow caster
	
	    For each pass in the shadow shader
	
	      For each shadow batch in the object
	
	        Render batch
	
	  For each lit visible object
	
	    For each pass in the light shader
	
	      For each visible batch in the object
	
	        Render batch

正如伪代码所述，为了减少批次数，可以进行一些与非可见性相关的优化。最应该优化的是渲染每个光照所必须的通道数。批次数随通道数线性增加，因此，我们应该最小化受限于CPU的游戏通道数。

我们可以使用可见性来减少批数。其中，为了减少批次，各个部分（可见部分、光源部分、光照部分、阴影部分）的集合分开讨论并生成。

可见性不仅能有效改善CPU的性能，也同样可以改善GPU的性能。对模板体执行逐像素光照时，填充率的消耗（模板体的填充或多次渲染大的物体）很快就变成了瓶颈，但可以使用剪切矩形（scissor
rectangle）限制显卡渲染的面积，解决此问题。

逐像素的照明需要大量的批次数和极高的填充率，所以要减少渲染的物体数和它们影响的屏幕面积。而使用这章中介绍的标准可见性算法和技术，可以充分改善运行性能。

![](media/fc2c00c1db06777ab92c1c859f037e96.jpg)

图 不在可见集合中的对象可能会影响渲染场景

## 【本章配套源代码汇总表】

Example 15-1 说明一个场景中必须渲染的批次数量的伪代码（pseudocode illustrates
the number of batches that must be rendered in a scene）.

Example 15-2：快速生成凸包的伪代码（pseudocode for quickly generate the convex
hull）

## 【关键词提炼】

逐像素光照（Per-Pixel Lighting）

可见性管理（Managing Visib1ility）

性能优化（Performance Optimization）

批次（Batch）

# 十九、空间BRDF（Spatial BRDFs）


## 【章节概览】

这章主要先聊到了空间双向反射分布函数（SBRDF），接着文章讨论了压缩SBRDF表达式，以及由离散光或环境贴图所照明的SBRDF的渲染方法。

## 【核心要点】

SBRDF是纹理贴图和双向反射分布函数（BRDF）的组合。纹理贴图存储了反射或其他的属性，它们沿着2D表面上的空间变化，而BRDF存储的是表面上单个点的反射，包括从入射角到出射角的全部分布。

![](media/f37e1d72ea9f280da1e41a0550ab047f.png)

图 SBRDF的定义域

SBRDF对标准点光源或方向光源照明的SBRDF表面，文中直接贴图了Shader源码，具体可以参考原文。

SBRDF除了可以用点光源或方向光源照明之外，还可以用环境贴图中所有方向的入射光进行照明。关键是在渲染前用BRDF的一部分卷积环境贴图。对于大多数的BRDF表达式，必须分别处理各个不同的BRDF。但因为一个SBRDF可能有上百万个不同的BRDF，所以这样做不可能。这篇文章采取的的做法是，简单地用一个Phong叶片卷积环境贴图，叶片可以选择不同的镜面指数，如n=0、1、4、16、64、256、这些贴图能存储在不同级别的立方体mipmap中。随后，SBRDF纹素的n值就指细节层次(LOD)，用于在立方体贴图中采样适当mipmap级别。

![](media/8edddd3f5776ead7d573cdb8bc2eb4ad.png)

图 用蓝色的油漆和铝BRDF得到的SBRDF渲染效果

## 【本章配套源代码汇总表】

Example 18-1. 用于离散光源的SBRDF片元Shader（An SBRDF Fragment Shader for
Discrete Lights）

Example 18-2. 使用Phong Lobe来描述环境地图的伪代码（Pseudocode for Convolving an
Environment Map with a Phong Lobe）

Example 18-3. 用于环境贴图的SBRDF片元Shader（An SBRDF Fragment Shader for
Environment Maps）


## 【关键词提炼】

双向反射分布函数（BRDF）

空间双向反射分布函数（SBRDF）

离散光（Discrete Lights）

环境贴图（Environment Maps）


# 二十、基于图像的光照（Image-Based Lighting）


### 【章节概览】

这篇文章打破了当时立方体贴图环境（Cube-Map Environment）用法的桎梏，深入研究了更多可能的逼真光照效果。文章主要研究了基于图像的光照（Image-Based Lighting，IBL），包括局部化的立方体映射，类似于使用基于图像的局部光照（Localizing
Image-Based Lighting），然后介绍了如何把哪些重要的技巧用于着色模型，包括逼真的反射、阴影和漫反射/环境项。

### 【核心要点】

立方体贴图通常用于创建无限远环境的反射效果。但是使用少量Shader算法，我们可以将物体放置在特定大小和位置的反射环境中，从而提供高质量的基于图像的光照（Image-Based
Lighting，IBL）。

在室内环境移动模型时，最好是使用近距离的立方体贴图，距离的大小与当前的房间类似。当模型在房间移动时，根据模型在房间中的位置，适当地放大或缩小放射。这种方法得到的模拟效果使人感到更为可靠和逼真。尤其在包含窗户，屏幕和其他可识别光源的环境中。而只要加入很少的Shader数学就能将反射局部化。具体可以看原文贴出的Shader源码。

![](media/406e4997427e4959de16ad7676327ca1.png)

图 不同位置上的局部反射

另外，我们可以将3D几何体做成立方体贴图，并且在正常地渲染环境的时候，把贴图应用到该环境的物体上。也可以使用贴图作为环境，把它投射到较简单的几何体上。

立方体贴图也能用来决定漫反射光照。Debevec的HDRShop程序能够从映射立方体光照环境积分出全部的漫反射贡献度，那么通过把表面法线带入预先卷积的立方体贴图，能够简单地查询漫反射贡献。

基于图像的光照为复杂的光照计算提供了综合而廉价的替代品，将一点数学加入纹理方法，可以大大拓宽“简单”IBL效果，给3D图像提供更强的的方位感。

## 【本章配套源代码汇总表】

Example 19-1生成世界空间和光照空间坐标的顶点着色器代码（Vertex Shader to
Generate World-Space and Lighting-Space Coordinates）

Example 19-2 本地化反射像素着色器代码（Localized-Reflection Pixel Shader）

Example 19-3 用于背景立方体对象的顶点着色器代码（Vertex Shader for Background
Cube Object）

Example 19-4 用于背景立方体对象的像素着色器代码（Pixel Shader for Background
Cube Object）

## 【关键词提炼】

基于图像的光照（Image-Based Lighting，IBL）

立方体贴图环境（Cube-Map Environment ）

基于图像的局部光照（Localizing Image-Based Lighting）


# 二十一、纹理爆炸（Texture Bombing）


## 【章节概览】

这章介绍了纹理爆炸（Texture
Bombing）和相关的细胞技术，它们能在Shader中增加视觉的丰富性，图像的多样性，并减少大块纹理图案的重复性。

## 【核心要点】

纹理爆炸（Texture
bombing）是一种程序化技术，它把小块图像以不规则的间隔放置。有助于减少团案的失真。

纹理爆炸的基本思想是把UV空间分为规则的单元栅格。然后使用噪声或者伪随机函数，把一个图像放在任意位置上的各个单元中。最终的结果是在背景上对这些图像的合成。

由于要组合数以百计的图像，因此实际上这种合成（composite）图像的方法效率并不高。而程序化（Procedural
）计算图像虽好，但是又不适合合成。这篇文章主要讲了图像合成和程序化生成这两种方法，可以发现他们各有优劣。

![](media/1f4929be9428a7031b3cbb41fa74d4f5.png)

图 纹理爆炸效果图

很显然，纹理爆炸也可以扩展到3D中，即3D程序化爆炸（Procedural 3D Bombing）

![](media/66a9323f26da5e154bda269c6618326a.png)

图 程序化的3D纹理爆炸效果

纹理爆炸有一种有趣的变化是在平面上画Voronoi区域。简言之，给定一个平面和那个平面上的一系列的点，接近那个点的面积就是点的Voronoi区域。Voronoi图案类似于树叶和皮肤上的单元形状、龟裂的泥土或爬虫类的皮。如下图。

![](media/345450849611257d2f711c7f1e4e398f.png)

图 Voronoi区域


总之，纹理爆炸和相关的细胞技术可以给Shader增加视觉的多样性。使用存储在纹理中的伪随机数表和一个小程序，可以增大一个图像或一组图像的变化，并减少大块纹理区域的重复。

## 【本章配套源代码汇总表】

Example 20-1 将采样扩展到四个单元格（Extending the Sampling to Four Cells）

Example 20-2 添加图像优先级（Adding Image Priority）

Example 20-3 使用程序化生成圆（Using a Procedurally Generated Circle）

Example 20-4 每个单元采样多个圆减少网格状图案（Sampling Multiple Circles per
Cell Reduces Grid-Like Patterns）

Example 20-5 3D程序化爆炸（Procedural 3D Bombing）

Example 20-6 程序化3D纹理程序（The Procedural 3D Texture Program）

Example 20-7 计算Voronoi区域（Computing Voronoi Regions）

## 【关键词提炼】

纹理爆炸（Texture Bombing）

3D程序化爆炸（Procedural 3D Bombing）

Voronoi区域（Voronoi Region）

<br>




# 二十二、颜色控制（Color Controls）


## 【章节概览】

这章将在游戏中图像处理的讨论，扩展到技术和艺术上控制颜色的方法和应用，包括将图像从一些的色彩空间中移入移出，以及快速地给任何2D或3D场景加上精美的色调。

## 【核心要点】

色彩校正（Color Correction）是几乎所有印刷和胶片成像应用的一部分。
色彩校正可用于将彩色图像从一个色彩空间移动到另一个色彩空间。

我们在电视、杂志和电影中剪刀的大部分图像，都经过了非常小心的彩色校正和控制。对于这个过程的理解，可以帮助开发者在实时应用程序中得到同样华美的视觉效果。

色彩校正通常有两种做法：一是各个通道的校正，分别是改变红色、绿色和蓝色各成分；二是混色操作，基于红、绿、蓝各个成分的同时操作，得到每个通道的输出值。

色彩校正的机理可以简洁而容易地在一个shader中描述。重要的是，美术和程序员使用的普通工具就能有效地控制他们。在这章中，运用Photoshop创建控制资源，然后通过像素shader应用到实时程序中。

在Photoshop中提供了一些基于通道校正的工具。如级别（levels）和曲线（Curves）工具。

其中曲线是仿制了化学中的交叉处理（cross-processing）外观，确切地说，就是在C41化合物中处理E6叫绝所产生的假颜色外观。这样的处理已在印刷、电影和电视领域使用多年。

![](media/b95941c57ca75f5ad2a48ff7a453376b.png)

图 重新创建交叉处理效果的Photoshop曲线

![](media/b2d6a1dbc10f3a3f6b0b8a24a97df7f2.png)

图 伪交叉处理 

（a）原始图 （b）曲线调节之后

可以使用下面几行shader代码运用于输出颜色，使用色彩校正纹理映射，可以随意地用曲线工具重新创建任何色彩变化：

float3 InColor = tex2D(inSampler, IN.UV).xyz;

float3 OutColor;

OutColor.r = tex1D(ColorCorrMap, InColor.r).r;

OutColor.g = tex1D(ColorCorrMap, InColor.g).g;

OutColor.b = tex1D(ColorCorrMap, InColor.b).b;

也就是说，使用每个原始的红、绿和蓝像素的灰度值，确定在梯度纹理中我们寻找的相关位置，然后由梯度纹理本身定义对新颜色的重映射，即由复杂曲线调节所定义的新颜色，如下图。

![](media/d01cd3f0054bd4178d7561b61e7c5f01.png)

图 对红、绿、蓝通道重映射结果

## 【本章配套源代码汇总表】

原文仅存在无编号的代码片段若干，具体详见原文。

## 【关键词提炼】

颜色控制（Color Controls）

色彩校正（Color Correction）

基于通道的颜色校正（Channel-Based Color Correction）

灰度变换（Grayscale Conversion）

色彩空间变换（Color-Space Conversions）

图像处理（Image Processing）


<br>


# 二十三、景深 （Depth of Field）


## 【章节概览】

本章主要介绍如何使用GPU创建实时的景深（Depth of Field）效果。

![](media/f74d7a2718b91518d938208f750b8b74.png)

图 实时景深效果 @Crysis 2

## 【核心要点】

物体在距离镜头的一个范围之内能够清晰成像（经过聚焦），在那个范围之外（或近或远）则成像模糊，这种效果就是景深。在相机业和电影业中，景深经常用来指示对场景的注意范围，并且提供场景深度的感觉。在本章中，把这个聚焦范围远的区域称为背景（background），在这个范围前的区域称为前景（foreground），而在范围外的面积称为中景（midground）。

景深效果由透镜的物理性质产生。若要穿过摄像机透镜（或人眼镜的晶体）的光辉聚到胶片（或人的视网膜）上的一个点，光源必须与透镜有着特定的距离。在这个距离上的平面称为焦平面（plane
in
focus）。不在这个精确距离上的任何东西，投影到胶片上的区域（而不是一个点）称为模糊圈（circle
of
confusion，CoC）。Coc的直径与透镜尺寸和偏离焦平面的距离成正比。偏离距离小到一定程度，CoC会变得比胶片的分辨率更小，摄影师和摄影师称这个距离为聚焦（in
focus），而在这个范围之外的任何东西都是没有对准聚点的（out of
focus，模糊的）。如下图。

![](media/d3fa2f5dbd2291d8094d263c446db246.png)

图 薄的透镜

![](media/b261554c6c79c1f2e1675e709d1d16e4.png)

图 模糊圈（circle of confusion）

这章中主要综述了5种近似景深效果的技术。

1、基于光线追踪的景深（Ray-Traced Depth of Field）[Cook et al. 1984]

2、基于累积缓冲的景深（Accumulation-Buffer Depth of Field）[Haeberli and Akeley
1990]

3、分层景深（Layered Depth of Field）[Scofield 1994]

4、前向映射的Z缓冲景深（Forward-Mapped Z-Buffer Depth of Field） [Potmesil and
Chakravarty 1981]

5、反向映射的Z缓冲景深（Reverse-Mapped Z-Buffer Depth of Field）[ Arce and Wloka
2002, Demers 2003]


## 【本章配套源代码汇总表】

原文仅存在无编号的代码片段若干，具体详见原文。

## 【关键词提炼】

景深（Depth of Field）

基于光线追踪的景深（Ray-Traced Depth of Field）

基于累积缓冲的景深（Accumulation-Buffer Depth of Field）

分层景深（Layered Depth of Field）

前向映射的Z缓冲景深（Forward-Mapped Z-Buffer Depth of Field）

反向映射的Z缓冲景深（Reverse-Mapped Z-Buffer Depth of Field）

图像处理（Image Processing）

<br>

# 二十四、高品质的图像滤波（High-Quality Filtering）


## 【章节概览】

这章描述了图像滤波和可以用于任意尺寸图像的效果，并将各种不同的滤波器核心（kernel），在分析计算后应用于各式2D和3D反走样问题中。

## 【核心要点】

GPU可以提供一些快速滤波的访问纹理的方法，但是仅限于几种类型的纹理过滤，并不是对每种纹素格式都适用。若我们自己建立自己的图像滤波方法，可以得到更好的质量和灵活性，但需要了解硬件和程序滤波之间存在的质量和速率的矛盾。

对滤波图像所考虑的内容也同样适用于3D渲染，尤其是把模型纹理化（光栅化）的时候，即把3D数据（和潜在的纹理信息）转换为一个新的2D图像的时候。

而混合过滤方法（Hybrid filtering
approaches）可以提供一个最佳的中间路径，即借助硬件纹理单元解析的着色。

GPU着色程序不同于CPU的主要之处在于：一般来说，CPU数学操作比纹理访问更快。在像RenderMan这样的着色语言中，texture()是最费时的操作之一，而在GPU中的情形恰恰相反。

图像滤波（ image
filtering）的目的很简单：对于给定的输入图像A，我们想要创建新的图像B，把源图像A变换到目标图像B的操作就是图像滤波。最一般的变换是调整图像的大小、锐化、变化颜色，以及模糊图像等操作。

源像素的模式，以及它们对图像B像素的相对共享，就称为滤波的核心（filter
kernel）。而把核心御用到源图像的过程叫做卷积（convolution）：即使用特殊的核心卷积源图像A的像素，创建新图像B的像素。

如果核心只是把像素简单地进行平均，我们称这个模型为盒式滤波器（box
filter），因为模型是一个简单的长方形（所有像素都在盒中）。每个采样的纹素（即，从纹理来的一个像素）的权重相等。盒式滤波器很容易构造，运行速度快，是GPU中硬件驱动过的一种滤波核心。

如果我们正好使用小的核心，可以把它作为参数直接代入Shader，下图显示的样本代码执行
3 x
3的滤波运算，对编入索引的纹素和其临近单元，赋予W00到W22的加权值，先求加权和，然后除以预计算的总和值（Sum）把它们重规范化。

![](media/d96533905192091206ac5345ebee2fda.png)

图 中心在W11的3x3滤波核心的像素布局

我们可以自己定义各种核心，如可以基于两个常数的3 x
3核心做边缘检测，后文也接着讲到了双线性滤波核心（Bilinear Kernel），双立方滤波核心（Bicubic
Filter Kernel），屏幕对齐的核心（Screen-Aligned Kernels）等内容。

![](media/74c6f428004569201c375c02f1713f69.png)

双线性和双立方滤波的效果。（题外话：不知道为什么，看这个小男孩，莫名觉得长得像冠希哥……）

(a)原始图像，注意眼睛上方的长方形。(b)用线性滤波把矩形的子图像区域放大32倍；(c)用双立方滤波把相同的区域放大32倍。

## 【本章配套源代码汇总表】

Example 24-1. 读取九个纹素来计算一个加权和的着色器代码（Reading Nine Texels to
Calculate a Weighted Sum）

Example 24-2. 将九个纹素减少到三个的着色器代码（Nine Texel Accesses Reduced to
Three）

Example 24-3. 使用点积，紧凑书写示例24-2中的代码（As in Listing 24-2, Compactly
Written Using Dot Products）

Example 24-4. 最紧凑的形式，使用预先合并的float4权重（The Most Compact Form,
Using Pre-Coalesced float4 Weights）

Example 24-5. 边缘检测像素着色器代码（Edge Detection Pixel Shader）

Example 24-6. 使用灰度辅助纹理的边缘检测着色器代码（The Edge Detection Shader
Written to Use Grayscale Helper Textures）

Example 24-7. 用于生成浮点内核纹理的OpenGL C ++代码（OpenGL C++ Code for
Generating a Floating-Point Kernel Texture）

Example 24-8. 使用内核纹理作为Cg函数（Using the Kernel Texture as a Cg
Function）

Example 24-9. 过滤四行纹素，然后将结果过滤为列（Filtering Four Texel Rows, Then
Filtering the Results as a Column）

Example 24-10. 原生条纹函数（Naive Stripe Function）

Example 24-11. 基于条纹覆盖量返回灰度值的条纹函数（Stripe Function that Returns
Grayscale Values Based on the Amount of Stripe Coverage）

Example 24-12. 简单的像素着色器来应用我们的滤波条纹函数（Simple Pixel Shader to
Apply Our Filtered Stripe Function）

Example 24-13. 使用条纹纹理进行简单的条带化（Using a Stripe Texture for Simple
Striping）

Example 24-14. 用亮度控制条纹函数的平衡（Using Luminance to Control the Balance
of the Stripe Function）

Example 24-15 HLSL .fx指令产生变条纹纹理（HLSL .fx Instructions to Generate
Variable Stripe Texture）

Example 24-16 在像素着色器中应用可变条纹纹理（Applying Variable Stripe Texture
in a Pixel Shader）

## 【关键词提炼】

高品质图像滤波（High-Quality Filtering）

边缘检测（Edge Detection）

双线性滤波（Bilinear Filtering）

双三次滤波（Bicubic Filtering）

三次滤波（Cubic Filtering）

<br>

# 二十五、用纹理贴图进行快速滤波宽度的计算（Fast Filter-Width Estimates with Texture Maps）


## 【章节概览】

这章描述基于纹理映射在2D空间中进行快速过滤宽度计算（Fast Filter-Width
Estimates）的方法。即使硬件profile对复杂函数的局部偏导函数不提供直接支持，基于本文提出的纹理操作技巧，也可以得到结果。

## 【核心要点】

Cg标准库提供了ddx()和ddy()函数，计算任意量关于x和y像素的导数。换言之，调用ddx(v)，可以求出变量v在x方向的当前像素与下一个像素之间的变化量，调用ddy(v)同样也可以求出y方向的情况。

那么，下面贴出的这个filterwidth()函数，可以很容易地计算任何值在像素之间变化的速率，以及程序纹理说需要过滤的面积。
	
	float filterwidth(float2 v)
	
	{
	
	  float2 fw = max(abs(ddx(v)), abs(ddy(v)));
	
	  return max(fw.x, fw.y);
	
	}

上述filterwidth()函数，仅在支持ddx()和ddy()函数的profile下工作，但可惜的是一些硬件profile不支持这两两个函数。而本文提出的这个trick，可以使用纹理映射硬件，进行与filterwidth()函数本质上相同的运算。

而这个技巧的关键在于，用函数tex2D()所做的纹理贴图查询，可以自动地对纹理查询进行反走样，而不考虑所代入的纹理坐标。也就是说，基于在相邻像素上所计算的纹理坐标，硬件可以为每个查询决定要过滤的纹理面积。

纹理映射的这个性质，可以用来替代滤波宽度函数filterwidth()，而无需调用ddx()和ddy()。我们以这样的一种方式执行纹理查询：通过它可以推测所过滤的纹理贴图面积，这里是推测需要过滤的程序化棋盘格纹理面积。这种解法分为两步：（1）为特定的纹理坐标选择mipmap级别；（2）利用上述技巧来决定过滤宽度。

最终，这个trick可以在很多情况下很好的计算滤波宽度，运行性能几乎与基于求导的计算滤波宽度函数filterwidth()相同。

## 【本章配套源代码汇总表】

Example 25-1 抗锯齿棋盘函数（Antialiased Checkerboard Function）

Example 25-2使用估算滤波宽度的值来加载Mipmap级别的代码（Code to Load Mipmap
Levels with Values Used for Estimating Filter Widths）

Example 25-3 使用示例25-2中的Mipmap来计算滤波器宽度的函数（Function to Compute
Filter Widths Using Mipmaps from Listing 25-2）

Example 25-4 滤波器宽度函数不容易走样滤波器宽度（Filter-Width Function That Is
Less Prone to Under-Aliasing Filter Widths）

## 【关键词提炼】

快速滤波宽度估算（Fast Filter-Width Estimates）

在着色器中求导（Derivatives in Shaders）

用纹理计算过滤宽度（Computing Filter Width with Textures）

<br>

# 二十六、OpenEXR图像文件格式（The OpenEXR Image File Format）

## 【章节概览】

这章中，大名鼎鼎的工业光魔公司的Florian Kainz、Rod Bogart和Drwe
Hess介绍了OpenEXR标准，这是一种当时新的高动态范围图像（HDRI）格式，在计算机成像的顶级电影中正在快速推广。对于基于图像照明的开发者而言，OpenEXR是关键的工具。

## 【核心要点】

OpenEXR是由工业光魔（ Industrial Light & Magic
，ILM ）公司开发的高动态范围图像（ high-dynamic-range image
，HDRI）文件格式。OpenEXR网站是 www.openexr.org ，上面有关于此格式的全部细节。

下图是一个例子，说明了需要HDR存在的原因。

如下图是一张显示相当高的动态范围的场景，场景中左边的油灯的火焰比中间小盘子下的阴影大约亮100000倍。

![](media/38440d033d85c19ef77ba96890ad4d43.png)

图 高动态范围场景

图像曝光的方式导致了一些区域的亮度超过了1.0，在计算机显示屏上，这些区域被裁剪（clipped）掉，并显示为白色或不自然的饱和桔色色调。

我们可以通过把图像变暗来校正白色和橘色区域，但是如果把原始图像存储在低动态范围文件格式中，如JPEG格式，把它变暗就会产生相当难看的图像。如下图。

![](media/3931c1f9af121e34b437f98117906fd6.png)

图
普通文件格式导致明亮的像素值被不可逆地裁剪，使得明亮的区域变灰，并且细节丢失，得到极不自然的效果

而如果原始图像存储在高动态范围文件格式中，如OpenEXR，保存明亮的像素值，而不是把他们裁剪到1.0，然后把图像变暗，就可以产生依旧自然的效果。如下图。

![](media/69c6d71d2ea14454a83640d331bec7b5.png)

图
上述变暗的图的高动态范围版本。在明亮的区域中显示出了其他细节，颜色看起来很自然

文章随后还讲到了OpenEXR的文件结构、数据压缩、使用、线性像素值、创建和使用HDR图像相关的内容。

## 【本章配套源代码汇总表】

Example 26-1 读取OpenEXR图像文件（Reading an OpenEXR Image File）

Example 26-2 将图像绑定到纹理（Binding an Image to a Texture）

Example 26-3 合成两个图像并写入OpenEXR文件（Compositing Two Images and Writing
an OpenEXR File）

Example 26-4 合成一个Pbuffer（Compositing into a Pbuffer）

Example 26-5 Cg Shader进行“Over”操作（Cg Shader for an "Over" Operation）

Example 26-6 Cg Shader进行“In”操作（Cg Shader for an "In" Operation）

Example 26-7 Cg Shader进行“Out”操作（Cg Shader for an "Out" Operation）

Example 26-8. 伽马校正一张图像并显示（Gamma-Correcting an Image for Display）

Example 26-9 调整调整图像的曝光（Adjusting an Image's Exposure）

Example 26-10 使用查找表来模拟摄影胶片的外观（Using a Lookup Table to Simulate
the Look of Photographic Film）

## 【关键词提炼】

高动态范围（High-Dynamic-Range , HDR）

高动态范围图像（High-Dynamic-Range Image，HDRI）

OpenEXR




# Reference

[1]
<https://cgcookie.deviantart.com/art/Subsurface-Scattering-Tutorial-658412208>

[2] <https://zhuanlan.zhihu.com/p/21247702?refer=graphics>

[3] <https://renderman.pixar.com/resources/RenderMan_20/subsurface.html>

[4] <https://www.davidmiranda.me/unity-skin/>

[5] <https://www.youtube.com/watch?v=OQ3D0Q5BlOs>

[6] <https://www.geforce.com/games-applications/pc-applications/a-new-dawn>

[7]
<https://www.shroudoftheavatar.com/forum/index.php?threads/on-video-game-graphics.54435/>

[8]
<https://support.solidangle.com/display/AFMUG/Guide+to+Rendering+Realistic+Skin>

[9] <http://forums.cgsociety.org/showthread.php?p=8310370>

[10]
<https://www.dualshockers.com/uncharted-4-dev-explains-how-drakes-incredible-shaders-were-made-shows-direct-feed-wip-screenshots/>


![](media/be47b90b234000f802e16fa2ee4e509d.jpg)

全文完。

With best wishes.

```

`Content/《GPU Gems 2》全书提炼总结/Part1/README.md`:

```md
![](media/title.jpg)

# 【GPU精粹与Shader编程】 《GPU Gems 2》全书核心内容提炼总结 · 上篇

本文的知乎专栏版本：
https://zhuanlan.zhihu.com/p/38411575


<br>

# 目录 · 本文核心内容Highlight

<!-- TOC -->

- [【GPU精粹与Shader编程】 《GPU Gems 2》全书核心内容提炼总结 · 上篇](#gpu精粹与shader编程-gpu-gems-2全书核心内容提炼总结-·-上篇)
- [目录 · 本文核心内容Highlight](#目录-·-本文核心内容highlight)
- [前言](#前言)
- [I、核心章节提炼篇](#i核心章节提炼篇)
- [一、实现照片级真实感的虚拟植物（Toward Photorealism in Virtual Botany）](#一实现照片级真实感的虚拟植物toward-photorealism-in-virtual-botany)
    - [【内容概览】](#内容概览)
    - [【核心内容提炼】](#核心内容提炼)
        - [1.1 场景管理（Scene Management）](#11-场景管理scene-management)
            - [1.1.1 种植栅格（The Planting Grid）](#111-种植栅格the-planting-grid)
            - [1.1.2 种植策略（Planting Strategy）](#112-种植策略planting-strategy)
            - [1.1.3 实时优化（Real-Time Optimization）](#113-实时优化real-time-optimization)
        - [1.2 草地层（The Grass Layer）](#12-草地层the-grass-layer)
            - [1.2.1 通过溶解模拟Alpha透明（Simulating Alpha Transparency via Dissolve）](#121-通过溶解模拟alpha透明simulating-alpha-transparency-via-dissolve)
            - [1.2.2 变化](#122-变化)
            - [1.2.3 光照](#123-光照)
            - [1.2.4 风](#124-风)
        - [1.3 地面杂物层（The Ground Clutter Layer）](#13-地面杂物层the-ground-clutter-layer)
        - [1.4 树和灌木层（The Tree and Shrub Layers）](#14-树和灌木层the-tree-and-shrub-layers)
        - [1.5 阴影（Shadowing）](#15-阴影shadowing)
        - [1.6 后处理（Post-Processing）](#16-后处理post-processing)
        - [1.7 业界领先的植物渲染解决方案SpeedTree](#17-业界领先的植物渲染解决方案speedtree)
    - [【核心要点总结】](#核心要点总结)
    - [【关键词提炼】](#关键词提炼)
- [二、GPU通用计算：流式编程与存储体系（General-Purpose Computation on GPU）](#二gpu通用计算流式编程与存储体系general-purpose-computation-on-gpu)
    - [【内容概览】](#内容概览-1)
    - [【核心内容提炼】](#核心内容提炼-1)
        - [2.1 流式计算（Stream Computation）](#21-流式计算stream-computation)
            - [2.2.1 流式编程模型](#221-流式编程模型)
        - [2.2 GPU存储器模型](#22-gpu存储器模型)
            - [2.2.1 存储器体系结构](#221-存储器体系结构)
            - [2.3.2 GPU与CPU元素类比](#232-gpu与cpu元素类比)
            - [2.2.3 GPU流类型](#223-gpu流类型)
                - [1.顶点流（Vertex Streams）](#1顶点流vertex-streams)
                - [2.片段流（Fragment Streams）](#2片段流fragment-streams)
                - [3.帧缓冲区流（Frame-Buffer Streams）](#3帧缓冲区流frame-buffer-streams)
                - [4.纹理流（Texture Streams）](#4纹理流texture-streams)
            - [2.2.4 GPU核的存储器访问](#224-gpu核的存储器访问)
- [II、次核心章节提炼篇](#ii次核心章节提炼篇)
- [三、使用基于GPU几何体裁剪图的地形渲染（Terrain Rendering Using GPU-Based Geometry Clipmaps）](#三使用基于gpu几何体裁剪图的地形渲染terrain-rendering-using-gpu-based-geometry-clipmaps)
    - [【章节概览】](#章节概览)
    - [【核心要点】](#核心要点)
    - [【关键词】](#关键词)
- [四、几何体实例化的内幕（Inside Geometry Instancing）](#四几何体实例化的内幕inside-geometry-instancing)
    - [【章节概览】](#章节概览-1)
    - [【核心要点】](#核心要点-1)
    - [【关键词】](#关键词-1)
- [五、分段缓冲（Segment Buffering）](#五分段缓冲segment-buffering)
    - [【章节概览】](#章节概览-2)
    - [【核心要点】](#核心要点-2)
    - [【关键词】](#关键词-2)
- [六、用多流来优化资源管理（Optimizing Resource Management with Multistreaming）](#六用多流来优化资源管理optimizing-resource-management-with-multistreaming)
    - [【章节概览】](#章节概览-3)
    - [【核心要点】](#核心要点-3)
    - [【关键词】](#关键词-3)
- [七、让硬件遮挡查询发挥作用（Hardware Occlusion Queries Made Useful）](#七让硬件遮挡查询发挥作用hardware-occlusion-queries-made-useful)
    - [【章节概览】](#章节概览-4)
    - [【核心要点】](#核心要点-4)
    - [【关键词】](#关键词-4)
- [八、带位移映射的细分表面自适应镶嵌（Adaptive Tessellation of Subdivision Surfaces with Displacement Mapping）](#八带位移映射的细分表面自适应镶嵌adaptive-tessellation-of-subdivision-surfaces-with-displacement-mapping)
    - [【章节概览】](#章节概览-5)
    - [【核心要点】](#核心要点-5)
    - [【关键词】](#关键词-5)
- [九、使用距离函数的逐像素位移贴图（Per-Pixel Displacement Mapping with Distance Functions）](#九使用距离函数的逐像素位移贴图per-pixel-displacement-mapping-with-distance-functions)
    - [【章节概览】](#章节概览-6)
    - [【核心要点】](#核心要点-6)
    - [【关键词】](#关键词-6)
- [十、S.T.A.L.K.E.R.中的延迟着色（Deferred Shading in S.T.A.L.K.E.R.）](#十stalker中的延迟着色deferred-shading-in-stalker)
    - [【章节概览】](#章节概览-7)
    - [【核心要点】](#核心要点-7)
    - [【关键词】](#关键词-7)
- [十一、动态辐照度环境映射实时计算（Real-Time Computation of Dynamic Irradiance Environment Maps）](#十一动态辐照度环境映射实时计算real-time-computation-of-dynamic-irradiance-environment-maps)
    - [【章节概览】](#章节概览-8)
    - [【核心要点】](#核心要点-8)
    - [【关键词】](#关键词-8)
- [十二、近似的双向纹理函数（Approximate Bidirectional Texture Functions）](#十二近似的双向纹理函数approximate-bidirectional-texture-functions)
    - [【章节概览】](#章节概览-9)
    - [【核心要点】](#核心要点-9)
    - [【关键词】](#关键词-9)
- [十三、基于贴面的纹理映射（Tile-Based Texture Mapping）](#十三基于贴面的纹理映射tile-based-texture-mapping)
    - [【章节概览】](#章节概览-10)
    - [【核心要点】](#核心要点-10)
    - [【关键词】](#关键词-10)
- [十四、动态环境光遮蔽与间接光照（Dynamic Ambient Occlusion and Indirect Lighting）](#十四动态环境光遮蔽与间接光照dynamic-ambient-occlusion-and-indirect-lighting)
    - [【章节概览】](#章节概览-11)
    - [【核心要点】](#核心要点-11)
    - [【关键词】](#关键词-11)
- [十五、精确的大气散射（Accurate Atmospheric Scattering）](#十五精确的大气散射accurate-atmospheric-scattering)
    - [【章节概览】](#章节概览-12)
    - [【核心要点】](#核心要点-12)
    - [【关键词】](#关键词-12)
- [附录：配套资源与源代码下载](#附录配套资源与源代码下载)

<!-- /TOC -->


# 前言

《GPU Gems 2》这本书除了丰富的内容之外，还有两个特点。

- 虚幻引擎之父Tim Sweeney为《GPU Gems 2》作序。作为Epic Games的创始人，Unreal Engine早期主要开发者，Tim也在序中展示了《GPU Gems 2》出版伊始（2005年3月）时开发完成的Unreal Engine 3。UE3可谓是开创了一个时代。随后包括《新鬼泣》在内的100+款大作（2005年~2015年），都是基于UE3开发。具体列表可见：https://en.wikipedia.org/wiki/List_of_Unreal_Engine_games


- 《GPU Gems 2》的中文版是龚大2005年开始翻译的，距今已13年。13年前龚大就已经是图形学业界一线大牛，实在是让人佩服不已。

另外，虽然本书出版于2005年，但可以不夸张地说，书中介绍的很多方法技巧trick，哪怕是放到现在，依然非常值得学习和借鉴。

ok，篇幅原因，开场话就不多说了，放一张本文的核心内容，真实感植物渲染的图，我们就直接开始正题。
![](media/89f9a2729e96f54f189fb6f00ff98822.png)

图 真实感植物渲染 @UE4


<br>


# I、核心章节提炼篇

<br>

# 一、实现照片级真实感的虚拟植物（Toward Photorealism in Virtual Botany）



## 【内容概览】

众所周知，植物的渲染需要很多的视觉深度和细节才能令人信服。

本章即关于渲染逼真自然场景的技术，描述了对实时游戏引擎友好的、用于渲染更真实的自然场景的策略。讲述了在不需要大量CPU或GPU占用的前提下渲染出包含大量植物和树组成的绿色植物场景。

内容安排方面，这章从管理大型户外环境场景数据这一基础开始描述。然后，提供一些细节，例如关于如何最大化GPU吞吐量，以便可以看到密集的草丛。接下来扩展这些技术，增加地面杂物和大型植物，如树，将阴影和环境影响组合进去。

一些真实感植物渲染的效果图：

![](media/e66658a5ca10fc9b5728471d4ffd6fd5.jpg)

图 真实感植物渲染 @UE4

![](media/8da1e9a983bce8f97f98d62fd48e4188.png)

图 真实感植物渲染 @UE4

![](media/996601e8702197b5eb9a68526eeb1c73.png)

图 真实感植物渲染@UE4

## 【核心内容提炼】

### 1.1 场景管理（Scene Management）

任何3D游戏引擎都应该有环境相关渲染技术的管理和组织。

游戏引擎必须管理其渲染技术，以适合于它们希望看到的环境范围。以自然场景为主的游戏由上千棵树，灌木和可能上百万片草叶组成。直接分开渲染会出现数据管理问题，只有解决了这一问题才能以交互的帧率实时渲染。

我们的目标是在一个逼真的室外场景中大范围地移动游戏相机，而不需要在任务管理上花费过多的存储器资源。

#### 1.1.1 种植栅格（The Planting Grid）

场景管理方面，首先是使用了虚拟栅格的思路。

我们在相机周围建立一个世界空间固定的栅格，来管理每一层的植物和其他自然物体的种植数据。每个栅格单元包含渲染它所在物理空间层的所有数据。特别是，单元数据结构存储了对应的顶点、索引缓冲区和材质信息来再现需要绘制的内容。

对植物的每个层，建立相机到层的距离，层需要用它来产生视觉效果，这决定了虚拟栅格的大小。相机移动，虚拟栅格也随之移动。当一个栅格单元不再在虚拟栅格中时，丢弃它，并在需要维护完整栅格结构的地方添加新的单元。在添加每个单元格时，用一种种植算法把渲染所需的数据填充到层。如下图。

![](media/8f2f9167f2775cfd70f2c978ce49ad6f.jpg)

图 一个虚拟栅格

图注：每层有一个世界空间对齐的固定大小的栅格。深绿的单元表现为活动单元。当相机向前移动时，丢弃标记为X的单元，添加新的单元（显示为亮绿色）以维持虚拟栅格的大小，实现过程中有用的改进是使用栅格单元池且循环使用，因为当一个旧单元被丢弃时，总会增加一个新单元。

#### 1.1.2 种植策略（Planting Strategy）

对于充满自然物体的每个单元，需要在地面上选择要放置物体的适当位置。采用试探的方法根据被放置对象的类型来选择这些点。通常，需要的密度随机选点，然后看地面上的对应点是否适合于要种植的东西。而地面多边形的材质决定了一个层是否适用。

最显然的方式是在单元体中随机发射光线，直达地面，每当击中一个多边形，检查它是否适合种植（判断：草能种在这里吗？斜度会不会太大？），如果成功，那么就得到了一个种植点，继续这个过程，直到到达合适的密度。

这种方法不能处理重叠地形，且在少数栅格单元中，可能会花费过多的CPU时间。

比较好的方法是，选择所有与单元相交的多边形，丢弃所有不合适种植的多边形，然后扫描并转换它们来寻找合适的种植点。这与渲染管线中的光栅化一个多边形类似。

#### 1.1.3 实时优化（Real-Time Optimization）

实时优化种植策略的方法包括，选择一个栅格单元中的多边形可以通过使用AABB树或类似的数据结构来快速完成。而由于相机的连续运动，许多单元可能要突然种植，所以它也可以高效地让这个任务排队，使任务在每帧中只占用相对固定的CPU资源。而通过扩大栅格，可以确保在单元的内容进入视野之前，所有的种植就已完成。

### 1.2 草地层（The Grass Layer）

实时渲染出无边的草地需要GPU技术和算法的细心平衡，主要的挑战是在相对低的计算和渲染开销下产生高度复杂的视觉外观。

这章的这一节中介绍了一种和[ Pelzer 2004
]“渲染无数波动的草叶”相似的技术，且这章的技术以更低的GPU和CPU负载产生更高质量和更稳定的结果。

![](media/04e8e2bee126a22e4ae4fa30fe71a1bf.jpg)

图 真实感草地渲染

首先，需要保证批次的最大化。该技术的目标是如何用相对较少的渲染API调用来绘制出尽可能多的草地，合理的方式是基于公告板。但其实更好的方式是在一次绘制调用中渲染尽可能多的内容（即一次draw
call渲染多个公告板）。

为实现这个目的，草的每一层（即使用相同纹理和其他参数的所有草）的每个栅格单元由一个顶点和一个索引缓冲区对表现。如下图。

![](media/a41e3afc06a8bc473d899e62d9257bbf.jpg)

图：绘制每个栅格的单元结构

对种植的每个草丛（或公告板），将其位置写入顶点缓冲区并更新对应的索引缓冲区。每个公告板需要4个顶点和6个索引。对每个顶点，将位置设置为已经种植草丛的点。

一旦顶点缓冲区建立并发送到显存，就可以用单次调用画出每个栅格单元的植物。

与Pelzer的方法不同的是，这里使用面向相机的公告板代替每丛3个方形，而且其方法没有进行屏幕对齐。面向屏幕的公告板在所有的视角下（即便向下看）创建一个固定的深度。而相机越是由上往下看草丛，3个方形丛的方法就越会失效。所以本文提到的方法，更加灵活，适用更多相机角度的情况。

#### 1.2.1 通过溶解模拟Alpha透明（Simulating Alpha Transparency via Dissolve）

在渲染草的时候，想要使用透明来改善视觉混合和在接近虚拟栅格边界时的淡出。然而，基于Alpha的透明并不理想，因为它需要排序且速度很慢。虽然可以利用草较为杂乱的性质最小化一些排序技术，但实际上可以完全忽略这种做法。

为此，采取溶解效应（dissolve effect），也称纱门效应（screen-door
effect）的方法，代替Alpha混合来模拟透明。首先，用一个噪音纹理调制草纹理的Alpha通道，然后使用Alpha测试从渲染中去除像素，通过从0到1调节Alpha测试数值，纹理表现出溶解的现象。这一过程如下图所示。

![](media/ed41e45d2906640097c5db3421fe53aa.jpg)

图 草纹理的构成

（a）漫反射纹理； （b）美工创建的alpha通道； （c）Perlin噪音纹理；
（d）Perlin噪音与Alpha相乘的结果。这可以在像素着色器，或固定的Alpha测试值产生淡出。

这项技术的有点是Alpha测试的速度快而且与顺序无关。我们不再需要排序，草依然可以在远处淡出。虽然溶解在正常的情况下看起来不像真实的Alpha透明那么好，但可以利用自然的分形属性来完全掩饰任何溶解技术的视觉失真。

而实验表明，使用Perlin噪音纹理（Perlin
2002）代替随机的噪音纹理，则溶解效应与环境的适配程度几乎与Alpha透明一样好。

#### 1.2.2 变化

为增加真实感，需引入一些变化。一种方式是使用多种草的图像，但分批方法限制我们在每个绘制调用中只能用一张纹理。好在可以使用大纹理，把多种草排布在上面，在建立顶点的时候，可以调整UV坐标以旋转纹理的不同子区域（即可以建立一个纹理图集）。

每个公告板也能带有颜色信息。如果在种植时也为每个草丛建立一种颜色，那么对渲染灰度纹理或在顶点着色器中做细微的颜色偏移非常有用。Perlin噪声在这里也可以使用，而且很容易，例如，草可以从健康的颜色过渡到垂死的褐色染色，以获得宽广的颜色变化并减少草的重复性。

![](media/8cdea6b4c4d2dc48fea0d9326739933d.jpg)

图 使用RGB信息来增加草地的真实感 @ GeNa @Unity5

![](media/93ca6ad54cad71c2042c8bf40669aceb.jpg)

图 使用RGB信息来增加草地的真实 @ GeNa @Unity5

![](media/49090fe6638902bc41a55a8275982a42.jpg)

图 使用RGB信息来增加草地的真实感 @ GAIA @Unity 5



【注：每颗草的顶点中都包含RGB的信息。在此场景中，颜色值来自Perlin噪声函数，模拟了比较绿的草，并修补了不太健康的褐色】

#### 1.2.3 光照

光照在草的外观上扮演了重要的角色。对于公告板草，要确保草和下面的地面一样受光。而地面自然起伏，并因此获得了不同角度的光照。我们需要通过减弱草的亮度来模拟这点，因此，需要知道草所在的地面角度，一个简单方法是在顶点定义中通过另一个向量传递这一信息。

在种植的时候，确定正在种植的草的多边形法线并把它带入公告板定义中。通过这种方式，顶点着色器就可以进行和草下多边形一样的光照计算、从而减弱它的彩色。在多丘陵的地形上，这会导致草和地面一样也有细微的到光的角度信息变化。

遗憾的是，这种方式导致草有一面一面的着色现象，即使地面的多边形是几乎平滑着色（如Gouraud着色）。为了避免这个问题，在种植处理期间必须平滑地插值通过顶点着色器的法线。

而如果太阳的角度是动态的，可以假设地面法线都大致向上，然后基于此法线和光的角度来计算光照。这样，就不一定要将地面的多边形法线带入顶点的定义和后续计算。这是一个画质的权衡，但这种方式对于应用程序来说已经完全足够。

#### 1.2.4 风

当风吹过，草地泛起涟漪，草变得鲜活起来了。

通过每一帧偏移草方形顶部的两个顶点，可以使方形在风中摇摆。可以使用一个正弦近似的和计算这个偏移，类似计算水表面的波动[Finch
2004]。这个技巧是在顶点定义中带一个混合权重，草方形的顶部两个顶点被设为1，底部两个顶点为0，然后把这一数值乘以风的缩放系数，底部的顶点仍然牢牢地依附在地上。

对于另外的变化，可以在种植期间略微随机变换顶部的两个顶点权重。这模拟了草的软硬区别。

在风中摇曳的时候，草叶时常改变其对光的方向，导致它们变亮或变暗，我们可以使用专门的风项来增加光照变化，以模拟这一现象。这极大地改善了风的视觉效果，甚至也能改善远处草丛的效果，虽然那里的物理摇摆变形以及变成子像素大小了。

然而，不允许风系数使草方形变形太多，否则产生的形变将会显得滑稽而不真实。谨记细微是关键。

### 1.3 地面杂物层（The Ground Clutter Layer）

地面不仅只有随风摆动的草，细枝、小植物、岩石和其他碎片共同组成了具有自然复杂性的效果。其中，一些杂物和草一样可以当做公告板表现。

而但当我们混入混合各种几何对象物体时，环境的复杂度也就增加了。

和处理草公告板的方法一样，对于每个栅格元素，可以把3D网格数据解开到顶点和索引缓冲区中，以使它们可以在单次调用中绘制。我们必须把地面杂物分组为使用相同的纹理和着色器的层。可以像选择种植点那样，应用随机变换来改变它们的大小和方向，但是变换必须依据网格的特性，例如岩石是可以颠倒过来的，但是灌木颠倒就不行了。对于另外的变化，如同处理草多边形一样，可以通过传递RGB信息来给物体染色。

另外，用于处理顺序无关透明特效的溶解技术在3D网格和公告板上工作起来完全一样。把perlin噪声纹理调制到纹理的alpha通道，并使用到相机的衰减距离，然后alpha测试溶解3D网格，类似处理草公告板。

![](media/d85c811d58e5187cf445614dc8d69988.png)

图 使用地面杂物来增加密集的细节\@UE4 \@Landscape Auto Material

![](media/8544048f8a6586cfbb57ce993dc8df9c.jpg)

图 使用地面杂物来增加密集的细节\@UE4

### 1.4 树和灌木层（The Tree and Shrub Layers）

树的树干和主要的树枝应该建模成3D网格。次级树枝可以用公告板来模拟，以增加视觉的复杂性。因为树的枝叶繁茂，所以可以用类似于草的技术，用面向相机的公告板建立树叶丛。

因为树需要在长距离上维护它们的基本体积，但高细节渲染又很昂贵，所以必须使用层次细节（LOD）策略。当树退到一定距离后，可以使用较大但较少的叶丛公告板。对于较大的公告板，使用带有较多但较小树叶的纹理。

而在一个适当的距离之外，最后想要用一个面向相机的公告板表现一颗树。当树的轮廓不对称时，会相对困难。为了避免这个问题，可以为公告板产生树在各种不同角度的图片，然后根据树和相机的角度混合它们。

![](media/841bf927d977d170d5f0d84cbc5a8ab3.png)

图 树的多级LOD与公告板 \@UE4

![](media/568e67e4033f0a64316448f2fe5b2714.png)

图 树的多级LOD与公告板 \@UE4

灌木和叶片可作为另一种类型的树，和普通的树使用相同的技术。例如，一个茂盛的灌木可以看做一棵树干很小，或者不存在树干的树。此外，我们可以翻转一棵树，去掉树叶，并获得一个精心制作的暴露的根系，去嫁接上一棵正常的树。

![](media/4e41bccf539ae7775743a71915dd858b.png)

图 灌木LOD与billboard \@UE4

![](media/eb9fcfe97c4cba0c610e4d4ea21a3140.png)

图 灌木的渲染 \@UE4

### 1.5 阴影（Shadowing）

因为传递了草和地面杂物的RGB颜色，所以可以为阴影的区域选择较暗的颜色。这需要知道植物是否在阴影中。为了在自然环境中有效，这种阴影只需要非常接近正确的阴影即可。

![](media/797d666a9b58c2d3d47893880e8eca5d.jpg)

图 草在树产生的阴影中 \@UE4

![](media/af224ad22b30dbaa0fa4914937ebfb05.png)

图 草在树产生的阴影中 \@UE4 \@Landscape Auto Material

一种方法是在种植时确定阴影。只需从植物位置向主要光源（太阳）投射一道阴影试探光线（shadow
feeler
ray），看看是否有相交。如果有，根据周围场景的环境颜色调整RGB值。记住投射阴影试探光线只考虑是否有相交（不只是最近的），所以其可以比标准的碰撞光线投射高效得多。

软阴影（Soft shadows）,在上下文中叫抗锯齿阴影（antialiased
shadows）其实更合适，可以通过投射一个以上的阴影试探（shadow
feeler）来实现。下图演示了这一方法，通过细微地偏移每道光线的开始位置，在一个给定点上可以进行3\~5次光线投射。击中的部分用来在漫反射太阳光的和场景的环境光之间减弱光照。偏移越宽，阴影就越模糊。

![](media/40f3733de4873b15f5d733bc3445c90f.jpg)

图 使用光线投射的可见性测试

图注：从种植点向光源（在这个例子中是方向光）投射阴影试探光线。几乎发生的任何碰撞都可以表明这个点是在阴影中。为得到一个模糊阴影，需要投射另外的偏移阴影试探光线，并使用击中的部分决定多少环境光的颜色。需要注意的是，不要让阴影试探光线立刻与种植点的地平面相交吗，否则这次试探就没有意义了。

这些阴影不是动态的，但是对于移动缓慢的光源来说，可以很快地在间隔中重新计算（如太阳的移动）。一般来说，它们提供了充分的视觉信息，把风景变得更栩栩如生。

当投过树的大部分时，可以使用树叶茂密部分的球体或树干的圆柱体碰撞。对于树叶茂密部分，使用一个基于树叶茂密的随机函数来确定光线是否相交。虽然这种阴影技术是粗糙的，但和正确的解决方案没有明显的差别。

如果种植是作为离线处理预计算的，那么可以极大地提高阴影逼真度。一种可能比阴影试探光线方法更好的方法是获取光照图（light
map）的纹素来确定阴影。如果光照图不在系统内存中，在实时处理方面可能有困难。

### 1.6 后处理（Post-Processing）

后处理方面，辉光（glow）和泛光（bloom
），以及用高斯（Gaussian）模糊实现自然柔和的效果，都是比较合适进行照片级真实感植物渲染的后处理效果。

![](media/ceb6e7e3a1c2db8d78220b20433a26d5.jpg)

图 使用了多种后处理效果的渲染图 @UE4

![](media/d6f5fcf758bd46d7c1072ed88c86033e.jpg)

图 使用了多种后处理效果的渲染图 @UE4

![](media/63f1635a48edb1b4bb6ca456d2d27531.png)

图 使用了多种后处理效果的渲染图 @UE4

### 1.7 业界领先的植物渲染解决方案SpeedTree

也需要提到的是，SpeedTree是很优秀的树与灌木层的中间件，是植物渲染方面业界领先的解决方案。自2008年以来的各种一线3A游戏，如《蝙蝠侠》、《使命召唤》、《神秘海域》系列，包括近期的《彩虹六号》、《孤岛惊魂5》、《地平线：黎明》、《絶地求生》、《最终幻想15》等游戏，都使用了SpeedTree作为树木植物相关渲染的解决方案。

电影方面，包括最近的《复仇者联盟3》、《黑豹》在内的好莱坞大片，以及早一些的《速度与激情8》《魔兽》《星球大战：原力觉醒》等大片，也都使用了SpeedTree作为树木植物相关渲染的解决方案。

SpeedTree官网：https://store.speedtree.com/

![](media/32a152dc4d4886903745739c829e4af3.png)

图 SpeedTree · CINEMA的宣传图

![](media/b80e73a6bad6f9b460d91e3ef121e6a3.png)

图 SpeedTree · GAME的宣传图

![](media/1b92464b7a254a80459eac04f750e68b.png)

图 电影《星球大战 原力觉醒》中的speed tree @https://www.speedtree.com/starwars.php

## 【核心要点总结】

【场景管理方面】

采用虚拟栅格的思路，实时优化种植的策略是使用AABB树类似的数据结构来选择一个栅格单元中的多边形。

【草地渲染方面】

基于公告板进行渲染，保证渲染批次的最大化、通过溶解模拟Alpha透明。

调整UV坐标以旋转纹理、使用RGB信息等方法来减少重复，增加真实感

草地的光照：多边形法线并把它带入公告板定义中，参与光照计算。滑地插值通过顶点着色器的法线，来解决草有一面一面的着色的现象。也可以假设地面法线都大致向上，然后基于此法线和光的角度来计算光照。

草地与风的交互：使用一个正弦近似的和计算这个偏移，类似计算水表面的波动[Finch
2004]，也可以使用专门的风项来模拟草地因风而出现的光照变化。

【地面杂物层方面】

3D网格结合公告板的渲染、通过溶解模拟Alpha透明。

【阴影方面】

基于阴影试探光线（shadow feeler
ray）、基于树叶茂密的随机函数来确定光线是否相交、基于光照图（light
map）的纹素来确定阴影。

【树与灌木层】

树干和主要树枝建模成3D网格，次级树枝用公告板。LOD。多个角度的公告板混合。

【后处理】

辉光（glow）、泛光（bloom ）、高斯（Gaussian）模糊

最后再上几张渲染图，都来自虚幻4引擎的渲染：

![](media/884517e8ec7d2aef0b5ad1bd7c8e8503.jpg)

![](media/9f4b87b3064801c621bcb3ce2dfe9e76.jpg)

![](media/b952ace0a5917201fb0c6d551ba468ab.png)

![](media/34baace7f0a13911171a220a8609ce34.png)

![](media/3dd03483e84361d405a7570f2df8c088.png)

![](media/1bc80b240f19e0200e0fa47401f7fbb5.png)

![](media/107f5ac68224623ee428576c95850ca3.jpg)

## 【关键词提炼】

真实感植物渲染（Photorealistic Botany Rendering）

场景管理（Scene Management）

<br>

# 二、GPU通用计算：流式编程与存储体系（General-Purpose Computation on GPU）


## 【内容概览】

本节是原书中第IV部分”Part IV: General-Purpose Computation on GPUS: A
Primer”的精华提炼版。

## 【核心内容提炼】

### 2.1 流式计算（Stream Computation）

首先，CPU不适合用于许多高性能应用程序的部分原因是其采用了串行编程模型(serial
programming
model)，无法在应用程序中利用并行性（parallelism）和通信模式（communication
patterns）。而GPU采用了流式编程模型（stream programming
model），本节中将讲到该模式允许高效计算和通信的方式来构造程序[Kapasi et al.
2003]，且它是今天GPU编程的基础。

#### 2.2.1 流式编程模型

在流式编程模型中，所有数据都表现为流（stream）。我们把流定义为具有相同数据类型的数据有序集。数据类型可以是简单的（整数或浮点数流）或复杂的（点或三角形或变换矩阵流）。流可以是任意长度，如果流很长（流中有上百或者更多的元素），那么流上的操作效率将很高。流上允许的操作包括复制，从中导出子流，用一个单独的索引流索引入，以及用核在其上执行计算。

**核（kernel）**操作整个流，获取一个或多个流作为输入并产生一个或多个流作为输出。核的定义特征是它操作多个流上所有元素而不是单个元素。对核最典型的用途是对输入流的每个元素用函数进行求值（“映射（map）”操作）。例如，变换核可以将一个点组成的流（a
stream of
points）中的每个元素投影到一个不同的坐标系中。其他常见的核操作，包括扩展expansions（为每个输入元件产生一个以上的输出元素），缩减reductions（把一个以下元素合并为单个输出元素）以及过滤filters（输出元素的一个子集）。

**核的输出**仅可能是该核输入的函数，并且在核之内，对流元素的计算从不依赖于在其他元素上的计算。这些制约有两个主要好处。首先，当写核（或编译）时，核执行所需要的数据完全已知。因此，当他们的输入元素和中间计算数据储存在局部或是仔细控制的全局引用时，核可以非常高效。其次，在一个核之内对不同的流元素需要独立计算，这运行把看起来像串行核计算的内容映射到数据并行的硬件。

在流式编程模型中，通过把多个核串联在一起来构建应用程序。例如，在流式编程模型中实现图形流水线需要写一个顶点程序核、三角形汇编核、剪切核等，然后把一个核的输出连接到下一个核的输入。下图显示了整个图形流水线是怎样映射到流式模型的。这个模型明确了核之间的通信，利用了图形流水线固有的核之间的数据局部性。

![](media/2022d4e2e744e14b4b69fed706034cf2.jpg)

图 将图形流水线映射成流式模型（Stream Model）
【图形流水线的流式化，把所有数据表达成流（由箭头表明），所有计算表达成核（由框表明）。图形流水线中的用户可以编程和不可编程阶段都可以表达成核。】

图形流水线在几方面都很好地匹配了流式模型。图形流水线传统上被构造为多个计算阶段，由阶段之间的数据流连接。这个结构近似于流式编程模型的流和核的抽象。图形流水线中阶段之间的数据流是高度局部化的，一个阶段产生的数据立刻被下一个阶段所消耗；在流式编程模型中，流在核之间的穿行也显现出相似的行为。而且在流水线的各个阶段所调用的计算在不同的图元之间一般是一致的，使这些阶段很容易映射成核。

### 2.2 GPU存储器模型

#### 2.2.1 存储器体系结构

下图演示了CPU和GPU的存储器体系结构。GPU的存储器系统结构。GPU的存取器建立了现代计算机存储器体系结构的一个分支。GPU与CPU类似，有它自己的cache和寄存器来加速计算中的数据访问。然而，GPU自己的主存储器也有它自己的存储器空间——这意味着在程序运行之间，程序员必须明确地把数据复制入GPU存储器。这个输入传统上是许多应用程序的一个瓶颈，但是新的PCI
Express总线标准可能使存储器在CPU和GPU之间共享在不远的将来变得更为可行。

![](media/b673605c54a03f918c8e0d7372587bd3.jpg)

图 CPU和GPU的存储器体系结构

#### 2.3.2 GPU与CPU元素类比

这一小节将传统的CPU计算概念和它们对应的GPU概念上做一些非常简单的类比总结，以方便更好的理解GPU的概念：

-   流：GPU纹理 = CPU数组 (Streams: GPU Textures = CPU Arrays)

-   核：GPU片段程序 = CPU“内循环” (Kernels: GPU Fragment Programs = CPU "Inner Loops")

-   渲染到纹理 = 反馈 (Render-to-Texture = Feedback)

-   几何体光栅化 = 计算的调用 ( Geometry Rasterization = Computation Invocation)

-   纹理坐标 = 计算的域 (Texture Coordinates = Computational Domain)

-   顶点坐标 = 计算的范围 (Vertex Coordinates = Computational Range)

#### 2.2.3 GPU流类型

与CPU存储器不同，GPU的存储器有一些用法的限制，而且只能通过抽象的图形编程接口来访问。每个这样的抽象可以想象成不同的流类型，各个流类型有它自己的访问规则集。GPU程序员可以看到这样的3种流类型是顶点流、帧缓冲区流和纹理流。第四种流类型是片段流，在GPU里产生并非完全消耗，下图演示了一个现代GPU的流水线，3个用户可以访问的流，以及在流水线中它们可以被用到的地点。

![](media/cbacda9eeb278f040ab2984959338d27.jpg)

图
现代GPU中的流【GPU程序员可以直接访问顶点、帧缓冲和纹理。片段流由光栅器产生，并被片段处理器消耗。它们为片段程序的输入流，但完全是在GPU内部建立和消耗的，所以对程序员来说是不能直接访问的。】

##### 1.顶点流（Vertex Streams）

顶点流通过图形API的顶点缓冲区指定。这些流保存了顶点位置和多种逐顶点属性。这些属性传统上用作纹理坐标、颜色、法线等，但它们可以用于顶点程序的任意输入流数据。

在一开始，顶点程序不允许随机索引它们的输入顶点。在《GPU Gems
2》出版的时候，顶点流的更新还只能通过把数据从CPU传到GPU来完成。GPU不允许写入顶点流。而当时的的API增强已经使GPU可以对顶点流进行写入。这是通过“复制到顶点缓冲区”或“渲染到顶点缓冲区”来完成的。其中，在前一种技术，“复制到顶点缓冲区”中，渲染结果将从帧缓冲区被复制到顶点缓冲区；而在后一种技术“渲染到顶点缓冲区”中，渲染结果直接写入顶点缓冲区。而当时增加的GPU可写顶点流技术，使GPU首次可以把来自流水线末端的结果，直接接入流水线的起始。

##### 2.片段流（Fragment Streams）

片段流由光栅器产生，并被片段处理器消耗。它们是片段程序的输入流，但是因为它们完全是在图形处理器内部建立和消耗，所以它们对程序员来说是不能直接访问的。片段流的值包括来自顶点处理器的所有插值输出：位置、颜色、纹理坐标等。因为有了逐顶点的流属性，传统上使用纹理坐标的逐片段值现在可以使用任何片段程序需要的流值。

需要注意的是，片段程序不能随机访问片段流。因为允许对片段流随机访问，会在片段流之间产生依赖，因此打破了编程模型的数据并行保证。而如果某算法有对片段流进行随机访问的要求，这个流必须首先被保存到存储器，并转换为一个纹理流（texture
stream）。

##### 3.帧缓冲区流（Frame-Buffer Streams）

帧缓冲区的流由片段处理器写入。其传统上被用作容纳要显示到屏幕的像素。然而，流式GPU计算帧缓冲区来容纳中间计算阶段的结果。除此之外，现代的GPU可以同时写入多个帧缓冲区表面（即多个RGBA缓冲区）。

片段或顶点程序都不能随机地访问帧缓冲区的流。然而，CPU通过图形API可以直接对其进行读写。通过允许渲染pass直接写入任意一种类型的流，当时的API已经开始模糊帧缓冲区、顶点缓冲区和纹理的区别。

##### 4.纹理流（Texture Streams）

纹理是唯一一种可以被片段程序和Vertex Shader 3.0
GPU顶点程序随机访问的GPU存储器。如果程序员需要随意地索引入一个顶点、片段或帧缓冲区流，其必须首先将它转换成一个纹理。纹理可以被CPU或GPU读取和写入。GPU通过直接渲染到纹理而非帧缓冲区，或把数据从帧缓冲区复制到纹理存储器来写入纹理。

纹理被声明为1D、2D或3D流，并分别为1D、2D或3D地址寻址。一个纹理也可以声明为一个立方图（cubemap），可以被看做6个2D纹理的数组。

#### 2.2.4 GPU核的存储器访问

顶点和片段程序是现代GPU的两架马车。

顶点程序在顶点流（vertex stream）元素上操作，并将输出送到光栅器（rasterizer）。

片段程序在片段流（fragment streams）上操作，并把输出写入帧缓冲区（frame
buffers）。

这些程序的能力由它们能执行的运算操作和它们能访问的存储器所定义。GPU核中可用的多种运算操作接近于在CPU上可用的操作，然而有很多的存储器访问限制。如同先前描述的，大部分这些限制是为了保证GPU必须的并行性以维持它们的速度优势。然而，其他的限制是进化中的GPU体系结构造成的，有不少已经在目前得到解决。

另一个访问模式是：指针流（pointer streams）[Purcell et al.
2002]。指针流源于可以使用任意输入流作为纹理读取地址的能力。下图演示了指针流是简单的流，其值是内存地址。如果从纹理读取指针流，则这种能力称为依赖纹理（dependent
texturing）。

![](media/0e6062dc305d7dad328235445e987e3d.jpg)

图 用纹理实现指针流

<br>

# II、次核心章节提炼篇

<br>

# 三、使用基于GPU几何体裁剪图的地形渲染（Terrain Rendering Using GPU-Based Geometry Clipmaps）

## 【章节概览】

本章描述了一种通过顶点纹理实现的，基于GPU的几何体裁剪图（Geometry
Clipmaps）技术。通过把地形几何体当做一组图像来处理，可以在GPU上执行几乎所有的计算，因此可以减少CPU的负载。且该技术较为容易实现。

## 【核心要点】

几何裁剪图（Geometry Clipmap）是Losasso 和
Hoppe在2004年提出的，一种新的用于渲染地形层次细节的数据结构。其将地形几何体缓存在一组嵌套规则栅格中，而栅格随着视点的移动而递增。

需要注意，裁剪图以非常特别而有限的方式使用顶点纹理：纹素基本上以光栅扫描的顺序存取，而且与顶点一一对应。

随着视点的移动，裁剪图窗口也会进行移动，并用新的数据更新。为了保证高效的递增更新，每层的裁剪图窗口都以环形方式被访问，即通过2D环绕寻址（2D
Wraparound Addressing）。

文中对此技术在GPU上的实现框架细节进行了详细的交代。

![](media/76289e9886574d37ab1c686fec6a6e2f.jpg)

图
几何体裁剪图的原理。给定一个L层的过滤地形棱锥，几何体剪切图在每个分辨率层缓存一个方形的窗口，从这些窗口提取了一组以视点为中心，具有L个嵌套的“环（ring）”，且最精细的层环是实心的。

![](media/37fd3656cee608dcb54d05ba2e9879c2.jpg)

图
使用粗粒度几何体裁剪图的地形渲染。（n=31，L=10）。每层环由不同的剪切图层构成。

## 【关键词】

地形渲染（Terrain Rendering）

裁剪图（Clipmap）

几何裁剪图（Geometry Clipmap）

环绕寻址（Wraparound Addressing）


<br>  

# 四、几何体实例化的内幕（Inside Geometry Instancing）

## 【章节概览】

本章讨论了在Direct3D中渲染一个几何体的许多独特实例（Instance）的技术细节问题，对几何体实例（Geometry
Instancing）的技术内幕进行了分析。

## 【核心要点】

使用几何体实例（Geometry
Instancing）的优势在于可以对渲染性能进行优化（最小化花费在提交渲染批次上的CPU时间）。

想要使用应用程序最小化状态和纹理变化次数，并在一次Direct3D调用中把统一批次中的同一个三角形渲染多次。这样就能最小化花费在提交批次上的CPU时间。

这章描述了4种不同的技术来实现Geometry Batch：

-   静态批次（Static
    batching）。最快的实例化几何体的方法。每个实例一旦转换到世界空间，则应用它的属性，然后每一帧把已经转换的数据发送给GPU。虽然简单，但静态批次是最不具灵活性的技术。

-   动态批次（Dynamic
    batching）。最慢的实例化几何体的方法。每个实例在每帧都流向GPU存储器，已经转换并应用了属性。动态批次无缝地支持蒙皮并提供了最灵活的实现。

-   顶点常量实例（Vertex constants
    instancing）。每个实例的几何体有多份副本一次复制到GPU存储器中的混合实现。然后实例属性在每一帧通过顶点常量设置，而由于顶点着色器完成几何体的实例化。

-   通过几何体实例化API的批次（Batching with Geometry Instancing
    API）。使用DirectX等图形API提供并支持的几何体实例化，此实现提供了灵活快速的几何体实例化解决方案。与其他方法不同的是，这不需要在Direct3D顶点流中复制几何体包

高效地渲染相同的几何体（静态批次、动态批次、顶点常量实例化，通过几何体实例化API的批次），他们各有优劣，根据应用和渲染的物体类型分别选取。一些建议：

-   有相同几何体的许多静态实例的室内场景，很少或从不移动的实例（比如墙壁或家具），采用静态批次较为理想。

-   有许多动画物体实例的一个室外景物，如策略游戏中有上百个士兵的大战场，在这种情况下，动态批次或许是最好的解决方案。

-   有许多植被和树以及许多粒子系统的室外场景，其中有很多经常需要修改的属性（例如，树和草随风摇摆），几何体实例API可能是最好的解决方案。

![](media/793e100cfc7a336d5c367063417968c5.jpg)

图 在真实场景中将静态批次和几何体实例化结合起来

## 【关键词】

几何体实例（Geometry Instancing）

静态批次（Static batching）

动态批次（Dynamic batching）

顶点常量实例（Vertex constants instancing）

通过几何体实例化API的批次（Batching with Geometry Instancing API）

<br>  

# 五、分段缓冲（Segment Buffering）

## 【章节概览】

本章介绍了一项可以明显减少一个显示帧中渲染的批次数目的技术——分段缓冲（segment
buffering），以及其改进。

## 【核心要点】

分段缓冲（segment
buffering）技术汇集了在场景中彼此靠近的多个实例，把它们合并到“超级实例（über-instances）”中，这样减少了批次的数目，而且提供了解决批次瓶颈问题的一个简单优化的方案。

分段缓冲（segment
buffering）技术自动合并相似的实例，同时保持呈现单独实例的大部分优势。分段缓冲的主要好处在于非重复的外观，以及无需重新绘制原始的实例，就像这部分实例从可见集合中被删除了一样，所以可以明显减少一个显示帧中渲染的批次的数目。而其具体步骤分为三步，原书中有进一步地说明。

而关于分段缓冲（Segment
Buffering）的改进，文章提出了结合自动纹理图集生成（automatic texture-atlas
generation [NVIDIA 2004]）的相关思路。

![](media/4333a11bdd0cd59f176689ac47e84716.jpg)

图 包含同一个物体的多个实例的场景

## 【关键词】

实例化（instance）

批次（batch）

分段缓冲（segment buffering）

超级实例（über-instances）

自动纹理图集生成（automatic texture-atlas generation）


<br>  


# 六、用多流来优化资源管理（Optimizing Resource Management with Multistreaming）

## 【章节概览】

现代实时图形应用程序最困难的问题之一是必须处理庞大的数据。复杂的场景结合多通道的渲染，渲染起来往往会较为昂贵。

首先，多流（Multistreaming）技术由微软在DirectX
8.0中引入。而这章介绍了一种用多流来优化资源管理的解决方案，可以用来处理庞大的数据，且在每个通道中只传输当前需要的顶点分量。

## 【核心要点】

这章介绍了当前的应用程序如何克服由于场景中几何体数据的增加所引起的问题。文中的讨论基于一个使应用程序对数据有更多控制的灵活模型—多流（Multistreaming），

这个方案联合了两项强大的技术，已经在名为Gothic
III的引擎中实现：一些顶点缓冲区通过多流联合，而且所有顶点缓冲区都由一个优化的资源管理器控制。

此方法的好处是：带宽有时可能受限于系统内存和GPU之间的总线，因为传输了重复或多余的数据，而现在此方法为数据有效地控制了带宽。

![](media/3307436d578e783e77f6935a765fc83b.jpg)

图 顶点流的四种类型

G – 用于几何体数据的顶点流。包含顶点位置、法线和(多个)顶点颜色。

T –
用于纹理映射数据顶点流。包含纹理坐标系和附加数据，如正切空间法线映射的正切向量。

A – 用于动画数据的顶点流。包含动画数据，如骨骼权重和相关因素。

I – 用于实例数据的顶点流。 包含顶点流频率实例数据。

而这四种流的子集结合起来可以处理不同的任务，如下图。

![](media/502134e527b1074380adb80327e5fe17.jpg)

图 组合当前需要的流

-   渲染没有动画的网格

可能的流组合： G或者G+T

-   渲染有动画的网格

可能的流组合： G+A或者G+T+A

-   渲染实例的网格（可选包含动画）

可能的流组合：G+I或G+T+I（可选：G+A+I或G+T+A+I）

-   渲染纯的Z通道(可选有或者没有实例，可选有或没有动画)

可能的流组合 G（可选 ：G+A 或 G+I 或 G+A+I）

原文中对上述的思路用DirectX 9.0c进行了实现。

## 【关键词】

资源管理（Resource Management）

多流（Multistreaming）

顶点流（Vertex stream）


<br>  


#  七、让硬件遮挡查询发挥作用（Hardware Occlusion Queries Made Useful）


## 【章节概览】

这章探究了如何最好地应用硬件遮挡查询（Hardware Occlusion
Queries）的思路，介绍了一个简单但强大的算法，其最小化了调用查询的次数，而且减少了由查询结果延迟造成的停滞影响。

## 【核心要点】

遮挡查询作为一个GPU特性，反馈的延迟很高，可以确定一个物体在被渲染之后是否看得见，不像早期的遮挡查询裁剪技术，Michael等人的算法是像素完美的，即此算法没有引入渲染走样，并产生一组最合适的可见物体来渲染，没有把不必要的负载放到GPU上，而且CPU的开销最小。

文中介绍的算法可以解决这些问题。
该算法用前一帧的遮挡查询结果来初始化和调度当前帧的查询，利用了可见性的空间和时间相关性。这通过把场景存储在一个层的数据结构来完成（比如k-d树或八叉树），以从前到后的顺序处理层的节点，渲染某些先前可见的节点来交叉地遮挡查询。

也就是说，该算法几乎可以节省任何在CPU和GPU上等待遮挡查询结果的时间。这是利用时间一致性（temporal
coherence）来实现的，假设正在先前帧可见的物体在当前帧仍保持可见。算法使用层结构来在单次测试中裁剪掉大块被遮挡的区域，减少了遮挡查询的数量，同事也避免了大部分其他内节点的遮挡测试。

![](media/1b35dc4e59118fbd172135badb4dfd4e.jpg)

图 两个连续帧中层次结构节点的可见性

## 【关键词】

硬件遮挡查询（Hardware Occlusion Queries）

时间一致性（temporal coherence）

一致性层裁剪（Coherent Hierarchical Culling）


<br>  

# 八、带位移映射的细分表面自适应镶嵌（Adaptive Tessellation of Subdivision Surfaces with Displacement Mapping）

## 【章节概览】

这章介绍了如何使用可选的位移贴图（Displacement
Mapping）执行Catmull-Clark细分曲面（Catmull-Clark Subdivision
Surfaces）的视图相关的自适应镶嵌（Adaptive
Tessellation）。使用GPU进行镶嵌计算，这可以节省图形总线带宽，并且比使用CPU快许多倍。

## 【核心要点】

文中通过重复细分（repeated
subdivision）的方法来实现镶嵌，通过渲染到2D纹理来实现。细分，平坦度测试（（Flatness
Test））和最终顶点属性计算使用片元着色器（也称像素着色器）完成。该方法假设细分曲面控制网格的顶点数据存储在纹理贴图中。中间结果也渲染到纹理贴图并从纹理贴图读取，并且最终的镶嵌结果（位置，法线等）被渲染到一个顶点数组中，以被渲染图元（render-primitives）如glDrawElements()函数使用。

![](media/4cb9e4f55f54345baf193a7d27e9efff.jpg)

图 对立方体的Catmull-Clark细分

![](media/cf81c02e293590e733309bcc776c7019.jpg)

图 自适应镶嵌（Adaptive Tessellation） vs. 均匀镶嵌（Uniform Tessellation）

总之，这章介绍了一个结合使用广度优先递归（breadth-first recursion
algorithm）细分算法在GPU上镶嵌细分表面的方法。文中描述了执行平坦度测试、实现细分和计算极限表面属性所需的着色器。而且解释了如何修改着色器来添加位移映射的支持，以增加细分表面模型的几何细节。

## 【关键词】

Catmull-Clark细分 （Catmull-Clark subdivision）

位移贴图（Displacement Mapping）

平坦度测试（Flatness Test）

GPU镶嵌（GPU Tessellation ）

自适应镶嵌（Adaptive Tessellation）


<br>  

# 九、使用距离函数的逐像素位移贴图（Per-Pixel Displacement Mapping with Distance Functions）

## 【章节概览】

距离贴图（distance
map）是一种在像素着色器中给对象添加小范围位移映射的技术。这章中详细介绍了使用距离函数的逐像素位移贴图（Per-Pixel
Displacement Mapping with Distance Functions）技术。

## 【核心要点】

这章中提出了距离贴图（Distance Mapping）/距离函数（Distance
Functions）的概念，是一种基于隐式曲面光线追踪的位移映射快速迭代技术（a fast
iterative technique for displacement mapping based on ray tracing of implicit
surfaces）。实际表明，距离函数中包含的信息，允许我们在光线远离表面时前进更大的距离，并保证不会跨得太远以至于在渲染的几何体上产生缝隙。实现的结果非常高效：会在很少的迭代次数内收敛。

文中将位移贴图（Displacement
Mapping）作为光线追踪问题来处理，首先从基础表面上的纹理坐标开始，然后计算观察光线与移动表面相交处的纹理坐标。
为此，文中预先计算了一个三维距离贴图，该贴图给出了空间点和位移表面之间距离的度量。距离贴图为我们提供了与光线快速相交所需的所有信息。
最终，算法在保持实时性能的同时显着增加了场景的感知几何复杂度。

![](media/d3174c6eaeccd2c211a0fb6f18d1af1c.jpg)

图 使用文中所讨论的位移贴图方法渲染出的滤栅。

## 【关键词】

距离贴图（Distance Mapping）

距离函数（Distance Functions）

位移贴图（Displacement Mapping）


<br>  

# 十、S.T.A.L.K.E.R.中的延迟着色（Deferred Shading in S.T.A.L.K.E.R.）

## 【章节概览】

本章是对《S.T.A.L.K.E.R.》中所用渲染器的几乎两年的研究和开发的事后剖析。该渲染器完全基于延迟着色（Derred
Shading）和100%动态光照，目标是高端GPU，因为没有任何一个解决方案可以适合所有需求，所以这章并不是延迟着色的全面指南，但是可以作为一个很好的参考。

## 【核心要点】

延迟着色（Deferred
Shading），虽然并不适合每个游戏，但是确是《S.T.A.L.K.E.R》中的优秀渲染架构。它提供了一个渲染引擎，权衡了现代GPU，比传统的前向着色架构有更低的几何体处理需求，更低的像素处理需求及更低的CPU开销。场景管理器也更干净更简单。一旦避开了延迟着色固有的不足，如多材质系统的潜在限制和缺乏反失真功能，产生的架构既灵活又快速，允许区域很广的效果。

![](media/b2c19e6b54faf091f56980ed4c1091fe.jpg)

图 基于延迟着色实现的渲染效果 @2005年

![](media/66a82c37040045d0c1c31ae82683e73a.jpg)

图 基于延迟着色实现的渲染效果 \@2005年

![](media/1322748b3b1719a88e7b97739a688cda.jpg)

图 基于延迟着色实现的渲染效果 @2005年

## 【关键词】

延迟着色（Deferred Shading）

几何缓冲区（G-buffer）

反走样（Antialiasing）


<br>  

# 十一、动态辐照度环境映射实时计算（Real-Time Computation of Dynamic Irradiance Environment Maps）

## 【章节概览】

环境映射（Environment
Maps）是常用的基于图像的渲染技术，用来表现以空间上不变的球面函数。本章描述了一种完全GPU加速的方法，来生成一个环境映射在图形上特别有趣的类型——辐照度环境映射（Irradiance
Environment maps）。

## 【核心要点】

本技术使应用程序可以在动态环境下（如来自动态关和动态对象的辐射度）快速地模拟复杂的全局光照效果。

辐照度环境映射的渲染非常高效，漫反射只用一次，漫反射+镜面反射只用两次。

![](media/82bda2bfc3ebdd3fc3dd1031c69f7f99.jpg)

图 一个由单个方向光（左）和实时辐照度环境映射（右）照亮的物体

![](media/c135b4f7854a5a36cc313ca4fbcf8014.jpg)

图 辐照度环境映射

（a）一个圣彼得教堂的立方体映射；（b）漫反射结果；（c）镜面映射结果。圣彼得教堂的光照探测。

而通过片元着色和浮点纹理，可以把球面调和卷积映射到GPU上变成简单的两个通道的操作：第一个pass中把光照换行转换成它的球面调和表示，另一个pass把它和反射函数进行卷积并把它转换为空域。且让环境映射的每个面有一个独立的查找表(Lookup
Table)。

![](media/e6d39172c6c96651c542230f730d3ddf.jpg)

图 10-3 将输出系数映射到一个面的分块输入查找表上

## 【关键词】

环境映射（Environment Maps）

动态辐照度环境映射（Dynamic Irradiance Environment Maps）

球面调和卷积(Spherical Harmonic Convolution)


<br>  

# 十二、近似的双向纹理函数（Approximate Bidirectional Texture Functions）

## 【章节概览】

本章介绍的内容关于如何较容易地采集和渲染的真实材质，如布料、羊毛和皮革等的技术。这些材质难以用早先的技术渲染，它们基本来与兼得的纹理映射。本章的目标是在采集上花费少量的努力，在渲染上花费少量的技术，但是仍然达到真实的外观。

## 【核心要点】

本章介绍了一种可以只用少量图像就进行采集和渲染空间变化的复杂材质的方法。这种经验的方法并不是采集真实的BRDF，而是仅仅展示了细微表面的结构如何引起照明的改变：且BRDF在随后使用。而使用这项技术的实时渲染可以容易地实现。

本文的方法以Kautz等在2004年的工作为基础。根据观测，在某种情况下，表面的材质可以通过少许图像采集，产生的结果类似于完整的双向纹理函数（Bidirectional
Texture
Functions,BTF）所达到的。用这个近似的BTF渲染总共只需1对一个简单的着色模型求值，并执行一个对体纹理的查询即可。渲染在图形硬件上很容易达到实时的帧速率，并在多种材质上都达到了引人注目的结果。

![](media/f41c53f4d8672af808057f9b2d0fe4e6.jpg)

图 采集的方法概览。上图：裁剪光的方向不同，视点固定正交的图像，产生一些着色图。下图：对于每张图像，计算平均反射出的辐出度（即平均亮度）。在渲染时，通过一些用户定义的照明模型计算（如Phong）计算r值，并使用该值根据平均亮度，逐片段地查找进入图像栈。最后，用光源的亮度缩放这个值。

![](media/efe24840ae08c3808d1f8340319dc0b6.jpg)

图 羊毛毛衣（a）基于完整的BTF完成（b）基于本文方法。

（a）图是用完整的BTF完成的（6500个图像，用主元分析（Principle Components
Analysis,
PCA）压缩成16个成分）。右图是用本章的技术做的。看得出来主要的差别在一些入射角上。

## 【关键词】

服饰的渲染（Clothing Rendering）

双向纹理函数（Bidirectional Texture Functions，BTF）


<br>  

# 十三、基于贴面的纹理映射（Tile-Based Texture Mapping）

## 【章节概览】

这章介绍了一个基于贴面的纹理映射（Tile-Based Texture
Mapping）系统，用来从一组贴面生成一个大的虚拟纹理。

## 【核心要点】

使用纹理贴面（Texture
Tiling）可以解决纹理过大来带的磁盘空间、系统存储。图像存储瓶颈等各种问题。

如下图，如果有重复的贴面组成的大墙壁或地板，显然不需要存储所有的贴面。相反，可以只存储一个贴面，然后在墙上重复它。对于更复杂的模式，可以把墙壁或地板切成较小的多边形，并对每个多边形应用不同的纹理贴片或纹理坐标变换。这种方法的有点是在理论上可以达到无限的压缩率，因为可以从少量贴面产生出一个任意打的输出。缺点是，应用程序代码和数据比较复杂。

![](media/a258ae10f30d67c444b8aaad95766e58.jpg)

图
基于贴面的纹理。左图：给定以小组输入纹理贴图（左），系统在不需要存储整个纹理的情况下可以提供大的虚拟纹理图（右），这种方法支持本地硬件纹理过滤，而且不需要修改应用程序的几何体或纹理坐标。

![](media/0c41e91f86197929ea2bfd451333fc88.jpg)

图
基于贴图的纹理映射的概览。左图：打包的输入贴面。右：输入的虚拟纹理。给定一个纹理请求（s，t），先确定请求的是哪个贴面，然后算法从输入贴面中获取相应的纹素。

## 【关键词】

纹理映射（Texture Mapping）

基于贴面的纹理映射（Tile-Based Texture Mapping）

纹理贴面（Texture Tiling）


<br>  

# 十四、动态环境光遮蔽与间接光照（Dynamic Ambient Occlusion and Indirect Lighting）

## 【章节概览】

这章在讲大家很熟知的环境光遮蔽（Ambient Occlusion , AO）。

文中的描述是，介绍了一种用于计算散射光传递的新技术，并演示如何用它来计算运动场景中的全局光照。主要是一种用GPU加速环境光遮蔽计算的技术，并将此算法变成了实时的解决方案。

## 【核心要点】

这章介绍的这项技术效率很高，可以实现在渲染每帧时即时计算环境光遮蔽和间接光照数据。其并没有预计算辐射传递（Precomputed
Radiance Transfer ，PRT）或预计算环境光遮蔽技术存在的限制。

![](media/0c3a47c39852e77246b1f98c9fa341d7.jpg)

图 通过环境光遮蔽和间接光照增加真实感

图注：左边的场景只用环境光，看起来很平面化。中间的场景用环境光遮蔽加模糊阴影，右边的场景增加的间接光照，感觉格外真实。

这章的技术通过把多边形网格看做一些可以发出、传播或反射光的元素，并且可以互相产生阴影的表面元素集合来工作。此方法效率很高，因为它不需要计算一个元素到另一个元素的可见性，而是用一种更简单而且更快的技术——基于近似投影的方法——来处理遮挡的几何体。

## 【关键词】

环境光遮蔽（Ambient Occlusion, AO）

间接光照（Indirect Lighting）


<br>  

# 十五、精确的大气散射（Accurate Atmospheric Scattering）

## 【章节概览】

生成真实大气散射的效果一直是计算机图形学领域的难题。描述大气的散射方程式非常复杂，以至于可以用整本书去解决这个课题。计算机图形模型通常使用简化的方程，这些模型中只有少数可以以交互速率运行。

这章介绍如何实现一个完全运行在GPU上的大气散射实时算法（原始算法由Nishita等人在1993年提出），并提供了实现此算法的全部CG和GLSL源代码。

## 【核心要点】

这章解释了如何在GPU着色器中实现Nishita等人在1993年提出的散射方程，并以可交互的速率运行。这些方程能更加精确地对大气建模，保证当高度降低的同时密度也呈指数级降低。且可以在不需要牺牲图像质量同时省略查找表，着色器代码足够小而快，可以在一个GPU着色器中实现整个算法。

一个重要的细节是怎样模拟大气中一个点的散射（Scattering）。最常见的两种大气散射形式是瑞利散射（Rayleigh
Scattering）和米氏散射（Mie Scattering）。

瑞利散射（Rayleigh
Scattering）是由空气中的小分子引起的，而且它对波长端的光散射更强（最先是蓝色，然后是绿色和红色）。

米氏散射（Mie
Scattering）由空气中更大一些的粒子引起，这些粒子被称为浮尘（aerosols），如灰尘（dust）或污染物（pollution）。

章节构成方面，这章一开始用一定的篇幅进行了散射方程的求解和简化，最终得到的实现在原本的大气散射模型上进行了不少简化，以至于最终的实现可以在对硬件要求不高的前提下，达到交互的速率进行渲染。并且采用了高范围动态（HDR）渲染，得到了更好的大气散射效果。

![](media/d398916378dc464ce8113f698a8f9f66.jpg)

图 散射Demo的截图

## 【关键词】

大气散射（Atmospheric Scattering）

瑞利散射（Rayleigh Scattering）

米氏散射（Mie Scattering）

高范围动态渲染（High-Dynamic-Range Rendering）



<br>  


# 附录：配套资源与源代码下载

这里提供了一些，《GPU Gems 2》书本的配套资源，以及源代码的下载地点。

PS:配套的不少工程中不仅包含完整的源码，也直接包含经过编译后的exe执行文件，可以直接运行后查看效果。

-   《GPU Gems 2》全文的Web版本：https://developer.nvidia.com/gpugems/GPUGems2/gpugems2_inside_front_cover.html

-   我维护的一个名为“GPU-Gems-Book-Source-Code”的GitHub仓库，以备份《GPU
    Gems》系列书籍相关的珍贵资源，《GPU Gems
    2》的随书CD和源代码可以在这里下载到：
https://github.com/QianMo/GPU-Gems-Book-Source-Code

 - 本文的知乎专栏版本：https://zhuanlan.zhihu.com/p/38411575



```

`Content/《GPU Gems 2》全书提炼总结/Part2/README.md`:

```md
![](media/title.jpg)


# 【GPU精粹与Shader编程】《GPU Gems 2》全书核心内容提炼总结 · 下篇

本文的知乎专栏版本：
https://zhuanlan.zhihu.com/p/40288273

本文核心内容为《GPU Gems 2》中讲到的真实感水体渲染，以及真实感头发渲染、通用的折射模拟、改进的Perlin噪声等次核心内容。



# 快捷导航目录
<!-- TOC -->

- [【GPU精粹与Shader编程】《GPU Gems 2》全书核心内容提炼总结 · 下篇](#gpu精粹与shader编程gpu-gems-2全书核心内容提炼总结-·-下篇)
- [快捷导航目录](#快捷导航目录)
- [前言](#前言)
- [I、核心章节提炼篇](#i核心章节提炼篇)
- [一、将顶点纹理位移用于水的真实感渲染（Using Vertex Texture Displacement for Realistic Water Rendering）](#一将顶点纹理位移用于水的真实感渲染using-vertex-texture-displacement-for-realistic-water-rendering)
    - [【章节概览】](#章节概览)
    - [【核心要点】](#核心要点)
        - [1.1 水体渲染模型的分析](#11-水体渲染模型的分析)
        - [1.2 实现思路概览](#12-实现思路概览)
        - [1.3 水体的表面模拟](#13-水体的表面模拟)
        - [1.4 实现细节概述](#14-实现细节概述)
        - [1.5 对高度图采样](#15-对高度图采样)
        - [1.6 提高渲染质量与优化性能的一些方案](#16-提高渲染质量与优化性能的一些方案)
            - [1.6.1 为双线性过滤打包高度值](#161-为双线性过滤打包高度值)
            - [1.6.2 使用分支避免不需要的工作](#162-使用分支避免不需要的工作)
            - [1.6.3 使用渲染到纹理策略（Render-to-Texture）](#163-使用渲染到纹理策略render-to-texture)
            - [1.6.4 处理波浪的背面](#164-处理波浪的背面)
        - [1.7 渲染局部扰动的策略](#17-渲染局部扰动的策略)
            - [1.7.1 解析型形变模型（Analytical Deformation Model）](#171-解析型形变模型analytical-deformation-model)
            - [1.7.2 动态位移贴图（Dynamic Displacement Mapping）](#172-动态位移贴图dynamic-displacement-mapping)
            - [1.7.3 泡沫的生成（Foam Generation）](#173-泡沫的生成foam-generation)
    - [【核心要点总结】](#核心要点总结)
        - [1.提高渲染质量与优化性能的方案](#1提高渲染质量与优化性能的方案)
        - [2.渲染局部扰动的策略](#2渲染局部扰动的策略)
    - [【配套源代码】](#配套源代码)
- [【关键词】](#关键词)
- [II、次核心章节提炼篇](#ii次核心章节提炼篇)
- [二、利用像素着色器分支的高效模糊边缘阴影（Efficient Soft-Edged Shadows Using](#二利用像素着色器分支的高效模糊边缘阴影efficient-soft-edged-shadows-using)
    - [【章节概览】](#章节概览-1)
    - [【核心要点】](#核心要点-1)
    - [【关键词】](#关键词-1)
- [三、通用的折射模拟（Generic Refraction）](#三通用的折射模拟generic-refraction)
    - [【章节概览】](#章节概览-2)
    - [【核心要点】](#核心要点-2)
    - [【关键词】](#关键词-2)
- [四、快速三阶纹理过滤（Fast Third-Order Texture Filtering）](#四快速三阶纹理过滤fast-third-order-texture-filtering)
    - [【章节概览】](#章节概览-3)
    - [【核心要点】](#核心要点-3)
    - [【关键词】](#关键词-3)
- [五、高质量反走样的光栅化（High-Quality Antialiased Rasterization）](#五高质量反走样的光栅化high-quality-antialiased-rasterization)
    - [【章节概览】](#章节概览-4)
    - [【核心要点】](#核心要点-4)
    - [【关键词】](#关键词-4)
- [六、快速预过滤线条（Fast Prefiltered Lines）](#六快速预过滤线条fast-prefiltered-lines)
    - [【核心要点】](#核心要点-5)
    - [【关键词】](#关键词-5)
- [七、Nalu Demo中的头发动画与渲染（Hair Animation and Rendering in the Nalu Demo）](#七nalu-demo中的头发动画与渲染hair-animation-and-rendering-in-the-nalu-demo)
    - [【章节概览】](#章节概览-5)
    - [【核心要点】](#核心要点-6)
    - [【关键词】](#关键词-6)
- [八、使用查找表加速颜色变换（Using Lookup Tables to Accelerate Color](#八使用查找表加速颜色变换using-lookup-tables-to-accelerate-color)
    - [【章节概览】](#章节概览-6)
    - [【核心要点】](#核心要点-7)
    - [【关键词】](#关键词-7)
- [九、实现改进的Perlin噪声（Implementing Improved Perlin Noise）](#九实现改进的perlin噪声implementing-improved-perlin-noise)
    - [【章节概览】](#章节概览-7)
    - [【核心要点】](#核心要点-8)
    - [【关键词】](#关键词-8)
- [十、高级高质量过滤（Advanced High-Quality Filtering）](#十高级高质量过滤advanced-high-quality-filtering)
    - [【章节概览】](#章节概览-8)
    - [【核心要点】](#核心要点-9)
    - [【关键词】](#关键词-9)
- [十一、Mipmap层级测定（Mipmap-Level Measurement）](#十一mipmap层级测定mipmap-level-measurement)
    - [【章节概览】](#章节概览-9)
    - [【核心要点】](#核心要点-10)
- [【关键词】](#关键词-10)
- [附录：配套资源与源代码下载](#附录配套资源与源代码下载)

<!-- /TOC -->




# 前言


之前和同事们讨论水体渲染时，大家说到目前业界水体实时渲染效果领先的游戏引擎，是Cry
Engine。Cry
Engine中的水体渲染可谓目前水体渲染方案中的集大成者，汲取了图形业界近几十年水体渲染各种思路的精华。以下是Cry
Engine 中的水体渲染实时画面：

![](media/bc62ed5fc450feac5ad3ccff76d70785.jpg)

视频链接：<https://www.youtube.com/watch?v=tZthI6M07iM>

注意这是6年前Cry Engine 3的水体渲染实时画面，很多人感觉其效果已经近乎真实。

而目前的Cry Engine 5，渲染质量还会更胜一筹。

值得开心的是，Cry Engine 5已经开源，其水体渲染的具体shader实现代码可以在Cry Engine源码中找到，以下是其中Water.cfx源码传送门，感兴趣的朋友不妨了解一下：

<https://github.com/CRYTEK/CRYENGINE/blob/26524289c15a660965a447dcb22628643917c820/Engine/Shaders/HWScripts/CryFX/Water.cfx>

值得注意的是，本文中提到的一些渲染水体的策略与思路，在Cry Engine 5实现水体渲染中，也有所体现。

OK，下面开始正题。






# I、核心章节提炼篇


# 一、将顶点纹理位移用于水的真实感渲染（Using Vertex Texture Displacement for Realistic Water Rendering）


## 【章节概览】

真实地表现水的质感是一个困难的问题，因为水表面的运动具有高度的视觉复杂性，且水的光影效果也很复杂。而这章中，介绍了为游戏《太平洋战机》开发的对海水的真实感渲染技术。

![18_vertex_texture_05.jpg](media/00de2d88f9609d8a39ecd22b3a01045d.jpg)

图 《太平洋战机》中的海水渲染

## 【核心要点】

### 1.1 水体渲染模型的分析

Gems2中这篇文章问世期间（2005年），当时最真实的水体渲染实现方法是基于流体动力学和快速傅里叶变换（FFT）（[Tessendorf
2001]）,但遗憾的是这种方法需要大量的计算，不适用于交互应用程序。

大多数游戏当时使用的是很简单的水模型，而其中的大多数采用了法线贴图来生成视觉细节，优点是计算量小，缺点是很多时候不能提供足够的真实感，并且不能真实重现水面的波浪。

而本文中介绍了一种能达到简单法线贴图方法的速度，但渲染质量类似于FFT方法的水面渲染技术。

### 1.2 实现思路概览

本文的水体渲染主要实现思路是基于法线贴图计算光照的渲染算法。因为法线图在高频的波浪中能够真实地产生精细的细节，所以将它用于光照的计算。除此之外，还对水模型的几何表面做了大振幅低频波浪的扰动。

### 1.3 水体的表面模拟

水体表面的模型是基于几张高度图（Height maps）的叠加，这些高度图在空间和时间上不断重复。每张纹理表示一个“谐波（harmonic）”或“倍频（octave）”频谱，然后这些纹理被叠加到一起，类似傅里叶分析中的做法。

而这些纹理之所以称为高度图，因为其中每个值代表了对应点相对于水平面的高度值。高度图对于美术同学来说创建非常容易，与创建和渲染灰度图一样简单。利用高度图，水的动画参数规约成一些独立的波，美术同学只要绘出它们的形状就可以很容易地控制水的动画。高度图也对顶点纹理有用：因为可以很容易地对顶点进行竖直方向的位移。

![](media/4ca98d3d9a52795483a997a9304b8779.jpg)

图18-2 一张用于水面位移的高度图

通过用不同的空间和时间范围来结合若干高度图，可以得到视觉上非常复杂的动画：

![](media/0c2737c4173d96953f6157eb2a71682b.jpg)

系数A和B以及求和的项数是由经验决定的，以求达到美学角度上最好的结果，同时减少重复图案的痕迹。在《太平洋战机》中，叠加4张高度图用于计算光照，其中最大范围的两张用于位移贴图。这对模拟动态的海洋表面来说已经足够了，可选范围为10cm到40km（10厘米到40千米）之高。

### 1.4 实现细节概述

可以把所有需要实现的计算分为两部分：

-   几何位移计算

-   光照计算

因为水面细分得很精细，所以可以只在片段程序级实现光照计算，而把位移映射的工作移交给顶点级，以减轻片段的负担。需要注意，如果在顶点级实现光照计算可能产生明显的走样，尤其是远处的物体。

### 1.5 对高度图采样

文中的实现是在每个顶点上对高度图进行采样，并且在顶点程序中计算应该取的位移值。为了计算采样，使用了一个中心在相机位置的径向栅格（radial
grid）。这个栅格的细分特点是离视点越近则提供越多的细节，如下图所示

![](media/081c4e549906e1c0393e4e5d9a42618a.jpg)

下面的方程表示了径向栅格上的顶点位置的计算方法：

![](media/08c50752a601cae32563f8bb6237f79a.png)

其中，i=[0..N - 1], j = [0..M - 1]。选择a0，a1，使

![](media/3d4800850db5960c938aceb3093539a2.png)

使用这种方法，可以得到根据距离细分的栅格，也体现了一个简单的层次细节LOD策略。其他方案，如ROAM或SOAR地形渲染算法，也可以用于此处，但是它们需要在CPU上进行大量计算，会减弱使用顶点纹理的优势。而我们也可以尝试在GPU中渲染自适应镶嵌栅格的高度域。

下面的代码列出了着色器的实现细节，用一个径向栅格对单张高度图进行采样。

    float4 main(float4 position : POSITION,
    uniform sampler2D tex0,
    uniform float4x4 ModelViewProj,
    uniform float4 DMParameters, // displacement map parameters
    uniform float4 VOfs) : POSITION
    {
        // Read vertex packed as (cos(), sin(), j)
        float4 INP = position;

        // Transform to radial grid vertex
        INP.xy = INP.xy * (pow(INP.z, 4) * VOfs.z);

        // Find displacement map texture coordinates
        // VOfs.xy, DMParameters.x - Height texture offset and scale
        float2 t = (INP.xy + VOfs.xy) * DMParameters.x;

        // Fetch displacement value from texture (lod 0)
        float vDisp = tex2D(tex0, t).x;

        // Scale fetched value from 0..1:
        // DMParameters.y - water level
        // DMParameters.z - wavy amplitude
        INP.z = DMParameters.y + (vDisp - 0.5) * DMParameters.z;

        // Displace current position with water height
        // and project it

        return mul(ModelViewProj, INP);
    }

### 1.6 提高渲染质量与优化性能的一些方案

#### 1.6.1 为双线性过滤打包高度值

访问顶点纹理的代价十分昂贵，在旧的GeForce 6系列的硬件上，一个顶点纹理的访问会在顶点程序中产生明显的延迟。所以比较合适的策略是把顶点程序中访问纹理的次数降到最低。另一方面，过滤纹理值非常必要，否则图像质量就会显著降低。

为了减小插值时纹理访问的次数，可以用一种特别的方法创建纹理，这样使每个纹理包含了一次双线性纹理查找必需的所有数据。因为高度图本质上是单通道的纹理，可以把四个高度值打包到一张四通道纹理的一个纹素内，以实现优化。

#### 1.6.2 使用分支避免不需要的工作

即使使用了优化的纹理过滤，渲染水体时，访问纹理的次数仍然很高，这会严重影响性能。一种方法是减少渲染的顶点数，但是这将全面地降低视觉上的细节并且增加失真度。

需要渲染的水体含有大量的几何数据，但其中有些三角面完全在屏幕之外。对这样的三角形，顶点程序仍然要进行处理，这其实是一种浪费。如果能跳过在相机视野之外三角形的相关计算，就可以在每个顶点上节约大量的工作。

以下的伪代码表达了这个方法的实现：

    float4 ClipPos = mul(ModelViewProj, INP);
    float3 b0 = abs(ClipPos.xyz) < (ClipPos.www * C0 + C1);
    if (all(b0))
    {
        // Vertex belongs to visible triangle,
        // Perform texture sampling and displace vertex accordingly
    }

在上面的代码中，使用了裁剪空间的顶点位置来确定当前的顶点是否位于视野之中，然后只对需要的顶点进行复杂运算即可。

#### 1.6.3 使用渲染到纹理策略（Render-to-Texture）

仍然可以使用上文提到的，用一张浮点纹理来压缩存储高度纹理的方法，先将其作为单独的pass来执行，以提高运行速度。而在顶点着色器里面实现多次昂贵的插值操作就变得没有太多必要。另外，可以用一个更紧凑的16位浮点纹理格式来存储原始的高度图。也可以存储一系列高度图序列帧作为三维纹理的切片，以使动画更加流畅。

经过上述优化，我们的渲染循环变成了如下两个pass：

（1）通过使用将单个四边形渲染为32位浮点纹理的特殊像素着色器，来组合高度贴图。而此纹理中的各个纹素映射到径向栅格的各个顶点。

（2）使用生成的高度贴图作为顶点纹理来平移径向栅格顶点。

#### 1.6.4 处理波浪的背面

大量的光照计算是在像素着色器中实现的。其假设了水面是水平的，而这个假设在某些情况下可能导致视觉效果的走样。

在下图所示的情况下，我们看到了波浪的背面，它在平面上是能被看见的，但是因为几何位移的关系它会背向观察者，所以在现实世界中并不应该出现。而这样的错误会在波浪的顶部产生奇怪的过亮区域。

![](media/2ad3c092f8e9bc9267235319bf6a33c4.jpg)

图 渲染走样的产生

图注：波浪（绿色）的背面也可能被渲染出来，尽管它并不应该出现。调整计算光照的法线将大大减少这种错误。

为了尽量减少这种错误，可以将计算光照时使用的法线稍微做调整，将他们朝向观察者方向“倾斜”一些，这样他们会更接近于波浪的正向面。

### 1.7 渲染局部扰动的策略

有时渲染渲染因为浮起物或者掉入水中的物体引起的波浪局部的起伏。这对游戏来说尤为重要，因为游戏需要产生类似于爆炸，船的行进痕迹等效果。因为很难继承物理上正确的方法将其用于这个基于高度图的水面模型中来，所以这里只根据经验讨论一些简单的方法。

#### 1.7.1 解析型形变模型（Analytical Deformation Model）

造成局部波浪起伏最简单的方法是把顶点的位移值做成一个解析上的扰动，把扰动和顶点着色器中计算好的顶点位置结合起来。

实现局部波浪起伏最简单的方法是通过将顶点位移与顶点着色器中计算的顶点位置相结合，来解析地扰动位移的顶点位置。对爆炸而言，可以用下面的公式：

![](media/30b0ec752eee991f30ffb2b4b69e8cf5.jpg)

其中，r是水平面上该点到爆炸中心的距离，b是一个常数，I_0，ω和k的值根据一个给定的爆炸及其参数决定。

在渲染时，可以使用和普通水体渲染时相同的径向栅格，尤其是在爆炸点。

#### 1.7.2 动态位移贴图（Dynamic Displacement Mapping）

另一个选择是将所有的局部创建的位移量直接渲染到顶点纹理，本质上是和GPU通用编程（GPGPU）类似的方法。这样，在第一个pass中生成顶点纹理，而在后续pass中，用此纹理来进行实际的水体渲染。另一个好处是，通过在像素着色器中过滤基础高度图和累加倍频程（octaves），可以把一些工作从顶点着色器转移到像素着色器中。

为了计算位移量，既可以采用前面提到的解析型模型，也可以用自动控制单元（cellular-automata）的方法，将局部位移进行逐帧衍变。也可以考虑风的效果，对纹理沿着适当的方向进行模糊。

![](media/eff130f1711a206311827e1d0d5cb51c.jpg)

图 用位移贴图渲染的水表面（左）和不用位移图渲染的水表面（右）对比

#### 1.7.3 泡沫的生成（Foam Generation）

在波浪足够强时，可以通过制造泡沫来加强真实感。最简单的方法是把一个预先创建的泡沫纹理在高于某一高度H0的顶点上进行混合。泡沫纹理的透明度根据以下公式进行计算：

![](media/345ebd12e79d64c1f48d9fd75ef2e416.jpg)

其中，H_max是泡沫最大时的高度，H_0是基准高度，H是当前高度。

泡沫纹理可以做成动画来表示泡沫的产生和消失的进化过程。这个动画序列既可以由美术同学制作，也可以由程序生成。

## 【核心要点总结】

本文的水体渲染实现思路是基于法线贴图计算光照的渲染算法，水体表面的模型为基于几张高度图（Height maps）的叠加。在每个顶点上对高度图进行采样，并且在顶点程序中计算应该取的位移值。计算采样方面，使用了一个中心在相机位置的径向栅格（radial grid），以及结合了一些优化的思路。

### 1.提高渲染质量与优化性能的方案

1.为双线性过滤打包高度值:
因为高度图本质上是单通道的纹理，可以把四个高度值打包到一张四通道纹理的一个纹素内，以实现优化。

2.使用分支避免不需要的工作：使用裁剪空间的顶点位置来确定当前的顶点是否位于视野之中，然后只对需要的顶点进行复杂运算即可。

3.使用渲染到纹理策略（Render-to-Texture）

4.处理波浪背面：将计算光照时使用的法线稍微做调整，将他们朝向观察者方向“倾斜”一些，这样他们会更接近于波浪的正向面。

### 2.渲染局部扰动的策略

1.解析型形变模型（Analytical Deformation Model）

2.动态位移贴图（Dynamic Displacement Mapping）

3.泡沫的生成：预先创建的泡沫纹理在高于某一高度H0的顶点上进行混合，其中泡沫纹理的透明度根据公式进行计算。

## 【配套源代码】

<https://github.com/QianMo/GPU-Gems-Book-Source-Code/tree/master/GPU-Gems-2-CD-Content/Shading_Lighting_and_Shadows/Ch_18_Using_Vertex_Texture_Displacement_for_Realistic_Water_Rendering>

具体shader代码位于fpWaterDM.cg，vpWaterDM.cg两个文件中。其中也提供了可运行的demo
exe，其运行效果如下：

![](media/1.gif)


![](media/5504321a0537a5f5a44a95fe6bca913b.png)


# 【关键词】

水渲染（Water Rendering）

顶点纹理位移（Vertex Texture Displacement）

高度贴图（Height Mapping）

双线性过滤（Bilinear Filtering）


# II、次核心章节提炼篇


# 二、利用像素着色器分支的高效模糊边缘阴影（Efficient Soft-Edged Shadows Using
Pixel Shader Branching）

## 【章节概览】

在计算机图形学中，渲染真实的阴影一直是难题之一，尤其是软阴影（soft
shadow）的渲染。且阴影是一种非常重要的视觉信息，它们有助于确立场景中物体的空间相对关系。

这章介绍了一种通过片段着色器中的PCF技术达到的实时渲染模糊（软）边界阴影的快速方法。

## 【核心要点】

文中首先讲到阴影渲染技术中最常见的两种流派模板阴影/阴影体（Stencil Shadow
/Shadow volume）和阴影贴图（Shadow Map）。

两种方法都各有其优缺点。且提到了这两种方法都不能直接用于“超出框”的模糊边界阴影。

随后这章介绍了一种以交互速率渲染模糊阴影的方法，其能高质量地模拟真实的模糊阴影。该方法使用了百分比邻近过滤（Percentage-Loser
Filtering,
PCF）技术，在片段着色器中不断对阴影图自适应地多次采样。这章自适应的采样方法与采样方法与采样数固定的方法相比，能在保证高性能的同时提高画面质量。

![](media/8a3ea2ee7d535d5fd67543cb96e0f739.jpg)

图 基于文中方法实时渲染出的模糊边缘阴影

## 【关键词】

软阴影（Soft Shadows）

模糊边缘阴影（Soft-Edged Shadows）

模板阴影/阴影体（Stencil Shadow /Shadow volume）

阴影贴图（Shadow Map）。

百分比邻近过滤（Percentage-Loser Filtering, PCF）

# 三、通用的折射模拟（Generic Refraction）

## 【章节概览】

本章介绍了一种折射的实现方案，思路是对场景中非折射的物体生成一幅图像，把该图像当做纹理，然后对查找该纹理的坐标进行扰动来达到模拟折射的目的。这种技术效率很高，而且很多情况下都有效。

## 【核心要点】

折射（Refraction）是当光从一种媒介穿到另一种折射率不同的媒介（如从空气到水，从空气到玻璃等）时产生的弯曲现象。

要模拟折射有很多种方法：其中一些方法是先预计算环境映射，然后在运行时使用；而其他方法是直接在运行时计算环境映射。这些技术的缺点是耗费大量的纹理存储空间并损失运行效率，尤其是当场景中有很多折射表面时，需要不同的环境映射。

而目前的水折射模拟技术的另一个问题是他们需要渲染两遍：第一个pass通过水面上的几何信息来生成折射图，另一个pass渲染水面。这种方案的性能很低，尤其对复杂的场景而言。

本章介绍了一种简单的技术来克服这些问题。从介绍基本想法开始，把现有的后台缓存当做一个折射贴图来用，并且通过对纹理坐标进行位移来模拟折射的效果。最基本的实现可能导致走样，因此文中讨论了如何将几何图形从折射图贴图中标注出来。最后演示了一些用该方法渲染真实的水和玻璃的通用技术。

![](media/47c6125108e26fc58592a933071a938a.jpg)

图 彩色玻璃的渲染步骤（a）折射 （b）环境凹凸映射 （c）最终的合成

这章给出的模拟折射的方法，虽然不是基于物理的，但是能得到质量很好的结果，且速度非常快。

但此方法的缺陷是，当应用到不同颜色的折射表面上时，在表面重叠的地方会得到不正确的结果。只要折射表面的颜色相近，结果看上去就是正确的。一个正确的解决方案就是，对折射网格从后到前进行排序，然后每次渲染一个折射网格时都更新一次折射图。或者用另一个不够准确的方案，对折射网格从后到前进行排序，在用alpha混合来渲染它们。

## 【关键词】

折射（Refraction）

水的渲染（Water Rendering）

玻璃的渲染（Glass Rendering）

# 四、快速三阶纹理过滤（Fast Third-Order Texture Filtering）

## 【章节概览】

对可编程图形硬件可以在使用片段着色器上使用通用的卷积过滤器来实现高质量的纹理过滤，如立方（cubic）过滤器（Bjorke
2004）。这些方法通常有许多缺点：它们需要进行多次纹理采样，而且无法对mipmap的纹理进行反失真处理。

而在本章中，介绍了一种能有效减少三阶纹理过滤需要输入的纹理数量的方法，使用了1D、2D及3D空间中的三次B样条（B-spline）曲线的卷积核和它的一阶、二阶导数来解决这些过滤问题。

## 【核心要点】

高阶纹理过滤的主要性能瓶颈是需要大量的纹理采样作为输入。通常是通过对输入纹理进行重复最近邻近（Repeated
Nearest-Neighbor）采样实现。为了减少采样的次数，基于线性采样来建立过滤器，这种方法能大量减少纹理采样的次数，尤其是2D和3D过滤。特别是能通过8次三线性纹理采样来完成一个需要64次累加操作的三立方（tricubic，也译作三重三次）过滤器。

![](media/39cbe619e0bfd05f32d10f483957fc3d.jpg)

Figure 20-1三次B样条（Cubic B-Spline）和其导数

（a）f_1和过滤器权重w_i（x）的卷积
（b）三次样条曲线的一阶导数；（c）三次样条曲线的二阶导数

总而言之，本章介绍了一个能有效减少高阶纹理过滤需要的对输入纹理进行采样的次数。而前提是假设一个线性采样操作和一个最邻近采样一样快（至少不慢太多）。对三阶过滤器核（如三次B样条）曲线过滤器进行了优化，让它只需要非常少的线性纹理采样次数。

而事实上，片元着色器里的代码更像一个手工写的线性插值程序，而不是一个立方过滤器。

## 【关键词】

纹理过滤（Texture Filtering）

高阶过滤（Higher-Order Filtering）

B样条过滤（ B-Spline Filtering）

三次B样条（Cubic B-Spline）

快速递归三次卷积（Fast Recursive Cubic Convolution）

# 五、高质量反走样的光栅化（High-Quality Antialiased Rasterization）

## 【章节概览】

这章介绍了一种分块的超采样（supersampling）技术，使用任意宽度和高采样率的自定义过滤器，可以用来渲染任意分辨率的图像，以实现高质量的反走样光栅化。

## 【核心要点】

如上所言，文中介绍了一种分块的超采样（supersampling）技术，描述了如何把一个图像分成块（tiles，也称为buckers），用高分辨率渲染每一块，然后降采样（downsample，即收缩）每一块以达到最终分辨率，在即使构造的片元程序中使用分离式的降采样。文中也介绍了如何在图像分块之间进行正确的重叠和延伸的细节问题。文中提供的代码可以很轻易地集成到现有的渲染系统中，而不需要对现有的代码进行大的改动。

![](media/b40c8f8fbeabe9381a3165a50001a96d.jpg)

图 将图像分解成tiles

对于最终图像的每一个分块，总体算法如下：

（1）把图像块渲染到一个大的离屏缓冲区中，调整投影矩阵，以现有的渲染代码把3D几何体用高采样率的分辨率渲染出来。

（2）把高分辨率的图像块用一个分离式的过滤器核进行降采样，通过使用实时生成的片元程序在屏幕上渲染两个全屏的四边形来实现。

（3）把低分辨率的图像块累加到最终图像中，或通过把图像块的数据读回到CPU中，或使用另外一个片元程序把图像块加入到最终图像中。

## 【关键词】

反走样光栅化（Antialiased Rasterization）

分块超采样（tiled supersampling）

降采样（downsample）

# 六、快速预过滤线条（Fast Prefiltered Lines）

【章节概览】

这章介绍了一种简单有效的绘制反走样（抗锯齿）的线条的方法。

## 【核心要点】

本章提到的预过滤（Prefiltered）方法最早由McNamara, McCormack, 和 Jouppi
在2000年提出，其有诸多优点。首先该方法能使对称的过滤器在运行时提供固定的开销；其次，和一般硬件支持的过滤器不同，本方法不仅仅对只处于像素内的点进行采样，它能支持更大范围的过滤器，反走样的结果是硬件无关的，这保证了在不同GPU上能得到相同的反走样结果。

![](media/3b7bff29e36a872ca8f11291bbe1f482.jpg)

图 比较细线和粗线的反走样效果

总之，通过对从中心到边界不同距离处，把直线和过滤器的卷积结果进行卷积，并将结果存储在一个查找表中来预过滤线条。

该方法允许相同的运行时开销开使用任意的对称过滤器。而且，该算法只需要很少的CPU和GPU运算、带宽及存储空间开销。这些特性使这种算法对大部分的实时渲染程序都有实用价值，如绘制围栏、电线以及游戏中其他细长的物体。

## 【关键词】

预过滤线条（Prefiltered Lines）

反走样/抗锯齿（Antialiasing ）

线条的反走样（Antialiasing Lines）

# 七、Nalu Demo中的头发动画与渲染（Hair Animation and Rendering in the Nalu Demo）

## 【章节概览】

这章讲到了NVIDIA公司的Nalu Demo中的头发动画和渲染技术。

![](media/f4fb6c813e50c5f92402a06ac3577c08.jpg)

图 Nalu的头发

## 【核心要点】

NVIDIA的Nalu demo中，要达到的目标是渲染在水中飘动的金色长发。这章将介绍用于实时达到这个目标所用的技术。这种技术包含一个模拟头发运动系统，一个计算头发自阴影的阴影生成算法，还有一个通过每一串头发来模拟光线散射的发射模型。把这些结合起来，就能实时创建出极其真实的头发渲染效果。

在Nalu头发的后台着色处理中，有一个在每帧里生成头发几何和控制动感与碰撞的系统。基本上分成两部分：几何生成器和动感/碰撞的计算。

这些头发是由4095条用直线图元来渲染的独立发丝组成。仅仅在渲染头发上就使用了123000个顶点。让所有这些顶点通过动力学和碰撞检测就将慢得无法接受，因此使用受控发丝（control hair）：尽管需要渲染成千次，但Nalu的发型能通过一组每组几百根发丝来描述和控制。所有开销大的动态计算都运用于这些受控发丝。

头发的实时反射模型方面，选用了Marschner反射模型（2003）。而在渲染头发的阴影方面，采用了一种针对渲染头发阴影设计的近似阴影——非透明阴影图（Opacity
shadow maps）(Kim and Neumann 2001)。

![](media/4052d83ee541057dab03a4349d313831.jpg)

图 基于Marschner反射模型的头发渲染

![](media/262b03440b559661adf9d1be8ebd5ad4.jpg)

图 Marschner反射模型的查找纹理（Lookup Textures）

## 【关键词】

头发渲染（Hair Rendering）

头发动画（Hair Animation）

Marschner反射模型（Marschner Reflectance Model）

非透明阴影图（Opacity Shadow Maps）

# 八、使用查找表加速颜色变换（Using Lookup Tables to Accelerate Color
Transformations）

## 【章节概览】

这章中，介绍了一种利用三维查找表的算法来实时处理高分辨率图像的方法。

## 【核心要点】

在函数的计算开销很大，但是把计算结果缓存起来的开销比较小时，用查找表（Lookup
Table，简称LUT）优化这种函数的计算是一种非常好的方法。通过预先把一些常见输入的对应结果计算出来，花费不多的查找操作就能代替开销较大的运行时计算。如果查找比开头开始计算结果（或者有不断重复的相同输入）要快，那么使用查找表就能提高程序性能。

这章中，介绍了一种利用三维查找表的算法来实时处理高分辨率图像的方法。这种方法有非常出色的性能，它与执行颜色操作的数量无关，与颜色操作的复杂度也无关，即能独立于颜色运算的数量和颜色变换的复杂度。涉及到的主要实现有，把查找表映射到GPU、着色器的实现、系统集成以及把三维查找表扩展到高动态范围图像等步骤。

![](media/19223f5755726a012c35b8ce340cda7c.jpg)

图 一个三维的查找表

![](media/2bdf5cfa1dd9128a7f4b33ffffa23223.jpg)

图
颜色校正流水线的比较。左图为传统的颜色校正流水线，通过发送低分辨率的图像来用作硬件加速的基础。右图为基于三维查找表的加速流水线。

## 【关键词】

查找表（Lookup Table， LUT）

颜色变换（Color Transformations）


<br>

# 九、实现改进的Perlin噪声（Implementing Improved Perlin Noise）

## 【章节概览】

这章上接《GPU Gems 1》中奥斯卡得主大牛Ken Perlin撰写的第五章[Perlin 2004]，《GPU Gems 1》中Ken
Perlin的章节讨论了该如何使用3D纹理实现过程噪声的快速近似，在这里描述一个改进噪声算法的GPU实现，其也完全符合用CPU进行实现。

## 【核心要点】

Perlin算法由两个主要阶段组成。

第一阶段在3D空间的每个整数（x，y，z）位置产生一个可重复的伪随机值。这可以以多种方式思想，但是Perlin的算法是使用一个散列函数。散列函数基于一个包含以随机顺序0\~255的整数排列的表（这张表可以在实现之间进行标准化，以便它们产生相同结果）。首先，这张表是基于位置的x坐标索引，然后将y坐标添加到表中该位置的值中，并使用结果再次在表中查一次表。然后为z坐标重复一次此过程。对z坐标重复此过程后，结果为每个可能的（x，y，z）位置的伪随机整数。

在算法中的第二阶段，将上述伪随机整数用于索引入一个3D梯度向量的表中。在“改良的”算法中，只用8个不同的梯度。这个梯度和噪声空间中的小数位置求点积可以得到一个标量值。最后的值通过空间中相邻8个点的噪声值插值获得。

Perlin改良的噪声算法是将CPU实现的排列表和梯度表存储在数组中。由于像素着色器当时不支持索引入常量存储器中，所以将这些表存储在纹理中，并使用纹理查找来访问它们。纹理寻址设为环绕（或重复）模式，因此不必考虑扩充表以避免索引越过数组结尾，如同在CPU实现中一样。

本章介绍了对像素着色器中的程序化噪声的实现。程序化噪声是丰富渲染外观一个重要的部分，而且它可以用于凹凸贴图和其他效果。

![](media/88624af868602cf53093cf48179b8f9a.jpg)

图 基于过程凹凸贴图的pixel着色器噪声

## 【关键词】

Perlin噪声（Improved Perlin Noise）

改进的Perlin噪声（Improved Perlin Noise）

# 十、高级高质量过滤（Advanced High-Quality Filtering）

## 【章节概览】

这章提供了一个基于GPU纹理过滤的实现细节和解决方案，其中重点放在纹理插值和反走样问题。

## 【核心要点】

本章阐述了一系列用于渲染纹理表面的高质量纹理过滤方法。这些技术可以用来执行许多常见的图像任务，如缩放、扭曲、锐化等。除此之外，用这些方法渲染简单的带纹理的3D场景时，还可以提供比图形硬件上的标准过滤器更好的渲染效果。

这章提到的技术是为质量最优的渲染而设计的，对高帧率的实时交互的程序和游戏来说依然显得昂贵，它更适合哪些渲染质量比速度更重要的程序，如医疗和科学图像、照片和电影编辑、图片合成、视频格式转换、专业3D渲染等。它也能用于游戏中与分辨率无关的纹理准备（预处理）当中。

另外，文中还介绍了一种适合用于增强重建图像的锐化过滤方法——冲击过滤冲击过滤（Shock Filtering），其能把纹理插值平滑地变换成陡峭的变换。

![](media/6f1792a2a9f48434d51a2363d52f50d8.jpg)

图 冲击过滤（Shock Filtering）方法

##【关键词】

GPU纹理过滤（GPU-based texture-filter）

纹理插值（ texture interpolation）

反走样/抗锯齿（antialiasing ）

冲击过滤（Shock Filtering）

# 十一、Mipmap层级测定（Mipmap-Level Measurement）

## 【章节概览】

这章讲到了使用“伪着色”（false-colored）的mipmap来代替原来的多级纹理进行场景渲染的方法。这样的mipmap每层都有不同的比对色。且这章展示了如何用GPU来自动化伪着色的整个过程。

## 【核心要点】

伪着色（false-colored）的mipmap，结合基于GPU的方法，可以高效地运用在游戏引擎中，可见的mip层次将被动态地反馈入引擎的纹理管理程序以减少内存消耗量。而所节省的内存可以用来增加别处的纹理分辨率，改进场景的华丽程度。Climax在Leviathan引擎中对地形场景使用了这项技术，使纹理空间节约了80%的内存，并没有任何可察觉的视觉质量损失。

![](media/6beae192bc08bce1bf49f58be8c35964.jpg)

图 对地形场景应用伪着色mipmap方法

图（a）地形场景适用Climax的Leviathan引擎渲染（b）通过下图“定标纹理”，将原纹理替换成伪着色的mipmap后的效果。可以看到最高的层（黄颜色）几乎不可见。

![](media/5f5aed8ad253dba4f7ba1d492679d53e.jpg)

图 定标纹理

# 【关键词】

纹理管理（texture management）

伪着色（false-colored）

Mipmap层级（Mipmap-Level）



# 附录：配套资源与源代码下载


这里提供了一些，《GPU Gems 2》书本的配套资源以及源代码的下载地点。

PS:配套的不少工程中不仅包含完整的源码，也直接包含经过编译后的exe执行文件，可以直接运行后查看效果。

《GPU Gems 2》全文的Web版本：

<https://developer.nvidia.com/gpugems/GPUGems2/gpugems2_inside_front_cover.html>

也有维护一个名为“GPU-Gems-Book-Source-Code”的GitHub仓库，以备份《GPU
Gems》系列书籍相关的珍贵资源，《GPU Gems 2》的随书CD和源代码可以在这里下载到：

<https://github.com/QianMo/GPU-Gems-Book-Source-Code>

以上。

​

```

`Content/《GPU Gems 3》全书提炼总结/Part1/README.md`:

```md



![](media/title.jpg)

# 《GPU Gems 3》：真实感皮肤渲染技术总结

本文的知乎专栏版本：
https://zhuanlan.zhihu.com/p/42433792


《GPU Gems 3》中的“Chapter 14. Advanced Techniques for Realistic Real-Time Skin Rendering”一文，自其问世以来，都是皮肤渲染领域经常会被参考到的主要文章，可谓皮肤渲染技术的集大成者，奠基之作。

本文正好借着系列文章对《GPU Gems 3》中此章节进行提炼总结的机会，对真实感皮肤渲染技术，进行一个系统的总结和提炼。

除了对《GPU Gems 3》中该篇文章本身内容的提炼，本文也会在其基础上，结合这些年真实感皮肤渲染技术的发展，聊一些更多的东西。希望能对当前业界真实感皮肤渲染技术的现状与发展，做一个较为全面系统的总结与提炼。

<br>



# 快捷导航目录

<!-- TOC -->

- [《GPU Gems 3》：真实感皮肤渲染技术总结](#gpu-gems-3真实感皮肤渲染技术总结)
- [快捷导航目录](#快捷导航目录)
- [一、总览：皮肤渲染技术发展史](#一总览皮肤渲染技术发展史)
- [二、近年游戏与渲染业界中的真实感皮肤渲染画面](#二近年游戏与渲染业界中的真实感皮肤渲染画面)
- [三、皮肤渲染基础理论](#三皮肤渲染基础理论)
    - [3.1 镜面反射（specular reflection）](#31-镜面反射specular-reflection)
    - [3.2 次表面散射（Subsurface Scattering）](#32-次表面散射subsurface-scattering)
        - [3.2.1 半透明材质与次表面散射（Translucent and Subsurface Scattering）](#321-半透明材质与次表面散射translucent-and-subsurface-scattering)
        - [3.2.2 BRDF与BSSRDF](#322-brdf与bssrdf)
        - [3.2.3 BTDF与透射（Transmittance）](#323-btdf与透射transmittance)
        - [3.2.4 关于BRDF、BSSRDF、BTDF、BSDF的关系](#324-关于brdfbssrdfbtdfbsdf的关系)
- [四、扩散剖面（Diffusion Profile）](#四扩散剖面diffusion-profile)
        - [4.1 多级子（Multipole）方法](#41-多级子multipole方法)
    - [4.2 高斯和的扩散剖面（Sum-of-Gaussians Diffusion Profile）](#42-高斯和的扩散剖面sum-of-gaussians-diffusion-profile)
    - [4.3 对皮肤的扩散剖面高斯和拟合（A Sum-of-Gaussians Fit for Skin）](#43-对皮肤的扩散剖面高斯和拟合a-sum-of-gaussians-fit-for-skin)
- [五、常规基于模糊的次表面散射方法](#五常规基于模糊的次表面散射方法)
    - [5.1 纹理空间模糊（Texture Space Blur）](#51-纹理空间模糊texture-space-blur)
    - [5.2 屏幕空间模糊（Screen Space Blur）[2009]](#52-屏幕空间模糊screen-space-blur2009)
- [六、其他皮肤渲染技术](#六其他皮肤渲染技术)
    - [6.1 半透明阴影贴图（Translucent Shadow Maps，TSMs）](#61-半透明阴影贴图translucent-shadow-mapstsms)
    - [6.2 预积分的皮肤渲染（Pre-Integrated Skin Rendering）](#62-预积分的皮肤渲染pre-integrated-skin-rendering)
    - [6.3 SSSS,可分离的次表面散射（Separable Subsurface Scattering）](#63-ssss可分离的次表面散射separable-subsurface-scattering)
    - [6.4 路径追踪次表面散射（Path-Traced Subsurface Scattering）与光线步进（Ray Marching）](#64-路径追踪次表面散射path-traced-subsurface-scattering与光线步进ray-marching)
    - [6.5 Deferred Single Scattering](#65-deferred-single-scattering)
- [七、本文内容总结](#七本文内容总结)
    - [1. 皮肤渲染建模](#1-皮肤渲染建模)
    - [2. 镜面反射部分](#2-镜面反射部分)
    - [3. 次表面散射部分](#3-次表面散射部分)
        - [3.1 扩散剖面（Diffusion Profile）](#31-扩散剖面diffusion-profile)
        - [3.2 其他皮肤渲染技术](#32-其他皮肤渲染技术)
    - [4. 皮肤渲染技术发展史](#4-皮肤渲染技术发展史)
- [八、参考文献](#八参考文献)

<!-- /TOC -->




# 一、总览：皮肤渲染技术发展史


按时间分布，近20年皮肤主流渲染技术的发展可以总结列举如下：

-   次表面光照传输模型（Subsurface Light Transport, SSLT）[2001]

-   扩散剖面（Diffusion Profile） [2001]

-   偶极子（dipole） [2001]

-   纹理空间模糊（Texture Space Blur）[2003]

-   多极子（multipole） [2005]

-   屏幕空间模糊（Screen Space Blur）或屏幕空间次表面散射（SSSSS,Screen Space SubSurface Scattering）[2009]

-   路径追踪次表面散射（Path-Traced Subsurface Scattering）与光线步进（Ray Marching）[2009]

-   预积分的皮肤着色（Pre-Integrated Skin Shading）[2010]

-   可分离的次表面散射（SSSS,Separable Subsurface Scattering）[2015]

-   等

需要注意的是，上面列出的时间点，可能并不是严格意义上的该技术提出的时间点，而是该技术在论文或会议上被提出，被大众熟知，被引入到皮肤渲染技术中的时间点。

接下来，先看一些近年游戏中的真实感皮肤渲染画面，然后让我们从皮肤渲染的基础理论开始讲起，接着对上面列出的近20年皮肤主流渲染技术，按流派和内容分别进行介绍。

<br>

# 二、近年游戏与渲染业界中的真实感皮肤渲染画面

首先是一个《孤岛惊魂5》中的演示视频（预渲染），有不少人觉得渲染出的画面已经和真人出演的美剧非常相似，主要注意视频中人物的皮肤渲染表现：

<https://www.youtube.com/watch?v=4W450G_UR1Q>

接着，看一些近几年，游戏中真实感皮肤渲染的典型效果图。

从《孤岛惊魂5》开始：

![](media/9c31af134fe2e8b31d3170f8a2a53de2.png)

图《孤岛惊魂5》中的皮肤渲染

![](media/006cd6fb948aeb4ea8e8f58d58d95194.jpg)

图《孤岛惊魂5》中的皮肤渲染


《神秘海域4》：

![](media/1241647f87d40cce0da976277b744e25.jpg)

图 《神秘海域4》中的皮肤渲染

![](media/6beb84faac02d2ffbf68157283b7f480.jpg)

图 《神秘海域4》中的皮肤渲染

《底特律：变人》：

![](media/32ce1d4a8b8fcf5fde31989af3fa2917.jpg)

图 《底特律：变人》中的皮肤渲染

![](media/0301cbb05fa6e03642733b201fc38636.jpg)

图 《底特律：变人》中的皮肤渲染

当然，怎么都不能少了今年的热门 UE4的Siren：

![](media/b3c38707fe520888a1908bc11a643b8b.jpg)

图 数字人Siren的皮肤渲染 @UE4

![](media/1cfe24ec51b878c93d86b064f44f3869.png)

图 数字人Siren的皮肤渲染 @UE4

<br>

# 三、皮肤渲染基础理论


皮肤的渲染一直是渲染领域的难点之一：皮肤具有许多微妙的视觉特征，而观察者对皮肤的外观，特别是脸部的外观会非常敏感。皮肤的真实感渲染模型须包括皱纹，毛孔，雀斑，毛囊，疤痕等细节的模拟，而真实还原人体皮肤上的这些细节则是一个较大的挑战。

皮肤作为一种属性复杂的材质，其物理结构由多层结构组成，其表面油脂层主要贡献了皮肤光照的反射部分，而油脂层下面的表皮层和真皮层则主要贡献了的次表面散射部分。实验测试表明，光线接触到皮肤时，有大约94%被皮肤各层散射，只有大约6%被反射。

![](media/016bf9ddb7c7e6d3e8ef980a6410f3f1.png)

图 多层皮肤结构

对于皮肤而言，图形学研究学者们已经制作了使用多达五个独立层[Krishnaswamy and Baranoski 2004]的非常细致的模型，用于描述皮肤中的光学散射现象，而真正的皮肤则更加复杂。在医学上，仅皮肤表皮（epidermis）即被认为包含五个不同的层[Poirer 2004]。在这种复杂性下对散射进行模拟可能是过度和没有必要的，但是真实的渲染需要在油质层下面建模至少两个不同的层，因为至少有一个层要用于镜面反射（specular）项。Donner和Jensen[Donner and Jensen 2005]在2005年证明了单层模型不足以对真实感皮肤进行渲染，并展示了使用三层建模的改进方案。

![](media/19dcd9f74e4594c0b7245f6195649da3.jpg)

图 多层皮肤模型

因为其具有半透明属性光线会在皮肤的表层进行多次散射，散射根据其通过的路径衰减，简单来说就是光线会扩散到周围，这对于表现皮肤的质感起到很大作用。

一般的材质采用BRDF(bidirectional reflectance distribution function)可以很好的表达，但皮肤往往需要更加复杂的建模，如BSSDF。

![](media/092aba5726f59db4e9bff787c0be6e50.jpg)

图 多层皮肤对光的散射和吸收

经验表明，皮肤渲染的渲染过程可由两个分量组成：

-   镜面反射（specular reflection）

-   次表面散射（subsurface scattering）

下文将对上述两个分量分别进行说明。


## 3.1 镜面反射（specular reflection）

镜面反射项（specular reflection）相对而言很简单，Gems 3中推荐Kelemen and
Szirmay-Kalos specular BRDF用于皮肤镜面反射项的计算。因为Kelemen and
Szirmay-Kalos specular
BRDF在实现和Torrance-Sparrow模型一样的渲染效果时，计算量要小得多。而现阶段基于物理的一些其他高光模型或改进方案也应该会得到不错的效果。

## 3.2 次表面散射（Subsurface Scattering）

### 3.2.1 半透明材质与次表面散射（Translucent and Subsurface Scattering）

首先，半透明材质在生活中无处不在：树叶、纸、蜡烛、牛奶、布料、生物的皮肤、贝壳、玛瑙等。事实上，几乎所有非金属物体都存在一定程度的次表面光传输(Subsurface Light Transport,SSLT)现象[Pharr 2010]，皮肤犹是如此。

上文提到，皮肤是一个多层结构，其表面油脂层主要贡献了皮肤光照的反射部分（约占入射光中的6%），而油脂层下面的表皮层和真皮层则主要贡献了次表面散射部分（约占入射光中的94%）。任何没有直接从皮肤表面反射出去的光，都会直接进入次表面层。这种占主要主导因素的次表面散射属性，决定了皮肤半透明的特征以及柔软的视觉外观。

入射光与皮肤进行交互的过程中，被部分吸收（获取颜色）并经过多次散射，返回并从进入点周围的3D邻域处表面离开。而有时光线会完全穿过像耳朵这样的薄薄区域，形成透射（Transmittance）。

![](media/e73677ea1b404446fa842e938109c611.jpg)

图 多层皮肤对光的散射和吸收

对于次表面散射而言，Jensen在2001年的论文《A Practical Model for Subsurface Light Transport》是次表面材质建模最重要的一篇论文，推导了许多重要的物理公式，计算模型，渲染时的参数转换，以及测量了许多生活中常见材质的散射系数等等。大部分后来的论文都是在基于这篇文章中的理论的一些提升。

### 3.2.2 BRDF与BSSRDF

模拟半透明物体的方法有很多，例如Volumetric Path Tracing，Volumetric Photon Mapping和BSSRDF。

其中，BSSRDF（Bidirectional Surface Scattering Reflectance Distribution Function，双向表面散射反射分布函数）是目前的主流技术。

简单来说，传统的 BRDF 模型是 BSSRDF的一种简化。BSSRDF和BRDF的不同之处在于，BSSRDF可以指定不同的光线入射位置和出射的位置。

![](media/3d97cf598c2bb107120a97b90fd1f13e.png)

图： BRDF和BSSRDF与皮肤交互，光散射的对比

对于BRDF模型来说，一次反射光照的计算是在光线交点的法线半球上的球面积分。而对于BSSRDF来说，每一次反射在物体表面上每一个位置都要做一次半球面积分，是一个嵌套积分。

![](media/48bce39efd52d7076fe1b7a9cc848fd0.png)

其中BSSRDF的定义是：

![](media/63fbc374696ae300b599bc496eae5d45.png)

![](media/58f644a4a1ad284b5325057592d6480d.png)只接受一个标量参数，这个参数的意义是光线入射位置和初设位置的曼哈顿距离。直观的理解就是，BSSRDF尝试将光线在物体表面内部中数千次的散射后所剩余的能量用一个基于入射点和出射点之间距离的函数去近似只接受一个标量参数，这个参数的意义是光线入射位置和初设位置的距离。也就是说，BSSRDF尝试将光线在物体表面内部中数千次的散射后所剩余的能量用一个基于入射点和出射点之间距离的函数去近似。这个近似则是基于几个假设:

1.    次表面散射的物体是一个曲率为零的平面

2.    这个平面的厚度，大小都是无限

3.    平面内部的介质参数是均匀的

4.    光线永远是从垂直的方向入射表面。

正因为有这些假设，所以很容易把出射光的强度与出射点和入射点之间的距离用一个函数去近似。而真实的模型往往比理想中要复杂的多，光线也有可能从各个角度入射，因此通过BSSRDF渲染的结果会有一定误差。

![](media/58f644a4a1ad284b5325057592d6480d.png)
的求解非常复杂，通过近似可以得到：

![](media/601b52ae28bd227b7e3b187cee254caa.png)

，有了![](media/6911bc9b9d4847b630ff5f049af3e2fb.png)可以得到![](media/afb687befe1164d6701fd7ee7d91db7c.png)

![](media/b8b926a3f9769073334404ed21726063.png)

其中![](media/85e555415c5953d9c62f6337802051f8.png)，可以看出和自然指数是有关系的。

<br>

### 3.2.3 BTDF与透射（Transmittance）

有时光线会完全穿过像耳朵这样的薄薄区域。这是因为，光线经过一部分次表面后，最终没有在入射侧进行出射，而是从入射侧另一侧透出来，形成透射（Transmittance）。透过光的手会产生桔红色视觉外观同理。

![](media/a600e1812796efc81862604328f8a860.jpg)

图 透射（Transmittance）的图示

![](media/dfa95a086579f0f2a9b0c7b84f13e430.jpg)

图 透过光的手会产生桔红色视觉外观

透射一般可以通过BTDF（双向透射分布函数， Bidirectional Transmittance Distribution Function）来描述。

这里先对几种分布函数的全称进行列举：

-   BRDF（双向反射分布函数，Bidirectional Reflectance Distribution Function）

-   BSSRDF（双向表面散射反射分布函数, Bidirectional Surface Scattering
    Reflectance Distribution Function）

-   BTDF（双向透射分布函数， Bidirectional Transmittance Distribution Function）

-   BSDF（双向散射分布函数，Bidirectional Scattering Distribution Function）

作为讲解内容，之前有一篇文章（<https://zhuanlan.zhihu.com/p/27014447>）关于BRDF、BTDF、BSDF的描述非常精炼，这边直接引用到本文中来。

当光线从一种介质射向另外一种介质时，根据其行进路线，可以被分为两个部分：

-   一部分光线在介质交界处发生了反射， 并未进入另外一种介质。

-   另外一部分光线则进入了另一种介质。

其中：

-   BRDF：反射部分的光照的辐射亮度（radiance）和入射光照的辐射照度（irradiance）的比例是一个和入射角度、出射角度相关的函数，这个函数就被称之为双向反射分布函数（BRDF）。

-   BTDF：相应的，穿越介质的那部分光照的辐射亮度和辐射照度的比例就被称之为双向透射分布函数（BTDF）。

-   BSDF：上述两部分出射光的辐射亮度总和和入射光的辐射照度的比例就被叫做双向散射分布函数（BSDF），即BSDF = BRDF + BTDF。

![](media/288d1679760d30e047aed0aa7b2ff7d6.png)

图 BSDF = BRDF + BTDF


透射的实现思路比较直观，可以分为三步：

（1）计算光照在进入半透明介质时的强度

（2）计算光线在介质中经过的路径长度

（3）根据路径长度和BTDF来计算出射光照的强度，这里BTDF可以简化为一个只和光线路径长度相关的函数

另外，《GPU Gems 3》中，有提到通过改进半透明阴影贴图（Translucent Shadow Maps，TSMs）来实现皮肤渲染中透射效果的模拟，下文中也有一些更详细的简略说明。

### 3.2.4 关于BRDF、BSSRDF、BTDF、BSDF的关系

另外，下面的这张PPT，能很好地解释BRDF、BSSRDF、BTDF、BSDF的关系。

![](media/7550d414d75dc36df51d21b1ed51230a.jpg)

图 BRDF、BSSRDF、BTDF、BSDF的关系

下面用一些补充说明，理清几者的关系。

如上图，光线从一种介质射向另外一种介质时，有反射，次表面散射、透射三种交互形态：

-   其普通反射的行为用BRDF描述

-   其次表现散射的行为用 BSSRDF描述

-   其透射的行为用BTDF描述

四者的联系：

-   总体来说，BRDF 为 BSSRDF 的一种简化

-   BSDF可分为反射和透射分量两部分，即BSDF = BRDF + BTDF

# 四、扩散剖面（Diffusion Profile）


扩散剖面（Diffusion Profile），是早年间渲染次表面散射比较热门的大方向。

首先，需要说明一下关于Diffusion Profiles这个词翻译相关的问题。按Diffusion Profiles其含义，可被译作扩散剖面，也可以被译作漫散射剖面、漫射剖面。（Diffusion Profiles目前还没有比较公认和共识的翻译，大多数文章中都直接使用英文原词组，上述翻译仅供参考。文章后文尽量会统一使用“扩散剖面”作为Diffusion Profiles的翻译）另外，有些文献中会将Diffusion 写作Diffuse Scattering，他们都是表示漫散射，或一种光线在材质内部扩散的现象。

简而言之，扩散剖面（diffusion profile）是描述光线如何在半透明物体中进行扩散和分布的函数。

扩散剖面（diffusion profile），相当于一个记录次表面散射细节的“地图”。你可以将其理解为一个LUT，一个记录了答案的索引，或者一张标记高度的“高度图”，他会告诉你什么地方的像素，应该进行什么程度的模糊。

也有文章指出，可以简单理解扩散剖面为一张权重查找表，不同的皮肤渲染方法，通常就是对扩散剖面的不同近似。

需要说明的是，与扩散剖面（diffusion profile）的概念往往一起出现的偶极子（Dipole）方法，多级子（Multipole）方法，高斯和（Sum-of-Gaussians）方法，都是更好地描述出扩散剖面（Diffusion Profiles）的一些策略。

对于一个平面来说当激光垂直照射它时会发现光扩散到周围，形成以照射点为中心的光晕，如果物体的材质各项均匀其散射行为和角度无关，我们就可以用一个一维函数来描述，对于不同的材质RGB根据距离衰减的行为是不一样的。扩散剖面（diffusion profile）就是用来描述光在物体内部的扩散(散射)行为。

具体来说，扩散剖面（diffusion profile）提供了光在高度散射的半透明材质表面下散射方式的近似。具体而言，它描述了以下简单实验的结果。

在暗室中使用非常薄的白色激光束照亮一个平坦的表面。我们将看到激光束照射到表面的中心点周围的光晕，因为一些光线在表面下方并在附近返回，如下(a)所示。

扩散剖面（diffusion profile）告诉我们有多少光作为角度和激光中心距离的函数出现。
如果我们只考虑均匀材质，则散射在所有方向上都是相同的，即散射行为和角度无关。

而每种颜色都有自己的剖面，我们可以将其绘制成一维曲线，如下图(b)所示。

![](media/c17c86d58c9e825a7aefe356c32676ab.jpg)

图 可视化扩散剖面（diffusion profile）

另外值得注意的是，RGB扩散的范围是不一样的，即扩散剖面具有很强的颜色相关性：红光比绿色和蓝色散射得更远。而正因为红色扩散得更远一些，所以耳朵和鼻子的部位通常会更有红彤彤的感觉。

时间方面，在2001年，Jensen 等人提出的散射模型[Jensen et al.2001]基于几种材质属性引入了扩散剖面，奠定了此流派的基础。并提出了使用偶极子（dipole）方程计算出扩散剖面的思想。

该方法简单地使用表面上两点之间的空间距离r来评估扩散剖面。其决定了任何两个位置之间的漫散射的描述问题，且无论两者之间的几何形状如何，如下图所示。

![](media/92bda77a36da86fa0e619316485bce5a.jpg)

图 用r进行曲面中漫散射（diffusion）的有效估算

给定几种属性，可以使用偶极子（dipole）方程计算出扩散剖面。而偶极子（dipole）也是较为常见的评估扩散剖面的方法。而有些文献中提到的偶极子剖面（Dipole
Profiles），即是用偶极子（dipole）来表示的扩散剖面（diffusion profile）。

![](media/764dfcfe79601a3ed3aba86358b9d8d1.png)

图 将入射光线转换为偶极子源以进行漫散射的近似[Jensen 2001]

我们可以将扩散剖面用R(r)表示。一般而言，所有材质都存在次表面散射现象，区别只在于其密度分布函数R(r)的集中程度，可分为两种情况：

（1）如果该函数的绝大部分能量都集中在入射点附近（r=0），就表示附近像素对当前像素的光照贡献不明显，次表面散射现象不明显，可以忽略，则在渲染时我们就用漫反射代替。

（2）如果该函数分布比较均匀，附近像素对当前像素的光照贡献明显，次表面散射现象明显，则需要单独计算次表面散射。

据此次表面散射的计算可以分为两个部分：

（1）对每个像素进行一般的漫反射计算。

（2）根据扩散剖面（diffusion profile）和（1）中的漫反射结果，加权计算周围若干个像素对当前像素的次表面散射贡献。

### 4.1 多级子（Multipole）方法

上文提到，与扩散剖面（diffusion
profile）概念往往一起出现的偶极子（Dipole），多级子（Multipole），高斯和（Sum-of-Gaussians），都是更好地描述出扩散剖面（Diffusion Profiles）的一些方案。

2005年，Donner and Jensen通过论文《Light Diffusion in Multi-Layered Translucent Materials》[Donner and Jensen 2005]将多极子（multipole）引入扩散剖面（diffusion profiles），来解决多层半透明材质中的次表面散射的渲染问题。

需要知道的是，多极子是偶极子概念的推广。在物理学中，对于含有2\^n个大小相等的点电荷，其中正负各半数，排列成有规律的点阵。n=0时，称为点电荷；n=1，称为偶极子（Dipole）；n=2，称为四极子；n≥2，统称为多极子（Multipole）。

![](media/b5efe2be3abae935b19ae55e56774353.png)

图 半无限几何图形的偶极子配置（左）和薄材质的多极子配置（右）[Donner 2005]

关于多极子拟合扩散剖面（diffusion profile）的具体方法，可见论文《Light Diffusion in Multi-Layered Translucent Materials》。<http://jbit.net/~sparky/layered.pdf>


<br>

## 4.2 高斯和的扩散剖面（Sum-of-Gaussians Diffusion Profile）

不难发现，对扩散剖面绘制的轮廓线类似于众所周知的高斯函数e^-r2，如下图。虽然单个高斯分布不能精确地拟合任何扩散分布，但实践表明多个高斯分布在一起可以对扩散剖面提供极好的近似。因此我们可以通过高斯函数来拟合扩散剖面（diffusion profile）。

![](media/c17c86d58c9e825a7aefe356c32676ab.jpg)

图 可视化扩散剖面（diffusion profile）

高斯函数表达式具有一些很好的特性，在当我们将扩散剖面表示为高斯和时，可以让我们非常有效地求解次表面散射。高斯函数是独特的，因为它们同时是可分离的和径向对称的，并且它们可以相互卷积来产生新的高斯函数。

这需要从偶极子或基于多极子的扩散剖面映射到高斯和。

对于每个扩散分布R(r)，我们找到具有权重w i和方差v i的k个高斯函数：

![](media/72cc6208b2c5f2355729884ceae5063c.jpg)

我们为高斯函数的方差v选择以下定义：

![](media/1673b1f4425e8cbfe07ad773ba25ad98.jpg)

选择常数1/（2v）使得G（v，r）在用于径向2D模糊时不会使输入图像变暗或变亮（其具有单位脉冲响应（unit impulse response））。

下图显示了扩散剖面（diffusion profile）（用于大理石中绿光的散射）和使用两级和四级高斯和的近似剖面。

我们使用[Jensen et al. 2001]中提出的散射参数：

![](media/000.jpg)

图 用多个高斯和拟合偶极子剖面（Dipole Profile）

从上图可以看出2个高斯函数和的Profile的误差较大，而4个高斯和已可以可以很好的逼近Profile。上述的四级高斯和为：

R(r) = 0.070G(0.036, r) + 0.18G(0.14, r) + 0.21G(0.91, r) + 0.29G(7.0, r)

那么，如何确定这几个高斯函数的权重和方差？

这是一个很经典的问题，即给定一条曲线，如何用多项式或者三角函数去拟合。

自己求解是十分费事的事情，对于经典的问题往往有现成的工具可以直接运用，不用重复造轮子。文章（<http://gad.qq.com/article/detail/33372>）提到，Matlab有一个曲线拟合功能即可满足我们的要求,详见<https://cn.mathworks.com/help/curvefit/gaussian.html>

Matlab通过高斯函数拟合最多可以支持8个高斯函数下图1，而下图2和图3是用2个高斯函数进行拟合的例子。

![](media/eea37284d9dbeb17b8b487203978b332.png)

图 Matlab中多个高斯拟合

![](media/0e766ab875fc85648f0e14fc0810626c.png)

图 Matlab中多个高斯拟合

![](media/753b53763f2b19f6d47ff070a7109bc9.png)

图 通过2个高斯函数拟合曲线的例子

<br>

## 4.3 对皮肤的扩散剖面高斯和拟合（A Sum-of-Gaussians Fit for Skin）

上一节讲到了高斯和的扩散剖面（Sum-of-Gaussians Diffusion Profile），并没有将其运用于皮肤渲染。本节将讲到适于皮肤的高斯和扩散剖面拟合。

对于大部分透明物体像牛奶，大理石一个偶极子剖面（Dipole Profile）足以，但是对于皮肤的这样多层结构的材质，用一个偶极子剖面（Dipole Profile）不能达到理想的效果。以一层材质配置一个偶极子（Dipole）的思路，通过3个偶极子（Dipole）即可模拟三层皮肤材质。实践表明，3个偶极子（Dipole）确实可以接近Jensen论文中的根据测量得出的皮肤Profile数据。

而3个偶极子剖面（Dipole Profile）通过前面描述的，对应于单个剖面的4个高斯函数不能得到很好的逼近结果。实践表明，通过6个高斯函数可以得到很不错的结果。

同样地，可以用前面提到的Matlab的拟合功能求解。下图是通过6个高斯拟合皮肤3层Dipole Profile的RGB对应的衰减，可以看出在红色比绿色和蓝色扩散的远得多。而得到的扩散曲线如下图所示。

![](media/68f871f2407cfec9318e6c899c0420e2.jpg)

图 三层皮肤模型的高斯和参数

![](media/8166f95f4f2af14afacb6fd46bac0117.jpg)

图 适用于三层皮肤模型的高斯和拟合

这里需要注意的是，对于每个剖面，高斯项的权重和为1.0。这是由于我们是用一个漫反射颜色贴图来定义皮肤的颜色，而不是用一个与之相符的漫反射剖面。通过对这些剖面进行归一化来得到白色的漫反射颜色，确保在散射入射光之后，平均结果能保持白色。然后，将此结果乘以基于图像的颜色贴图以获得肤色的色调即可。


<br>

# 五、常规基于模糊的次表面散射方法


<br>
上文提到，扩散剖面（diffusion profile）是描述光线如何在半透明物体中进行扩散和分布的函数。

得到扩散剖面（diffusion profile），即光线是如何在半透明物体中进行扩散和分布之后，接下来就可以对附近的像素进行加权求和，以模拟次表面散射的效果。

这个求和的过程其实是根据扩散剖面（diffusion profile）的指导，对周围像素进行模糊操作。按操作空间划分，比较常规的思路有两种：

-   纹理空间模糊（Texture Space Blur）

-   屏幕空间模糊（Screen Space Blur）

下面分别对其进行说明。

<br>

## 5.1 纹理空间模糊（Texture Space Blur）

纹理空间漫散射（Texture-Space Diffusion），也常被称作Texture Space Blur（纹理空间模糊）方法，由[Borshukov and Lewis 2003]提出，首次用于进行《黑客帝国》续集中的面部渲染技术，可用于精确模拟次表面散射（subsurface scattering）。

其言简意赅的思路是利用皮肤中散射的局部特性，通过使用纹理坐标作为渲染坐标展开3D网格，在2D纹理中有效地对其进行模拟。

![](media/55fb73ab3b61edfda6d489b8ee2592f9.png)

图 用于进行《黑客帝国》续集中的纹理空间模糊（Texture Space Blur）面部渲染方法

GDC 2007有一场来自NVIDIA的talk “Advanced Skin Rendering”（<http://developer.download.nvidia.com/presentations/2007/gdc/Advanced_Skin.pdf>.）中，其采用Texture Space Blur的技术即为Gems 3中所描述的方案。
该技术在纹理空间做了6次高斯模糊，每一次高斯模糊即为偶极子（Dipole）近似所采用的高斯模糊的参数，如下图。Texture Space Blur有一个很严重的问题，需要较高的纹理分辨率，这导致每做一次高斯模糊都是很费的操作，更不要说6次高斯模糊。虽然当年这个技术取得的效果很不错，但是因为计算量等原因，很少有人实际去采用。

![](media/d18cbe00b07bf2bff4402d9e5e5ce5ca.jpg)

图 《GPU Gems 3》中改进的纹理空间模糊（Texture Space Blur）算法综述

纹理空间模糊（Texture Space Blur）进行Combining blurs操作的相关shader源码如下：

    float3 diffuseLight= nonBlur* E1 * pow( diffuseCol, 0.5 );
    float3 blur2tap = f3tex2D( blur2Tex, v2f.c_texCoord.xy );
    float3 blur4tap = f3tex2D( blur4Tex, v2f.c_texCoord.xy );
    float3 blur8tap = f3tex2D( blur8Tex, v2f.c_texCoord.xy );
    float3 blur16tap = f3tex2D( blur16Tex, v2f.c_texCoord.xy );
    float3 blur32tap = f3tex2D( blur32Tex, v2f.c_texCoord.xy );
    diffuseLight+= blur2 * blur2tap.xyz;
    diffuseLight+= blur4 * blur4tap.xyz;
    diffuseLight+= blur8 * blur8tap.xyz;
    diffuseLight+= blur16 * blur16tap.xyz;
    diffuseLight+= blur32 * blur32tap.xyz;
    // renormalize weights so they sum to 1.0
    float3 norm2 = nonBlur+ blur2 + blur4 + blur8 + blur16 + blur32;
    diffuseLight/= norm2;
    diffuseLight*= pow( diffuseCol, 0.5 );

<br>

## 5.2 屏幕空间模糊（Screen Space Blur）[2009]

屏幕空间模糊（Screen Space Blur） [Jimenez et al.2009]也常被称作屏幕空间次表面散射（Screen Space SubSurfaceScattering）或SSSSS。

![](media/6231331540b5c16c85a54606609f6c76.png)

图 基于屏幕空间模糊（Screen Space Blur）的渲染图

和纹理空间模糊（Texture Space Blur）不同的是，屏幕空间模糊（Screen Space Blur）[Jimenez et al.2009]只需要处理被Stencil标记过的Skin的像素，极大地降低了Blur的像素数目，可以很大程度的提升性能。

该算法计算过程中会对Stencil标记出的皮肤材质进行若干次卷积操作，卷积核的权重由扩散剖面（Diffusion Profile）确定，而卷积核的大小则需要根据当前像素的深度（d(x,y)）及其导数（dFdx(d(x,y))和dFdy(d(x,y))）来确定。

![](media/bf25c2a200a061a9c55615fb958b721c.png)

图 屏幕空间模糊（Screen Space Blur）思路概览

![](media/8b07c0956730dca3dd0c86367cd3446c.png)

图 屏幕空间模糊（Screen Space Blur）算法流程图

![](media/7b19dd7a757540e9d538606fe1ab536d.png)

图 屏幕空间模糊（Screen Space Blur）

从原理上来说，图像空间的方法和屏幕空间的方法很大程度上都是通过周边像素对当前像素的光照贡献来实现次表面散射的效果，区别不大，方法之间的区别通常只是在于如何去近似扩散剖面（Diffusion Profile），在性能和效果上有一个较好平衡。


<br>

# 六、其他皮肤渲染技术

<br>


## 6.1 半透明阴影贴图（Translucent Shadow Maps，TSMs）

<br>

《GPU Gems 3》中，通过改进半透明阴影贴图（Translucent Shadow Maps，TSMs）来实现皮肤渲染中透射效果的模拟。

考虑到纹理空间漫散射（Texture-Space Diffusion）不会很好地模拟在三维空间中非常接近的表面光通过透光区域的完全透射效果（如耳朵和鼻孔处桔红色的视觉外观）。《GPU Gems 3》改进了半透明阴影贴图（Translucent Shadow Maps，TSMs）(Dachsbacher and Stamminger 2004)方法，通过重用卷积过的辐照度纹理，能非常有效地估计通过较薄区域的漫散射。

![](media/2496bb4c44c558c2649f55cd0d076ff4.jpg)

图 《GPU Gems 3》中改进的Translucent Shadow Maps思路图示

![](media/9dd9a42115859b6c7572166f2ea79cd3.jpg)

图 在阴影区域计算透射光

另外，ShaderX7中的“Real-Time Subsurface Scattering using Shadow Maps”也介绍了类似的使用阴影贴图（Shadow Maps）来进行次表面散射模拟的方法。

![](media/145ff7c80a4788d64cb5f1ac1b144bb7.png)

图 Rendering AAA-QualityCharacters of Project ‘A1’ @ NDC 2016 Programming Session


<br>

## 6.2 预积分的皮肤渲染（Pre-Integrated Skin Rendering）



预积分的皮肤着色（Pre-Integrated Skin Shading）在《GPU Pro 2》的” Pre-Integrated Skin Shading”一文中正式进入大家的视野。

预积分的皮肤着色（Pre-Integrated Skin Shading），其实是一个从结果反推实现的方案，具体思路是把次表面散射的效果预计算成一张二维查找表，查找表的参数分别是dot(N,L)和曲率，因为这两者结合就能够反映出光照随着曲率的变化。

![](media/9d44620ec5f7565c1f79fe8dca9461f7.png)

图 预积分的皮肤着色（Pre-Integrated Skin Shading）思路。

【左上：如何使用两个导数同时绘制曲率的图示。|右上：通过曲率（球面半径）和N·L索引的漫反射BRDF查找（The diffuse BRDF lookup）|下：使用该方法新的BRDF查找不同r大小，渲染渲染出的多个球体】

通过下图可以发现，预积分方法和纹理空间漫散射（Texture-Space
Diffusion）的渲染效果在肉眼观察下看不出太多差别，但预积分的方法计算量却要小很多。

![](media/396bd53b2a4a46632c0db005d326edf9.png)

图 预积分方法对比纹理空间漫散射（Texture-Space Diffusion）方法

另外，最终幻想15中的人物皮肤渲染，大量用到了预积分的皮肤渲染，如下图中的希德妮的渲染效果：

![](media/d642a791d8174fa098666f55bdac2c61.jpg)

图 基于 Pre-Integrated Skin Shading的《最终幻想15》希德妮渲染图【（左图：离线渲染，右图：游戏实时渲染】

关于预积分的皮肤渲染（Pre-Integrated Skin Rendering）的更多细节，可见《GPU Pro 2》中的” Pre-Integrated Skin Shading”一文。

<br>

## 6.3 SSSS,可分离的次表面散射（Separable Subsurface Scattering）

次表面散射（Subsurface Scattering）被称作SSS,或3S，而可分离的次表面散射（Separable Subsurface Scattering）常被人称为SSSS，4S, Separable Subsurface Scattering，是Jimenez等人在2015年提出的新的渲染算法[Jimenez J 2015]。

上文提到，虽然屏幕空间模糊（Screen Space Blur）性能比纹理空间模糊（Texture Space Blur）好很多，但做6个高斯模糊需要12个pass(一个高斯模糊对应一个水平和垂直模糊)。

暴雪的Jorge等人，在GDC 2013,的talk“Next-Generation Character Rendering”（<http://www.iryoku.com/images/posts/next-generation-life/Next-Generation-Character-Rendering-Teaser.pptx>）中首次展示了SSSS的渲染图，并在2015年通过论文正式提出了SSSS(可分离的次表面散射,Separable Subsurface Scattering)(<http://iryoku.com/separable-sss>)其通过水平和垂直卷积2个Pass来近似，效率更进一步提升，这是目前游戏里采用的主流技术，Unreal也对其进行了集成。

![](media/16ca4672e73c981be74b70a14ef467b8.png)

图 可分离卷积（Separable Convolution）

![](media/7a1aaa9899bce6ff554f8e9a3a902e19.jpg)

图 基于SSSS的皮肤渲染 @GDC 2013 by Activision-Blizzard

![](media/fae2fad57ffef872a0645e080d5a30db.jpg)

图 基于SSSS的皮肤渲染 @GDC 2013 by Activision-Blizzard

![](media/ee465182af6946df9bd2c7108c0794d2.png)

图《Separable Subsurface Scattering》论文中的SSSS渲染图 @ COMPUTER GRAPHICS forum 2015 by Jorge Jimenez @ Activision-Blizzard


<br>


## 6.4 路径追踪次表面散射（Path-Traced Subsurface Scattering）与光线步进（Ray Marching）

路径追踪次表面散射（Path-Traced Subsurface Scattering）也有时被称作蒙特卡洛次表面散射（Monte-Carlo Subsurface Scattering），区别于传统的光栅图形学，是光线追踪流派下模拟次表面散射的技术，主要是基于Ray Marching的实现方案。

在SIGGRAPH 2017 Course: Physically Based Shading in Theory and Practice课程系列“Volumetric Skin and Fabric Shading at Framestore”（http://blog.selfshadow.com/publications/s2017-shading-course/walster/s2017_pbs_volumetric_notes.pdf）中有一些介绍，不过需要注意，此Course有些血腥，配图中一些是异形类生物的皮肤渲染。

同样，NDC 2016 Programming Session中的Rendering AAA-QualityCharacters of Project‘A1’也有一些介绍，相关PPT页面如下：

![](media/0dd0e3a64d10bda3cef3869eea01f4c7.png)

图 Rendering AAA-QualityCharacters of Project ‘A1’ @ NDC 2016 Programming Session

另外一些参考资料也包括：

<https://www.cs.rpi.edu/~cutler/classes/advancedgraphics/S11/final_projects/white.pdf>

<br>

## 6.5 Deferred Single Scattering

另外也有结合延迟渲染的方法，具体思路可见如下PPT:

![](media/014dda21a69692b8332f388f9a7421a5.png)

图 Rendering AAA-QualityCharacters of Project ‘A1’ @ NDC 2016 Programming Session


<br>

# 七、本文内容总结

<br>

以下是本文内容总结，即对当前业界真实感皮肤渲染技术的总结：

## 1. 皮肤渲染建模

皮肤渲染过程可由两个分量组成：

-   镜面反射（specular reflection）

-   次表面散射（subsurface scattering）

其中，次表面散射的真实感模拟，是主要难点。

## 2. 镜面反射部分

镜面反射（specular reflection）部分的光照模型可用：

-   Torrance-Sparrow

-   Kelemen and Szirmay-Kalos specular BRDF

-   基于物理其他高光模型

其中，Kelemen and Szirmay-Kalos specular BRDF在实现和Torrance-Sparrow模型一样的渲染效果时，计算量要小得多。

## 3. 次表面散射部分

### 3.1 扩散剖面（Diffusion Profile）

扩散剖面（diffusion profile）是描述光线如何在半透明物体中进行扩散和分布的函数。

与扩散剖面常一起出现的三种方法：

-   偶极子（Dipole）方法

-   多级子（Multipole）方法

-   高斯和（Sum-of-Gaussians）方法

它们都是更好地描述出扩散剖面（Diffusion Profiles）的一些策略。得到扩散剖面（diffusion profile），即光线是如何在半透明物体中进行扩散和分布之后，接下来就可以对附近的像素进行加权求和，以模拟次表面散射的效果。这个求和的过程其实是根据扩散剖面（diffusion profile）的指导，对周围像素进行模糊操作。

按操作空间划分，常规的思路有两种：

-   纹理空间模糊（Texture Space Blur）

-   屏幕空间模糊（Screen Space Blur），也称屏幕空间次表面散射（Screen Space
    SubSurfaceScattering）或SSSSS。

### 3.2 其他皮肤渲染技术

-   半透明阴影贴图（Translucent Shadow Maps，TSMs）

-   预积分的皮肤渲染（Pre-Integrated Skin Rendering）

-   可分离的次表面散射（SSSS , Separable Subsurface Scattering）

-   路径追踪次表面散射（Path-Traced Subsurface Scattering）与光线步进（Ray Marching）

-   Deferred Single Scattering

## 4. 皮肤渲染技术发展史

-   次表面光照传输模型（Subsurface Light Transport, SSLT）[2001]

-   扩散剖面（Diffusion Profile） [2001]

-   偶极子（dipole） [2001]

-   纹理空间模糊（Texture Space Blur）[2003]

-   多极子（multipole） [2005]

-   屏幕空间模糊（Screen Space Blur）或屏幕空间次表面散射（SSSSS,Screen Space SubSurface Scattering）[2009]

-   路径追踪次表面散射（Path-Traced Subsurface Scattering）与光线步进（Ray Marching）[2009]

-   预积分的皮肤着色（Pre-Integrated Skin Shading）[2010]

-   可分离的次表面散射（SSSS,Separable Subsurface Scattering）[2015]

-   等

<br>

# 八、参考文献
<br>

[1] Eugene d'Eon, David Luebke. GPU Gems 3, Chapter 14. Advanced Techniques for Realistic Real-Time Skin Rendering,2007.(<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch14.html>)

[2] Volumetric Skin and Fabric Shading at Framestore , SIGGRAPH 2017 Course: Physically Based Shading in Theory and Practice（<http://blog.selfshadow.com/publications/s2017-shading-course/walster/s2017_pbs_volumetric_notes.pdf>）

[3] Rendering AAA-QualityCharacters of Project ‘A1’, NDC 2016 Programming Session

[4] <https://zhuanlan.zhihu.com/p/27014447>

[5] <http://gad.qq.com/article/detail/33372>

[6] <http://gad.qq.com/article/detail/33373>

[7] <http://www.iryoku.com/next-generation-life>

[8] <https://gamingbolt.com/final-fantasy-15s-in-game-characters-are-as-impressive-as-the-pre-rendered-ones>

[9] Next-Generation-Character-Rendering ，GDC 2013 <http://www.iryoku.com/images/posts/next-generation-life/Next-Generation-Character-Rendering-Teaser.pptx>

[10] <https://en.wikipedia.org/wiki/Bidirectional_scattering_distribution_function>

[11] Jensen, Henrik Wann, Stephen R. Marschner, Marc Levoy, and Pat Hanrahan.2001. "A Practical Model for Subsurface Light Transport." In Proceedings of SIGGRAPH 2001.

[12]  Matlab online doc <https://cn.mathworks.com/help/curvefit/gaussian.html>

[13]d'Eon, Eugene."NVIDIA Demo Team Secrets–Advanced Skin Rendering." Presentation at Game Developer Conference 2007. <http://developer.download.nvidia.com/presentations/2007/gdc/Advanced_Skin.pdf>.

[14]  Jorge Jimenez, Károly Zsolnai, etc. Separable Subsurface Scattering(<http://iryoku.com/separable-sss/>)

[15]   Faceworks <https://github.com/NVIDIAGameWorks/FaceWorks>

[16]  Colin Barre-Brisebois,Marc Bouchard. 2011. Presentation at Game Developer
Conference 2011. <https://colinbarrebrisebois.com/2011/03/07/gdc-2011-approximating-translucency-for-a-fast-cheap-and-convincing-subsurface-scattering-look/>

[17] Jorge Jimenez, David Whelan, etc. Real-Time Realistic Skin Translucency(<http://iryoku.com/translucency/downloads/Real-Time-Realistic-Skin-Translucency.pdf>)

[18] orge Jimenez. Next Gen Character Rendering GDC 2013.

[19] Koki Nagano，Graham Fyffe，Oleg Alexander etc."Skin Microstructure Deformation with Displacement Map Convolution"<http://gl.ict.usc.edu/Research/SkinStretch/>

[20] RenderDoc. <https://github.com/baldurk/renderdoc>

[21] Per H. Christensen, Brent Burley. "Approximate Reflectance Profiles for Efficient Subsurface Scattering" Presentation at SIGGRAPH 2015. <https://graphics.pixar.com/library/ApproxBSSRDF/paper.pdf>

[22] Per H. Christensen, Brent Burley. "Approximate Reflectance Profiles for Efficient Subsurface Scattering" Presentation at SIGGRAPH 2015. <https://graphics.pixar.com/library/ApproxBSSRDF/paper.pdf>

```

`Content/《GPU Gems 3》全书提炼总结/Part2/README.md`:

```md
![](media/title.jpg)
1
# 《GPU Gems 3》全书核心内容提炼总结

本文的知乎专栏版本：
https://zhuanlan.zhihu.com/p/44671434


本文是【GPU精粹与Shader编程】系列的第七篇文章。文章盘点、提炼和总结了《GPU Gems 3》全书总计28章的核心内容。

同时这篇文章，也是【GPU精粹与Shader编程】系列文章对GPU精粹三部曲中《GPU Gems》、《GPU Gems 2》、《GPU Gems 3》组成的第一部曲的完结篇，是一个短暂的里程碑。

下篇文章，将开启全新的《GPU Pro》系列。


![](media/d51868713d19a9460a1f8171d3fa929f.jpg)

<br>

 # 快捷导航目录
<!-- TOC -->

- [《GPU Gems 3》全书核心内容提炼总结](#gpu-gems-3全书核心内容提炼总结)
- [《GPU Gems 3》全书核心框架脉络思维导图](#gpu-gems-3全书核心框架脉络思维导图)
- [第一部分 几何体（Geometry）](#第一部分-几何体geometry)
- [第1章 使用GPU 生成复杂的程序化地形（Generating Complex Procedural Terrains Using the GPU）](#第1章-使用gpu-生成复杂的程序化地形generating-complex-procedural-terrains-using-the-gpu)
    - [【关键词】](#关键词)
    - [【内容盘点】](#内容盘点)
- [第2章 群体动画渲染（Animated Crowd Rendering）](#第2章-群体动画渲染animated-crowd-rendering)
    - [【关键词】](#关键词-1)
    - [【内容盘点】](#内容盘点-1)
- [第3章 DirectX 10 中的混合形状（DirectX 10 Blend Shapes: Breaking the Limits）](#第3章-directx-10-中的混合形状directx-10-blend-shapes-breaking-the-limits)
    - [【关键词】](#关键词-2)
    - [【内容盘点】](#内容盘点-2)
- [第4章 下一代SpeedTree 渲染（Next-Generation SpeedTree Rendering）](#第4章-下一代speedtree-渲染next-generation-speedtree-rendering)
    - [【关键词】](#关键词-3)
    - [【内容盘点】](#内容盘点-3)
- [第5章 通用自适应网格细化（Generic Adaptive Mesh Refinement）](#第5章-通用自适应网格细化generic-adaptive-mesh-refinement)
    - [【关键词】](#关键词-4)
    - [【内容盘点】](#内容盘点-4)
- [第6章 对于树的GPU 生成程序式风动画（GPU-Generated Procedural Wind Animations for Trees）](#第6章-对于树的gpu-生成程序式风动画gpu-generated-procedural-wind-animations-for-trees)
    - [【关键词】](#关键词-5)
    - [【内容盘点】](#内容盘点-5)
- [第7章 GPU 上基于点的变形球可视化（Point-Based Visualization of Metaballs on a GPU）](#第7章-gpu-上基于点的变形球可视化point-based-visualization-of-metaballs-on-a-gpu)
    - [【关键词】](#关键词-6)
    - [【内容盘点】](#内容盘点-6)
- [第二部分 光照和阴影（Light and Shadows）](#第二部分-光照和阴影light-and-shadows)
- [第8章 区域求和的差值阴影贴图（Summed-Area Variance Shadow Maps）](#第8章-区域求和的差值阴影贴图summed-area-variance-shadow-maps)
    - [【关键词】](#关键词-7)
    - [【内容盘点】](#内容盘点-7)
- [第9章 使用全局光照交互电影级重光照（Interactive Cinematic Relighting with Global Illumination）](#第9章-使用全局光照交互电影级重光照interactive-cinematic-relighting-with-global-illumination)
    - [【关键词】](#关键词-8)
    - [【内容盘点】](#内容盘点-8)
- [第10章 在可编程GPU 上实现并行分割阴影贴图（Parallel-Split Shadow Maps on Programmable GPUs）](#第10章-在可编程gpu-上实现并行分割阴影贴图parallel-split-shadow-maps-on-programmable-gpus)
    - [【关键词】](#关键词-9)
    - [【内容盘点】](#内容盘点-9)
- [第11章 基于层次化的遮挡剔除和几何着色器的高效鲁棒阴影体（Efficient and Robust Shadow Volumes Using Hierarchical Occlusion Culling and Geometry Shaders）](#第11章-基于层次化的遮挡剔除和几何着色器的高效鲁棒阴影体efficient-and-robust-shadow-volumes-using-hierarchical-occlusion-culling-and-geometry-shaders)
    - [【关键词】](#关键词-10)
    - [【内容盘点】](#内容盘点-10)
- [第12章 高质量的环境光遮蔽（High-Quality Ambient Occlusion）](#第12章-高质量的环境光遮蔽high-quality-ambient-occlusion)
    - [【关键词】](#关键词-11)
    - [【内容盘点】](#内容盘点-11)
- [第13章 后处理特效：体积光散射（Volumetric Light Scattering as a Post-Process）](#第13章-后处理特效体积光散射volumetric-light-scattering-as-a-post-process)
    - [【关键词】](#关键词-12)
    - [【内容盘点】](#内容盘点-12)
- [第三部分 渲染（Rendering）](#第三部分-渲染rendering)
- [第14章 用于真实感实时皮肤渲染的高级技术（Advanced Techniques for Realistic Real-Time Skin Rendering）](#第14章-用于真实感实时皮肤渲染的高级技术advanced-techniques-for-realistic-real-time-skin-rendering)
    - [【关键词】](#关键词-13)
    - [【内容盘点】](#内容盘点-13)
- [第15章 可播放的全方位动作捕捉（Playable Universal Capture）](#第15章-可播放的全方位动作捕捉playable-universal-capture)
    - [【关键词】](#关键词-14)
    - [【内容盘点】](#内容盘点-14)
- [第16章 Crysis 中植被的程序化动画和着色（Vegetation Procedural Animation and Shading in Crysis）](#第16章-crysis-中植被的程序化动画和着色vegetation-procedural-animation-and-shading-in-crysis)
    - [【关键词】](#关键词-15)
    - [【内容盘点】](#内容盘点-15)
- [第17章 鲁棒的多镜面反射和折射（Robust Multiple Specular Reflections and Refractions）](#第17章-鲁棒的多镜面反射和折射robust-multiple-specular-reflections-and-refractions)
    - [【关键词】](#关键词-16)
    - [【内容盘点】](#内容盘点-16)
- [第18章 用于浮雕映射的松散式锥形步进（Relaxed Cone Stepping for Relief Mapping）](#第18章-用于浮雕映射的松散式锥形步进relaxed-cone-stepping-for-relief-mapping)
    - [【关键词】](#关键词-17)
    - [【内容盘点】](#内容盘点-17)
- [第19章 《Tabula Rasa》中的延迟着色（Deferred Shading in Tabula Rasa）](#第19章-tabula-rasa中的延迟着色deferred-shading-in-tabula-rasa)
    - [【关键词】](#关键词-18)
    - [【内容盘点】](#内容盘点-18)
- [第20章 基于GPU的重要性采样（GPU-Based Importance Sampling）](#第20章-基于gpu的重要性采样gpu-based-importance-sampling)
    - [【关键词】](#关键词-19)
    - [【内容盘点】](#内容盘点-19)
- [第四部分 图像效果（Image Effects）](#第四部分-图像效果image-effects)
- [第21章 真实Impostor（True Impostors）](#第21章-真实impostortrue-impostors)
    - [【关键词】](#关键词-20)
    - [【内容盘点】](#内容盘点-20)
- [第22章 在GPU上烘焙法线贴图（Baking Normal Maps on the GPU）](#第22章-在gpu上烘焙法线贴图baking-normal-maps-on-the-gpu)
    - [【关键词】](#关键词-21)
    - [【内容盘点】](#内容盘点-21)
- [第23章 高速的离屏粒子（High-Speed, Off-Screen Particles）](#第23章-高速的离屏粒子high-speed-off-screen-particles)
    - [【关键词】](#关键词-22)
    - [【内容盘点】](#内容盘点-22)
- [第24章 保持线性的重要性（The Importance of Being Linear）](#第24章-保持线性的重要性the-importance-of-being-linear)
    - [【关键词】](#关键词-23)
    - [【内容盘点】](#内容盘点-23)
- [第25章 在GPU 上渲染矢量图（Rendering Vector Art on the GPU）](#第25章-在gpu-上渲染矢量图rendering-vector-art-on-the-gpu)
    - [【关键词】](#关键词-24)
    - [【内容盘点】](#内容盘点-24)
- [第26章 通过颜色进行对象探测：使用 GPU 进行实时视频图像处理（Object Detection by Color: Using the GPU for Real-Time Video Image Processing）](#第26章-通过颜色进行对象探测使用-gpu-进行实时视频图像处理object-detection-by-color-using-the-gpu-for-real-time-video-image-processing)
    - [【关键词】](#关键词-25)
    - [【内容盘点】](#内容盘点-25)
- [第27章 后处理效果：运动模糊（Motion Blur as a Post-Processing Effect）](#第27章-后处理效果运动模糊motion-blur-as-a-post-processing-effect)
    - [【关键词】](#关键词-26)
    - [【内容盘点】](#内容盘点-26)
- [第28章 实用景深后期处理（Practical Post-Process Depth of Field）](#第28章-实用景深后期处理practical-post-process-depth-of-field)
    - [【关键词】](#关键词-27)
    - [【内容盘点】](#内容盘点-27)
- [【GPU精粹三部曲】 Part I • 尾声](#gpu精粹三部曲-part-i-•-尾声)

<!-- /TOC -->


<br>


# 《GPU Gems 3》全书核心框架脉络思维导图


以下是《GPU Gems 3》全书核心章节的思维导图：

![](media/struct.png)

**PS:原图过大，网页端可能显示并不清晰，建议将原图另存为本地图片后查看**

另外值得注意的几点是：
- 《GPU Gems 3》出版于2007年8月12日，全书共1008页，41章。
- 《GPU Gems 3》的英文原版已经由NVIDIA开源： https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_pref01.html
- 本文对《GPU Gems 3》全书渲染相关的前28章进行了盘点、提炼与总结。
- 本文正文可以作为一个文字版的索引，方便后续通过此文，对《GPU Gems 3》一书的内容进行快速分类检索与对应章节的深入阅读与研究。


OK，下面开始正文。

<br>

# 第一部分 几何体（Geometry）

<br>

# 第1章 使用GPU 生成复杂的程序化地形（Generating Complex Procedural Terrains Using the GPU）


## 【关键词】

- 程序化地形（Procedural Terrains）

- MC（Marching Cubes）算法

- 密度函数（Density Function）

- 地形生成（Terrain Generation）

## 【内容盘点】

作为《GPU精粹3》的开篇章节，这章给出了一个使用GPU在交互速率下生成复杂程序化三维地形的方法。同样也展示了如何对地形进行纹理映射和着色、如何为地形创建LOD的方案。

阅读这一章时让我想起了近年两款大作《地平线：黎明》和《幽灵行动：荒野》在GDC 2017上关于程序化地形和植被生成的分享：

-   GPU-Based Procedural Placement in Horizon Zero Dawn，GDC
    2017（https://d1z4o56rleaq4j.cloudfront.net/downloads/assets/GDC2017_VanMuijden_GPUBasedProceduralPlacementInHorizonZeroDawn.pptx?mtime=20170307152717）

-   Ghost Recon Wildlands: Terrain Tools and Technology，GDC 2017（https://666uille.files.wordpress.com/2017/03/gdc2017_ghostreconwildlands_terrainandtechnologytools-onlinevideos1.pptx）

这边是《幽灵行动：荒野》在GDC 2017程序化地形技术演示视频：

<https://www.youtube.com/watch?v=JIQ_YVwUONA>

而这边是《地平线：黎明》中Decima Engine程序化地形和植被生成的演示视频：

<https://www.youtube.com/watch?v=t258ePDlxtQ>

![](media/a4cde33622cc2ed0f6f5c04688ea3c54.jpg)

图《地平线：黎明》的地形和植被程序化生成

![](media/33b8ebd4e3c5a23065c1332bcf896443.jpg)

图《地平线：黎明》的地形和植被程序化生成

![](media/03be2d49ee425613b792d00ea12b09af.jpg)

图 《幽灵行动：荒野》中程序化地形的11+种生物群系和140+种地表材质

![](media/0c59fca2969cd395b282c51d43a4b557.jpg)

图 《幽灵行动：荒野》的 32k x 32k x 4 layer的程序化地形大世界，让其成为了育碧至今地形最大的开放世界游戏

![](media/2c82f47e3a48ad616d658a3963669831.jpg)

图 《幽灵行动：荒野》中基于程序化地形的16平方公里的湖面，河流和溪流面积

![](media/b52b81a8e3bdfa7a9377e916297cf2a7.jpg)

图 《幽灵行动：荒野》中基于程序化地形的超过600公里的道路

OK,回到本章内容中来。

传统上，程序化地形（Procedural Terrains）受限于CPU生成的，且用GPU进行渲染的高度场（Height Fields）。然而，生成复杂地形是一项高度并行化的任务，CPU的串行处理本质上不适合完成这项工作。此外，CPU生成高度场的方法也无法很好地提供吸引人的地形特征（如凹洞和凸起物）。为了交互级的帧率下生成高度复杂的程序化地形，文中使用GPU和来进行此项工作。

理论上，地形表面可以用单个函数完整地进行描述，这个函数被称为密度函数（Density Function）。

![](media/f4e51841acd31a96df940bf4ffdc8eb2.jpg)

图 一个已知8个棱角密度（Density）值的体素（黑点指示了棱角处的正密度值，每个棱角为一个“位（byte）”，用于在总共8位的情况中进行判断）

使用GPU来生成地形块所需要的多边形，这个块进行进而被细分成 32 x 32 x 32的小单元，即体素（Voxel）。Marching Cubes算法允许我们在一个单独的体素中生成正确的多边形。MarchingCubes(简称MC)算法是面绘制算法中的经典算法，它是W.Lorensen等人于1987年提出来的一种体素级重建方法。MarchingCubes算法也被称为“等值面提取”(Isosurface Extraction)算法。

下图阐述了应用Marching Cube算法的一些基本案例

![](media/50c75e857633753d88619a35ff5db407.jpg)

图 Marching Cubes算法的14种基本案例（而其他的240种案例仅仅是这些纪元案例的旋转或翻转的结果）

首先，将世界划分成无限数目的等大小立方体块。在世界空间坐标系中，每个立方块的大小为1 x 1 x 1。然而，每个块中有32\^3个体素可能含有多边形。为当前视锥可视的地形块动态划分一个含有大约300个顶点缓冲区的内存池，较近的块具有较高的优先权。随着用户的移动，当有新的地形块进入视锥时，视锥中被裁掉的最远或最近的顶点缓冲区便被回收，以被新的块使用。

而对每一帧的渲染思路方面，文中的思路是，根据位置从前到后对所有的顶点缓冲区进行排序（它们的包围盒已知）。然后生成所有需要的立方体块，剔除最远距离的块。最终，按照从前到后的顺序绘制各个块，以免在被遮挡的块上进行像素着色时浪费大量的时间。

本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch01.html>


<br>

# 第2章 群体动画渲染（Animated Crowd Rendering）

## 【关键词】

- 群体动画渲染（Animated Crowd Rendering）

- 蒙皮实例化（Skinned Instancing）

- 性能优化（Performance Optimization）

- Draw Call降低（Reduce Draw Call）

## 【内容盘点】

使用实例化(instancing)方法，可以通过减少Draw Call、状态更改以及缓冲区更新的数量来减少CPU的开销。

这章中展示了如何使用顶点纹理存取的DirectX 10实例化来实现基于硬件调色板的蒙皮角色（skinned characters）。这个demo同时使用了常量缓冲区和系统变量SV_InstanceID来有效实现这项技术。在Intel Core 2 Duo GeForce 8800 GTX显卡上，能够实现大约1万个人物拥有不同的动画和蒙皮。

![](media/b65a446e2f584b24dbd2288fa7275c1b.jpg)

图 动画人群的特写镜头

![](media/823c6c824b0968fb51379630e44a3893.jpg)

图 使用Skinned实例化的群体动画

蒙皮实例化（Skinned
instancing）这项技术适用于实时地渲染数量庞大且彼此独立的动画人物。它使用顶点纹理存取来读取存储在单一纹理中的动画数据，也使用了SV_InstanceID来索引包含了示例数据的常量缓冲区（位置和动画时间）。而配合一个简单易行的LOD系统，能在合适距离上有更高的多边形/光照细节。

![](media/975eed2faba219d50391c7f4e516c8ad.jpg)

图 Instancing Basics

![](media/2457d3852593da2ab9a4974b494a49c2.jpg)

图 LOD数据的布局

本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch02.html>


<br>

# 第3章 DirectX 10 中的混合形状（DirectX 10 Blend Shapes: Breaking the Limits）


## 【关键词】

- 混合形状（blend shapes）

- 流输出方法（Stream-Out Method）

- 缓冲区-模板方法（Buffer-Template Method）

## 【内容盘点】

本章中，作者展示了流输出方法（Stream-Out Method）和缓冲区-模板方法（Buffer-Template Method）两种方法，来突破之前基于GPU加速的混合形状的应用限制。

![](media/c1999f7b212b1c30538d244a5879eeac.jpg)

图 Little Vampire blendshapes\@ Artstation by Jimmy Levinsky

![](media/0b5dae2a69aadbd7bb45c28993d1cca0.jpg)

图 Dawn Demo中拥有50多个混合形状的角色

上图是基于上述两种方案在模型Dawn的脸上组合出了54种面部表情的Demo。

其中，流输出方法（Stream-Out Method）可以打破DirectX
10中属性个数限制，思路是使用迭代的方式来操作网格。通过在每个pass中组织当前活动混合形状的子集（subset），只需每个pass中少量的属性。

![](media/42c203482568ecb633e60fd33b0da2cd.jpg)

图 一次仅使用全部混合形状的一个子集

而缓冲区-模板方法（Buffer-Template Method）的思路是使用GPU来实现遍历（与流输出方法类似）。DirectX 10通过在顶点着色器中提供流控制来管理遍历，并提供了将缓冲区与着色器资源视图相绑定以存取数据的能力，进而使得GPU遍历成为可能。

![](media/9e46973e32bb29a49414fe1f9775f569.jpg)

图 使用循环来减少API调用

本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch03.html>


<br>

# 第4章 下一代SpeedTree 渲染（Next-Generation SpeedTree Rendering）


## 【关键词】

- SpeedTree

- 植物渲染（Vegatable Rendering）

- 轮廓裁剪（Silhouette Clipping）

- 树叶光照（Leaf Lighting）

- 半透明覆盖算法（Alpha to Coverage）

## 【内容盘点】

众所周知，SpeedTree是Interactive Data Visualization, Inc.(IDV)公司出品的用来实时渲染树木的中间件。

![](media/46b6e4c05331af9fe85cd6274d039663.jpg)

图 SpeedTree效果图 @ARK

![](media/91bab10a8173cf05eb174fefeeb093f5.jpg)

图 SpeedTree示例

![](media/58cf1d37a902c881c0f5971aa71acb75.jpg)

图 SpeedTree示例

文章提到，使用了SpeedTree的游戏可以对渲染方式进行更为灵活的选择。在本章中，使用了当时较新的显卡GeForce 8800的几个特性为SpeedTree生成下一代高质量的扩展。首先，轮廓剪切增加了树枝和树干外形的细节。其次，阴影贴图提供了逐树叶级的真实感自我遮挡。除此之外，我们进一步使用了双页面光照模型和高动态范围渲染来优化光照。最后，多重采样和抗锯齿和半透明覆盖（alpha to coverage）提供了非常高的视觉质量，避免了锯齿的失真。

本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch04.html>

<br>

# 第5章 通用自适应网格细化（Generic Adaptive Mesh Refinement）


## 【关键词】

- 自适应网格优化（Adaptive Mesh Refinement）

- 自适应优化模型（Adaptive Refinement Patterns，ARP）

- 深度标签（Depth-Tagging）

## 【内容盘点】

这章给出了一个单通道的、具有普通适性的顶点程序，以对任意拓扑形状的网络进行动态的自适应优化。

![](media/7dadeebc3a7f17d4ce2a89a9d246fc69.jpg)

图 文中的通用自适应网格细化的工作流架构

从静态或动态的粗网格开始，该顶点程序用存储在GPU存储器中的一组预镶嵌图案中的细化三角形补丁（refined triangular patch）替换每个三角形，所述三角形补丁根据所需的局部几何细化量来选择。

通过在参数空间中对这些模式进行编码，这种一对多（one-to-many），即时的（on-the-fly）三角形替换被转换为顶点位移函数的简单重心插值，其可以由用户提供，也可以在现有的数据基础上进行计算。除了顶点位移之外，在细化过程中还可以使用相同的过程来插值任何其他每顶点属性。

该方法在某种意义上是完全通用的，即对网格拓扑，位移函数或细化级别没有任何限制。

![](media/f7e02cc22c01b161f31df3a19e3741ac.jpg)

图 自适应细化的模式

![](media/ecf4789edef406289e235d5b56244611.jpg)

图 通过深度标记控制自适应GPU细化


本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch05.html>

<br>

# 第6章 对于树的GPU 生成程序式风动画（GPU-Generated Procedural Wind Animations for Trees）


## 【关键词】

- 程序式风动画（Procedural Wind Animations）

- 树木动画渲染（Rendering Tree Animation）

- 噪声（Noise）

- 风场（Wind Field）


## 【内容盘点】

这章描述了一个程序式的方法，可以生成真实受风场影响的树木动画。该方法的主要目标是实现具有大量植被的大型开放环境的模拟和可视化。

具体而言，这是一种在受到诸如风场等外力影响的情况下合成树木运动的方案，基于将树木运动建模为随机过程（stochastic processes）等方法，并通过添加简单规则对其进行扩展，同时模拟树枝行为中的空气动力学特性。文中还提供了基于GPU的流体模拟与文中方法相结合的方案，以改善对风的真实感的模拟。文中还给出了在GPU上进行运动合成的详细说明，以及基于DirectX 9和DirectX 10的运动合成方法的实现。

![](media/ff0fabd6160adbe2889004b1386a8099.jpg)

图 由三层节点深层结构表示的树结构

![](media/c58040a2e1ba5707bbecb700d64f1049.jpg)

图 用于驱动树干动画的噪声函数

![](media/fdc4c89efa2af38eaef589eb11564d83.jpg)

图 影响给定顶点的分支索引列表，其存储在顶点属性中

![](media/3e31023af5f26b3367453961604fec93.jpg)

图6-8为每个分支合成角运动（Angular Motion）

![](media/e72a0763e0fe712f08b0954aebaea7ab.jpg)

图  DirectX 10下的GPU管线

本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch06.html>


<br>

# 第7章 GPU 上基于点的变形球可视化（Point-Based Visualization of Metaballs on a GPU）


## 【关键词】

- 元球/变形球（metaball）

- 表面粒子（Surface Particles）

- 局部粒子斥力（Local Particle Repulsion）

- 哈希表（Hash Table）

- 限制粒子（Constraining Particles）


## 【内容盘点】

变形球（metaball），又常译作元球，是计算机图形学中的 n维物体。变形球渲染技术最初由 Jim Blinn 于1980年代初提出。

![](media/70bfeadf5613b41733fcc2d7c79671fe.gif)

图 两个变形球的融合

这章给出了一种在GPU上以交互式速率渲染变形球的方法，其有效且高效地在GPU上实现了Withkin and Heckbert 1994的基于点的隐式表面可视化，在保持互动级帧速率的情况下渲染变形球。

该方法由三部分组成：计算受限速度、斥力及粒子密度，来实现接近一致的粒子分布。

需要注意的是，该方法并不是采用步进立方体（Marching Cubes）算法来生成多边形列表，而是通过将自由移动的粒子约束到这个表面来对元球的隐式表面进行采样。其的目标是通过渲染数千个粒子将元球可视化为光滑表面，每个粒子覆盖一个微小的表面区域。

为了在GPU上成功应用这种基于点的技术，文中解决了三个基本问题。首先，需要评估元球的隐式函数及其每个渲染粒子的梯度，以便将粒子约束到曲面。为此，文章设计了一种新颖的数据结构，用于快速评估片段着色器中的隐式函数。其次，需要将颗粒均匀地分布在表面上。对此，文章提出了一种快速方法，用于在每个粒子上执行最近邻搜索，在GPU上进行两次渲染传递。该方法用于根据平滑粒子流体动力学方法计算排斥力。第三，为了进一步加速颗粒分散，文中也提出了一种将颗粒从高密度区域转移到表面上的低密度区域的方法。

![](media/638a91dafc048694023c2d3faa2583f3.jpg)

图 CPU上执行的流体模拟循环以及在GPU上执行的流体可视化循环

![](media/0f3c5e9abd04e726fabdfb47f5c818b0.jpg)

图 排斥（Repulsion）算法

![](media/30590425ddd695dbd196eb584bdf233b.jpg)

图 逐粒子光照、带有纹理和混合的流表面。
左图为无重力环境中的圆块状对象，右图为杯子中的水

本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch07.html>

<br>

# 第二部分 光照和阴影（Light and Shadows）

<br>

# 第8章 区域求和的差值阴影贴图（Summed-Area Variance Shadow Maps）


## 【关键词】

- 差值阴影贴图（Variance Shadow Maps）

- 区域求和差值阴影贴图(Summed-Area Variance Shadow Maps,SAVSM)

- 百分比临近过滤（Percentage-Closer Filtering）


## 【内容盘点】

这章主要讨论了阴影贴图过滤和柔和阴影，回顾了差值阴影贴图算法，并解释了如何用它来解决很多常见的阴影贴图问题（如缩变锯齿、偏移及软阴影）。同时还介绍了一种简单且有效的技术，该技术能够显著减少差值阴影贴图（Variance Shadow Maps，VSM）中的light-bleeding失真。最后，文章介绍了一种基于差值阴影贴图（Variance Shadow Maps，VSM）和区域求和表（Summed-Area Tables,SAT）的实时阴影算法。

对任意的方波过滤器区域，该算法都能有效地计算出阴影权值，最终文章得出结论，区域求和的差值阴影贴图（Summed-Area Variance Shadow Mapping ,SAVSM）是计算没有锯齿现象的柔和阴影的理想算法。

![](media/4c0f97a550e41a889c4bf88089e8f664.jpg)

图8-10样本数据和相关的区域求和表

![](media/3995354e628efa57d645e3a252bc18f8.jpg)

图 区域求和的基于差值阴影贴图（Summed-Area Variance Shadow Mapping ,SAVSM）算法渲染的硬边和软边阴影

![](media/baebeba920da674057d6d15de53738ae.jpg)

图 文中基于区域求和的差值阴影贴图技术渲染出的效果图

![](media/195e0fefa9631a3a0a368dd3e78c48c3.jpg)

图 文中基于区域求和的差值阴影贴图技术渲染出的效果图

本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch08.html>

<br>

# 第9章 使用全局光照交互电影级重光照（Interactive Cinematic Relighting with Global Illumination）

## 【关键词】

- 全局光照（Global Illumination）

- 重光照（Relighting）

- 间接光照（indirect illumination）

- 压缩稀疏矩阵（Packing Sparse Matrix Data）

## 【内容盘点】

这章中介绍了用于电影级光照设计的GPU重光照（Relighting）引擎。该方法对传统的帧缓存方法进行了扩展，支持多次反射的间接光照，可应用于具有高几何复杂性、光泽材质和使用程序化着色器所得到的灵活的直接光照模型的场景。

![](media/dec217d782fce2558879e89c123d47bf.jpg)

图 文中的重光照算法架构

以下是文中重光照算法的完整伪代码：

    Texture computeLighting(light, viewSamples, gatherSamples)
    {

        // Direct illumination on view and gather samples
        viewDirect = computeDirectIllumination(light, viewSamples);
        gatherDirect = computeDirectIllumination(light, gatherSamples);

        // Multibounce indirect illumination on gather samples
        gatherDirectWavelet = waveletTransform(gatherDirect);
        gatherIndirect =sparseMultiply(multiBounceWaveletMatrix, gatherDirectWavelet);
        gatherFull = gatherDirect + gatherIndirect;

        // Final bounce from gather to view samples
        gatherFullWavelet = waveletTransform(gatherFull);
        viewIndirect =sparseMultiply(finalGatherWaveletMatrix, gatherFullWavelet);

        // Combine into final image.
        viewFull = viewDirect + viewIndirect;

        return viewFull;

    }

![](media/a42c764024d783ef2c7980a86a47d28f.jpg)

图 该文中介绍的系统中使用点光源灯和聚光灯渲染的场景

本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch09.html>


<br>

# 第10章 在可编程GPU 上实现并行分割阴影贴图（Parallel-Split Shadow Maps on Programmable GPUs）


## 【关键词】

- 并行分割阴影贴图（Parallel-split shadow maps，PSSMs）

- 阴影贴图（Shadow Maps）

- 多阴影贴图(Multiple Shadow Maps)

- 几何着色器克隆(Geometry Shader Cloning)

## 【内容盘点】

本章提出了一种高级阴影贴图技术——“并行分割阴影贴图（Parallel-Split Shadow
Maps，PSSMs）”，可以在大型环境中提供抗锯齿和实时的光影效果，文章同样展示了在目前的可编程GPU中这种技术的实现细节，提供了多种实现方式。

在此技术中，视锥体使用平行于投影面积的多个剪辑平面被分割成多个深度层，并且每个层会被一个独立的阴影贴图所渲染。如下图所示。

该算法主要步骤有：

-   步骤1：分割视锥体（Splitting the View Frustum）

-   步骤2：计算光的变换矩阵（Calculating Light's Transformation Matrices）

-   步骤3和4：产生PSSMs和综合阴影（Generating PSSMs and Synthesizing Shadows）

![](media/47706ccfd7776590467469733224e666.jpg)

图PSSMs对三个特定于硬件实现的渲染管线的可视化

![](media/0a754fdc0b823495b997af96ab509c53.jpg)

图 并行分割的阴影贴图在Dawnspire：Prelude游戏中的应用

![](media/2147135beacf619394059f486b27302f.jpg)

图 SSM和Multipass PSSM的比较

![](media/3e490b660bdd5988fea97956aadef8ae.jpg)

图 渲染阴影贴图基于几何着色器克隆(Geometry Shader Cloning)的GPU渲染管道

本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch10.html>

<br>

# 第11章 基于层次化的遮挡剔除和几何着色器的高效鲁棒阴影体（Efficient and Robust Shadow Volumes Using Hierarchical Occlusion Culling and Geometry Shaders）


## 【关键词】

- 阴影体（Shadow Volumes）

- 层次化的遮挡剔除（Hierarchical Occlusion Culling）

- 几何着色器（Geometry Shaders）

## 【内容盘点】

这章通过使用非常规的生成阴影几何体的方法，实现了一种非常鲁棒的阴影体渲染技术，该技术对于复杂的网格模型同样有效。通过结合层次硬件遮挡查询（hierarchical hardware occlusion）和几何着色器，文章同样在那些之前使用模板阴影效果不太好的场景中达到了很高的性能。该方法的实现主要包括，针对低质量网络的鲁棒阴影，使用几何体着色器动态生成阴影体，使用层次化遮挡裁剪提高性能，三个部分。

![](media/6d91b46de19d9e16d359ac793f5a22ed.jpg)

图 使用动态阴影体方法生成的实时渲染效果

本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch11.html>

<br>

# 第12章 高质量的环境光遮蔽（High-Quality Ambient Occlusion）


## 【关键词】

- 环境光遮蔽（Ambient Occlusion）

- 平滑处理不连续（Smoothing Discontinuities）

- 波形因子（form factor）

## 【内容盘点】

Buuel在2005年提出了一种新技术来对环境光遮蔽进行近似，所采用的方法是将遮蔽整合到自适应对模型层次的遍历过程中。这种技术在模拟光滑变动的阴影方面效果很好，但对于输入模型，在高质量的应用方面不够鲁棒。

本章对该方法进行了阐述，并在实践中进行了改进，使其更实用，对更普遍的模型的更加鲁棒。思路方面，保持算法的基本骨架不变
-该章节内容自适应地对存储在树中的粗遮挡解决方案中的遮挡进行求和，而一些关键变化显着提高了结果的稳健性，最终得到了令人信服的光滑的软阴影，以及具有真实感的多样局部细节。而改进思路方面，可分为，对不连续处进行平滑滑处理（Smoothing Discontinuities），和移除尖点并加入细节（Removing Pinches and Adding Detail）两部分。

![](media/b26f5c3cf86c0b775d7052c84035b1ef.jpg)

图 不连续处的平滑处理：过渡区的几何

![](media/d5d465fa63ee264b8fd9c38097046b77.jpg)

图 移除尖点并加入细节：将三角形剪切为可见的四边形

![](media/a13a3b8fa9cfc84d4c1084f044e67240.jpg)

图
本章算法实现的汽车模型中环境光遮蔽的比较【左上：应用于逐顶点的原始算法；左下：应用于逐片段的原始算法；右上：应用于平面法线（flat
normals）的新算法；右下：应用于光滑着色法线的新算法】

本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch12.html>

<br>

# 第13章 后处理特效：体积光散射（Volumetric Light Scattering as a Post-Process）


## 【关键词】

- 体积光散射（Volumetric Light Scattering）

- 后处理（Post-Process）

- 云隙光（Crepuscular Rays）

- 屏幕空间遮蔽（Screen-Space Occlusion）

## 【内容盘点】

本章中提出了一种简单的后处理方法，该方法可以产生由于大气中阴影引起的体积光散射效果。我们对已有的日光散射（daylight scattering）的分析模型进行了改进，将体遮挡效果包含在内，并且给出了其在像素着色器中的实现方法。

内容方面，包括云隙光（Crepuscular Rays）、体积光散射（Volumetric Light Scattering）、后处理像素着色器（Post-Process Pixel Shader）、屏幕空间遮蔽方法（Screen-Space Occlusion Methods）几部分。

![](media/bfae6bef8d157f6c8006b210c8846875.jpg)

图 屏幕空间中的光线投射

![](media/f34011ce1defe75aa4392ddf5b8d938e.jpg)

图 基于本章实现的实时动画场景中的体积光散射

本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch13.html>


<br>

# 第三部分 渲染（Rendering）

<br>

# 第14章 用于真实感实时皮肤渲染的高级技术（Advanced Techniques for Realistic Real-Time Skin Rendering）


## 【关键词】

- 皮肤渲染（Skin Rendering）

- 次表面散射（Subsurface Scattering）

- 纹理空间漫反射（Texture-Space Diffusion）

- Bloom过滤器(Bloom Filter)

## 【内容盘点】

这章是《GPU Gems 3》中的核心章节，《GPU Gems 3》书的封面即是选取的本章的渲染效果图。自其问世以来，就成为了皮肤渲染领域经常会被参考到的文章，可谓皮肤渲染技术的集大成者，奠基之作。

内容方面，文章从皮肤外观开始，总结出实时皮肤渲染系统由两个分量组成：

-   镜面反射分量（specular reflection component）

-   次表面散射分量（subsurface scattering component）

文中详细描述了这两个分量的GPU实现，包括漫散射（diffuse scattering）理论的回顾和漫散射扩散剖面（diffuse scattering profiles）的新公式的呈现。

![](media/19dcd9f74e4594c0b7245f6195649da3.jpg)

图 多层皮肤模型

散射理论（Scattering Theory）方面，文章首先讲到了扩散剖面（diffusion profile）的概念，然后是高斯和的扩散剖面（A Sum-of-Gaussians Diffusion Profile），以及适于皮肤的高斯和（A Sum-of-Gaussians Fit for Skin）。

高级次表面散射（Advanced Subsurface Scattering）方面，文章讲到了纹理空间漫反射（texture-space diffusion）[Borshukov and Lewis 2003]

通过改进透射阴影贴图（ranslucent shadow maps）[Dachsbacher and Stamminger 2004]来计算穿过表面的深度，并将阴影区域连接到面向光的表面上的位置，完成穿过如耳朵类似表面区域的透射（Transmission）效果。

![](media/b211c883c2fa966569fe46bc42c0c05e.jpg)

图 一个实时的皮肤渲染结果【这幅图像十分接近Donnerand Jesen 2005的渲染结果，但其生成所需的时间要少许多】

另外，关于实时皮肤渲染技术总结，可以参考本系列文章中的上一篇文章：《<GPU Gems3>：真实感皮肤渲染技术总结》<https://zhuanlan.zhihu.com/p/42433792>

本章英文原书全文传送门：
<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch14.html>


<br>

# 第15章 可播放的全方位动作捕捉（Playable Universal Capture）


## 【关键词】

- 全方位捕捉（Universal Capture）

- 动作捕捉（Motion Capture）

- 主成分分析（Principal Component Analysis， PCA）

- 数据捕捉（Data Acquisition）


## 【内容盘点】

这章讨论了一个全方位捕捉（Universal Capture）的实时实现方法，用于真实感人物角色的动作以及渲染，该方法从电影《黑客帝国》中改进而来。此方法基于对变动漫反射纹理贴图的PCA压缩以及GPU解压缩。而纹理贴图通过当时最先进的脸部特征捕捉系统得到。而结果已经通过测试并应用到高质量的实时原型系统，以及游戏开发中。

![](media/952ea9ad7488e4e0777b4b6230740f54.jpg)

图15-11帧解压缩（Frame Decompression Algorithm）算法的图示

![](media/db976cba1f4940d42b73e64a9254fba5.jpg)

图 三个摄像机视图中的图像

![](media/7a95ab43db084101df8f23a223def6d3.jpg)

图 未最终渲染得到的“Leanne”角色

![](media/642a112d64ade89260eb0c6681f202d4.jpg)

图 经过最终渲染得到的“Leanne”角色

![](media/c6f92f8e2f4219476756a27c680f05f9.jpg)

图 E3 2006 Tigger Woods游戏demo中，伍兹标志性的笑容的出色捕捉复现

本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch15.html>

<br>

# 第16章 Crysis 中植被的程序化动画和着色（Vegetation Procedural Animation and Shading in Crysis）


## 【关键词】

- 植被过程化动画（Vegetation Procedural Animation）

- 植被着色（Vegetation Shading）

- 孤岛危机（Crysis）

- Cry Engine 2

## 【内容盘点】

这章阐述了如何以高效且具有真实感的方法处理着色和程序化植被动画。主要介绍了《孤岛危机（Crysis）》中植被的渲染以及程序化动画如何实现（基于Cry
ENGINE 2）。本章中给出的程序化动画技术使用普通的方式实现，因此将风力实现于非植被对象（如衣服和头发）也是有可能的；唯一不同之处在于这些情况下不需要使用主弯曲（main bending）。文中的方法实现了直升机、手雷爆炸、武器火力对植被、衣服和头发的影响，在这些实现中均使用了极为高效的方法。

内容方面，分为程序化动画（Procedural Animation）和植被着色（Vegetation Shading）两部分。

![](media/2ed083531c323762c004ac1b8aa26a2a.jpg)

图 顶点色的使用

![](media/fc4ee42cabc30ea1a779581f66748ad4.jpg)

图 次表面纹理贴图

![](media/fcb126633f6feb29bea24bbef0495303.jpg)

图 边缘平滑

![](media/8fc8f1bd77cb2d3a04e60d8b5b814e9f.jpg)

图 最终渲染结果【左：没有使用动态范围、阴影和后处理的结果；右：使用了所有技术的结果】

不得不说的是，2007年11月面世的《孤岛危机（Crysis）》，已经过了10周岁，其渲染效果放到今天，依然很能打：

![](media/8cbf4b109edd5f65f473955c03cc4438.jpg)

图 植被渲染效果图 @Crysis @2007

![http://img.hb.aicdn.com/8a9ef20217a5fd8835c9e236143fc16e758eea066f97a-mABe9Z](media/0f94e5c6635c7cfe2ffb9a9d328bf365.jpg)

图 植被渲染效果图 @Crysis @2007

![https://i.ytimg.com/vi/f_khryMjmog/maxresdefault.jpg](media/6e9f45b421c32f8a7ab37b317c7895ed.jpg)

图 植被渲染效果图 @Crysis @2007

本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch16.html>


<br>

# 第17章 鲁棒的多镜面反射和折射（Robust Multiple Specular Reflections and Refractions）

## 【关键词】

- 多镜面反射（Multiple Specular Reflections）

- 多折射（Multiple Refractions）

- 层次化距离图（Layered Distance Maps）

## 【内容盘点】

本章中，给出了一个鲁棒的算法来计算GPU中的单个和多个反射和折射。

为了使片段着色器能够在查找辅助光线的交点时访问整个场景的几何描述，文中首先将场景渲染为层次化距离图（layer distance map）。

![](media/3904ae8e5f3d943417d7063287764df8.jpg)

图 具有3 + 1层的分层距离图

![](media/ee7bfc97c1429c7a0c2f40b16e3c91f4.jpg)

图 以方位来追踪射线

每个层在纹理内存中被存储为一个立方体贴图（cube map）。算法基于搜索来辅助光线追踪。搜索过程从光线遍历开始，这样保证不会漏掉任何光线与屏幕的交点，继而进行割线搜索（secant serch）以保证精确性。

相比于直接实现经典的光线跟踪方法，使用光栅化的几何体表示中跟踪光线方法的一个重要优点，是这些方法可以被整合到当前的游戏引擎中，可以利用游戏开发中的可见性算法，并使用当时最新显卡的全部潜能。

![](media/85de07e552e5d714836605510fb19e52.jpg)

图 茶壶单次和多次反射的结果。【图(a)最多一次反射，50/100 FPS 图(b)
最多两次反射36/80 FPS，(c)最多三次反射 30/60 FPS】

本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch17.html>

<br>

# 第18章 用于浮雕映射的松散式锥形步进（Relaxed Cone Stepping for Relief Mapping）

## 【关键词】

- 浮雕映射（Relief Mapping）

- 松散式锥形步进（Relaxed Cone Stepping）

- 锥形步进映射(Cone step mapping ,CSM)

## 【内容盘点】

本章中，描述了一个用于逐片段的置换映射的新的光线场相交(ray-height-field intersection)策略，其结合了锥形步进映射和二分查找两者的优点。

文章将这种新的空间跳跃（space-leaping）算法命名为松散式锥形步进（Relaxed Cone Stepping, RCS）,这是由于其消除了在锥形步进映射(Cone step mapping ,CSM)中对锥形半径定义的限制。而光场相交的思想是使用一个一个改进的space-leaping技术替代线性查找，其后立刻接一个二分查找。

![](media/9171641e4bd2084409ce728401e93437.jpg)

图 锥形步进映射(Cone step mapping ,CSM)

![](media/bded4c0dac35b5bce59c4d5af71644e3.jpg)

图 不同深度和tiling因子对外观的影响的图示

本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch18.html>

<br>


# 第19章 《Tabula Rasa》中的延迟着色（Deferred Shading in Tabula Rasa）

## 【关键词】

- 延迟着色（Deferred Shading）

- 前向着色（Forward Shading）

- 体积光（Light Volumes）

- 可读深度（Readable Depth）

- 法线缓存（Normal Buffer）

- 双向光照（Bidirectional Lighting）

- 球体映射（Globe Mapping）

- 盒式光照（Box Lights）

- 阴影贴图（Shadow Maps）

- 高效光照体（Efficient Light Volumes）

- 模板掩码（Stencil Masking）

- 动态分支（Dynamic Branching）

## 【内容盘点】

![](media/749a9e34be8332329d81d439f65fee99.jpg)

图《Tabula Rasa》封面图

这章内容关于延迟着色，承接了《GPU Gem2》中的《S.T.A.L.K.E.R中的延迟着色》一文，是对其内容的延伸。相较于《S.T.A.L.K.E.R中的延迟着色》，这章着重于介绍基于延迟渲染的引擎中所需要的高层次问题、技术以及解决方法。

文中提到延迟着色的主要缺点包括：

-   高内存带宽的使用

-   没有硬件抗锯齿

-   缺乏合适的对透明度混合的支持。

而延迟着色的主要优点包括：

-   光照计算的消耗与场景复杂度无关

-   着色器能够对深度及其他像素信息进行访问

-   每个像素仅被每个光照亮一次。即，若像素后来被其他不透明几何体所遮挡，其上便不会有光照计算。

-   清晰分布的着色器代码：材质渲染从光照计算中分开

该章中讲到了一些可以在前向或者延迟着色引擎中实现的高级光照特性，包括双向光照（Bidirectional Lighting）、球体映射（Globe Mapping），盒式光照（Box Lights）、阴影贴图（Shadow Maps）等技术。

延迟渲染的优化方面，讲到了高效光照体积（Efficient Light Volumes）、模板掩码（Stencil Masking）以及动态分支（Dynamic Branching）等内容。

本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch19.html>


<br>

# 第20章 基于GPU的重要性采样（GPU-Based Importance Sampling）


## 【关键词】

- 渲染方程（Rendering Formulation）

- 基于GPU的重要性采样（GPU-Based Importance Sampling）

- 蒙特卡洛积分（Monte Carlo quadrature）

- 拟随机低差异序列（Quasirandom Low-Discrepancy Sequences）

- mipmap

## 【内容盘点】

高动态范围（High-Dynamic-Range ,HDR），结合环境贴图预过滤技术（Environment map prefiltering techniques）（Kautz et al. 2000），以及结合使用小波（wavelets）(Wang et al. 2006)或球面调和函数（spherical harmonics）（Ramamoorthi and Hanrahan 2002）的频空间解决方案，为实时渲染提供了可行的思路。然而，这种方式过于呆板，因为需要大量的预计算或繁多的代码用于光滑表面反射。

这章给出了上述方案的一种替代技术——基于GPU的重要性采样（GPU-Based Importance Sampling），该技术基于蒙特卡罗积分对光滑对象使用基于图像的光照，采用该技术仅需要很少的预计算，并在单个GPU着色器中运算。因此合适于几乎所有需要实时动态改变材质或光照的管线。

![](media/52718e1e086b3e4211d2c16c092d77ae.jpg)

图 每像素40个样本的重要性采样

![](media/423f8ea0cfc58187894b7c7e05319a54.jpg)

图 过滤重要性采样示意图

![](media/68a4cb059d731f61f985682bea1e6e39.jpg)

图 对斯坦福兔子使用逐像素40次采样的实时渲染效果。

![](media/c25fc13e5eb1353538bb1d3ce71f3f0f.jpg)

图 空间变化的BRDF（Spatially Varying BRDF）设计器

本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch20.html>


<br>

# 第四部分 图像效果（Image Effects）

<br>

# 第21章 真实Impostor（True Impostors）

## 【关键词】

- Billboard

- impostor

- 半透明impostor (Translucence impostor)


## 【内容盘点】

这章给出了 “真实impostor（ture imposters）”方法，这是一种向任意场景中加入大量简单模型而不需要渲染大量多边形的方法。这种方法使用了现代着色硬件来执行光线发射到已定义的纹理体积中，且表示非高度场表面数据的多深度层与四边形相关。

如同传统的imposter方法，ture imposter方法将四边形沿其中心渲染使其总是朝向摄像机。而与传统的显示静态纹理的imposter技术不同，真实imposter技术使用像素着色器发射一个观察光线穿过四边形的纹理坐标空间，与3D模型相交并计算相交点处的颜色。而纹理坐标空间通过一个以四边形中心为原点的框架定义。

![](media/1a3babb601de0a5191b2c6fd31067c5a.jpg)

图 生成公告板

![](media/0e4354357e59376128172ca07ef1682b.jpg)

图 真实imposter投影的多边形

![](media/bf10ba9ed5ec521376afcfa2a72bfd2a.jpg)

图 投射视图光线拍摄2D切片

![](media/507c29ff175a0bf087aa2b6c5760adf1.jpg)

图 基于射线步进（Ray March）和二分搜索确定体积交点

真imposter支持模型上的自阴影、反射以及折射，是一个查找体积间距离的有效方法。且文中基于相交测试的扩展，也对半透明效果进行了支持。

![](media/53db87caf0f3a5d9b698b1c9fc1ad2f1.jpg)

图 扩展相交测试以支持半透明

本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch21.html>


<br>

# 第22章 在GPU上烘焙法线贴图（Baking Normal Maps on the GPU）


## 【关键词】

- 法线贴图烘焙（Baking Normal Maps）

- 均匀网格（Uniform Grid）

## 【内容盘点】

这章分析了传统的基于光线投射的法线贴图投影技术如何在GPU上成功地实现，还阐述了一些其中普遍存在的问题，例如，内存限制和反走样。

而对文中实现的技术进行一些微小的改动，就可以生成位移贴图（displacement mapping），以及视差贴图（parallax mapping）和浮雕贴图（relief
mapping）。而使用更加复杂的着色器，还可以生成局部环境光遮蔽（local ambient occlusion）或腔贴图（cavity maps）。且这种技术的一个优点是可以足够快递显式地单独渲染所有mip等级。

![](media/2e65a0aba6dee153fc7a109705b80562.jpg)

图 映射到GPU的数据的可视化表示

![](media/190c857d39792ff9ab4c3a3e2c439d74.jpg)

图 最终在GPU上生成的法线贴图及其对应模型

本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch22.html>

<br>

# 第23章 高速的离屏粒子（High-Speed, Off-Screen Particles）


## 【关键词】

- 粒子系统（Particle System）

- 离屏粒子（Off-Screen Particle）

- 深度降采样（Downsampling Depth）

## 【内容盘点】

粒子效果在游戏中随处可见，大量粒子系统普遍用于烟、火、爆炸、沙尘、和雾。然而若这些粒子填满了屏幕，过度绘制（overdraw）可能几乎会达到无限，并且通常会导致帧速率问题。

文章提出的解决方案是，将昂贵的粒子渲染到离屏（off-screen）的渲染目标中，而这个渲染目标的大小是帧缓冲区大小的一小部分。这可以在过度绘制（overdraw）中产生巨大的开销节省，但是会牺牲一些图像处理的开销。

而结果显示，低分辨率的离屏渲染可以带来巨大的性能提升，它有助于使粒子系统耗费更加可控，因此帧速率并不会在过度绘制的最坏的情况下成为性能问题。

![](media/094eb5c6b39b861d8b395e0a875a6584.jpg)

图 基本离屏算法的步骤【(a)仅固体对象 (b)仅在低分辨率、离屏渲染对象中的粒子
(c)结合后的场景】

本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch23.html>

<br>

# 第24章 保持线性的重要性（The Importance of Being Linear）


## 【关键词】

- 颜色空间（Color Space）

- 线性空间（Linear Space）

- 伽马空间（Gamma Space）

- 伽马校正（Gamma Correction）

## 【内容盘点】

这章讲到，OpenGL、DirectX以及任何我们书写的着色器，会将所有的纹理输入、光照/材质交互，以及输出当做线性（即、光照强度和，漫反射乘积）来执行数学运算。但假如我们的纹理输入是非线性的，并且用户使用了未校准及未修正的显示器来应用非线性颜色空间变换。而这样会导致各种形式的失真和不精确等问题（如mipmap过滤错误）以及一些粗糙错误（如及不正确的光照渐变）。而适当的gamma修正可能是最简单，花费最小，也是最广泛使用的技术。而为了让读者规避这些问题，文中给出了一系列的解决方法与建议。

值得一提的是，目前流行的基于物理的渲染若要得到正确精准的渲染结果，正是需要在线性空间下进行。

![](media/174e23868c1f8f37d73e05979fa15f9b.jpg)

图 显示器的典型响应曲线

![](media/ad342e76ca4a97a4a6ea2107e097e3a7.jpg)

图 使用合适的gamma校正（左侧）及不进行gamma校正的渲染（右侧）图

本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch24.html>


<br>

# 第25章 在GPU 上渲染矢量图（Rendering Vector Art on the GPU）


## 【关键词】

- 矢量（Vector）

- 二次条样（Quadratic Splines）

- 三次贝塞尔曲线（cubic Bezier curves）

## 【内容盘点】

矢量（Vector）表示为指定形状的一种分辨率无关的方法，其具有任意大小，可以对内容进行显示而不需要细化（tessellation）以及没有采样失真的优点。

这章给出了一个算法，用于渲染由封闭路径所定义的向量图形，而封闭路径可以包含二次样条（Quadratic
Splines）或三次贝塞尔曲线（cubic Bézier curves）。

![](media/e4e177c4bce95819ed6ea5a09f5042ea.jpg)

图 所有参数立方平面曲线可归类为此三种曲线类型之一的某些段的参数化

![](media/b82e124e533cdaaad40f56525a1ea69d.jpg)

图 渲染二次样条曲线

![](media/8ebd1db2b475b8959e50e093dba13229.jpg)

图
渲染三次样条【(a)有向的多轮廓三次样条输入、(b)每个贝塞尔凹包被局部地三角化；内侧区域被全局地三角化；(c)内部三角形被填充，曲线段使用一个特殊的像素着色器程序渲染】

本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch25.html>

<br>

# 第26章 通过颜色进行对象探测：使用 GPU 进行实时视频图像处理（Object Detection by Color: Using the GPU for Real-Time Video Image Processing）

## 【关键词】

- 对象探测（Object Detection）

- 图像处理（Image Processing）

## 【内容盘点】

严格意义上并非游戏开发相关，略。

本章英文全文链接：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch26.html>


<br>

# 第27章 后处理效果：运动模糊（Motion Blur as a Post-Processing Effect）

## 【关键词】

- 运动模糊（Motion Blur）

- 后处理（Post-Processing Effect）

## 【内容盘点】

在视频游戏中，模拟速度最好的方法之一便是使用运动模糊（Motion
Blur）。这章中阐述了一种使用在深度缓存中的深度值来计算对象世界空间位置的以实现运动模糊的方法，该方法可以作为一个基础方法使用，并且可以很轻易地整合到游戏引擎中，同时提供了比传统的多路径方法更高的性能。

![](media/35c4b292fc27f3ee2999403d299c2ba1.jpg)

图 不具有运动模糊的场景

![](media/9755ef5fca5d3326f99b2ceab69de195.jpg)

图 使用了运动模糊的场景

![](media/7a26d2087a6b13dda162db52b573fc74.jpg)

图 有无运动模糊的对比

![](media/e7bd600ccfd7f938aed80310518d1d0c.png)

图 《神秘海域4》中的运动模糊

本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch27.html>

<br>

# 第28章 实用景深后期处理（Practical Post-Process Depth of Field）

## 【关键词】

- 景深（Depth of Field,DoF）

- 后处理（Post-Processing Effect）

## 【内容盘点】

景深（Depth of field，DOF），也叫焦点范围（focus range）或有效焦距范围（effective focus），是指场景中最近和最远的物体之间出现的可接受的清晰图像的距离。

这章中阐述了一个景深（Depth of Field,DoF）算法，该算法主要适合于FPS游戏，最初使用于《使命召唤：现代战争》中。完整的算法包含以下4个阶段：

1、对前进对象的散光圈进行降采样。

2、模糊临近的散光圈图像。

3、通过模糊后和未模糊的图像计算实际前景散光圈。

4、在一个最后的全屏处理路径中使用可变宽度模糊，并在其中应用前景和背景散光圈图像。

几张带景深的渲染效果，取最近几年的一些引擎和游戏截图。

![](media/e21dd2a0abbb592d418025fc870da011.jpg)

图 CryEngine3 中有无景深的渲染对比（有景深）

![](media/90f2aa48340bc6738eceb2dee50ac68f.jpg)

图 CryEngine3 中有无景深的渲染对比（无景深）

![](media/b9193c25c7f03efd528d38e0017255bd.jpg)

图 《地平线：黎明》中的景深


本章英文原书全文传送门：

<https://developer.nvidia.com/gpugems/GPUGems3/gpugems3_ch28.html>

<br>

# 【GPU精粹三部曲】 Part I • 尾声


这篇文章至此，GPU精粹三部曲中《GPU Gems》、《GPU Gems 2》、《GPU Gems3》组成的第一部曲，也就告一段落了。

![](media/d51868713d19a9460a1f8171d3fa929f.jpg)

通过【GPU精粹与Shader编程】系列的这前7篇文章，我们已经将这三本书中的重点内容，全都过了一遍。希望各位读者能因此有所收获。

下篇文章，将开启全新的《GPU Pro》系列。

再会。

```

`Content/《GPU Pro 1》全书提炼总结/README.md`:

```md
![](media/0e0a560374de76f36e936236ba36e879.jpg)

# 《GPU Pro 1》全书核心内容提炼总结

本文的知乎专栏版本：
https://zhuanlan.zhihu.com/p/47959028


本文是【GPU精粹与Shader编程】系列的第八篇文章，全文共两万余字。文章盘点、提炼和总结了《GPU Pro 1》全书总计22章的核心内容。

题图来自《荒野大镖客2》。


<br>

# 全文快捷导航目录

本文将对《GPU Pro 1》全书中游戏开发与渲染相关，相对更具含金量的5个部分，共22章的内容进行提炼与总结，详细列举如下：

<!-- TOC -->

- [《GPU Pro 1》全书核心内容提炼总结](#gpu-pro-1全书核心内容提炼总结)
- [全文快捷导航目录](#全文快捷导航目录)
- [《GPU Pro 1》其书](#gpu-pro-1其书)
- [《GPU Pro 1》书本配套源代码](#gpu-pro-1书本配套源代码)
- [Part I. 游戏渲染技术剖析 Game Postmortems](#part-i-游戏渲染技术剖析-game-postmortems)
    - [一、《孢子（Spore）》中的风格化渲染 | Stylized Rendering in Spore](#一孢子spore中的风格化渲染--stylized-rendering-in-spore)
        - [1.1 后处理过滤链系统的实现要点](#11-后处理过滤链系统的实现要点)
            - [1.1.1 动态参数（Dynamic parameters）](#111-动态参数dynamic-parameters)
            - [1.1.2 自定义过滤器（Custom filters）](#112-自定义过滤器custom-filters)
        - [1.2 五种屏幕后处理Shader的实现思路](#12-五种屏幕后处理shader的实现思路)
            - [1.2.1 油画后处理效果 Oil Paint Filter](#121-油画后处理效果-oil-paint-filter)
            - [1.2.2 水彩画后处理效果 Watercolor Filter](#122-水彩画后处理效果-watercolor-filter)
            - [1.2.3 8位后处理效果 8-Bit Filter](#123-8位后处理效果-8-bit-filter)
            - [1.2.4 黑色电影后处理效果 Film Noir Filter](#124-黑色电影后处理效果-film-noir-filter)
            - [1.2.5 旧电影后处理效果 Old Film Filter](#125-旧电影后处理效果-old-film-filter)
    - [二、《狂野西部：生死同盟》中的渲染技术 | Rendering Techniques in Call of Juarez: Bound in Blood](#二狂野西部生死同盟中的渲染技术--rendering-techniques-in-call-of-juarez-bound-in-blood)
    - [三、《正当防卫2》中的大世界制作经验与教训 | Making it Large, Beautiful, Fast,and Consistent: Lessons Learned](#三正当防卫2中的大世界制作经验与教训--making-it-large-beautiful-fastand-consistent-lessons-learned)
        - [3.1 光照索引 Light indexing](#31-光照索引-light-indexing)
        - [3.2 阴影系统 Shadowing System](#32-阴影系统-shadowing-system)
        - [3.3 环境光遮蔽 Ambient Occlusion](#33-环境光遮蔽-ambient-occlusion)
        - [3.4 其他内容](#34-其他内容)
    - [四、《矿工战争》中的可破坏体积地形 | Destructible Volumetric Terrain](#四矿工战争中的可破坏体积地形--destructible-volumetric-terrain)
- [Part II. 渲染技术 Rendering Techniques](#part-ii-渲染技术-rendering-techniques)
    - [五、基于高度混合的四叉树位移贴图 | Quadtree Displacement Mapping with Height Blending](#五基于高度混合的四叉树位移贴图--quadtree-displacement-mapping-with-height-blending)
        - [5.1 核心实现Shader代码](#51-核心实现shader代码)
    - [六、使用几何着色器的NPR效果 | NPR Effects Using the Geometry Shader](#六使用几何着色器的npr效果--npr-effects-using-the-geometry-shader)
        - [6.1 轮廓渲染（Silhouette Rendering）](#61-轮廓渲染silhouette-rendering)
        - [6.2 铅笔素描渲染（Pencil Rendering）](#62-铅笔素描渲染pencil-rendering)
    - [七、后处理Alpha混合 | Alpha Blending as a Post-Process](#七后处理alpha混合--alpha-blending-as-a-post-process)
        - [7.1 核心实现Shader代码](#71-核心实现shader代码)
    - [八、虚拟纹理映射简介 | Virtual Texture Mapping 101](#八虚拟纹理映射简介--virtual-texture-mapping-101)
    - [8.1 核心实现Shader代码](#81-核心实现shader代码)
        - [8.1.1 MIP 贴图计算的Shader实现 | MIP Map Calculation](#811-mip-贴图计算的shader实现--mip-map-calculation)
            - [8.1.2 图块ID 的Shader实现 | Tile ID Shader](#812-图块id-的shader实现--tile-id-shader)
            - [8.1.3 虚拟纹理查找的Shader实现 | Virtual Texture Lookup](#813-虚拟纹理查找的shader实现--virtual-texture-lookup)
- [Part III、全局光照 Global Illumination](#part-iii全局光照-global-illumination)
    - [九、基于间接光照的快速，基于模板的多分辨率泼溅 Fast, Stencil-Based Multiresolution Splatting for Indirect Illumination](#九基于间接光照的快速基于模板的多分辨率泼溅-fast-stencil-based-multiresolution-splatting-for-indirect-illumination)
        - [9.1 实现思路小结](#91-实现思路小结)
            - [9.1.1 多分辨率泼溅的实现思路 | Multiresolution Splatting Implement](#911-多分辨率泼溅的实现思路--multiresolution-splatting-implement)
            - [9.1.2 设置可接受模糊 | Setting acceptable blur](#912-设置可接受模糊--setting-acceptable-blur)
            - [9.1.3 从虚拟点光源收集光照进行泼溅 | Gathering illumination from VPLs for splatting](#913-从虚拟点光源收集光照进行泼溅--gathering-illumination-from-vpls-for-splatting)
            - [9.1.4 降采样多分辨率照明缓存 | Unsampling the multiresolution illumination buffer.](#914-降采样多分辨率照明缓存--unsampling-the-multiresolution-illumination-buffer)
            - [9.1.5 并行泼溅求精 | Parallel splat refinement](#915-并行泼溅求精--parallel-splat-refinement)
            - [9.1.6 最终基于模板的多分辨率泼溅算法](#916-最终基于模板的多分辨率泼溅算法)
    - [十、屏幕空间定向环境光遮蔽 Screen-Space Directional Occlusion （SSDO）](#十屏幕空间定向环境光遮蔽-screen-space-directional-occlusion-ssdo)
        - [10.1 核心实现Shader代码](#101-核心实现shader代码)
            - [10.1.1 屏幕空间定向环境光遮蔽SSDO 的Shader源码](#1011-屏幕空间定向环境光遮蔽ssdo-的shader源码)
            - [10.1.2 SSDO间接光计算Shader实现代码](#1012-ssdo间接光计算shader实现代码)
    - [十一、基于几何替代物技术的实时多级光线追踪 | Real-Time Multi-Bounce Ray-Tracing with Geometry Impostors](#十一基于几何替代物技术的实时多级光线追踪--real-time-multi-bounce-ray-tracing-with-geometry-impostors)
- [Part IV. 图像空间 Image Space](#part-iv-图像空间-image-space)
    - [十二、 GPU上的各项异性的Kuwahara滤波 | Anisotropic Kuwahara Filtering on the GPU](#十二-gpu上的各项异性的kuwahara滤波--anisotropic-kuwahara-filtering-on-the-gpu)
        - [12.1 Kuwahara滤波器（Kuwahara Filtering）](#121-kuwahara滤波器kuwahara-filtering)
        - [12.2 广义Kuwahara滤波器（Generalized Kuwahara Filtering）](#122-广义kuwahara滤波器generalized-kuwahara-filtering)
        - [12.3 各向异性Kuwahara滤波器（Anisotropic Kuwahara Filtering）](#123-各向异性kuwahara滤波器anisotropic-kuwahara-filtering)
    - [十三、基于后处理的边缘抗锯齿 | Edge Anti-aliasing by Post-Processing](#十三基于后处理的边缘抗锯齿--edge-anti-aliasing-by-post-processing)
    - [十四、基于Floyd-Steinberg半色调的环境映射 | Environment Mapping with Floyd-Steinberg Halftoning](#十四基于floyd-steinberg半色调的环境映射--environment-mapping-with-floyd-steinberg-halftoning)
        - [14.1 核心实现Shader代码](#141-核心实现shader代码)
    - [十五、用于粒状遮挡剔除的分层项缓冲 | Hierarchical Item Buffers for Granular Occlusion Culling](#十五用于粒状遮挡剔除的分层项缓冲--hierarchical-item-buffers-for-granular-occlusion-culling)
    - [十六、后期制作中的真实景深 | Realistic Depth of Field in Postproduction](#十六后期制作中的真实景深--realistic-depth-of-field-in-postproduction)
    - [十七、实时屏幕空间的云层光照 | Real-Time Screen Space Cloud Lighting](#十七实时屏幕空间的云层光照--real-time-screen-space-cloud-lighting)
        - [17.1 实现方案](#171-实现方案)
        - [17.2 核心实现Shader代码](#172-核心实现shader代码)
    - [十八、屏幕空间次表面散射 | Screen-Space Subsurface Scattering](#十八屏幕空间次表面散射--screen-space-subsurface-scattering)
        - [18.1 核心实现Shader代码](#181-核心实现shader代码)
- [Part V. 阴影 Shadows](#part-v-阴影-shadows)
    - [十九、快速传统阴影滤波 | Fast Conventional Shadow Filtering](#十九快速传统阴影滤波--fast-conventional-shadow-filtering)
    - [二十、混合最小/最大基于平面的阴影贴图 | Hybrid Min/Max Plane-Based Shadow Maps](#二十混合最小最大基于平面的阴影贴图--hybrid-minmax-plane-based-shadow-maps)
    - [二十一、基于四面体映射实现全向光阴影映射 | Shadow Mapping for Omnidirectional Light Using Tetrahedron Mapping](#二十一基于四面体映射实现全向光阴影映射--shadow-mapping-for-omnidirectional-light-using-tetrahedron-mapping)
    - [二十二、屏幕空间软阴影 | Screen Space Soft Shadows](#二十二屏幕空间软阴影--screen-space-soft-shadows)

<!-- /TOC -->

<br>

# 《GPU Pro 1》其书


《GPU Pro 1》全称为《GPU Pro : Advanced Rendering Techniques》，其作为GPU Pro系列的开山之作，出版于2010年，汇聚了当代业界前沿的图形学技术。全书共10个部分，41章。

一个有趣的细节是，《GPU Pro 1》是GPU Pro系列7本书中，页数最多的一本，共712页。

![](media/12558f640a9de6746b368b644c93093b.jpg)

图 《GPU Pro 1》封面

<br>

# 《GPU Pro 1》书本配套源代码


类似之前的GPU Gems系列的源码收藏GitHub repo（<https://github.com/QianMo/GPU-Gems-Book-Source-Code>），我也维护了的一个名为“GPU-Pro-Books-Source-Code”的GitHub仓库，以备份GPU Pro系列珍贵的资源，也方便直接在GitHub Web端查看业界大牛们写的代码，链接如下：

<https://github.com/QianMo/GPU-Pro-Books-Source-Code>

<br>

# Part I. 游戏渲染技术剖析 Game Postmortems

<br>

## 一、《孢子（Spore）》中的风格化渲染 | Stylized Rendering in Spore

《孢子（Spore）》是一款非常有创意的游戏。在游戏《孢子（Spore）》中，使用了可编程过滤链系统（scriptable filter chain system）在运行时对帧进行处理，以实现游戏整体独特的风格化渲染。（注，在本文中，filter按语境，译为滤波或者过滤）。

![](media/620848421a07229f820409740714677c.jpg)

图 《孢子》封面图

![](media/3a9aa2f3ef677c1efe33fe4ca8307e33.jpg)

图 《孢子》中的风格化渲染

过滤器链（filter chain）可以看作一系列按顺序应用的参数化的图像处理（image processing）着色器，即后处理链。《孢子》中的每一帧都使用此系统进行处理和合成。
除了《孢子》标准的艺术导向的视觉风格外，开发人员还创建了一组特有的滤波器，为游戏产生截然不同的视觉风格。而在这章中，作者讲到了一些在开发《孢子》时生成的视觉样式，并分享了关于《孢子》过滤器链系统的设计和实现的细节。

诸如模糊（blur），边缘检测（edge detection）等图像处理技术的GPU实现在图像处理领域较为常见。《孢子》的开发目标是构建一个具有此类过滤器的调色系统，美术师可以利用这些过滤器来创作不同的视觉样式。
下图显示了该系统在渲染管线中如何进行放置。

![](media/38e267d74e73bc8bc3639a7b9fe48458.jpg)

图 过滤器链系统总览

![](media/35cfe05da7330c1802b4cf2bdfb1935e.jpg)

图 《孢子》中以油画方式进行渲染的飞机

下图显示了《孢子》中细胞阶段的过滤器链如何使用由渲染管线的其他阶段生成的多个输入纹理，并形成最终的合成帧。

![](media/550c7bbdfa3b0092d0d739aa418c6392.jpg)

图 《孢子》中细胞阶段游戏流体环境的复杂过滤器链

<br>

### 1.1 后处理过滤链系统的实现要点


过滤链系统实现的方面，分为两个要点：

-   动态参数（Dynamic parameters）

-   自定义过滤器（Custom filters）

#### 1.1.1 动态参数（Dynamic parameters）

《孢子》中的动态环境需要调用按帧变化参数。所以，游戏中添加了可以通过任何过滤器访问的每帧更新的全局参数。例如，使用相机高度和当日时间作为行星大气过滤器的变化参数，如下图。

而在其他情况下，游戏需要在给定过滤器的两组不同参数值之间平滑插值。例如，每当天气系统开始下雨时，全局着色过滤器的颜色就会转换为阴天的灰色。在系统中也添加了支持游戏控制插值的参数，也添加了可以平滑改变滤波器强度的衰减器（fader）。

![](media/fe557549ec3c7e0251042e8c6de65d56.jpg)

图 按当日时间驱动的颜色过滤器。这种经过彩色压缩的输出会进行模糊并以bloom的方式添加到场景中

#### 1.1.2 自定义过滤器（Custom filters）

过滤链系统的一个重要补充是自定义过滤器，可以将其着色器指定为参数。这意味着程序员可以通过向现有构建添加新着色器来轻松添加新的图像技术。此外，程序员可以通过将多个过滤器折叠到一个实现相同视觉效果的自定义过滤器中来优化艺术家生成的过滤器链。

### 1.2 五种屏幕后处理Shader的实现思路

接着，介绍五种《孢子》中比较有意思的后处理效果。

#### 1.2.1 油画后处理效果 Oil Paint Filter

对于油画过滤器（Oil Paint
Filter），首先渲染画笔描边的法线贴图，用于对传入的场景进行扭曲。
然后使用相同的法线贴图结合三个光源照亮图像空间中的笔触（Brush stroke）。
而笔触可以通过带状的粒子特效驱动，使过滤效果变得动态，并且在时间上更加连贯。

![](media/c8625692aaef6f4020e93d430f6e2c1b.jpg)

图 《孢子》中的油画后处理效果

用于油画效果的像素着色器核心代码如下：

    # Oil Paint Effect
    # kDistortionScale 0.01, kBrighten 2.0
    # kNormalScales (1.5, 2.5, 1.6)
    # Get the normal map and bring normals into [-1,1] range
    half4 pNormalMap = tex2D ( normalMap , fragIn .uv0 );
    half3 nMapNormal = 2 * pNormalMap .rgb - half3( 1, 1, 1 );


    # Distort the UVs using normals ( Dependent Texture Read!)
    half4 pIn = tex2D (sceneTex ,
    saturate (uv - nMapNormal .xy * kDistortionScale) );


    # Generate the image space lit scene
    half3 fakeTangN = nMapNormal .rbg * kNormalScales;
    fakeTangN = normalize (fakeTangN );

    # Do this for 3 lights and sum , choose different directions
    # and colors for the lights
    half NDotL = saturate (dot (kLightDir , fakeTangN ));
    half3 normalMappingComponent = NDotL * kLightColor ;

    # Combine distorted scene with lit scene
    OUT .color .rgb = pIn .rgb * normalMappingComponent * kBrighten ;



#### 1.2.2 水彩画后处理效果 Watercolor Filter

对于水彩画过滤器（watercolor filter）。首先，使用传入场景的简易Sobel边缘检测版本与原始场景相乘。
然后使用平滑滤波器（smoothing filter）的四个pass对结果进行平滑，且该平滑滤波器从四周的taps中找到每个pass的最亮值。
接着，基于边缘检测的轮廓添加一些在平滑过程中丢失的精确度。
具体核心代码如下，而offset和scales是可调的参数，允许我们改变绘制涂抹笔触的大小。

![](media/49cf56255f1f35c49c3bb4e0b719b8fa.jpg)

图 《孢子》中的水彩后处理效果

《孢子》中的水彩后处理效果像素着色器代码如下：

    # Water Color Smoothing
    # kScaleX = 0.5, kScaleY = 0.5
    # offsetX1 = 1.5 * kScaleX offsetY1 = 1.5 * kScaleX
    # offsetX2 = 0.5 * kScaleX offsetY2 = 0.5 * kScaleY

    # Get the taps
    tap0 = tex2D (sceneTex , uv + float2 (-offsetX1 ,-offsetY1 ));
    tap1 = tex2D (sceneTex , uv + float2 (-offsetX2 ,-offsetY2 ));
    tap2 = tex2D (sceneTex , uv + float2 (offsetX2 , offsetY2 ));
    tap3 = tex2D (sceneTex , uv + float2 (offsetX1 , offsetY1 ));

    # Find highest value for each channel from all four taps
    ret0 = step(tap1 , tap0 );
    ret1 = step(tap3 , tap2 );
    tapwin1 = tap0* ret0 + tap1 * (1.0 - ret0);
    tapwin2 = tap2* ret1 + tap3 * (1.0 - ret1);
    ret = step(tapwin2 , tapwin1 );
    OUT .color .rgb = tapwin1 * ret + (1.0 -ret) * tapwin2 ;


#### 1.2.3 8位后处理效果 8-Bit Filter

![](media/4cd49abf4519cebc88ce3c40e7aa1b40.jpg)

图 8-Bit Filter

要创建一个8位滤波器（8-Bit Filter），可以使用像素着色器中的round函数，并通过点采样绘制到游戏分辨率大小1/4的低分辨率缓冲区中。
这是一个非常简单的效果，使游戏看起来像一个旧式8位游戏。

《孢子》中8-bit后处理效果的像素着色器代码如下：

    # 8 Bit Filter
    # kNumBits : values between 8 and 20 look good
    half4 source = tex2D (sourceTex , fragIn .uv0 );
    OUT .color .rgb = round (source .rgb * kNumBits) / kNumBits ;

#### 1.2.4 黑色电影后处理效果 Film Noir Filter

在创建黑色电影后处理效果时，首先将传入的场景转换为黑白。 然后进行缩放和偏移。添加一些噪声，雨水颗粒效果是很好的画龙点睛。

![](media/e3b9349a1ba9e4b4bf7abfcbc9df0e60.png)

图 《孢子》中黑色电影后处理效果

《孢子》中黑色电影后处理像素着色器代码如下，其中，kNoiseTile可用于调整粒度，而kBias和kScale用作线性对比度拉伸的参数：

    # Film Noir filter
    # kNoiseTile is 4.0
    # kBias is 0.15, kScale is 1.5
    # kNoiseScale is 0.12
    pIn = tex2D (sourceTex , uv);
    pNoise = tex2D (noiseTex , uv * kNoiseTile) ;

    # Standard desaturation
    converter = half3 (0.23 , 0.66, 0.11);
    bwColor = dot (pIn .rgb , converter );

    # Scale and bias
    stretched = saturate (bwColor - kBias) * kScale ;

    # Add
    OUT .color .rgb = stretched + pNoise * kNoiseScale ;

#### 1.2.5 旧电影后处理效果 Old Film Filter

对于旧电影后处理效果，可以采用简单的棕褐色着色与锐化滤波器（sharpen filter）相结合。 且可以使用粒子效果进行划痕和渐晕的处理。

![](media/92e02f49298b69da103f846bc388116f.jpg)

图 旧电影后处理效果

《孢子》中旧电影后处理效果像素着色器代码如下：

    # Old Film Filter
    # offsetX and offsetY are 2 pixels . With such wide taps , we
    # get that weird sharpness that old photos have.
    # kNoiseTile is 5.0, kNoiseScale is 0.18
    # kSepiaRGB is (0.8, 0.5, 0.3)
    # Get the scene and noise textures
    float4 sourceColor = tex2D (sourceTex , uv);
    float4 noiseColor = tex2D (noiseTex , uv * kNoiseTile );

    # sharpen filter
    tap0 = tex2D (sceneTex , uv + float2 (0, -offsetY ));
    tap1 = tex2D (sceneTex , uv + float2 (0, offsetY ));
    tap2 = tex2D (sceneTex , uv + float2 (-offsetX , 0));
    tap3 = tex2D (sceneTex , uv + float2 (offsetX , 0));
    sourceColor = 5 * sourceColor - (tap0 + tap1 + tap2 + tap3 );

    # Sepia colorize
    float4 converter = float4 (0.23 , 0.66, 0.11, 0);
    float bwColor = dot (sourceColor , converter );
    float3 sepia = kSepiaRGB * bwColor ;

    # Add noise
    OUT .color = sepia * kTintScale + noiseColor * kNoiseScale ;


关于《孢子》更多的风格化渲染的教程，可以在这里找到：

<http://www.spore.com/comm/tutorials>


<br>

## 二、《狂野西部：生死同盟》中的渲染技术 | Rendering Techniques in Call of Juarez: Bound in Blood

《狂野西部：生死同盟》（Call of Juarez: Bound in Blood）是由Techland公司开发，育碧发行，并于2009年夏季在PS3，Xbox360和PC上发布的游戏。

![](media/8c1f5c8e294d71153c1d505cc6e3e4c6.jpg)

图《狂野西部：生死同盟》封面

![](media/5dbe0eb8c0cb6c2f658f874a56f05889.jpg)

图《GPU Pro 1》的封面，即是采用的《狂野西部：生死同盟》的图片

![](media/728c736d64bbd6d8d1a5b4245ada9324.jpg)

图 《狂野西部：生死同盟》游戏截图

《狂野西部：生死同盟》基于ChromeEngine 4，游戏中大量用到了延迟着色（deferred shading）技术。

众所周知，延迟着色 [Hargreaves 04]是一种在屏幕空间使用存储了诸如漫反射颜色，法向量或深度值等像素信息的中间缓冲区（G-buffer）的技术。

G-buffer是一组屏幕大小的渲染目标（MRT），可以使用现代图形硬件在单个pass中生成，可以显着降低渲染负载。然后使用G-buffer作为着色算法的输入（例如光照方程），而无需浏览原始几何体（此阶段计算所需的所有信息，如三维世界空间中的像素的位置，可以从G-buffer中提取）。以这种方式，算法仅对可见像素进行操作，这极大地降低了照明计算的复杂性。

![](media/045f3d4f1d5db9bc2d624b24cd5dbf78.png)

表 《狂野西部：生死同盟》中的MRT配置

延迟着色方法的主要优点是对渲染管线的简化，节省复杂着色器资源和计算的开销，以及能对复杂光照（如动态光源）进行简约而健壮的管理。

延迟着色技术在与后处理渲染效果的结合方面可以获得不错的化学反应。在《狂野西部：生死同盟》中，延迟渲染与诸如屏幕空间环境光遮蔽（SSAO），运动模糊（motion-blur），色调映射（tone mapping）以及用于改善最终图像质量的边缘抗锯齿（edge anti-aliasing）等后处理效果都可以很好的结合使用。

![](media/5805c19c529c4437067ceeb9420b79ee.jpg)

图 拥有动态光源和环境光遮蔽的室内场景

这章中还展示了不少《狂野西部：生死同盟》中自然现象效果的渲染方法，如雨滴，体积地面雾，light shafts，真实感天空和云彩，水面渲染，降雨效果，以及体积光的渲染技巧。以及色调映射相关的技术。

![](media/6bb9df54b962f3cd39d0672319db0ffc.jpg)

图 场景色调映射，在阴影区域和光照区域之间转换

<br>

## 三、《正当防卫2》中的大世界制作经验与教训 | Making it Large, Beautiful, Fast,and Consistent: Lessons Learned

《正当防卫2（Just Cause 2）》是Avalanche Studios为PC，Xbox 360和PLAYSTATION
3开发的沙盒游戏。游戏的主要风格是大世界，主要视觉特征是具有巨大渲染范围的巨型景观，森林、城市、沙漠、丛林各种环境不同的气候，以及昼夜循环技术。

![](media/11c915b42785aed12338cf882463210f.jpg)

图 《正当防卫2》封面


对于多动态光源的渲染，《正当防卫2》没有使用延迟渲染，而是提出了一种称作光源索引（Light indexing）的方案，该方案可以使用前向渲染渲染大量动态光源，而无需多个pass，或增加draw calls。

### 3.1 光照索引 Light indexing

光照索引（Light indexing）技术的核心思路是：通过RGBA8格式128 x 128的索引纹理将光照信息提供给着色器。

将该纹理映射到摄像机位置周围的XZ平面中，并进行点采样。 每个纹素都映射在一个4m x 4m的区域，并持有四个该正方形相关的光源索引。这意味着我们覆盖了512m × 512m的区域，且动态光源处于活动状态。

活动光源存储在单独的列表中，可以是着色器常量，也可以是一维纹理，具体取决于平台。虽然使用8位通道可以索引多达256个光源，但我们将其限制为64个，以便将光源信息拟合到着色器常量中。每个光源都有两个恒定的寄存器，保存位置（position），倒数平方半径（reciprocal squared radius）和颜色（color）这三个参数。

![](media/cb588c524267abdeafc0de518613af95.png)

表 光源常量

此外，还有一个额外的“禁用（disabled）”光源槽位，其所有这些都设置为零。那么总寄存器计数会达到130。当使用一维纹理时，禁用的光源用边框颜色（border color）编码替代。 位置和倒数平方半径以RGBA16F格式存储，颜色以RGBA8格式存储。为了保持精度，位置存储在相对于纹理中心的局部空间中。

光源索引纹理在CPU上由全局光源列表生成。一开始，其位置被放置在使得纹理区域被充分利用的位置，最终以尽可能小的空间，放置在摄像机之后。

在启用并落入索引纹理区域内的光源中，根据优先级，屏幕上的近似大小以及其他因素来选择最相关的光源。每个光源都插入其所覆盖的纹素的可用通道中。如果纹理像素被四个以上的光源覆盖，则需要丢弃此光源。

如果在插入时纹理像素已满，程序将根据图块中的最大衰减系数检查入射光源是否应替换任何现有的光源，以减少掉光源的视觉误差。这些误差可能导致图块边框周围的光照不连续性。通常这些误差很小，但当四处移动时可能非常明显。而为了避免这个问题，可以将索引纹理对齐到纹素大小的坐标中。在实践中，光源的丢弃非常少见，通常很难发现。

![](media/bdb0097479d27279d7402dade7dfe206.jpg)

图 轴对齐世界空间中的光照索引。 放置纹理使得尽可能多的区域在视锥体内。 图示的4m x 4m区域由两个由R和G通道索引的光源相交。 未使用的插槽表示禁用的光源。

<br>

### 3.2 阴影系统 Shadowing System

阴影方面，《正当防卫2》中采用级联阴影映射（cascaded shadow mapping）。并对高性能PC提供软阴影（Soft shadows）选项。虽然在任何情况下都不是物理上的准确，但算法确实会产生真正的软阴影，而不仅仅是在许多游戏中使用的恒定半径模糊阴影。

![](media/5b80d8287950dd63abd4d51c0e28b170.jpg)

图 《正当防卫2》中的软阴影。注意树底部的锐利阴影逐渐变得柔和，以及注意，树叶投下了非常柔和的阴影。

此软阴影算法的步骤如下：

1、在阴影贴图中搜索遮挡物的邻域。

2、投射阴影的样本计为遮挡物。

3、将遮挡物中的中心样本的平均深度差用作第二个pass中的采样半径，并且在该半径内取多个标准PCF样本并取平均值。

4、为了隐藏有限数量的样本失真，采样图案以从屏幕位置产生的伪随机角度进行旋转。

实现Shader代码如下：

    // Setup rotation matrix
    float3 rot0 = float3(rot.xy, shadow_coord.x);
    float3 rot1 = float3(float2(-1, 1) * rot.yx, shadow_coord.y);
    float z = shadow_coord.z * BlurFactor;

    // Find average occluder distances .
    // Only shadowing samples are taken into account .
    [unroll] for (int i = 0; i<SHADOW_SAMPLES; i++)
    {
        coord.x = dot(rot0 , offsets[i]);
        coord.y = dot(rot1 , offsets[i]);
        float depth = ShadowMap.Sample(ShadowDepthFilter, coord).r;
        de.x = saturate(z - depth* BlurFactor);
        de.y = (de.x > 0.0);
        dd += de;
    }

    // Compute blur radius
    float radius = dd.x / dd.y + BlurBias;
    rot0.xy *= radius ;
    rot1.xy *= radius ;

    // Sample shadow with radius
    [unroll] for (int k = 0; k<SHADOW_SAMPLES; k++)
    {
        coord.x = dot(rot0 , offsets[k]);
        coord.y = dot(rot1 , offsets[k]);
        shadow += ShadowMap.SampleCmpLevelZero(
        ShadowComparisonFilter, coord, shadow_coord.z).r;
    }


### 3.3 环境光遮蔽 Ambient Occlusion

对于环境遮挡（AO），使用了三种不同的技术：

-   美术师生成的AO（artist-generated AO）
-   遮挡体（Occlusion Volumes）
-   SSAO [Kajalin 09]


其中，美术师生成的环境光遮蔽用于静态模型，由材质属性纹理中的AO通道组成。此外，美术师有时会在关键点放置环境遮挡几何。对于动态对象，使用遮挡体（OcclusionVolumes）在底层几何体上投射遮挡阴影，主要是角色和车辆下的地面。而SSAO是PC版本的可选设置，里面使用了一种从深度缓冲导出切线空间的方案。

其中，SSAO从深度缓冲区导出切线空间的实现Shader代码如下：

    // Center sample
    float center = Depth . Sample ( Filter , In. TexCoord . xy ). r;

    // Horizontal and vertical neighbors
    float  x0  =  Depth.Sample ( Filter , In. TexCoord .xy , int2 (-1 , 0)). r; 
    float  x1  =  Depth.Sample ( Filter , In. TexCoord .xy , int2 ( 1 , 0)). r; 
    float  y0  =  Depth.Sample ( Filter , In. TexCoord .xy , int2 ( 0 , 1)). r; 
    float  y1  =  Depth.Sample ( Filter , In. TexCoord .xy , int2 ( 0 , -1)). r;

    // Sample another step as well for edge detection
    float ex0 = Depth . Sample ( Filter , In. TexCoord , int2 (-2 , 0)). r; 
    float ex1 = Depth . Sample ( Filter , In. TexCoord , int2 ( 2 , 0)). r; 
    float ey0 = Depth . Sample ( Filter , In. TexCoord , int2 ( 0 , 2)). r; 
    float ey1 = Depth . Sample ( Filter , In. TexCoord , int2 ( 0 , -2)). r;

    // Linear depths
    float lin_depth = LinearizeDepth ( center , DepthParams . xy ); 
    float lin_depth_x0  =  LinearizeDepth (x0 , DepthParams .xy ); 
    float lin_depth_x1  =  LinearizeDepth (x1 , DepthParams . xy ); 
    float lin_depth_y0  =  LinearizeDepth (y0 , DepthParams . xy ); 
    float lin_depth_y1  =  LinearizeDepth (y1 , DepthParams . xy );

    //   Local   position   ( WorldPos   -   EyePosition ) float3 pos = In. Dir * lin_depth ;
    float3 pos_x0 = In. DirX0 * lin_depth_x0 ; 
    float3 pos_x1 = In. DirX1 * lin_depth_x1 ; 
    float3 pos_y0 = In. DirY0 * lin_depth_y0 ; 
    float3 pos_y1 = In. DirY1 * lin_depth_y1 ;

    //   Compute   depth   differences    in   screespace    X   and   Y float dx0 = 2.0 f * x0 - center - ex0 ;
    float dx1 = 2.0 f * x1 - center - ex1 ; 
    float dy0 = 2.0 f * y0 - center - ey0 ; 
    float  dy1  =  2.0 f  *  y1  -  center  -  ey1 ;

    // Select the direction that has the straightest
    // slope and compute the tangent vectors float3 tanX , tanY ;
    if ( abs ( dx0 ) < abs ( dx1 )) 
        tanX = pos - pos_x0 ;
    else
        tanX = pos_x1 - pos ;

    if ( abs ( dy0 ) < abs ( dy1 )) 
        tanY = pos - pos_y0 ;
    else
        tanY = pos_y1 - pos ;
    
    tanX = normalize ( tanX ); tanY = normalize ( tanY );
    float3 normal = normalize ( cross ( tanX , tanY ));

### 3.4 其他内容

这一章的其他内容包括：

-   角色阴影（Character Shadows）
-   软粒子（Soft Particles）
-   抖动错误：处理浮点精度（The Jitter Bug: Dealing with Floating-Point Precision）
-   着色器常量管理（Shader constant management）
-   伽马校正和sRGB混合相关问题
-   云层渲染优化（Cloud Rendering Optimization）
-   粒子修剪（Particle Trimming）
-   内存优化（Memory Optimizations）

由于篇幅所限，这些内容无法展开讲解。感兴趣的朋友，不妨可以找到原书对应部分进行阅读。

<br>

## 四、《矿工战争》中的可破坏体积地形 | Destructible Volumetric Terrain

这篇文章中，主要讲到了游戏《矿工战争（Miner Wars）》中基于体素（voxel）的可破坏体积地形技术。

《矿工战争（Miner Wars）》游戏的主要特征是多维度地形的即时破坏，并且引擎依赖预先计算的数据。
每个地形变化都会实时计算，消耗尽可能少的内存并且没有明显的延迟。

![](media/dd3cc4def672a0a802fd71a30a451544.jpg)

图 《矿工战争》游戏截图

在游戏的实现中，体素是具有以米为单位的实际尺寸的三维像素。
每个体素都保存有关其密度的信息 – 是否全空，是否全满，或介于空和满之间，而体素的材质类型用于贴图，破坏以及游戏逻辑中。

文中将体素贴图（voxel map）定义为一组体素（例如，256 x 512 x 256）的集合。每个体素贴图包含体素的数据单元（data cells），以及包含静态顶点缓冲区和三角形索引的渲染单元（render cells）。

《矿工战争》的引擎不会直接渲染体素，相反，是将体素多边形化，在渲染或检测碰撞之前将其转换为三角形。使用标准的行进立方体（Marching Cubes , MC）算法 [“Marching”09]进行多边形化。

![](media/image25.jpg)

图 一艘采矿船用炸药进行隧道的挖掘

![](media/81d4b415ed7177c48d10b7516144d870.png)


图 具有表示体素边界的虚线的体素图。 此图描绘了4 x 4个体素;

图中的小十字代表体素内的网格点; 实线代表三维模型。


<br>

# Part II. 渲染技术 Rendering Techniques 


## 五、基于高度混合的四叉树位移贴图 | Quadtree Displacement Mapping with Height Blending 


这章中，介绍了当前表面渲染（surface rendering）技术的概述和相关比较，主要涉及在如下几种方法：

-   Relief Mapping | 浮雕贴图

-   Cone step mapping (CSM) | 锥步映射

-   Relaxed cone step mapping (RCSM) | 宽松锥步映射

-   Parallax Occlusion Mapping(POM) | 视差遮蔽贴图

-   Quadtree Displacement Mapping（QDM）| 四叉树位移贴图

内容方面，文章围绕表面渲染技术，分别介绍了光线追踪与表面渲染、四叉树位移映射（Quadtree Displacement Mapping）、自阴影（Self-Shadowing）、环境光遮蔽（Ambient Occlusion）、表面混合（Surface Blending）几个部分。为了获得最高的质量/性能/内存使用率，文章建议在特定情况下使用视差映射，软阴影，环境遮挡和表面混合方法的组合。

此外，文中还提出了具有高度混合的四叉树位移贴图。对于使用复杂，高分辨率高度场的超高质量表面，该方法明显会更高效。此外，使用引入的四叉树结构提出了高效的表面混合，软阴影，环境遮挡和自动LOD方案的解决方案。在实践中，此技术倾向于以较少的迭代和纹理样本产生更高质量的结果。

![](media/1a7051ace54640bd566a5d8f23a49358.jpg)

图 Parallax Occlusion Mapping(POM) 视差遮蔽贴图和Quadtree Displacement Mapping（QDM）四叉树位移贴图和的渲染质量比较。其中，左图为POM；右图为QDM。深度尺寸分别为：1.0,1.5,5.0。可以发现，在深度尺寸1.5以上时，使用POM（左图）会看到失真。

![](media/bb6c02aaed96d06830e23ab69e47f9e9.jpg)

![](media/8c4e3cc814ab179df6bb1f64d47b8838.jpg)

图 表面混合质量比较。上图：浮雕贴图（Relief Mapping），下图：带高度混合的视差遮蔽贴图（POM with height blending）



### 5.1 核心实现Shader代码

以下为视差遮蔽贴图（Parallax Occlusion Mapping，POM）核心代码：

    float Size = 1.0 / LinearSearchSteps;
    float Depth = 1.0;
    int StepIndex = 0;
    float CurrD = 0.0;
    float PrevD = 1.0;
    float2 p1 = 0.0;
    float2 p2 = 0.0;

    while (StepIndex < LinearSearchSteps)
    {
        Depth -= Size; // move the ray
        float4 TCoord = float2 (p+(v*Depth )); // new sampling pos
        CurrD = tex2D (texSMP , TCoord ).a; //new height
        if (CurrD > Depth ) // check for intersection
        {
            p1 = float2 (Depth , CurrD );
            p2 = float2 (Depth + Size , PrevD ); // store last step
            StepIndex = LinearSearchSteps; // break the loop
        }
        StepIndex ++;
        PrevD = CurrD ;
    }

    // Linear approximation using current and last step
    // instead of binary search , opposed to relief mapping .
    float d2 = p2.x - p2.y;
    float d1 = p1.x - p1.y;

    return (p1.x * d2 - p2.x * d1) / (d2 - d1);



四叉树位移贴图（Quadtree Displacement Mapping ，QDM）使用mipmap结构来表示密集的四叉树，在高度场的基准平面上方存储最大高度。QDM会在在交叉区域使用细化搜索，以便在需要时找到准确的解决方案。以下为四叉树位移贴图（QDM）搜索的核心代码：

    const int MaxLevel = MaxMipLvl ;
    const int NodeCount = pow (2.0, MaxLevel );
    const float HalfTexel = 1.0 / NodeCount / 2.0;
    float d;
    float3 p2 = p;
    int Level = MaxLevel ;

    //We calculate ray movement vector in inter -cell numbers .
    int2 DirSign = sign(v.xy);

    // Main loop
    while (Level >= 0)
    {
        //We get current cell minimum plane using tex2Dlod .
        d = tex2Dlod (HeightTexture , float4 (p2.xy , 0.0 , Level )). w;
        //If we are not blocked by the cell we move the ray .
        if (d > p2.z)
        {
            //We calculate predictive new ray position .
            float3 tmpP2 = p + v * d;

            //We compute current and predictive position .
            // Calculations are performed in cell integer numbers .
            int NodeCount = pow (2, (MaxLevel - Level ));
            int4 NodeID = int4((p2.xy , tmpP2 .xy) * NodeCount );

            //We test if both positions are still in the same cell.
            //If not , we have to move the ray to nearest cell boundary .
            if (NodeID .x != NodeID .z || NodeID .y != NodeID .w)
            {
                //We compute the distance to current cell boundary .
                //We perform the calculations in continuous space .
                float2 a = (p2.xy - p.xy);
                float2 p3 = (NodeID .xy + DirSign) / NodeCount ;
                float2 b = (p3.xy - p.xy);

                //We are choosing the nearest cell
                //by choosing smaller distance .
                float2 dNC = abs (p2.z * b / a);
                d = min (d, min (dNC .x, dNC .y));

                // During cell crossing we ascend in hierarchy .
                Level +=2;

                // Predictive refinement
                tmpP2 = p + v * d;
            }

            //Final ray movement
            p2 = tmpP2 ;
        }
        
        // Default descent in hierarchy
        // nullified by ascend in case of cell crossing
        Level --;
    }
    return p2;


这章也引入了一种表面混合的新方法，能更自然地适合表面混合，并且保证了更快的收敛。

文中建议使用高度信息作为额外的混合系数，从而为混合区域和更自然的外观添加更多种类，具体实现代码如下：

    float4 FinalH ;
    float4 f1 , f2 , f3 , f4;

    //Get surface sample .
    f1 = tex2D(Tex0Sampler ,TEXUV .xy).rgba;

    //Get height weight .
    FinalH .a = 1.0 - f1.a;
    f2 = tex2D(Tex1Sampler ,TEXUV .xy).rgba;
    FinalH .b = 1.0 - f2.a;
    f3 = tex2D(Tex2Sampler ,TEXUV .xy).rgba;
    FinalH .g = 1.0 - f3.a;
    f4 = tex2D(Tex3Sampler ,TEXUV .xy).rgba;
    FinalH .r = 1.0 - f4.a;

    // Modify height weights by blend weights .
    //Per -vertex blend weights stored in IN.AlphaBlends
    FinalH *= IN.AlphaBlends ;

    // Normalize .
    float Blend = dot (FinalH , 1.0) + epsilon ;
    FinalH /= Blend ;

    //Get final blend .
    FinalTex = FinalH .a * f1 + FinalH .b * f2 + FinalH .g * f3 + FinalH .r * f4;


在每个交叉点搜索（intersection search）步骤中，使用新的混合运算符重建高度场轮廓，实现代码如下所示：

    d = tex2D (HeightTexture ,p.xy).xyzw;
    b = tex2D (BlendTexture ,p.xy). xyzw;
    d *= b;
    d = max (d.x ,max (d.y,max (d.z,d.w)));

<br>

## 六、使用几何着色器的NPR效果 | NPR Effects Using the Geometry Shader


本章的内容关于非真实感渲染（Non-photorrealistic rendering ，NPR）。在这章中，介绍了一组利用GPU几何着色器流水线阶段实现的技术。

具体来说，文章展示了如何利用几何着色器来在单通道中渲染对象及其轮廓，并对铅笔素描效果进行了模拟。

单通道方法通常使用某种预计算来将邻接信息存储到顶点中[Card and Mitchell 02]，或者使用几何着色器 [Doss 08]，因为可能涉及到查询邻接信息。这些算法在单个渲染过程中生成轮廓，但对象本身仍需要第一个几何通道。

### 6.1 轮廓渲染（Silhouette Rendering）

轮廓渲染是大多数NPR效果的基本元素，因为它在物体形状的理解中起着重要作用。在本节中，提出了一种在单个渲染过程中检测，生成和纹理化模型的新方法。

轮廓渲染（Silhouette rendering）技术中， 两大类算法需要实时提取轮廓：

-   基于阴影体积的方法（shadow volume-based approaches）

-   非真实感渲染（non-photorealistic rendering）

而从文献中，可以提取两种不同的方法：

-   对象空间算法（object-space algorithms）

-   图像空间算法（image-space algorithms）

但是，大多数现代算法都在图像空间（image space）或混合空间（hybrid space）中工作。本章中主要介绍基于GPU的算法。GPU辅助算法可以使用多个渲染通道或单个渲染通道来计算轮廓。

为了一步完成整个轮廓渲染的过程，将会使用到几何着色器（geometry shader）。因为几何着色阶段允许三角形操作，能获取相邻三角形的信息，以及为几何体生成新的三角形。

轮廓渲染过程在流水线的不同阶段执行以下步骤：

-   顶点着色器（Vertex shader）。 顶点以通常的方式转换到相机空间。

-   几何着色器（Geometry shader）。
    在该阶段中，通过使用当前三角形及其邻接的信息来检测属于轮廓的边缘，并生成相应的几何体。

-   像素着色器（Pixel shader）。
    对于每个栅格化片段，生成其纹理坐标，并根据从纹理获得的颜色对像素进行着色。

![](media/6065d242b5fb94811659827213e1d145.jpg)

图 管线概述：顶点着色器（左）变换传入几何体的顶点坐标;第二步（几何着色器）为对象的轮廓生成新几何体。最后，像素着色器生成正确的纹理坐标。

几何着色器轮廓检测代码如下：

    [maxvertexcount (21)]
    void main( triangleadj VERTEXin input [6],
    inout TriangleStream <VERTEXout > TriStream )
    {
        // Calculate the triangle normal and view direction .
        float3 normalTrian = getNormal ( input [0].Pos .xyz ,
            input [2].Pos .xyz , input [4].Pos .xyz );
        float3 viewDirect = normalize (-input [0].Pos .xyz
            - input [2]. Pos .xyz - input [4].Pos .xyz );

        //If the triangle is frontfacing
        [branch ]if(dot (normalTrian ,viewDirect ) > 0.0f)
        {
            [loop]for (uint i = 0; i < 6; i+=2)
            {
                // Calculate the normal for this triangle .
                float auxIndex = (i+2)%6;
                float3 auxNormal = getNormal ( input [i].Pos .xyz ,
                    input[i+1].Pos .xyz , input[auxIndex ].Pos .xyz );
                float3 auxDirect = normalize (- input[i].Pos .xyz
                    - input [i+1].Pos .xyz - input[auxIndex ].Pos .xyz );

                //If the triangle is backfacing
                [branch ]if(dot (auxNormal ,auxDirect) <= 0.0f)
                {
                    // Here we have a silhouette edge.
                }
            }
        }
    }


几何着色器轮廓生成代码如下：

    // Transform the positions to screen space .
    float4 transPos1 = mul (input [i].Pos ,projMatrix );
    transPos1 = transPos1 /transPos1 .w;
    float4 transPos2 = mul (input [auxIndex ].Pos ,projMatrix );
    transPos2 = transPos2 /transPos2 .w;

    // Calculate the edge direction in screen space .
    float2 edgeDirection = normalize (transPos2 .xy - transPos1 .xy);

    // Calculate the extrude vector in screen space .
    float4 extrudeDirection = float4 (normalize (
    float2 (-edgeDirection.y ,edgeDirection.x)) ,0.0f ,0.0f);

    // Calculate the extrude vector along the vertex
    // normal in screen space.
    float4 normExtrude1 = mul (input [i].Pos + input [i]. Normal
    ,projMatrix );
    normExtrude1 = normExtrude1 / normExtrude1.w;
    normExtrude1 = normExtrude1 - transPos1 ;
    normExtrude1 = float4 (normalize (normExtrude1.xy),0.0f ,0.0f);
    float4 normExtrude2 = mul (input [auxIndex ].Pos
    + input [auxIndex ].Normal ,projMatrix );
    normExtrude2 = normExtrude2 / normExtrude2.w;
    normExtrude2 = normExtrude2 - transPos2 ;
    normExtrude2 = float4 (normalize (normExtrude2.xy),0.0f ,0.0f);

    // Scale the extrude directions with the edge size.
    normExtrude1 = normExtrude1 * edgeSize ;
    normExtrude2 = normExtrude2 * edgeSize ;
    extrudeDirection = extrudeDirection * edgeSize ;

    // Calculate the extruded vertices .
    float4 normVertex1 = transPos1 + normExtrude1;
    float4 extruVertex1 = transPos1 + extrudeDirection;
    float4 normVertex2 = transPos2 + normExtrude2;
    float4 extruVertex2 = transPos2 + extrudeDirection;

    // Create the output polygons .
    VERTEXout outVert ;
    outVert .Pos = float4 (normVertex1 .xyz ,1.0f);
    TriStream .Append (outVert );
    outVert .Pos = float4 (extruVertex1.xyz ,1.0f);
    TriStream .Append (outVert );
    outVert .Pos = float4 (transPos1 .xyz ,1.0f);
    TriStream .Append (outVert );
    outVert .Pos = float4 (extruVertex2.xyz ,1.0f);
    TriStream .Append (outVert );
    outVert .Pos = float4 (transPos2 .xyz ,1.0f);
    TriStream .Append (outVert );
    outVert .Pos = float4 (normVertex2 .xyz ,1.0f);
    TriStream .Append (outVert );
    TriStream .RestartStrip();



在像素着色器中轮廓纹理映射的实现代码：

    float4 main(PIXELin inPut ):SV_Target
    {
        // Initial texture coordinate .
        float2 coord = float2 (0.0f,inPut.UV.z);

        // Vector from the projected center bounding box to
        //the location .
        float2 vect = inPut .UV.xy - aabbPos ;

        // Calculate the polar coordinate .
        float angle = atan(vect.y/vect.x);
        angle = (vect.x < 0.0 f)? angle+PI:
        (vect.y < 0.0f)?angle +(2* PI): angle ;

        // Assign the angle plus distance to the u texture coordinate .
        coord .x = ((angle /(2* PI)) + (length (vect)* lengthPer ))* scale;

        //Get the texture color .
        float4 col = texureDiff .Sample (samLinear ,coord );

        // Alpha test.
        if(col .a < 0.1 f)
        discard ;
        
        // Return color .
        return col ;
    }



![](media/9961590888343ce5f500bc4dbcf7b442.png)

图 轮廓渲染算法的运行效果图，轮廓剪影的实时生成和纹理化。

完整的实现Shader源码可见：
<https://github.com/QianMo/GPU-Pro-Books-Source-Code/blob/master/GPU-Pro-1/03_Rendering%20Techniques/02_NPReffectsusingtheGeometryShader/NPRGS/NPRGS/Silhouette.fx>


### 6.2 铅笔素描渲染（Pencil Rendering）

基于Lee等人[Lee et al. 06]铅笔渲染思路可以概括如下。

首先，计算每个顶点处的最小曲率（curvature）。然后，三角形和其曲率值作为每个顶点的纹理坐标传入管线。
为了对三角形的内部进行着色，顶点处的曲率用于在屏幕空间中旋转铅笔纹理。该铅笔纹理会在屏幕空间中进行三次旋转，每个曲率一次，旋转后的结果进行混合结合。不同色调的多个纹理，存储在纹理阵列中，同时进行使用。最终，根据光照情况在其中选择出正确的一个。

![](media/fa42018d66709fbd9879f1ca334d987c.jpg)

图 管线概述：顶点着色器将顶点转换为屏幕空间;几何着色器将三角形的顶点曲率分配给三个顶点。最后，像素着色器生成三个曲率的纹理坐标并计算最终颜色。

可以通过以下方式使用GPU管线实现此算法：

-   顶点着色器（Vertex shader）。 顶点转换为屏幕坐标。顶点曲率也被变换，只有x和y分量作为二维向量传递。

-   几何着色器（Geometry shader）。 将曲率值作为纹理坐标分配给每个顶点。

-   像素着色器（Pixel shader）。 计算最终颜色。

几何着色器的实现代码如下：

    [maxvertexcount (3)]
    void main( triangle VERTEXin input [3],
    inout TriangleStream <VERTEXout > TriStream )
    {
        // Assign triangle curvatures to the three vertices .
        VERTEXout outVert ;
        outVert .Pos = input [0].Pos ;
        outVert .norm = input [0]. norm;
        outVert .curv1 = input [0]. curv;
        outVert .curv2 = input [1]. curv;
        outVert .curv3 = input [2]. curv;
        TriStream .Append (outVert );
        outVert .Pos = input [1].Pos ;
        outVert .norm = input [1]. norm;
        outVert .curv1 = input [0]. curv;
        outVert .curv2 = input [1]. curv;
        outVert .curv3 = input [2]. curv;
        TriStream .Append (outVert );
        outVert .Pos = input [2].Pos ;
        outVert .norm = input [2]. norm;
        outVert .curv1 = input [0]. curv;
        outVert .curv2 = input [1]. curv;
        outVert .curv3 = input [2]. curv;
        TriStream .Append (outVert );
        TriStream . RestartStrip();
    }


像素着色器的实现代码如下：

    float4 main(PIXELin inPut ):SV_Target
    {
        float2 xdir = float2 (1.0f ,0.0f);
        float2x2 rotMat ;
        // Calculate the pixel coordinates .
        float2 uv = float2 (inPut .Pos .x/width ,inPut .Pos .y/height );

        // Calculate the rotated coordinates .
        float2 uvDir = normalize (inPut .curv1 );
        float angle = atan(uvDir .y/uvDir.x);
        angle = (uvDir .x < 0.0 f)? angle +PI:
        (uvDir .y < 0.0f)? angle +(2* PI): angle ;
        float cosVal = cos (angle );
        float sinVal = sin (angle );
        rotMat [0][0] = cosVal ;
        rotMat [1][0] = -sinVal ;
        rotMat [0][1] = sinVal ;
        rotMat [1][1] = cosVal ;
        float2 uv1 = mul (uv ,rotMat );

        uvDir = normalize (inPut.curv2 );
        angle = atan(uvDir .y/uvDir.x);
        angle = (uvDir .x < 0.0 f)? angle +PI:
        (uvDir .y < 0.0f)? angle +(2* PI): angle ;
        cosVal = cos (angle );
        sinVal = sin (angle );
        rotMat [0][0] = cosVal ;
        rotMat [1][0] = -sinVal ;
        rotMat [0][1] = sinVal ;
        rotMat [1][1] = cosVal ;
        float2 uv2 = mul (uv ,rotMat );

        uvDir = normalize (inPut .curv3 );
        angle = atan(uvDir.y/uvDir.x);
        angle = (uvDir .x < 0.0 f)? angle +PI:
        (uvDir .y < 0.0f)?angle +(2* PI): angle ;
        cosVal = cos (angle );
        sinVal = sin (angle );
        rotMat [0][0] = cosVal ;
        rotMat [1][0] = -sinVal ;
        rotMat [0][1] = sinVal ;
        rotMat [1][1] = cosVal ;
        float2 uv3 = mul (uv ,rotMat );

        // Calculate the light incident at this pixel.
        float percen = 1.0f - max (dot (normalize (inPut .norm),
        lightDir ) ,0.0);

        // Combine the three colors .
        float4 color = (texPencil .Sample (samLinear ,uv1 )*0.333 f)
        +( texPencil .Sample (samLinear ,uv2 )*0.333 f)
        +( texPencil .Sample (samLinear ,uv3 )*0.333 f);

        // Calculate the final color .
        percen = (percen *S) + O;
        color .xyz = pow (color .xyz ,float3 (percen ,percen ,percen ));
        return color;
    }


最终的渲染效果：

![](media/007e69cbd0da96706c4a163a201f3c44.png)

图 铅笔渲染效果图

完整的实现Shader源码可见：
<https://github.com/QianMo/GPU-Pro-Books-Source-Code/blob/master/GPU-Pro-1/03_Rendering%20Techniques/02_NPReffectsusingtheGeometryShader/NPRGS/NPRGS/Pencil.fx>


<br>

## 七、后处理Alpha混合 | Alpha Blending as a Post-Process


在这篇文章中提出了一种新的Alpha混合技术，屏幕空间Alpha遮罩（ Screen-Space Alpha Mask ,简称SSAM）。该技术首次运用于赛车游戏《Pure》中。《Pure》发行于2008年夏天，登陆平台为Xbox360,PS3和PC。

![](media/c4768e8edcdf14450dab6a5ae65e4af7.jpg)

图 《Pure》中的场景（tone mapping & bloom效果）

在《Pure》的开发过程中，明显地需要大量的alpha混合（alpha blending）操作。但是众所周知，传统的计算机图形学的难题之一，就是正确地进行alpha混合操作，并且往往在性能和视觉质量之间，经常很难权衡。

实际上，由于不愿意承担性能上的风险，一些游戏会完全去避免使用alpha混合。有关alpha混合渲染所带来的问题的全面介绍，可以参考[Thibieroz 08]，以及[Porter and Duﬀ 84]。

在这篇文章中，提出了一种新颖的（跨平台）解决方案，用于树叶的alpha混合，这种解决方案可以提高各种alpha测试级渲染的质量，为它们提供真正的alpha混合效果。

文中设计的解决方案——屏幕空间Alpha遮罩（Screen-Space Alpha Mask ,简称SSAM），是一种采用渲染技术实现的多通道方法，如下图。无需任何深度排序或几何分割。

在《Pure》中使用的SSAM技术对环境的整体视觉质量有着深远的影响。
效果呈现出柔和自然的外观，无需牺牲画面中的任何细节。

![](media/b9a8f6f5dec7856785493ee8b0db28a2.jpg)

图 SSAM的技术思路图示

此解决方案可以产生与alpha混合相同的结果，同时使用alpha测试技术正确解决每个像素的内部重叠（和深度交集）。

文中使用全屏幕后处理高效地执行延迟alpha混合（deferred alpha blending），类似于将帧混合操作设置为ADD的帧缓冲混合;源和目标参数分别设置为SRCALPHA和INVSRCALPHA。

混合输入被渲染成三个单独的渲染目标（render targets），然后绑定到纹理采样器（texture samplers），由最终的组合后处理像素着色器引用。

在内存资源方面，至少需要三个屏幕分辨率的渲染目标，其中的两个至少具有三个颜色的通道（rtOpaque & rtFoliage），而另一个至少有两个通道（rtMask）和一个深度缓冲区（rtDepth） 。

下面列举一些SSAM的优点和缺点。

SSAM的优点：

-   树叶边缘与周围环境平滑融合。

-   使用alpha测试技术，在每像素的基础上对内部重叠和相互穿透的图元进行排序。

-   该效果使用简单，低成本的渲染技术实现，不需要任何几何排序或拆分（只需要原始调度顺序的一致性）。

-   无论场景复杂度和overdraw如何，最终的混合操作都是以线性成本（每像素一次）来执行运算。

-   该效果与能渲染管线中的其他alpha混合阶段（如粒子等）完美集成。

-   与其他优化（如将光照移到顶点着色器）以及优化每个通道的着色器等方法结合使用时，总体性能可能会高于基于MSAA（MultiSampling
    Anti-Aliasing，多重采样抗锯齿）的技术。

SSAM的缺点：

-   需要额外的渲染Pass的开销。

-   内存要求更高，因为需要存储三张图像。

-   该技术不能用于对大量半透明，玻璃状的表面进行排序（或横跨大部分屏幕的模糊alpha梯度），可能会产生失真。


### 7.1 核心实现Shader代码

最终后处理合成的像素着色器实现代码：

    sampler2D rtMask : register (s0);
    sampler2D rtOpaque : register (s1);
    sampler2D rtFoliage : register (s2);
    half maskLerp : register (c0); // 0.85h
    half4 main(float2 texCoord : TEXCOORD0) : COLOR
    {
        half4 maskPixel = tex2D ( rtMask , texCoord );
        half4 opaquePixel = tex2D ( rtOpaque , texCoord );
        half4 foliagePixel = tex2D (rtFoliage , texCoord );
        half mask = lerp(maskPixel .x , maskPixel .w, maskLerp );
        return lerp(opaquePixel , foliagePixel , mask * mask);
    }


## 八、虚拟纹理映射简介 | Virtual Texture Mapping 101


在这篇文章主要探讨了如何实现一个功能完备的虚拟纹理映射（Virtual Texture Mapping，VTM）系统。

首先，虚拟纹理映射（VTM）是一种将纹理所需的图形内存量减少到仅取决于屏幕分辨率的技术：对于给定的视点，我们只将纹理的可见部分保留在图形存储器中适当的MIP映射级别上，如下图。

![](media/beba6a37fa84e7ce99d9a614c3c67483.jpg)

图 使用单个的虚拟纹理渲染出独特的纹理地形

早期的纹理管理方案是针对单个大纹理设计的[Tanner et al. 98],文章发表期间的VTM系统则更加灵活，模仿了操作系统的虚拟内存管理的思路：将纹理分成小的图块（tiles），或者页（pages）[Kraus and Ertl 02, Lefebvre et al.04]。这些会根据渲染当前视点的需要自动缓存并加载到GPU上。但是，有必要将对缺失数据的访问重定向（redirect）到后备纹理。这可以防止渲染中出现“空洞”（加载请求完成前的阻塞和等待的情况）。

文中的实现的灵感来源于GDC上Sean Barrett[Barret 08]的演讲。如下图所示，在每帧开始，先确定哪些图块（tiles）可见，接着识别出其中没有缓存且没有磁盘请求的图块。在图块上传到GPU上的图块缓存之后，更新一个间接纹理（indrection texture,）或者页表（page table）。最终，渲染场景，对间接纹理执行初始查找，以确定在图块缓存中采样的位置。

![](media/9197db42270ce9c5c4a422252d4a129d.jpg)

图 渲染图块ID，然后识别并更新最近可见的图块到图块缓存中（图中的红色），并可能会覆盖不再可见的图块（图中的蓝色）。更新间接纹理并渲染纹理化表面（texturized surfaces）

间接纹理（indirection texture）是完整虚拟纹理的缩小版本，其中每个纹素都指向图块缓存（tile cache）中的图块。在文中的示例中，图块缓存只是GPU上的一个大纹理，包含小的，相同分辨率的正方形图块。

这意味着来自不同mip map级别的图块（tiles）会覆盖虚拟纹理的不同大小区域，但会大大简化图块缓存的管理。


## 8.1 核心实现Shader代码

### 8.1.1 MIP 贴图计算的Shader实现 | MIP Map Calculation

    float ComputeMipMapLevel(float2 UV_pixels , float scale)
    {
        float2 x_deriv = ddx (UV_pixels );
        float2 y_deriv = ddy (UV_pixels );
        float d = max (length (x_deriv ), length (y_deriv ));
        return max (log2(d) - log2(scale ), 0);
    }


#### 8.1.2 图块ID 的Shader实现 | Tile ID Shader

    float2 UV_pixels = In.UV * VTMResolution ,

    float mipLevel = ComputeMipMapLevel(UV_pixels , subSampleFactor);
    mipLevel = floor(min (mipLevel , MaxMipMapLevel));

    float4 tileID ;
    tileID .rg = floor (UV_pixels / (TileRes * exp2(mipLevel )));
    tileID .b = mipLevel ;
    tileID .a = TextureID ;

    return tileID ;


#### 8.1.3 虚拟纹理查找的Shader实现 | Virtual Texture Lookup

    float3 tileEntry = IndTex .Sample (PointSampler , In.UV);
    float actualResolution = exp2(tileEntry .z);
    float2 offset = frac(In.UV * actualResolution) * TileRes ;
    float scale = actualResolution * TileRes ;
    float2 ddx_correct = ddx (In.UV) * scale;
    float2 ddy_correct = ddy (In.UV) * scale;
    return TileCache .SampleGrad (TextureSampler ,
    tileEntry .xy + offset ,
    ddx_correct ,
    ddy_correct );


# Part III、全局光照 Global Illumination 


## 九、基于间接光照的快速，基于模板的多分辨率泼溅 Fast, Stencil-Based Multiresolution Splatting for Indirect Illumination


本章介绍了交互式即时辐射度（radiosity）解决方案的改进，该解决方案通过使用多分辨率泼溅（multiresolution splats）技术，显着降低了填充率（fill rate），并展示了其使用模板缓冲（stencil buﬀer）的一种高效实现。与最原始的多分辨率泼溅[Nichols and Wyman 09]不同的是，此实现不通过几何着色器执行放大，因此能保持在GPU快速路径（GPU fast path）上。相反，这章利用了GPU的分层模板剔除（hierarchical stencil culling）和Z剔除（z culling）功能，以在合适的分辨率下高效地进行光照的渲染。

其核心实现算法如下：

    pixels ←FullScreenQuad();
    vpls ← SampledVirtualPointLights();
    for all ( v ∈ vpls ) do
        for all ( p ∈ pixels ) do
            if ( FailsEarlyStencilTest( p ) ) then
                continue; // Not part of multiresolution splat
            end if
            IlluminatePatchFromPointLight( p, v );
        end for
    end for


![](media/2c9b16a1c95fb8284a498967e6e5e19b.png)

图 多分辨率光照泼溅开始于直接光照的渲染（左图）。每个VPL产生一个全屏幕的图示，允许每个VPL为每个像素提供光线。每个VPL产生一个全屏的泼溅，允许每个VPL为每个像素提供光线。但根据本地照明变化的速度，这些图层会以多种分辨率呈现。伪彩色全屏泼溅（中图）显示了不同分辨率的区域，这些区域被渲染为不同的buffer（右图）

![](media/d334dde4b4259dddeb29cad0a92eb953.png)

图 多分辨率片的迭代求精从统一的粗图像采样开始（例如，162个采样）。处理粗粒度片元，识别需要进一步求精的片元并创建四个更精细的分辨率片元。进一步的操作会进一步细化片元直到达到某个阈值，例如最大精度级别或超过指定的片元数量。

![](media/cf2ff293b62b459a26b503c79036a663.png)

图 前一幅图中的，多分辨率泼溅可以进行并行计算而不是迭代计算（左图）。右图中的多分辨率buffer中的片元，都为并行处理。


### 9.1 实现思路小结

#### 9.1.1 多分辨率泼溅的实现思路 | Multiresolution Splatting Implement

以下是多分辨率泼溅实现思路，其中VPL的全称是虚拟点光源（virtual point light）：

    1.	Render a shadow map augmented by position, normal, and color.
    2.	Select VPLs from this shadow map.
    3.	Render from the eye using only direct light.
    4.	For each VPL:
        (a)	Draw a full-screen “splat.”
        (b)	Each splat fragment illuminates one texel (in one of the multiresolu- tion buﬀers in Figure 1.4) from a single VPL, though this texel may ultimately aﬀect multiple pixels.
        (c)	Blend each fragment into the appropriate multiresolution buﬀer.
    5.	Combine, upsample and interpolate the multiresolution buﬀers.
    6.	Combine the interpolated illumination with the direct light.


#### 9.1.2 设置可接受模糊 | Setting acceptable blur

    patches ← CoarseImageSampling();
        for (i=1 to numRefinementPasses) do
            for all (p ∈ patches) do
            if ( NoDiscontinuity( p ) ) then
                continue;
            end if
            patches ← (patches − {p});
            patches ← (patches ∪ SubdivideIntoFour( p ) );
        end for
    end for



#### 9.1.3 从虚拟点光源收集光照进行泼溅 | Gathering illumination from VPLs for splatting

    patches ← IterativelyRefinedPatches();
    vpls ← SampledVirtualPointLights();
    for all ( v ∈ vpls ) do
        for all ( p ∈ patches ) do
            TransformToFragmentInMultiresBuffer( p ); // In vertex shader
            IlluminateFragmentFromPointLight( p, v ); // In fragment shader
            BlendFragmentIntoMultiresBufferIllumination( p );
        end for
    end for


#### 9.1.4 降采样多分辨率照明缓存 | Unsampling the multiresolution illumination buffer.

    coarserImage ← CoarseBlackImage();
    for all ( buffer resolutions j from coarse to fine ) do
        finerImage ← MultresBuffer( level j );
        for all ( pixels p ∈ finerImage ) do
            if ( InvalidTexel( p, coarserImage ) ) then
                continue; // Nothing to blend from lower resolution!
            end if
            p1, p2, p3, p4 ← FourNearestCoarseTexels( p, coarserImage );
            ω1, ω2, ω3, ω4 ← BilinearInterpolationWeights( p, p1, p2, p3, p4);
            for all ( i ∈ [1..4] ) do
                ωi = InvalidTexel( pi, coarserImage ) ) ? 0 : ωi;
            end for
            finerImage[p] += (ω1p1 + ω2p2 + ω3p3 + ω4p4)/(ω1 + ω2 + ω3 + ω4)
        end for
        coarserImage ← finerImage;
    end for


#### 9.1.5 并行泼溅求精 | Parallel splat refinement

    for all (fragments f ∈ image) do
        if ( _ j such that f ∈ MipmapLevel( j ) ) then
            continue; // Fragment not actually in multires buffer
        end if
        j ← GetMipmapLevel( f );
        if ( IsDiscontinuity( f, j ) ) then
            continue; // Fragment needs further subdivision
        end if
        if ( NoDiscontinuity( f, j + 1 ) ) then
            continue; // Coarser fragment did not need subdivision
        end if
        SetStencil( f );
    end for


#### 9.1.6 最终基于模板的多分辨率泼溅算法

    pixels ←FullScreenQuad();
    vpls ← SampledVirtualPointLights();
    for all ( v ∈ vpls ) do
        for all ( p ∈ pixels ) do
            if ( FailsEarlyStencilTest( p ) ) then
                continue; // Not part of multiresolution splat
            end if
            IlluminatePatchFromPointLight( p, v );
        end for
    end for

<br>

## 十、屏幕空间定向环境光遮蔽 Screen-Space Directional Occlusion （SSDO）


环境光遮蔽（AO）是全局光照的一种近似，由于其良好的视觉质量和简单的实现[Landis 02]，其常常用于电影和游戏中。环境光遮蔽的基本思想是预先计算网格表面几个位置的平均可见性值。然后这些值在运行时与图形硬件提供的未遮挡光照相乘。

环境光遮蔽的一个缺点是它仅适用于静态场景。如果为每个顶点或纹理元素预先计算了可见性值，则在网格变形时这些值将无效。

动态场景的一些初步想法有[Bunnell 06]和[Hoberock and Jia07]通过用层次圆盘（hierarchy of discs）近似几何体的思路。处理动态场景的最简单方法是根据帧缓冲区中的信息计算环境光遮蔽，即所谓的屏幕空间环境光遮蔽（SSAO）。这里深度缓冲区用于在运行时计算平均可见度值而不是预先计算。这章内容发表期间的GPU算力已足以实时计算SSAO。此外，该方法不需要场景的任何特殊几何的表现，因为仅使用到帧缓冲器中的信息来计算遮蔽值。甚至不需要使用由多边形组成的三维模型，因为我们可以从产生深度缓冲区的任何渲染计算遮挡。

![](media/379bd1804f56e7f478afd38f52fe2652.png)
图 屏幕空间环境光遮蔽（SSAO）：对于帧缓冲器中的每个像素，检查一组相邻像素，并将一个极小的球状物体放置在相应的三维位置。为每个球体计算遮蔽值，并将所有这些值累积到一个环境遮蔽值中。最后，该值乘以来自所有方向的未被遮蔽的光照。

环境光遮蔽通常显示空腔暗化（darkening of cavities）和接触阴影（contact shadows），但忽略入射光的所有方向信息。发生这种情况是因为只有几何体用于计算环境光遮蔽，而忽略了实际光照。典型的问题情况如下图所示：在方向变化的入射光的情况下，环境光遮蔽将显示错误的颜色。因此，该章将SSAO扩展到称之为屏幕空间定向遮挡（SSDO）的更真实光照技术。

由于循环遍历片段程序中的许多相邻像素，因此可以为每个像素计算单独的可见性值，而不是将所有信息折叠为单个AO值。因此，基本思想是使用来自每个方向的入射光的可见性信息，并仅从可见方向照射，从而产生定向的光照。

为对SSDO的数据做进一步描述，假设有一个深度帧缓冲区，其中包含每像素的位置，法线和反射率值。

![](media/c32e665b609fc1b1ceb2b413aac865e4.png)

图 环境光遮蔽的典型问题示例。由于红色光源被遮挡而绿色光源照亮了点P，我们希望在这里看到一个绿色的阴影。但环境遮挡首先计算来自所有方向的光照，因此点P最初为黄色，然后通过某个平均遮挡值进行缩放，从而产生了不正确的棕色。

本章提出的SSDO算法具体可以总结如下：

-   首先，在像素的三维点周围放置一个半球，该半球沿着表面法线定向。该半球的半径r_max是用户参数，其用于决定搜索阻挡物的本地邻域的大小。

-   然后，将一些三维采样点均匀分布在半球内部。同样，采样点数N是用于时间质量平衡的用户参数。

-   接着，测试每个采样方向的光照是否被阻挡或可见。因此，我们将每个采样点反投影到深度帧缓冲区。在像素位置，可以读取表面上的三维位置，并将每个点移动到表面上。如果采样点朝向观察者移动，则它最初位于表面下方并且被分类为被遮挡。如果它远离观察者，它最初在表面上方并且被分类为可见。

在下图的示例中，点A，B和D在表面下方并被分类为遮挡物。只有样本C可见，因为它在表面上方。因此，仅从方向C计算光照。

![](media/1418d17ef805f2f67c126551e1fba78f.png)

图 SSDO屏幕空间定向环境光遮蔽。左图：为了计算点P处的方向遮挡，在半球中创建一些均匀分布的采样点，并将它们反投影到深度帧缓冲区中。（最初）在表面下方的每个点被视为遮挡物。 右图：仅从可见点计算光照。在这里，假设每个采样方向的立体角，并使用模糊环境贴图传入光亮度。

![](media/e62828ddc53abaa4b53577695ee5b483.jpg)

图 屏幕空间定向环境光遮蔽（Screen-Space Directional Occlusion，SSDO）效果图


### 10.1 核心实现Shader代码

#### 10.1.1 屏幕空间定向环境光遮蔽SSDO 的Shader源码

    // Read position and normal of the pixel from deep framebuffer .
    vec4 position = texelFetch2D(positionTexture ,
    ivec2 ( gl_FragCoord.xy), 0);
    vec3 normal = texelFetch2D(normalTexture ,
    ivec2( gl_FragCoord.xy), 0);

    // Skip pixels without geometry .
    if(position .a > 0.0) {
        vec3 directRadianceSum = vec3 (0.0);
        vec3 occluderRadianceSum = vec3 (0.0);
        vec3 ambientRadianceSum = vec3 (0.0);
        float ambientOcclusion = 0.0;

        // Compute a matrix that transform from the unit hemisphere .
        // along z = -1 to the local frame along this normal
        mat3 localMatrix = computeTripodMatrix(normal );

        // Compute the index of the current pattern .
        // We use one out of patternSize * patternSize
        // pre -defined unit hemisphere patterns (seedTexture ).
        // The i’th pixel in every sub -rectangle uses always
        // the same i’th sub -pattern .
        int patternIndex = int (gl_FragCoord.x) % patternSize +
        (int ( gl_FragCoord.y) % patternSize) *
        patternSize ;

        // Loop over all samples from the current pattern .
        for (int i = 0; i < sampleCount ; i++) {

            // Get the i’th sample direction from the row at
            // patternIndex and transfrom it to local space .
            vec3 sample = localMatrix * texelFetch2D(seedTexture ,
            ivec2(i, patternIndex), 0). rgb ;
            vec3 normalizedSample = normalize (sample );

            // Go sample -radius steps along the sample direction ,
            // starting at the current pixel world space location .
            vec4 worldSampleOccluderPosition = position +
            sampleRadius * vec4(sample .x, sample .y , sample .z, 0);

            // Project this world occluder position in the current
            // eye space using the modelview -projection matrix .
            // Due to the deferred shading , the standard OpenGL
            // matrix can not be used.
            vec4 occluderSamplePosition = (projectionMatrix *
            modelviewMatrix) * worldSampleOccluderPosition ;

            // Compute the pixel position of the occluder :
            // Do a division by w first (perspective projection ),
            // then scale /bias by 0.5 to transform [-1,1] -> [0 ,1].
            // Finally scale by the texure resolution .
            vec2 occluderTexCoord = textureSize2D(positionTexture ,0)
            * (vec2 (0.5) + 0.5 * ( occluderSamplePosition .xy /
            occluderSamplePosition .w));

            // Read the occluder position and the occluder normal
            // at the occluder texture coordinate .
            vec4 occluderPosition = texelFetch2D(positionTexture ,
            ivec2 (occluderTexCoord), 0);
            vec3 occluderNormal = texelFetch2D(normalTexture ,
            ivec2 (occluderTexCoord), 0);
            float depth = (modelviewMatrix *
            worldSampleOccluderPosition ).z;

            // Compute depth of corresponding (proj.) pixel position .
            float sampleDepth = (modelviewMatrix *
            occluderPosition).z + depthBias ;

            // Ignore samples that move more than a
            // certain distance due to the projection
            // (typically singularity is set to hemisphere radius ).
            float distanceTerm = abs (depth - sampleDepth) <
            singularity ? 1.0 : 0.0;

            // Compute visibility when sample moves towards viewer .
            // We look along the -z axis , so sampleDepth is
            // larger than depth in this case.
            float visibility = 1.0 - strength *
            (sampleDepth > depth ? 1.0 : 0.0) * distanceTerm;

            // Geometric term of the current pixel towards the
            // current sample direction
            float receiverGeometricTerm = max (0.0,
            dot (normalizedSample , normal ));

            // Compute spherical coordinates (theta , phi )
            // of current sample direction .
            float theta = acos(normalizedSample.y);
            float phi = atan( normalizedSample.z ,normalizedSample.x);
            if (phi < 0) phi += 2*PI;

            // Get environment radiance of this direction from
            // blurred lat /long environment map .
            vec3 senderRadiance = texture2D (envmapTexture ,
            vec2( phi / (2.0* PI), 1.0 - theta / PI ) ).rgb ;

            // Compute radiance as the usual triple product
            // of visibility , radiance , and BRDF.
            // For practical reasons , we post -multiply
            // with the diffuse reflectance color.
            vec3 radiance = visibility * receiverGeometricTerm *
            senderRadiance;

            // Accumulate the radiance from all samples .
            directRadianceSum += radiance ;
            // Indirect light can be computed here
            // (see Indirect Light Listing )
            // The sum of the indirect light is stored
            // in occluderRadianceSum
        }

        // In case of a large value of -strength , the summed
        // radiance can become negative , so we clamp to zero here.
        directRadianceSum = max (vec3(0), directRadianceSum);
        occluderRadianceSum = max (vec3 (0), occluderRadianceSum );

        // Add direct and indirect radiance .
        vec3 radianceSum = directRadianceSum + occluderRadianceSum;

        // Multiply by solid angle and output result .
        radianceSum *= 2.0 * PI / sampleCount ;
        gl_FragColor = vec4(radianceSum , 1.0);
        } else {

        // In case we came across an invalid deferred pixel
        gl_FragColor = vec4 (0.0);
    }


#### 10.1.2 SSDO间接光计算Shader实现代码

间接光计算的源代码。 此时，从SSDO计算中已知像素位置和遮挡物位置/纹理坐标。这段代码可以包含在上述SSDO实现代码的循环结尾处。

    // Read the (sender ) radiance of the occluder .
    vec3 directRadiance = texelFetch2D(directRadianceTexture ,
    ivec2( occluderTexCoord), 0);

    // At this point we already know the occluder position and
    // normal from the SSDO computation . Now we compute the distance
    // vector between sender and receiver .
    vec3 delta = position .xyz - occluderPosition.xyz ;
    vec3 normalizedDelta = normalize (delta );

    // Compute the geometric term (the formfactor ).
    float unclampedBounceGeometricTerm =
    max (0.0, dot (normalizedDelta , -normal )) *
    max (0.0, dot (normalizedDelta , occluderNormal)) /
    dot (delta , delta );

    // Clamp geometric term to avoid problems with close occluders .
    float bounceGeometricTerm = min (unclampedBounceGeometricTerm ,
    bounceSingularity);

    // Compute the radiance at the receiver .
    vec3 occluderRadiance = bounceStrength * directRadiance *
    bounceGeometricTerm ;

    // Finally , add the indirect light to the sum of indirect light .
    occluderRadianceSum += occluderRadiance;




## 十一、基于几何替代物技术的实时多级光线追踪 | Real-Time Multi-Bounce Ray-Tracing with Geometry Impostors


在实时应用中渲染反射和折射物体或它们的焦散（caustics）是一个具有挑战性的问题。其需要非局部着色，这对于光栅化渲染管线来说比较复杂，其中片段着色器只能使用局部插值顶点数据和纹理来查找曲面点的颜色。

物体的反射、折射和其焦散效果通常需要光线跟踪进行渲染，但光线跟踪通常不具备与光栅化渲染相同的性能。

而通常，使用基于纹理的特殊tricks可以将光线跟踪效果加入到实时场景中。这些技术通常假设场景中只有一个反射或折射物体，并且仅考虑一次或两次反射光就足够了。在这章中，遵循了类似的实践原理，但是除去这些限制，以便能够渲染布满玻璃碎片的完整棋盘，甚至折射物体浸没在动画液体中等场景。

这章中扩展了先前基于环境距离替代物技术（environment distance impostors）的近似光线追踪技术，以便在当时硬件条件的限制下，实时渲染具有多个反射和折射物体的场景。

有两个关键的思路。

首先，文章改为使用距离替代物（distance impostor）方法，不将内部光线（internal rays）与封闭的环境几何体相交，而是将外部光线（external rays）与物体相交。另外，这章展示了如何高效地追踪二次反射和折射光线，还研究了可以适应相同的任务的其他类型的几何替代物技术 – 如几何图像（geometry images）[Carr et al. 06]和高度场（height fields）[Oliveira et al. 00, Policarpo et al. 05]。

第二个思路是静态和动态对象的分离。经典的距离替代物（distance impostors）技术可以用于静态环境，只需要在每一帧中更新移动对象的环境替代物（environment impostors）。通过搜索几何替代物（geometry impostors）可以找到穿过移动物体的光路。

![](media/2a4baca9e5522da6a9d761020fb81283.png)

图（a）环境距离替代物技术（environment distance impostor）（b）具有搜索投影前两步策略的物体距离替代物（Object distance impostor）

![](media/b28e980933f49e44b1d66882beea987f.jpg)
图 左：整个测试场景。 右：使用高度图替代物进行双折射。

这章中扩展了先前基于环境距离替代物技术（environment distance impostors）的近似光线追踪技术，以便在当时硬件条件的限制下，实时渲染具有多个反射和折射物体的场景。

当然，随着技术的发展，2018年已经有了RTX技术，实时光线追踪已经不在话下。以下便是一个能展现实时光线追踪魅力的NVIDIA RTX Demo：

<https://www.youtube.com/watch?v=KJRZTkttgLw>


<br>

# Part IV. 图像空间 Image Space 


## 十二、 GPU上的各项异性的Kuwahara滤波 | Anisotropic Kuwahara Filtering on the GPU


这章中介绍一种各向异性的Kuwahara滤波器[Kyprianidis et al. 09]。各向异性的Kuwahara滤波器是Kuwahara滤波器的一种广义上的变体，通过调整滤波器的形状，比例和方向以适应输入的局部结构，从而避免了失真。由于这种适应性，定向图像特征被更好地保存和强调，得到了整体更清晰的边缘和更具特色的绘画效果。

![](media/fccbcccfbcbc250aa592f1fe9a61c395.png)

图 原始图像（左），对各向异性的Kuwahara滤波输出（右）。沿着局部特征方向产生绘画般的增强效果，同时保留形状边界。

### 12.1 Kuwahara滤波器（Kuwahara Filtering）

Kuwahara滤波器背后的一般思想是将滤波器内核分成四个重叠一个像素的矩形子区域。滤波器的响应由具有最小方差的子区域的平均值来定义。

![](media/7de17304312d5c3977eaeb3bc01054de.png)

图 Kuwahara滤波器将滤波器内核分成四个矩形子区域。然后过滤器响应由具有最小方差的子区域的平均值来定义

![](media/089fbc7afe80d3d50f9be009e77f1912.png)

图 Kuwahara滤波器的输出效果图


### 12.2 广义Kuwahara滤波器（Generalized Kuwahara Filtering）

而广义Kuwahara滤波器，为了克服不稳定次区域选择过程的局限性，定义了一个新的标准。结果被定义为次区域平均值的加权总和，而不是选择一个单独的次区域。权重是根据子区域的差异来定义的。 这导致区域边界更平滑并且失真更少。为了进一步改善这一点，矩形子区域被扇区上的平滑权重函数所取代：

![](media/fba981a4c3dcfa4ef47d8b70838ed4a6.png)

图 广义的Kuwahara滤波器使用定义在光盘扇区上的加权函数。滤波过滤器响应被定义为局部平均值的加权总和，其中对具有低标准偏差的那些平均值赋予更多的权重。

![](media/c266aa1040c5202e07fe01e096ed5554.png)

图 广义Kuwahara滤波器的输出效果图



### 12.3 各向异性Kuwahara滤波器（Anisotropic Kuwahara Filtering）

广义的Kuwahara滤波器未能捕获定向特征并会导致集群的失真。而各向异性的Kuwahara滤波器通过使滤波器适应输入的局部结构来解决这些问题。在均匀区域中，滤波器的形状应该是一个圆形，而在各向异性区域中，滤波器应该变成一个椭圆形，其长轴与图像特征的主方向一致。

![](media/5b62cbc4a5323e108f039da9e93b7071.png)

图 各向异性Kuwahara滤波器图示

## 十三、基于后处理的边缘抗锯齿 | Edge Anti-aliasing by Post-Processing 


抗锯齿是高质量渲染的关键之一。例如，高质量的CG优先考虑抗锯齿的质量，而用于打印和品宣的游戏截图通常会采用人为高水平的超级采样来提高图像质量。

硬件多采样抗锯齿（Multi-Sampled Anti-Aliasing ，MSAA) [Kirkland 99]支持的是实现抗锯齿的标准方法，但是它是实现高质量抗锯齿的一种非常昂贵的方式，并且对抗锯齿与后处理效果提供的帮助甚微。

本章介绍了一种通过选择性像素混合对边缘进行抗锯齿的新方法。其仅需要MSAA所需空间的一小部分，并且与后处理效果相兼容。此抗锯齿方法的执行分为两个阶段。

首先，图像是没有任何多采样（multisampling）方法或超采样（super-sampling）方法的作用下渲染的。作为关于邻近边缘轮廓的近似细小的渲染提示被写出到帧缓冲区。然后应用后处理的pass，该通道使用这些细小的渲染提示来更新边缘像素，以提供抗锯齿。而在延迟效果（deferred effects）之后应用后处理（post-process），表示它们会接收边缘消除锯齿。

这种方法的核心部分为像素着色器提供了一种计算最近轮廓边缘位置的高效方法。这种技术也可以应用于阴影贴图放大，并提供了保持锐利边缘的放大方法。

下图显示了该方法的实际应用。

![](media/ec5d226c6e9667bd12bdf5b84ba06230.jpg)

图 本章中的抗锯齿方法的效果图特写

![](media/f1c42e08dc4acce2e2229d5f5fae40e8.jpg)

图 复杂背景的抗锯齿效果演示。每个放大部分的左侧为4 MSAA的抗锯齿效果。右侧为本章方法（edge-blur render，边缘模糊抗锯齿）



## 十四、基于Floyd-Steinberg半色调的环境映射 | Environment Mapping with Floyd-Steinberg Halftoning


这章中提出了一种使用GPU计算重要性采样的算法。该算法巧妙地应用了经典的半色调技术，可用于加速高质量环境映射照明中的重要性采样步骤。

这章想传达的最重要的信息是半色调（halftoning）算法和重要性采样（importance sampling）是等价的，因此我们可以在重要性采样中使用半色调算法。文中研究了Floyd-Steinberg半色调方法在环境映射中的应用，并得出结论认为，该方法可以比随机抽样更好地对样本进行分配，所以，对的样本计算的积分也会更准确。

![](media/51d1539e3fb64bd68b146b421142f974.png)

图 左图为随机采样加权环境贴图（Sampling weighted environment maps）；右图为弗洛伊德 - 斯坦伯格采样半色调环境映射（Floyd-Steinberg halftoning）

![](media/356f60e324fa8b54011adf4a3065348e.png)

图 光源采样结果。随机采样基于Floyd-Steinberg半色调映射通过方向光源对兔子模型的漫反射和镜面光照。

### 14.1 核心实现Shader代码

在几何着色器中实现的Floyd-Steinberg采样器Shader代码：

    [maxvertexcount (32)]
    void gsSampler ( inout PointStream <float4 > samples ) {
        uint M = 32; float S = 0;
            [loop]for (uint v = 0; v < R.y; v++)
                [loop]for (uint u = 0; u < R.x; u++)
                    S += getImportance(uint2(u, v));
        float threshold = S / 2 / M;
        float4 cRow[RX4 ]={{0,0,0,0},{0 ,0 ,0 ,0},{0 ,0,0,0} ,{0,0,0 ,0}};
        float cPixel = 0, cDiagonal = 0, acc [4];
        [loop]for (uint j = 0; j < R.y; j++) {
            uint kper4 = 0;
            [loop]for (uint k = 0; k < R.x; k += 4) {
            for (uint xi = 0; xi < 4; xi++) {
                float I = getImportance(uint2 (k+xi , j));
                float Ip = I + cRow[kper4 ][xi] + cPixel ;
                if(Ip > threshold) {
                    float3 dir = getSampleDir(uint2 (k+xi , j));
                    samples .Append ( float4 (dir , I / S) );
                    Ip -= threshold * 2;
                }
                acc [xi] = Ip * 0.375 + cDiagonal ;
                cPixel = Ip * 0.375;
                cDiagonal = Ip * 0.25;
            }
            cRow[kper4 ++] = float4 (acc [0], acc [1], acc [2], acc [3]);
        }
        j++; kper4 --;
        [loop]for (int k = R.x -5; k >= 0; k -= 4) {
            for (int xi = 3; xi >= 0; xi--) {
                float I = getImportance(uint2 (k+xi , j));
                float Ip = I + cRow[kper4 ][xi] + cPixel ;
                if(Ip > threshold ) {
                    float3 dir = getSampleDir(uint2 (k+xi , j));
                    samples .Append ( float4 (dir , I / S) );
                    Ip -= threshold * 2;
                }
                acc [xi] = Ip * 0.375 + cDiagonal ;
                cPixel = Ip * 0.375;
                cDiagonal = Ip * 0.25;
            }
            cRow[kper4 --] = float4 (acc [0], acc [1], acc [2], acc [3]);
            }
        }
    }




## 十五、用于粒状遮挡剔除的分层项缓冲 | Hierarchical Item Buffers for Granular Occlusion Culling

剔除（Culling）算法是许多高效的交互式渲染技术的关键，所有剔除算法的共同目标都是从渲染管线的几乎所有阶段减少工作量。

最常用的算法是在应用阶段采用视锥剔除（frustum culling）和视口剔除（portal culling）来排除不可见的几何体，通常按层次数据结构组织。更复杂的算法会在昂贵的前期流程中预计算整个可见集，以实现高效的实时可见性计算。

这章提出了一种直接在GPU上运行的剔除方法，该方法对应用程序完全透明且实现起来非常简单，特别是在下一代硬件和图形API上。文中表明，只需很少的开销，每帧的渲染时间可以显着减少，特别是对于昂贵的着色器或昂贵的渲染技术。该方法特别针对像几何着色器这样的早期着色器阶段，且应用目标是多方面。例如，[Engelhardt and Dachsbacher 09]展示了这种技术的应用，以加速每像素位移映射，但它也为基于可见性的LOD控制和曲面细分着色器中的剔除提供了可能性。

![](media/9c2b071b069eda2e4df844b060909a87.png)

图 分层项缓冲区（Hierarchical Item Buffers）图示（a）确定可见度的实体;（b）光栅化后的项缓冲区（item buffer）;（c）项缓冲区的直方图。实体3没有计算任何内容，因此是不可见的。


## 十六、后期制作中的真实景深 | Realistic Depth of Field in Postproduction


景深（Depth of field，DOF）是一种典型的摄影效果，其结果是根据摄像机与摄像机的距离而产生不同的聚焦区域。

这章中，提出了一种交互式GPU加速的景深实现方案，其扩展了现有方法的能力，具有自动边缘改进和基于物理的参数。散焦效应通常由模糊半径控制，但也可以由物理特性驱动。此技术支持在图像和序列上使用灰度深度图图像和参数，如焦距，f-stop，subject magnitude，相机距离，以及图像的实际深度。

另外，景深实现中额外的边缘质量改进会产生更逼真和可信的图像。而局部邻域混合算法的缺点是二次计算能力，但这其实可以通过GPU进行补偿。

![](media/262723e5a61ca21ab839fbdf6534329d.jpg)

图 景深效果图

![](media/0b0a367098df217262a28c29e9502e28.png)

图 模拟曝光的光圈孔径形状示例


## 十七、实时屏幕空间的云层光照 | Real-Time Screen Space Cloud Lighting

在创造逼真的虚拟环境时，云是一个重要的视觉元素。实时渲染美丽的云可能非常具有挑战性，因为云在保持交互式帧率的同时会呈现出难以计算的多重散射（multiple scattering）。

目前的问题是，大多数游戏都无法承担精确计算物理上正确的云层光照的计算成本。

本章介绍了一种可以实时渲染真实感的云层的非常简单的屏幕空间技术。这种技术已经在PS3上实现，并用于游戏《大航海时代Online》（Uncharted Waters Online）中。这项技术并不关注严格的物理准确性，而是依靠重新创建云层的经验外观。另外需要注意的是，此技术适用于地面场景，玩家可以在地面上观看，并且只能从远处观看云层。

光照是创造美丽和真实感云彩最重要的方面之一。当太阳光穿过云层时，被云层中的粒子吸收，散射和反射。下图展示了一个典型的户外场景。

![](media/9f705cf6b5a91b5fae1b81c1c61603bd.png)

图 一个典型的户外场景。 最靠近太阳的云显示出最大的散射并且看起来最亮

如图所示，从图中所示的视图看云层时，最靠近太阳的云显得最亮。这种现象是由于太阳的光线到达云层的后方，然后通过多次散射，在云的前部（最靠近观察者）重新出现。这一观察结果是这章所介绍技术的关键部分。为了再现这种视觉提示，屏幕空间中的简单点模糊或方向模糊足以模仿通过云层的光散射。

### 17.1 实现方案

这章的云层渲染技术可以分为三个pass执行：

-   首先，渲染云密度（cloud density）为离屏渲染目标（RT），且云密度是可以由艺术家绘制的标量值。

-  其次，对密度贴图（density map）进行模糊处理。

-   最终，使用模糊的密度贴图来渲染具有散射外观的云层。

![](media/7b87efd297e401d47bf14224f0fa0227.png)

图 基于这章技术实现的demo截图

在demo中，云层被渲染为一个统一的网格。 云层纹理在每个通道中包含四个密度纹理。每个通道代表不同的云层，根据第一个通道中的天气在像素着色器中混合。并且也通过滚动纹理坐标UV来实现动画。

总之，这章提出了一种实时渲染的真实感天空的技术。由于云的形状与光源分离，程序化云的生成和程序化动画都可以支持。

需要注意的是，此方法忽略了大气的某些物理特性，以创建更高效的技术。例如，不考虑大气的密度，但这个属性对于创造逼真的日落和日出是必要的。也忽略了进入云层的光的颜色。在日落或日出的场景中，只有靠近太阳的区域应该明亮而鲜艳地点亮。有必要采取更基于物理的方法来模拟太阳和云之间的散射，以获得更自然的结果。

### 17.2 核心实现Shader代码

以下为云层光照像素着色器核心代码;注意，常数为大写。此着色器可以通过适当设置SCALE和OFFSET常量来提供平行线或点的模糊：

    // Pixel shader input
    struct SPSInput 
    {
        float2 vUV : TEXCOORD0 ;
        float3 vWorldDir : TEXCOORD1 ;
        float2 vScreenPos : VPOS;
    };

    // Pixel shader
    float4 main( SPSInput Input ) 
    {
        // compute direction of blur.
        float2 vUVMove = Input .vScreenPos * SCALE + OFFSET ;

        // Scale blur vector considering distance from camera .
        float3 vcDir = normalize ( Input .vWorldDir );
        float fDistance = GetDistanceFromDir( vcDir );
        vUVMove *= UV_SCALE / fDistance ;

        // Limit blur vector length .
        float2 fRatio = abs ( vUVMove / MAX_LENGTH );
        float fMaxLen = max ( fRatio .x, fRatio .y );
        vUVMove *= fMaxLen > 1.0 f ? 1.0 f / fMaxLen : 1.0 f;

        // Compute offset for weight .
        // FALLOFF must be negative so that far pixels affect less.
        float fExpScale = dot ( vUVMove , vUVMove ) * FALLOFF ;

        // Blur density toward the light.
        float fShadow = tex2D ( sDensity , Input.vUV ).a;
        float fWeightSum = 1.0 f;
        for ( int i = 1; i < FILTER_RADIUS; ++i ) {
        float fWeight = exp ( fExpScale * i );
        fShadow +=
        fWeight * tex2D(sDensity , Input .vUV +vUVMove *i).a;
        fWeightSum += fWeight ;
        }
        fShadow /= fWeightSum ;

        // 0 means no shadow and 1 means all shadowed pixel .
        return fShadow ;
    }

<br>


## 十八、屏幕空间次表面散射 | Screen-Space Subsurface Scattering

这章提出了一种能够以后处理的方式，将渲染帧的深度-模板和颜色缓冲区作为输入，来模拟屏幕空间中的次表面散射的算法。此算法开创了皮肤渲染领域的基于屏幕空间的新流派。其具有非常简单的实现，在性能，通用性和质量之间取得了很好的平衡。

![](media/b3fed4591cc69b98184b1b5f8b0a4104.jpg)

图 在纹理空间中执行模糊处理，如当前的实时次表面散射算法（上图）所做的那样，直接在屏幕空间完成模糊（下图）

该算法转换了从纹理到屏幕空间的扩散近似的计算思路。主要思想并不是计算辐照度图并将其与扩散剖面进行卷积，而是将卷积直接应用于最终渲染图像。下显示了此算法的核心思想。

![](media/30099c1363ddb9474a7d78f54bd25ac3.png)

图 屏幕空间次表面散射流程图

需要注意的是，要在屏幕空间中执行此工作，需要输入渲染该帧的深度模板和颜色缓冲区。

![](media/8b3a9dd264b68e76d4d9421a8b83a214.png)

图 屏幕空间次表面散射示例。与纹理空间方法不同，屏幕空间的方法可以很好地适应场景中的对象数量（上图）。在不考虑次表面散射的情况下进行渲染会导致石头般的外观（左下图）;次表面散射技术用于创建更柔和的外观，更能好地代表次表面散射效果（右下图）。

本章提出的次表面散射算法当物体处于中等距离时，提供了与Hable等人的方法[Hable et al.09]类似的性能，并且随着物体数量的增加能更好地胜任工作。且此方法更好地推广到其他材质。在特写镜头中，其确实需要用一些性能去换取更好的质量，但它能够保持原来d'Eon方法的肉感（fleshiness）[d’Eon and Luebke 07]。但是，在这些特写镜头中，玩家很可能会密切关注角色的脸部，因此值得花费额外的资源来为角色的皮肤提供更好的渲染质量。

### 18.1 核心实现Shader代码

进行水平高斯模糊的像素着色器代码：

    float width ;
    float sssLevel , correction , maxdd;
    float2 pixelSize ;
    Texture2D colorTex , depthTex ;

    float4 BlurPS (PassV2P input) : SV_TARGET {
        float w[7] = { 0.006 , 0.061 , 0.242 , 0.382 ,
        0.242 , 0.061 , 0.006 };

        float depth = depthTex .Sample (PointSampler ,
        input .texcoord ).r;
        float2 s_x = sssLevel / (depth + correction *
        min (abs (ddx (depth )), maxdd ));
        float2 finalWidth = s_x * width * pixelSize *
        float2 (1.0, 0.0);
        float2 offset = input .texcoord - finalWidth ;
        float4 color = float4 (0.0, 0.0, 0.0, 1.0);

        for (int i = 0; i < 7; i++) {
            float3 tap = colorTex .Sample (LinearSampler , offset ).rgb ;
            color .rgb += w[i] * tap ;
            offset += finalWidth / 3.0;
        }

        return color ;
    }


<br>

# Part V. 阴影 Shadows 


阴影方面，作为次核心章节，仅进行更精炼的小篇幅的总结。

<br>

## 十九、快速传统阴影滤波 | Fast Conventional Shadow Filtering


这章介绍了如何减少常规阴影贴图过滤的硬件加速百分比邻近过滤（percentage closer filtering，PCF）纹理操作次数。现在只需要16次PCF操作就可以执行通常使用49次PCF纹理操作进行的均匀8×8过滤器。由于纹理操作的数量通常是传统阴影滤波的限制因素，因此实现的加速效果比较显著。PS:文中附带了大量的shader实现源码。

![](media/64b005316a6260bb9fa241d2072b75a1.jpg)
图 效果截图


<br>

## 二十、混合最小/最大基于平面的阴影贴图 | Hybrid Min/Max Plane-Based Shadow Maps


这章介绍了如何从常规的深度阴影贴图（depth-only shadow map）导出二次贴图。这种二次纹理可以用来大大加快昂贵的阴影滤波与过大的过滤器性能占用。它以原始阴影图中二维像素块的平面方程或最小/最大深度的形式存储混合数据。,被称为混合最小/最大平面阴影贴图（hybrid min/max plane shadow map，HPSM）。该技术特别适用于在大型过滤区域和前向渲染的情况下加速阴影过滤，例如，当阴影过滤成本随着场景的深度复杂度而增加时。

![](media/47c584f6c0b089d7c64be5ce26f2fa93.jpg)

图 一个最小/最大阴影贴图像素（即有噪声的四边形）可以映射到许多屏幕上的像素。

<br>


## 二十一、基于四面体映射实现全向光阴影映射 | Shadow Mapping for Omnidirectional Light Using Tetrahedron Mapping


阴影映射（Shadow mapping）是用于三维场景渲染阴影的一种常用方法。William的原始Z-缓冲器阴影映射算法〔[Williams 78]是用于方向光源的，需要一种不同的方法来实现全向光（Omnidirectional Light）的阴影。

有两种流行的方法来接近全向光：一个是立方体映射（cube mapping ）[Voorhies and Foran 94]和另一个是双抛物面映射（dual-paraboloid mapping）[Heidrich and Seidel 98]。而在本章中，提出了一种全新的使用四面体映射（tetrahedron mapping）的全向光阴影映射技术。

![](media/35e8f5273e7fd46cb0231a8a238a73f6.jpg)

图 四个点光源，并使用四面体阴影映射与模板缓冲和硬件阴影映射得到渲染效果。二维深度纹理尺寸为1024×1024


<br>

## 二十二、屏幕空间软阴影 | Screen Space Soft Shadows 


这章中提出了一种基于阴影映射的半影（penumbrae）实时阴影渲染的新技术。该方法使用了包含阴影与其潜在遮挡物之间距离的屏幕对齐纹理，其用于设置在屏幕空间中应用的各向异性高斯滤波器内核的大小，从而平滑标准阴影创建半影（penumbra）。考虑到高斯滤波器是可分离的，创建半影的样本数量会远低于其他软阴影方法。因此，该方法获得了更高的性能，同时也能得到外观正确的半影。

![](media/e60c1736e7712e99c5bc75c52c3f2848.jpg)

图 不同光源尺寸和不同光源颜色的半影的示例


<br>



The End.

下次更新，《GPU Pro 2》全书核心内容提炼总结，再见。

With best wishes.

```

`Content/《GPU 编程与CG 语言之阳春白雪下里巴人》读书笔记/01-第一章-绪论/README.md`:

```md
第一章 绪论
===========

1.1 Programmable Graphics Processing Unit 发展历程
--------------------------------------------------

Programmable Graphics Processing Unit（ GPU），即可编程图形处理单元，

通常也称之为可编程图形硬件。

GPU的发展历史
-------------

GPU 概念在 20 世纪 70 年代末和 80 年代初被提出，使用单片集成电路（
monolithic）作为图形芯片，此时的 GPU
已经被用于视频游戏和动画方面，它能够很快地进行几张图片的合成（仅限于此）。

-   在20 世纪 80 年代末到 90 年代 ，基于数字信号处理芯片（digital signal
    processor chip）的 GPU 被
    研发出来，与前代相比速度更快、功能更强，当然价格非常昂贵。

-   1991 年，S3 Graphics 公司研制出第一个单芯片 2D 加速器。

-   1995 年，主流的 PC 图形芯片厂商都在自己的芯片上增加了对 2D 加速器的支持。

-   1998 年 NVIDIA 公司宣布 modern GPU 的研发成功，标志着 GPU 研发的历
    史性突破成为现实。

GPU发展的两个时期
-----------------

通常将 20 世纪 70 年代末到 1998 年的这一段时间称之为pre-GPU 时期，而自 1998
年往后的 GPU 称之为 modern GPU。

-   在 pre-GPU 时期， 一些图形厂商，如 SGI、Evans & Sutherland，都研发了各自的
    GPU，这些 GPU
    在现在并没有被淘汰，依然在持续改进和被广泛的使用，当然价格也是非常的高 昂。

-   而modern GPU 使用晶体管（transistors）进行计算，在微芯片（microchip）中，
    GPU 所使用的晶体管已经远远超过 CPU。

Modern GPU时期的四个阶段
------------------------

回顾 Modern GPU 的发展历史，自 1998 年后可以分为 4 个阶段。

1.  NVIDIA 于 1998 年宣布 Modern GPU 研发成功，这标志着第一代 Modern GPU
    的诞生， 第一代 Modern GPU 包括 NVIDIA TNT2，ATI 的 Rage 和 3Dfx 的
    Voodoo3。这 些 GPU 可以独立于 CPU
    进行像素缓存区的更新，并可以光栅化三角面片以及进
    行纹理操作，但是缺乏三维顶点的空间坐标变换能力，这意味着“必须依赖于 GPU
    执行顶点坐标变换的计算”。这一时期的 GPU 功能非常有限，只能用于纹理组合
    的数学计算或者像素颜色值的计算。

2.  从 1999 到 2000 年，是第二代 modern GPU 的发展时期。这一时期的 GPU
    可以进行三维坐标转换和光照计算（3D Object Transformation and Lighting,
    T&L），并且 OpenGL 和 DirectX7 都提供了开发接口，支持应用程序使用基于
    硬件的坐标变换。这是一个非常重要的时期，在此之前只有高级工作站（workstation）的图形硬件才支持快速的顶点变换。同时，这一阶段的
    GPU 对 于纹理的操作也扩展到了立方体纹理（cube map）。NVIDIA 的 GeForce256，
    GeForce MAX，ATI 的 Radeon 7500 等都是在这一阶段研发的。

3.  2001 年是第三代 modern GPU 的发展时期，这一时期研发的 GPU 提供 vertex
    programmability（顶点编程能力），如 GeForce 3，GeForce 4Ti，ATI 的 8500 等。
    这些 GPU 允许应用程序指定一个序列的指令进行顶点操作控制（GPU 编程的本
    质！），这同样是一个具有开创意义的时期，这一时期确立的 GPU 编程思想一
    直延续到 2009 年的今天，不但深入到工程领域帮助改善人类日常生活（医疗、
    地质勘探、游戏、电影等），而且开创或延伸了计算机科学的诸多研究领域 （体
    绘制、光照模拟、人群动画、通用计算等）。同时，Direct8 和 OpenGL 都本着
    与时俱进的精神，提供了支持 vertex programmability 的扩展。不过，这一时期的
    GPU 还不支持像素级的编程能力，即 fragment programmability（片段编程能力），
    在第四代 modern GPU 时期，我们将迎来同时支持 vertex programmability 和
    fragment programmability 的 GPU。

4.  第四代 modern GPU 的发展时期从 2002 年末到 2003 年。NVIDIA 的 GeForce FX 和
    ATI Radeon 9700 同时在市场的舞台上闪亮登场，这两种 GPU 都支持 verte x
    programmability 和 fragment programmability。同时 DirectX 和
    OpenGL也扩展了自身的 API，用以支持 vertex programmability 和 fragment
    programmability。自 2003 年起，可编程图形硬件正式诞生，并且由于 DirectX 和
    OpenGL 锲而不舍的追赶潮流，致使 基于图形硬件的编程技术简称 GPU
    编程，也宣告诞生。

![](media/3318ab8b7b2ace6b50a7e925bd9816cc.png)

图1

```

`Content/《GPU 编程与CG 语言之阳春白雪下里巴人》读书笔记/README.md`:

```md
# 《GPU 编程与CG 语言之阳春白雪下里巴人》读书笔记

这是一篇很有意思的著作。GPU 编程与Shader、CG编程的入门良书。

# 目录

- [01-第一章-绪论](https://github.com/QianMo/Game-Programmer-Study-Notes/tree/master/Content/%E3%80%8AGPU%20%E7%BC%96%E7%A8%8B%E4%B8%8ECG%20%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%98%B3%E6%98%A5%E7%99%BD%E9%9B%AA%E4%B8%8B%E9%87%8C%E5%B7%B4%E4%BA%BA%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/01-%E7%AC%AC%E4%B8%80%E7%AB%A0-%E7%BB%AA%E8%AE%BA)

```

`Content/《Real-Time Rendering 3rd》知识网络图谱/README.md`:

```md
# 《《Real-Time Rendering 3rd》知识网络图谱

考虑到图片过大，建议放大网页后查看，或另存为本地图片后放大查看。

![](Real-Time-Rendering-3rd-Knowledge-Diagram.jpg)








```

`Content/《Real-Time Rendering 3rd》读书笔记/Content/BlogPost01/README.md`:

```md
![](media/title.jpg)


【《Real-Time Rendering 3rd》 提炼总结】 (一) 全书知识点总览
====================

<br />

一、《Real-Time Rendering 3rd》其书
-----------------------------------

在实时渲染和计算机图形学领域，《Real-Time Rendering
3rd》这本书一直备受推崇。有人说，它实时渲染的圣经。也有人说，它是绝世武功的目录。

诚然，《Real-Time Rendering
3rd》这本书的世界观架构宏大，基本涵盖了计算机图形学的方方面面，可谓包罗万象。概念讲得清楚明了，有丰富的论文引用，可供作为工具书查阅，深入某细分领域继续学习使用。

![](media/1.jpg)

当然，如果我们吹毛求疵，那么也可以说，正因这本书包罗万象，由于篇幅受限，就会拥有一个缺点，就是大而不精。由于篇幅，很多知识点到为止，无法展开讲解，缺少更多范例，这就会让初学者读起来理解坡度稍为陡峭。但我们知道，图形学和实时渲染领域的知识浩如烟海，就算是写个字典式的总览，这本书的篇幅也已经达到了惊人的1047页，要是再写详细一些，估计至少得3000页了。

总之，《Real-Time Rendering
3rd》这本书，可谓图形学界“九阴真经总纲”一般的存在，当世武功的心法口诀，尽数记载。它涵盖了计算机图形和实时渲染的方方面面，可做论文综述合集了解全貌，也可作案头工具书日后查用。
<br />
<br />

二、相关背景
------------

《Real-Time Rendering
3rd》出版于2008年，至今已经9年之久，但丝毫不能减弱它作为实时渲染界泰斗之作的重量。

另外，《Real-Time Rendering
4th》的出版遥遥无期，据了解，作者目前似乎没有出第四版的计划。

这本书第三版目前没有中译版，只有第二版（英文原版出版于2002年）的中译版。网络上有一些第三版的翻译，但大多翻译到第四章后就没有下文。
<br />
<br />

三、《Real-Time Rendering 3rd》全书知识点总览
---------------------------------------------

上文已经说到，《Real-Time Rendering
3rd》这本书，可谓图形学界“九阴真经总纲”一般的存在，当世武功的心法口诀，尽数记载。

而当我画完这张思维导图的时候，仔细看了看，还真有点“九阴真经总纲”图解的感觉。（建议另存为后放大查看）

![](media/2.png)

<br />
<br />

四、包含宝藏的书本主页
----------------------

当然不能忘记书本主页，里面有一大堆图形学和渲染的书籍推荐，也有不少丰富的博文与资源。相信喜欢图形学和实时渲染的你，一定会爱不释手的。

地址在这里：[Real-Time Rendering
Resources](http://www.realtimerendering.com/)

![](media/3.png)



<br />
<br />
<br />
```

`Content/《Real-Time Rendering 3rd》读书笔记/Content/BlogPost02/README.md`:

```md


![](media/title.jpg)

【《Real-Time Rendering 3rd》 提炼总结】(二) 第二章 · 图形渲染管线 The Graphics Rendering Pipeline
==========================================================

<br />

这篇文章是提炼总结计算机图形学界“九阴真经总纲”一般存在的《Real-Time Rendering
3rd》系列文章的第二篇。将带来RTR3第二章内容“Chapter 2 The Graphics Rendering
Pipeline 图形渲染管线”的总结、概括与提炼。

文章分为全文内容思维导图、核心内容分章节提炼、本章内容提炼总结三个部分来呈现，其中：

-   文章的第一部分，“全文内容思维导图”，分为“章节框架思维导图”和“知识结构思维导图”两个部分。

-   文章的第二部分，“核心内容分节提炼”，是按原书章节顺序分布的知识梳理。

-   而文章的第三部分“本章内容提炼总结”，则是更加精炼，只提炼出关键信息的知识总结。

一、全文内容思维导图
--------------------

<br />

### 1.章节框架思维导图

![](media/0.png)

### 2.知识结构思维导图

![](media/1.png)

<br />
<br />


二、核心内容分节提炼
--------------------

<br />


### 2.1 图像渲染管线架构概述 Architecture

<br />


渲染管线的主要功能就是决定在给定虚拟相机、三维物体、光源、照明模式，以及纹理等诸多条件的情况下，生成或绘制一幅二维图像的过程。对于实时渲染来说，渲染管线就是基础。因此，我们可以说，渲染管线是实时渲染的底层工具。

图2.1展示了使用渲染管线步骤。渲染出的图像的位置、形状是由它们的几何形状，环境特性，摄像机位置决定的。而物体的外观由材质特性，光源，纹理和着色模型确定。

![](media/2.png)

原书图2.1
左图中，相机放在棱椎的顶端（四条线段的交汇点），只有可视体内部的图元会被渲染。

在概念上可以将图形渲染管线分为三个阶段：

-   应用程序阶段（The Application Stage）

-   几何阶段（The Geometry Stage）

-   光栅化阶段（The Rasterizer Stage）

如下图：

![](media/3.png)

原书图2.2 绘制管线的基本结构包括3个阶段：应用程序、几何、光栅化。

几个要点：

-   每个阶段本身也可能是一条管线，如图中的几何阶段所示。此外，还可以对有的阶段进行全部或者部分的并行化处理，如图中的光栅化阶段。应用程序阶段虽然是一个单独的过程，但是依然可以对之进行管线化或者并行化处理。

-   最慢的管线阶段决定绘制速度，即图像的更新速度，这种速度一般用FPS来表示，也就是每秒绘制的图像数量，或者用Hz来表示。

<br />


### 2.2 应用程序阶段 The Application Stage

<br />

-   应用程序阶段一般是图形渲染管线概念上的第一个阶段。应用程序阶段是通过软件方式来实现的阶段，开发者能够对该阶段发生的情况进行完全控制，可以通过改变实现方法来改变实际性能。其他阶段，他们全部或者部分建立在硬件基础上，因此要改变实现过程会非常困难。

-   正因应用程序阶段是软件方式实现，因此不能像几何和光栅化阶段那样继续分为若干个子阶段。但为了提高性能，该阶段还是可以在几个并行处理器上同时执行。在CPU设计上，称这种形式为超标量体系（superscalar）结构，因为它可以在同一阶段同一时间做不同的几件事情。

-   应用程序阶段通常实现的方法有碰撞检测、加速算法、输入检测，动画，力反馈以及纹理动画，变换仿真、几何变形，以及一些不在其他阶段执行的计算，如层次视锥裁剪等加速算法就可以在这里实现。

-   应用程序阶段的主要任务：在应用程序阶段的末端，将需要在屏幕上（具体形式取决于具体输入设备）显示出来绘制的几何体（也就是绘制图元，rendering
    primitives，如点、线、矩形等）输入到绘制管线的下一个阶段。

-   对于被渲染的每一帧，应用程序阶段将摄像机位置，光照和模型的图元输出到管线的下一个主要阶段——几何阶段。

<br />

### 2.3 几何阶段 The Geometry Stage

<br />

几何阶段主要负责大部分多边形操作和顶点操作。可以将这个阶段进一步划分成如下几个功能阶段：

-   模型视点变换 Model & View Transform

-   顶点着色 Vertex Shading

-   投影 Projection

-   裁剪 Clipping

-   屏幕映射 Screen Mapping

如图2.3所示。

![](media/4.png)

原书图2.3 几何阶段细分为的功能阶段管线

需要注意：

-   根据具体实现，这些阶段可以和管线阶段等同，也可以不等同。在一些情况下，一系列连续的功能阶段可以形成单个管线阶段（和其他管线阶段并行运行）。在另外情况下，一个功能阶段可以划分成其他更细小的管线阶段。

-   几何阶段执行的是计算量非常高的任务，在只有一个光源的情况下，每个顶点大约需要100次左右的精确的浮点运算操作。

<br />

#### 2.3.1 模型和视图变换 Model and View Transform

<br />

-   在屏幕上的显示过程中，模型通常需要变换到若干不同的空间或坐标系中。模型变换的变换对象一般是模型的顶点和法线。物体的坐标称为模型坐标。世界空间是唯一的，所有的模型经过变换后都位于同一个空间中。

-   不难理解，应该仅对相机（或者视点）可以看到的模型进行绘制。而相机在世界空间中有一个位置方向，用来放置和校准相机。

-   为了便于投影和裁剪，必须对相机和所有的模型进行视点变换。变换的目的就是要把相机放在原点，然后进行视点校准，使其朝向Z轴负方向，y轴指向上方,x轴指向右边。在视点变换后，实际位置和方向就依赖于当前的API。我们称上述空间为相机空间或者观察空间。

下图显示了视点变换对相机和模型的影响。

![](media/5.png)

原书图2.4
在左图中，摄像机根据用户指定的位置进行放置和定位。在右图中，视点变换从原点沿着Z轴负方向对相机重新定位，这样可以使裁剪和投影操作更简单、更快速。可视范围是一个平截椎体，因此可以认为它是透视模式。

【总结】模型和视图变换阶段分为模型变换和视图变换。模型变换的目的是将模型变换到适合渲染的空间当中，而视图变换的目的是将摄像机放置于坐标原点，方便后续步骤的操作。

<br />

#### 2.3.2 顶点着色 Vertex Shading

<br />

为了产生逼真的场景，渲染形状和位置是远远不够的，我们需要对物体的外观进行建模。而物体经过建模，会得到对包括每个对象的材质，以及照射在对象上的任何光源的效果在内的一些描述。且光照和材质可以用任意数量的方式，从简单的颜色描述到复杂的物理描述来模拟。

确定材质上的光照效果的这种操作被称为着色（shading），着色过程涉及在对象上的各个点处计算着色方程（shading
equation）。通常，这些计算中的一些在几何阶段期间在模型的顶点上执行（vertex
shading），而其他计算可以在每像素光栅化（per-pixel
rasterization）期间执行。可以在每个顶点处存储各种材料数据，诸如点的位置，法线，颜色或计算着色方程所需的任何其它数字信息。顶点着色的结果（其可以是颜色，向量，纹理坐标或任何其他种类的阴着色数据）计算完成后，会被发送到光栅化阶段以进行插值操作。

通常，着色计算通常认为是在世界空间中进行的。在实践中，有时需要将相关实体（诸如相机和光源）转换到一些其它空间（诸如模型或观察空间）并在那里执行计算，也可以得到正确的结果。

这是因为如果着色过程中所有的实体变换到了相同的空间，着色计算中需要的诸如光源，相机和模型之间的相对关系是不会变的。

【总结】顶点着色阶段的目的在于确定模型上顶点处材质的光照效果。

<br />


#### 2.3.3 投影 Projection

<br />

在光照处理之后，渲染系统就开始进行投影操作，即将视体变换到一个对角顶点分别是(-1,-1,-1)和(1,1,1)单位立方体（unit
cube）内，这个单位立方体通常也被称为规范立方体（Canonical View Volume，CVV）。

目前，主要有两种投影方法，即：

-   正交投影（orthographic projection，或称parallel projection）。

-   透视投影（perspective projection）。

如下图所示。

![](media/6.png)

原书图2.5 左边为正交投影，右边为透视投影

两种投影方式的主要异同点：

-   正交投影。正交投影的可视体通常是一个矩形，正交投影可以把这个视体变换为单位立方体。正交投影的主要特性是平行线在变换之后彼此之间仍然保持平行，这种变换是平移与缩放的组合。

-   透视投影。相比之下，透视投影比正交投影复杂一些。在这种投影中，越远离摄像机的物体，它在投影后看起来越小。更进一步来说，平行线将在地平线处会聚。透视投影的变换其实就是模拟人类感知物体的方式。

-   正交投影和透视投影都可以通过4 x
    4的矩阵来实现，在任何一种变换之后，都可以认为模型位于归一化处理之后的设备坐标系中。

虽然这些矩阵变换是从一个可视体变换到另一个，但它们仍被称为投影，因为在完成显示后，Z坐标将不会再保存于的得到的投影图片中。通过这样的投影方法，就将模型从三维空间投影到了二维的空间中。

【总结】投影阶段就是将模型从三维空间投射到了二维的空间中的过程。

<br />

#### 2.3.4 裁剪 Clipping

<br />

只有当图元完全或部分存在于视体（也就是上文的规范立方体，CVV）内部的时候，才需要将其发送到光栅化阶段，这个阶段可以把这些图元在屏幕上绘制出来。

不难理解，一个图元相对视体内部的位置，分为三种情况：完全位于内部、完全位于外部、部分位于内部。所以就要分情况进行处理：

-   当图元完全位于视体内部，那么它可以直接进行下一个阶段。

-   当图元完全位于视体外部，不会进入下一个阶段，可直接丢弃，因为它们无需进行渲染。

-   当图元部分位于视体内部，则需要对那些部分位于视体内的图元进行裁剪处理。

对部分位于视体内部的图元进行裁剪操作，这就是裁剪过程存在的意义。裁剪过程见下图。

![](media/7.png)

原书图2.6
投影变换后，只对单位立方体内的图元（相应的是视锥内可见图元）继续进行处理，因此，将单位立方体之外的图元剔除掉，保留单位立方体内部的图元，同时沿着单位立方体将与单位立方体相交的图元裁剪掉，因此，就会产生新的图元，同时舍弃旧的图元。

【总结】裁剪阶段的目的，就是对部分位于视体内部的图元进行裁剪操作。

<br />

#### 2.3.5 屏幕映射 Screen Mapping

<br />

只有在视体内部经过裁剪的图元，以及之前完全位于视体内部的图元，才可以进入到屏幕映射阶段。进入到这个阶段时，坐标仍然是三维的（但显示状态在经过投影阶段后已经成了二维），每个图元的x和y坐标变换到了屏幕坐标系中，屏幕坐标系连同z坐标一起称为窗口坐标系。

假定在一个窗口里对场景进行绘制，窗口的最小坐标为（x1，y1），最大坐标为（x2，y2），其中x1\<x2，y1\<y2。屏幕映射首先进行平移，随后进行缩放，在映射过程中z坐标不受影响。新的x和y坐标称为屏幕坐标系，与z坐标一起（-1≦
z ≦ 1）进入光栅化阶段。如下图：

![](media/8.png)

原书图2.8
经过投影变换，图元全部位于单位立方体之内，而屏幕映射主要目的就是找到屏幕上对应的坐标

屏幕映射阶段的一个常见困惑是整型和浮点型的点值如何与像素坐标（或纹理坐标）进行关联。可以使用Heckbert[书后参考文献第520篇]的策略，用一个转换公式进行解决。

【总结】屏幕映射阶段的主要目的，就是将之前步骤得到的坐标映射到对应的屏幕坐标系上。

<br />

### 2.4 光栅化阶段 The Rasterizer Stage

<br />

给定经过变换和投影之后的顶点，颜色以及纹理坐标（均来自于几何阶段），给每个像素（Pixel）正确配色，以便正确绘制整幅图像。这个过个过程叫光栅化（rasterization）或扫描变换（scan
conversion），即从二维顶点所处的屏幕空间（所有顶点都包含Z值即深度值，及各种与相关的着色信息）到屏幕上的像素的转换。

与几何阶段相似，该阶段细分为几个功能阶段：

-   三角形设定（Triangle Setup）阶段

-   三角形遍历（Triangle Traversal）阶段

-   像素着色（Pixel Shading）阶段

-   融合（Merging）阶段

如下图所示:

![](media/9.png)

原书图2.8 光栅化阶段一般细分为三角形设定，三角形遍历，像素着色和融合四个子阶段。

<br />

#### 2.4.1 三角形设定 Triangle Setup

<br />

三角形设定阶段主要用来计算三角形表面的差异和三角形表面的其他相关数据。该数据主要用于扫描转换（scan
conversion），以及由几何阶段处理的各种着色数据的插值操作所用。
该过程在专门为其设计的硬件上执行。

<br />

#### 2.4.2 三角形遍历 Triangle Traversal

<br />

在三角形遍历阶段将进行逐像素检查操作，检查该像素处的像素中心是否由三角形覆盖，而对于有三角形部分重合的像素，将在其重合部分生成片段（fragment）。

找到哪些采样点或像素在三角形中的过程通常叫三角形遍历（TriangleTraversal）或扫描转换（scan
conversion）。每个三角形片段的属性均由三个三角形顶点的数据插值而生成（在第五章会有讲解）。这些属性包括片段的深度，以及来自几何阶段的着色数据。

【总结】找到哪些采样点或像素在三角形中的过程通常叫三角形遍历（TriangleTraversal）或扫描转换（scan
conversion）。

<br />

#### 2.4.3 像素着色 Pixel Shading

<br />

所有逐像素的着色计算都在像素着色阶段进行，使用插值得来的着色数据作为输入，输出结果为一种或多种将被传送到下一阶段的颜色信息。纹理贴图操作就是在这阶段进行的。

像素着色阶段是在可编程GPU内执行的，在这一阶段有大量的技术可以使用，其中最常见，最重要的技术之一就是纹理贴图（Texturing）。纹理贴图在书的第六章会详细讲到。简单来说，纹理贴图就是将指定图片“贴”到指定物体上的过程。而指定的图片可以是一维，二维，或者三维的，其中，自然是二维图片最为常见。如下图所示：

![](media/10.png)

原书图2.9
左上角为一没有纹理贴图的飞龙模型。左下角为一贴上图像纹理的飞龙。右图为所用的纹理贴图。

【总结】像素着色阶段的主要目的是计算所有需逐像素操作的过程。

<br />

#### 2.4.4 融合 Merging

<br />

每个像素的信息都储存在颜色缓冲器中，而颜色缓冲器是一个颜色的矩阵列（每种颜色包含红、绿、蓝三个分量）。融合阶段的主要任务是合成当前储存于缓冲器中的由之前的像素着色阶段产生的片段颜色。不像其它着色阶段，通常运行该阶段的GPU子单元并非完全可编程的，但其高度可配置，可支持多种特效。

此外，这个阶段还负责可见性问题的处理。这意味着当绘制完整场景的时候，颜色缓冲器中应该还包含从相机视点处可以观察到的场景图元。对于大多数图形硬件来说，这个过程是通过Z缓冲（也称深度缓冲器）算法来实现的。Z缓冲算法非常简单，具有O(n)复杂度（n是需要绘制的像素数量），只要对每个图元计算出相应的像素z值，就可以使用这种方法，大概内容是：

Z缓冲器器和颜色缓冲器形状大小一样，每个像素都存储着一个z值，这个z值是从相机到最近图元之间的距离。每次将一个图元绘制为相应像素时，需要计算像素位置处图元的z值，并与同一像素处的z缓冲器内容进行比较。如果新计算出的z值，远远小于z缓冲器中的z值，那么说明即将绘制的图元与相机的距离比原来距离相机最近的图元还要近。这样，像素的z值和颜色就由当前图元对应的值和颜色进行更新。反之，若计算出的z值远远大于z缓冲器中的z值，那么z缓冲器和颜色缓冲器中的值就无需改变。

上面刚说到，颜色缓冲器用来存储颜色，z缓冲器用来存储每个像素的z值，还有其他缓冲器可以用来过滤和捕获片段信息。

-   比如alpha通道（alpha
    channel）和颜色缓冲器联系在一起可以存储一个与每个像素相关的不透明值。可选的alpha测试可在深度测试执行前在传入片段上运行。片段的alpha值与参考值作某些特定的测试（如等于，大于等），如果片断未能通过测试，它将不再进行进一步的处理。alpha测试经常用于不影响深度缓存的全透明片段（见6.6节）的处理。

-   模板缓冲器（stencil
    buffer）是用于记录所呈现图元位置的离屏缓存。每个像素通常与占用8个位。图元可使用各种方法渲染到模板缓冲器中，而缓冲器中的内容可以控制颜色缓存和Z缓存的渲染。举个例子，假设在模版缓冲器中绘制出了一个实心圆形，那么可以使用一系列操作符来将后续的图元仅在圆形所出现的像素处绘制，类似一个mask的操作。模板缓冲器是制作特效的强大工具。而在管线末端的所有这些功能都叫做光栅操作（raster
    operations ，ROP）或混合操作（blend operations）。

-   帧缓冲器（frame
    buffer）通常包含一个系统所具有的所有缓冲器，但有时也可以认为是颜色缓冲器和z缓冲器的组合。

-   累计缓冲器（accumulation
    buffer），是1990年，Haeberli和Akeley提出的一种缓冲器，是对帧缓冲器的补充。这个缓冲器可以用一组操作符对图像进行累积。例如，为了产生运动模糊（motion
    blur.，可以对一系列物体运动的图像进行累积和平均。此外，其他的一些可产生的效果包括景深（e
    depth of field），反走样（antialiasing）和软阴影（soft shadows）等。

而当图元通过光栅化阶段之后，从相机视点处看到的东西就可以在荧幕上显示出来。为了避免观察者体验到对图元进行处理并发送到屏幕的过程，图形系统一般使用了双缓冲（double
buffering）机制，这意味着屏幕绘制是在一个后置缓冲器（backbuffer）中以离屏的方式进行的。一旦屏幕已在后置缓冲器中绘制，后置缓冲器中的内容就不断与已经在屏幕上显示过的前置缓冲器中的内容进行交换。注意，只有当不影响显示的时候，才进行交换。

【总结】融合阶段的主要任务是合成当前储存于缓冲器中的由之前的像素着色阶段产生的片段颜色。此外，融合阶段还负责可见性问题（Z缓冲相关）的处理。

<br />

### 2.5 管线纵览与总结

<br />

在概念上可以将图形渲染管线分为三个阶段：应用程序阶段、几何阶段、光栅化阶段。

这样的管线结构是API和图形硬件十年来以实时渲染应用程序为目标进行演化的结果。需要注意的是这个进化不仅仅是在我们所说的渲染管线中，离线渲染管线（offline
rendering
pipelines）也是另一种进化的路径。且电影产品的渲染通常使用微多边形管线（micropolygon
pipelines）。而学术研究和预测渲染的（predictive
rendering）应用，比如建筑重建（architectural
previsualization）通常采用的是光线跟踪渲染器（ray tracing renderers）

<br />
<br />

三、本章内容提炼总结
--------------------

<br />

以下是对《Real Time Rendering 3rd》第二章“图形渲染管线”内容的文字版概括总结：

图形渲染管线的主要功能就是决定在给定虚拟相机、三维物体、光源、照明模式，以及纹理等诸多条件的情况下，生成或绘制一幅二维图像的过程。在概念上可以将图形渲染管线分为三个阶段：应用程序阶段、几何阶段、光栅化阶段。
<br />

### 1、应用程序阶段

<br />

应用程序阶段的主要任务，是将需要绘制图元输入到绘制管线的下一个阶段，以及实现一些软件方式来实现的方法。主要方法有碰撞检测、加速算法、输入检测，动画，力反馈以及纹理动画，变换仿真、几何变形，以及一些不在其他阶段执行的计算，如层次视锥裁剪等加速算法。

对于被渲染的每一帧，应用程序阶段将摄像机位置，光照和模型的图元输出到管线的下一个主要阶段，即几何阶段。

<br />

### 2、几何阶段

<br />

几何阶段主要负责大部分多边形操作和顶点操作，可以将这个阶段进一步划分成如下几个功能阶段：模型视点变换、顶点着色、投影、裁剪、屏幕映射。这些功能阶段的主要功能如下：

-   【模型和视图变换阶段】：模型变换的目的是将模型变换到适合渲染的空间当中，而视图变换的目的是将摄像机放置于坐标原点，方便后续步骤的操作。

-   【顶点着色阶段】：顶点着色的目的在于确定模型上顶点处材质的光照效果。

-   【投影阶段】：投影阶段就是将模型从三维空间投射到了二维的空间中的一个过程。投影阶段也可以理解为将视体变换到一个对角顶点分别是(-1,-1,-1)和(1,1,1)单位立方体内的过程
    。

-   【裁剪阶段】裁剪阶段的目的，就是对部分位于视体内部的图元进行裁剪操作。

-   【屏幕映射阶段】屏幕映射阶段的主要目的，就是将之前步骤得到的坐标映射到对应的屏幕坐标系上。

在几何阶段，首先，对模型的顶点和法线进行矩阵变换，并将模型置于观察空间中（模型和视图变换），然后，根据材质、纹理、以及光源属性进行顶点光照的计算（顶点着色阶段），接着，将该模型投影变换到一个单位立方体内，并舍弃所有立方体之外的图元（投影阶段），而为了得到所有位于立方体内部的图元，接下来对与单位立方体相交的图元进行裁剪（裁剪阶段），然后将顶点映射到屏幕上的窗口中（屏幕映射阶段）。在对每个多边形执行完这些操作后，将最终数据传递到光栅，这样就来到了管线中的最后一个阶段，光栅化阶段。
<br />

### 3、光栅化阶段

<br />

给定经过变换和投影之后的顶点，颜色以及纹理坐标（均来自于几何阶段），给每个像素正确配色，以便正确绘制整幅图像。这个过个过程叫光栅化，即从二维顶点所处的屏幕空间（所有顶点都包含Z值即深度值，及各种与相关的着色信息）到屏幕上的像素的转换。光栅化阶段可分为三角形设定阶段、三角形遍历阶段、像素着色阶段、融合阶段。这些功能阶段的主要功能如下：

-   【三角形设定阶段】三角形设定阶段主要用来计算三角形表面的差异和三角形表面的其他相关数据。

-   【三角形遍历阶段】找到哪些采样点或像素在三角形中的过程通常叫三角形遍历。

-   【像素着色阶段】像素着色阶段的主要目的是计算所有需逐像素计算操作的过程。

-   【融合阶段】融合阶段的主要任务是合成当前储存于缓冲器中的由之前的像素着色阶段产生的片段颜色。此外，融合阶段还负责可见性问题（Z缓冲相关）的处理。

在光栅化阶段，所有图元会被光栅化，进而转换为屏幕上的像素。首先，计算三角形表面的差异和三角形表面的其他相关数据（三角形设定阶段），然后，找到哪些采样点或像素在三角形中（三角形遍历阶段），接着计算所有需逐像素计算操作（像素着色阶段），然后，合成当前储存于缓冲器中的由之前的像素着色阶段产生的片段颜色，可见性问题可通过Z缓存算法解决，随同的还有可选的alpha测试和模版测试（融合阶段）。所有对像依次处理，而最后的图像显示在屏幕上。

```

`Content/《Real-Time Rendering 3rd》读书笔记/Content/BlogPost03/README.md`:

```md
![](media/title.jpg)
# 【《Real-Time Rendering 3rd》 提炼总结】(三) 第三章 · GPU渲染管线与可编程着色器 #


<br />
这篇文章是解析计算机图形学界“九阴真经总纲”一般存在的《Real-Time Rendering
3rd》系列文章的第三篇。将带来RTR3第三章内容“Chapter 3 The Graphics Processing
Unit 图形处理器”的总结、概括与提炼。

这章的主要内容是介绍GPU渲染管线的组成，以及可编程着色的进化史，顶点、几何、像素三种可编程着色器。

本文总字数7.3k，分为全文内容图示、原书核心内容分章节提炼、本章内容提炼总结三个部分来呈现。

<br />

# 一、全文内容图示

<br />

## 1.章节框架图示

![](media/1.jpg)


## 2. GPU渲染管线流程图

![](media/2.jpg)

其中：

-   绿色的阶段都是完全可编程的。

-   黄色的阶段可配置，但不可编程。

-   蓝色的阶段完全固定。

<br />


# 二、原书核心内容分节提炼


<br />


## 3.1 GPU管线概述

<br />

-   第一个包含顶点处理，面向消费者的图形芯片（NVIDIA GeForce256）发布于1999年，且NVIDIA提出了图形处理单元（Graphics Processing Unit，GPU）这一术语，将GeForce256和之前的只能进行光栅化处理的图形芯片相区分。在接下来的几年中，GPU从可配置的固定功能管线演变到了支持高度可编程的管线。直到如今，各种可编程着色器依然是控制GPU的主要手段。为了提高效率，GPU管线的一部分仍然保持着可配置，但不是可编程的，但大趋势依然是朝着可编程和更具灵活性的方向在发展。

-   GPU实现了第二章中描述的几何和光栅化概念管线阶段。其被分为一些不同程度的可配置性和可编程性的硬件阶段。如图3.1所示。

![](media/3.jpg)

图3.1 GPU实现的渲染管线

上图中，不同颜色的阶段表示了该阶段不同属性。其中：

-   绿色的阶段都是完全可编程的。

-   黄色的阶段可配置，但不可编程。

-   蓝色的阶段完全固定。

需要注意，GPU实现的渲染管线和第二章中描述的渲染管线的功能阶段在结构上略有不同。以下是对GPU渲染管线的一个流程概览：

-   顶点着色器（The Vertex Shader）是完全可编程的阶段，顶点着色器可以对每个顶点进行诸如变换和变形在内的很多操作，提供了修改/创建/忽略顶点相关属性的功能，这些顶点属性包括颜色、法线、纹理坐标和位置。顶点着色器的必须完成的任务是将顶点从模型空间转换到齐次裁剪空间。

-   几何着色器（The Geometry Shader）位于顶点着色器之后，允许GPU高效地创建和销毁几何图元。几何着色器是可选的，完全可编程的阶段，主要对图元（点、线、三角形）的顶点进行操作。几何着色器接收顶点着色器的输出作为输入，通过高效的几何运算，将数据输出，数据随后经过几何阶段和光栅化阶段的其他处理后，会发送给片段着色器。

-   裁剪（Clipping）属于可配置的功能阶段，在此阶段可选运行的裁剪方式，以及添加自定义的裁剪面。

-   屏幕映射（Screen Mapping）、三角形设置（Triangle Setup）和三角形遍历（Triangle Traversal）阶段是固定功能阶段。

-   像素着色器（Pixel Shader，Direct3D中的叫法）常常又称为片断着色器，片元着色器(Fragment Shader，OpenGL中的叫法)，是完全可编程的阶段，主要作用是进行像素的处理，让复杂的着色方程在每一个像素上执行。

-   合并阶段（The Merger Stage）处于完全可编程和固定功能之间，尽管不能编程，但是高度可配置，可以进行一系列的操作。其除了进行合并操作，还分管颜色修改（Color Modifying），Z缓冲（Z-buffer），混合（Blend），模板（Stencil）和相关缓存的处理。

随着时间的推移，GPU管线已经远离硬编码的运算操作，而朝着提高灵活性和控制性改进。编程着色器的引入是这个进化的最重要的一步。

<br />

## 3.2 可编程着色模型

<br />

-   现代着色阶段（比如支持shader model 4.0，DirectX 10以及之后）使用了通用着色核心（common-shader core），这就表明顶点，片段，几何着色器共享一套编程模型。

-   早期的着色模型可以用汇编语言直接编程，但DX10之后，汇编就只在调试输出阶段可见，改用高级着色语言。

-   目前的着色语言都是C-like的着色语言，比如HLSL,CG和GLSL，其被编译成独立于机器的汇编语言语言，也称为中间语言（IL）。这些汇编语言在单独的阶段，通常是在驱动中，被转化成实际的机器语言。这样的安排可以兼容不同的硬件实现。这些汇编语言可以被看做是定义一个作为着色语言编译器的虚拟机。这个虚拟机是一个处理多种类型寄存器和数据源、预编了一系列指令的处理器。

-   着色语言虚拟机可以理解为一个处理多种类型寄存器和数据源、预编了一系列指令的处理器。考虑到很多图形操作都使用短矢量（最高四位），处理器拥有4路SIMD（single-instruction multiple-data，单指令多数据）兼容性。每个寄存器包含四个独立的值。32位单精度浮点的标量和矢量是其基本数据类型；也随后支持32位整型。浮点矢量通常包含数据如位置（xyzw），法线，矩阵行，颜色（rgba），或者纹理坐标（uvwq）。而整型通常用来表示，计数器，索引，或者位掩码。也支持综合数据类型比如结构体，数组，和矩阵。而为了便于使用向量，向量操作如调和（swizzling，也就是向量分量的重新排序或复制），和屏蔽（masking，只使用指定的矢量元素），也能够支持。虚拟机的输入和输出见图3.2。

![](media/4.jpg)

图3.2 DX 10下的通用Shader核心虚拟机架构以及寄存器布局。每个资源旁边显示最大可用编号。其中，用两个斜杠分开的三个数值，分别是顶点，几何、像素着色器对应的可用最大值。

-   一个绘制调用（也就是喜闻乐见的Draw Call）会调用图形API来绘制一系列的图元，会驱使图形管线的运行。

-   每个可编程着色阶段拥有两种类型的输入：

    -   uniform输入，在一个draw call中保持不变的值（但在不同draw call之间可以更改）；

    -   varying输入，shader里对每个顶点和像素的处理都不同的值。纹理是特殊类型的uniform输入，曾经一直是一张应用到表面的彩色图片，但现在可以认为是存储着大量数据的数组。

-   在现代GPU上 ，图形运算中常见的运算操作执行速度非常快。通常情况下，最快的操作是标量和向量的乘法和加法，以及他们的组合，如乘加运算（multiply-add）和点乘 （dot-product）运算。其他操作，比如倒数（reciprocal）, 平方根（square root），正弦（sine），余弦（cosine），指数（exponentiation）、对数（logarithm）运算，往往会稍微更加昂贵，但依然相当快捷。纹理操作非常高效，但他们的性能可能受到诸如等待检索结果的时间等因素的限制。

-   着色语言表示出了大多数场常见的操作（比如加法和乘法通过运算符+和\*来表示）。其余的操作用固有的函数，比如atan() , dot() , log(),等。更复杂的操作也存在内建函数，比如矢量归一化（vector normalization）、反射（reflection）、叉乘（cross products）、矩阵的转置（matrix transpose）和行列式（determinant）等。

-   流控制（flow control）是指使用分支指令来改变代码执行流程的操作。这些指令用于实现高级语言结构，如“if”和“case”语句，以及各种类型的循环。Shader支持两种类型的流控制。静态流控制（Static flow control）是基于统一输入的值的。这意味着代码的流在调用时是恒定的。静态流控制的主要好处是允许在不同的情况下使用相同的着色器（例如，不同数量的光源）。动态流控制（Dynamic flow control）基于不同的输入值。但动态流控制远比静态流量控制更强大但同时也需更高的开销，特别是在调用shader之间，代码流不规律改变的时候。正如18.4.2节中讨论的，评估一个shader的性能，是评估其在一段时间内处理顶点或像素的个数。如果流对某些元素选择“if”分支，而对其他元素选择“else”分支，这两个分支必须对所有元素进行评估（并且每个元素的未使用分支将被丢弃）。

-   Shader程序可以在程序加载或运行时离线编译。和任何编译器一样，有生成不同输出文件和使用不同优化级别的选项。一个编译过的Shader作为字符串或者文本来存储，并通过驱动程序传递给GPU。

**3.3 可编程着色的进化史 The Evolution of Programmable Shading**

可编程着色的框架的思想可以追溯到1984年Cook的 shade
trees。一个简单的Shader以及其对应的shade tree如图3.3。

![](media/5.jpg)

原书图3.3 一个简单的铜着色器（Cook的 shade trees）和其对应的着色语言代码

-   RenderMan 着色语言（RenderManShading Language）是从80年代中后期根据这个可编程着色的框架思想开发出来的，目前仍然广泛运用于电影制作的渲染中。在GPU原生支持可编程着色之前，有一些通过多个渲染通道实现实时可编程着色的尝试。

-   在1999年，《雷神III：竞技场》脚本语言是在这个领域上第一个成功广泛商用的语言。

-   在2000年，Peery等人，描绘了一个将RnederMan Shader翻译成在多通道上并且运行在图形硬件上的系统。

-   在2001年，NVIDIA'sGeForce 3 发布，它是第一个支持可编程顶点着色器的GPU，向DirectX
    8.0开放，并以扩展的形式提供给OpenGL。

-   2002年， DirectX 9.0发布，里面包括了Shader Model
    2.0（以及其扩展版本2.X），Shader Model 2.0 支持真正的可编程顶点和像素着色。着色编程语言 HLSL也是随着DirectX
    9.0的发布而问世。

-   2004年，Shader Model
    3.0推出。SM3.0是一个增量改进，将之前的可选功能进行了实现，进一步增加资源上限，并在顶点着色器中添加了有限的纹理读取支持。新一代主机的问世，2005(Microsofts Xbox 360)，2006 (Sony Play Station)，它们配备配备了Shader Model 3.0级别的GPU。

-   2006年底 ，任天堂发布了搭载固定功能管线GPU的Wii主机 ，固定功能管线，并没有像预想中的会完全死亡（其实一直活得很好）。

-   2007年，Shader Model4.0发布，包含于DirectX
    10.0中，OpenGL以扩展的方式支持。SM 4.0新增了几个着色器和流输出等新特性。SM
    4.0包括支持所有Shader类型（顶点、几何、像素着色器）的一套统一着色模型（uniform programming model）

![](media/6.jpg)

图3.4 一个名为“mental
mill”的可视化着色器设计系统。各种操作都封装在功能窗中，位于左侧。每个功能窗都有可调参数，每个功能框的输入和输出彼此连接，形成最终结果。

### 3.3.1 着色模型对比 Comparison of Shader Models

下表3.1比较了各种着色模型的能力。在这个表格中，VS”代表顶点着色器和“PS”代表像素着色器（而着色模型4.0
引入了几何着色器，其能力与顶点着色相似）。如果没有出现“VS”和“PS”，那么该行适用于顶点和像素着色器。

![](media/6x.jpg)

表3.1 不同版本的着色模型能力对比，按DirectX着色模型版本列出

## 3.4 顶点着色器 Vertext Shader

-   顶点着色器（The Vertex Shader）的功能于2001年首次在DirectX
    8中引入。由于它是流水线上的第一个阶段，可选是在GPU还是CPU上实现。而在CPU上实现的话，需将CPU中的输出数据发送到GPU进行光栅化。目前几乎所有的GPU都支持顶点着色。

-   顶点着色器是完全可编程的阶段，是专门处理传入的顶点信息的着色器，顶点着色器可以对每个顶点进行诸如变换和变形在内的很多操作。顶点着色器一般不处理附加信息，也就是说，顶点着色器提供了修改，创建，或者忽略与每个多边形顶点相关的值的方式，例如其颜色，法线，纹理坐标和位置。通常，顶点着色器程序将顶点从模型空间（Model
    Space）变换到齐次裁剪空间（Homogeneous Clip
    Space），并且，一个顶点着色器至少且必须输出此变换位置。

-   值得注意的是，在这个顶点着色阶段之前发生了一些数据操作。比如在DirectX中叫做输入装配（Input
    Assembler）的阶段，会将一些数据流组织在一起，以形成顶点和基元的集合，发送到管线。

-   顶点着色器本身与前面3.2节所述的通用核心虚拟机（Common-Shader Core Virtual
    Machine）非常相似。传入的每个顶点由顶点着色器程序处理，然后输出一些在三角形或直线上进行插值后获得的值。顶点着色器既不能创建也不能消除顶点，并且由一个顶点生成的结果不能传递到另一个顶点。由于每个顶点都被独立处理，所以GPU上的任何数量的着色器处理器都可以并行地应用到传入的顶点流上。

-   顶点着色器的输出可以以许多不同的方式来使用，通常是随后用于每个实例三角形的生成和光栅化，然后各个像素片段被发送到像素着色器，以便继续处理。而在Shader
    Model 4.0中，数据也可以发送到几何着色器（Geometry Shader）或输出流（Streamed
    Output）或同时发动到像素着色器和几何着色器两者中。

如图3.5 使用顶点着色器的一些示例。

![](https://pic2.zhimg.com/v2-ecf4270d2bd2859bea1b93508420f805_b.jpg)

原书图3.5
左图，一个普通茶壶。中图，经过顶点着色程序执行的简单剪切（shear）操作产生的茶壶。右图，通过噪声（noise）产生的发生形变的茶壶。

## 3.5 几何着色器 The Geometry Shader

-   几何着色器（Geometry Shader）是顶点和片段着色器之间一个可选的着色器，随着2006年底DirectX10的发布被加入到硬件加速图形管线中。几何着色器作为Shader Model 4.0的一部分，不能早期着色模型（<=SM 3.0）中使用。

-   几何着色器的输入是单个对象及对象相关的顶点，而对象通常是网格中的三角形，线段或简单的点。另外，扩展的图元可以由几何着色器定义和处理。如图3.6。

![](media/8.jpg)

  
原书图3.6
几何着色器程序的输入是一个单独的类型：点，线段，三角形。两个最右边的图元，包括与线和三角形对象相邻的顶点也可被使用。

-   几何着色器可以改变新传递进来的图元的拓扑结构，且几何着色器可以接收任何拓扑类型的图元，但是只能输出点、折线（line
    strip）和三角形条（triangle strips）。

-   几何着色器需要图元作为输入，在处理过程中他可以将这个图元整个丢弃或者输出一个或更多的图元（也就是说它可以产生比它得到的更多或更少的顶点）。这个能力被叫做几何增长（growing
    geometry）。如上所述，几何着色器输出的形式只能是点，折线和三角形条。

-   当我们未添加几何着色器时，默认的行为是将输入的三角形直接输出。我们添加了几何着色器之后，可以在几何着色器中修改输出的图形，我们可以输出我们想要输出的任何图形。

![](media/9.jpg)

图
3.7.一些几何着色器的应用。左图，使用几何着色器实现元球的等值面曲面细分（metaball
isosurface
tessellation）。中图，使用了几何着色器和流输出进行线段细分的分形（fractal
subdivision of line
segments）。右图，使用顶点和几何着色器的流输出进行布料模拟。（图片来自NVIDIA SDK
10的示例）

### 3.5.1 流输出 Stream Output

-   GPU的管线的标准使用方式是发送数据到顶点着色器，然后对所得到的三角形进行光栅化处理，并在像素着色器中处理它们。
    数据总是通过管线传递，无法访问中间结果。流输出的想法在Shader Model
    4.0中被引入。在顶点着色器（以及可选的几何着色器中）处理顶点之后，除了将数据发送到光栅化阶段之外，也可以输出到流，也就是一个有序数组中进行处理。事实上，可以完全关掉光栅化，然后管线纯粹作为非图形流处理器来使用。以这种方式处理的数据可以通过管线回传，从而允许迭代处理。如原书的第10.7节所述，这种操作特别适用于模拟流动的水或其他粒子特效。

## 3.6 像素着色器 Pixel Shader

-   像素着色器(Pixel
    Shader，Direct3D中的叫法)，常常又称为片断着色器,片元着色器(Fragment Shader,
    OpenGL中的叫法)，用于进行逐像素计算颜色的操作，让复杂的着色方程在每一个像素上执行。如图3.1
    GPU渲染管线所示，像素着色器是光栅化阶段的主要步骤之一。在顶点和几何着色器执行完其操作之后，图元会被裁剪、屏幕映射，结束几何阶段，到达光栅化阶段，在光栅化阶段中先经历三角形设定和三角形遍历，之后来到像素着色阶段。

-   像素着色器常用来处理场景光照和与之相关的效果，如凸凹纹理映射和调色。名称片断着色器似乎更为准确，因为对于着色器的调用和屏幕上像素的显示并非一一对应。举个例子，对于一个像素，片断着色器可能会被调用若干次来决定它最终的颜色，那些被遮挡的物体也会被计算，直到最后的深度缓冲才将各物体前后排序。

-   需要注意，像素着色程序通常在最终合并阶段设置片段颜色以进行合并，而深度值也可以由像素着色器修改。模板缓冲（
    stencil buﬀer ）值是不可修改的，而是将其传递到合并阶段（merge stage）。在SM
    2.0以及以上版本，像素着色器也可以丢弃（discard
    ）传入的片段数据，即不产生输出。这样的操作会消耗性能，因为通常在这种情况下不能使用由GPU执行的优化
    。详见第18.3.7节。 诸如雾计算和alpha测试的操作已经从合并操作转移到SM 4.0
    中的像素着色器里计算。

-   可以发现，顶点着色程序的输出，在经历裁剪、屏幕映射、三角形设定、三角形遍历后，实际上变成了像素着色程序的输入。在Shader
    Model
    4.0中，共有16个向量（每个向量含4个值）可以从顶点着色器传到像素着色器。当使用几何着色器时，可以输出32个向量到像素着色器中。像素着色器的追加输入是在Shader
    Model
    3.0中引入的。例如，三角形的哪一面是可见的是通过输入标志来加入的。这个值对于在单个通道中的正面和背面渲染不同材质十分重要。而且像素着色器也可以获得片段的屏幕位置。

## 3.7 合并阶段 The Merging Stage

作为光栅化阶段名义上的最后一个阶段，合并阶段（The Merging
Stage）是将像素着色器中生成的各个片段的深度和颜色与帧缓冲结合在一起的地方。这个阶段也就是进行模板缓冲（Stencil-Buffer）和Z缓冲（Z-buffer）操作的地方。最常用于透明处理（Transparency）和合成操作（Compositing）的颜色混合（Color
Blending）操作也是在这个阶段进行的。

虽然合并阶段不可编程，但却是高度可配置的。在合并阶段可以设置颜色混合来执行大量不同的操作。最常见的是涉及颜色和Alpha值的乘法，加法，和减法的组合。其他操作也是可能的，比如最大值，最小值以及按位逻辑运算。

## 3.8 效果 Effect

-   GPU渲染管线中的可编程阶段有顶点、几何和像素着色器三个部分，他们需要相互结合在一起使用。正因如此，不同的团队研发出了不同的特效语言，例如HLSL
    FX，CgFX，以及COLLADA FX，来将他们更好的结合在一起。

-   一个效果文件通常会包含所有执行一种特定图形算法的所有相关信息，而且通常定义一些可被应用程序赋值的全局参数。例如，一个单独的effect
    file可能定义渲染塑料材质需要的vs(顶点着色器)和ps（像素着色器），它可能暴露一些参数例如塑料颜色和粗糙度，这样渲染每个模型的时候可以改变效果而仅仅使用同一个特效文件。一个效果文件中能存储很多techniques。这些techniques通常是一个相同effect的变体，每种对应于一个不同的Shader
    Model（SM2.0，SM3.0等等）。如图3.9，使用Shader实现的效果。

![](media/10x.jpg)

原书图3.9 可编程着色器可以实现各种材料和后处理效果

<br>


# 三、本章内容提炼总结

以下是对《Real Time Rendering 3rd》第三章“The Graphics Processing Unit
图形处理器”内容概括总结，有必要再次放出这张图：

![](media/11.jpg)

图3.1 GPU实现的渲染管线

上图中，不同颜色的阶段表示了该阶段不同属性。其中：

-   绿色的阶段都是完全可编程的。

-   黄色的阶段可配置，但不可编程。

-   蓝色的阶段完全固定。

对每个阶段的分别概述：

-   顶点着色器（The Vertex
    Shader）是完全可编程的阶段，顶点着色器可以对每个顶点进行诸如变换和变形在内的很多操作，提供了修改/创建/忽略顶点相关属性的功能，这些顶点属性包括颜色、法线、纹理坐标和位置。顶点着色器的必须完成的任务是将顶点从模型空间转换到齐次裁剪空间。

-   几何着色器（The Geometry
    Shader）位于顶点着色器之后，允许GPU高效地创建和销毁几何图元。几何着色器是可选的，完全可编程的阶段，主要对图元（点、线、三角形）的顶点进行操作。几何着色器接收顶点着色器的输出作为输入，通过高效的几何运算，将数据输出，数据随后经过几何阶段和光栅化阶段的其他处理后，会发送给片段着色器。

-   裁剪（Clipping）属于可配置的功能阶段，在此阶段可选运行的裁剪方式，以及添加自定义的裁剪面。

-   屏幕映射（Screen Mapping）、三角形设置（Triangle
    Setup）和三角形遍历（Triangle Traversal）阶段是固定功能阶段。

-   像素着色器（Pixel
    Shader，Direct3D中的叫法）常常又称为片断着色器，片元着色器(Fragment
    Shader，OpenGL中的叫法)，是完全可编程的阶段，主要作用是进行像素的处理，让复杂的着色方程在每一个像素上执行。

-   合并阶段（The Merger
    Stage）处于完全可编程和固定功能之间，尽管不能编程，但是高度可配置，可以进行一系列的操作。其除了进行合并操作，还分管颜色修改（Color
    Modifying），Z缓冲（Z-buffer），混合（Blend），模板（Stencil）和相关缓存的处理。

```

`Content/《Real-Time Rendering 3rd》读书笔记/Content/BlogPost04/README.md`:

```md

![](media/a540e701e2468109bce90b48d859749a.jpg)


# 【《Real-Time Rendering 3rd》 提炼总结】(四) 第五章 · 图形渲染与视觉外观 The Visual Appearance




这篇文章将总结和提炼《Real-Time Rendering 3rd》（实时渲染图形学第三版）的第五章“Visual Appearance（视觉外观）”的内容。


# 壹·导读

当我们渲染三维模型的图像时，模型不仅要有适当的几何形状，还应该有所需的视觉外观。《Real-Time
Rendering
3rd》第五章内容，讨论光照和材质在现实世界的表现，关于光照和表面模型，着色方程，以及渲染出真实外观的一些额外技术。

简而言之，通过阅读这篇总结式文章，你将对图形渲染中的以下要点有所了解：

-   渲染与视觉物理现象

-   光照与材质

-   着色原理

-   抗锯齿

-   透明渲染

-   伽玛校正

当然，本文作为总结式文章，知识点会相对密集，很多地方对细节并不可能展开描述，对一些地方不太理解的朋友，自然还是推荐是去阅读《Real-Time
Rendering 3rd》的对应原文与相应文献。


<br>

# 贰·渲染与视觉物理现象

当渲染类似图1中的逼真场景时，可以帮助了解渲染相关的物理现象。一般情况，这些物理现象分为三种：

-   太阳光与其他光源（天然或人造光）发出光。

-   光与场景中的物体相互作用。部分被吸收；部分散射开来，向新的方向传播。

-   最终，光被传感器（人眼，电子传感器）吸收。

![](media/8ba4610d9d3437bf3d6208080a8c1fe7.jpg)

图1 光源与各种物体交互的卧室照片

而在图1中，我们可以看到所有的如上三种物理现象：

-   光线从灯光发出并直接传播给房间里其他物体。

-   物体表面吸收一些物体，并将一些物体散射到新的方向。没有被吸收的光线继续在环境中移动，遇到其他物体。

-   通过场景的光一小部分光进入用于捕获图像的传感器（如摄像机）。

叁·光照与材质

-   关于光源的特性。光被不同地模拟为几何光线，电磁波或光子（具有一些波特性的量子粒子）。无论如何处理，光都是电磁辐射能-通过空间传播的电磁能。光源发光，而不是散射或吸收光。根据渲染目的，光源可以以许多不同的方式来表示。光源可以分为三种不同类型：平行光源、点光源和聚光灯。

-   关于材质的特性。在渲染中，通过将材质附加到场景中的模型来描绘对象外观。每个材质都和一系列的Shader代码，纹理，和其他属性联系在一起，用来模拟光与材质相互作用。

## 3.1 光照现象：散射与吸收

-   从根本上来说，所有的光物质相互作用都是两种现象的结果：
    散射（scattering）和吸收（absorption）。

-   散射（scattering）发生在当光线遇到任何种类的光学不连续性（optical
    discontinuity）时，可能存在于具有不同光学性质的两种物质分界之处，晶体结构破裂处，密度的变化处等。散射不会改变光量，它只是使其改变方向。光的散射（scattering）一般又分为反射（reflection）和折射（refraction）。

![](media/0892632f5ffd5ce75399048b18c515d6.jpg)

图2 光的散射（scattering）——反射（reflection）和折射（refraction）

-   吸收（absorption）发生在物质内部，其会导致一些光转变成另一种能量并消失。
    吸收会减少光量，但不会影响其方向。

![](media/2da45212f77010f377ca75ae3be80b42.jpg)

图3 反射（reflected light）和透射光（transmitted light）的相互作用

-   镜面反射光表示在表面反射的光。而漫反射光表示经历透射（transmission），吸收（absorption）和散射（scattering）
    的光。

-   入射光（Incoming
    illumination）通过表面辉度（irradiance）来度量。而出射光（outgoing
    light）通过出射率（exitance）来度量，类似于辉度是每单位面积的能量。光物质相互作用是线性的;
    使辉度加倍将会使出射率增加一倍。出射率除以辉度可以作为材质的衡量特性。对于不发光的表面，该比率为0到1之间。出射率和辉度的比率对于不同的光颜色是不同的，所以其表示为RGB矢量或者颜色，也就是我们通常说的表面颜色c。

<br>

## 3.2 表面粗糙度

-   镜面反射项的方向分布取决于表面粗糙度（smoothness，又译作光滑度）。反射光线对于更平滑的表面更加紧密，并且对于较粗糙的表面更加分散。我们可以看到下图中的这种依赖关系，它显示了不同粗糙度的两个表面的反射效果。

![](media/619a22065d249ffa8747cc7ee56b1941.jpg)

图4 光在粗糙度不同表面的反射


<br>

# 肆·着色

## 4.1 着色与着色方程

着色（Shade）是使用方程式根据材质属性和光源，计算沿着视线v的出射光亮度*Lo*的过程。我们使用的着色方程具有漫反射和镜面反射分量。

### 4.1.1 着色方程的漫反射分量

其中漫反射分量较为简单，书中推导出的对Ldiff的着色方程如下：
<br>
<br>
<div  align="center">    
<img src="media/2c7ffb0dbc09aa290878053e34761d8e.jpg" height = "55" alt="name" align=center />
</div>

这种类型的漫反射着色也被叫做兰伯特（Lambertian）着色。兰伯特定律指出，对于理想的漫反射表面，出射光亮度与cosθi成正比。注意，这种夹紧型cos因子（clamped
dot product，可写作max(n·l,
0)，通常称为n点乘l因子），不是兰伯特表面的特征;正如我们所见，它一般适用于辉度（irradiance）的度量。兰伯特表面的决定性特征是出射光亮度（radiance）和辉度（irradiance）成正比。

#### 4.1.2 着色方程的镜面反射分量

原书中推导出的镜面反射项的着色方程：

<div  align="center">    
<img src="media/37b890a30181aa7b3e2d8104bc8ec318.jpg" height = "55" alt="name" align=center />
</div>

#### 4.1.3 着色方程

组合漫反射和镜面反射两个项，得到完整的着色方程，总出射光亮度Lo：


<div  align="center">    
<img src="media/051d469c265a92e7a10e704460e4cdf2.jpg" height = "55" alt="name" align=center />
</div>

这个着色方程与“Blinn-Phong”方程类似，“Blinn-Phong”方程是Blinn在1977年首次提出的。主要形式如下：


<div  align="center">    
<img src="media/da177d97f6e96b285ab35937a917807b.jpg" height = "55" alt="name" align=center />
</div>

## 4.2 三种着色处理方法

着色处理是计算光照并由此决定像素颜色的过程，存在3种常见的着色处理方法：平滑着色、高洛德着色与冯氏着色。

-   平滑着色（Flat
    shading）：简单来讲，就是一个三角面用同一个颜色。如果一个三角面的代表顶点(也许是按在index中的第一个顶点)，恰好被光照成了白色，那么整个面都会是白的。

-   高洛德着色（Gouraud
    shading）：每顶点求值后的线性插值结果通常称为高洛德着色。在高洛德着色的实现中，顶点着色器传递世界空间的顶点法线和位置到Shade(
    )
    (首先确保法线矢量长度为1），然后将结果写入内插值。像素着色器将获取内插值并将其直接写入输出。
    高洛德着色可以为无光泽表面产生合理的结果，但是对于强高光反射的表面

-   冯氏着色（Phong
    shading）：冯氏着色是对着色方程进行完全的像素求值。在冯氏着色实现中，顶点着色器将世界空间法线和位置写入内插值，此值通过像素着色器传递给Shade(
    )函数。而将Shade(
    )函数返回值写入到输出中。请注意，即使表面法线在顶点着色器中缩放为长度1，插值也可以改变其长度，因此可能需要在像素着色器中再次执行此归一化操作。

![](media/abbddc86c79d6a7bda9064359f945a64.jpg)

图5 从左到右，平面着色（Flat shading），高洛德着色（ Gouraud shading）,
和冯氏着色（Phong shading）

-   注意Phong Shading和Phong Lighting
    Model的区别，前者是考虑如何在三个顶点中填充颜色，而后者表示的是物体被光照产生的效果。

-   注意冯氏着色可以说是三者中最接近真实的着色效果，当然开销也是最大的。因为高洛德着色是每个顶点(vertex)计算一次光照，冯氏着色是每个片元(fragment)或者说每像素计算一次光照，点的法向量是通过顶点的法向量插值得到的。所以说不会出现高洛德着色也许会遇到的失真问题。

<br>

# 伍·抗锯齿与常见抗锯齿类型总结

抗锯齿（英语：anti-aliasing，简称AA），也译为边缘柔化、消除混叠、抗图像折叠有损，反走样等。它是一种消除显示器输出的画面中图物边缘出现凹凸锯齿的技术，那些凹凸的锯齿通常因为高分辨率的信号以低分辨率表示或无法准确运算出3D图形坐标定位时所导致的图形混叠（aliasing）而产生的，抗锯齿技术能有效地解决这些问题。

下面将常见的几种抗锯齿类型进行总结介绍，也包括RTR3中没有讲到的，最近几年新提出的常见抗锯齿类型。

## 5.1 超级采样抗锯齿（SSAA）

超级采样抗锯齿（Super-Sampling
Anti-Aliasing，简称SSAA）是比较早期的抗锯齿方法，比较消耗资源，但简单直接。这种抗锯齿方法先把图像映射到缓存并把它放大，再用超级采样把放大后的图像像素进行采样，一般选取2个或4个邻近像素，把这些采样混合起来后，生成的最终像素，令每个像素拥有邻近像素的特征，像素与像素之间的过渡色彩，就变得近似，令图形的边缘色彩过渡趋于平滑。再把最终像素还原回原来大小的图像，并保存到帧缓存也就是显存中，替代原图像存储起来，最后输出到显示器，显示出一帧画面。这样就等于把一幅模糊的大图，通过细腻化后再缩小成清晰的小图。如果每帧都进行抗锯齿处理，游戏或视频中的所有画面都带有抗锯齿效果。
超级采样抗锯齿中使用的采样法一般有两种：

-   OGSS，顺序栅格超级采样（Ordered Grid
    Super-Sampling，简称OGSS），采样时选取2个邻近像素。

-   RGSS，旋转栅格超级采样（Rotated Grid
    Super-Sampling，简称RGSS），采样时选取4个邻近像素。

另外，作为概念上最简单的一种超采样方法，全场景抗锯齿（Full-Scene
Antialiasing,FSAA）以较高的分辨率对场景进行绘制，然后对相邻的采样样本进行平均，从而生成一幅新的图像。

## 5.2 多重采样抗锯齿（MSAA）

多重采样抗锯齿（Multi Sampling
Anti-Aliasing，简称MSAA），是一种特殊的超级采样抗锯齿（SSAA）。MSAA首先来自于OpenGL。具体是MSAA只对Z缓存（Z-Buffer）和模板缓存(Stencil
Buffer)中的数据进行超级采样抗锯齿的处理。可以简单理解为只对多边形的边缘进行抗锯齿处理。这样的话，相比SSAA对画面中所有数据进行处理，MSAA对资源的消耗需求大大减弱，不过在画质上可能稍有不如SSAA。

## 5.3 覆盖采样抗锯齿（CSAA）

覆盖采样抗锯齿（Coverage Sampling
Anti-Aliasing，简称CSAA）是NVIDIA在G80及其衍生产品首次推向实用化的AA技术，也是目前NVIDIA
GeForce
8/9/G200系列独享的AA技术。CSAA就是在MSAA基础上更进一步的节省显存使用量及带宽，简单说CSAA就是将边缘多边形里需要取样的子像素坐标覆盖掉，把原像素坐标强制安置在硬件和驱动程序预先算好的坐标中。这就好比取样标准统一的MSAA，能够最高效率的执行边缘取样，效能提升非常的显著。比方说16xCSAA取样性能下降幅度仅比4xMSAA略高一点，处理效果却几乎和8xMSAA一样。8xCSAA有着4xMSAA的处理效果，性能消耗却和2xMSAA相同。

## 5.4 高分辨率抗锯齿（HRAA）

高分辨率抗锯齿方法(High Resolution
Anti-Aliasing，简称HRAA)，也称Quincunx方法，也出自NVIDIA公司。“Quincunx”意思是5个物体的排列方式，其中4个在正方形角上，第五个在正方形中心，也就是梅花形，很像六边模型上的五点图案模式。此方法中，采样模式是五点梅花状，其中四个样本在像素单元的角上，最后一个在中心。

## 5.5 可编程过滤抗锯齿（CFAA）

可编程过滤抗锯齿（Custom Filter
Anti-Aliasing，简称CFAA）技术起源于AMD-ATI的R600家庭。简单地说CFAA就是扩大取样面积的MSAA，比方说之前的MSAA是严格选取物体边缘像素进行缩放的，而CFAA则可以通过驱动和谐灵活地选择对影响锯齿效果较大的像素进行缩放，以较少的性能牺牲换取平滑效果。显卡资源占用也比较小。

## 5.6 形态抗锯齿（MLAA）

形态抗锯齿（Morphological
Anti-Aliasing，简称MLAA），是AMD推出的完全基于CPU处理的抗锯齿解决方案。与MSAA不同，
MLAA将跨越边缘像素的前景和背景色进行混合，用第2种颜色来填充该像素，从而更有效地改进图像边缘的变现效果。

## 5.7 快速近似抗锯齿（FXAA）

快速近似抗锯齿(Fast Approximate Anti-Aliasing，简称FXAA)
，是传统MSAA(多重采样抗锯齿)效果的一种高性能近似。它是一种单程像素着色器，和MLAA一样运行于目标游戏渲染管线的后期处理阶段，但不像后者那样使用DirectCompute，而只是单纯的后期处理着色器，不依赖于任何GPU计算API。正因为如此，FXAA技术对显卡没有特殊要求，完全兼容NVIDIA、AMD的不同显卡(MLAA仅支持A卡)和DirectX
9.0、DirectX 10、DirectX 11。

## 5.8 时间性抗锯齿（TXAA）

时间性抗锯齿（Temporal Anti-Aliasing，简称TXAA），将
MSAA、时间滤波以及后期处理相结合，用于呈现更高的视觉保真度。与CG电影中所采用的技术类似，TXAA集MSAA的强大功能与复杂的解析滤镜于一身，可呈现出更加平滑的图像效果。此外，TXAA还能够对帧之间的整个场景进行抖动采样，以减少闪烁情形，闪烁情形在技术上又称作时间性锯齿。目前，TXAA有两种模式：TXAA
2X和TXAA 4X。TXAA 2X可提供堪比8X MSAA的视觉保真度，然而所需性能却与2X
MSAA相类似；TXAA 4X的图像保真度胜过8XMSAA，所需性能仅仅与4X MSAA相当。

## 5.9 多帧采样抗锯齿（MFAA）

多帧采样抗锯齿（Multi-Frame Sampled Anti-Aliasing，MFAA）是
NVIDIA公司根据MSAA改进出的一种抗锯齿技术。目前仅搭载 Maxwell
架构GPU的显卡才能使用。可以将MFAA理解为MSAA的优化版，能够在得到几乎相同效果的同时提升性能上的表现。MFAA与MSAA最大的差别就在于在同样开启4倍效果的时候MSAA是真正的针对每个边缘像素周围的4个像素进行采样，MFAA则是仅仅只是采用交错的方式采样边缘某个像素周围的两个像素。

<br>

# 陆·透明渲染与透明排序


## 6.1 透明渲染

透明渲染是是图形学里面的常见问题之一，可以从《Real-Time Rendering
3rd》中总结出如下两个算法：

-   Screen-Door
    Transparency方法。基本思想是用棋盘格填充模式来绘制透明多边形，也就是说，以每隔一个像素绘制一点方式的来绘制一个多边形，这样会使在其后面的物体部分可见，通常情况下，屏幕上的像素比较紧凑，以至于棋盘格的这种绘制方式并不会露馅。同样的想法也用于剪切纹理的抗锯齿边缘，但是在子像素级别中的，这是一种称为alpha覆盖（alpha
    to coverage）的特征。screen-door
    transparency方法的优点就是简单，可以在任何时间任何顺序绘制透明物体，并不需要特殊的硬件支持（只要支持填充模式）。缺点是透明度效果仅在50%时最好，且屏幕的每个区域中只能绘制一个透明物体。

-   Alpha混合（Alpha
    Blending）方法。这个方法比较常见，其实就是按照Alpha混合向量的值来混合源像素和目标像素。当在屏幕上绘制某个物体时，与每个像素相关联的值有RGB颜色和Z缓冲深度值，以及另外一个成分alpha分量，这个alpha值也可以根据需要生成并存储，它描述的是给定像素的对象片段的不透明度的值。
    alpha为1.0表示对象不透明，完全覆盖像素所在区域;
    0.0表示像素完全透明。为了使对象透明，在现有场景的上方，以小于1的透明度进行绘制即可。每个像素将从渲染管线接收到一个RGBA结果，并将这个值和原始像素颜色相混合。

<br>

## 6.2 透明排序

要将透明对象正确地渲染到场景中，通常需要对物体进行排序。下面分别介绍两种比较基本的透明排序方法（深度缓存和油画家算法）和两种高级别的透明排序算法（加权平均值算法和深度剥离）。

### 6.2.1 深度缓存（Z-Buffer）

Z-Buffer也称深度缓冲。在计算机图形学中，深度缓冲是在三维图形中处理图像深度坐标的过程，这个过程通常在硬件中完成，它也可以在软件中完成，它是可见性问题的一个解决方法。可见性问题是确定渲染场景中哪部分可见、哪部分不可见的问题。

Z-buffer的限制是每像素只存储一个对象。如果一些透明对象与同一个像素重叠，那么单独的Z-buffer就不能存储并且稍后再解析出所有可见对象的效果。这个问题是通过改变加速器架构来解决的，比如用A-buffer。A-buffer具有“深度像素（deep
pixels）”，其可以在单个像素中存储一系列呈现在所有对象之后被解析为单个像素颜色的多个片段。但需注意，Z-buffer是市场的主流选择。

### 6.2.2 画家算法（Painter's Algorithm）

画家算法也称优先填充算法，效率虽然较低，但还是可以有效处理透明排序的问题。其基本思想是按照画家在绘制一幅画作时，首先绘制距离较远的场景，然后用绘制距离较近的场景覆盖较远的部分的思想。画家算法首先将场景中的多边形根据深度进行排序，然后按照顺序进行描绘。这种方法通常会将不可见的部分覆盖，这样就可以解决可见性问题。

### 6.2.3 加权平均值算法（Weighted Average）

使用简单的透明混合公式来实现无序透明渲染的算法，它通过扩展透明混合公式，来实现无序透明物件的渲染，从而得到一定程度上逼真的结果。

### 6.2.4 深度剥离算法（Depth Peeling）

深度剥离是一种对深度值进行排序的技术。它的原理比较直观，标准的深度检测使场景中的Z值最小的点输出到屏幕上，就是离我们最近的顶点。但还有离我们第二近的顶点，第三近的顶点存在。要想显示它们，可以用多遍渲染的方法。第一遍渲染时，按照正常方式处理，这样就得到了离我们最近的表面中的每个顶点的z值。在第二遍渲染时，把现在每个顶点的深度值和刚才的那个深度值进行比较，凡是小于等于第一遍得到的z值，把它们剥离，后面的过程依次类推即可。

![](media/8a57b9d65342ddd0e42e615336da597e.jpg)

图6
每个深度剥离通道渲染特定的一层透明通道。左侧是第一个Pass，直接显示眼睛可见的层，中间的图显示了第二层，显示了每个像素处第二靠近透明表面的像素。右边的图是第三层，每个像素处第三靠近透明表面的像素。

<br>


# 柒·伽玛校正

伽马校正（Gamma correction） 又叫伽马非线性化（gamma
nonlinearity），伽马编码（gamma encoding）
或直接叫伽马（gamma），是用来对光线的辉度（luminance）或是三色刺激值（tristimulus
values）所进行非线性的运算或反运算的一种操作。为图像进行伽马编码的目的是用来对人类视觉的特性进行补偿，从而根据人类对光线或者黑白的感知，最大化地利用表示黑白的数据位或带宽。

<br>


# 捌·其他参考

[1] <https://zh.wikipedia.org/wiki/%E5%8F%8D%E9%8B%B8%E9%BD%92>

[2] [如何在Unity中分别实现Flat Shading(平面着色)、Gouraud
Shading(高洛德着色)、Phong
Shading(冯氏着色)](http://www.cnblogs.com/z12603/p/6860730.html)

[3] <http://blog.csdn.net/wang15061955806/article/details/50564035>

[4] <http://blog.csdn.net/xoyojank/article/details/3918091>

[5] [Gouraud shading - Wikipedia](http://en.wikipedia.org/wiki/Gouraud_shading)

[6] [Phong shading - Wikipedia](http://en.wikipedia.org/wiki/Phong_shading)

[7] <http://www.nbb.cornell.edu/neurobio/land/OldStudentProjects/cs490-95to96/guo/report.html>

[8] <https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E7%BC%93%E5%86%B2>

[9] <https://zh.wikipedia.org/wiki/%E4%BC%BD%E7%91%AA%E6%A0%A1%E6%AD%A3>

[10] 题图来自《刺客信条：枭雄》

The end.

```

`Content/《Real-Time Rendering 3rd》读书笔记/Content/BlogPost05/README.md`:

```md
![](media/title.jpg)


【《Real-Time Rendering 3rd》 提炼总结】(五) 第六章 · 纹理贴图及相关技术
========================================================================

在计算机图形学中，纹理贴图（Texturing）是使用图像、函数或其他数据源来改变物体表面外观的技术。这篇文章，将总结和提炼《Real-Time
Rendering
3rd》（实时渲染图形学第三版）的第六章“Texturing（纹理贴图）”的内容，讲述纹理贴图与其相关技术的方方面面。

简而言之，通过阅读这篇总结式文章，你将对纹理贴图技术中的以下要点有所了解：

-   纹理管线 The Texturing Pipeline

-   投影函数 The Projector Function

-   映射函数 The Corresponder Function

-   体纹理 Volume Texture

-   立方体贴图 Cube Map

-   纹理缓存 Texture Caching

-   纹理压缩 Texture Compression

-   程序贴图纹理 Procedural Texturing

-   Blinn凹凸贴图 Blinn Bump Mapping

-   移位贴图 Displacement Mapping

-   法线贴图 Normal Mapping

-   视差贴图 Parallax Mapping

-   浮雕贴图 Relief Mapping

壹 · 导读
=========

《Real-Time Rendering 3rd》第六章内容“Chapter 6
Texturing”，讨论了纹理贴图的方方面面。在计算机图形学中，纹理贴图是使用图像、函数或其他数据源来改变物体表面外观的技术。例如，可以将一幅砖墙的彩色图像应用到一个多边形上，而不用对砖墙的几何形状进行精确表示。当观察这个多边形的时候，这张彩色图像就出现在多边形所在位置上。只要观察者不接近这面墙，就不会注意到其中几何细节的不足（比如其实砖块和砂浆的图像是显示在光滑的表面上的事实）。通过这种方式将图像和物体表面结合起来，可以在建模、存储空间和速度方面节省很多资源。

![](media/3a780cc3cfb40bc8d695dec7304b549a.jpg)

图1
一幅使用了纹理颜色贴图、凹凸贴图和视差贴图等方法来增加画面复杂性和真实感的游戏截图（来自《黑暗之魂3》）

贰 · 纹理管线 The Texturing Pipeline
====================================

简单来说，纹理（Texturing）是一种针对物体表面属性进行“建模”的高效技术。图像纹理中的像素通常被称为纹素（Texels），区别于屏幕上的像素。根据Kershaw的术语，通过将投影方程（projector
function）运用于空间中的点
，从而得到一组称为参数空间值（parameter-spacevalues）的关于纹理的数值。这个过程就称为贴图（Mapping，也称映射
）,也就是纹理贴图（Texture Mapping，也称纹理映射
）这个词的由来。纹理贴图可以用一个通用的纹理管线来进行描述。纹理贴图过程的初始点是空间中的一个位置。这个位置可以基于世界空间，但是更常见的是基于模型空间。因为若此位置是基于模型空间的，当模型移动时，其纹理才会随之移动。

如图2 为一个纹理管线（The Texturing
Pipeline），也就是单个纹理应用纹理贴图的详细过程，而此管线有点复杂的原因是每一步均为用户提供了有效的控制。

![](media/23e1576a967760aee8def15c7752b4c2.jpg)

图2 单个纹理的通用纹理管线

下面是对上图中描述的纹理管线的分步概述：

-   第一步。通过将投影方程（projector function）运用于空间中的点
    ，从而得到一组称为参数空间值（parameter-space values）的关于纹理的数值。

-   第二步。在使用这些新值访问纹理之前，可以使用一个或者多个映射函数（corresponder
    function）将参数空间值（parameter-space values ）转换到纹理空间。

-   第三步。使用这些纹理空间值（texture-space
    locations）从纹理中获取相应的值（obtain
    value）。例如，可以使用图像纹理的数组索引来检索像素值。

-   第四步。再使用值变换函数（value transform
    function）对检索结果进行值变换，最后使用得到的新值来改变表面属性，如材质或者着色法线等等。

而如下这个例子应该对理解纹理管线有所帮助。下例将描述出使用纹理管线，一个多边形在给定一张砖块纹理时在其表面上生成样本时（如图3）发生了哪些过程。

![](media/ca5b5b1aba93a4396c6c3b733a455bc0.jpg)

图3 一个砖墙的纹理管线过程

如图3所示，在具体的参考帧画面中找到物体空间中的位置(x,y,z)，如图中点（-2.3,7.1,88.2），然后对该位置运用投影函数。这个投影函数通常将向量(x,y,z)转换为一个二元向量(u,v)。在此示例中使用的投影函数是一个正交投影，类似一个投影仪，将具有光泽的砖墙图像投影到多边形表面上。再考虑砖墙这边，其实这个投影过程就是将砖墙平面上的点变换为值域为0到1之间的一对(u,v)值，如图，(0.32,0.29)就是这个我们通过投影函数得到的uv值。而我们图像的分辨率是256
x 256，所以，将256分别乘以(0.32,0.29)，去掉小数点，得到纹理坐标(81,
74)。通过这个纹理坐标，可以在纹理贴图上查找到坐标对应的颜色值，所以，我们接着找到砖块图像上像素位置为(81,74)处的点，得到颜色(0.9,0.8,0.7)。而由于原始砖墙的颜色太暗，因此可以使用一个值变换函数，给每个向量乘以1.1，就可以得到我们纹理管线过程的结果——颜色值(0.99,0.88,0.77)。

随后，我们就可以将此值用于着色方程，作为物体的漫反射颜色值，替换掉之前的漫反射颜色。

下面对纹理管线中主要的两个组成，投影函数（The Projector
Function）和映射函数（The Corresponder Function）进行概述。

2.1 投影函数 The Projector Function
------------------------------------------------

作为纹理管线的第一步，投影函数的功能就是将空间中的三维点转化为纹理坐标，也就是获取表面的位置并将其投影到参数空间中。

在常规情况下，投影函数通常在美术建模阶段使用，并将投影结果存储于顶点数据中。也就是说，在软件开发过程中，我们一般不会去用投影函数去计算得到投影结果，而是直接使用在美术建模过程中，已经存储在模型顶点数据中的投影结果。但有一些特殊情况，例如：

1、OpenGL的glTexGen函数提供了一些不同的投影函数，包括球形函数和平面函数。利用空闲时间可以让图形加速器来执行投影过程，而这样做的优点是不需要将纹理坐标送往图形加速器，从而可以节省带宽。

2、更一般的情况，
可以在顶点或者像素着色器中使用投影函数，这可以实现各种效果，包括一些动画和一些渲染方法（比如如环境贴图，environment
mapping，有自身特定的投影函数，可以针对每个顶点或者每个像素进行计算）。

通常在建模中使用的投影函数有球形、圆柱、以及平面投影，也可以选其他一些输入作为投影函数。

![](media/223f78ee8ab2ecc968be64fbcdd53987.jpg)

图4
不同的纹理坐标，上面一行从左到右分别为球形、圆柱、平面，以及自然uv投影：下面一行所示为把不同的投影运用于同一个物体的情形。

非交互式渲染器（Noninteractive
renderers）通常将这些投影方程称为渲染过程本身的一部分。一个单独的投影方程就有可能适用于整个模型，但其实实际上，美术同学不得不使用各种各样的工具将模型进行分割，针对不同的部分，分别使用不同的投影函数。如图5所示。

![](media/acbeebac577de01563a57be7e2c45ed8.jpg)

图5 使用不同的投影函数将纹理以不同的方式投射到同一个模型上

各种常见投影的不同要点：

-   球形投影（The spherical
    projection）。球形投影将点投射到一个中心位于某个点的虚拟球体上，这个投影与Blinn与Newell的环境贴图方法相同。

-   圆柱投影（Cylindrical
    projection）。与球体投影一样，圆柱投影计算的是纹理坐标u，而计算得到的另一个纹理坐标v是沿该圆柱轴线的距离。这种投影方法对具有自然轴的物体比较适用，比如旋转表面，如果表面与圆柱体轴线接近垂直时，就会出现变形。

-   平面投影（The planar
    projection）。平面投影非常类似于x-射线幻灯片投影，它沿着一个方向进行投影，并将纹理应用到物体的所有表面上。这种方法通常使用正交投影，用来将纹理图应用到人物上，其把模型看作一个用纸做的娃娃，将不同的纹理粘贴到该模型的前后。

    ![https://pic1.zhimg.com/50/v2-b253e752bfd526af39473d731bd6b32e_hd.jpg](media/22da2f6ff8dcb49f33d3d6fc0d79af95.jpg)

    图6
    雕塑模型上的多个较小纹理，保存在两个较大的纹理上。右图显示了多边形网格如何展开并显示在纹理上的。

2.2 映射函数 The Corresponder Function
------------------------------------------------

映射函数（The Corresponder Function）的作用是将参数空间坐标（parameter-space
coordinates）转换为纹理空间位置（texture space locations）。

我们知道图像会出现在物体表面的(u,v)位置上，且uv值的正常范围在[0,1)范围内。超出这个值域的纹理，其显示方式便可以由映射函数（The
Corresponder Function）来决定。

在OpenGL中，这类映射函数称为“封装模式（Warapping
Mode）”，在Direct3D中，这类函数叫做“寻址模式（Texture Addressing
Mode）”。最常见的映射函数有以下几种：

-   重复寻址模式，wrap (DirectX), repeat (OpenGL)。图像在表面上重复出现。

-   镜像寻址模式，mirror。图像在物体表面上不断重复，但每次重复时对图像进行镜像或者反转。

-   夹取寻址模式，clamp (DirectX) ,clamp to edge
    (OpenGL)。夹取纹理寻址模式将纹理坐标夹取在[0.0，1.0]之间，也就是说，在[0.0，1.0]之间就是把纹理复制一遍，然后对于[0.0，1.0]之外的内容，将边缘的内容沿着u轴和v轴进行延伸。

-   边框颜色寻址模式，border (DirectX) ,clamp to border
    (OpenGL)。边框颜色寻址模式就是在[0.0，1.0]之间绘制纹理，然后[0.0，1.0]之外的内容就用边框颜色填充。

![](media/16216434a77f1675b2787df5a34e65a3.jpg)

图7 图像寻址模式，从左到右分别是重复寻址、镜像寻址、夹取寻址、边框颜色寻址

另外，每个纹理轴可以使用不同的映射函数。例如在u轴使用重复寻址模式，在v轴使用夹取寻址模式。

叁 · 体纹理 Volume Texture
==========================

三维纹理（3D texture），即体纹理（volume texture），是传统二维纹理（2D
texture）在逻辑上的扩展。二维纹理是一张简单的位图图片，用于为三维模型提供表面点的颜色值；而一个三维纹理，可以被认为由很多张
2D 纹理组成，用于描述三维空间数据的图片。三维纹理通过三维纹理坐标进行访问 。

虽然体纹理具有更高的储存要求，并且滤波成本更高，但它们具有一些独特的优势：

-   使用体纹理，可以跳过为三维网格确定良好二维参数的复杂过程，因为三维位置可以直接用作纹理坐标，从而避免了二维参数化中通常会发生的变形和接缝问题。

-   体纹理也可用于表示诸如木材或大理石的材料的体积结构。使用三维纹理实现出的这些模型，看起来会很逼真，浑然天成。

劣势：

-   使用体纹理作为表面纹理会非常低效，因为三维纹理中的绝大多数样本都没起到作用。

肆 · 立方体贴图 Cube Map
========================

立方体纹理（cube texture）或立方体贴图（cube
map）是一种特殊的纹理技术，它用6幅二维纹理图像构成一个以原点为中心的纹理立方体，这每个2D纹理是一个立方体（cube）的一个面。对于每个片段，纹理坐标(s,
t, r)被当作方向向量看待，每个纹素(texel)都表示从原点所看到的纹理立方体上的图像。

![](media/0901f5e80743db1f3726721b18d35f8e.jpg)

图8 Cube Map图示1

![](media/79a41fe0cc8285c3dbc8f131478cec3c.jpg)

图9 Cube Map图示2

可以使用三分量纹理坐标向量来访问立方体贴图中的数据，该矢量指定了从立方体中心向外指向的光线的方向。选择具有最大绝对值的纹理坐标对应的相应的面。（例如：对于给定的矢量(−3.2,
5.1, −8.4)，就选择-Z面），而对剩下的两个坐标除以最大绝对值坐标的绝对值，即8.4。
那么就将剩下的两个坐标的范围转换到了-1到1，然后重映射到[0，1]范围，以方便纹理坐标的计算。例如，坐标（-3.2,5.1）映射到（（-3.2
/ 8.4 + 1）/ 2，（5.1/ 8.4 + 1）/ 2）≈（0.31,0.80）。

立方体贴图支持双线性滤波以及mip
mapping，但问题可以可能会在贴图接缝处出现。有一些处理立方体贴图专业的工具在滤波时考虑到了可能的各种因素，如ATI公司的CubeMapGen，采用来自其他面的相邻样本创建mipmap链，并考虑每个纹素的角度范围，可以得到比较不错的效果。如图10。

![](media/a2212a157a050314a80c12be9d5676a8.jpg)

图10 立方体贴图过滤。最左边两个图像使用2 x 2和4 x
4的立方体贴图的纹理层次，采用标准立方体贴图生成mipmap链。因接缝显而易见，除了极端细化的情况，这些mipmap级别并不可用。两个最右边的图像使用相同分辨率的mipmap级别，通过在立方体面和采用角度范围进行采样生成。
由于没有接缝，不易失真，这些mipmap甚至可以用于显示在很大的屏幕区域的对象。

伍 · 纹理缓存 Texture Caching
=============================

一个复杂的应用程序可能需要相当数量的纹理。快速纹理存储器的数量因系统而异，但你会发现它们永远不够用。有各种各样的纹理缓存（texture
caching）技术，但我们一直在上传纹理到内存的开销和纹理单次消耗的内存量之间寻求一个好的平衡点。比如，一个由纹理贴图的多边形对象，初始化在离相机很远的位置，程序也许会只加载mipmap中更小的子纹理，就可以很完美的完成这个对象的显示了。

一些基本的建议是——保持纹理在不需要放大再用的前提下尽可能小，并尝试基于多边形将纹理分组。即便所有纹理都一直存储在内存中，这种预防措施也可能会提高处理器的缓存性能。

以下是一些常见的纹理缓存使用策略。

5.1 最近最少使用策略（Least Recently Used ,LRU）
------------------------------------------------

最近最少使用（Least Recently Used
,LRU）策略是纹理缓存方案中常用的一种策略，其作用如下。加载到图形加速器的内存中的每个纹理都被给出一个时间戳，用于最后一次访问以渲染图像时。当需要空间来加载新的纹理时，首先卸载最旧时间戳的纹理。一些API还允许为每个纹理设置一个优先级：如果两个纹理的时间戳相同，则优先级较低的纹理首先被卸载。
设置优先级可以帮助避免不必要的纹理交换。

5.2 最近最常使用策略（Most Recently Used，MRU）
-----------------------------------------------

如果开发自己的纹理管理器，Carmack（就是那个游戏界大名鼎鼎的卡马克）提出了一种非常有用的策略，也就是对交换出缓冲器的纹理进行核查
[具体可见原书参考文献374]。大概思想是这样：鉴于如果在当前帧中载入纹理，会发生抖动（Thrashing）的情况。这种情况下，LRU策略是一种非常不好的策略，因为在每帧画面中会对每张纹理图像进行交换。在这种情况下，可以采用最近最常使用（Most
Recently Used，MRU）策略，直到在画面中没有纹理交换时为止，再然后切换回LRU。

5.3 预取策略（Prefetching）
---------------------------

加载纹理花费显着的时间，特别是在需将纹理转换为硬件原生格式时。
纹理加载在每个框架可以有很大的不同。在单个帧中加载大量纹理使得难以保持恒定的帧速率。一种解决方案是使用预取（prefetching），在将来需要预期的情况下，预计未来的需求然后加载纹理，将加载过程分摊在多帧中。

5.4 裁剪图策略（Clipmap）
-------------------------

对于飞行模拟和地型模拟系统，图像数据集可能会非常巨大。传统的方法是将这些图像分解成更小的硬件可以处理的瓦片地图（tiles）。Tanner等人提出了一种一种称为裁剪图（clipmap）的改进数据结构。其思想是，将整个数据集视为一个mipmap，但是对于任何特定视图，只需要mipmap的较低级别的一小部分即可。支持DirectX
10的GPU就能够实现clipmap技术。用这种技术制作的图像如图11所示。

![](media/91c18142dd3b12f74945cf191ea0ae07.jpg)

图11
高分辨率地形图访问海量图像数据库。使用clipmapp技术可以减少在同一时间所需数据量。

陆 · 纹理压缩 Texture Compression
=================================

直接解决内存和带宽问题和缓存问题的一个解决方案是固定速率纹理压缩（Fixed-rate
Texture
Compression）。通过硬件解码压缩纹理，纹理可以需要更少的纹理内存，从而增加有效的高速缓存大小。至少这样的纹理使用起来更高效，因为他们在访问时消耗更少的内存带宽。

有多种图像压缩方法用于图像文件格式，如JPEG和PNG，但在硬件上对其实现解码会非常昂贵。S3公司开发一种名为S3纹理压缩（S3
Texture
Compression，S3TC）的方法，目前已经被选为DirectX中的标准压缩模式，称为DXTC。在DirectX
10中，这种方法称为BC (Block
Compression)。其优点是创建了一个固定大小，具有独立的编码片段，并且解码简单，同时速度也很快。每个压缩部分的图像可以独立处理，没有共享查找表（look-up
tables）或其他依赖关系，这同样地简化了解码过程。

还有几种S3/DXTC/BC压缩方案的变种存在，他们有一些共同的特征。把纹理按4x4个单元（纹素）大小划分为块。每个块对应一张四色查找表，表中存有两个标准RGB565格式表示的16位颜色，另外使用标准插入算法在插入两个新的颜色值，由此构成四色查找表。4x4大小的纹理块中每个单元（像素点）用两个bit表示，每一个都代表四色查找表中的一种颜色。可以看出，实质上是利用每个单元（像素点）中的两个bit来索引四色查找表中的颜色值。

这些压缩技术可以应用于立方体或体积图，以及二维纹理。而其主要缺点是它们是有损的压缩。
也就是说，原始图像通常不能从压缩版本检索。
仅使用四个或八个内插值来表示16个像素。
如果一个瓦片贴图有更大的数值，相较压缩前就会有一些损失。
在实践中，如果正常使用这些压缩方案，一般需给出可接受的图像保真度。

DXTC的一个问题是用于块的所有颜色都位于RGB空间的直线上。例如，DXTC不能在一个块中同时表示红色，绿色和蓝色。

下面对几种不同纹理压缩变体(S3/DXTC/BC以及ETC)在编码上的异同点分节概述。

6.1 DXT1
--------

DXT1（DirectX 9.0）或BC1（DirectX 10.0及更高版本） -
每个块具有两个16位参考RGB值（5位红，6绿，5蓝）的纹素，而每个纹素具有2位插值因子，以便从一个参考值或两个中间值之间选择。DXT1作为五种变体中最精简的版本，块占用为8个字节，即每个纹素占用4位。
与未压缩的24位RGB纹理相比，有着6：1的纹理压缩率。

6.2 DXT3
--------

DXT3（DirectX 9.0）或BC2（DirectX 10.0及更高版本） -
每个块都具有与DXT1块相同的RGB数据编码。另外，每个纹素都具有单独存储4位alpha值（这是唯一的直接存储数据的形式，而不是用插值的形式）。DXT3块占用16个字节，或每个纹理元素8位。与未压缩的32位RGBA纹理相比，有着4：1的纹理压缩率。

6.3 DXT5
--------

DXT5（DirectX 9.0）或BC3（DirectX 10.0及更高版本） -
每个块都具有与DXT1块相同的RGB数据编码。此外，alpha数据使用两个8位参考值和一个每纹素3位的插值因子进行编码。每个纹素可以选择参考alpha值之一或六个中间值之一作为其值。DXT5块具有与DXT3块相同的存储要求，也就是DXT3块占用16个字节，即每个纹理元素8位。与未压缩的32位RGBA纹理相比，有着4：1的纹理压缩率。

6.4 ATI1
--------

ATI1（ATI公司的特定扩展名）或BC4（DirectX 10.0及更高版本）-
每个块存储单个颜色的数据通道，以与DXT5中的alpha数据相同的方式进行编码。
BC4块占用8个字节，即每个纹素占用4位。与未压缩的8位单通道纹理相比，有着4：1的纹理压缩率。仅在较新的ATI的硬件或任意供应商的DirectX
10.0硬件上才支持此格式。

6.5 ATI2
--------

ATI2（ATI公司的特定扩展名，也称为3Dc）或BC5（DirectX10.0及更高版本） -
每个块存储两个颜色通道的数据，以与BC4块或DXT5中的alpha数据相同的方式进行编码。
BC5块占用16个字节，即每个纹理元素8位。与未压缩的16位双通道纹理相比，有着4：1的纹理压缩率。也仅在较新的ATI的硬件或任意供应商的DirectX
10.0硬件上才支持此格式。

6.6 ETC
-------

对于OpenGL ES，选择了另一种称为ETC（Ericsson texture
compression，ETC）的压缩算法。方案与S3TC具有相同的特点，即快速解码，随机访问，无间接查找，速率固定。ETC算法将4×4纹素的块编码为64位，即每个纹理元素4位。基本思想如图12所示。

![](media/5328d31a4a96c7dbbb6404e63edd8c60.jpg)

图12 ETC算法对像素块的颜色进行编码，然后修改每像素的亮度以创建最终的纹理颜色

每个2×4块（或4×2，取决于哪个质量更佳）存储基本颜色。每个块还从一个小的静态查找表中选择一组四个常量，并且块中的每个纹素可以选择在选定的查找表中添加一个值，添加的这个值就可以是每像素的亮度。

也可以这样理解：ETC压缩算法将图像中的chromatic和luminance分开存储的方式，而在解码时使用luminance对chromatic进行调制进而重现原始图像信息。

两个要点：

-   ETC的图片压缩的质量和DXTC相当。

-   ETC也主要有两种方法：ETC1和改进后的ETC2。

柒 · 程序贴图纹理 Procedural Texturing
======================================

程序贴图纹理（Procedural
Texturing，也可译为过程纹理）是用计算机算法生成的，旨在创建用于纹理映射的自然元素（例如木材，大理石，花岗岩，金属，石头等）的真实表面或三维物体而创建的纹理图像。通常，会使用分形噪声（fractal
noise）和湍流扰动函数（turbulence
functions）这类“随机性”的函数来生成程序贴图纹理。

给定纹理空间位置，进行图像查找是生成纹理值的一种方法。另一种方法是对函数进行求值，从而得到一个程序贴图纹理（procedural
texture）。

过程纹理主要用于模拟自然界中常见的Marble,Stone,Wood,Cloud等纹理。大多数的过程纹理都是基于某类噪声函数（Noise
Function），比如说perlin
noise。在过去，由于过程纹理计算量很大，在实时绘制中很少使用。但是GPU的出现，促进了过程纹理在实时渲染中的广泛应用。

![](media/56cfe82825fcd9e0a4ae51b55fe2c685.jpg)

图13 程序贴图纹理示例

程序贴图纹理通常用于离线渲染应用程序，而图像纹理在实时渲染中更为常见。这是由于在现代GPU中的图像纹理硬件有着极高效率，其可以在一秒钟内执行数十亿个纹理访问。然而，GPU架构正在朝着更便宜的计算能力和（相对）更昂贵的存储器访问而发展。这将使程序纹理在实时应用程序中更常见，尽管它们不可能完全替代图像纹理。

考虑到体积图像纹理的高存储成本，体积纹理是用于程序贴图纹理是一项特别有吸引力的应用。这样的纹理可以通过各种技术来合成，最常见的是使用一个或多个噪声函数来产生纹理的值。

捌 · 凹凸贴图与其改进
=====================

凹凸贴图（Bump Mapping）思想最早是由图形学届大牛中的大牛Jim
Blinn提出，后来的Normal Mapping，Parallax Mapping，Parallax Occulision
Mapping，Relief
Mapping等等，均是基于同样的思想，只是考虑得越来越全面，效果也越来越逼真。

以下是几种凹凸贴图与其改进方法的总结对比。

![](media/8c4927fb74b7eefefffaf694165e897f.jpg)

除了Displacement
Mapping方法以外，其他的几种改进一般都是通过修改每像素着色方程来实现，关键思想是访问纹理来修改表面的法线，而不是改变光照方程中的颜色分量。物体表面的几何法线保持不变，我们修改的只是照明方程中使用的法线值。他们比单独的纹理有更好的三维感官，但是显然还是比不上实际的三维几何体。

以下是各个方法分别的原理和特性说明。

8.1 凹凸贴图 Bump Mapping
-------------------------

凹凸贴图是指计算机图形学中在三维环境中通过纹理方法来产生表面凹凸不平的视觉效果。它主要的原理是通过改变表面光照方程的法线，而不是表面的几何法线，或对每个待渲染的像素在计算照明之前都要加上一个从高度图中找到的扰动，来模拟凹凸不平的视觉特征，如褶皱、波浪等等。

Blinn于1978年提出了凹凸贴图方法。使用凹凸贴图，是为了给光滑的平面，在不增加顶点的情况下，增加一些凹凸的变化。他的原理是通过法向量的变化，来产生光影的变化，从而产生凹凸感。实际上并没有顶点（即Geometry）的变化。

表示凹凸效果的另一种方法是使用高度图来修改表面法线的方向。每个单色纹理值代表一个高度，所以在纹理中，白色表示高高度区域，黑色是低高度的区域（反之亦然）。示例如图14。

![](media/be5694fdb910baaee86443c367637baa.jpg)

图14 波浪高度凹凸贴图以及其在材质上的使用

8.2 移位贴图 Displacement Mapping
---------------------------------

Displacement
Mapping，移位贴图，也有人称为置换贴图，或称高度纹理贴图（Heightfield
Texturing）。这种方法类似于法线贴图，移位贴图的每一个纹素中存储了一个向量，这个向量代表了对应顶点的位移。注意，此处的纹素并不是与像素一一对应，而是与顶点一一对应，因此，纹理的纹素个数与网格的顶点个数是相等的。在VS阶段，获取每个顶点对应的纹素中的位移向量，（注意，直到3.0版本的vs才支持纹理数据的获取，之前的版本只有ps才能获取纹理数据），施加到局部坐标系下的顶点上，然后进行世界视点投影变换即可。

8.3 法线贴图 Normal Mapping
---------------------------

法线贴图（Normal mapping）是凸凹贴图（Bump
mapping）技术的一种应用，法线贴图有时也称为“Dot3（仿立体）凸凹纹理贴图”。凸凹与纹理贴图通常是在现有的模型法线添加扰动不同，法线贴图要完全更新法线。与凸凹贴图类似的是，它也是用来在不增加多边形的情况下在浓淡效果中添加细节。但是凸凹贴图通常根据一个单独的灰度图像通道进行计算，而法线贴图的数据源图像通常是从更加细致版本的物体得到的多通道图像，即红、绿、蓝通道都是作为一个单独的颜色对待。

简单来说，Normal
Map直接将正确的Normal值保存到一张纹理中去，那么在使用的时候直接从贴图中取即可。

![](media/5db77f3bbf99ddb84653ee9f8a5f050f.jpg)

图15 基于法线贴图的凹凸映射，每个颜色通道实际上是表面法线坐标。红色通道是x偏差;
红色越多，正常点越多。 绿色是y偏差，蓝色是z。 右边是使用法线贴图生成的图像。
请注意立方体顶部的扁平外观。

8.4 视差贴图 Parallax Mapping

视差贴图Parallax Mapping，又称为 Offset Mapping，以及virtual displacement
mapping)，于2001年由Kaneko引入，由Welsh进行了改进和推广。视差贴图是一种改进的Bump
Mapping技术，相较于普通的凹凸贴图，视差贴图技术得到凹凸效果得会更具真实感（如石墙的纹理将有更明显的深度）。视差贴图是通过替换渲染多边形上的顶点处的纹理坐标来实现的，而这个替换依赖于一个关于切线空间中的视角（相对于表面法线的角度）和在该点上的高度图的方程。简单来说，Parallax
Mapping利用Height Map进行了近似的Texture Offset。如图 6.32。

![](media/b80392a4d895922f5830146cff602441.jpg)

图16 视差贴图

8.5 浮雕贴图 Relief Mapping
---------------------------

关于浮雕贴图（Relief Mapping），有人把它誉为凹凸贴图的极致。我们知道，Parallax
Mapping是针对Normal Mapping的改进，利用HeightMap进行了近似的Texture
Offset。而Relief Mapping是精确的Texture Offset，所以在表现力上比较完美。

![](media/f57596a5bb2148f8507fadf29895771a.jpg)

图17 法线贴图和浮雕贴图的对比。法线贴图不发生自遮挡。

![](media/3f496d9129c865d4aa9242c7b61f75dd.jpg)

图18 相较于视差贴图（左），浮雕贴图（右）可以实现更深的凹凸深度。

Parallax Mapping能够提供比Bump
Mapping更多的深度,尤其相比于小视角下,但是如果想提供更深的深度,Parallax
Mapping就无能为力了，Relief Mapping则可以很好的胜任。相较于Parallax
Mapping，浮雕贴图（Relief
Mapping）可以实现更深的凹凸深度。浮雕贴图方法不仅更容易提供更深的深度,还可以做出自阴影和闭塞效果,当然算法也稍稍有点复杂，具体细节可以参考这篇中文文献：[Relief
mapping:凹凸贴图的极致](https://link.zhihu.com/?target=http%3A//www.ixueshu.com/document/3dc4369a761ca0d6318947a18e7f9386.html)，而如果要用一句话概括Relief
Mapping，将会是：“在Shader里做光线追踪”。

![](media/b963123671d07272fffb9dfccd73a957.jpg)

图19 浮雕贴图，使石块看起来更逼真

玖·其他参考
===========

[1] [Learn OpenGL, extensive tutorial resource for learning Modern
OpenGL](https://link.zhihu.com/?target=https%3A//learnopengl.com/%23%21Advanced-OpenGL/Cubemaps)

[2] [体绘制（Volume
Rendering）概述](https://link.zhihu.com/?target=http%3A//blog.csdn.net/pizi0475/article/details/6650855)

[3] [几种主流贴图压缩算法的实现原理 - BugRunner的专栏 - 博客频道 -
CSDN.NET](https://link.zhihu.com/?target=http%3A//blog.csdn.net/bugrunner/article/details/50538770)

[4] [过程纹理(Procedural Texture) [2005-11-20
update]](https://link.zhihu.com/?target=http%3A//www.cnblogs.com/szlongman/archive/2005/11/17/278955.html)

[5] [https://zh.wikipedia.org/wiki/%E6%B3%95%E7%BA%BF%E8%B4%B4%E5%9B%BE](https://link.zhihu.com/?target=https%3A//zh.wikipedia.org/wiki/%25E6%25B3%2595%25E7%25BA%25BF%25E8%25B4%25B4%25E5%259B%25BE)

[6] [Relief
mapping:凹凸贴图的极致](https://link.zhihu.com/?target=http%3A//www.ixueshu.com/document/3dc4369a761ca0d6318947a18e7f9386.html)

[7] [Bump Mapping综述 - Just a Programer -
博客园](https://link.zhihu.com/?target=http%3A//www.cnblogs.com/cxrs/archive/2009/11/22/1608086.html)

```

`Content/《Real-Time Rendering 3rd》读书笔记/Content/BlogPost06/README.md`:

```md

![](media/title.jpg)


# 【《Real-Time Rendering 3rd》 提炼总结】(六) 第七章 · 高级着色：BRDF及相关技术

在计算机图形学中，BRDF（Bidirectional Reflectance Distribution
Function，双向反射分布函数）是真实感图形学中最核心的概念之一，它描述的是物体表面将光能从任何一个入射方向反射到任何一个视点方向的反射特性，即入射光线经过某个表面反射后如何在各个出射方向上分布。BRDF模型是绝大多数图形学算法中用于描述光反射现象的基本模型。

这篇文章，将专注于总结和提炼《Real-Time Rendering
3rd》（实时渲染图形学第三版）中第七章“Advanced Shading ·
高级着色”的内容，并对这章中介绍BRDF的内容进行适当补充和引申，构成全文，成为一个对BRDF进行近乎系统式总结的文章。

![](media/10ab01213dba8ed11f44985e84f2683e.jpg)

图1 基于BRDF渲染的场景图 ©Disney 2014.《超能陆战队》

一、导读
========

简而言之，通过阅读这篇总结式文章，你将对BRDF的以下要点有所了解：

-   一、BRDF的前置知识 · 数学篇

    -   球面坐标 Spherical Coordinate

    -   立体角 Solid Angle

    -   投影面积 Foreshortened Area

-   二、BRDF前置知识 · 辐射度量学篇

    -   辐射度量学基本参数表格

    -   辐射通量/光通量 Radiant Flux

    -   辐射强度/发光强度 Radiant Intensity

    -   辐射率/光亮度 Radiance

    -   辐照度/辉度 Irradiance

-   三、BRDF的定义与理解

    -   BRDF的定义式

    -   BRDF的非微分形式

    -   BRDF与着色方程

    -   BRDF的可视化表示

-   四、BRDF的性质

    -   亥姆霍兹光路可逆性

    -   能量守恒性质

    -   线性特征

-   五、BRDF模型的分类

    -   BRDF经验模型

    -   数据驱动的BRDF模型

    -   基于物理的BRDF模型

-   六、基于物理的BRDF · 前置知识

    -   次表面散射 Subsurface Scattering

    -   菲涅尔反射 Fresnel Reflectance

    -   微平面理论 Microfacet Theory

-   七、基于物理的BRDF · 常见模型

    -   Cook-Torrance BRDF模型

    -   Ward BRDF模型

-   八、BRDF与其引申

    -   BSSRDF

    -   SBRDF(SVBRDF)

    -   BTDF与BSDF

二 、BRDF前置知识· 数学篇
=========================

在正式了解BRDF的概念之前，有必要先了解数学和辐射度量学相关的前置基础知识。

2.1 球面坐标 SphericalCoordinate
--------------------------------

由于光线主要是通过方向来表达，通常用球面坐标表达它们比用笛卡尔坐标系更方便。

如图，球面坐标中的向量用三个元素来指定：

![](media/bca8b01eb43dacb1beddeeb548b910bb.jpg)

图2 球面坐标

其中：

-   r表示向量的长度

-   θ表示向量和Z轴的夹角

-   Φ表示向量在x-y平面上的投影和x轴的逆时针夹角。

2.2 立体角 Solid Angle
----------------------

立体角描述了从原点向一个球面区域张成的视野大小，可以看成是弧度的三维扩展。

![](media/5ff50dbf74077e2f704a812d67473940.jpg)

图3 立体角

我们知道弧度是度量二维角度的量，等于角度在单位圆上对应的弧长，单位圆的周长是2π，所以整个圆对应的弧度也是2π
。立体角则是度量三维角度的量，用符号Ω表示，单位为立体弧度（也叫球面度，Steradian，简写为sr），等于立体角在单位球上对应的区域的面积（实际上也就是在任意半径的球上的面积除以半径的平方ω=
s/r2 ），单位球的表面积是4π ，所以整个球面的立体角也是4π 。

![](media/4f72f91f846b5a51b5daf31155dc96be.jpg)

图4 立体角

立体角ω有如下微分形式：
<div  align="center"> 
 <img src="media/5.jpg" width = "122" height = "71" alt="name" align=center />
</div>
其中*dA*为面积微元。而面积微元*dA*在球面坐标系下可以写成：
<div  align="center">   
 <img src="media/6.jpg" width = "350" height = "41" alt="name" align=center />
</div>
因此：
<div  align="center">   
 <img src="media/7.jpg" width = "220" height = "58" alt="name" align=center />
</div>

2.3 投影面积 Foreshortened Area
-------------------------------

投影面积描述了一个物体表面的微小区域在某个视线方向上的可见面积。

对于面积微元A，则沿着与法向夹角为θ方向的A的可见面积为：

<div  align="center">    
 <img src="media/8.jpg" width = "182" height = "47" alt="name" align=center />
</div>

![](media/66e11d2f41165001d2bbb09ae9d4ca15.jpg)

图5 投影面积


三、BRDF前置知识· 辐射度量学篇
==============================

3.1 辐射度量学基本参数表格
--------------------------

如下是截取的wiki（[https://en.wikipedia.org/wiki/Radiometry](http://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Radiometry))）上的辐射度量学国际单位制的辐射量参数表格：

![](media/51b29f898497fa2e2a7d70bd6545e8b8.jpg)

下面对几个核心的基本量进行分别介绍。

3.2 辐射通量/光通量 Radiant Flux
--------------------------------

辐射通量（Radiant
Flux，又译作光通量，辐射功率）描述的是在单位时间穿过截面的光能，或每单位时间的辐射能量，通常用Φ来表示，单位是W，瓦特。
<div  align="center">    
 <img src="media/11.jpg" height = "70" alt="name" align=center />
</div>


其中的Q表示辐射能(Radiant energy)，单位是J，焦耳。

3.3 辐射强度/发光强度 Radiant Intensity
---------------------------------------

对一个点（比如说点光源）来说，辐射强度表示每单位立体角的辐射通量，用符号I表示，单位  ：


<div  align="center">    
 <img src="media/12.jpg" height = "76" alt="name" align=center />
</div>

概括一下：辐射强度(Radiant
intensity，又译作发光强度)，表示每单位立体角的辐射通量，通常用符号I表示，单位  ，瓦特每球面度。

3.4 辐射率/光亮度 Radiance
--------------------------

辐射率（Radiance，又译作光亮度，用符号L表示）,表示物体表面沿某一方向的明亮程度，它等于每单位投影面积和单位立体角上的辐射通量，单位是W·sr−1·m−2，瓦特每球面度每平方米。在光学中，光源的辐射率，是描述非点光源时光源单位面积强度的物理量，定义为在指定方向上的单位立体角和垂直此方向的单位面积上的辐射通量。光亮度L也可以理解为发光程度I在表面dA上的积分。

一种直观的辐射率的理解方法是：将辐射率理解为物体表面的微面元所接收的来自于某方向光源的单位面积的光通量，因此截面选用垂直于该方向的截面，其面积按阴影面积技术计算。

辐射率的微分形式：
<div  align="center">    
<img src="media/13.jpg" height = "90" alt="name" align=center />
</div>


其中：Φ是辐射通量，单位瓦特（W）；Ω是立体角，单位球面度（sr）。

另外需要注意的是，辐射率使用物体表面沿目标方向上的投影面积，而不是面积。

概括一下：辐射率（Radiance，又译作光亮度），表示每单位立体角每单位投影面积的辐射通量，通常用符号L表示,单位是  ，瓦特每球面度每平方米。

3.5 辐照度/辉度 Irradiance
--------------------------

辐照度（Irradiance，又译作辉度，辐射照度，用符号E表示），指入射表面的辐射通量，即单位时间内到达单位面积的辐射通量，或到达单位面积的辐射通量，也就是辐射通量对于面积的密度，

用符号E表示，单位  ，瓦特每平方米。

辐照度可以写成辐射率（Radiance）在入射光所形成的半球上的积分：
<div  align="center">    
<img src="media/14.jpg" height = "70" alt="name" align=center />
</div>

其中，Ω是入射光所形成的半球。L(ω)是沿ω方向的光亮度。

概括一下：辐照度（Irradiance，又译作辉度，辐射照度），表示单位时间内到达单位面积的辐射通量，也就是辐射通量对于面积的密度，通常用符号E表示，单位  ，瓦特每平方米。

四、BRDF的定义与理解
====================

4.1 BRDF的定义式
----------------

可以将给一个表面着色的过程，理解为给定入射的光线数量和方向，计算出指定方向的出射光亮度（radiance）。，在计算机图形学领域，BRDF
（Bidirectional Reflectance Distribution Function，译作双向反射分布函数
)是一个用来描述表面如何反射光线的方程。顾名思义，BRDF就是一个描述光如何从给定的两个方向（入射光方向l和出射方向v）在表面进行反射的函数。

BRDF的精确定义是出射辐射率的微分（differential outgoing
radiance）和入射辐照度的微分（differential incoming irradiance）之比：
<div  align="center">    
<img src="media/15.jpg" height = "70" alt="name" align=center />
</div>

要理解这个方程的含义，可以想象一个表面被一个来自围绕着角度**l**的微立体角的入射光照亮，而这个光照效果由表面的辉度dE来决定。

表面会反射此入射光到很多不同的方向，在给定的任意出射方向v，光亮度dLo与辐照度dE成一个比例。而两者之间的这个取决于l和v的比例，就是BRDF。

![](media/86a26c1f917c5730b32f223fa7bf33b9.jpg)

图6 BRDF图示

一个最常见的疑问是，BRDF为什么要取这样的定义。BRDF为什么被定义为辐射率（radiance）和辐照度（irradiance）之比，而不是radiance和radiance之比，或者irradiance和irradiance之比呢？

首先，我们分别重温它们的定义：

-   辐照度（Irradiance，又译作辉度，辐射照度），表示单位时间内到达单位面积的辐射通量，也就是辐射通量对于面积的密度，通常用符号E表示，单位  ，瓦特每平方米。

-   辐射率（Radiance，又译作光亮度），表示每单位立体角每单位投影面积的辐射通量，通常用符号L表示,单位是  ，瓦特每球面度每平方米。

那么，关于这个问题，我们可以这样理解：因为照射到入射点的不同方向的光，都可能从指定的反射方向出射，所以当考虑入射时，需要对面积进行积分。而辐照度irradiance正好表示单位时间内到达单位面积的辐射通量。所以BRDF函数，选取入射时的辐照度Irradiance，和出射时的辐射率Radiance，可以简单明了地描述出入射光线经过某个表面反射后如何在各个出射方向上分布。而直观来说，BRDF的值给定了入射方向和出射方向能量的相对量。

概括一下：BRDF（Bidirectional Reflectance Distribution
Function，译作双向反射分布函数 )，定义为出射辐射率的微分（differential outgoing
radiance）和入射辐照度的微分（differential incoming
irradiance）之比，描述了入射光线经过某个表面反射后如何在各个出射方向上分布，给定了入射方向和出射方向能量的相对量，单位是  ，每球面度。

4.2 BRDF的非微分形式
--------------------

这里的讨论仅限于非区域光源，如点光源或方向光源。在这种情况下，BRDF定义可以用非微分形式表示：

<div  align="center">    
<img src="media/17.jpg" height = "70" alt="name" align=center />
</div>

其中：

-   EL是光源在垂直于光的方向向量L平面测量的辐照度（irradiance）。

-   Lo（v）是在视图矢量v的方向上产生的出射辐射率（radiance）。

4.3 BRDF与着色方程
------------------

根据上文所了解了BRDF的定义，现在，就很容易得到BRDF是如何用n个非区域光来拟合一般的着色方程的：

<div  align="center">    
<img src="media/18.jpg" height = "70" alt="name" align=center />
</div>

其中k是每个光源的索引。使用⊗符号（分段向量乘法），是因为BRDF和辉度（irradiance）都是RGB向量。考虑到入射和出射方向都拥有两个自由度（通常参数化是使用两个角度：相对于表面法线的仰角θ和关于法线的旋转角度*φ*），一般情况下，BRDF是拥有四个标量变量的函数。

另外，各向同性BRDFs（Isotropic
BRDFs）是一个重要的特殊情况。这样的BRDF在输入和输入方向围绕表面法线变化（保持相同的相对夹角）时保持不变。所以，各向同性BRDF是关于三个标量的函数。

4.4 对BRDF的可视化表示
----------------------

一种理解BRDF的方法就是在输入方向保持恒定的情况下对它进行可视化表示，如下图。对于给定方向的入射光来说，图中显示了出射光的能力分布：在交点附近球形部分是漫反射分量，因此出射光来任何方向上的反射概率相等。椭圆部分是一个反射波瓣（Reflectance
Lobe）。它形成了镜面分量。显然，这些波瓣位于入射光的反射方向上，波瓣厚度对应反射的模糊性。根据互易原理，可以将这些相同的可视化形成认为是每个不同入射光方向对单个出射方向的贡献量大小。

![](media/897dc5430a09096c357353c16f6672e5.jpg)

图7 BRDF的可视化表示

五、BRDF的性质
==============

5.1 可逆性
----------

BRDF的可逆性源自于亥姆霍兹光路可逆性（Helmholtz Recoprpcity Rule）。

BRDF的可逆性即，交换入射光与反射光，并不会改变BRDF的值：
<br>
<br>
<div  align="center">    
<img src="media/19.1.gif" height = "25" alt="name" align=center />
</div>

5.2 能量守恒性质
----------------

BRDF需要遵循能量守恒定律。能量守恒定律指出：入射光的能量与出射光能量总能量应该相等。能量守恒方程如下：
<div  align="center">    
<img src="media/20.jpg" height = "45" alt="name" align=center />
</div>
由此可知：

<div  align="center">    
<img src="media/21.jpg" height = "45" alt="name" align=center />
</div>
因此BRDF必须满足如下的积分不等式，也就是能量守恒性质：
<div  align="center">    
<img src="media/22.1.png" height = "55" alt="name" align=center />
</div>


5.3 线性特征
------------

很多时候，材质往往需要多重BRDF计算以实现其反射特性。表面上某一点的全部反射辐射度可以简单地表示为各BRDF反射辐射度之和。例如，镜面漫反射即可通过多重BRDF计算加以实现。

六、BRDF的模型分类
==================

根据BRDF的定义来直接应用，会有一些无从下手的感觉。而为了方便和高效地使用BRDF数据，大家往往将BRDF组织成为各种参数化的数值模型。

有各式各样的BRDF模型，如：

-   Phong (1975)

-   Blinn-Phong (1977)

-   Cook-Torrance (1981)

-   Ward (1992)

-   Oren-Nayar (1994)

-   Schlick (1994)

-   Modified-Phong (Lafortune 1994)

-   Lafortune (1997)

-   Neumann-Neumann (1999)

-   Albedo pump-up (Neumann-Neumann 1999)

-   Ashikhmin-Shirley (2000)

-   Kelemen (2001)

-   Halfway Vector Disk (Edwards 2006)

-   GGX (Walter 2007)

-   Distribution-based BRDF (Ashikmin 2007)

-   Kurt (2010)

-   etc.

这些BRDF的模型可以分为如下几类：

-   经验模型（Empirical Models）：使用基于实验提出的公式对BRDF做快速估计。

-   数据驱动的模型（Data-driven
    Models）：采集真实材质表面在不同光照角度和观察角将BRDF按照实测数据建立查找表，记录在数据库中，以便于快速的查找和计算。

-   基于物理的模型（Physical-based
    Models）：根据物体表面材料的几何以及光学属性建立反射方程，从而计算BRDF，实现极具真实感的渲染效果。

6.1 BRDF经验模型
----------------

关于BRDF的经验模型，有如下几个要点：

-   经验模型提供简洁的公式以便于反射光线的快速计算。

-   经验模型不考虑材质特性，仅仅提供一个反射光的粗糙近似。

-   经验模型不一定满足物理定律，比如Helmholtz可逆性或能量守恒定律。

-   经验模型因为其简洁和高效性被广泛运用。

常见的BRDF经验模型有：

-   Lambert漫反射模型

-   Phong模型

-   Blinn-Phong模型

-   快速Phong模型

-   可逆Phong模型

Lambert模型，Phong模型、Blinn-Phong模型和其改进模型都是常见的光照模型，由于篇幅原因，就不展开论述了。


6.2 数据驱动的BRDF模型
----------------------

数据驱动的BRDF模型可以理解为，度量一个大的BRDF材质集合，并将其记录为高维向量，利用降维的方法从这些数据中计算出一个低维模型，这样基于查表的方式，可以直接找到渲染结果，省去大量的实时计算。代表工作如：A
Data-Driven Reflectance Model,ACM
SIGGRAPH,2003 [http://people.csail.mit.edu/wojciech/DDRM/index.html](http://link.zhihu.com/?target=http%3A//people.csail.mit.edu/wojciech/DDRM/index.html)

另外，MERL等实验室使用各类仪器测量了上多种真实材质表面在不同光照角度和观察角度下的反射数据，并记录在数据库中，如MERL
BRDF Database。

![](media/b10e282149a8d128616c43622d591511.jpg)

图8 一个名为“MERL
100”的BRDF数据库。其中，含50种“光滑材质”（例如金属和塑料），和50种“粗糙材质”（例如纺织物）

需要注意的是，由于这些数据由于采集自真实材质，即便渲染出来的结果很真实，但缺点是没有可供调整效果的参数，无法基于这些数据修改成想要的效果，另外部分极端角度由于仪器限制，无法获取到数据，而且采样点密集，数据量非常庞大，所以并不适合游戏等实时领域，一般可用在电影等离线渲染领域，也可以用来做图形学研究，衡量其他模型的真实程度。

这边提供一些数据库的链接供参考：

-   MERLBRDF
    Database： [http://www.merl.com/brdf/](http://link.zhihu.com/?target=http%3A//www.merl.com/brdf/)

-   MITCSAIL: [http://people.csail.mit.edu/addy/research/brdf/](http://link.zhihu.com/?target=http%3A//people.csail.mit.edu/addy/research/brdf/)

-   CAVE
    Database:[http://www1.cs.columbia.edu/CAVE/databases/tvbrdf/about.php](http://link.zhihu.com/?target=http%3A//www1.cs.columbia.edu/CAVE/databases/tvbrdf/about.php)

6.3 基于物理的BRDF模型
----------------------

基于物理的渲染(PBR, Physically-based
rendering)是计算机图形学中用数学建模的方式模拟物体表面各种材质散射光线的属性从而渲染照片真实图片的技术，是近年来是实时渲染领域的大趋势。

基于物理的BRDF模型通过包含材质的各种几何及光学性质来尽可能精确的近似现实世界中的材料。而一个基于物理的BRDF要必须满足至少如下两条BRDF的特性：能量守恒、亥姆霍兹光路可逆性。

常见的基于物理的BRDF模型有：

-   Cook-Torrance BRDF模型

-   Ward BRDF模型

下文将先介绍基于物理的BRDF常常用到到的菲涅尔反射，次表面散射和微平面理论等理论，分别概括这两种基于物理的BRDF模型。

七、基于物理的BRDF · 前置知识
=============================

7.1 次表面散射 Subsurface Scattering
------------------------------------

在真实世界中许多物体都是半透明的，比如皮肤、玉、蜡、大理石、牛奶等。当光入射到透明或半透明材料表面时，一部分被反射，一部分被吸收，还有一部分经历透射。这些半透明的材质受到数个光源的透射，物体本身就会受到材质的厚度影响而显示出不同的透光性，光线在这些透射部分也可以互相混合、干涉。

次表面散射，Subsurface
Scattering，简称SSS(又简称3S)，就是光射入半透明材质后在内部发生散射，最后射出物体并进入视野中产生的现象，是指光从表面进入物体经过内部散射，然后又通过物体表面的其他顶点出射的光线传递过程。

![](media/1cdecce356f6f3f5f39169ea569cad48.jpg)

图9 次表面散射示例1

![](media/12db40a81c96bfa9d3e553dfba7682a5.jpg)

图10 次表面散射示例2

又如文章开头，贴出的《超能陆战队》中大白的渲染照中，大白的白色身体，略微有些透明的感觉，就是典型的次表面散射。

简而言之：次表面散射，即光射入表面，在材质里散射，然后从与射入点不同的地方射出表面的一种现象。

![](media/6280ca245be9ddec829da28a51589276.jpg)

图11
光与表面的相互作用。左图，可以看到次表面相互作用导致光从入口点重新射出。红色和绿色圆圈代表两个不同尺度下的像素所覆盖的区域。在右边，所有的次表面散射光都是从入口点发出的，忽略了表面之下的细节。

7.2 菲涅尔反射 Fresnel Reflectance
----------------------------------

菲涅耳方程（Fresnel
equations）是一组用于描述光在两种不同折射率的介质中传播时的反射和折射的光学方程。方程中所描述的反射被称作“菲涅耳反射”。

菲涅尔反射（Fresnel Reflectance）或者菲涅尔效果（Fresnel
Effect），即当光入射到折射率不同的两个材质的分界面时，一部分光会被反射，而我们所看到的光线会根据我们的观察角度以不同强度反射的现象。

菲涅尔反射能够真实地模拟真实世界中的反射。在真实世界中，除了金属之外，其它物质均有不同程度的菲涅尔反射效果。

关于菲涅尔反射，一个很好的例子是一池清水。从水池上笔直看下去（也就是与法线成零度角的方向）的话，我们能够一直看到池底。而如果从接近平行于水面的方向看去的话，水池表面的高光反射会变得非常强以至于你看不到池底。

![](media/c1ee1c4ea5e293d9d0ec43ffe6c55c57.jpg)

图12 菲涅尔反射效果

简单来说，视线垂直于表面时，反射较弱，而当视线并非垂直表面时，夹角越小，反射越明显。

对于粗糙表面来说，在接近平行方向的高光反射也会增强但不够达到100%的强度.为何如此是因为影响菲涅尔效应的关键参数在于每个微平面的法向量和入射光线的角度，而不是宏观平面的法向量和入射光线的角度。因此我们在宏观层面看到的实际上是微平面的菲涅尔效应的一个平均结果。

根据菲涅尔反射，若你看向一个圆球，那么圆球中心的反射会较弱，而靠近边缘是反射会较强。另外需注意，这种关系也受折射率影响。

![](media/f39d56cb64eab66f423c5098b2509a1d.jpg)

图13 基于菲涅尔反射，在Unreal Engine 4中实现的边缘光Shader

7.3 微平面理论 Microfacet Theory
--------------------------------

微表面理论假设表面是由不同方向的微小细节表面，也就是微平面（microfacets）组成。每一个微小的平面都会根据它的法线方向在一个方向上反射光线。

表面法线朝向光源方向和视线方向中间的微表面会反射可见光。然而，不是所有的表面法线和半角法线（half
normal）相等的微表面都会反射光线，因为其中有些会被遮挡，如下图所示。

![](media/c83ab9adf0f18f082e0060fb6ac16afd.jpg)

图14 微平面理论图示

我们用法线分布函数（Normal Distribution
Function，简写为NDF），D(h)来描述组成表面一点的所有微表面的法线分布概率。则可以这样理解：向NDF输入一个朝向h，NDF会返回朝向是h的微表面数占微表面总数的比例，比如有8%的微表面朝向是h，那么就有8%的微表面可能将光线反射到v方向。

![](media/fae6d41ba5ea0051c455432f2bc05627.jpg)

图15
由微平面组成的表面。仅红色微平面的表面法线和半矢量h对齐，能参与从入射光线向量l到视线向量v的光线反射

NDF的定义式：
<div  align="center">    
<img src="media/32.jpg" height = "65" alt="name" align=center />
</div>


在微观层面上不规则的表面会造成光的漫反射。例如，模糊的反射是由于光线的散射造成的。而反射的光线并不均匀，因此我们得到的高光反射是模糊的。如下图。

![](media/2e4a602140263296a55d7632b69fb4ae.jpg)

图16 模糊的微平面高光反射

八、基于物理的BRDF · 常见模型
=============================

8.1 Cook-Torrance BRDF模型
--------------------------

Cook-Torrance模型作为图形学中最早的基于物理的BRDF模型，由Cook和Torrance提出，是Torrance-Sparrow模型的一个应用版本。现今，Cook-Torrance模型已经成为基于物理着色的标准模型之一。Cook-Torrance模型将物理学中的菲涅尔反射引入了图形学，实现了比较逼真的效果。

Cook-Torrance微平面着色模型（Cook-Torrance microfacet specular shading
model），即Microfacet Specular BRDF，定义为：

<div  align="center">    
<img src="media/34.jpg" height = "75" alt="name" align=center />
</div>

其中：

-   F为菲涅尔反射函数( Fresnel 函数 )

-   G为阴影遮罩函数（Geometry Factor，几何因子），即未被shadow或mask的比例

-   D为法线分布函数(NDF)

篇幅原因，就不展开论述了，若大家有兴趣，可以参考历年的SIGGRAPH Course:
Physically Based Shading in Theory and Practice系列与其他相关文章。

如SIGGRAPH 2013 Course: Physically Based Shading in Theory and Practice:

[http://blog.selfshadow.com/publications/s2013-shading-course/](http://link.zhihu.com/?target=http%3A//blog.selfshadow.com/publications/s2013-shading-course/)

具体的课程中的两篇推荐：

1.  Background:Physics and Math of
    Shading: [http://blog.selfshadow.com/publications/s2013-shading-course/hoffman/s2013_pbs_physics_math_slides.pdf](http://link.zhihu.com/?target=http%3A//blog.selfshadow.com/publications/s2013-shading-course/hoffman/s2013_pbs_physics_math_slides.pdf)

2.  Physically Based Lighting in Call of Duty: Black Ops
    ：[http://blog.selfshadow.com/publications/s2013-shading-course/lazarov/s2013_pbs_black_ops_2_slides_v2.pdf](http://link.zhihu.com/?target=http%3A//blog.selfshadow.com/publications/s2013-shading-course/lazarov/s2013_pbs_black_ops_2_slides_v2.pdf)

8.2 Ward BRDF模型
-----------------

一般情况下，我们可以将BRDF分为两类：

各项同性（Isotropic）的BRDF

-   反射不受与给定表面法向夹角的约束

-   随机表面微结构

各向异性（Anisotropic）的BRDF

-   反射比随着与某个给定的表面法向之间的夹角而变化

-   图案的表面微结构

-   金属丝，绸缎，毛发等

Phong和Cook-Torrance BRDF模型都不能处理各项异性的效果，Ward模型却可以。

Ward模型由Ward于1992年提出[Measuringand Modeling Anissropic Reflection,ACM
SIGGRAPH,1992]。Ward模型介绍了更一般的表面法向表达方式：通过椭圆体（ellipsoids）这种允许各向异性反射的形式来表达。

然而，由于没有考虑菲涅耳因子（Fresnel factor）和几何衰减因子（geometric
attenuation factor），该模型更像是一种经验模型，但还是属于基于物理的BRDF模型。

各向同性的Ward模型定义为：

<div  align="center">    
<img src="media/35.jpg" height = "75" alt="name" align=center />
</div>



九、BRDF与其引申
================

有不少与BRDF类似的函数：

-   BSSRDF：Bidirectional Surface Scattering Reflectance
    Distribution，双向表面散反射分布函数

-   SBRDF(SVBRDF): spatially varying BRDF(spatial BRDF) 空间BRDF

-   BTDF：Bidirectional Transmittance Distribution Function 双向透射分布函数

-   BSDF : Bidirectional Scattering Distribution Function，双向散射分布函数

下面分别进行介绍。

9.1 BSSRDF
----------

BRDF只是更一般方程的一种近似,这个方程就是BSSRDF（Bidirectional
scattering-surface reflectance distribution
function，双向表面散反射分布函数）。BSSRDF描述了射出辐射率与入射通量之间的关系，BSSRDF函数通过把入射和出射位置作为函数的输入，从而来包含这些现象，它描述了沿入射方向从物体表面的一点到另外一点，最后顺着出射方向出去的光线的相对量。注意，这个函数还考虑了物体表面的一点到另外一点，最好顺着出射方向出去的光线相对量。注意，这个函数还考虑了物体表面不一致的情况，因为随着位置的变化，反射系数也会发生变化。在实时绘制中，物体表面上的位置可以用来获取颜色纹理、光泽度，以及凹凸纹理图等信息。

![](media/398183f217f8be62b6cd386243c485ce.jpg)

图17 BRDF渲染图

![](media/1fb4e0458939444804da12336e640802.jpg)

图18 BSSRDF渲染图

9.2 SBRDF(SVBRDF)
-----------------

一个捕获基于空间位置BRDF变化的函数被称为空间变化的BRDF（Spatially Varying BRDF
,SVBRDF）或称空间BRDF，空间双向反射分布函数（Spatial BRDF ，SBRDF）。

9.3 BTDF与BSDF
--------------

即使一般的BSSRDF函数，无论其多么复杂，仍然忽略了现实世界中非常重要的一些变量，比如说光的偏振。此外，也没有处理穿过物体表面的光线传播，只是对反射情况进行了处理。为了处理光线传播的问题，对物体表面定义了两个BRDF和两个BTDF（T表示传播“Transmittance”），每侧各有一个，这样就组成了BSDF（S表示散射“Scattering”）。

![](media/d084fcee93a2803cf9565f8519099598.jpg)

图19
当用于镜面反射的BRDF和用于镜面透射的BTDF使用菲涅尔公式进行调制渲染时，得到了如真实玻璃视觉上精确的反射和透射的角度变化。来自《Physically
Based Rendering, Third Edition》Figure 8.10

而在实践中，这些更复杂的函数很少使用，BRDF和SVBRDF足以胜任一般情况下表面渲染的效果。

十、其他参考
============

[1] [http://graphics.stanford.edu/\~henrik/images/subsurf.html](http://link.zhihu.com/?target=http%3A//graphics.stanford.edu/%7Ehenrik/images/subsurf.html)

[2] [http://www.scratchapixel.com/lessons/3d-basic-rendering/introduction-to-shading/reflection-refraction-fresnel](http://link.zhihu.com/?target=http%3A//www.scratchapixel.com/lessons/3d-basic-rendering/introduction-to-shading/reflection-refraction-fresnel)

[3] [http://wiki.nuaj.net/index.php?title=BRDF](http://link.zhihu.com/?target=http%3A//wiki.nuaj.net/index.php%3Ftitle%3DBRDF)

[4] [https://www.allegorithmic.com/pbr-guide](http://link.zhihu.com/?target=https%3A//www.allegorithmic.com/pbr-guide)

[5] [http://www.icourses.cn/coursestatic/course_2987.html](http://link.zhihu.com/?target=http%3A//www.icourses.cn/coursestatic/course_2987.html)

[6] [https://docs.unrealengine.com/latest/INT/Engine/Rendering/Materials/HowTo/Fresnel/index.html](http://link.zhihu.com/?target=https%3A//docs.unrealengine.com/latest/INT/Engine/Rendering/Materials/HowTo/Fresnel/index.html)

[7] [https://en.wikipedia.org/wiki/Fresnel_equations](http://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Fresnel_equations)

[8] <https://zhuanlan.zhihu.com/p/21376124>

[9] [https://en.wikipedia.org/wiki/Radiometry](http://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Radiometry)

[10] Real Shading in Unreal Engine
4：[https://cdn2.unrealengine.com/Resources/files/2013SiggraphPresentationsNotes-26915738.pdf](http://link.zhihu.com/?target=https%3A//cdn2.unrealengine.com/Resources/files/2013SiggraphPresentationsNotes-26915738.pdf)

[11] SIGGRAPH 2013 Course: Physically BasedShading in Theory and
Practice：[http://blog.selfshadow.com/publications/s2013-shading-course/](http://link.zhihu.com/?target=http%3A//blog.selfshadow.com/publications/s2013-shading-course/)

[12] Physically Based Rendering, Third Edition

```

`Content/《Real-Time Rendering 3rd》读书笔记/Content/BlogPost07/README.md`:

```md
![](media/title.jpg)

# 【《Real-Time Rendering 3rd》 提炼总结】(七) 第七章续 · 延迟渲染(Deferred Rendering)的前生今世

题图为基于Deferred Rendering技术的渲染效果图。

在计算机图形学中，延迟渲染( Deferred Rendering) ，即延迟着色（Deferred
Shading），是将着色计算延迟到深度测试之后进行处理的一种渲染方法。延迟着色技术的最大的优势就是将光源的数目和场景中物体的数目在复杂度层面上完全分开，能够在渲染拥有成百上千光源的场景的同时依然保持很高的帧率，给我们渲染拥有大量光源的场景提供了很多可能性。

![https://pic4.zhimg.com/50/v2-eed8ec9b0113eb28259bde3020ff1326_hd.jpg](media/fb3e377c948f34d0f85ee7349c0dc15f.jpg)

图1 使用Deferred Rendering方法渲染的多光源场景

在《Real-Time Rendering 3rd》（实时渲染图形学第三版）的第七章“Advanced Shading ·
高级着色”中，除了上篇文章中我们聊到的BRDF，还有Deferred
Shading（延迟着色）这个重要概念我们没有聊到。这篇文章，就主要和大家一起聊一聊Deferred
Shading和它的“前生今世”，以及文末简单提一提第八章“区域和环境光照 Area and
Environmental Lighting”中的Environment
Mapping（环境映射）相关的内容。下篇文章，预计直接开始全局光照（Global
Illumination）的内容。

简而言之，通过阅读这篇文章，你将对以下要点有所了解：

-   延迟着色/延迟渲染的概念 Deferred Shading / Deferred Rendering

-   几何缓冲区 G-buffer

-   延迟渲染的渲染过程

-   延迟渲染 vs 正向渲染

-   延迟渲染的优缺点

-   延迟光照 Light Pre-Pass / Deferred Lighting

-   分块延迟渲染 Tile-Based Deferred Rendering

-   延迟渲染 vs 延迟光照

-   实时渲染中常见的Rendering Path总结

-   环境映射 Environment Mapping

一、延迟渲染 Deferred Rendering
===============================

延迟渲染( Deferred Rendering)，即延迟着色（Deferred
Shading），顾名思义，是将着色计算延后进行处理的一种渲染方法，在2004年的GDC上被正式提出[http://www.tenacioussoftware.com/gdc_2004_deferred_shading.ppt](http://link.zhihu.com/?target=http%3A//www.tenacioussoftware.com/gdc_2004_deferred_shading.ppt)。

我们知道，正向渲染(Forward Rendering)，或称正向着色(Forward
Shading)，是渲染物体的一种非常直接的方式，在场景中我们根据所有光源照亮一个物体，之后再渲染下一个物体，以此类推。

传统的正向渲染思路是，先进行着色，再进行深度测试。其的主要缺点就是光照计算跟场景复杂度和光源个数有很大关系。假设有n个物体，m个光源，且每个每个物体受所有光源的影响，那么复杂度就是O(m\*n)。

正向渲染简单直接，也很容易实现，但是同时它对程序性能的影响也很大，因为对每一个需要渲染的物体，程序都要对每个光源下每一个需要渲染的片段进行迭代，如果旧的片段完全被一些新的片段覆盖，最终无需显示出来，那么其着色计算花费的时间就完全浪费掉了。

而延迟渲染的提出，就是为了解决上述问题而诞生了（尤其是在场景中存在大量光源的情况下）。延迟着色给我们优化拥有大量光源的场景提供了很多可能性，因为它能够在渲染拥有成百上千光源的场景的同时还能够保持能让人接受的帧率。下面这张图展示了一个基于延迟着色渲染出的场景，这个场景中包含了1000个点光源，对于目前的硬件设备而言，用传统的正向渲染来实现几乎是不可能的。

![https://pic2.zhimg.com/50/v2-3d9fc9c58abbd7698ac23da57a0761f8_hd.jpg](media/1fbf3e71d0fd2f4af04f03f4277a5922.jpg)

图2 基于Deferred Rendering 渲染的含1000个点光源的场景 [J. Andersson, SIGGRAPH
2009 Beyond Programmable shading course talk] \@ Frostbite 2引擎

可以将延迟渲染( Deferred
Rendering)理解为先将所有物体都先绘制到屏幕空间的缓冲（即G-buffer，Geometric
Buffer，几何缓冲区）中，再逐光源对该缓冲进行着色的过程，从而避免了因计算被深度测试丢弃的⽚元的着色而产⽣的不必要的开销。也就是说延迟渲染基本思想是，先执行深度测试，再进行着色计算，将本来在物空
间（三维空间）进行光照计算放到了像空间（二维空间）进行处理。

对应于正向渲染O(m\*n)的 复杂度，经典的延迟渲染复杂度为O(n+m)。

![https://pic2.zhimg.com/50/v2-37804e656782c478c0a09c3a830e6078_hd.jpg](media/e08751ab760736c987d758a0d2abb3e1.jpg)

图3 Unreal Engine 3中实现的Deferred Shading \@GDC 2011

Jimmikaelkael在2016年12月24日发了一条推文（[https://twitter.com/jimmikaelkael/status/812631802242273280](http://link.zhihu.com/?target=https%3A//twitter.com/jimmikaelkael/status/812631802242273280)），分享了一组在Unity3D中基于Deferred
Shading渲染的SpeedTree场景，非常逼真：

![https://pic4.zhimg.com/50/v2-dd200212781e12372994ac5e87252c54_hd.jpg](media/73c141e27786370cde96efafea2b7382.jpg)

图4 SpeedTree deferred shading with translucency \@Unity3D引擎 by jimmikaelkael

![https://pic1.zhimg.com/50/v2-5caba4f66950a043dde1d568f303c21e_hd.jpg](media/5d07fdf2b3d6b96527011a635435f106.jpg)

图5 SpeedTree deferred shading with translucency \@Unity3D引擎 by jimmikaelkael

![https://pic3.zhimg.com/50/v2-77ed41497e8a903414a5e876d1a5f5ba_hd.jpg](media/6c018fa5c34e6abda1443b840258cd1e.jpg)

图6 SpeedTree deferred shading with translucency \@Unity3D引擎 by jimmikaelkael

![https://pic2.zhimg.com/50/v2-df8b5733ad4ca2d9deabd83ee2a8aa73_hd.jpg](media/c166463231683836d1c6f03a482882a3.jpg)

图7 SpeedTree deferred shading with translucency \@Unity3D引擎 by jimmikaelkael

延迟着色中一个非常重要的概念就是G-Buffer，下面先聊一下G-Buffer。

二、几何缓冲区 G-buffer
=======================

G-Buffer，全称Geometric Buffer
，译作几何缓冲区，它主要用于存储每个像素对应的位置（Position），法线（Normal），漫反射颜色（Diffuse
Color）以及其他有用材质参数。根据这些信息，就可以在像空间（二维空间）中对每个像素进行光照处理。

![https://pic4.zhimg.com/50/v2-47c9fef61aa3228471bec68ce3f7cf0d_hd.jpg](media/367b8335a4aa1ffa2d1718506cd6f0e7.jpg)

图8 一个典型的G-buffer layout。Source: W. Engel, “Light-Prepass Renderer Mark
III” \@SIGGRAPH 2009Talks

下图是一帧中G-buffer中存储的内容：

![https://pic3.zhimg.com/50/v2-658e8377a138e4a16d5819e513b83918_hd.jpg](media/7d9a5a8be478fa7408bba69849a72c85.jpg)

图9 G-buffer存储的信息

三、延迟渲染的过程分析
======================

可以将延迟渲染理解为两个Pass的过程：

1、几何处理阶段(Geometry
Pass)。这个阶段中，我们获取对象的各种几何信息，并将第二步所需的各种数据储存（也就是渲染）到多个G-buffer中；

2、光照处理阶段(Lighting
Pass)。在这个pass中，我们只需渲染出一个屏幕大小的二维矩形，使用第一步在G-buffer中存储的数据对此矩阵的每一个片段计算场景的光照；光照计算的过程还是和正向渲染以前一样，只是现在我们需要从对应的G-buffer而不是顶点着色器(和一些uniform变量)那里获取输入变量了。

下面这幅图片很好地展示了延迟着色的整个过程：

![https://pic3.zhimg.com/50/v2-1393db5a72ffe0c053c00f044955e3cf_hd.jpg](media/5d5829f27c19b9f24046e64375a99071.jpg)

图10 延迟着色的过程

延迟渲染方法一个很大的好处就是能保证在G-buffer中的片段和在屏幕上呈现的像素所包含的片段信息是一样的，因为深度测试已经最终将这里的片段信息作为最顶层的片段。这样保证了对于在光照处理阶段中处理的每一个像素都只处理一次，所以我们能够省下很多无用的渲染调用。除此之外，延迟渲染还允许我们做更多的优化，从而渲染更多的光源。

在几何处理阶段中填充G-buffer非常高效，因为我们直接储存位置，颜色，法线等对象信息到帧缓冲中，这个过程几乎不消耗处理时间。

而在此基础上使用多渲染目标(Multiple Render Targets,
MRT)技术，我们可以在一个Pass之内完成所有渲染工作。

总结一下，典型的Deferred Rendering 的渲染流程有两步：

1. 几何处理阶段：渲染所有的几何/颜色数据到G-buffer

2. 光照处理阶段：使用G-buffer计算场景的光照。

四、延迟渲染的伪代码
====================

为了便于理解，这里贴出一些各种描述版本的延迟渲染算法的伪代码：

1、通用版本的延迟着色算法伪代码：

    For each object:
	Render to multiple targets
    For each light:
	Apply light as a 2D postprocess

2、一个通用版本的deferred shading过程描述：

	“Standard” deferred shading is a 2-stage process:
	
	(1) draw (opaque) geometry storing its attributes (i.e. position as depth,
	normals, albedo color, specular color and other material properties) in a number
	of full screen buffers (typically 3 or 4)
	
	(2) for each light source, draw its volume and accumulate lit surface color
	into final render target

3、两个Pass的延迟着色算法伪代码：

	Two-pass deferred shading algorithm
	Pass 1: geometry pass
	- Write visible geometry information to G-buffer
	Pass 2: shading pass
	For each G-buffer sample, compute shading
	- Read G-buffer data for current sample
	- Accumulate contribution of all lights
	- Output final surface color

4、多光源的延迟渲染的伪代码：

	Many-light deferred shading algorithm
	For each light:
	- Generate/bind shadow/environment maps
	- Compute light’s contribution for each G-buffer sample:
	For each G-buffer sample
	- Load G-buffer data
	- Evaluate light contribution (may be zero)
	- Accumulate contribution into frame-buffer

可以将这里的多光源计算过程理解为，对每个光源创建一个屏幕空间包围矩形，然后用光照shader渲染这个矩形。

五、延迟渲染 vs 正向渲染
========================

这边对正向渲染和延迟渲染的特性做一个对照列举：

5.1 正向渲染
------------

-   正向渲染（Forward Rendering），先执行着色计算，再执行深度测试。

-   正向渲染渲染n个物体在m个光源下的着色，复杂度为O(n\*m)次。

-   Forward
    Rendering，光源数量对计算复杂度影响巨大，所以比较适合户外这种光源较少的场景。

-   Forward Rendering的核心伪代码可以表示为：

    	For each light:
			For each object affected by the light: 
				framebuffer += object * light

Forward Rendering的管线流程如下：

![https://pic1.zhimg.com/50/v2-bb3e04960df408287d7114ce128ef65d_hd.jpg](media/8fbd6ddfc4a777a3130dae8e0200686b.jpg)

图11 正向渲染（Forward Rendering）管线流程

5.2 延迟渲染
------------

-   延迟渲染( Deferred Rendering)，先执行深度测试，再执行着色计算。

-   延迟渲染渲染n个物体在m个光源下的着色，复杂度为O(n+m)次。

-   Deferred Rendering
    的最大的优势就是将光源的数目和场景中物体的数目在复杂度层面上完全分开。也就是说场景中不管是一个三角形还是一百万个三角形，最后的复杂度不会随
    光源数目变化而产生巨大变化。

-   Deferred
    Rendering的核心伪代码可以表示如下，上文已经贴出过，这边再次贴出，方便对比：

    For each object:
    	Render to multiple targets 
	For each light:
    	Apply light as a 2D postprocess

Deferred Rendering的管线流程如下：

![https://pic1.zhimg.com/50/v2-fcf2b24826baa59ac7c2c833f7b167e7_hd.jpg](media/e87c28ee0474e48a59ef0fd39f24be8d.jpg)

图12 延迟渲染( Deferred Rendering)管线流程

六、延迟渲染的优缺点分析
========================

这里列举一下经典版本的延迟渲染的优缺点。

6.1 延迟渲染的优点
------------------

Deferred Rendering
的最大的优势就是将光源的数目和场景中物体的数目在复杂度层面上完全分开。也就是说场景中不管是一个三角形还是一百万个三角形，最后的复杂度不会随光源数目变化而产生巨大变化。

一些要点：

-   复杂度仅O(n+m)。

-   只渲染可见的像素，节省计算量。

-   用更少的shader。

-   对后处理支持良好。

-   在大量光源的场景优势尤其明显。

6.2 延迟渲染的缺点
------------------

一些要点：

-   内存开销较大。

-   读写G-buffer的内存带宽用量是性能瓶颈。

-   对透明物体的渲染存在问题。在这点上需要结合正向渲染进行渲染。

-   对多重采样抗锯齿（MultiSampling Anti-Aliasing,
    MSAA）的支持不友好，主要因为需开启MRT。

七、延迟渲染的改进
==================

针对延迟渲染上述提到的缺点，下面简单列举一些降低 Deferred Rendering
存取带宽的改进方案。最简单也是最容易想到的就是将存取的 G-Buffer
数据结构最小化，这也就衍生出了 Light Pre-Pass（即Deferred Lighting）
方法。另一种方式是将多个光照组成一组，然后一起处理，这种方法衍生了 Tile-Based
Deferred Rendering。

也就是说，常见的两种Deferred Rendering的改进是：

-   延迟光照 Light Pre-Pass（即Deferred Lighting）

-   分块延迟渲染 Tile-BasedDeferred Rendering

下面分别进行说明。

八、延迟光照 LightPre-Pass / Deferred Lighting
==============================================

Light Pre-Pass即Deferred Lighting（延迟光照），旨在减少传统Defferred
Rendering使用G-buffer 时占用的过多开销（reduce G-buffer overhead），最早由
Wolfgang
Engel于2008年在他的博客([http://diaryofagraphicsprogrammer.blogspot.com/2008/03/light-pre-pass-renderer.html](http://link.zhihu.com/?target=http%3A//diaryofagraphicsprogrammer.blogspot.com/2008/03/light-pre-pass-renderer.html))中提到。

延迟光照的具体的思路是：

1、渲染场景中不透明（opaque ）的几何体。将法线向量n和镜面扩展因子（specular
spread factor）m 写入缓冲区。这个n/m-buffer 缓冲区是一个类似
G-Buffer的缓冲区，但包含的信息更少，更轻量，适合于单个输出颜色缓冲区，因此不需要MRT支持。

2、渲染光照。计算漫反射和镜面着色方程，并将结果写入不同的漫反射和镜面反射累积缓冲区。这个过程可以在一个单独的pass中完成（使用MRT），或者用两个单独的pass。环境光照明可以在这个阶段使用一个
full-screen pass进行计算。

3、对场景中的不透明几何体进行第二次渲染。从纹理中读取漫反射和镜面反射值，对前面步骤中漫反射和镜面反射累积缓冲区的值进行调制，并将最终结果写入最终的颜色缓冲区。若在上一阶段没有处理环境光照明，则在此阶段应用环境光照明。

4、使用非延迟着色方法渲染半透明几何体。

具体的流程图可以展示如下：

![https://pic4.zhimg.com/50/v2-6a4235519f4aa2334d90f63783f311c4_hd.jpg](media/0a670145a0202467e3c8ac8bdb945a19.jpg)

图13 Deferred Lighting流程图

相对于传统的 Deferred Render，使用 Light Pre-Pass 可以对每个不同的几何体使用不同
的 shader 进行渲染，所以每个物体的 material properties 将有更多变化。

这里我们可以看出对于传统的 Deferred
Render，它的第二步是遍历每个光源，这样就增加了光源设置的灵活性，而 Light
Pre-Pass第三步使用的其实是 forward rendering，所以可以对每mesh
设置其材质，这两者是相辅相成的，有利有弊。

另一个 Light Pre-Pass 的优点是在使用 MSAA 上很有利。虽然并不是 100%使用上了
MSAA（除非使用 DX10/11 的特性），但是由于使用了Z 值和 Normal
值，就可以很容易找到边缘，并进行采样。

九、分块延迟渲染 Tile-BasedDeferred Rendering
=============================================

作为传统Defferred Rendering的另一种主要改进，分块延迟渲染（Tile-Based Deferred
Rendering，TBDR）旨在合理分摊开销（amortize overhead），自SIGGRAPH
2010上提出以来逐渐为业界所了解。

实验数据表明TBDR在大量光源存在的情况下明显优于上文提到的Light Pre-Pass。

我们知道，延迟渲染的瓶颈在于读写
G-buffer，在大量光源下，具体瓶颈将位于每个光源对
G-buffer的读取及与颜色缓冲区（color
buffer）混合。这里的问题是，每个光源，即使它们的影响范围在屏幕空间上有重疉，因为每个光源是在不同的绘制中进行，所以会重复读取G-buffer中相同位置的数据，计算后以相加混合方式写入颜色缓冲。光源越多，内存带宽用量越大。

而分块延迟渲染的主要思想则是把屏幕分拆成细小的栅格，例如每 32 × 32
象素作为一个分块（tile）。然后，计算每个分块会受到哪些光源影响，把那些光源的索引储存在分块的光源列表里。最后，逐个分块进行着色，对每像素读取
G-buffer
和光源列表及相关的光源信息。因此，G-buffer的数据只会被读取1次且仅1次，写入 color
buffer也是1次且仅1次，大幅降低内存带宽用量。不过，这种方法需要计算光源会影响哪些分块，这个计算又称为光源剔除（light
culling），可以在 CPU 或 GPU（通常以 compute shader
实现）中进行。用GPU计算的好处是，GPU 计算这类工作比 CPU 更快，也减少 CPU／GPU
数据传输。而且，可以计算每个分块的深度范围（depth range），作更有效的剔除。

![https://pic3.zhimg.com/50/v2-4f8520cdcc9aa80ec2212ddbf918a231_hd.jpg](media/be8576aa344b7be36f165b2b1376d61b.jpg)

图14 Tile-Based Deferred Rendering 图示 \@GDC2011，SPU-based deferred shading
for Battlefield 3 onPlaystation 3.

也就是说，TBDR 主要思想就是将屏幕分成一个个小块 tile。然后根据这些 Depth
求得每个 tile 的 bounding box。对每个 tile 的 bounding box 和 light
进行求交，这样就得到了对该 tile 有作用 的 light
的序列。最后根据得到的序列计算所在 tile 的光照效果。

对比 Deferred Rendering，之前是对每个光源求取其作用区域 light
volume，然后决定其作用的的 pixel，也就是说每个光源要求取一次。而使用
TBDR，只要遍历每个 pixel，让其所属 tile 与光线求交，来计算作用其上的
light，并利用 G-Buffer 进行 Shading。一方面这样做减少
了所需考虑的光源个数，另一方面与传统的 Deferred Rendering
相比，减少了存取的带宽。

![https://pic3.zhimg.com/50/v2-f037e5a6fe62520f79659f70c0fb69f5_hd.jpg](media/e80635792cc31c57e58c50e6c066995a.jpg)

图15 在1920x1080分辨率下，Tile-Based vs. 传统 deferred shading

![https://pic2.zhimg.com/50/v2-544fb296a7530b6d29543e4e852fecc1_hd.jpg](media/7cd5c2d7a28d2cba9bd7c3f544eef3d3.jpg)

图16 使用Tile-Based Deferred Rendering思路渲染的场景，场景含4096个点光源

十、延迟渲染 vs 延迟光照
========================

关于延迟着色和延迟光照，经常会被弄混，这边简单区分一下。

-   延迟渲染（Deferred Rendering）又称延迟着色（Deferred
    Shading），在2004年的GDC上被提出。

-   延迟光照（Deferred Lighting）又称Light
    Pre-Pass，是延迟着色的一种改进，在2008年被提出。

Deferred Rendering与Deferred Lighting在思想上的主要异同：

-   DeferredShading需要更大的G-Buffer来完成对Deferred阶段的前期准备，而且一般需要硬件有MRT的支持，可以说是硬件要求更高。

-   DeferredLighting需要两个几何体元的绘制过程来来完成整个渲染操作：G-Pass与Shading
    pass。这个既是劣势也是优势：由于Deferred
    Shading中的Deffered阶段是在完全基于G-Buffer的屏幕空间进行，这也导致了物体材质信息的缺失，这样在处理多变的渲染风格时就需要额外的操作；而Deferred
    Lighting却可以在Shading阶段得到物体的材质信息进而使这一问题的处理变得较简单。

-   两种方法的上述操作均是只能完成对不透明物体的渲染，而透明或半透明的物体则需额外的传统Pass来完成。

两者流程图的对比：

![https://pic4.zhimg.com/50/v2-a2b21ebcf19923e23a7dcdca0937cc73_hd.jpg](media/15ca75231160440b75f7ad60350927e5.jpg)

图17 Deferred Shading流程图

![https://pic4.zhimg.com/50/v2-6a4235519f4aa2334d90f63783f311c4_hd.jpg](media/0a670145a0202467e3c8ac8bdb945a19.jpg)

图18 Deferred Lighting流程图

十一、实时渲染中常见的Rendering Path总结
========================================

这一节对常见实时渲染中常见的几种 Rendering Path进行一个简单小节。

本文目前已经提到的Rendering Path有：

-   正向渲染 （Forward Rendering）

-   延迟渲染 （Deferred Rendering）

-   延迟光照 （Light Pre-Pass / Deferred Lighting）

-   分块延迟渲染（Tile-Based Deferred Rendering）

除此之外，还有如下一些后来提出的Rendering Path比较有趣：

-   Forward+（即Tiled Forward Rendering，分块正向渲染）

-   群组渲染 Clustered Rendering

篇幅原因，这边就不展开了，有兴趣的朋友不妨去查阅相关资料进行了解。

十二、环境映射 Environment Mapping
==================================

最后简单聊一聊《Real-Time Rendering 3rd》第八章“区域和环境光照 Area and
Environmental
Lighting”中的EnvironmentMapping环境映射。下一篇文章，就直接开始提炼第九章“Global
Illumination 全局光照”的内容。

Environment mapping（环境映射），又称Reflection
Mapping（反射映射）,是计算机图形学领域中使用基于图像的光照（Image-Based
Lighting，IBL）技术，用预先计算的纹理图像模拟复杂镜面的一种高效方法。由Blinn 和
Newell 在1976首次提出。

由于是事先准备好的数据，这种实现方法比传统的光线跟踪算法效率更高，但是需要注意的是这种方法是实际反射的一种近似，有时甚至是非常粗糙的近似。这种技术的一个典型的缺点是没有考虑自反射，即无法看到物体反射的物体自身的某一部分。

![https://pic3.zhimg.com/50/v2-a39ac847f66e444da223d24bbd7ebf53_hd.jpg](media/1c1e893c0173146aaa218ed06a625c78.jpg)

图19 Image Based Lighting Environment Mapping 环境映射效果图

环境映射的常见类型有：

-   球型环境映射 Sphere Environment Mapping

-   立方体环境映射 Cubic Environment Mapping

-   抛物线环境映射 Parabolic Environment Mapping

环境映射的一些引申：

-   光泽反射环境映射(Glossy Reflections from Environment Maps)

-   基于视角的反射映射(View-Dependent Reflection Maps)

-   辐照度环境映射 (Irradiance Environment Mapping)

另外，推荐一个下载CubeMap资源的站点：

[http://www.humus.name/index.php?page=Textures](http://link.zhihu.com/?target=http%3A//www.humus.name/index.php%3Fpage%3DTextures)

Reference
=========

[1] Lauritzen, Andrew. "Deferredrendering for current and future rendering
pipelines." SIGGRAPH Course:Beyond Programmable Shading (2010): 1-34.

[2] Coffin, Christina. "SPU-based deferredshading for Battlefield 3 on
Playstation 3." Game Developer ConferencePresentation. Vol. 8. 2011.

[3] Lee M. Pre-lighting in Resistance 2[J].GDC San Francisco, 2009.

[4] Valient M. Deferred rendering inKillzone 2[C]//The Develop Conference and
Expo. 2007.

[5]Andersson, Johan. "Directx 11rendering in battlefield 3." Game Developers
Conference. Vol. 2. 2011.

[6] [http://www.cnblogs.com/ghl_carmack/p/4150232.html](http://link.zhihu.com/?target=http%3A//www.cnblogs.com/ghl_carmack/p/4150232.html)

[7] [https://twitter.com/jimmikaelkael/status/812631802242273280](http://link.zhihu.com/?target=https%3A//twitter.com/jimmikaelkael/status/812631802242273280)

[8] [http://www.realtimerendering.com/blog/deferred-lighting-approaches/](http://link.zhihu.com/?target=http%3A//www.realtimerendering.com/blog/deferred-lighting-approaches/)

[9] [http://miloyip.com/2014/many-lights/](http://link.zhihu.com/?target=http%3A//miloyip.com/2014/many-lights/)

[10] [http://www.cnblogs.com/polobymulberry/p/5126892.html](http://link.zhihu.com/?target=http%3A//www.cnblogs.com/polobymulberry/p/5126892.html)

[11] [http://blog.csdn.net/bugrunner/article/details/7436600](http://link.zhihu.com/?target=http%3A//blog.csdn.net/bugrunner/article/details/7436600)

[12] [https://learnopengl-cn.readthedocs.io/zh/latest/05%20Advanced%20Lighting/08%20Deferred%20Shading/](http://link.zhihu.com/?target=https%3A//learnopengl-cn.readthedocs.io/zh/latest/05%2520Advanced%2520Lighting/08%2520Deferred%2520Shading/)

[13] [http://www.cnblogs.com/ghl_carmack/p/4150232.html](http://link.zhihu.com/?target=http%3A//www.cnblogs.com/ghl_carmack/p/4150232.html)

[14] [http://gameangst.com/?p=141](http://link.zhihu.com/?target=http%3A//gameangst.com/%3Fp%3D141)

[15] [https://www.flickr.com/photos/mylaboratory/2332900823/in/photostream/](http://link.zhihu.com/?target=https%3A//www.flickr.com/photos/mylaboratory/2332900823/in/photostream/)

[16] [https://gamedevcoder.wordpress.com/2011/04/11/light-pre-pass-vs-deferred-renderer-part-1/](http://link.zhihu.com/?target=https%3A//gamedevcoder.wordpress.com/2011/04/11/light-pre-pass-vs-deferred-renderer-part-1/)

[17] CMU 15869 lecture 12 Slides：

[http://www.cs.cmu.edu/afs/cs/academic/class/15869-f11/www/lectures/12_deferred_shading.pdf](http://link.zhihu.com/?target=http%3A//www.cs.cmu.edu/afs/cs/academic/class/15869-f11/www/lectures/12_deferred_shading.pdf)

[18] Lauritzen A. Deferred rendering forcurrent and future rendering
pipelines[J]. SIGGRAPH Course: Beyond ProgrammableShading, 2010:
1-34. [https://software.intel.com/sites/default/files/m/d/4/1/d/8/lauritzen_deferred_shading_siggraph_2010.pdf](http://link.zhihu.com/?target=https%3A//software.intel.com/sites/default/files/m/d/4/1/d/8/lauritzen_deferred_shading_siggraph_2010.pdf)

[19] Nguyen, Hubert. GPU Gems 3. Chapter 19. Addison-Wesley Professional, 2007.

```

`Content/《Real-Time Rendering 3rd》读书笔记/Content/BlogPost08/README.md`:

```md
![](media/title08.jpg)

# 【《Real-Time Rendering 3rd》 提炼总结】(八) 第九章 · 全局光照:光线追踪、路径追踪与GI技术进化编年史

全局光照（Global Illumination,简称 GI），
作为图形学中比较酷的概念之一，是指既考虑场景中来自光源的直接光照，又考虑经过场景中其他物体反射后的间接光照的一种渲染技术。

大家常听到的光线追踪，路径追踪等同样很酷的概念，都是全局光照中人气较高的算法流派。

而这篇文章将围绕全局光照技术，介绍的要点有：

-   全局光照的基本概念

-   全局光照的算法主要流派

-   全局光照技术进化编年史

-   光线追踪 Ray Tracing

-   路径追踪 Path Tracing

-   光线追踪、路径追踪、光线投射的区别

-   环境光遮蔽 Ambient Occlusion

一、行文思路说明
================

阅读过《Real-Time Rendering
3rd》第九章的读者们都会发现，作为一章关于全局光照的章节，作者讲了不少在严格意义上全局光照主线以外的内容，如Reflections、Refractions、Shadow等节，而这些内容在《Real-Time
Rendering 2nd》中，其实是放在Chapter 6 Advanced Lighting and Shading一节的。

既然《Real-Time Rendering
3rd》第九章标题就叫全局光照，核心内容也是全局光照，本文即决定脱离原书安排的100来页的多余内容，以全局光照的主线内容为主，构成一篇包含全局光照基本概念，主要算法流派，以及全局光照技术进化编年史，和全局光照算法中人气较高的光线追踪、路径追踪等算法的综述式文章。

二、全局光照
============

全局光照，(Global Illumination,简称 GI), 或被称为Indirect Illumination,
间接光照，是指既考虑场景中直接来自光源的光照（Direct
Light）又考虑经过场景中其他物体反射后的光照（Indirect
Light）的一种渲染技术。使用全局光照能够有效地增强场景的真实感。

即可以理解为：全局光照 = 直接光照(Direct Light) + 间接光照(Indirect Light)

![](media/acd2ad57b7321185d4794f0dbbef3f67.jpg)

图1 Direct illumination

![](media/e9938f4930bc52626a495073d0437ed3.jpg)

图2 Global illumination = Direct illumination +Indirect illumination

上述两幅图片来自CMU 15-462/15-662, Fall 2015 Slider，Lecture 14: Global
Illumination,当然，细心的朋友也可以发现，它也被《Physically Based
Rendering,Second Edition From Theory To Implementation》选作封面。

同样可以看到，加入了Indirect
illumination的图2，在直接光源（阳光）照射不到的地方，得到了更好的亮度和细节表现，从而使整张渲染效果更具真实感。

虽说实际应用中只有漫反射全局照明的模拟算法被称为全局照明算法，但其实理论上说反射、折射、阴影都属于全局光照的范畴，因为模拟它们的时候不仅仅要考虑光源对物体的直接作用还要考虑物体与物体之间的相互作用。也是因为，镜面反射、折射、阴影一般不需要进行复杂的光照方程求解，也不需要进行迭代的计算。因此，这些部分的算法已经十分高效，甚至可以做到实时。不同于镜面反射，光的漫反射表面反弹时的方向是近似“随机”，因此不能用简单的光线跟踪得到反射的结果，往往需要利用多种方法进行多次迭代，直到光能分布达到一个基本平衡的状态。

三、全局光照的主要算法流派
==========================

经过几十年的发展，全局光照现今已有多种实现方向，常见的全局光照主要流派列举如下：

-   Ray tracing 光线追踪

-   Path tracing 路径追踪

-   Photon mapping 光子映射

-   Point Based Global Illumination 基于点的全局光照

-   Radiosity 辐射度

-   Metropolis light transport 梅特波利斯光照传输

-   Spherical harmonic lighting 球谐光照

-   Ambient occlusion 环境光遮蔽

-   Voxel-based Global Illumination 基于体素的全局光照

-   Light Propagation Volumes Global Illumination

-   Deferred Radiance Transfer Global Illumination

-   Deep G-Buffer based Global Illumination

-   等。

而其中的每种流派，又可以划分为N种改进和衍生算法。

如光线追踪（Ray
Tracing）派系，其实就是一个框架，符合条件的都可称为光线追踪，其又分为递归式光线追踪（Whitted-style
Ray Tracing），分布式光线追踪（DistributionRay
Tracing），蒙特卡洛光线追踪（Monte Carlo Ray Tracing）等。

而路径追踪（Path tracing）派系，又分为蒙特卡洛路径追踪（Monte Carlo Path
Tracing），双向路径追踪（Bidirectional Path
Tracing），能量再分配路径追踪（Energy Redistribution Path Tracing）等。

其中有些派系又相互关联，如路径追踪，就是基于光线追踪，结合了蒙特卡洛方法而成的一种新的派系。

四、全局光照技术进化编年史
==========================

这节以光线追踪和路径追踪派系为视角，简单总结一下全局光照技术发展早期（1968-1997）的重要里程碑。

4.1 光线投射 Ray Casting [1968]
-------------------------------

光线投射（Ray
Casting），作为光线追踪算法中的第一步，其理念起源于1968年，由Arthur
Appel在一篇名为《 Some techniques for shading machine rendering of
solids》的文章中提出。其具体思路是从每一个像素射出一条射线，然后找到最接近的物体挡住射线的路径，而视平面上每个像素的颜色取决于从可见光表面产生的亮度。

![](media/1c43617a918e1c2228cb090212d69285.jpg)

图3 光线投射：每像素从眼睛投射射线到场景

4.2 光线追踪 Ray Tracing [1979]
-------------------------------

1979年，Turner
Whitted在光线投射的基础上，加入光与物体表面的交互，让光线在物体表面沿着反射，折射以及散射方式上继续传播，直到与光源相交。这一方法后来也被称为经典光线跟踪方法、递归式光线追踪（Recursive
Ray Tracing）方法，或 Whitted-style 光线跟踪方法。

光线追踪方法主要思想是从视点向成像平面上的像素发射光线，找到与该光线相交的最近物体的交点，如果该点处的表面是散射面，则计算光源直接照射该点产生的颜色；如果该点处表面是镜面或折射面，则继续向反射或折射方向跟踪另一条光线，如此递归下去，直到光线逃逸出场景或达到设定的最大递归深度。

![](media/a8697cdb5b01ea92007dde448cc677d9.jpg)

图4 经典的光线追踪： 每像素从眼睛投射射线到场景，并追踪次级光线（(shadow,
reflection, refraction），并结合递归

4.3 分布式光线追踪 Distributed Ray Tracing [1984]
-------------------------------------------------

Cook于1984年引入蒙特卡洛方法（Monte Carlo
method）到光线跟踪领域，将经典的光线跟踪方法扩展为分布式光线跟踪算法（Distributed
Ray Tracing），又称为随机光线追踪（stochasticray
tracing），可以模拟更多的效果，如金属光泽、软阴影、景深（ Depthof
Field）、运动模糊等等。

4.4 渲染方程 The Rendering Equation [1986]
------------------------------------------

在前人的研究基础上，Kajiya于1986年进一步建立了渲染方程的理论，并使用它来解释光能传输的产生的各种现象。这一方程描述了场景中光能传输达到稳定状态以后，物体表面某个点在某个方向上的辐射率（Radiance）与入射辐射亮度等的关系。

可以将渲染方程理解为全局光照算法的基础，Kajiya在1986年第一次将渲染方程引入图形学后，随后出现的很多全局光照的算法，都是以渲染方程为基础，对其进行简化的求解，以达到优化性能的目的。渲染方程根据光的物理学原理，以及能量守恒定律，完美地描述了光能在场景中的传播。很多真实感渲染技术都是对它的一个近似。渲染方程在数学上的表示如下：

![](media/4b1039e50c02e976e516395ae5f397b2.jpg)

![](media/39a4f7fd5fc78a93ae462b0602ba0160.jpg)

图5 渲染方程描述了从x点沿某一方向看的光放射的总额。

4.5 路径追踪 Path Tracing [1986]
--------------------------------

Kajiya也于1986年提出了路径追踪算法的理念，开创了基于蒙特卡洛的全局光照这一领域。根据渲染方程，
Kajiya
提出的路径追踪方法是第一个无偏（Unbiased）的渲染方法。路径追踪的基本思想是从视点发出一条光线，光线与物体表面相交时根据表面的材质属性继续采样一个方向，发出另一条光线，如此迭代，直到光线打到光源上（或逃逸出场景），然后用蒙特卡洛的方法，计算其贡献，作为像素的颜色值。

4.6 双向路径追踪 Bidirectional Path Tracing [1993，1994]
--------------------------------------------------------

双向路径追踪（Bidirectional Path
Tracing）的基本思想是同时从视点、光源打出射线，经过若干次反弹后，将视点子路径（
eye path） 和光源子路径（ light path）
上的顶点连接起来（连接时需要测试可见性），以快速产生很多路径。这种方法能够产生一些传统路径追踪难以采样到的光路，所以能够很有效地降低噪声。
进一步的， [Veach
1997]将渲染方程改写成对路径积分的形式，允许多种路径采样的方法来求解该积分。

4.7 梅特波利斯光照传输 Metropolis Light Transport [1997]
--------------------------------------------------------

Eric Veach等人于1997年提出了梅特波利斯光照传输（Metropolis Light
Transport，常被简称为MLT）方法。路径追踪（ Path
Tracing）中一个核心问题就是怎样去尽可能多的采样一些贡献大的路径，而该方法可以自适应的生成贡献大的路径，简单来说它会避开贡献小的路径，而在贡献大的路径附近做更多局部的探索，通过特殊的变异方法，生成一些新的路径，这些局部的路径的贡献往往也很高。
与双向路径追踪相比， MLT
更加鲁棒，能处理各种复杂的场景。比如说整个场景只通过门缝透进来的间接光照亮，此时传统的路径追踪方法因为难以采样到透过门缝的这样的特殊路径而产生非常大的噪声。

五、光线追踪 Ray Tracing
========================

光线追踪（Ray
tracing）是三维计算机图形学中的特殊渲染算法，跟踪从眼睛发出的光线而不是光源发出的光线，通过这样一项技术生成编排好的场景的数学模型显现出来。这样得到的结果类似于光线投射与扫描线渲染方法的结果，但是这种方法有更好的光学效果，例如对于反射与折射有更准确的模拟效果，并且效率非常高，所以当追求高质量的效果时经常使用这种方法。

上文已经提到过，Whitted于1979年提出了使用光线跟踪来在计算机上生成图像的方法，这一方法后来也被称为经典光线跟踪方法、递归式光线追踪方法，或
Whitted-style
光线跟踪方法。其主要思想是从视点向成像平面上的像素发射光线，找到与该光线相交的最近物体的交点，如果该点处的表面是散射面，则计算光源直接照射该点产生的颜色；如果该点处表面是镜面或折射面，则继续向反射或折射方向跟踪另一条光线，如此递归下去，直到光线逃逸出场景或达到设定的最大递归深度。

以下这张图示可以很好的说明光线追踪方法的思路：

![](media/6771b60565f233dccf5eef6ff453ba8f.jpg)

图6 Ray Tracing Illustration First Bounce

![](media/65809e8c0955da4e58dad4ee1faa10c2.jpg)

图7 基于光线追踪渲染出的效果图1

![](media/cd533d179c4e179125bbdceb1a8ed714.jpg)

图8 基于光线追踪渲染出的效果图2

![](media/f052ed6ae5bde9190cfe683862d295ce.jpg)

图9 基于光线追踪渲染效果图 \@Caustic-Graphics，Inc

![](media/cdfea7e9bee7a508ffca5eb408659e50.jpg)

图10 典型的光线追踪渲染效果图

光线跟踪的一个最大的缺点就是性能，需要的计算量非常巨大，以至于目前的硬件很难满足实时光线追踪的需求。传统的光栅图形学中的算法，利用了数据的一致性从而在像素之间共享计算，而光线跟踪通常是将每条光线当作独立的光线，每次都要重新计算。但是，这种独立的做法也有一些其它的优点，例如可以使用更多的光线以抗混叠现象，并且在需要的时候可以提高图像质量。尽管它正确地处理了相互反射的现象以及折射等光学效果，但是传统的光线跟踪并不一定是真实效果图像，只有在非常近似或者完全实现渲染方程的时候才能实现真正的真实效果图像。由于渲染方程描述了每个光束的物理效果，所以实现渲染方程可以得到真正的真实效果，但是，考虑到所需要的计算资源，这通常是无法实现的。于是，所有可以实现的渲染模型都必须是渲染方程的近似，而光线跟踪就不一定是最为可行的方法。包括光子映射在内的一些方法，都是依据光线跟踪实现一部分算法，但是可以得到更好的效果。

用一套光线追踪的伪代码，结束这一节的内容：

    for each pixel of the screen
	{
		Final color = 0;
	      	Ray = { starting point, direction };
	      	Repeat
		{
			for each object in the scene
	          	{
	                 	determine closest ray object/intersection;
	          	}
		        if intersection exists
	      	        {
	             		for each light inthe scene
	             		{
	                    		if the light is not in shadow of anotherobject
	                    		{
	                           			addthis light contribution to computed color;
	                    		}
			        }
		       }
	      	       Final color = Final color + computed color * previous reflectionfactor;
	      	       reflection factor = reflection factor * surface reflectionproperty;
	      	       increment depth;
	      } until reflection factor is 0 or maximumdepth is reached
	}


六、路径追踪 Path Tracing
=========================

路径追踪（Path
Tracing）方法由Kajiya在1986年提出，该方法的基本思想是从视点发出一条光线，光线与物体表面相交时根据表面的材质属性继续采样一个方向，发出另一条光线，如此迭代，直到光线打到光源上（或逃逸出场景），然后用蒙特卡洛方法，计算光线的贡献，作为像素的颜色值。而使用蒙特卡洛方法对积分的求解是无偏的，只要时间足够长，最终图像能收敛到一个正确的结果。

简单来说，路径追踪 = 光线追踪+ 蒙特卡洛方法。

这边有一个用99行代码实现路径追踪算法的一个简易全局光照渲染器，有兴趣的朋友可以进行了解：

[http://www.kevinbeason.com/smallpt/](https://link.zhihu.com/?target=http%3A//www.kevinbeason.com/smallpt/)

![](media/aaf7697564031ec7d4d0b8b849dbd4a7.jpg)

图11 基于路径追踪渲染的效果图

![](media/3babd983e248f9fb7345b3e70f013ed5.jpg)

图12 基于路径追踪实现的次表面散射渲染效果图 ©Photorealizer

![](media/5a873c551cc5fa6cd1bb5c60b43c40b4.jpg)

图13 基于路径追踪渲染的效果图
©[http://www.pathtracing.com](https://link.zhihu.com/?target=http%3A//www.pathtracing.com)

![](media/918941ce9bf2284135d84bb9504797c2.jpg)

图14 基于路径追踪渲染的效果图 ©NVIDIA

七、Ray Casting ，Ray Tracing，Path Tracing区别
===============================================

初学者往往会弄不明白光线投射（Ray Casting ），光线追踪（Ray
Tracing），路径追踪（Path
Tracing）三者的的区别，龚大 [\@叛逆者](https://www.zhihu.com/people/0b21747b1fec79ad8af7e68a2b1ff681) 在<https://www.zhihu.com/question/29863225>这个答案中的回答已经很精辟，本文就直接引用了过来：

-   Ray
    Tracing：这其实是个框架，而不是个方法。符合这个框架的都叫raytracing。这个框架就是从视点发射ray，与物体相交就根据规则反射、折射或吸收。遇到光源或者走太远就停住。一般来说运算量不小。

-   Ray Casting：其实这个和volumetric可以脱钩。它就是ray
    tracing的第一步，发射光线，与物体相交。这个可以做的很快，在Doom
    1里用它来做遮挡。

-   Path Tracing：是ray tracing +
    蒙特卡洛法。在相交后会选一个随机方向继续跟踪，并根据BRDF计算颜色。运算量也不小。还有一些小分类，比如Bidirectional
    path tracing。

文末，简单聊一下环境光遮蔽，AO。

八、环境光遮蔽 Ambient Occlusion
================================

环境光遮蔽（Ambient
Occlusion，简称AO）是全局光照明的一种近似替代品，可以产生重要的视觉明暗效果，通过描绘物体之间由于遮挡而产生的阴影，
能够更好地捕捉到场景中的细节，可以解决漏光，阴影漂浮等问题，改善场景中角落、锯齿、裂缝等细小物体阴影不清晰等问题，增强场景的深度和立体感。

可以说，环境光遮蔽在直观上给玩家的主要感觉体现在画面的明暗程度上，未开启环境光遮蔽特效的画面光照稍亮一些；而开启环境光遮蔽特效之后，
局部的细节画面尤其是暗部阴影会更加明显一些。

Ambient Occlusion的细分种类有：

-   SSAO-Screen space ambient occlusion

-   SSDO-Screen space directional occlusion

-   HDAO-High Definition Ambient Occlusion

-   HBAO+-Horizon Based Ambient Occlusion+

-   AAO-Alchemy Ambient Occlusion

-   ABAO-Angle Based Ambient Occlusion

-   PBAO

-   VXAO-Voxel Accelerated Ambient Occlusion

一般而言，Ambient Occlusion最常用方法是SSAO，如Unreal Engine
4中的AO，即是用SSAO实现。

最后，贴一些和AO相关的，较经典的渲染效果图，结束这篇文章。

![](media/ba89994f09a0dfd898b82dd47a41a7ad.jpg)

图15 Scene without Ambient Occlusion ©Unreal

![](media/dedad359b08a2f0e2c94c8072b8cf15d.jpg)

图16 Ambient Occlusion Only ©Unreal

![](media/22ed587d43cdccff3039835508e2c128.jpg)

图17 Scene with Ambient Occlusion ©Unreal

![](media/e83d5072a6973b4f7d007c7046aaaff3.jpg)

图18 使用环境光遮蔽制作人物的步骤

![](media/f7e25a344906d91e7a2a1e1f43efa36e.jpg)

图19 一张典型的环境光遮蔽的渲染图

![](media/97d41a8d8936b6d9f9e5ce5958b8497e.jpg)

图20 有无环境光遮蔽渲染效果对比图示

九、其他参考
============

[1] [http://15462.courses.cs.cmu.edu/fall2015/lecture/globalillum](https://link.zhihu.com/?target=http%3A//15462.courses.cs.cmu.edu/fall2015/lecture/globalillum)

[2] [https://docs.unrealengine.com/latest/INT/Engine/Rendering/LightingAndShadows/AmbientOcclusion/](https://link.zhihu.com/?target=https%3A//docs.unrealengine.com/latest/INT/Engine/Rendering/LightingAndShadows/AmbientOcclusion/)

[3] [https://en.wikipedia.org/wiki/Ambient_occlusion](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Ambient_occlusion)

[4] [https://www.ics.uci.edu/\~gopi/CS211B/RayTracing%20tutorial.pdf](https://link.zhihu.com/?target=https%3A//www.ics.uci.edu/%7Egopi/CS211B/RayTracing%2520tutorial.pdf)

[5] [http://www.cnblogs.com/hielvis/p/6371840.html](https://link.zhihu.com/?target=http%3A//www.cnblogs.com/hielvis/p/6371840.html)

[6] [http://blog.csdn.net/thegibook/article/details/53058206](https://link.zhihu.com/?target=http%3A//blog.csdn.net/thegibook/article/details/53058206)

[7] [http://www.di.ubi.pt/\~agomes/cig/teoricas/02-raycasting.pdf](https://link.zhihu.com/?target=http%3A//www.di.ubi.pt/%7Eagomes/cig/teoricas/02-raycasting.pdf)

[8] [https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-837-computer-graphics-fall-2012/](https://link.zhihu.com/?target=https%3A//ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-837-computer-graphics-fall-2012/)

[9] [Crytek on DX12, Vulkan, Async Compute, Global Illumination, Ray-tracing,
Physically-based Rendering & E3
Demos](https://link.zhihu.com/?target=http%3A//www.dsogaming.com/interviews/crytek-dx12-vulkan-async-compute-global-illumination-ray-tracing-physically-based-rendering-e3-demos/)

```

`Content/《Real-Time Rendering 3rd》读书笔记/Content/BlogPost09/README.md`:

```md

![](media/title09.jpg)

# 【《Real-Time Rendering 3rd》 提炼总结】(九) 第十章 · 游戏开发中基于图像的渲染技术总结

这是一篇近万字的总结式文章，关于游戏开发中基于图像的渲染（Image-Based
Rendering，简称IBR）技术的方方面面，将总结《RTR3》书中第十章提到的16种常用的IBR渲染技术。

他们包括：

-   渲染谱 The Rendering Spectrum

-   固定视角的渲染 Fixed-View Rendering

-   天空盒 Skyboxes

-   光场渲染 Light Field Rendering

-   精灵与层 Sprites and Layers

-   公告板 Billboarding

-   粒子系统 Particle System

-   替代物 Impostors

-   公告板云 Billboard Clouds

-   图像处理 Image Processing

-   颜色校正 Color Correction

-   色调映射 Tone Mapping

-   镜头眩光和泛光 Lens Flare and Bloom

-   景深 Depth of Field

-   运动模糊 Motion Blur

-   体渲染 Volume Rendering

在过去很多年里，基于图像的渲染（Image-Based Rendering
，简称IBR），已经自成一派，逐渐发展成了一套广泛的渲染理念。正如其字面所表示的，图像是用于渲染的主要数据来源。用图像表示一个物体的最大好处在于渲染消耗与所要绘制的像素数量成正比，而不是几何模型的顶点数量。因此，使用基于图像的渲染是一种有效的渲染模型的方法。除此之外，IBR技术还有其他一些更为广泛的用途，比如云朵，皮毛等很多很难用多边形来表示的物体，却可以巧妙运用分层的半透明图像来显示这些复杂的表面。

OK，下面开始正文，对这16种常见的基于图像的渲染技术，分别进行介绍。

一、渲染谱 The Rendering Spectrum
=================================

众所周知，渲染的目的就是在屏幕上渲染出物体，至于如何达到结果，主要依赖于用户的选择，白猫黑猫，抓到老鼠的就是好猫。而用多边形将三维物体显示在屏幕上，并非是进行三维渲染的唯一方法，也并非是最合适的方法。多边形具有从任何视角以合理的方式表示对象的优点，当移动相机的时候，物体的表示可以保持不变。但是，当观察者靠近物体的时候，为了提高显示质量，往往希望用比较高的细节层次来表示模型。与之相反，当物体位于比较远的地方时，就可以用简化形式来表示模型。这就是细节层次技术(Level
Of Detail,LOD)。使用LOD技术主要目的是为了加快场景的渲染速度。

还有很多技术可以用来表示物体逐渐远离观察者的情形，比如，可以用图像而不是多边形来表示物体，从而减少开销，加快渲染速度。另外，单张图片可以很快地被渲染到屏幕上，用来表示物体往往开销很小。

如《地平线：黎明》远处的树木，即是采用公告板技术（Billboard）替换3D树木模型进行渲染。（关于公告板技术的一些更具体的总结，详见本文第六节）。

![](media/590e3c64bb248e4a5cb872db4ccbde07.jpg)

图1 《地平线：黎明》中利用了Billboard进行画面的渲染

Lengyel于1998在《The Convergence of Graphics and
Vision》一文中提出了一种表示渲染技术连续性的方法，名为The Rendering Spectrum
渲染谱，如下图所示。

![](media/fc43c8bcb25d64bb7f5138b1ef27121b.jpg)

图2 渲染谱 The Rendering Spectrum（RTR3书中版本）

![](media/17dcd2984bc58bc515c7454074e116ff.jpg)

图3 渲染谱 The Rendering Spectrum（Lengyel 1998论文版本）

可以将渲染谱理解为渲染的金字塔。从左到右，由简单到复杂，由二维图像到几何模型，从外观特征到物理渲染。

二、固定视角的渲染 Fixed-View Rendering
=======================================

固定视角的渲染（Fixed-View
Rendering）技术，通过将复杂几何模型转换为可以在多帧中重复使用的一组简单的buffer来节省大量渲染时间与性能。

对于复杂的几何和着色模型，每帧去重新渲染整个场景很可能是昂贵的。可以通过限制观看者的移动能力来对渲染进行加速。
最严格的情况是相机固定在位置和方位，即根本不移动。而在这种情况下，很多渲染可以只需做一次。

例如，想象一个有栅栏的牧场作为静态场景，一匹马穿过它。牧场和栅栏渲染仅一次，存储其颜色和Z缓冲区。每帧将这些buffer复制到可显示的颜色和Z缓冲中。为了获得最终的渲染效果，马本身是需要渲染的。如果马在栅栏后面，存储和复制的z深度值将把马遮挡住。请注意，在这种情况下，马不能投下阴影，因为场景无法改变。可以进行进一步的处理，例如，可以确定出马影子的区域，根据需求进行处理。关键是对于要显示的图像的颜色何时或如何设置这点上，是没有限制的。固定视角的特效（Fixed-View
Effects），可以通过将复杂几何模型转换为可以在多帧中重复使用的一组简单的buffer来节省大量时间。

在计算机辅助设计（CAD）应用程序中，所有建模对象都是静态的，并且在用户执行各种操作时，视图不会改变。一旦用户移动到所需的视图，就可以存储颜色和Z缓冲区，以便立即重新使用，然后每帧绘制用户界面和突出显示的元素。
这允许用户快速地注释，测量或以其他方式与复杂的静态模型交互。通过在G缓冲区中存储附加信息，类似于延迟着色的思路，可以稍后执行其他操作。
例如，三维绘画程序也可以通过存储给定视图的对象ID，法线和纹理坐标来实现，并将用户的交互转换为纹理本身的变化。

一个和静态场景相关的概念是黄金线程(Golden Thread)或自适应（Adaptive
Refinement）渲染。其基本思想是，当视点与场景不运动时，随着时间的推移，计算机可以生成越来越好的图像，而场景中的物体看起来会更加真实，这种高质量的绘制结果可以进行快速交换或混合到一系列画面中。这种技术对于CAD或其他可视化应用来说非常有用。而除此之外，还可以很多不同的精化方法。一种可能的方法是使用累积缓冲器（accumulation
buffer）做抗锯齿（anti-
aliasing），同时显示各种累积图像。另外一种可能的方法是放慢每像素离屏着色（如光线追踪，环境光遮蔽，辐射度）的速度，然后渐进改进之后的图像。

在RTR3书的7.1节介绍一个重要的原则，就是对于给定的视点和方向，给定入射光，无论这个光亮度如何计算或和隔生成这个光亮度的距离无关。眼睛没有检测距离，仅仅颜色。在现实世界中捕捉特定方向的光亮度可以通过简单地拍一张照片来完成。

QuickTime
VR是由苹果公司在1995年发布的VR领域的先驱产品，基本思路是用静态图片拼接成360度全景图。QuickTime
VR中的效果图像通常是由一组缝合在一起的照片，或者直接由全景图产生。随着相机方向的改变，图像的适当部分被检索、扭曲和显示。虽然这种方法仅限于单一位置，但与固定视图相比，这种技术具有身临其境的效果，因为观看者的头部可以随意转动和倾斜。

Kim，Hahn和Nielsen提出了一种有效利用GPU的柱面全景图，而且通常，这种全景图也可以存储每个纹素的距离内容或其他值，以实现动态对象与环境的交互。

如下的三幅图，便是是基于他们思想的全景图（panorama），使用QuickTime
VR来渲染出的全景视野范围。其中，第一幅是全景图原图，后两幅图是从中生成的某方向的视图。注意观察为什么这些基于柱面全景图的视图，没有发生扭曲的现象。

![](media/293977d9a4c798a56773f0fa30f80372.jpg)

图4 全景图原图

![](media/7caee45786dddd389ad0d1b16ff34ede.jpg)

图5 通过全景图得到的视图1

![](media/ae674686e49a6cec5f7c89741240f4f7.jpg)

图6 通过全景图得到的视图2

三、天空盒 Skyboxes
===================

对于一些远离观众的物体，观众移动时几乎没有任何视差效果。换言之，如果你移动一米，甚至一千米，一座遥远的山本身看起来通常不会有明显的不同。当你移动时，它可能被附近的物体挡住视线，但是把那些物体移开，山本身看起来也依旧一样。天空盒就属于这种类型的物体。

![](media/45a11667c371090a16b64b25a98d547e.jpg)

图7 基于天空盒渲染的场景 @mad max

环境贴图（environment
map）可以代表本地空间入射光亮度。虽然环境贴图通常用于模拟反射，但它们也可以直接用来表示环绕环境的远处物体。任何独立于视图的环境地图表示都可以用于此目的；立方体贴图（cubic
maps）是最为常见的一种环境贴图。环境贴图放置在围绕着观察者的网格上，并且足够大以包含场景中所有的对象。且网格的形状并不重要，但通常是立方体贴图。如下图，在该图所示的室内环境更像是一个QuickTime
VR全景的无约束版本。观众可以在任何方向观察这个天空盒，得到很好的真实体验。但同样，任何移动都会破坏这个场景产生的真实感错觉，因为移动的时候，并不存在视差。

![](media/5613fec115e5df6af05d5532ca16438e.jpg)

图8 一个典型的立方体环境贴图

环境贴图通常可以包含相对靠近反射对象的对象。因为我们通常并没有多精确地去在乎反射的效果，所以这样的效果依然非常真实。而由于视差在直接观看时更加明显，因此天空盒通常只包含诸如太阳，天空，远处静止不动的云和山脉之类的元素。

![](media/cac499b4a404ec45d94131fb76934f87.jpg)

图9 玻璃球折射和反射效果的一个立方体环境贴图，这个map本身用可作天空盒。

为了使天空盒看起来效果不错，立方体贴图纹理分辨率必须足够，即每个屏幕像素的纹理像素。
必要分辨率的近似值公式：

![](media/6c394a732a5b97f2f9394f961fe622a7.jpg)

其中，fov表示视域。该公式可以从观察到立方体贴图的表面纹理必须覆盖90度的视域（水平和垂直）的角度推导出。并且应该尽可能隐藏好立方体的接缝处，最好是能做到无缝的衔接，使接缝不可见。一种解决接缝问题的方法是，使用六个稍微大一点的正方形，来形成一个立方体，这些正方形的每个边缘处彼此相互重叠，相互探出。这样，可以将邻近表面的样本复制到每个正方形的表面纹理中，并进行合理插值。

![](media/9cf891288a85bc3614d650550c299cca.jpg)

图10 基于天空盒渲染的场景 \@rage

四、光场渲染 Light Field Rendering
==================================

所谓光场（Light Field），可以理解为空间中任意点发出的任意方向的光的集合。

而光场渲染（Light Field
Rendering），可以理解为在不需要图像的深度信息或相关性的条件下，通过相机阵列或由一个相机按设计的路径移动，把场景拍摄下来作为输出图像集。对于任意给定的新视点，找出该视点邻近的几个采样点进行简单的重新采样和插值，就能得到该视点处的视图。

magic leap公司目前的原型产品，Nvidia 公司的near-eye light field
display，Lytro公司发布的光场相机，都是基于Light Field技术。

![](media/934fd7b2cd303bd790828a51461d6fd1.jpg)

图11 Lytro公司的光场相机

![](media/e700f076625b74d80de4ba9b512d1256.jpg)

图12 SIGGRAPH 2014会议上，MIT’s Camera
CultureGroup介绍了一种基于开普勒望远镜中投影机和光学技术的无眼镜3D的新方法。
他们提出的“压缩光场投影（Compressive Light Field
Projection）”新方法由单个设备组成，并没有机械移动的物件。

五、精灵与层 Sprites and Layers
===============================

最基本的基于图像的渲染的图元之一便是精灵（sprite）。精灵（sprite）是在屏幕上移动的图像，例如鼠标光标。精灵不必具有矩形形状，而且一些像素可以以透明形式呈现。对于简单的精灵，屏幕上会显示一个一对一的像素映射。存储在精灵中的每个像素将被放在屏幕上的像素中。可以通过显示一系列不同的精灵来生成动画。

![](media/fa27b86f970d5806313d4b52ed5a5f5d.jpg)

图13 基于Sprite层级制作的《雷曼大冒险》@UBISOFT

更一般的精灵类型是将其渲染为应用于总是面向观看者的多边形的图像纹理。图像的Alpha通道可以为sprite的各种像素提供全部或部分透明度。这种类型的精灵可以有一个深度，所以在场景本身，可以顺利地改变大小和形状。一组精灵也可以用来表示来自不同视图的对象。对于大型物体，这种用精灵来替换的表现效果会相当弱，因为从一个精灵切换到另一个时，会很容易穿帮。也就是说，如果对象的方向和视图没有显着变化，则给定视图中的对象的图像表示可以对多个帧有效。而如果对象在屏幕上足够小，存储大量视图，即使是动画对象也是可行的策略。

考虑场景的一种方法是将其看作一系列的层（layers），而这种思想也通常用于二维单元动画。每个精灵层具有与之相关联的深度。通过这种从前到后的渲染顺序，我们可以渲染出整个场景而无需Z缓冲区，从而节省时间和资源。

![](media/f29a7a437733a209c4dd0bfd4162f570.jpg)

图14 基于Sprite层级制作的《雷曼大冒险》@UBISOFT

六、公告板 Billboarding
=======================

我们将根据观察方向来确定多边形面朝方向的技术叫做公告板（Billboarding，也常译作布告板）。而随着观察角度的变化，公告板多边形的方向也会根据需求随之改变。与alpha纹理和动画技术相结合，可以用公告板技术表示很多许多不具有平滑实体表面的现象，比如烟，火，雾，爆炸效果，能量盾（Energy
Shields），水蒸气痕迹，以及云朵等。如下文中贴图的，基于公告板渲染出的云朵。

![](media/bd2a5ee14a908178de09af9a79694e10.jpg)

图15 一棵由公告板技术渲染出的树木

![](media/c9b5933401c3fc92deefe9e3e619e754.jpg)

图16
给定表面的法线向量n和近似向上方向的向量u，通过创建一组由三个相互垂直的向量，就可以确定公告板的方向。其中，左图是互相垂直的u和n。中图是r向量通过u和n的叉乘得到，因此同时垂直于u和n，而在右图中，对固定向量n和r进行叉乘就可以得到与他们都垂直的的向上向量u’

有三种不同类型的Billboard，分别是：

-   Screen-Aligned Billboard 对齐于屏幕的公告板

-   World-Oriented Billboard 面向世界的公告板

-   Axial Billboard 轴向公告板

其中：

-   Screen-Aligned Billboard的n是镜头视平面法线的逆方向,u是镜头的up。

-   Axial Billboard的u是受限制的Axial, r = u\*
    n,(n是镜头视平面法线的逆方向,或,视线方向的逆方向),最后再计算一次n' = r \*
    u,即n'才是最后可行的代入M的n,表达了受限的概念。

-   World-orientedbillboard就不能直接使用镜头的up做up,因为镜头roll了,并且所画的billboard原本是应该相对世界站立的,按Screen-Aligned的做法就会随镜头旋转,所以此时应该r
    = u \* n(u是其在世界上的up,n是镜头视线方向的逆方向),最后再计算一次u = r \*
    n,即u'才是最后的up,即非物体本身相对世界的up,亦非镜头的up。

所以公告板技术是一种看似简单其实较为复杂的技术,它的实现变种较多。归其根本在于：

-   View Oriented / View plane oriented的不同

-   Sphere/ Axial的不同

-   Cameraup / World up的不同

如View Oriented 和View plane oriented的不同，得到的公告板效果就完全不同：

![](media/514cc3485f7c24b731867d72f60db19a.jpg)

图17 两种公告板对其技术的顶视图，左图为view
plane-aligned（视图平面对齐），右图为viewpoint-oriented（视点对齐），其面向的方向根据算法的不同而有所不同。

![](media/b9939199295c39ea8e3f14ffde2c64de.jpg)

图18 使用world-oriented Billboard创建的云层

在Unreal 4 Engine中，使用Axial Billboard作为树木LOD中的一级的一些图示 ：

![](media/19a1637a05ee7fad47cf66de36f9a518.jpg)

图19 使用Axialbillboard作为树木LOD中的一级 @Unreal 4 Engine

![](media/505fa53c10e94d80d7fc7576695ef371.jpg)

图20 使用Axialbillboard作为树木LOD中的一级 @Unreal 4 Engine

七、粒子系统 Particle System
============================

粒子系统（Particle
System）是一组分散的微小物体集合，其中这些微小物体按照某种算法运动。粒子系统的实际运用包括模拟火焰，烟，爆炸，流水，树木，瀑布，泡沫，旋转星系和其他的一些自然现象。粒子系统并不是一种渲染形式，而是一种动画方法，这种方法的思想是值粒子的生命周期内控制他们的产生，运动，变化和消失。

可以用一条线段表示一个实例，另外，也可以使用轴向公告板配合粒子系统，显示较粗的线条。

除了爆炸，瀑布，泡沫以及其他现象以外，还可以使用粒子系统进行渲染。例如，可以使用粒子系统来创建树木模型，也就是表示树木的几何形状，当视点距离模型较近时，就会产生更多的粒子来生成逼真的视觉效果。

以下是一幅用粒子系统渲染树木的示例：

![](media/809914acebf1a9534db788410292b687.jpg)

图21 基于粒子系统渲染的树木

八、替代物 Impostors
====================

作为一种公告板技术，替代物（Impostors）是通过从当前视点将一个复杂物绘制到一幅图像纹理上来创建的，其中的图像纹理用于映射到公告板上，渲染过程与替代物在屏幕上覆盖的像素点数成正比，而不是与顶点数或者物体的复杂程度成正比。替代物可以用于物体的一些实例上或者渲染过程的多帧上，从而使整体性能获得提升。

![](media/20899c734bcee76bd4c0423a03d6cde4.jpg)

图22
一幅树的视图和一个Impostors（Impostors的黑色背景是透明通道，在渲染时可以处理）

![](media/823f483ac1c39e30ff0215360db67f40.jpg)

图23 一幅相同的树和Impostors的线框视图

另外，Impostors和Billboard的纹理还可以结合深度信息（如使用深度纹理和高度纹理）进行增强。如果对Impostors和Billboard增加一个深度分量，就会得到一个称为深度精灵（depth
sprite）或者nailboard（译作钉板，感觉很奇怪）的相关绘制图元。也可以对Impostors和Billboard的纹理做浮雕纹理映射（relief
texture mapping）。

关于Impostors，一篇很好的文章是William Damon的《Impostors Made
Easy》，有进一步了解兴趣的朋友可以进行延伸阅读：

[https://software.intel.com/en-us/articles/impostors-made-easy](http://link.zhihu.com/?target=https%3A//software.intel.com/en-us/articles/impostors-made-easy)

九、公告板云 Billboard Clouds
=============================

使用Imposters的一个问题是渲染的图像必须持续地面向观察者。如果远处的物体正在改变方向，则必须重新计算Imposters的朝向。而为了模拟更像他们所代表的三角形网格的远处物体，D´ecoret等人提出了公告板云（Billboard
Clouds）的想法，即一个复杂的模型通常可以通过一系列的公告板集合相互交叉重叠进行表示。我们知道，一个真实物体可以用一个纸模型进行模拟，而公告板云可以比纸模型更令人信服，比如公告板云可以添加一些额外的信息，如法线贴图、位移贴图和不同的表面材质。另外，裂纹沿裂纹面上的投影也可以由公告板进行处理。而D´ecoret等人也提出了一种在给定误差容限内对给定模型进行自动查找和拟合平面的方法。

如下是在UNIGINE Engine（注意这不是虚幻引擎，经常会被看错）中基于Billboard
Clouds技术创建云层效果的一个示例：

![](media/e1f3da41e0446f83963d052804080d9b.jpg)

图24 Billboard Clouds技术创建云层示例图 \@UNIGINE Engine

![](media/3297ffb6a33be00acbf7723d94f64aa0.jpg)

图25 Billboard Clouds技术创建云层的最终效果图 \@UNIGINE Engine

十、图像处理 Image Processing
=============================

图像处理的过程，一般在像素着色器中进行，因为在像素着色器中，可以很好地将渲染过程和纹理结合起来，而且在GPU上跑像素着色器，速度和性能都可以满足一般所需。

一般而言，首先需要将场景渲染成2D纹理或者其他图像的形式，再进行图像处理，这里的图像处理，往往指的是后处理（post
effects）。而下文将介绍到的颜色校正（Color Correction）、色调映射（Tone
Mapping）、镜头眩光和泛光（Lens Flare and Bloom）、景深（Depth of
Field）、运动模糊（Motion Blur），一般而言都是后处理效果。

![](media/d0924ae103676223cc8132512e321a7e.jpg)

图26
使用像素着色器进行图像处理。左上为原始图像；右上角显示高斯差分操作，左下边缘显示检测，右下混合的边缘检测与原图像混合。

十一、颜色校正 Color Correction
===============================

色彩校正(Color
correction)是使用一些规则来转化给定的现有图像的每像素颜色到其他颜色的一个过程。颜色校正有很多目的，例如模仿特定类型的电影胶片的色调，在元素之间提供一致的外观，或描绘一种特定的情绪或风格。一般而言，通过颜色校正，游戏画面会获得更好的表现效果。

![](media/b4b24b0b45244b0c24ed068f6272449c.jpg)

图27 左图是准备进行颜色校正的原图。右图是通过降低亮度，使用卷积纹理（Volume
Texture），得到的夜间效果。\@Valve

颜色校正通常包括将单个像素的RGB值作为输入，并向其应用算法来生成一个新的RGB。颜色校正的另一个用途是加速视频解码，如YUV色彩空间到RGB色彩空间的转换。基于屏幕位置或相邻像素的更复杂的功能也可行，但是大多数操作都是使用每像素的颜色作为唯一的输入。

对于一个计算量很少的简单转换，如亮度的调整，可以直接在像素着色器程序中基于一些公式进行计算，应用于填充屏幕的矩形。

而评估复杂函数的通常方法是使用查找表（Look-Up
Table，LUT）。由于从内存中提取数值经常要比复杂的计算速度快很多，所以使用查找表进行颜色校正操作，速度提升是很显著的。

![](media/5f056b22719c32235d5aec6bbfaf71c6.jpg)

图28 原图和经过色彩校正后的几幅效果图 \@Unreal 4 Engine

![](media/b9076de4359ad8ae0837d53b8c466877.jpg)

图29 原图和经过颜色校正的效果图 @Crysis

十二、色调映射 Tone Mapping
===========================

计算机屏幕具有特定的亮度范围，而真实图像具有更巨大的亮度范围。色调映射（Tonemapping），也称为色调复制（tone
reproduction），便是将宽范围的照明级别拟合到屏幕有限色域内的过程。色调映射与表示高动态范围的HDR和HDRI密切相关：

-   HDR，是High-Dynamic
    Range（高动态范围）的缩写，可以理解为一个CG的概念，常出现在计算机图形学与电影、摄影领域中。

-   HDRI是High-Dynamic Range Image的缩写，即HDR图像，高动态范围图像。

-   而实际过程中，HDR和HDRI两者经常会被混用，都当做高动态范围成像的概念使用，这也是被大众广泛接受的。

本质上来讲，色调映射要解决的问题是进行大幅度的对比度衰减将场景亮度变换到可以显示的范围，同时要保持图像细节与颜色等表现原始场景的重要信息。

根据应用的不同，色调映射的目标可以有不同的表述。在有些场合，生成“好看”的图像是主要目的，而在其它一些场合可能会强调生成尽可能多的细节或者最大的图像对比度。在实际的渲染应用中可能是要在真实场景与显示图像中达到匹配，尽管显示设备可能并不能够显示整个的亮度范围。

![](media/488ea9626a214483fe33def051bd7f9e.jpg)

图30 经过色调映射得到的高动态范围图像 \@新西兰惠灵顿圣保罗教堂

十三、镜头眩光和泛光 Lens Flare and Bloom
=========================================

镜头眩光（Lens
flare）是由于眼睛的晶状体或者相机的透镜直接面对强光所产生的一种现象，由一圈光晕（halo）和纤毛状的光环（ciliary
corona）组成。光晕的出现是因为透镜物质（如三棱镜）对不同波长光线折射数量的不过而造成的，看上去很像是光周围的一个圆环，外圈是红色，内圈是紫红色。纤毛状的光环源于透镜的密度波动，看起来像是从一个点发射出来的光线。Lens
flare是近来较为流行的一种图像效果，自从我们认识到它是一种实现真实感效果的技术后，计算机便开始模拟此效果。

![](media/66f25241522b5c020bdcb902f32c38a7.jpg)

图31 镜头眩光效果 @WatchDogs

泛光（Bloom）效果，是由于眼睛晶状体和其他部分的散光而产生，在光源附近出现的一种辉光。在现实世界中，透镜无法完美聚焦是泛光效果的物理成因；理想透镜也会在成像时由于衍射而产生一种名为艾里斑的光斑。

常见的一个误解便是将HDR和Bloom效果混为一谈。Bloom可以模拟出HDR的效果，但是原理上和HDR相差甚远。HDR实际上是通过映射技术，来达到整体调整全局亮度属性的，这种调整是颜色，强度等都可以进行调整，而Bloom仅仅是能够将光照范围调高达到过饱和，也就是让亮的地方更亮。不过Bloom效果实现起来简单，性能消耗也小，却也可以达到不错的效果。

![](media/28d2610b43aa2418618e26c40353e3bf.jpg)

图32 Bloom效果 @ Battlefield3

![](media/4621bd1852fc09f6f4d99b7585ac0307.jpg)

图33 《Battlefield 3》中的渲染效果，同时包含镜头眩光（Lens
flare），泛光（Bloom）和Dirty Lens

十四、景深 Depth of Field
=========================

在光学领域，特别是摄影摄像领域，景深（Depth of field，DOF），也叫焦点范围（focus
range）或有效焦距范围（effective
focus），是指场景中最近和最远的物体之间出现的可接受的清晰图像的距离。换言之，景深是指相机对焦点前后相对清晰的成像范围。在相机聚焦完成后，在焦点前后的范围内都能形成清晰的像，这一前一后的距离范围，便叫做景深。

![](media/58cd5c81df41392b012bd7c0f50b4fa2.jpg)

图34 摄影中典型的景深效果

虽然透镜只能够将光聚到某一固定的距离，远离此点则会逐渐模糊，但是在某一段特定的距离内，影像模糊的程度是肉眼无法察觉的，这段距离称之为景深。当焦点设在超焦距处时，景深会从超焦距的一半延伸到无限远，对一个固定的光圈值来说，这是最大的景深。

景深通常由物距、镜头焦距，以及镜头的光圈值所决定（相对于焦距的光圈大小）。除了在近距离时，一般来说景深是由物体的放大率以及透镜的光圈值决定。固定光圈值时，增加放大率，不论是更靠近拍摄物或是使用长焦距的镜头，都会减少景深的距离；减少放大率时，则会增加景深。如果固定放大率时，增加光圈值（缩小光圈）则会增加景深；减小光圈值（增大光圈）则会减少景深。

景深的效果在计算机图形学中应用广泛，电影，游戏里面经常会利用景深特效来强调画面重点。相应的，已经有了很多成熟的算法在不同的渲染方法，而光栅化可以很高效的实现现有的景深算法。

![](media/9b534556c434464843bfa4fcf157c4e3.jpg)

图35 景深效果 @Battlefield 4

![](media/3e72d369cbd6598ebcd44220f3d43805.jpg)

图36 景深效果 @ Witcher 2

十五、运动模糊 Motion Blur
==========================

现实世界中，运动模糊（Motion
Blur，或译为动态模糊)，是因为相机或者摄影机的快门时间内物体的相对运动产生的。在快门打开到关上的过程中，感光材料因为受到的是物体反射光持续的照射成像。即在曝光的这个微小时间段内，对象依然在画面中移动，感光材料便会记录下这段时间内物体运动的轨迹，产生运动模糊。

我们经常在电影中看到这种模糊，并认为它是正常的，所以我们期望也可以在电子游戏中看到它，以带给游戏更多的真实感。

若无运动模糊，一般情况下，快速移动的物体会出现抖动，在帧之间的多个像素跳跃。这可以被认为是一种锯齿，但可以理解为基于时间的锯齿，而不是基于空间的锯齿。在这个意义上，运动模糊可以理解为是一种时间意义上的抗锯齿。

正如更高的显示分辨率可以减少但不能消除锯齿，提高帧速率并不能消除运动模糊的需要。而视频游戏的特点是摄像机和物体的快速运动，所以运动模糊可以大大改善画面的视觉效果。而事实表明，带运动模糊的30
FPS画面，通常看起来比没有带运动模糊的60 FPS画面更出色。

![](media/815f9fbd643f59be375a4299c3c1100d.jpg)

图37 Motion Blur效果 @GTA5

在计算机绘制中产生运动模糊的方法有很多种。一个简单但有限的方法是建模和渲染模糊本身。

实现运动模糊的方法大致分3种：

1、直接渲染模糊本身。通过在对象移动之前和之后添加几何体来完成，并通过次序无关的透明，避免Alpha混合。

2、基于累积缓冲区（accumulationbuffer），通过平均一系列图像来创建模糊。

3、基于速度缓冲器（velocity
buffer）。目前这个方法最为主流。创建此缓冲区，需插入模型三角形中每个顶点的屏幕空间速度。通过将两个建模矩阵应用于模型来计算速度，一个用于最后一个帧，一个用于当前模型。顶点着色器程序计算位置的差异，并将该向量转换为相对的屏幕空间坐标。图10.34显示了速度缓冲器及其结果。

![](media/4ae3528687a1fc8a40cc5dfe86daaa75.jpg)

图38 Motion Blur效果 @Battlefield4

运动模糊对于由摄像机运动而变得模糊的静态物体来说比较简单，因为往往这种情况下不需要速度缓冲区。如果需要的是摄像机移动时的运动感，可以使用诸如径向模糊（radial
blur）之类的固定效果。如下图。

![](media/e182a99641e64dd2fe899aa29fadbaa1.jpg)

图39 径向模糊可以增强运动感 @《刺客信条》Ubisoft

十六、体渲染 Volume Rendering
=============================

体渲染（Volume
Rendering），又称立体渲染，体绘制，是一种用于显示离散三维采样数据集的二维投影的技术。体渲染技术中的渲染数据一般用体素（Volumeric
Pixel，或Voxel）来表示，每个体素表示一个规则空间体。例如，要生成人头部的医学诊断图像（如CT或MRI），同时生成256
x256个体素的数据集合，每个位置拥有一个或者多个值，则可以将其看做三维图像。因此，体渲染也是基于图像的渲染技术中的一种。

![](media/6d03618e22c195156deff452400dd96f.jpg)

图40 一个典型的体渲染Pipeline

体渲染技术流派众多，常见的流派有：

-   体光线投射Volume ray casting

-   油彩飞溅技术Splatting

-   剪切变形技术Shear warp

-   基于纹理的体绘制Texture-based volume rendering

-   等。

![](media/e3e5e853d751c4608163ccd93806c6f1.jpg)

图41 基于Splatting和voxel在Unreal 4中进行的体渲染

![](media/6ba56f71f53af9b57c93893bd4eec1fd.jpg)

图42 Volume Cloud（体积云）效果 @Unity 5

![](media/4ca35afecf4f94631818c69e51e784c5.jpg)

图43 Volume Fog（体积雾）效果 @CRY ENGINE 3

```

`Content/《Real-Time Rendering 3rd》读书笔记/Content/BlogPost10/README.md`:

```md
![](media/title10.jpg)

# 【《Real-Time Rendering 3rd》 提炼总结】(十) 第十一章 · 非真实感渲染(NPR)相关技术总结

与传统的追求照片真实感的真实感渲染不同，非真实感渲染（Non-Photorealistic
Rendering，NPR）旨在模拟艺术式的绘制风格，常用来对绘画风格和自然媒体（如铅笔、钢笔、墨水、木炭、水彩画等）进行模拟。而卡通渲染（Toon
Rendering）作为一种特殊形式的非真实感渲染方法，近年来倍受关注。

通过阅读这篇文章，你将对非真实感渲染技术的以下要点有所了解：

-   非真实感渲染的基本思想和相关领域

-   卡通渲染

-   轮廓描边的几种实现流派

-   1）基于视点方向的描边

-   2）基于过程几何方法的描边

-   3）基于图像处理生成的描边

-   4）基于轮廓边缘检测的描边

-   5）混和轮廓描边

-   其他风格的NPR渲染技术

-   1）纹理调色板（Palette of Textures）

-   2）色调艺术图（Tonal Art Maps，TAM）

-   3）嫁接（Graftals）

-   水彩风格的NPR

一、非真实感渲染
================

正如变化的字体会给人不一样的感觉，不同的渲染风格会带给人们不同的心情，感受与意境。

非真实感渲染（Non-Photorealistic Rendering，NPR），
亦被称为风格化渲染（Stylistic
Rendering），是致力于为数字艺术提供多种表达方式的一种渲染流派。与传统的追求照片真实感的真实感渲染（Photorealistic
Rendering）计算机图形学不同，非真实感渲染旨在模拟艺术式的绘制风格，也用于尝试新的绘制风格。

![](media/8a4df70b2c61e3a745d6fae5bcfb1875.jpg)

图1 真实感渲染 vs. 非真实感渲染 @ruben3d

NPR的目的之一就是创建类似技术示意图、技术图纸相关的图像，而另一个应用领域便是对绘画风格和自然媒体（如铅笔、钢笔、墨水、木炭、水彩画等）进行模拟。这是一个涉及内容非常之多的应用领域，为了捕捉各种媒体的真实效果，人们已经提出了各种不同的算法。

![](media/77f97adcad1d1cedb531a104e8e65875.jpg)

图2 基于NPR渲染出的水墨画 @suiboku

![](media/e05abb1ef58fda963600498c4ff1b48f.jpg)

图3 基于NPR渲染出的铅笔素描\@ Real-Time Hatching . SIGGRAPH 2001

非真实感渲染与我们并不遥远，它早以“卡通着色（Toon
Shading）”的形式出现在各式动漫和电影中。

![](media/555c2a10c99f86666bdb84d40d45ff03.jpg)

图4 基于卡通着色的2016年高分动漫电影《你的名字》

在游戏制作方面，各种涉及到非真实感渲染的作品数不胜数，《Ōkami(大神)》，《The
Legend of
Zelda（塞尔达传说）》系列，甚至到现在的《Dota2》、《英雄联盟》、《守望先锋》，都多多少少涉及到了NPR。

![](media/e353855fcbaefed07d13ea26c40e4a77.jpg)

图5 非真实感渲染风格强烈的《塞尔达传说：荒野之息》

![](media/f89af80f794db7d68576521f3c034c44.jpg)

图6 非真实感渲染风格强烈的《塞尔达传说：荒野之息》

二、卡通渲染
============

上文提到，一直以来，有一种特殊形式的NPR倍受关注，且和我们的生活息息相关，那就是卡通渲染（Toon
Rendering，又称Cel Rendering）。这种渲染风格能够给人以独特的感染力与童趣。

这种风格很受欢迎的原因之一是McCloud的经典著作《Understanding
Comics》中所讲述到的“通过简化进行增强（Amplification Through
Simplification）”。通过简化并剔除所包含的混杂部分，可以突出于主题相关的信息，而大部分观众都会认同那些用简单风格描绘出来的卡通形象。

在计算机图形学领域，大约在20世纪90年代就开始使用toon渲染风格来实现三维模型和二维cel动画之间的结合。而且和其他NPR风格相比，这种绘制方法比较简单，可以很容易地利用计算机进行自动生成。

可以将最卡通着色基本的三个要素概括为：

-   锐利的阴影（Sharp shadows）

-   少有或没有高亮的点（Little or no highlight）

-   对物体轮廓进行描边（Outline around objects）

关于toon渲染，有很多不同的实现方法。

-   对于含有纹理但没有光照的模型来说，可以通过对纹理进行量化来近似具有实心填充颜色的卡通风格。

-   对于明暗处理，有两种最为常见的方法，一种是用实心颜色填充多边形区域。但这种方式实用价值不大。另一种是使用2-tone方法来表示光照效果和阴影区域。也称为硬着色方法（Hard
    Shading），可以通过将传统光照方程元素重新映射到不同的调色板上来实现。此外，一般用黑色来绘制图形的轮廓，可以达到增强卡通视觉效果的目的。

![](media/7cd08f44f46b4f8a78538e5a2fc5ebb2.jpg)

图7 真实感光照模型和卡通着色模型

具体的着色方法，可以理解为在Fragment
shader中测试每个像素漫反射diffuse中的NdotL值，让漫反射形成一个阶梯函数，不同的NdotL区域对应不同的颜色。下图显示了不同的漫反射强度值的着色部分阶梯指定了不同的像素颜色。

![](media/b6f46828044ec4370b5556005ef959d3.jpg)

图8 不同的漫反射强度值的着色部分阶梯指定不同的像素颜色

![](media/ca931107812f4c1200d0ef82395b520e.jpg)

图9 不同的卡通着色细节效果

三、轮廓描边的渲染方法小结
==========================

轮廓描边的渲染方法可以分为以下五种：

1）基于视点方向的描边

2）基于过程几何方法的描边

3）基于图像处理的描边

4）基于轮廓边缘检测的描边

5）混和轮廓描边

下面分别进行介绍。

3.1 基于视点方向的描边
----------------------

基于视点方向的描边方法，即表面角描边（Surface Angle
Silhouetting），其基本思想是使用视点方向（view point）和表面法线（surface
normal）之间的点乘结果得到轮廓线信息。如果此点乘结果接近于零，那么可以断定这个表面极大概率是侧向（Edge-on）的视线方向，而我们就将其视做轮廓边缘，进行描边。

这种方法相当于用一个边缘为黑色圆环的环境贴图（Environment
Map），对物体表面进行着色处理，如图所示。

![](media/43494acacc169029846e0f63ff308449.png)

图10
使用球形图来绘制边缘轮廓，如果沿着球形图的边缘对圆进行加宽，即可产生较粗的轮廓

在实际应用中，通常使用一张一维纹理（一般我们称其为ramp图）来代替环贴图。也就是使用视角方向与顶点法向的点乘对该纹理进行采样。

需要注意，这种技术仅适用于一些特定的模型，这些模型必须保证法线与轮廓边缘之间存在一定关系。诸如立方体这样的模型，此方法并不太适用，因为往往无法得到轮廓边缘。但我们可以通过显式地绘制出折缝边缘，来正确地表现出这类比较明显的特征。

3.2 基于过程几何方法的描边
--------------------------

基于过程几何方法生成的描边，即过程几何描边（Procedural Geometry
Silhouetting），基本思想是先渲染正向表面（frontfaces），再渲染背向表面（backfaces），从而使得轮廓边缘可见，达到描边的目的。

有多种方法用来渲染背向表面，且各有优缺点。但它们都是先渲染正向表面，然后打开正向表面裁剪（culling）开关，同时关闭背向裁剪开关。这样这个pass中的渲染结果便只会显示出背向表面。

一种基于过程几何方法生成的描边的方法是仅仅渲染出背向表面的边界线（而不是面），使用偏置（Biasing）或者其他技术来确保这些线条恰好位于正向表面之前。这样就可以将除轮廓边缘之外的其他所有线条全部隐藏起来。这种方法非常适合单像素宽的线条，但如果线条的宽度超过这个值，那么通常会出现无法连接独立线段的情况，从而造成明显的缝隙。

另一种渲染较宽描边线条的方法是直接将背面表面本身渲染成黑色。但没有任何偏置操作，背向表面就会保持不可见，所以需要做的就是通过偏置将这些背向表面沿屏幕Z方向向前移动，这样，便只有背向表面的三角形边缘是可见的。

如下图，可以使用背向表面的斜率对对多边形进行向前偏置，但是线条宽度依然依赖于正向表面的角度。

![](media/aa35ec948bfac13ee5e611eda4571878.jpg)

图11
描边的z偏置方法，可以通过对背向表面进行向前平移来实现。如果正向表面的角度不同，那么背向表面的可见量也不同。

3.3 基于图像处理的描边
----------------------

基于图像处理生成轮廓描边（Silhouetting by Image
Processing），即通过在各种缓冲区上执行图像处理技术，来实现非真实渲染的方法。可以将其理解为一种后处理操作。通过寻找相邻Z缓冲数值的不连续性，就可以确定大多数轮廓线的位置。同样，借助邻接表面法线向量的不连续性，可以确定出分界线（往往也是轮廓线）边缘的位置。此外，利用环境色对场景进行绘制，也可以用来检测前两种方法可能会漏掉的边缘。

![](media/bd2ae2deeb73d6ac98ee4c9833a70f60.jpg)

图12 基于图像处理的描边

![](media/87462d3ce18b23d74a87cdf4bd181e37.jpg)

图13
通过对场景的法线图和z深度值就行处理来进行边缘检测，右图所示为经过加粗的合成结果。注意，在这种情况下，使用法线图就主义检测出所有的边缘。

3.4 基于轮廓边缘检测的描边
--------------------------

上文提到的大多数渲染描边的方法都存在一个缺点，那就是他们都需要两个通道才能完成物体轮廓描边的渲染。

基于轮廓边缘检测的描边，通过检测出轮廓边缘（Silhouette
EdgeDetection）），并直接对它们进行绘制，这种形式的描边，可以很好地控制线条绘制的过程。由于边缘独立于模型，因此这种方法还有另外一个优点，就是能够生成一些特殊的效果。例如，在网格密集的地方可以突现出轮廓边缘。

可以将轮廓边缘理解为朝向相反的相邻三角形的交接。也就是说，其中的一个三角形是朝向视点，另一个三角形背向视点。具体测试方法如下：

![](media/90007e63aacbdd5b1027c6950a44fbad.jpg)

其中n0和n1分别表示两个三角形的表面法线向量，v表示从视点到这条边缘（也就是其中任何一个端点）的视线方向向量。而为了确保这种测试的准确性，必须保证表面的取向一致。

3.5 混和轮廓描边
----------------

混和轮廓描边（Hybrid
Silhouetting），即结合了图像处理方法和几何要素方法，来渲染轮廓的方法。

这种方法的具体思想是：首先，找到一系列轮廓边缘的列表。其次，渲染出所有物体的三角形和轮廓边缘，同时为他们指定一个不同的ID值（也就是说，赋予不同的颜色）。接着读取该ID缓冲器并从中判断出可见的轮廓边缘，随之对这些可见线段进行重叠检测，并将它们连接起来形成平滑的笔划路径。最后就可以对这些重建起来的路径进行风格化笔划渲染，其中，这些笔划本身可以用很多方法来进行风格化处理，包括变细、火焰、摆动、淡化等效果，同时还有深度和距离信息。如下图。

![](media/da3e47df266d222ad6876b1f067e3214.jpg)

图14
使用混合轮廓描边方法生成的图像，其中可以将找到的轮廓边缘连接起来作为笔划进行渲染。

四、其他风格的NPR渲染技术小结
=============================

除了toon渲染这种比较受欢迎的模拟风格之外，还存在其他各式各样的风格。NPR效果涵盖的范围非常广泛，从修改具有真实感效果的纹理，到使用算法一幅幅画面的几何修饰。RTR3中主要谈了3种不同的其他风格的NPR渲染技术：

-   纹理调色板（Palette of Textures）

-   色调艺术图（Tonal Art Maps，TAM）

-   嫁接（Graftals）

下面分别进行介绍。

4.1 纹理调色板（Palette of Textures）
-------------------------------------

纹理调色板（palette of
textures）由Lake等人讨论提出，基本思想是通过反射着色项（diffuse shading
term）的不同，来选择应用于物体表面上的不同纹理。随着漫反射项逐渐变暗，可以选用相应更暗的纹理，而为了能够产生手绘的效果，可以使用屏幕空间坐标来采样纹理。同时，为了增强绘制效果，可以在屏幕空间上的所有表面上运用纸纹理。随着物体的运动，他们就可以在纹理之间进行穿梭。原因在于这个纹理是在屏幕空间中实现的。此外，也可以在世界空间中运用这个纹理，这样就能够得到一个与屏幕空间完全不同的效果。

![](media/b2a7f2cc345d999465e89e230cb50c42.jpg)

图15 使用纹理调色板（paletteof
textures）、纸纹理，以及轮廓边缘绘制生成的一幅图像。

4.2 色调艺术图（Tonal Art Maps，TAM）
-------------------------------------

通过在纹理之间进行切换形成的硬着色效果和toon着色效果之间的一种混合，Praun等人（[https://www.dimap.ufrn.br/\~motta/dim102/Projetos/p581-praun.pdf](https://link.zhihu.com/?target=https%3A//www.dimap.ufrn.br/%7Emotta/dim102/Projetos/p581-praun.pdf)）提出了一种可以实时生成笔划纹理分级细化图的方法，并可以将其以平滑的方式运用到物体表面上。第一步是生成即时使用的纹理，称为色调艺术图（Tonal
Art Maps，TAM）,主要思想是将笔划绘制为分级细分图层次，如图。

![](media/12b6f54b662f7ec8729e4da53e5177a2.jpg)

图16
TAM将笔划绘制到细分图层次中，每个分级细化图层次包含图中左边和上边纹理中的所有笔划，这样，在细化图层次之间和相邻纹理之间的插值就比较平滑

![](media/b9dedc289bed06fa05d21a98fd9c2252.jpg)

图17 使用TAM渲染一副素描图的过程

![](media/7ca03ec484d437500961064558096732.jpg)

图18 6种不同的TAM渲染出的6组不同模型

4.3 嫁接（Graftals）
--------------------

嫁接（Graftals）的基本思想，是将几何或者贴花纹理应用到物体表面，从而产生某种特殊效果。可以通过所需要的细节层次，物体表面相对视点的方位或者其他因素，对纹理进行控制。这种方法可以用来模拟钢笔或者画刷的笔刷，如下图。

![](media/8f1d2a9fce0a9ea47ae0bba8c89aca3a.jpg)

图19 使用两种不同的嫁接（Graftals）风格绘制出来的Standord小兔

五、关于水彩风格的NPR
=====================

在写这篇文章查阅NPR相关资料的过程中，发现了非常酷的一个水彩风格化渲染的框架，Maya
Non-photorealistic Rendering
Framework，简称MNPR.[http://artineering.io/docs/mnprDocsWC/](https://link.zhihu.com/?target=http%3A//artineering.io/docs/mnprDocsWC/)。

MNPR在SIGGRAPH
2017有亮相，可以实现非常棒的水彩（Watercolor）渲染效果。有兴趣的朋友可以了解一下。以下是相关的一些精彩的图示。

![](media/b48283a83c3231560729e31869c48c62.jpg)

图20 一个典型水彩风格渲染流程图

![](media/f9760de1d46bba49d6f8ba564557a520.jpg)

图21 水彩风格的NPR建模过程

![](media/fd357e9644f691f239ed99621c2d27ab.jpg)

图22 水彩风格的NPR效果图

![](media/f28b20fde96bdfd003bd7b4841bd8167.jpg)

图23 真实感渲染 vs. 水彩风格NPR渲染

![](media/f6ad5ca770f2aea4296b1db72ce5408b.jpg)

图24 水彩NPR的渲染过程

六、NPR相关著作
===============

如下两本书从技术和NPR绘画算法两个方面，对非真实感渲染有了一个系统的涵盖，可谓NPR界的泰斗之作，有兴趣的朋友不妨进一步深入阅读。

-   Gooch, Bruce or Amy, and Amy or Bruce Gooch, Non-Photorealistic Rendering,A
    K Peters Ltd., 2001.

-   Strothotte, Thomas, and Stefan Schlechtweg ,Non-Photorealistic Computer
    Graphics: Modeling, Rendering, and Animation, Morgan Kaufmann, 2002.

七、NPR相关延伸资料推荐
=======================

-   链接（[http://kesen.realtimerendering.com/](https://link.zhihu.com/?target=http%3A//kesen.realtimerendering.com/)）中的Non-Photorealistic
    Animation and Rendering Proceedings
    一栏里可以找到NPR业界前沿的一些发展近况，即NPAR会议相关的资源。

-   SIGGRAPH 2010 上Stylized Rendering in Games 课程（[Stylized Rendering in
    Games](https://link.zhihu.com/?target=http%3A//stylized.realtimerendering.com/)）里有不少值得了解的NPR的内容。

-   NPR resources
    page（[http://www.red3d.com/cwr/npr/](https://link.zhihu.com/?target=http%3A//www.red3d.com/cwr/npr/)）里的材料也值得一看。

Reference
=========

[1] [http://www.gatheryourparty.com/2013/05/30/crash-course-cel-shading-in-video-games/](https://link.zhihu.com/?target=http%3A//www.gatheryourparty.com/2013/05/30/crash-course-cel-shading-in-video-games/)

[2] [http://www-cg.cis.iwate-u.ac.jp/lab/suiboku.html](https://link.zhihu.com/?target=http%3A//www-cg.cis.iwate-u.ac.jp/lab/suiboku.html)

[3] <https://zhuanlan.zhihu.com/p/26409746>

[4] <https://www.zhihu.com/question/32078473>

[5] [http://www.valvesoftware.com/publications/2007/NPAR07_IllustrativeRenderingInTeamFortress2.pdf](https://link.zhihu.com/?target=http%3A//www.valvesoftware.com/publications/2007/NPAR07_IllustrativeRenderingInTeamFortress2.pdf)

[6] [http://www.4gamer.net/games/216/G021678/20140703095/](https://link.zhihu.com/?target=http%3A//www.4gamer.net/games/216/G021678/20140703095/)

[7] [http://www.4gamer.net/games/216/G021678/20140714079/](https://link.zhihu.com/?target=http%3A//www.4gamer.net/games/216/G021678/20140714079/)

[8] [http://www.4gamer.net/games/216/G021678/20150317055/](https://link.zhihu.com/?target=http%3A//www.4gamer.net/games/216/G021678/20150317055/)

[9][https://en.wikipedia.org/wiki/Cel_shading](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Cel_shading)

[10] Praun E, Hoppe H, Webb M, et al.Real-time hatching[C]//Proceedings of the
28th annual conference on Computergraphics and interactive techniques. ACM,
2001:
581. [http://gfx.cs.princeton.edu/proj/hatching/](https://link.zhihu.com/?target=http%3A//gfx.cs.princeton.edu/proj/hatching/)

[11] [http://blog.csdn.net/silangquan/article/details/17184807](https://link.zhihu.com/?target=http%3A//blog.csdn.net/silangquan/article/details/17184807)

[12] [http://blog.csdn.net/candycat1992/article/details/45577749](https://link.zhihu.com/?target=http%3A//blog.csdn.net/candycat1992/article/details/45577749)

[13] [http://blog.csdn.net/thenile/article/details/8858702](https://link.zhihu.com/?target=http%3A//blog.csdn.net/thenile/article/details/8858702)

[14] [http://www.cs.duke.edu/courses/compsci344/spring15/classwork/16_npr/cmu.pdf](https://link.zhihu.com/?target=http%3A//www.cs.duke.edu/courses/compsci344/spring15/classwork/16_npr/cmu.pdf)

[15] [http://libregraphicsworld.org/blog/entry/freestyle-jot-and-the-future-of-non-photorealistic-rendering](https://link.zhihu.com/?target=http%3A//libregraphicsworld.org/blog/entry/freestyle-jot-and-the-future-of-non-photorealistic-rendering)

[16] [http://www.cartoonbrew.com/tag/non-photorealistic-rendering](https://link.zhihu.com/?target=http%3A//www.cartoonbrew.com/tag/non-photorealistic-rendering)

[17] Art-directed watercolor stylization of3D animations in real-time

[http://artineering.io/articles/Art-directed-watercolor-stylization-of-3D-animations-in-real-time/](https://link.zhihu.com/?target=http%3A//artineering.io/articles/Art-directed-watercolor-stylization-of-3D-animations-in-real-time/)

[18] [https://expressivesymposium.com/](https://link.zhihu.com/?target=https%3A//expressivesymposium.com/)

![](media/21df4a296f72cb12ea7fb54f0f77d1d7.jpg)

```

`Content/《Real-Time Rendering 3rd》读书笔记/Content/BlogPost11/README.md`:

```md
![](media/title11.jpg)

# 【《Real-Time Rendering 3rd》 提炼总结】(十一) 第十四章 : 游戏开发中的渲染加速算法总结
<br>

导读
====

这是一篇1万3千余字的总结式文章，通过阅读，你将对游戏开发与实时渲染中加速渲染算法的以下要点有所了解：

-   常用空间数据结构（Spatial Data Structures）

    -   层次包围盒（BVH ,Bounding Volume Hierarchies）

    -   BSP树（BSP Trees）

    -   八叉树（Octrees）

    -   场景图（Scene Graphs）

-   各种裁剪技术（Culling Techniques）

    -   背面裁剪（Backface Culling）

    -   视锥裁剪（View Frustum Culling）

    -   遮挡剔除（Occlusion Culling）

    -   层次视锥裁剪（Hierarchical View Frustum Culling）

    -   入口裁剪（Portal Culling）

    -   细节裁剪（Detail Culling）

-   各种层次细节（LOD，Level of Detail）技术

    -   几种LOD切换技术（Discrete Geometry LODs、Blend LODs、Alpha LODs、CLODs
        and Geomorph LODs）

    -   几种LOD的选取技术（Range-Based、Projected Area-Based、Hysteresis）

-   大型模型的渲染（Large Model Rendering）

-   点渲染（Point Rendering）

引言
====

《Real-Time Rendering
3rd》书中提到，实时渲染领域有四大目标，激励着游戏开发者们不断进步，它们是：

-   更高的每秒帧数

-   更高的分辨率

-   渲染更多的物体与更具真实感的场景

-   实现更高的复杂度

而要不断地追逐这四大目标，需要持续不断的优化算法，进行技术革新和硬件的升级。其中，加速渲染相关的算法一直是追逐这四大目标的重要一环。

这篇文章将基于《Real-Time Rendering 3rd》第十四章“Acceleration
Algorithms”的内容，介绍计算机图形学和游戏开发中常用的对渲染进行加速的算法，尤其是对大量几何体的渲染，而很多这类算法的核心都是基于空间数据结构（Spatial
Data
Structures）。所以，本文将先介绍一些游戏开发中常用的空间数据结构，再进行各种加速算法，不同种类的裁剪算法，LOD相关的介绍。

一、空间数据结构 \| Spatial Data Structures
===========================================

空间数据结构（Spatial Data
Structures）是将几何体组织在N维空间中的一系列数据结构，而且我们可以很容易地将二维和三维的一些概念扩展到高维之中。这些空间数据结构可以用于很多实时渲染相关操作的加速查询中，如场景管理，裁减算法、相交测试、光线追踪、以及碰撞检测等。

空间数据结构的组织通常是层次结构的。宽泛地说，即最顶层包含它之下的层次，后者又包含更下层的层次，以此类推。因此，这种结构具有嵌套和递归的特点。用层次结构的实现方式对访问速度的提升很有帮助，复杂度可以从O(n)提升到O(log
n)。但同时，使用了层次结构的大多数空间数据结构的构造开销都比较大，虽然也可以在实时过程中进行渐进更新，但是通常需要作为一个预处理的过程来完成。

一些常见的空间数据结构包括：

-   层次包围盒（Bounding Volume Hierachy，BVH）

-   二元空间分割树（Binary Space Partitioning，BSP），

-   四叉树 （QuadTree）

-   kd树（k-dimensional tree）

-   八叉树（Octree）

-   场景图 （Scene Graphs）

其中，BSP树和八叉树都是基于空间细分（Space
Subdivision）的数据结构，这说明它们是对整个场景空间进行细分并编码到数据结构中的。例如，所有叶子节点的空间集合等同于整个场景空间，而且叶子节点不相互重叠。

BSP树的大多数变种形式都是不规则的，而松散地意味着空间可以被任意细分。

八叉树是规则的，意味着空间是以一种均匀的形式进行分割，虽然这种均匀性限制比较大，但这种均匀性常常是效率的源泉。另外值得注意的是，八叉树是四叉树的三维空间推广。

另一方面，层次包围盒不是空间细分结构，它仅将几何物体周围的空间包围起来，所以包围层次不需要包围所有的空间。

下文将对其中的层次包围盒、二元空间分割树、八叉树进行近一步介绍，并还将简单提到场景图(SceneGraph)，这是一种比较高层次的，相较渲染性能更关注模型关系的数据结构。

当然，限于篇幅原因，这里的每种数据结构都无法介绍得事无巨细，但已在每种数据结构介绍的最后备好了一些延伸的阅读材料，方便希望进一步了解的朋友们进行延伸阅读。

1.1 层次包围盒 \| Bounding Volume Hierarchies , BVH
---------------------------------------------------

层次包围盒（Bounding Volume Hierarchies,
BVH）方法的核心思想是用体积略大而几何特征简单的包围盒来近似地描述复杂的几何对象，从而只需对包围盒重叠的对象进行进一步的相交测试。此外，通过构造树状层次结构，可以越来越逼近对象的几何模型，直到几乎完全获得对象的几何特征。

对于三维场景的实时渲染来说，层次包围体（Bounding Volume
Hierarchy，BVH）是最常使用的一种空间数据结构。例如，层次包围体经常用于层次视锥裁减。场景以层次树结构进行组织，包含一个根节点（root）、一些内部节点（internal
nodes），以及一些叶子节点（leaves）。顶部的节点是根，其无父节点。叶子节点（leaf
node）包含需渲染的实际几何体，且其没有子节点。

相比之下，内部节点包含指向它子节点的指针。因此，只要根节点不是这颗树唯一的一个节点，那么它就是一个内部节点。树中的每一个节点，包括叶子节点，都有一个包围体可以将其子树中的所有几何体包围起来，这就是包围体层次的命名来源，同时，也说明了根节点有一个包含整个场景的包围体。

![](media/b5bb6601996dc236aa103f3ca00dee97.jpg)

图1
左图为一个包含6个物体的简单场景，每个物体由一个包围的球体封闭起来，其中可以将包围球体归组为一个更大的包围球体，如此内推，直到所有的物体被最大的球体包围，右图所示为层次包围体（树），可以用来表示左图的物体层次、根节点的包围体包含场景中的所有物体。

![](media/78f6347269f86aa2dc6abdd8ea1c2bf8.jpg)

图2 层次包围盒的实现
\@[http://thomasdiewald.com/blog/?p=1488](https://link.zhihu.com/?target=http%3A//thomasdiewald.com/blog/%3Fp%3D1488)

![](media/9f4aa1c2805e0cac3b1cb1e60fbbbf06.jpg)

图3 层次包围盒的实现
\@[http://thomasdiewald.com/blog/?p=1488](https://link.zhihu.com/?target=http%3A//thomasdiewald.com/blog/%3Fp%3D1488)

### 1.1.1 BVH的延伸阅读材料

[1] [https://hal.inria.fr/inria-00537446/file/bounding_volume_hierarchies.pdf](https://link.zhihu.com/?target=https%3A//hal.inria.fr/inria-00537446/file/bounding_volume_hierarchies.pdf)

[2] [https://www.codeproject.com/Articles/832957/Dynamic-Bounding-Volume-Hiearchy-in-Csharp](https://link.zhihu.com/?target=https%3A//www.codeproject.com/Articles/832957/Dynamic-Bounding-Volume-Hiearchy-in-Csharp)

[3] Wald I, Boulos S, Shirley P. Raytracing deformable scenes using dynamic
bounding volume hierarchies[J]. ACM Transactions on Graphics (TOG), 2007, 26(1):
6.

1.2 BSP树 \| BSP Trees
----------------------

BSP树(二叉空间分割树，全称Binary Space Partitioning
Tree)是一种常用于判别对象可见性的空间数据结构。类似于画家算法，BSP树可以方便地将表面由后往前地在屏幕上渲染出来，特别适用于场景中对象固定不变，仅视点移动的情况。

其中，BSP是Binary
SpacePartitioning（二叉空间划分法）的缩写。这种方法递归地将空间使用超平面划分为凸面体集合。而这种子划分引出了借助于称之为BSP树的树形数据结构的场景表示。

![](media/dfcb34e1cd59f4645d21066fcc0ca34f.jpg)

图4 一个BSP树的构造

BSP
树是一棵二叉树，每个节点表示一个有向超平面，其将当前空间划分为前向（front）和背向（back）两个子空间，分别对应当前节点的左子树和右子树。且BSP
树已经在游戏工业上应用了许多年（Doom是第一个使用BSP树的商业游戏）。尽管在现今BSP树已经没像过去那么受欢迎了，但使用依然广泛。

BSP树的一个有趣特性是，如果用一种特定的方式遍历，树的几何内容可以从任何角度进行前后排序。这个排序可以近似轴对齐，精确对齐多边形BSP。与BVH不同的是，BVH通常不包含任何形式的排序。

### 1.2.1 BSP树的构造

-   从空树开始，每次选择一个面片作为节点插入树中

-   每次插入一个新节点，从树的根节点开始遍历

    -   如果新节点面片与当前结点片面相交，将新面片分割成两个面片

    -   新节点在当前节点前向空间，插入左子树

    -   新节点在当前节点背向空间，插入右子树

    -   当前节点为空，直接插入新节点

-   直到所有面片都被插入树中

简单来说，若要创建BSP树，需递归将一个平面空间一分为二，并将几何体归类到这两个空间中来完成。

### 1.2.2 BSP树的遍历

从根节点开始，判断输入位置与当前分割平面的“前”、“后”关系，

“前”则遍历左子树，“后”则遍历右子树，递归到叶子节点终止。

用平面方程 Ax + By + Cz + D = 0判断前后位置，可用 D(x0, y0, z0 ) = Ax0 + By0
+Cz0 +D 进行判别，其中：

-   D \> 0：在平面前面

-   D = 0：在平面上

-   D \< 0：在平面后面

这里贴出从后向前遍历BSP的示例代码：

    traverse_tree(bsp_tree* tree,point eye)  
	{  
	    location = tree->find_location(eye);  
	  
	    if(tree->empty())  
	        return;  
	  
	    if(location > 0)      // if eyeinfront of location  
	    {  
	        traverse_tree(tree->back,eye);  
	        display(tree->polygon_list);  
	        traverse_tree(tree->front,eye);  
	    }  
	    else if(location < 0) // eye behind location  
	    {  
	        traverse_tree(tree->front,eye);  
	        display(tree->polygon_list);  
	        travers_tree(tree->back,eye);  
	    }  
	    else                  // eyecoincidental with partition hyperplane  
	    {  
	        traverse_tree(tree->front,eye);  
	        traverse_tree(tree->back,eye);  
	    }  
	}  

### 1.2.3 BSP树的种类

在计算机图形学中，BSP树有两大类别，分别是为轴对齐（Axis-Aligned）BSP树和多边形对齐（Polygon-Aligned）BSP树。下面分别进行介绍。

### 1.2.4 轴对齐BSP树 \| Axis-aligned BSP tree

轴对齐BSP树可以按如下方式来创建。首先，将整个场景包围在一个AABB（轴对齐包围盒，Axis-Aligned
Bounding Box）中，然后以递归的方式将这个包围盒分为若干个更小的盒子。

现在，考虑一下任何递归层次的盒子。选取盒子的一个轴，生成一个与之垂直的平面，将盒子一分为二。有一些方法可以将这个分割平面固定，从而将这个盒子分为完全相同的两部分，而也有其他的一些方法，允许这个平面在位置上有一些变化。与分割平面相交的物体，要么存储在这个层次上，成为两个子集中的一员，要么被这个平面分割为两个不同的物体。经过这个过程，每个子集就处于一个比较小的盒子中，重复这个平面分割的过程，就可以对每个AABB进行递归细分，直到满足某个标准才终止这个分割过程。而这个标准，通常是用户定义的树最大深度，或者是盒子里面所包含的几何图元数量，需低于用户定义的某个值。

分割平面的轴线和位置对提高效率至关重要。一种分割包围盒的方法就是轴进行循环。即在根节点，沿着x轴对盒子进行分割，然后再沿着y轴对其子盒子进行分割，最后沿z轴对其孙盒子进行分割。这样，就完成了一个循环周期。使用这种分割策略的BSP树常被称为k-d树。而另一种常见策略是找到盒子的最长边，沿着这条边的方向对盒子进行分割。

下图展示了一种轴对齐BSP树的分割过程。

![https://pic1.zhimg.com/50/v2-d154c99c184d9bacf7b155972f6f6bdf_hd.jpg](media/022411ac02ac57056dc035e1185e167f.jpg)

图5 轴对齐
BSP树。在这个示例中，允许空间分割位于轴上的任意位置，不一定必须在中点位置，形成的空间体分别用A\~E来标志。右图所示的树是当前的BSP树数据结构，每个叶子节点表示一个区域，区域内容显示在下方。注意，黄色三角形在物体列表中含有C和E两个区域，因为它同时覆盖了这两个区域。

值得一提的是，从前到后的粗排序（Rough Front-to-Back
Sorting）是轴对齐BSP树的一种应用示例，这种方法对于遮挡剔除算法非常有用。而在视点的另一侧进行遍历，可以得到从后向前的粗排序（Rough
Fack-to-Gront
Sorting）,这对于透明排序非常有用。且还可以用来测试射线和场景几何体相交的问题，只需将视点位置换为射线原点即可，另外还可以用于视锥裁剪。

### 1.2.5 多边形对齐BSP树 | Polygon-aligned BSP tree

多边形对齐BSP树（Polygon-aligned BSP
tree）是BSP树的另一大类型，其中将多边形作为分隔物，对空间进行平分。也就是说，在根节点处，选取一个多边形，用这个多边形所在平面将场景中剩余多边形分为两组。对于与分割平面相交的多边形来说，沿着其中的交线将这个多边形分为两部分。然后，在分割平面的每个半空间中，选取另外一个多边形作为分隔物，只对这个分隔物所在平面的多边形进行继续分割，直到所有的多边形都在BSP树中为止。

需要注意，多边形对齐BSP树的创建是一个非常耗时的过程，这些树通常只需计算一次，可以存储起来进行重用。

下图是一个多边形对齐BSP树的图示。

![](media/9ffd918bb7b1aa7dc46eeab648b48630.jpg)

图6
多边形对齐BSP树。左图中，多边形分别用A\~G表示。首先，用多边形A对空间进行分割，生成的两个半空间分别由多边形B和C分割，由B形成的分割平面与左下角的多边形相交，将其分割为多边形D和E。最后形成的BSP书如右图所示。

因为完全不平衡树的效率非常低，所以多边形对齐BSP树分割时最好是形成平衡树，即每个叶子节点的深度相同或者相差一个层次的树。

多边形对齐BSP树的一个典型性质就是对于一个给定的视点来说，可以对该结构按照从后往前（或者从前往后）的顺序进行严格遍历，而轴对齐的BSP通常只能给出粗略的排序顺序。所以，基于多边形对齐BSP树的此性质，建立了严格的前后顺序，可以配合画家算法来绘制整个场景，而无需Z缓冲。

多边形对齐BSP树的其他应用也包括相交测试和碰撞检测等。

### 1.2.6 BSP树的延伸阅读材料推荐

[1] [http://web.cs.wpi.edu/\~matt/courses/cs563/talks/bsp/bsp.html](https://link.zhihu.com/?target=http%3A//web.cs.wpi.edu/%7Ematt/courses/cs563/talks/bsp/bsp.html)

[2] [https://pdfs.semanticscholar.org/90e4/c4a65b4b04d9e2374e5753659c102de4c0eb.pdf](https://link.zhihu.com/?target=https%3A//pdfs.semanticscholar.org/90e4/c4a65b4b04d9e2374e5753659c102de4c0eb.pdf)

[3] [https://en.wikipedia.org/wiki/Binary_space_partitioning](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Binary_space_partitioning)

[4] [http://archive.gamedev.net/archive/reference/programming/features/bsptree/bsp.pdf](https://link.zhihu.com/?target=http%3A//archive.gamedev.net/archive/reference/programming/features/bsptree/bsp.pdf)

1.3 八叉树 \| Octrees
---------------------

八叉树（octree），或称八元树，是一种用于描述三维空间的树状数据结构。八叉树的每个节点表示一个正方体的体积元素，每个节点有八个子节点，这八个子节点所表示的体积元素加在一起就等于父节点的体积。一般中心点作为节点的分叉中心。

简单来说，八叉树的空间划分方式很简单，即递归地进行规整地1分为8的操作。如下图，把一个立方体分割为八个同样大小的小立方体，然后递归地分割出更的小立方体。这个就是八叉树的命名来源。这种分割方式可以得到比较规则的结构，从而使得查询变得高效。

![](media/7c9d18c422565ae2aed50084fa2c3b80.jpg)

图7 八叉树的构成 \@wiki

相似地，四叉树是把一个二维的正方形空间分割成四个小正方形。而八叉树是四叉树的三维空间推广。

![](media/cf01ae3d574b79814066f5bc6b1356da.jpg)

图8 八叉树的实现
\@[http://thomasdiewald.com/blog/?p=1488](https://link.zhihu.com/?target=http%3A//thomasdiewald.com/blog/%3Fp%3D1488)

![](media/7d02593bdc15315abc7fba98c8e9f02d.jpg)

图9 八叉树的实现
\@[http://thomasdiewald.com/blog/?p=1488](https://link.zhihu.com/?target=http%3A//thomasdiewald.com/blog/%3Fp%3D1488)

![](media/bc7ebc55d67e2fc8b4faef66ecabe3a5.jpg)

图10 八叉树的实现
\@[http://thomasdiewald.com/blog/?p=1488](https://link.zhihu.com/?target=http%3A//thomasdiewald.com/blog/%3Fp%3D1488)

上述三幅图也均来自《Space Partitioning: Octree
vs.BVH》[http://thomasdiewald.com/blog/?p=1488](https://link.zhihu.com/?target=http%3A//thomasdiewald.com/blog/%3Fp%3D1488)一文，这是一篇比较八叉树和BVH的有趣的文章，有兴趣的朋友可以阅读一下。

### 1.3.1 松散八叉树 Loose Octrees

松散八叉树的基本思想和普通八叉树一样，但是每个长方体的大小选中比较宽松。而如果一个普通长方体的边长为l，那么可以用kl来代替，其中k\>1，如下图所示。

![](media/2f73f0749d344b674784d3fb6affd7fd.jpg)

图11
一个普通八叉树和松散八叉树的比较。图中黑色的原点表示长方形的中心点（第一次细分）。在左图中，星形物体刺穿了一个普通八叉树的一个分割平面。，这样，一种选择就是将这个星型物体放在最大的长方形中（根节点的长方体）。而右图所示为一个k=1.5的松散八叉树，也就是将长方体放大了50%，如果将这些长方体稍微移动，就可以保证区分出它们。这样，这个星型多边形就完全位于左上角的长方形之中。

### 1.3.2 八叉树延伸阅读材料

[1] [http://web.cs.wpi.edu/\~matt/courses/cs563/talks/color_quant/CQoctree.html](https://link.zhihu.com/?target=http%3A//web.cs.wpi.edu/%7Ematt/courses/cs563/talks/color_quant/CQoctree.html)

[2] [https://en.wikipedia.org/wiki/Octree](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Octree)

[3] Losasso F, Gibou F, Fedkiw R.Simulating water and smoke with an octree data
structure[C]//ACM Transactionson Graphics (TOG). ACM, 2004, 23(3): 457-462.

1.4 场景图 | Scene Graphs
--------------------------

BVH、BSP树和八叉树都是使用某种形式的树来作为基本的数据结构，它们的具体区别在于各自是如何进行空间分割和几何体的存储，且他们均是以层次的形式来保存几何物体。然而三维场景的绘制不仅仅是几何体。

然而，渲染三维场景不仅仅只是渲染出几何图形，对动画，可见性，以及其他元素的控制，往往需要通过场景图（Scene
Graphs）来完成。

场景图被誉为“当今最优秀且最为可重用的数据结构之一。”Wiki中的对场景图的定义是“场景图（Scene
Graph）是组织和管理三维虚拟场景的一种数据结构，是一个有向无环图（Directed
Acyclic Graph， DAG）。”

场景图是一个面向用户的树结构，可以通过纹理、变换、细节层次、渲染状态（例如材质属性）、光源以及其他任何合适的内容进行扩充。它由一棵以深度优先遍历来渲染整个场景的树来表示。

![](media/0db8d3f35501190b2e971a3b83b804e1.jpg)

图12 通过创建场景图来表示对象

另外提一句，开源的场景图有Open Scene
Graph和OpenSG等，有兴趣的朋友们可以进行进一步了解。

### 1.4.1 场景图的延伸阅读材料

[1] [http://www.openscenegraph.org/index.php/documentation/knowledge-base/36-what-is-a-scene-graph](https://link.zhihu.com/?target=http%3A//www.openscenegraph.org/index.php/documentation/knowledge-base/36-what-is-a-scene-graph)

[2] [https://en.wikipedia.org/wiki/Scene_graph](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Scene_graph)

[3] [http://archive.gamedev.net/archive/reference/programming/features/scenegraph/index.html](https://link.zhihu.com/?target=http%3A//archive.gamedev.net/archive/reference/programming/features/scenegraph/index.html)

二、裁剪技术 \| Culling Techniques
==================================

裁剪（Culling）的字面意思是“从大量事物中进行删除”。在计算机图形学中，相对应的就是裁剪技术（Culling
Techniques）所要做的工作——“从大量游戏事物中进行删除”。所谓的“大量事物”就是需要绘制的整个场景，删除的是对最终图像没有贡献的场景部分，然后将剩余场景发送到渲染管线。因此，在渲染方面通常使用“可见性裁剪（Visibility
Culling）”这个术语。但其实，裁剪也可以用于程序的其他部分，如碰撞检测（对不可见物体进行不十分精确的计算）、物理学计算，以及人工智能（AI）领域。

与渲染相关的裁剪技术，常见的有背面裁剪（Backface Culling），视锥裁剪（View
Frustum Culling），以及遮挡裁剪（Occlusion Culling，也常常称作遮挡剔除）：

-   背面裁剪即是将背向视点的物体删除，是一种非常简单直观的操作，只能一次一对个单一多边形进行操作。

-   视锥裁剪是将视锥之外的多边形删除，相对而言，这种操作比背面裁剪稍微复杂。

-   遮挡裁剪，是将被其他物体遮挡的物体进行删除，这种操作在三者中最为复杂，因为其需要聚集一个或者多个物体，同时还需使用其他物体的位置信息。

理论上，裁剪操作可以发生在渲染管线的任何一个阶段，而且对于一些遮挡裁剪算法来说，甚至可以预先计算出来。对于在硬件中实现的裁剪算法来说，有时只需启动/禁止或者设置一些裁剪函数即可。而为了进行完全控制，我们可以在应用程序阶段在（CPU上）实现一些裁剪算法。假设瓶颈位置不在CPU上，渲染最快的多边形就是没有送到图形加速器管线上的多边形，裁剪通常可以使用几何计算来实现，但也不局限于此。例如，某算法也可以使用帧缓冲中的内容。而理想的裁剪算法预期是只发送所有图元中通过管线的精确可见集(Exact
Visible Set, EVS)。

下图是三种裁剪技术的对比图示。

![](media/45194866e96921a358f78e22a9c4e857.jpg)

图13 三种裁剪技术的对比，其中被裁剪掉的几何体用虚线表示

下文接下来将分别介绍背面裁剪、层次视锥裁剪、入口裁剪、细节裁剪、遮挡剔除等几种裁剪技术。

三、背面裁剪 \| Backface Culling
================================

假设你正在观察一个场景中不透明的球体。大约有一半的球体是不可见的。那么，可以从中这个例子里得到一个众所周知的结论，那就是，对不可见的内容不需要进行渲染，因为它们对最终的渲染图像没有贡献。不需要对球体的背面进行处理，这就是背面裁剪的基本思想。对于一组物体来说，还可以一次性地进行背面裁剪，这也称为聚集背面裁剪（Clustered
Backface Culling）。

![](media/c099e6700c40253bd03081fde57c55de.jpg)

图14
确定多边形是否背向的两种不同测试。左图所示为屏幕空间的测试情形，三角形和四边形是正向，而七边形是背向。对背向的七边形，无需进行光栅化。

右图为视点空间中背面测试情形，多边形A是背向的，而B和C是正向的。多背向的多边形A，无需进行光栅化。

四、层次视锥裁剪 \| Hierarchical View Frustum Culling
=====================================================

如上文所示，只需对完全或者部分在视锥中的图元进行渲染。一种加快渲染速度的方法便是将每个物体的包围体与视锥进行比较，如果包围体位于视锥之外，那么便不需要渲染包围体中的几何体。由于这些计算在CPU上进行，因此包围体中的几何体不需要通过管线中的几何和光栅阶段。相反，如果包围体在视锥内或者与视锥相交，那么包围体中的内容就是可见的，所以必须发送到渲染管线中去。

利用空间数据结构，可以分层地来应用这种裁剪。例如，对于层次包围体BVH来说，从根节点进行先序遍历（Preorder
Transversal），就可以完成这一任务。

![](media/966760d5def6a518d9d0b26d1f4a2482.jpg)

图15
左图所示为一组几何体和相应的包围体（球体），从视点位置使用视锥裁剪来渲染场景。右图所示为层次包围体，视节点的包围体与视锥相交，对子包围体进行遍历测试，左子树的包围体与视锥相交，而其中只有一个子节点与视锥相交，另外一个子包围体体外边，无需发送到管线。根节点中间子树的包围体完全位于视锥内部，可以立即进行渲染，右边的子树的包围体也完全位于视锥内部，所以不需要进一步测试就可以渲染整个子树。

视锥裁剪操作位于应用程序阶段（CPU），这意味着几何阶段和光栅阶段都可以从中受益，对于大场景或者一定的相机视线来说，场景只有一小部分是可见的，只需要将这部分发送到渲染管线。可期望获得一定的加速效果，视锥裁剪技术利用了场景中的空间相关性，因为可以将彼此靠近的物体包围在一个包围体中，而且几乎所有包围体都是以层次形式聚集在一起。

除了层次包围体，其他的空间数据结构同样也可以用于视锥裁剪，包括上文提到的八叉树和BSP树。但是当渲染动态场景时，这些方法便会显得不够灵活,不如层次包围体。

五、入口裁剪 \| Portal Culling
==============================

对建筑物模型来说，很多裁剪方面的算法可以归结为入口裁剪（Protal
Culling）。在这个方向，最早的算法由Airey提出，随后Teller和Sequin，以及Teller和Hanrahan构造出了更高效，更复杂的算法。

入口裁剪算法的基本思想是，在室内场景中，建筑物墙面通常充当大的遮挡物，通过每个入口（如门或者窗户）进行视锥裁剪。当遍历入口的时候，就减小视锥。

使得与入口尽可能紧密贴合。因此，可以将入口裁减算法看作是视锥裁剪算法的一种扩展，且需将位于视锥之外的入口丢弃。

入口裁剪方法以某种方式对场景进行预处理，可以是自动形式，也可以是手动形式，可以将场景分割为一系列单元（Cells），其通常对应于建筑物中的房间或者走廊；链接进阶房间的门和窗口称为入口（Protals）。单元中的每个物体和单元的墙面可以存储在一个与单元关联的数据结构中，还可以将邻接单元和链接这些单元的入口信息保存在一个临接图中。

![](media/f8c39ee216cc583194906bec4a03aef8.jpg)

图16
入口裁剪。单元分别从A到H，入口是连接单元的通路，只对穿过入口能看到的几何体进行渲染。

![](media/6890224ea8733ab7349ed33ca2b6e62d.jpg)

图17
入口裁剪，左图为房间顶视图，白线表示每一个入口的截锥体减少的方式。红线是在镜子上反射圆台来产生的。实际视图显示在右侧的图像中。

六、细节裁剪 \| Detail Culling
==============================

细节裁剪（Detail
Culling）是一种通过牺牲质量换取速度的技术。其基本原理是，当视点处于运动的时候，场景中的微小细节对渲染出的图像贡献甚微。且当视点停下来的时候，通常禁止细节裁剪。

考虑一个具有包围体的问题，将这个包围体投射到投影平面，然后以像素为单位来估算投影面积，如果像素的数量小于用户定义的阈值，那么不对这个物体进行进一步处理。基于这个原因，细节裁剪也往往被称为屏幕尺寸裁剪（Screen-Size
Culling）。另外，细节裁剪也可以在场景图上以层次形式来实现，几何阶段和光栅阶段都可以从这个算法中受益。

细节裁剪还可以作为一种简化的LOD技术来实现，其中一个LOD是整个模型，另外一个LOD是空物体。

七、遮挡剔除 \| Occlusion Culling
=================================

遮挡裁剪（Occlusion Culling），也常被称作遮挡剔除。

聊一聊遮挡剔除必要性。不难理解，可见性问题可以通过Z缓冲器的硬件构造来实现，即使可以使用Z缓冲器正确解决可见性问题，但其中Z缓冲并不是在所有方面都不是一个很“聪明”的机制。例如，假设视点正沿着一条直线观察，其中，在这条直线上有10个球体，虽然这10个球体进行了扫描转换，同时与Z缓冲器进行了比较并写入了颜色缓冲器和Z缓冲器，但是这个从这个视点渲染出的图像只会显示一个球体，即使所有10个球体都将被光栅化并与Z缓冲区进行比较，然后可能写入到颜色缓冲区与Z缓冲区。

下图中间部分显示了在给定视点处场景的深度复杂度，深度复杂度指的是对每个像素重写的次数。对于有10个球体的情形，最中间的位置，深度复杂度为10，因为在这个地方渲染了10个球体（假设背面裁剪是关闭的），而且这意味着其中有9次像素写入是完全没有必要的。

![](media/c6d17a21e8a4ee4d32bcb510f95a2185.jpg)

图18 展示遮挡剔除必要性的图示

像上图这样无聊极端的场景，现实生活中很难找到，但其描述的这种密集性很高的模型的情形，在现实生活中却很常见，如热带雨林，发动机，城市，以及摩天大楼的内部。下图显示了曼哈顿式城市的示例。

![](media/ecd5347e24a3def949585440c73463b8.jpg)

图19
城市鸟瞰图，左图为视锥裁剪后的图示，中图为视锥裁剪后的图示，右图所示为遮挡剔除和视锥裁剪后的图示

从上面给出的示例可以看出，这种用来避免低效率的算法可以带来速度上的补偿，具体可以将这些方法归类为遮挡剔除算法（Occlusion
Culling
Algorithms），因为它们都试图裁剪掉被遮挡的部分，也就是被场景中其他物体遮挡的物体，最优的遮挡裁剪算法只选择其中可见得的部分。

有两种主要形式的遮挡裁剪算法，分别是基于点的遮挡裁剪和基于单元的遮挡裁剪。如下图所示。

![](media/5bc065899184a23ac95778a586db1651.jpg)

图20
左图所示为基于点的可见性，右图所示为基于单元的可见性，其中单元是一个长方形，从中可以看出，从视点左边看上去，有些圆被遮挡了，但是从右边看上去，这些圆却是可见的，因为可以从单元的某个位置到这些圆画一些射线，这些射线没有和任何遮挡物相交

下图所示为一种遮挡剔除算法的伪代码。

![](media/02ea46a088b3a7b913ec7a90838f6fa2.jpg)

前人在遮挡剔除方面已经做了大量的工作，有多种不同种类的遮挡剔除算法：

-   Hardware Occlusion Queries 硬件遮挡查询

-   Hierarchical Z-Buffering 层次Z缓冲

-   Occlusion Horizons 遮挡地平线

-   Occluder Shrinking 遮挡物收缩

-   Frustum Growing视锥扩张

-   Virtual occluder 虚拟遮挡物算法

-   Shaft Occlusion Culling 轴遮挡裁剪

-   The HOM algorithm 层次遮挡映射算法

-   Ray Space Occlusion Culling 射线空间遮挡剔除

下面将对其中的常见几种介绍。

7.1 硬件遮挡查询 \| Hardware Occlusion Queries
----------------------------------------------

现代GPU可以以一种特殊的渲染模式来支持遮挡剔除。通过硬件遮挡查询（Hardware
Occlusion Queries），我们能够直接获得所提交的物体是否被绘制到场景中。

简单来说，硬件遮挡查询的基本思想是，当和Z缓冲器中内容进行比较时，用户可以通过查询硬件来找到一组多边形是否可见的，且这些多边形通常是复杂物体的包围体（如长方体或者k-DOP）。如果其中没有多边形可见，那么便可将这个物体裁剪掉。硬件实现对查询的多边形进行光栅化，并且将其深度和Z缓冲器进行比较。

更多细节，可以参考这篇论文：

Bittner J, Wimmer M, Piringer H, et al. Coherent hierarchical culling: Hardware
occlusion queries made useful[C]//Computer Graphics Forum. Blackwell Publishing,
Inc, 2004, 23(3): 615-624.

7.2 层次Z缓冲 \| Hierarchical Z-Buffering
-----------------------------------------

层次Z-缓冲算法（Hierarchical Z-Buffering
，HZB）是由Greene等人提出的一种算法，对遮挡剔除的研究有着显著的影响。尽管其在CPU上很少使用，但该算法是GPU上做Z-Culling（深度裁剪）的基础。

层次Z-缓冲算法用八叉树来维护场景模型，并将画面的Z缓冲器作为图像金字塔（也称为Z-金字塔（Z-pyramid）），该算法因此在图像空间中进行操作。其中，八叉树能够对场景的遮挡区域进行层次剔除，而Z-金字塔则可以对单个基元和边界体积进行层次Z缓冲。
因此Z-金字塔可以作为此算法的遮挡表示。

![](media/9d3a0bd5ebdd5d3560f27035eb5c8296.jpg)

图21
使用HZB算法的遮挡裁剪示例，显示了一个复杂的场景（右下），相应的Z-pyramid(左图)，以及八叉树细分（右上）。通过从前到后遍历八叉树并裁剪遇到的八叉树节点，此算法可以仅访问可见的八叉树节点及其子节点（右上角的节点），的容器只对可见包围体中的多边形进行渲染。在这个例子中，遮挡八叉树节点的裁剪可以将深度复杂度从84，降低到了2.5。

更多细节，可以参考这篇论文：

Greene N, Kass M, Miller G. Hierarchical Z-buffer visibility[C]//Proceedings of
the 20th annual conference on Computer graphics and interactive techniques. ACM,
1993: 231-238.

7.3 其他遮挡剔除技术 \| Other Occlusion Culling Techniques
----------------------------------------------------------

前人在遮挡剔除方面已经做了大量的工作，但由于GPU的性能早已超过了CPU，所以这些算法中的大部分已经不再受青睐。因此这边只对一些常见的方案做一些简单介绍，至少他们还是值得传递下去的一些知识，因为架构和硬件的不断发展。

而随着多核系统的崛起，CPU端有了额外的资源，但难以直接给渲染本身带来提升，但同时使用单核或多核来执行基于单元的可见性测试或者其他进行方案，也已变得可以想象。

### 7.3.1 层次遮挡映射算法 \| Hierarchical Occlusion Map

层次遮挡映射（Hierarchical Occlusion Map
，HOM)）算法，类似层次Z缓冲算法，是一种启用分层图像空间剔除的方法。但其也不同于层次Z缓冲，因为它提供了使用近似遮挡剔除的能力。
HOM算法的基本思想是，每帧建立一个分层深度缓冲区，用于遮挡测试。并且在每个级别使用不透明度阈值来确定是否有足够的要渲染的对象是可见的。如果只有一小部分的对象是可见的，那么该对象被剔除。但作为一个基于CPU的算法系统，这个算法已经不受欢迎了。

对此算法感兴趣的朋友，可以进一步参考这篇论文：

Zhang H, Manocha D, Hudson T, et al. Visibility culling using hierarchical
occlusion maps[C]//Proceedings of the 24th annual conference on Computer
graphics and interactive techniques. ACM Press/Addison-Wesley Publishing Co.,
1997: 77-88.

### 7.3.2 遮挡地平线算法 \| Occlusion Horizons

遮挡地平线（Occlusion
Horizons）算法是一种非常简单的、基于点的可见性算法，可以对遮挡物进行融合，在基于点的可见性算法演示方面非常有用。由Wonka和Schmalstieg等人首先提出，并通过图形硬件将其进行了实现，随后Downs等人使用几何计算的方法将其独立开发实现，最早于1995年在电脑游戏中使用。

顾名思义，遮挡地平线算法的基本思想是裁剪掉位于地平线之间和之下的物体。
这种类型的算法经常被用来高效绘制如城市和村庄一样的城市环境。

通过从前到后渲染一个场景，我们可以定位到地平线在哪里进行渲染，而任何在当前地平线之后和之下的物体都可以被裁剪掉。

对此算法感兴趣的朋友，可以进一步参考这篇论文：

Downs L, Möller T, Séquin CH. Occlusion horizons for driving through urban
scenery[C]//Proceedings of the2001 symposium on Interactive 3D graphics. ACM,
2001: 121-124.

### 7.3.3 遮挡物收缩与视锥扩张算法 \| Occluder Shrinking and Frustum Growing

上文给出的遮挡地平线算法是基于点的可见性来判断的。有些时候采用基于单元的可见性方法更合适，但基于单元通常比基于点的可见性计算复杂度要高得多。Wonka等人提出了一种称为遮挡物收缩（Occluder
Shrinking）的方法，可以使用基于点的遮挡算法来生成基于单元的可见性，根据给定的量来缩小场景中所有遮挡物来达到延伸有效可见点的目的。他们也提出了一种视锥扩张（Frustum
Growing）技术，通常与Occluder Shrinking算法一起配合使用。

对此算法感兴趣的朋友，可以进一步参考如下三篇论文：

[1] Wonka P, Wimmer M, Schmalstieg D. Visibility preprocessing with occluder
fusion for urban walk throughs[M]//Rendering Techniques 2000. Springer, Vienna,
2000: 71-82.

[2] Wonka P, Wimmer M, Sillion F X. Instantvisibility[C]//Computer Graphics
Forum. Blackwell Publishers Ltd, 2001, 20(3):411-421.

[3] Wonka, Peter, Occlusion Culling for Real-Time Rendering of Urban
Environments,Ph.D. Thesis, The Institute of Computer Graphics and Algorithms,
Vienna University of Technology, June, 2001. Cited on p. 679

八、层次细节 \| LOD，Level of Detail
====================================

细节层次（Level of
Detail,LOD）的基本思想是当物体对渲染出图像贡献越少，使用越简单的形式来表达该物体。这是一个已经在各种游戏中广泛使用的基本优化技术。

例如，考虑一个包含1万个三角形的汽车，其中所包含的细节信息比较丰富。当视点靠近物体时，可以使用详细的细节表示，而当视点远离物体时，比如仅需覆盖200个像素，则完全无需渲染出1百万个三角形，相反，我可以使用诸如只有1000个三角形的简化模型。而由于距离的原因，简化后的模型与细节较丰富的模型看上去其实很接近。以这种方式，可以显著地提高渲染的性能开销。

![](media/764dd53e3a5c220059b189499b567282.jpg)

图22 LOD图示

![](media/9a220a6808cb458ce4210fe1948d15eb.jpg)

图23 LOD图示

NVIDIA提供了一个非常有趣的网站，可以在网页上自己拖动分界线进行交互，查看《古墓丽影:崛起》的游戏画面不同级别的LOD显示情况，可以对LOD有一个很直观的认识，感兴趣的同学不妨试试：

[http://images.nvidia.com/geforce-com/international/comparisons/rise-of-the-tomb-raider/alt/rise-of-the-tomb-raider-level-of-detail-interactive-comparison-001-very-high-vs-low-alt.html](https://link.zhihu.com/?target=http%3A//images.nvidia.com/geforce-com/international/comparisons/rise-of-the-tomb-raider/alt/rise-of-the-tomb-raider-level-of-detail-interactive-comparison-001-very-high-vs-low-alt.html)

![](media/5e774571032fda2b007c407e068f03f1.jpg)

图24 《古墓丽影:崛起》不同LOD的在线对比网站 \@NVIDIA

通常情况下，雾效会与LOD一起使用。这样我们可以完全跳过对一些物体的渲染，直接用不透明的雾来进行遮挡。另外，雾效的机制可以实现下文所介绍到的时间临界LOD渲染（Time-Critical
LOD
Rendering）。通过将元平面移近观察者，可以更早地剔除对象，并且可以实现更快速的渲染以保持帧速率。

一般情况下，完整的LOD算法包含3个主要部分：

-   生成 Generation

-   选择 Selection

-   切换 Switching

其中，LOD的生成就是生成不同细节的模型表示。RTR3书中12.5节中讨论的简化方法可用于生成所需数量的LOD。另一种方法是手工制作具有不同数量的三角形模型。选择机制就是基于某种准则选取一个层次细节模型，比如屏幕上的评估面积。最后，我们还需要从一个细节层次转换到另一个细节层次，而这个过程便称为LOD切换。

下面对LOD的切换和选取相关的算法进一步说明。

8.1 LOD的切换 \| LOD Switching
------------------------------

当从一个LOD切换到另一个LOD的时候，忽然的模型替换往往会引起观察者的注意。这种现象被称为突越（Poping）。这里有几种不同的LOD切换方法，有着不同的特性：

-   离散几何LOD \| Discrete Geometry LODs

-   混合LOD \| Blend LODs

-   透明LOD \| Alpha LODs

-   连续LOD和几何形变LOD \| CLODs and Geomorph LODs

### 8.1.1 离散几何LOD \| Discrete Geometry LODs

离散几何LOD是最简单的LOD算法，不同的表示是不同图元数量的同一模型，但这种方法突越现象严重。

### 8.1.2 混合LOD \| Blend LODs

在概念上，完全可能存在一种直观的方法，从一个LOD切换到另一个LOD，只需要在较短的时间内在两个LOD之间执行一个线性混合，这种方法无疑可以得到一种比较平滑的切换，但是这种混合操作的代价较高。渲染两个LOD要比一个LOD需要更大开销，因此也就违背了LOD的初衷。但LOD切换通常发生在较短时间内容，在同一时间也不是对场景中所有物体进行切换，所以依然可以从中获益。

Giegl等人在《Unpopping: Solvingthe Image-Space Blend Problem for Smooth Discrete
LOD Transition
》这篇文章中提出了一种方法，实际应用的效果较为出色。思路是在两个LOD之间有一个alpha值的过渡，有兴趣的朋友可以进一步了解。

### 8.1.3 透明LOD \| Alpha LODs

完全避免突越现象的一种简单方法便是使用alpha
LOD。其中并没有使用同一物体很多不同细节的实例，而且每个物体只有一个实例。

随着LOD选取度量值（如与物体之间的距离）的增大，物体整体透明度也随之增大（也就是alpha值减小），当完全透明时，物体最终就会消失。

这种方法的优点是，比离散几何LOD方法上感觉更连续一些，可以避免突跃现象。此外，由于物体最终会完全消失而不需要进行渲染，可以得到很好的加速效果。

![](media/f272f89c74a91128b63748fe6600471b.jpg)

图25 使用Alpha
LOD对图中的圆锥体进行渲染，当距离圆锥体较远时，就提高它的透明度，直到最后消失。直线左边的图像是从同一距离处进行的观察，而直线右边的图像是左边图像不同尺寸的情形。

### 8.1.4 连续LOD和几何形变LOD \| CLODs and Geomorph LODs

连续细节层次（Continuous Level of Detail ,
CLOD）的基本思想是基于LOD选取值来精确决定可见多边形的数量。在100m远处，模型包含1000个多边形，当移动的到101m的地方时，模型减少到998个多边形。

几何形变层次细节（Geomorph
LODs）是基于简化生成的一组离散模型，且其中模型顶点之间的链接关系保持不变。而网格简化的过程可以从一个复杂的物体中创建各种不同的LOD模型，具体做法可以参见《Real-Time
Rendering
3rd》12.5.1一节，一种方法就是创建一组离散的LOD，然后按照上文中提到的方法来使用。这里的边塌陷（Edge
Collapse Methods）方法有一个有趣的性质，即允许在不同的LOD之间采用其他过渡方法。

![](media/0a2229902ac6a2ff13c93c05af5b588b.jpg)

图26
几何形变LOD的简化模型图示。左边和右边的图像所示分为为低细节层次和高细节层次的模型，中间的图像是在左右模型中间进行插值生成的几何变形模型。注意。中间的牛模型和右边的模型具有相同数量的顶点和三角形。

8.2 LOD的选取 \| LOD Selection
------------------------------

给定一个物体不同细节层次，必须做一个选择，决定渲染或者混合其中的哪一个层次，这就是LOD选择（LOD
selection）的任务。有几种不同的LOD选择方案，这些方案也可以用于遮挡裁剪算法。

常见的三种LOD选取技术是：

-   基于距离的LOD选取( Range-Based )

-   基于投影面积的LOD选取( Projected Area-Based )

-   基于滞后的LOD选取(Hysteresis)

依然是分别进行简要概述。

### 8.2.1 基于距离的LOD选取 \|Range-Based

选取LOD的一种常用方法是将物体的不同LOD于不同距离联系起来。细节最丰富的LOD的距离从0到一个用户定义值r1之间，下次层次的LOD的距离位于r1\~r2之间，以此类推，如下图：

![](media/1aa78b0e0fff0191b646f331ea3dbd99.jpg)

图27
左图为基于距离的LOD的原理示例图。其中，LOD3是一个空物体，也就是表示当物体大于r3时，就不渲染任何物体，因为物体对图像的贡献度不够。右图为场景中的一个LOD节点，它只有一个子节点基于r。

### 8.2.2 基于投影面积的LOD选取 \| Projected Area-Based

基于投影面积的LOD选取，顾名思义，即投影面积越大，就选取细节越丰富的LOD。

### 8.2.3 基于滞后的LOD选取 \| Hysteresis

若用于确定LOD度量标准围绕某个值ri在画面之间是变化的，那么就会出现不必要的突跃现象，也就会在不同的LOD之间来回快速切换。对此，可以引入一个围绕ri值的滞后来解决这个问题。如下图，这是一个基于距离的LOD，可以应用于任何类型，当r增大时，使用上一行的LOD距离；当r减小时，使用下面一行的LOD距离。

![](media/5c7e919a94fd6cd8488bbe6d922f68b6.jpg)

图28 灰色区域表示的是基于滞后的LOD选取方法的滞后区域

### 8.2.4 其他LOD选取方法

基于距离和基于投影面积的LOD选取最常用。除了投影面积，Funk houser等人《Adaptive
Display Algorithm for Interactive Frame Rates During Visualization of Complex
Virtual
Environments》一文中还提出了使用物体的重要程度，运动，以及焦点等方法来作为LOD的选取方案。

观察者的注意力是一个重要的因素。例如，在一个体育游戏中，控制球的图像是用户最注意的地方，那么其他的部分就可以相对来说低的层次细节，具体可以参见论文《Never
Let ’Em See You Pop — Issues in Geometric Level of Detail Selection,”》。

另外，也可以使用整体的可见性，如通过密集的叶子看到的附近对象可以用较低的LOD呈现。以及限制整体高级别LOD的数量以控制渲染的三角形总数的开销。其他的一些LOD选取的因素有颜色、以及纹理等。此外，也可以使用感知尺度来选择LOD。

8.3 时间临界LOD渲染 \| Time-Critical LOD Rendering
--------------------------------------------------

我们通常希望渲染系统有一个固定的帧率，实际上这就是通常所说的“硬实时（Hard Real
Time）”或者时间临界（Time-Critical）。通常给定这类系统一个特定时间段（如30ms），必须在这段时间内完成相应的任务（如图像渲染）；当时间到的时候，必须停止处理。如果场景中的物体用LOD来表示，则可以实现硬实时渲染算法。

Funk houser等人在《Adaptive display algorithm for interactive frame rates during
visualization of complex virtual
environments》一文中提出了一种启发式算法（heuristic
algorithm），对于场景中的所有可见物体，可以自适应选取细节层次，从而满足固定帧率的要求。这个算法在场景中具有预测性，因为可见物体的LOD选取基于预期帧率和可见物体。这种启发式算法与对应的反应性算法（reactive
algorithm）形成了鲜明对比，后者的LOD选取基于前一帧画面的渲染时间。

九、 大型模型的渲染 \| Large Model Rendering
============================================

人们一直都认为所渲染的模型是适合存放到计算机主内存中的，但通常的情况其实并非如此。一个简单的例子便是渲染一个地球模型。这是一个非常复杂的话题，《Real-Time
Rendering 3rd》中也仅提了一下，然后列了一些相关文献，这里也仅简单说一下。

为了简单起见，大型模型的渲染通常会使用多个嵌套的数据结构，使用一个四叉树形式的数据结构来覆盖地球表面。而在每个叶节点内部可以根据具体内容使用不同的数据结构。此外，为了保持合适的帧率，即将进入视野中的模型区域，在需要之前从磁盘中分页，而四叉树也可以在这里使用的。

值得一提的是，在RTR3书中6.2.5节(对应本系列文章第五篇的5.4
节)讨论了裁剪图（clip-mapping）策略，便是管理大型纹理的一种技术。

将不同的加速算法进行结合是不容易的事情。Aliaga等人将几种算法结合起来，用于非常大型的场景，具体可以参考如下3篇文章：

[1] Akeley, K., and T. Jermoluk, “High-Performance Polygon Rendering,” Computer
Graphics (SIGGRAPH ’88 Proceedings), pp. 239–246, August 1988. Cited on p.22

[2] Akeley, K., P. Haeberli, and D. Burns, tomesh.c, a C-program on the SGI
Developer’s Toolbox CD, 1990. Cited on p. 543, 553, 554

[3] Akeley, Kurt, “RealityEngine Graphics,” Computer Graphics (SIGGRAPH 93
Proceedings), pp. 109–116, August 1993. Cited on p. 126

而关于大型模型的渲染，有兴趣的朋友可以近一步参考这篇SIGGRAPH笔记：

Manocha D, Aliaga D. Interactive walkthroughs of large geometric datasets[J].
SIGGRAPH 00 Course notes, 2000.

十、点渲染 \| Point Rendering
=============================

在1985年，Levoy 和 Whitted写了一篇具有开创性的技术报告《The use of points asa
display
primitive》。在这篇报告中，他们提出点作为一种新的图元来进行渲染，基本思想是用一个大的点集来表示物体表面并予以渲染。在随后的通道中，使用高斯滤波来填充渲染点之间的间隙。而高斯滤波器的半径取决于表面上点的密度和屏幕上的投影密度。有朋友的同学可以进一步了解。PDF地址在这里：

[https://www.cs.princeton.edu/courses/archive/spring01/cs598b/papers/levoy85.pdf](https://link.zhihu.com/?target=https%3A//www.cs.princeton.edu/courses/archive/spring01/cs598b/papers/levoy85.pdf)

![](media/8ee70b931e79f76fd64713747011c2a0.jpg)

图29 根据点渲染的方法渲染出来的模型，使用原型油彩（circular
splats）。左图为名为Lucy的天使模型，拥有10万个顶点。但在渲染中只用到了300万个油彩，中图、和右图是对左边图的放大。在渲染中，中间的图像使用4万个油彩，当视点停止移动时，就变成了右图，使用了60万个油彩（此图由Szymon
Rusinkiewicz的QSPlat program产生，Lucy的模型来自斯坦福图形实验室）

Reference
=========

[1] Bittner J, Wimmer M, Piringer H, et al. Coherent hierarchical culling:
Hardware occlusion queries made useful[C]//Computer Graphics Forum. Blackwell
Publishing, Inc, 2004, 23(3): 615-624.

[2] Zhang H, Manocha D, Hudson T, et al. Visibility culling using hierarchical
occlusion maps[C]//Proceedings of the 24th annual conference on Computer
graphics and interactive techniques. ACM Press/Addison-Wesley Publishing Co.,
1997: 77-88.

[3] 实时计算机图形学第二版[J]. 2004.

[4] Wonka P, Wimmer M, Schmalstieg D. Visibility preprocessing with occluder
fusion for urban walkthroughs[M]//Rendering Techniques 2000. Springer, Vienna,
2000: 71-82.

[5] [http://thomasdiewald.com/blog/?p=1488](https://link.zhihu.com/?target=http%3A//thomasdiewald.com/blog/%3Fp%3D1488)

[6] [http://blog.csdn.net/skybreaker/article/details/1828104](https://link.zhihu.com/?target=http%3A//blog.csdn.net/skybreaker/article/details/1828104)

[7] [https://en.wikipedia.org/wiki/Bounding_volume_hierarchy](https://link.zhihu.com/?target=https%3A//en.wikipedia.org/wiki/Bounding_volume_hierarchy)

[8] Wonka P, Wimmer M, Sillion F X. Instant visibility[C]//Computer Graphics
Forum. Blackwell Publishers Ltd, 2001, 20(3):  
411-421.

[9] Wonka, Peter, Occlusion Culling for Real-Time Rendering of Urban
Environments,Ph.D. Thesis, The Institute of Computer Graphics and Algorithms,
Vienna University of Technology, June, 2001. Cited on p. 679

[10] [http://insaneguy.me/attachments/spatial_ds--bsp_tree-octree-kd-tree.pdf](https://link.zhihu.com/?target=http%3A//insaneguy.me/attachments/spatial_ds--bsp_tree-octree-kd-tree.pdf)

[11] [http://book.51cto.com/art/201008/220506.htm](https://link.zhihu.com/?target=http%3A//book.51cto.com/art/201008/220506.htm)

[12] [http://blog.csdn.net/silangquan/article/details/17386353](https://link.zhihu.com/?target=http%3A//blog.csdn.net/silangquan/article/details/17386353)

[13] Akeley, K., and T. Jermoluk, “High-Performance Polygon Rendering,”Computer
Graphics (SIGGRAPH ’88 Proceedings), pp. 239–246, August 1988. Cited on p.22

[14] Akeley, K., P. Haeberli, and D. Burns, tomesh.c, a C-program on the SGI
Developer’s Toolbox CD, 1990. Cited on p. 543, 553, 554

[15] Akeley, Kurt, “RealityEngine Graphics,” Computer Graphics (SIGGRAPH 93
Proceedings),pp. 109–116, August 1993. Cited on p. 126

[16] 题图来自《最终幻想XV》

```

`Content/《Real-Time Rendering 3rd》读书笔记/Content/BlogPost12/README.md`:

```md
![](media/title12.jpg)


# 【《Real-Time Rendering 3rd》 提炼总结】(十二) 渲染管线优化方法论：从瓶颈定位到优化策略

<br>

导读
====

这篇文章约1万8千字，构成主要分为上篇（渲染管线瓶颈定位策略），下篇（渲染管线优化策略），以及常用的性能分析工具的列举三部分，详细目录如下。

-   一、渲染管线的构成

-   二、渲染管线优化策略概览

-   三、上篇：渲染管线的瓶颈定位

    -   3.1 光栅化阶段的瓶颈定位

        -   3.1.1 光栅化操作的瓶颈定位

        -   3.1.2 纹理带宽的瓶颈定位

        -   3.1.3 片元着色的瓶颈定位

    -   3.2 几何阶段的瓶颈定位

        -   3.2.1 顶点与索引传输的瓶颈定位

        -   3.2.2 顶点变换的瓶颈定位

    -   3.3 应用程序阶段的瓶颈定位

-   四、下篇：渲染管线的优化策略

    -   4.1 对CPU的优化策略

        -   4.1.1 减少资源锁定

        -   4.1.2 批次的尺寸最大化

    -   4.2 应用程序阶段的优化策略

        -   4.2.1 内存层面的优化

        -   4.2.2 代码层面的优化

    -   4.3 API调用的优化策略

    -   4.4 几何阶段的优化策略

        -   4.4.1 减少顶点传输的开销

        -   4.4.2 顶点处理的优化

    -   4.5 光照计算的优化策略

    -   4.6 光栅化阶段的优化策略

        -   4.6.1 加速片元着色

        -   4.6.2 减少纹理带宽

        -   4.6.3 优化帧缓冲带宽

-   五、主流性能分析工具列举

-   六、更多性能优化相关资料

文中列举了渲染管线各个阶段中用到的几十种主流的优化策略。其中，个人印象比较深刻的优化方法有使用实例（Instance）结合层次细节和impostors方法来对多人同屏场景的渲染进行优化，以及使用纹理页（Texture
Pages）来进行批次的尺寸最大化。

这篇文章会是《Real-Time Rendering 3rd》第十五章“Pipeline Optimization”和《GPU
Gem I》第28章“Graphics Pipeline
Performance”的一个结合，而不是之前一贯的《Real-Time Rendering
3rd》的单篇章节为主线。

需要吐槽的是，如果你对照阅读《GPU Gem
I》的英文原版和中文翻译版，会发现中文翻译版中有一些不合理甚至曲解英文原文意思的地方，在第五部分性能与实这一部分尤其明显。

OK，正文开始。

一、渲染管线的构成
==================

通常，可以将渲染管线的流程分为CPU和GPU两部分。下图显示了图形渲染管线的流程，可以发现，在GPU中存在许多并行运算的功能单元，本质上它们就像独立的专用处理器，其中存在许多可能产生瓶颈的地方。包括顶点和索引的取得、顶点着色（变换和照明，Transform
& Lighting，即T&L）、片元着色和光栅操作( Raster Operations ，ROP)。

![](media/091a575236054ddcde8422a3aa6095d0.jpg)

图1 图形渲染管线

如《Real-Time Rendering 3rd》第二章所述，
图形的渲染过程基于由三个阶段组成的管线架构：

-   应用程序阶段（The Application Stage）

-   几何阶段（The Geometry Stage）

-   光栅化阶段（The Rasterizer Stage）

基于这样的管线架构，其中的任意一个阶段，或者他们之间的通信的最慢的部分，都可能成为性能上的瓶颈。瓶颈阶段会限制渲染过程中的整个吞吐量，从而影响总结渲染的性能，所以不难理解，瓶颈的部分便是进行优化的主要对象。

![](media/ae678cacdd471cb8991658341b2f6e80.jpg)

图2 渲染管线架构

若有对这个过程不太熟悉的朋友，具体可以移步回看这个系列的第二篇文章《[【《Real-TimeRendering
3rd》 提炼总结】(二) 第二章 · 图形渲染管线 The Graphics Rendering
Pipeline](https://zhuanlan.zhihu.com/p/26527776)》

二、渲染管线的优化概览
======================

准确定位瓶颈是渲染管线优化的关键一步。若没有很好确认瓶颈就进行盲目优化，将造成大量开发的工作的无谓浪费。

根据以往的优化经验，可以把优化的过程归纳为以下基本的确认和优化的循环：

-   Step 1.
    定位瓶颈。对于管线的每个阶段，改变它的负载或计算能力（即时钟速度）。如果性能发生了改变，即表示发现了一个瓶颈。

-   Step 2.
    进行优化。指定发生瓶颈的阶段，减小这个阶段的负载，直到性能不再改善，或者达到所需要的性能水平。

-   Step 3. 重复。重复第1步和第2步，直到达到所需要的性能水平。

需要注意的是，在经过一次优化步骤后，瓶颈位置可能依然在优化前的位置，也可能不在。比较好的想法是，尽可能对瓶颈阶段进行优化，保证瓶颈位置能够转移到另外一个阶段。在这个阶段再次成为瓶颈之前，必须对其他阶段进行优化处理，这也是为什么不能在一个阶段上进行过多优化的原因。

同一帧画面中，瓶颈位置也有可能改变。由于某个时候要渲染很多细小的三角形，这个时候，几何阶段就可能是瓶颈；在画面后期，由于要覆盖屏幕的大部分三角形单元进行渲染，因此这时光栅阶段就可能成为瓶颈。因此，凡涉及渲染瓶颈问题，即是指画面中花费时间最多的阶段。

在使用管线结构的时候应该意识到，如果不能对最慢的阶段进行进一步优化，就要使其他阶段与最慢阶段的工作负载尽可能一样多（也就是既然都要等瓶颈阶段，不妨给其他阶段分配更多任务来改善最终的表现，反正是要等）。由于没有改变最慢阶段的速度，因此这样做并没有改变最终的整个性能。例如，假定应用程序阶段成为瓶颈，需要花费50ms，而其他阶段仅需要花费25ms。这意味着，在不改变管线渲染速度(50ms，即每秒20帧)的情况下，几何阶段和光栅化阶段可以在50ms内完成各自任务。这时，可以使用一个更高级的光照模型或者使用阴影和反射来提高真实感（在不增加应用程序阶段工作负载的前提下）。

管线优化的一种大致思路是，先将渲染速度最大化，然后使得非瓶颈部分和瓶颈部分消耗同样多的时间（如上文所述，这里的思想是，既然要等，不等白不等，不妨多给速度快的部分分配更多工作量，来达到更好的画面效果）。但这种想法已经不适于不少新架构，如XBOX
360，因其为自动加载平衡计算资源。

因为优化技术对于不同的架构有很大的不同，且不要过早地进行优化。在优化时，请牢记如下三句格言：

-   “KNOW YOUR ARCHITECTURE（**了解你所需优化的架构**）”

-   “Measure（**去测量，用数据说话**）”

-   “We should forget about small efficiencies, say about 97% of the time:
    Premature optimization is the root of all
    evil.”（我们应该忘记一些小的效率，比如说97%的时间：**过早的优化是万恶之源。**）-
    Donald Knuth

OK，下面开始，本文的上篇，渲染管线的瓶颈定位。

三、上篇：渲染管线的瓶颈定位策略
================================

正确定位到了瓶颈，优化工作就已完成了一半，因为可以针对管线上真正需要优化的地方有的放矢
。

提到瓶颈定位，很多人都会想到Profiler工具。Profiler工具可以提供API调用耗时的详细信息，由此可以知道哪些API调用是昂贵费时的，但不一定能准确地确定管道中哪些阶段正在减慢其余部分的速度。（PS:本文文末提供了一系列常用的profiler工具的列表）

确定瓶颈的方法除了用Profiler查看调用耗时的详细信息这种众所周知的方法外，也可以采用基于工作量变化的控制变量法。**设置一系列测试，其中每个测试减少特定阶段执行的工作量。如果其中一个测试导致每秒帧数增加，则已经找到瓶颈阶段。**

而上述方法的排除法也同样可行，即在不降低测试阶段的工作量的前提下减少其他阶段的工作量。如果性能没有改变，瓶颈就是工作负载没有改变的此阶段。

下图显示了一个确认瓶颈的流程图，描述了在应用程序中精确定位瓶颈所需要的一系列步骤。

![](media/92e0d51275b3d869c63559373079f0ce.jpg)

图3 确认渲染管线瓶颈流程图 \@ 《GPU GEMS I》

整个确认瓶颈的过程从渲染管线的尾端，光栅化阶段开始，经过帧缓冲区的操作（也称光栅操作），终于CPU（应用程序阶段）。虽然根据定义，某个图元（通常是一个三角形）只有一个瓶颈，但在帧的整个流程中瓶颈有可能改变。因此，修改流水线中多个节点的负载常常会影响性能。例如，少数多边形的天空包围盒经常受到片元着色或帧缓冲区存取的限制：只映射为屏幕上几个像素的蒙皮网络时常受到CPU或顶点处理的约束。因此，逐个物体地改变负载，或逐个材质地改变负载时常是有帮助的。

另外，管线的每个阶段都依赖于GPU频率（分为GPU Core Clock ，GPU核心频率，以及GPU
Memory Lock，GPU显存频率），这个信息可以配合工具 PowerStrip（EnTech Taiwan
2003），减小相关的时钟速度，并在应用中观察性能的变化。

下文将按照按照优化定位的一般顺序（即上述图中的流程），按光栅化阶段、几何阶段、应用程序阶段的的顺序来依次介绍瓶颈定位的方法与要点。

3.1 光栅化阶段的瓶颈定位
------------------------

众所周知，光栅化阶段由三个独立的阶段组成：
三角形设置，像素着色器程序，和光栅操作。

其中三角形设置阶段几乎不会是瓶颈，因为它只是将顶点连接成三角形。**而测试光栅化操作是否是瓶颈的最简单方法是将颜色输出的位深度从32（或24）位减少到16位**。如果帧速率大幅度增加，那么此阶段为瓶颈所在。

一旦光栅化操作被排除，**像素着色器程序的是否是瓶颈所在可以通过改变屏幕分辨率来测试**。如果较低的屏幕分辨率导致帧速率明显上升，像素着色器则是瓶颈，至少在某些时候会是这样。当然，如果是渲染的是LOD系统，就需斟酌一下是否瓶颈确实是像素着色器了。

另一种方法与顶点着色器程序所采用的方法相同，可以添加更多的指令来查看对执行速度的影响。当然，也要确保这些额外的指示不会被编译器优化。

下文将对光栅化阶段三个常常可能是瓶颈的地方进行进一步论述。

### 3.1.1 光栅化操作的瓶颈定位

光栅化操作的瓶颈主要与帧缓冲带宽（Frame-Buffer
Bandwidth）相关。众所周知，位于管线末端的光栅化操作（Raster  
Operations，常被简称为ROP），用于深度缓冲和模板缓冲的读写、深度缓冲和模板缓冲比较，读写颜色，以及进行alpha
混合和测试。而光栅化操作中许多负载都加重了帧缓冲带宽负载。

**测试帧缓冲带宽是否是瓶颈所在，比较好的办法是改变颜色缓冲的位深度，或深度缓冲的位深度（也可以同时改变两者）。**如果此操作（比如将颜色缓冲或深度缓冲的深度位从32位减少到16位）明显地提高了性能，那么帧缓冲带宽必然是瓶颈所在。

另外，帧缓冲带宽也与GPU显存频率（GPU memory
clock）有关，因此，修改该频率也可以帮助识别瓶颈。

### 3.1.2 纹理带宽的瓶颈定位

在内存中出现纹理读取请求时，就会消耗纹理带宽(Texture
Bandwidth)。尽管现代GPU的纹理高速缓存设计旨在减少多余的内存请求，但纹理的存取依然会消耗大量的内存带宽。

在确认光栅化操作阶段是否是瓶颈所在时，修改纹理格式比修改帧缓冲区的格式更麻烦。所以，**比较推荐使用大量正等级mipamap细节层次(LOD)的偏差，让纹理获取访问非常粗糙的mipmap金字塔级别，来有效地减小纹理尺寸。**同样，如果此修改显著地改善性能，则意味着纹理带宽是瓶颈限制。

纹理带宽也与GPU显存频率相关。

### 3.1.3 片元着色的瓶颈定位

片元着色关系到产生一个片元的实际开销，与颜色和深度值有关。这就是运行”像素着色器（Pixel
Shader ）“或”片元着色器（Fragment Shader ）“的开销。片元着色（Fragment
shading）和帧缓冲带宽（Frame-Buffer Bandwidth）由于填充率（Fill
Rate）的关系，经常在一起考虑，因为他们都与屏幕分辨率相关。尽管它们在管线中位于两个截然不同的阶段，区分两者的差别对有效优化至关重要。

在可编程片元处理的高级GPU出现之前，片元着色几乎没有什么局限性，时常是帧缓冲带宽引起的屏幕分辨率和性能之间不可避免的瓶颈。但随着开发者利用新的灵活性制造出一些新奇的像素，片元着色的性能问题也就出现了。

改变分辨率是确定片元着色是否为瓶颈的第一步。因为在上述光栅化操作步骤中，已经通过改换不同的深度缓冲位，排除了帧缓冲区带宽是瓶颈的可能性。所以，**如果调整分辨率使得性能改变，片元着色就可能是瓶颈所在**。而辅助的鉴别方法可以是修改片元长度，看这样是否会影响性能。但是要注意，不要添加可以被一些“聪明”的设备驱动轻松优化的指令。

片元着色的速度与GPU核心频率有关。

3.2 几何阶段的瓶颈定位
----------------------

几何阶段是最难进行瓶颈定位的阶段。这是因为如果在这个阶段的工作负载发生了变化，那么其他阶段的一个或两个阶段的工作量也常常发生变化。为了避免这个问题，Cebenoyan
[1] 提出了一系列的试验工作从光栅化阶段后的管线。

在几何阶段有两个主要区域可能出现瓶颈：顶点与索引传输( Vertex and  
Index Transfer)和顶点变换阶段（Vertex Transformation
Stage）。要看瓶颈是否是由于顶点数据传输的原因，可以增加顶点格式的大小。这可以通过每个顶点发送几个额外的纹理坐标来实现，例如。如果性能下降，这个部分就是瓶颈。

顶点变换是由顶点着色器或固定功能管线的转换和照明功能完成的。对于顶点着色器瓶颈，
测试包括使着色器程序更长。为了确保编译器没有优化这些附加指令，必须采取一些注意事项。对于固定功能管线，可以通过打开附加功能（如镜面高光）或将光源转换成更复杂的形式（例如聚光灯）来提高处理负荷。

下文将对几何阶段两个常可能是瓶颈的阶段的定位方法进行进一步论述。

### 3.2.1 顶点与索引传输的瓶颈定位

GPU渲染管线的第一步，是让GPU获取顶点和索引。而GPU获取顶点和索引的操作性能取决于顶点和索引的实际位置。其位置通常是在系统内存中（通过AGP或PCI
Express总线传送到GPU），或在局部帧缓冲内存中。通常，在PC平台上，这取决于设备驱动程序而不是应用程序，而现代图形API允许应用程序提供使用提示，以帮助驱动程序选择正确的内存类型。

**可以通过调整顶点格式的大小，来确定得到顶点或索引传输是否是应用程序的瓶颈。**

如果数据放在系统内存内，得到顶点或索引的性能与AGP或PCI
Express总线传输速率有关；如果数据位于局部缓冲内存，则与内存频率有关。

如果上述测试对性能都没有明显影响，那么顶点与索引传输阶段的瓶颈也可能位于CPU上。我们可以通过对CPU降频来确认这一事实，如果性能按比例进行变化，那么CPU就是瓶颈所在。

### 3.2.2 顶点变换的瓶颈定位

渲染管线中的顶点变换阶段（Vertex Transformation
Stage）负责输入一组顶点属性（如模型空间位置、顶点法线、纹理坐标等等），以及生产一组适合裁剪和光栅化的属性（如齐次裁剪空间位置，顶点光照结果，纹理坐标等等）。当然，这个阶段的性能与每个顶点完成的工作，以及正在处理的顶点数量有关。

**对于可编程的顶点变换，只要简单地改变顶点程序的长度，就能确定顶点处理是否是瓶颈。**如果此时发生性能的变化，就可以判定顶点处理阶段是瓶颈所在。如上文提到过的，如果要增加指令，在添加富有意义的指令时需要留心，  
以防止被编译器或驱动将指令优化掉。例如，因为驱动程序通常不知道程序编译时常量的值，没有被常量寄存器引用的空操作指令（no-ops）不能被优化（如加入一个含有值为零的常量寄存器）。

**对于固定功能的顶点变换，判定瓶颈则有点麻烦。试着通过改变顶点的工作，例如修改镜面光照或纹理坐标生成的状态来修改负载。**

另外需要注意，顶点处理的速度与GPU核心频率有关。

3.3 应用程序阶段的瓶颈定位
--------------------------

以下是应用程序阶段的瓶颈定位的一些策略的总结：

-   **可以用Profiler工具查看CPU的占用情况。**主要是看当前的程序是否使用了接近100%的CPU占用。比如AMD出品的Code  
    Analyst代码分析工具，可以对运行在CPU上的代码进行分析和优化。Intel也出品了一个称为Vtune的工具，可以分析在应用程序或驱动器（几何处理阶段）中时间花费的位置情况。

-   **一种巧妙的方法是发送一些其他阶段工作量极小甚至根本不工作的数据。**对于某些API而言，可以通过简单地使用一个空驱动器（就是指可以接受调用但不执行任何操作）来取代真实驱动器来完成。这就有效地限制了整个程序运行的速度，因为我们没有使用图形硬件，因此CPU始终是瓶颈。通过这个测试，您可以了解在应用阶段没有运行的阶段有多大的改进空间。也就是说，请注意，使用空驱动程序还隐藏了由于驱动程序本身和阶段之间的通信所造成的瓶颈。

-   **另一个更直接的方法是对CPU 进行降频(
    Underclock）。**如果性能与CPU速率成正比，则应用程序的瓶颈与CPU相关。但需要注意，降频的方法可以帮助识别瓶颈，也有可能导致一个之前不是瓶颈的阶段成为瓶颈。

-   另外，则是排除法，**如果GPU阶段没有瓶颈，那么CPU就一定是瓶颈所在。**

四、下篇：渲染管线的优化策略
============================

一旦确定了瓶颈位置，就可以对瓶颈所处阶段进行优化，以改善我们游戏的性能。下面根据解决问题的不同阶段，对一些优化策略进行了分类整理，将分为六个部分来进行呈现：

-   对CPU的优化策略

-   应用程序阶段的优化策略

-   API调用的优化策略

-   几何阶段的优化策略

-   光照计算的优化策略

-   光栅化阶段的优化策略

4.1 对CPU的优化策略
-------------------

许多应用的瓶颈都位于CPU，有的是正当理由（如复杂的物理或AI运算）导致，有的是因为不好的批处理或资源管理导致。如果已经发现应用程序受到CPU限制，可以试行下列建议，以对渲染管线中CPU的性能进行优化。

### 4.1.1 减少资源锁定

每当执行一个需要访问GPU的同步操作，就可能严重堵塞GPU管线，这将消耗CPU和GPU两者的周期。CPU必须保持在一个循环中，等待GPU管线工作，直到它闲下来并返回所请求的资源，这种等待会造成CPU周期的浪费。然后GPU等待对管线的再填充，这种等待又造成GPU周期的浪费。

上述的锁定发生在以下情况下：

-   对前面正在渲染的表面进行锁定或读出时

-   对GPU正在读的表面进行写入，例如纹理或顶点缓冲区

**而减少资源锁定的方法，可以尝试避免访问渲染期间GPU正在使用的资源。**

### 4.1.2 批次的尺寸最大化

这个策略也可以称为“将批次的数量减到最小”。

批次（batch）是调用单个API渲染所做的一组基本渲染。用来绘制几何体的每个API函数调用，都有对应的CPU消耗。因此最大限度地增加每次调用所提交的三角形的数量，CPU渲染给定数目三角形的消耗就可以减到最小。也即批次的尺寸乘以批次数量得到的工作总量一定，此消彼长。

使批次最大化的技巧列举如下：

-   **若使用了三角形带（Triangle Strips），则使用退化三角形（Degenerate
    Triangles）将不相交的条带拼接起来**。这样就能够一次发送多条三角形带，以便能在单个Draw
    Call中共享材质。

-   **使用纹理页（Texture
    Pages）**。不同物体使用不同纹理时，批次时常会被打破，若通过把多个纹理安排进单个的2D纹理内并适当设定纹理坐标，就能在单个Draw
    Call中发送使用了多个纹理的几何体。此技术可能存在mipmapping和反走样的问题，而回避大部分这类问题的技术是，把单个的2D纹理打包到一个立方体贴图的各个面内。

-   **使用Shader分支来增加单个批次大小从而合批。**现代GPU具有灵活的顶点和片元处理管线。允许Shader里有分支。例如，若两个分开的批次，因为其中一个需要四个骨骼蒙皮顶点着色器，而另一个需要两个骨骼蒙皮顶点着色器，你可以编写一个顶点着色器来遍历所需的骨骼数量，累积混合权重，然后在权重相加为一个时跳出循环。这样两个批次就可以合并为一个。在不支持shader分支的架构上，可以实现相似的功能，方法是上述两种情况都使用4块骨骼的顶点着色器，对骨骼数量不足4块的顶点，将其骨骼权重因子设置为0。

-   **将顶点着色器常量内存（vertex shader constant
    memory）作为矩阵查找表（Lookup Table of
    matrices）使用**。通常，当许多小对象共享所有的属性，但仅矩阵状态不同时（例如，含相似树木的森林，或一个粒子系统），批次就会遭到破坏。这时，可以把n个不同的矩阵加载到顶点着色器常量内存中，并将索引以每个对象的顶点格式存储在常量内存中。然后使用此索引查询顶点shader的常量内存，并使用正确的变换矩阵，从而一次渲染n个对象。

-   **尽可能远地往管线下端推迟决策。**若要速度更快，应该使用纹理的alpha通道作为发光值，而不是打破批次，为光泽设定一个像素shader常量。同样地，把着色数据放入纹理和顶点可以使单个批次的提交量更大。

4.2 应用程序阶段的优化策略
--------------------------

对应用程序阶段的优化，可以通过提高代码的执行速度，以及提到程序的存储访问速度（或者减少存储访问的次数）来实现。下面将给出一些通用的优化技术，适用于大多数的CPU。

最基本的代码优化策略包括为编译器打开优化标志。通常有很多不同的标志，一般需要检查哪些标志可以应用于程序代码中，而且对所使用的优化选项一般不做任何假设。例如，可以将编译器的开关设置为“最小代码大小（minimize
code size）”而不是“速度优化（optimizing for
speed）”，这样可以导致代码执行速度的提高，因为缓冲性能提高了。此外，如果可能的话，可以尝试不同的编译器，因为不同编译器一般是按照不同的方式进行优化的。

对于代码优化来说，定位大部分时间花在哪部分代码是很关键的。一个好的代码profiler是找到大部分运行时间都花费在代码哪里的关键。然后在这些地方进行优化工作。而这些位置通常是内部循环，或是每帧执行多次的代码片段。（PS:本文文末提供了一系列常用的profiler工具的列表）

优化的基本原则是尝试多种策略，包括重新检查算法，假设，以及代码语法等，也就是尽可能多的尝试各种变化情况。

下文将从内存层面和代码层面进一步说明。

### 4.2.1 内存层面的优化

对于存储层次结构来说，如何在各种不同的CPU体系结构上编写执行速度较快的代码变得越来越重要。在编写程序时，应该注意下列准则：

-   **在代码中连续访问的存储内容在内存中也应保持连续存储。**例如，当渲染一个三角形网格的时候，如果访问的顺序是：纹理坐标\#0、法线\#0、颜色\#0、顶点\#0、纹理坐标\#1、法线\#1等，那么在内存中也应该按这个顺序连续存储。**尽量避免指针的间接、跳转，以及函数调用，因为它们很容易显著降低CPU中缓冲的性能。**比如当一个指针指向另一个指针，而这个指针又指向其他指针时，以此类推，类似典型的链表和树结构，而这将导致数据缓存未命中（cache
    misses for data）。为了避免这种情况，应该尽可能使用数组来代替。

PS: 上述条准则的思想有点类似《Game Programming
Patterns》书中讲到的数据局部性模式（Data Locality pattern），具体可以参考《Game
Programming
Patterns》这本书的web版关于数据局部性模式的讲解：[http://gameprogrammingpatterns.com/data-locality.html](http://link.zhihu.com/?target=http%3A//gameprogrammingpatterns.com/data-locality.html)

-   **某些系统中，默认的内存分配和删除功能可能比较慢，因此，在启动时最好为相同大小的对象分配一个大的内存池，然后使用自己分配或空闲部分来处理该池的内存。**

-   **尽量尝试去避免在渲染循环中分配或释放内存**。例如，可以单次分配暂存空间(scratch
    space)，并且使用栈、数组等其他仅增长的数据结构（也可以使用标志位来标识哪些元素应该被视为已删除）。

-   **对数据结构尝试用不同的组织形式。**例如，Hecker[2]指出，对于一个简单的矩阵乘法器而言，通过不同的矩阵结构可以节省大量的计算开销。例如，一个结构数组如下：

**struct** Vertex {**float** x,y,z;}

Vertex myvertices[1000];

或者为：

**struct** VertexChunk {**float** x[1000],y[1000],z[1000];}

VertexChunk myvertices;

对于给定的体系结构而言，上述第二种结构对于SIMD命令来说要更好一些。但是随着顶点数目的增多，高速缓存的命中失误率也会随之增多。当数组大小增加到一定程度时，下面这种混合方案可能是最好的一种选择：

**struct** Vertex4 {**float** x[4],y[4],z[4];}

Vertex4 myvertices[250];

### 4.2.2 代码层面的优化

下面的会列出编写与计算机图形相关的高效代码的一些技术。这些方法随着编译器和不断发展的CPU而有所不同，但大多数已经保存了很多年（主要是针对C/C++而言）：

-   **善用SIMD。**单指令多数据流（Single Instruction Multiple
    Data，SIMD），例如Intel的MMX或SSE，以及AMD的3D
    Now!指令集，在很多情形下能获得很好的性能，可以并行计算多个单元，且比较适合用于顶点操作。

-   **使用float转long转换在奔腾系列处理器上速度较慢。**如果可以请尽量避免。

-   **尽可能避免使用除法。**相对于其他大多数指令而言，执行除法指令所需要的时间大约是执行其他指令所需时间的2.5倍或更多。

-   **许多数学函数，如sin、cos、tan、exp、arcsin等，计算开销较高，使用的时候必须小心。如果可以接受低精度，那么只需要使用麦克劳林（MacLaurin）或泰勒（Taylor）级数的前几项即可。**由于现代CPU对内存的访问的代价依然很高，因此使用级数的前几项比使用查找表（Lookup
    Tables）强得多。

-   **条件分支会有一定的开销，Shader中的条件分支开销尤甚。**尽管大多数处理器都有分支预测功能，但是这意味着只有准确地进行分支预测，才有可能降低计算开销。错误的分支预测对一些体系结构、特别是对于具有深管线的体系结构来说，计算开销通常会较高。

-   **对于经常调用的小函数使用内联（Inline）。**

-   **在合理的情况下减少浮点精度，比如用float代替double。**而当选用float型来代替double型数据时，需要在常数末尾加上一个f。否则，整个表达式就会被强制转换为double型；因此，语句float
    x =2.42f；要比float x = 2.42；执行得更快。

-   **尽可能使用低精度数据，让发送到图形管线的数据量更少。**

-   **虚函数方法、动态转换、（继承）构造，以及按值传递结构体（passing structs by
    value）都会对效率造成一定影响。**据了解，一帧画面中大约有40%的时间花费在用于模型管理的虚拟继承层次结构上。Blinn提出了一种技术[3]，可以避免计算C++中向量表方面的一部分开销。

4.3 API调用的优化策略
---------------------

上文已经提到，批次（batch）是调用单个API渲染所做的一组基本渲染。用来绘制几何体的每个API函数调用，都有对应的CPU消耗。改进批次过小问题的方法有很多种，且它们都有共同的目标——更少的API调用。以下是一些要点。

-   **一种减少API调用的方法是使用某种形式的实例（Instance）**。大多数API都支持在一次调用中拥有一个对象并进行多次绘制。因此，与其为森林中的每一棵树单独调用API，不如使用单次调用来渲染树模型的许多副本。如下图。

![](media/f0613d0d3a05fd00a20e406960b2a066.jpg)

![](media/82fd0dea9bcaf4fb767fb3eba8075b04.jpg)

图4 植被实例（Vegetation instancing）。所有同样颜色的物体在一个Draw
Call中进行渲染。

PS: 此思想有点类似设计模式中的享元模式（flyweight pattern）。具体可以参考《Game
Programming
Patterns》这本书的web版关于享元模式的精彩讲解：[http://gameprogrammingpatterns.com/flyweight.html](http://link.zhihu.com/?target=http%3A//gameprogrammingpatterns.com/flyweight.html)

-   **进行批处理（batching）**。批处理的基本思想是将多个对象合并成一个对象，因此只需要一个API调用便可以渲染整个集合。批处理中的合并可以一次性完成，且缓冲区对静态对象集合都能每帧进行重用。对于动态对象，可以使用多个网格填充单个缓冲区。但这种基本方法的局限性是，网格中的所有对象都需要使用一组相同的着色器程序，即相同的材质。

-   **可以用不同的颜色来合并对象，例如，通过用标识符对每个对象的顶点进行标记。**着色器程序可以根据此标识符，查找使用什么颜色来遮挡物体。同样的想法可以扩展到其他表面属性。类似地，附于表面的纹理也可以用于标识使用哪种材质。而单独物体的光照贴图需合并成纹理图集（texture
    atlases）或纹理数组（texture array）。

-   **多人同屏的场景很适合使用实例进行渲染，其中每个角色都拥有独特的一套外表。**而进一步的变化可以添加随机的肤色和贴花。这种基于实例的方法也可以结合LOD技术进行。如下图。

![](media/fd7d4ea340f5190bfdc4a827230bd2e2.jpg)

图5 多人同屏场景（crowd scene）。使用实例（instancing）来减少Draw
Call，也可以结合LOD技术使用，比如对于远处的模型，使用 impostors进行渲染。

-   **提高性能的另一种方法是通过将具有类似渲染状态的对象（顶点和像素着色器、纹理、材质、光照、透明度等）分组并将它们按顺序渲染，从而最小化状态更改**。

-   改变状态时，有时需要完全或部分地清理管线。出于这个原因，改变着色器程序或材质参数可能非常昂贵。**对使用共享材质（shared
    material）的节点可以进行分组，以获得更好的性能，而采用共享纹理（shared
    texture）绘制多边形可以减小纹理缓存的抖动。**另外，正如上文提到的，一种减少纹理改变的变化的方法便是把一些纹理图像到一个大的纹理图集或纹理数组中。

-   **理解对象缓冲（object
    buffer）在渲染时的分配和存储方式也同样重要。**对于一个含CPU和GPU的系统，GPU和CPU有各自的内存，而图形驱动程序通常控制对象所在的位置，它也可以给出存储在何处是更优的建议。一个常见的类型分类是静态与动态缓冲区。如果一个物体不形变，或者形变可以完全由着色器程序（如蒙皮）完成，那么在GPU内存中存储对象的数据是较为合适的。而该对象的不变属性可以通过将其存储在为静态缓冲区中。通过这种方式，不必在渲染的每帧在总线上发送这些不变的数据，从而避免在管线的这一阶段出现瓶颈。

4.4 几何阶段的优化策略
----------------------

几何阶段主要负责变换、光照、裁剪、投影，以及屏幕映射。其中，变换和光照过程比较容易优化，其他几个部分的优化稍显困难。以下是一些要点：

-   变换、光照、裁剪、投影，以及屏幕映射操作可以使用较低精度的数据，以减小开销。

-   合理地使用索引和顶点缓冲区可以帮助几何阶段减小计算量。

-   **可以简化模型来减小整个管线的顶点和绘制图元的数量，以降低顶点数据传输和顶点变换成本。**而诸如视锥裁剪和遮挡剔除之类的技术避免了将全部的图元发送到管线。

-   可以使用缓存感知（cache-oblivious）布局算法，其中顶点以某种形式排列，以最大限度地提高缓存重用性，从而节省处理时间。（具体可见RTR3原文
    12.4.4节）

-   同理，**为了节省内存和访问时间，尽可能在顶点、法线、颜色和其他着色参数上，选择更低精度的数据格式。**有时我们会在half、single、double。float精度之间做选择，需要注意，除了其中因为精度更低带来的速度提升外，有些格式也会因为是硬件内部使用的原生格式（native
    format）而更快。

-   **减少内存使用的另一种方法是将顶点数据存储在压缩格式中。**对此，Deering
    [4]深入讨论了这种技术. Calver
    [5]提出了各种方案，使用顶点着色器进行解压。zarge [ 6
    ]也指出，数据压缩也有助于调整顶点格式缓存线。而Purnomo等人[ 7
    ]结合简化方法和顶点的量化技术，使用图像空间的度量，提出了为一个给定的目标网格尺寸优化网格的方案。

### 4.4.1 减少顶点传输的开销

顶点传递是瓶颈的可能性很小，但也偶有发生。假如顶点或索引（索引是瓶颈的可能性更小）的传递是应用瓶颈，可以试着使用下列各项策略：

-   **在顶点格式中使用尽可能少的位。**位数足够即可，不需要对所有数据都使用浮点格式（例如对颜色）。

-   **在顶点程序中产生可推导的顶点属性，而不是把他们存储在输入顶点格式中。**例如，正切线(tangent)、法线(normal)和副法线(binormal)通常不需要都存储。给出任意两个，能用Vertex-program简单叉积推导出第三个。这项技术，即为用顶点处理速度去换取顶点传输速率。

-   **使用16位的索引代替32位的索引。**16位索引更容易查找。移动起来更轻量，而且占用的内存更少。

-   **以相对连续的方式访问顶点数据。**当访问顶点数据时现代GPU可以进行缓存。因为在任意内存层次中，引用的空间局部性有助于最大化缓存的命中率，这可以减少对带宽的要求。

### 4.4.2 顶点处理的优化

顶点处理是现代GPU的瓶颈可能性很小，但是也偶有发生，这取决于所使用的模式和目标硬件。如果发现顶点处理是瓶颈所在，可以试用如下列举的各项策略：

-   **对变换和照明(T&L)后的顶点存储进行优化。**现代GPU有一个小的先入先出(FIFO)的缓存，用于存储最近所转换的顶点结果：命中这个高速缓冲器可以保存所有的变换和照明，以及所有流水线早先完成的工作。为了利用这个缓存的优势，必须使用经过索引的图元，而且必须对顶点进行排序，以最大化网格上的引用局部性。可以帮助完成这个任务的工具有D3DX和NVTriStrip等。

-   **减少所处理的顶点数。**这是能想到的很基本的解决方案。但是使用简单的层次细节方案，例如一组静态的LOD，确实有助于减少顶点处理的负担。

-   **使用顶点处理LOD。**在使用层次细节减少所处理的顶点数时，可以试着把层次细节用于顶点计算本身。例如，对远处的任务没必要完全做4块骨骼的蒙皮，或许可以使用更轻量的光照近似。而如果当前材质的shader是多通道的，那么减少位于远处低LOD级别的渲染通道数量，也会减少顶点处理的成本。

-   **把每个物体的计算留给CPU去做。**每个物体或每帧都改变的计算时常在顶点着色器中进行。例如，将方向光矢量转换到视点空间的通常在顶点shader中进行，虽然计算结果只是每帧改变一次。

-   **使用正确的坐标空间。**坐标空间的选择时常影响计算视点程序值所需的指令数。例如，计算顶点光照时，如果顶点法线存储在物体空间中，而方向光矢量存储在视图空间中，就须在顶点shader中转换其中之一，将两者转换到统一空间下。而如果改为在CPU上对每个物体一次性地把光矢量转换到物体空间，再进行逐个顶点的转换就没有必要了，这样就节省了GPU顶点处理的运算量。

-   **使用顶点分支来“提前结束”计算**。例如，若在顶点着色器中循环多个光源，然后进行法线、[0，1]低动态范围的光照，你可以判断饱和度到1，或者远离光源的顶点，来break掉，避免进一步无用的计算。对于蒙皮阶段有一个类似的优化，当权重之和达到1时，停止计算（因此所有后来加权的值是0）。需要注意，这个方法是否生效，依赖于GPU如何实现顶点分支，无法在所有架构上保证性能的改善。

4.5 光照计算的优化策略
----------------------

考虑光照的影响可以每顶点，每像素的进行计算，光照计算可以通过多种方式进行优化：

-   **首先，应该考虑使用的光源类型，以及可以考虑是否所有的多边形都需要光照。**有时模型只需纹理贴图，或者在顶点使用纹理，或只需要顶点颜色。那么很多多边形就无需进行光照计算。

-   **如果光源是静态的，且照明对象是几何体，那么漫反射光照和环境光可以预先计算并存储在顶点颜色中。**这样做通常被称为烘焙照明（baking
    lighting）。一个预光照（prelighting）更复杂的形式是使用辐射度（Radiosity）方法预先计算场景中的漫反射全局光照，而这样的光照可以存储在顶点颜色或光照贴图（lightmaps）中。

-   **控制光源的数量。**光源的数量影响几何阶段的性能，更多的光源意味着更少的速度。此外，双面的光照可以比单面光照更为昂贵。当对光源使用固定功能距离衰减时，根据物体与光源的距离来关闭/打开光源是有较为有用，且几乎不会被察觉。而距离足够大时，可以关掉光源。

-   **一种常见的优化方法是根据光源的距离来进行剔除，只渲染受本地光源影响的对象。**

-   **另一种减少工作的方法是禁用光源，取而代之的是使用环境贴图（environment
    map）**

-   **如果场景拥有大量光源，可以使用延迟着色技术来限制计算量和避免状态的变化。**

4.6 光栅化阶段的优化策略
------------------------

光栅化阶段可以以多种方式进行优化。现将主流的优化策略列举如下：

-   **善用背面裁剪**。对封闭（实心）的物体和无法看到背面的物体（例如，房间内墙的背面）来说，应该打开背面裁剪开关。这样对于封闭的物体来说，可以将需光栅化处理的三角形数量减少近50%。但需要注意的是，虽然背面裁剪可以减少不必要的图元处理，但需要花费一定的计算量来判断图元是否朝向视点。例如，如果所有的多边形都是正向的，那么背向裁剪计算就会降低几何阶段的处理速度。

-   **一种光栅化阶段的优化技术是在特定时期关闭Z缓冲（Z-buffering）。**例如，在清楚帧缓冲之后，必须要进行深度测试也可以直接渲染出任何背景图像。如果屏幕上的每个像素保证被某些对象覆盖（如室内场景，或正在使用背景天空图），则不需要清楚颜色缓冲区。同样，确保只有在需要时才使用混合模式（blend
    modes）。

-   **值得一提的是，如果在使用Z缓冲，在一些系统上使用模板缓冲不需要额外的时间开销。**这是因为8位的模板缓冲的值是存储为24位z深度值的同一个word中。

-   **优先使用原生的纹理和像素格式。**即使用显卡内部使用的原生格式，以避免可能会有的从一种格式到另一种格式的昂贵转换。

-   **另一种适用于光栅化阶段的优化技术是进行合适的纹理压缩。**如果在送往图形硬件之前已经将纹理压缩好，那么将它发送到纹理内存中的速度将会非常迅速。压缩纹理的另一个优点是可以提高缓存使用率，因为经过压缩的纹理会使用更少的内存。

-   **另一种有用的相关优化技术是基于物体和观察者之间的距离，使用不同的像素着色器。**例如，在场景中有三个飞碟模型，最接近摄像机的飞碟的可能用详细的凹凸贴图来进行渲染，而另外两个较远的对象则不需要渲染出细节。此外，对最远的飞碟可以使用简化的镜面高光，或者直接取消高光，来简化了计算量以及减少采样次数。

-   **理解光栅化阶段的行为。**为了很好地理解光栅阶段的负荷，可以对深度复杂度进行可视化，所谓的深度复杂度就是指一个像素被接触的次数。生成深度复杂度图像的一种简单方法就是，使用一种类似于OpenGL的glBlendFunc(GL
    ONE,GL
    ONE)调用，且关闭Z缓冲。首先，将图像清除成黑色；然后，对场景中所有的物体，均使用颜色(0,0,1)进行渲染。而混合函数（blend
    function）设置的效果即是对每个渲染的图元来说，可以将写入的像素值增加(0,0,1)。那么，深度复杂度为0的像素是黑色，而深度复杂度为255的像素为全蓝色（0,
    0, 255）。

-   **可以通过计数得到通过Z缓冲与否的像素进行计数，从而确定需进一步优化的地方。**使用双通道的方法对那些通过或没通过Z缓冲深度测试的像素进行计数。在第一个通道中，激活Z缓冲，并对那些通过深度测试的像素进行计数。而对那些没有通过深度测试的像素进行计数，可以通过增加模板缓冲的方式。另一种方法是关闭Z缓冲进行渲染来获得深度复杂度，然后从中减去第一个通道的结果。

通过上述方法得到结果后，可以确认：

（1）场景中深度复杂度的平均值、最小值和最大值

（2）每个图元的像素数目（假定已知场景中图元的数目）;

（3）通过或没有通过深度测试的像素数目。

而上述这些像素数量对理解实时图形应用程序的行为、确定需要进一步优化处理的位置都非常有用。

通过深度复杂度可以知道每个像素覆盖的表面数量，重复渲染的像素数量与实际绘制的表面的多少是相关的。假设两个多边形覆盖了一个像素，那么深度复杂度就是2。如果开始绘制的是远处的多边形，那么近处的多边形就会重复绘制整个远处的多边形，重绘数量也就为1。如果开始绘制的是近处的多边形，那么远处的多边形就不会通过深度测试，从而也就没有重绘问题。假设有一组不透明的多边形覆盖了一个像素，那么平均绘制数量就是调和级数：
![](media/5.1.png)

上式背后所包含的逻辑是：第一个绘制的多边形是一次绘制：第2个多边形在第一个多边形之前绘制的概率是1/2：第三个多边形在前两个多边形前绘制的概率是1/3。依次类推，当n取极极限时：

![](media/5.2.jpg)

其中，γ=0.57721…是Euler-Mascheroni常量。当深度复杂度很低时，重绘量会急剧增加，但增加速度也会逐渐减少。深度复杂度为4，平均绘制2.08次，深度复杂度为11，平均绘制3.02次，但深度复杂度为12367，平均绘制10次。

通过进行粗排序，并从前向后场景的渲染对性能提升会有帮助。这是因为后面绘制的被遮挡物体无需写入颜色缓冲区或Z缓冲区中。此外，在到达像素着色器程序之前，像素片元也可以被遮挡剔除硬件丢弃掉。

-   **另一种称为“early z
    pass”的技术对带复杂片元着色器的表面很有用**。即首先渲染z缓冲，然后再对整个场景进行渲染。此方法对于避免不必要的像素着色器的计算非常有用，因为只有可见的表面才会进行像素着色的计算。而通过BSP树遍历或显式地排序提供了一个粗略的前后顺序，可以提供很多优势，而不需要额外的Pass。

### 4.6.1 加速片元着色

如果你正在使用长而复杂的片元着色器，那么往往瓶颈就处于片元着色器中。若果真如此，那么可以试试如下这些建议：

-   **优先渲染深度。**在渲染主要着色通道（Pass）前，先进行仅含深度的通道（depth-only
    (no-color)
    pass）的渲染，能显著地提高性能，尤其是在高深度复杂性的场景中。因为这样可以减少需要执行的片元着色量，以及帧缓冲存储器的存取量，从而提高性能。而为了发挥仅含深度的通道的全部优势，仅仅禁用颜色写入帧缓冲是远远不够的，同时也应该禁用所有向片元的着色，甚至禁用影响到深度以及颜色的着色（比如
    alpha test）。

-   **帮助early-z优化（即Z缓冲优化），来避免多余片元处理** 。现代GPU配有设计良好的芯片，以避免对被遮挡片元的着色，但是这些优化依赖场景知识。而以粗略地从前向后的顺序进行渲染，可以明显提高性能。以及，先在单独的pass中先渲染深度（见前一条tip），通过将着色深度复杂度减少到1，可以有效地帮助之后的pass（主要的昂贵的shader计算的位置）进行加速。

-   **在纹理中存储复杂功能。**纹理作为查找表( lookup
    tables)其实非常好用，而且可以无消耗地过滤它们的结果。一个典型例子便是单位立方体贴图，它仅允许以一个单一纹理查找的代价来高精度地对任意向量进行标准化。

-   **将更多每片元的工作移到顶点着色器。**对于优化的大方向而言，正如顶点着色器中的每个物体的计算量工作应该尽可能地移到CPU中一样，每顶点的计算也应该尽量被移到顶点着色器（连同在屏幕空间中线性插值计算）。常见的例子包括计算向量和坐标系之间的变换向量。

-   **使用必需的最低精度。**诸如DirectX之类的API允许您在着色器代码中指定精度，以减少精度高所带来的额外计算量。很多GPU都可以利用这些提示来减少内部精度以及提高性能。

-   **避免过度归一化（Normalization）。**在写shader时，对每个步骤的每个矢量都进行归一化的习惯，常常被调侃为“以归一化为乐（Normalization-Happy）”。这个习惯通常来说其实是不太好的习惯。我们应该意识到不改变长度的变换（例如标准正交基上的变换）和不依赖矢量长度的计算（例如正方体贴图的查询）是完全没必要进行归一化后再进行的。

-   **考虑使用片元着色器的LOD层次细节。**虽然片元着色器的层次细节不像顶点着色器的层次细节影响那么大（由于投射，在远处物体本身的层次细节自然与像素处理有关），但是减少远处着色器的复杂性和表面的通道数，可以减少片元处理的负载。

-   **在不必要的地方禁用三线性过滤**。在现代GPU结构的片元着色器中计算三线性过滤(Trilinear
    filtering)，即使不消耗额外的纹理带宽，也要消耗额外的循环。在mip级别转换不容易辨别的纹理上，关掉三线性过滤，可以节省填充率。

-   **使用尽可能简单的Shader类型。**在Direct3D和OpenGL中，对片元进行着色都有多种方法。举例来说，在Direct3D
    9中，可以指定片元着色的使用，随着复杂性和功率的增加，有纹理阶段、像素shader版本
    1.x、像素 shader版本 2.x，以及像素shader
    3.0等。一般而言，应该使用最简单的着色器版本来创建预期的效果。更简单的着色版本提供了更多的一些隐式编译选项，通常可以用来让它们更快地被GPU驱动程序编译成处理像素的原生代码。

### 4.6.2 减少纹理带宽

如果发现内存带宽是瓶颈，但是大部分结果又要从纹理中取得，那么可以考虑以下方面的优化。

-   **减少纹理尺寸。**考虑目标分辨率和纹理坐标。如果玩家是不是真的会看到最高级别的mip级别，如果不是，就应该考虑缩减纹理大小。此方法在超载的帧缓冲存储器从非本地存储器（例如系统存储器，通过AGP或PCI
    Express总线）强制进行纹理化时会非常有用。一个NVIDIA在2003年出品的名叫NVPerfHUD的工具可以帮助诊断这个问题，其显示了各个堆（heaps）中由驱动所分配的内存量。

-   **压缩所有的彩色纹理**。应该压缩作为贴花或细节的一切纹理，根据特定纹理alpha的需要，选用DXT1、DXT3或DXT5进行压缩。这个步骤将会减少内存使用，减少纹理带宽需求，并提高纹理缓存效率。

-   **避免没必要的昂贵纹理格式。**64位或128位浮点纹理格式，显然要花费更多带宽，仅在不得已时才可以使用它们。

-   **尽可能地在缩小的表面上使用mipmapping**。mipmapping除了可以通过减少纹理走样改善质量外，还可以通过把纹理内存访问定位在缩小的纹理上来改善纹理缓存效用。如果发现某个mipmapping使表面看起来很模糊，不要禁用mipmapping，或增加大的LOD级别的基准偏移，而是使用各向异性过滤（anisotropic
    filtering），并适当调整每个批次各向异性的级别。

### 4.6.3 优化帧缓冲带宽

管线的最后阶段，光栅化操作，与帧缓冲存储器直接衔接，是消耗帧缓冲带宽的主要阶段。因此如果带宽出了问题，经常会追踪到光栅化操作。下面几条技巧将讲到如何优化帧缓冲带宽。

-   **首先渲染深度。**这个步骤不但减少片元着色的开销(见上文)，也会减少帧缓冲带宽的消耗。

-   **减少alpha混合。**当alpha混合的目标混合因子非0时，则要求对帧缓冲区进行读取和写入操作，因此可能消耗双倍的带宽。所以只有在必要时才进行alpha混合，并且要防止高深度级别的alpha混合复杂性。

-   **尽可能关闭深度写入。**深度写入会消耗额外的带宽，应该在多通道的渲染中被禁用（且多通道渲染中的最终深度已经在深度缓冲区中了）。比如在渲染alpha混合效果（例如粒子）时，也比如将物体渲染进阴影映射时，都应该关闭深度写入。另外，渲染进基于颜色的阴影映射也可以关闭深度读取。

-   **避免无关的颜色缓冲区清除**。如果每个像素在缓冲区都要被重写，那么就不必清除颜色缓冲区，因为清除颜色缓冲区的操作会消耗昂贵的带宽。但是，只要是可能就应该清除深度和模板缓冲区，这是因为许多早期z值优化都依赖被清空的深度缓冲区的内容。

-   **默认大致上从前向后进行渲染。**除了上文提到的片元着色器会从默认大致上从前向后进行渲染这个方法中受益外，帧缓冲区带宽也会得到类似的好处。早期z值硬件优化能去掉无关的帧缓冲区读出和写入。实际上，没有优化功能的老硬件也会从此方法中受益。因为通不过深度测试的片元越多，需要写入帧缓冲区的颜色和深度就越少。

-   **优化天空盒的渲染。**天空盒经常是帧缓冲带宽的瓶颈，因此必须决定如何对其进行优化，以下有两种策略：

（1）最后渲染天空盒，读取深度，但不写入深度，而且允许和一般的深度缓冲一起进行早期early-z优化，以节省带宽。

（2）首先渲染天空盒，而且禁用所有深度读取和写入。

以上两种策略，究竟哪一种会节省更多开端，取决于目标硬件的功能和在最终帧中有多大部分的天空盒可见。如果大部分的天空盒被遮挡，那么策略（1）更好，否则，策略（2）可以节省更多带宽。

-   **仅在必要时使用浮点帧缓冲区。**显然，这种格式比起较小的整数格式来说，会消耗更多的带宽，所以，能不用就不用。对多渲染目标(
    Multiple Render Targets，MRT)也同样如此。

-   **尽可能使用16为的深度缓冲区**。深度处理会消耗大量带宽，因此使用16位代替32位是极有好处的，且16位对于小规模、不需要模板操作的室内场景往往就足够了。对于需要深度的纹理效果，16位深度缓冲区也常常足够渲染，如动态的立方体贴图。

-   **尽可能使用16位的颜色**。这个建议尤其适用于对纹理的渲染效果，因为这些工作的大多数，用16位的颜色能工作得很好，例如动态立方体贴图和彩色投射阴影贴图。

综上，现代GPU能力和可编程性的增强，使得改善机器性能变得更复杂。无论是打算加速应用程序的性能，还是希望无成本地改善图像质量，都需要对渲染管线的内部工作原理有深刻理解。而GPU管线优化的基本思路是，通过改变每个单位的负荷或计算能力来识别瓶颈，然后运用每个传递单元工作原理的理解，系统地解决那些瓶颈。

五、主流性能分析工具列举
========================

有很多不错的分析图形加速器和CPU使用的的工具，以及性能优化相关的Profiling工具，在这里，将主流的工具进行列举：

-   Adreno Profiler

-   GPA

-   Tegra Graphics Debuger

-   Xcode Profiler

-   Xcode Instruments

-   PIX for Windows (for DirectX)

-   gDEBugger (for OpenGL)

-   NVIDIA’s NVPerfKit suite of tools

-   ATI’s GPU PerfStudio

-   Apple’s OpenGL Profiler

-   Linux
    上的Valgrind [http://valgrind.org/](http://link.zhihu.com/?target=http%3A//valgrind.org/)

-   NVIDIA出品的Nsight系列性能优化套件

-   [https://developer.nvidia.com/gameworks-tools-overview](http://link.zhihu.com/?target=https%3A//developer.nvidia.com/gameworks-tools-overview)

-   CPU端内循环优化工具
    Vtune [https://software.intel.com/en-us/intel-vtune-amplifier-xe](http://link.zhihu.com/?target=https%3A//software.intel.com/en-us/intel-vtune-amplifier-xe)

-   AQTime - 代码
    profilers工具 [https://smartbear.com/product/aqtime-pro/overview/](http://link.zhihu.com/?target=https%3A//smartbear.com/product/aqtime-pro/overview/)

现今主流游戏引擎提供的Profiler有：

-   Unreal Engine
    的一列系列Profiler工具集 [https://docs-origin.unrealengine.com/latest/INT/Engine/Performance/](http://link.zhihu.com/?target=https%3A//docs-origin.unrealengine.com/latest/INT/Engine/Performance/)

-   Unity的Profiler和后续新加入的Frame Debugger

    -   Unity –
        Profiler [https://docs.unity3d.com/Manual/ProfilerWindow.html](http://link.zhihu.com/?target=https%3A//docs.unity3d.com/Manual/ProfilerWindow.html)

    -   Unity - Frame
        Debugger [https://docs.unity3d.com/Manual/FrameDebugger.html](http://link.zhihu.com/?target=https%3A//docs.unity3d.com/Manual/FrameDebugger.html)

![](media/01802dfa57da72a6c6a76161da4b1e04.jpg)

图6 Unreal Engine的GPU Visualizer

![](media/764ef0dcbbfd8d6ae91186e3a36d0821.jpg)

图7 Unity的Profiler

六、更多性能优化相关资料
========================

-   虽然有点过时，Cebenoyan的文章[1]概述了如何找到提高效率的瓶颈和技术。

-   《NVIDIA's extensive guide》[8]包含了相关的各种主题。

-   一些很赞的C++优化指南包括Fog的文章[9]和Isensee的文章[10]。

Reference
=========

[1] Cebenoyan, Cem, “Graphics Pipeline Performance,” in Randima Fernando,
ed.,GPU Gems, Addison-Wesley, pp. 473–486,2004. Cited on p. 681, 699, 701,
716,722

[2] Hecker, Chris, “More Compiler Results, and What To Do About It,” Game
Developer, pp. 14–21, August/September 1996. Cited on p. 705

[3] Blinn, Jim, “Optimizing C++ Vector Expressions,” IEEE Computer Graphics
&Applications, vol. 20, no. 4, pp. 97–103, 2000. Also collected in [110],
Chapter 18.Cited on p. 707

[4] Deering, Michael, “Geometry Compression,” Computer Graphics (SIGGRAPH 95
Proceedings), pp. 13–20, August 1995. Cited on p. 555, 713

[5] Calver, Dean, “Vertex Decompression Using Vertex Shaders,” in Wolfgang
Engel, ed., ShaderX, Wordware, pp. 172–187, May 2002. Cited on p. 713

[6] Zarge, Jonathan, and Richard Huddy, “Squeezing Performance out of your Game
with ATI Developer Performance Tools and Optimization Techniques,”Game
Developers Conference, March
2006. [http://ati.amd.com/developer/gdc/2006/GDC06-ATI](http://link.zhihu.com/?target=http%3A//ati.amd.com/developer/gdc/2006/GDC06-ATI) Session-Zarge-PerfTools.pdf  
Cited on p. 270, 699, 700, 701,702, 712, 713, 722, 847

[7] Purnomo, Budirijanto, Jonathan Bilodeau, Jonathan D. Cohen, and Subodh
Kumar,“Hardware-Compatible Vertex Compression Using Quantization and
Simplification,”Graphics Hardware, pp. 53–61, 2005. Cited on p. 713

[8] NVIDIA Corporation, “NVIDIA GPU Programming Guide,” NVIDIA developer
website, 2005. [http://developer.nvidia.com/object/gpu programming
guide.html](http://link.zhihu.com/?target=http%3A//developer.nvidia.com/object/gpu%2520programming%2520guide.html)Cited
on p. 38, 282, 699, 700, 701, 702, 712, 722

[9] Fog, Agner, Optimizing software in C++, 2007. Cited on p. 706, 722

[10] Isensee, Pete, “C++ Optimization Strategies and Techniques,” 2007. Cited on
p.706, 722

```

`Content/《Real-Time Rendering 3rd》读书笔记/README.md`:

```md

# 【《Real-Time Rendering 3rd》 提炼总结】
 《Real-Time Rendering 3rd》可谓图形学界“九阴真经总纲”一般的存在，当世武功的心法口诀，尽数记载。这个系列的读书笔记，是对这本神作一个系统而有特色的总结提炼。
 
 <img src="Content/BlogPost01/media/1.jpg" height = "600" alt="name" align=center />
<br>

# 目录

* [【《Real-Time Rendering 3rd》 提炼总结】(一) 全书知识点总览](https://github.com/QianMo/Game-Dev-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Content/BlogPost01)

* [【《Real-Time Rendering 3rd》 提炼总结】(二) 第二章 · 图形渲染管线 The Graphics Rendering Pipeline](https://github.com/QianMo/Game-Dev-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Content/BlogPost02)

* [【《Real-Time Rendering 3rd》 提炼总结】(三) 第三章 · GPU渲染管线与可编程着色器](https://github.com/QianMo/Game-Dev-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Content/BlogPost03)

* [【《Real-Time Rendering 3rd》 提炼总结】(四) 第五章 · 图形渲染与视觉外观 The Visual Appearance](https://github.com/QianMo/Game-Dev-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Content/BlogPost04)

* [【《Real-Time Rendering 3rd》 提炼总结】(五) 第六章 · 纹理贴图及相关技术](https://github.com/QianMo/Game-Dev-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Content/BlogPost05)

* [【《Real-Time Rendering 3rd》 提炼总结】(六) 第七章 · 高级着色：BRDF及相关技术](https://github.com/QianMo/Game-Dev-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Content/BlogPost06)

* [【《Real-Time Rendering 3rd》 提炼总结】(七) 第七章续 · 延迟渲染(Deferred Rendering)的前生今世](https://github.com/QianMo/Game-Dev-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Content/BlogPost07)

* [【《Real-Time Rendering 3rd》 提炼总结】(八) 第九章 · 全局光照:光线追踪、路径追踪与GI技术进化编年史](https://github.com/QianMo/Game-Dev-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Content/BlogPost08)

* [【《Real-Time Rendering 3rd》 提炼总结】(九) 第十章 · 游戏开发中基于图像的渲染技术总结](https://github.com/QianMo/Game-Dev-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Content/BlogPost09)

* [【《Real-Time Rendering 3rd》 提炼总结】(十) 第十一章 · 非真实感渲染(NPR)相关技术总结](https://github.com/QianMo/Game-Dev-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Content/BlogPost10)

* [【《Real-Time Rendering 3rd》 提炼总结】(十一) 第十四章 : 游戏开发中的渲染加速算法总结](https://github.com/QianMo/Game-Dev-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Content/BlogPost11)

* [【《Real-Time Rendering 3rd》 提炼总结】(十二) 渲染管线优化方法论：从瓶颈定位到优化策略](https://github.com/QianMo/Game-Dev-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Content/BlogPost12)

<br>

# 【《Real-Time Rendering 3rd》 提炼总结】的合辑PDF电子书版本

<br>

链接： [电子书《《Real-Time Rendering 3rd》提炼总结》](https://github.com/QianMo/Real-Time-Rendering-3rd-Summary-Ebook)


# 配套伴侣-实时渲染核心知识网络图解

![](https://github.com/QianMo/Game-Programmer-Study-Notes/blob/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E7%9F%A5%E8%AF%86%E7%BD%91%E7%BB%9C%E5%9B%BE%E8%B0%B1/Real-Time-Rendering-3rd-Knowledge-Diagram.jpg)






```

`Content/《代码整洁之道》读书笔记/README.md`:

```md
# 《代码整洁之道》读书笔记
<br>


Part1 让代码比你来时更干净
--------------------------

- 编写代码的难度，取决于周边代码的阅读难度。想要快速实现需求，想要快速完成任务，想要轻松的写代码，请先让你书写的代码整洁易读。

- 保持整洁的习惯，发现脏代码就要及时纠正。花时间保持代码代码整洁，这不但有关效率，还有关项目的生存。


- 程序员遵从不了解混乱风险的产品经理(策划)的意愿，都是不专业的做法。

- 让代码比你来时更干净：如果每次签入时，代码都比签出时干净，那么代码就不会腐坏。


- 赶上期限的唯一方法，做得更快的唯一方法，就是在始终尽可能保持代码的整洁。

<br>

Part2 整洁代码的命名法则
------------------------

- 要点一：要名副其实。一个好的变量、函数或类的名称应该已经答复了所有的大问题。一个好名称可以大概告诉你这个名称所代表的内容，为什么会存在，做了什么事情，应该如何用等。

- 要点二：要避免误导。我们应该避免留下隐藏代码本意的错误线索，也应该避免使用与本意相悖的词。

- 要点三：尽量做有意义的区分。尽量避免使用数字系列命名（a1、a2…….aN）和没有意义的区分。

- 要点四：尽量使用读得出来的名称。如名称读不出来，讨论的时候会不方便且很尴尬。

- 要点五：尽量使用可搜索的名称。名称长短应与其作用域大小相对应，若变量或常量可能在代码中多处使用，应赋予其以便于搜索的名称。

- 要点六：取名不要绕弯子。取名要直白，要直截了当，明确就是王道。

- 要点七：类名尽量用名词。类名尽量用名词或名词短语，最好不要是动词。

- 要点八：方法名尽量用动词。方法名尽量用动词或动词短语。

- 要点九：每个概念对应一词，并一以贯之。对于那些会用到你代码的程序员，一以贯之的命名法简直就是天降福音。

- 要点十：通俗易懂。应尽力写出易于理解的变量名，要把代码写得让别人能一目了然，而不必让人去非常费力地去揣摩其含义。

- 要点十一：尽情使用解决方案领域专业术语。尽管去用那些计算机科学领域的专业术语、算法名、模式名、数学术语。

- 要点十二：要添加有意义的语境。需要用有良好命名的类，函数或名称空间来放置名称，给读者提供语境。若没能提供放置的地方，还可以给名称添加前缀。

<br>

Part3 整洁代码的函数书写准则
----------------------------

- 第一原则：短小。若没有特殊情况，最好将单个函数控制在十行以内。

- 第二原则：单一职责。函数应该只做一件事情。只做一件事，做好这件事。

- 第三原则：命名合适且具描述性。长而具有描述性的名称，比短而令人费解的名称好。当然，如果短的名称已经足够说明问题，还是越短越好。

- 第四原则：参数尽可能少。最理想的函数参数形态是零参数，其次是单参数，再次是双参数，应尽量避免三参数及以上参数的函数，有足够的理由才能用三个以上参数。

- 第五原则：尽力避免重复。重复的代码会导致模块的臃肿，整个模块的可读性可能会应该重复的消除而得到提升。

<br>

Part4 整洁代码的格式准则
------------------------

整洁代码的书写格式，可以遵从如下几个原则：

- 第一原则：像报纸一样一目了然。优秀的源文件也要像报纸文章一样，名称应当简单并且一目了然，名称本身应该足够告诉我们是否在正确的模块中。源文件最顶部应该给出高层次概念和算法。细节应该往下渐次展开，直至找到源文件中最底层的函数和细节。

- 第二原则：恰如其分的注释。带有少量注释的整洁而有力的代码，比带有大量注释的零碎而复杂的代码更加优秀。

- 第三原则：合适的单文件行数。尽可能用几百行以内的单文件来构造出出色的系统，因为短文件通常比长文件更易于理解。

- 第四原则：合理地利用空白行。在每个命名空间、类、函数之间，都需用空白行隔开。

- 第五原则：让紧密相关的代码相互靠近。靠近的代码行暗示着他们之间的紧密联系。所以，紧密相关的代码应该相互靠近。

- 第六原则：基于关联的代码分布。

	-   变量的声明应尽可能靠近其使用位置。
	
	-   循环中的控制变量应该在循环语句中声明。
	
	-   短函数中的本地变量应当在函数的顶部声明。
	
	-   对于某些长函数，变量也可以在某代码块的顶部，或在循环之前声明。
	
	-   实体变量应当在类的顶部声明。
	
	-   若某个函数调用了另一个，就应该把它们放到一起，而且调用者应该尽量放到被调用者上面。
	
	-   概念相关的代码应该放到一起。相关性越强，则彼此之间的距离就该越短。

- 第七原则：团队遵从同一套代码规范。一个好的团队应当约定与遵从一套代码规范，并且每个成员都应当采用此风格。


Part5 整洁类的书写准则
----------------------


- 原则一：合理地分布类中的代码。 类中代码的分布顺序大致是：

	>   1. 公有静态常量
	
	>   2. 私有静态变量
	
	>   3. 公有普通变量
	
	>   4. 私有普通变量
	
	>   5. 公共函数
	
	>   6. 私有函数

- 原则二：尽可能地保持类的封装。尽可能使函数或变量保持私有，不对外暴露太多细节。

- 原则三：类应该短小，尽量保持单一权责原则。类或模块应有且只有一条加以修改的理由。

- 原则四：合理提高类的内聚性。我们希望类的内聚性保持在较高的水平。内聚性高，表示类中方法和变量相互依赖，相互结合成一个逻辑整体。

- 原则五：有效地隔离修改。类应该依赖于抽象，而不是依赖于具体细节。尽量对设计解耦，做好系统中的元素的相互隔离，做到更加灵活与可复用。

```

`Content/《游戏编程模式》读书笔记/README.md`:

```md
# 《游戏编程模式》全书内容梗概总结

这是一篇超过万字读书笔记，总结了《游戏编程模式》一书中所有章节与内容的知识梗概。


![](media/1.png)

<br>
<br>


# 目录与说明



《游戏编程模式》一书中总共介绍了19种设计模式，权当目录，现列举如下：

* [零、全书内容思维导图](#00)
* [一、常用GOF设计模式](#01)
	* [1.命令模式](#1)
	* [2.享元模式](#2)
	* [3.观察者模式](#3)
	* [4.原型模式](#4)
	* [5.单例模式](#5)
	* [6.状态模式](#6)
* [二、序列型模式](#02)
	* [7.双缓冲模式](#7)
	* [8.游戏循环模式](#8)
	* [9.更新方法](#9)
* [三、行为型模式](#03)
	* [10.字节码模式](#10)
	* [11.子类沙箱模式](#11)
	* [12.类型对象模式](#12)
* [四、解耦型模式](#04)
	* [13.组件模式](#13)
	* [14.事件队列模式](#14)
	* [15.服务定位器模式](#15) 
* [五、优化型模式](#05)
	* [16.数据局部性模式](#16)
	* [17.脏标识模式](#17)
	* [18.对象池模式](#18)
	* [19.空间分区模式](#19) 
* [六、更多参考与学习资源](#06) 


本文对以上19种模式进行分别进行了总结，对每种模式分以下三个方面进行了介绍：

-   要点

-   使用场合

-   引申与参考

依次介绍完19种模式之后，最终给出了一些更多的参考与学习资源。

以下是全书内容的知识导图：

<br>


<h1 id="01">零、全书内容思维导图</h1>

![](media/2.png)

以下开始正文。
<br>
<br>



<h1 id="01">一、常用GOF设计模式</h1>
这一部分介绍了游戏开发中较为常用的六种GOF设计模式。

<h2 id="1">1. 命令模式 Command Pattern</h2>

命令模式将“请求”封装成对象，以便使用不同的请求、队列或者日志来参数化其他对象，同时支持可撤消的操作。

### 要点

-   将一组行为抽象为对象，这个对象和其他对象一样可以被存储和传递，从而实现行为请求者与行为实现者之间的松耦合，这就是命令模式。

-   命令模式是回调机制的面向对象版本。

-   命令模式的本质是对命令进行封装，将发出命令的责任和执行命令的责任分割开。

-   命令模式的优点有：对类间解耦、可扩展性强、易于命令的组合维护、易于与其他模式结合，而缺点是会导致类的膨胀。

-   命令模式有不少的细分种类，实际使用时应根据当前所需来找到合适的设计方式。

### 使用场合

-   命令模式很适合实现诸如撤消，重做，回放，时间倒流之类的功能。

-   基于命令模式实现录像与回放等功能，也就是执行并解析一系列经过预录制的序列化后的各玩家操作的有序命令集合。

### 引申与参考

-   最终你可能会得到很多不同的命令类。为了更容易实现这些类，定义一个具体的基类，包含一些能定义行为的高层方法，往往会有帮助。可以将命令的主体execute()转到子类沙箱中。

-   对象可以响应命令，或者将命令交给它的从属对象。 如果我们这样实现了，就完成了一个职责链模式。

-   对于等价的实例，可以用享元模式提高内存利用率。

-   命令模式的Unity版本实现：<https://github.com/QianMo/Unity-Design-Pattern/tree/master/Assets/Behavioral%20Patterns/Command%20Pattern>

-   本节内容相关的英文原文：<http://gameprogrammingpatterns.com/command.html>

-   本节内容相关的中文翻译：<http://gpp.tkchu.me/command.html>

<br>


<h2 id="2"> 2. 享元模式 Flyweight Pattern</h2>

享元模式，以共享的方式高效地支持大量的细粒度的对象。通过复用内存中已存在的对象，降低系统创建对象实例的性能消耗。

### 要点

-   享元模式中有两种状态。内蕴状态（Internal State）和外蕴状态（External
    State）。

    -   内蕴状态，是不会随环境改变而改变的，是存储在享元对象内部的状态信息，因此内蕴状态是可以共享的。对任何一个享元对象而言，内蕴状态的值是完全相同的。

    -   外蕴状态，是会随着环境的改变而改变的。因此是不可共享的状态，对于不同的享元对象而言，它的值可能是不同的。

-   享元模式通过共享内蕴状态，区分外蕴状态，有效隔离系统中的变化部分和不变部分。

### 使用场合

在以下情况都成立时，适合使用享元模式：

1.  当系统中某个对象类型的实例较多的时候。

2.  由于使用了大量的对象，造成了很大的存储开销。

3.  对象的大多数状态都可变为外蕴状态。

4.  在系统设计中，对象实例进行分类后，发现真正有区别的分类很少的时候。

### 引申与参考

-   为了返回一个已经创建的享元，需要和那些已经实例化的对象建立联系，我们可以配合对象池来进行操作。

-   当使用状态模式时，很多时候可以配合使用享元模式，在不同的状态机上使用相同的对象实例。

-   享元模式的Unity版本实现：<https://github.com/QianMo/Unity-Design-Pattern/tree/master/Assets/Structural%20Patterns/Flyweight%20Pattern>

-   本节内容相关的英文原文：<http://gameprogrammingpatterns.com/flyweight.html>

-   本节内容相关的中文翻译：<http://gpp.tkchu.me/flyweight.html>

<br>

<h2 id="3">3. 观察者模式 Observer Pattern</h2>
观察者模式定义了对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。

### 要点

-   观察者模式定义了对象间的一种一对多的依赖关系，当一个对象的状态发生改变时，所有依赖于它的对象都得到通知并被自动更新。

-   我们知道，将一个系统分割成一个一些类相互协作的类有一个不好的副作用，那就是需要维护相关对象间的一致性。我们不希望为了维持一致性而使各类紧密耦合，这样会给维护、扩展和重用都带来不便。观察者就是解决这类的耦合关系的。

-   目前广泛使用的MVC模式，究其根本，是基于观察者模式的。

-   观察者模式应用广泛，Java甚至将其放到了核心库之中（java.util.Observer），而C\#直接将其嵌入了语法（event关键字）中。

### 使用场合

-   当一个抽象模式有两个方面，其中一个方面依赖于另一个方面，需要将这两个方面分别封装到独立的对象中，彼此独立地改变和复用的时候。

-   当一个系统中一个对象的改变需要同时改变其他对象内容，但是又不知道待改变的对象到底有多少个的时候。

-   当一个对象的改变必须通知其他对象作出相应的变化，但是不能确定通知的对象是谁的时候。

### 引申与参考

-   观察者模式的Unity版本实现：<https://github.com/QianMo/Unity-Design-Pattern/tree/master/Assets/Behavioral%20Patterns/Observer%20Pattern>

-   本节内容相关的英文原文：<http://gameprogrammingpatterns.com/observer.html>

-   本节内容相关的中文翻译：<http://gpp.tkchu.me/observer.html>

<br>


<h2 id="4">4.原型模式 Prototype Pattern</h2>

用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。

### 要点

-   原型模式：用原型实例指定创建对象的种类，并且通过拷贝这些原型创建新的对象。

-   原型模式是一种比较简单的模式，也非常容易理解，实现一个接口，重写一个方法即完成了原型模式。在实际应用中，原型模式很少单独出现。经常与其他模式混用，他的原型类Prototype也常用抽象类来替代。

-   使用原型模式拷贝对象时，需注意浅拷贝与深拷贝的区别。

-   原型模式可以结合JSON等数据交换格式，为数据模型构建原型。

### 使用场合

-   产生对象过程比较复杂，初始化需要许多资源时。

-   希望框架原型和产生对象分开时。

-   同一个对象可能会供其他调用者同时调用访问时。

### 参考与引申

-   原型模式的Unity版本实现：<https://github.com/QianMo/Unity-Design-Pattern/tree/master/Assets/Creational%20Patterns/Prototype%20Pattern>

-   本节内容相关的英文原文：<http://gameprogrammingpatterns.com/prototype.html>

-   本节内容相关的中文翻译： <http://gpp.tkchu.me/prototype.html>

<br>


<h2 id="5">5.单例模式 Singleton Pattern</h2>

保证一个类只有一个实例，并且提供了访问该实例的全局访问点。

### 要点

-   单例模式因其方便的特性，在开发过程中的运用很多。

-   单例模式有两个要点，保证一个类只有一个实例，并提供访问该实例的全局访问点。

-   尽量少用单例模式。单例模式作为一个全局的变量，有很多全局的变量的弊病。它会使代码更难理解，更加耦合，并且对并行不太友好。

### 使用场合

-   当在系统中某个特定的类对象实例只需要有唯一一个的时候。

-   单例模式要尽量少用，无节制的使用会带来各种弊病。
-   证实例是单一的，可以简单的使用静态类。还可以使用静态标识位，在运行时检测是不是只有一个实例被创建了。

### 参考与引申

-   下文中介绍的子类沙箱模式通过对状态的分享，给实例以类的访问权限而无需让其全局可用。

-   下文中介绍的服务定位器模式不但让一个对象全局可用，还可以带来设置对象的一些灵活性。

-   单例模式的Unity版本实现：<https://github.com/QianMo/Unity-Design-Pattern/tree/master/Assets/Creational%20Patterns/Singleton%20Pattern>

-   本节内容相关的英文原文：<http://gameprogrammingpatterns.com/singleton.html>

-   本节内容相关的中文翻译：<http://gpp.tkchu.me/singleton.html>

<br>

<h2 id="6">6.状态模式 State Pattern</h2>

允许对象在当内部状态改变时改变其行为，就好像此对象改变了自己的类一样。

### 要点

-   状态模式用来解决当控制一个对象状态转换的条件表达式过于复杂的情况，它把状态的判断逻辑转移到表示不同的一系列类当中，可以把复杂的逻辑判断简单化。

-   状态模式的实现分为三个要点：

    -   为状态定义一个接口。

    -   为每个状态定义一个类。

    -   恰当地进行状态委托。

-   通常来说，状态模式中状态对象的存放有两种实现存放的思路：

    -   静态状态。初始化时把所有可能的状态都new好，状态切换时通过赋值改变当前的状态。

    -   实例化状态。每次切换状态时动态new出新的状态。

### 使用场合

在游戏开发过程中，涉及到复杂的状态切换时，可以运用状态模式以及状态机来高效地完成任务。

有限状态机的实现方式，有两种可以选择：

-   用枚举配合switch case语句。

-   用多态与虚函数（即状态模式）。

有限状态机在以下情况成立时可以使用：

-   有一个行为基于一些内在状态的实体。

-   状态可以被严格的分割为相对较少的不相干项目。

-   实体可以响应一系列输入或事件。

### 参考与引申

-   Hierarchical State Machines分层状态机：<http://www.eventhelix.com/RealtimeMantra/HierarchicalStateMachine.htm#.WAHM3Y996Uk>

-   Pushdown Automata下推自动机：<https://en.wikipedia.org/wiki/Pushdown_automaton>

-   状态模式的Unity版本实现：<https://github.com/QianMo/Unity-Design-Pattern/tree/master/Assets/Behavioral%20Patterns/State%20Pattern>

-   本节内容相关的英文原文：<http://gameprogrammingpatterns.com/state.html>

-   本节内容相关的中文翻译：<http://gpp.tkchu.me/state.html>

<br>

<h1 id="02">二、序列型模式 Sequencing Patterns</h1>

本章的三种模式都是游戏开发中的常客：

-   游戏循环是游戏运行的主心骨。

-   游戏对象通过更新方法来进行每帧的更新。

-   我们可以用双缓冲模式存储快照，来隐藏计算机的顺序执行，从而使得游戏世界能够同步更新。


<h2 id="7">7.双缓冲模式 Double Buffer</h2>

双缓冲模式，使用序列操作来模拟瞬间或者同时发生的事情。

### 要点

-   一个双缓冲类封装了一个缓冲：一段可改变的状态。这个缓冲被增量的修改，但我们想要外部的代码将其视为单一的元素修改。为了实现这点，双缓冲类需保存两个缓冲的实例：下一缓存和当前缓存。

-   当信息从缓冲区中读取，我们总是去读取当前的缓冲区。当信息需要写到缓存，我们总是在下一缓冲区上操作。当改变完成后，一个交换操作会立刻将当前缓冲区和下一缓冲区交换，这样新缓冲区就是公共可见的了。旧的缓冲区则成为了下一个重用的缓冲区。

-   双缓冲模式常用来做帧缓冲区交换。

### 使用场合

双缓冲模式是那种你需要它时自然会想起来的模式。以下情况都满足时，使用这个模式很合适：

-   我们需要维护一些被增量修改的状态

-   在修改过程中，状态可能会被外部请求。

-   我们想要防止请求状态的外部代码知道内部是如何工作的。

-   我们想要读取状态，而且不想在修改的时候等待。

### 引申与参考

-   我们几乎可以在任何一个图形API中找到双缓冲模式的应用。如OpenGl中的swapBuffers() 函数, Direct3D中的“swap chains”,微软XNA框架的 endDraw() 方法。

-   本节内容相关的英文原文：<http://gameprogrammingpatterns.com/double-buffer.html>

-   本节内容相关的中文翻译： <http://gpp.tkchu.me/double-buffer.html>

<br>

<h2 id="8">8.游戏循环模式 Game Loop</h2>

游戏循环模式，实现游戏运行过程中对用户输入处理和时间处理的解耦。

### 要点

-   游戏循环模式：游戏循环在游戏过程中持续运转。每循环一次，它非阻塞地处理用户的输入，更新游戏状态，并渲染游戏。它跟踪流逝的时间并控制游戏的速率。

-   游戏循环将游戏的处理过程和玩家输入解耦，和处理器速度解耦，实现用户输入和处理器速度在游戏行进时间上的分离。

-   游戏循环也许需要与平台的事件循环相协调。如果在操作系统的高层或有图形UI和内建事件循环的平台上构建游戏，那就有了两个应用循环在同时运作，需要对他们进行相应的协调。

### 使用场合

任何游戏或游戏引擎都拥有自己的游戏循环，因为游戏循环是游戏运行的主心骨。

### 引申与参考

-   讲述游戏循环模式的一篇经典文章是来自Glenn Fiedler的“Fix Your Timestep“。<http://gafferongames.com/game-physics/fix-your-timestep/>

-   Witters的文章 game loops 也值得一看。<http://www.koonsolo.com/news/dewitters-gameloop/>

-   Unity的框架具有一个复杂的游戏循环，这里有一个对其很详尽的阐述。<https://docs.unity3d.com/Manual/ExecutionOrder.html>

-   本节内容相关的英文原文：<http://gameprogrammingpatterns.com/game-loop.html>

-   本节内容相关的中文翻译：<http://gpp.tkchu.me/game-loop.html>

<br>


<h2 id="9">9.更新方法 Update Method</h2>

更新方法，通过每次处理一帧的行为来模拟一系列独立对象。

### 要点

-   更新方法模式：在游戏中保持游戏对象的集合。每个对象实现一个更新方法，以处理对象在一帧内的行为。每一帧中，游戏循环对集合中的每一个对象进行更新。

-   当离开每帧时，我们也许需要存储下状态，以备不时之需。

### 使用场合

更新方法和游戏循环模式一般一起使用。更新方法适应以下情况：

-   游戏中有很多对象或系统需要同时运行。

-   每个对象的行为都与其他的大部分独立。

-   游戏中的对象需要随时间模拟。

### 引申与参考

-   更新方法模式，以及游戏循环模式和组件模式，是构建游戏引擎核心的铁三角。

-   Unity引擎在多个类中使用了这个模式，包括MonoBehaviour。

-   微软的XNA框架在 Game 和 GameComponent 类中使用了这个模式。

-   当你关注在每帧中更新实体或组件的缓存性能时，数据局部性模式可以帮上忙。

-   本节内容相关的英文原文：<http://gameprogrammingpatterns.com/update-method.html>

-   本节内容相关的中文翻译：<http://gpp.tkchu.me/update-method.html>

<br>

<h1 id="03">三、行为型模式 Behavioral Patterns</h1>

本章的模式可以帮助我们快速定义和完善多种多样的行为：

-   类型对象模式定义行为的类别而无需完成真正的类。

-   子类沙盒模式定义各种行为的安全原语。

-   字节码模式将行为从代码中拖出，放入数据。

<br>

<h2 id="10">10. 字节码模式 Bytecode</h2>

字节码模式，将行为编码为虚拟机器上的指令，来赋予其数据的灵活性。从而让数据易于修改，易于加载，并与其他可执行部分相隔离。

### 要点

-   字节码模式：指令集定义了可执行的底层操作。 一系列的指令被编码为字节序列。虚拟机使用中间值堆栈 依次执行这些指令。通过组合指令，可以定义复杂的高层行为。

-   可以理解为项目中的转表工具，将excel中的数据转为二进制数据，并读取到工程中，如在项目中使用google protobuf或json。

-   字节码类似GOF的解释器模式，这两种方式都能让我们将数据与行为相组合。其实很多时候都是两者一起使用。用来构造字节码的工具会有内部的对象树，而为了编译到字节码，我们需要递归回溯整棵树，就像用解释器模式去解释它一样。唯一的不同在于，并不是立即执行一段行为，而是生成整个字节码再执行。

### 使用场合

这是GPP一书中最复杂的模式，不能轻易的加入到游戏中。
当我们需要定义很多行为，而游戏实现语言因为以下原因不能很好地完成任务时，就可以使用字节码模式：

-   这些行为过于底层，繁琐易错。

-   这些行为遍历起来很缓慢，导致编译时间长。

-   这些行为太受依赖。如果想保证行为不会破坏游戏，你需要将其与代码的其他部分隔开。

如果是上述的这些情况，就比较适合使用字节码模式。

但需要注意，字节码比本地代码慢，所以最好不要用于引擎对性能敏感的部分。

### 引申与参考

-   Lua的内部实现就是一个非常紧凑的，基于寄存器的字节码虚拟机。

-   Kismet是个可视化脚本编辑工具，应用于Unreal引擎的编辑器UnrealEd。（<https://udn.epicgames.com/Three/KismetHome.html>）

-   本节内容相关的英文原文：<http://gameprogrammingpatterns.com/bytecode.html>

-   本节内容相关的中文翻译：<http://gpp.tkchu.me/bytecode.html>

<br>

<h2 id="11">11. 子类沙箱模式 Subclass Sandbox</h2>

用一系列由基类提供的操作定义子类中的行为。

### 要点

子类沙箱模式：基类定义抽象的沙箱方法和几个提供操作的实现方法，将他们设为protected，表明它们只为子类所使用。每个推导出的沙箱子类用提供的操作实现了沙箱方法。

### 使用场合

子类沙箱模式是潜伏在编程日常中简单常用的模式，哪怕是在游戏之外的地方。
如果有一个非虚的protected方法，你可能早已在用类似的技术了。

沙箱方法在以下情况适用：

-   你有一个能推导很多子类的基类。

-   基类可以提供子类需要的所有操作。

-   在子类中有行为重复，你想要更容易的在它们间分享代码。

-   你想要最小化子类和程序的其他部分的耦合。

### 引申与参考

-   当你使用上文中介绍到的更新模式时，你的更新函数通常也是沙箱方法。

-   这个模式与GOF模板方法正好相反。两种模式中，都使用了一系列受限操作实现方法。使用子类沙箱时，方法在推导类中，受限操作在基类中。使用模板方法时，基类有方法，而受限操作在推导类中。

-   你也可以认为这个模式是GOF外观模式的变形。外观模式将一系列不同系统藏在简化的API后。使用子类沙箱，基类起到了在子类前隐藏整个游戏引擎的作用。

-   子类沙箱模式的Unity版本实现：<https://github.com/QianMo/Unity-Design-Pattern/tree/master/Assets/Game%20Programming%20Patterns/SubclassSandbox%20Pattern>

-   本节内容相关的英文原文：<http://gameprogrammingpatterns.com/subclass-sandbox.html>

-   本节内容相关的中文翻译：<http://gpp.tkchu.me/subclass-sandbox.html>

<br>

<h2 id="12">12. 类型对象模式 Type Object</h2>

创造一个类A来允许灵活的创造新的类，而类A的每个实例都代表了不同类型的对象。

### 要点

-   类型对象模式：定义类型对象类与有类型的对象类。每个类型对象实例代表一种不同的逻辑类型。每种有类型的对象保存描述它类型的对类型对象的引用。

-   类型对象的基本思想就是给基类一个品种类（breed类），而不是用一些子类继承自这个基类。所以我们在做种类区分的时候就可以只有两个类，怪物类monster和品种类breed，而不是monster，dragon，troll等一堆类。所以在此种情况下，游戏中的每个怪物都是怪物类的一个实例，而实例中的breed类包含了所有同种类型怪物共享的信息。

### 使用场合

这个模式在任何你需要定义不同“种”事物，使用不当会让你的系统过于僵硬。而下面两者之一成立时，就非常适合使用：

-   不知道后续还需什么新类型。（举个例子，如果你的游戏需要支持增量更新，让用户下载后续新包含进来的怪物品种）

-   想要不改变代码或不重新编译就能修改或添加新类型。

### 引申与参考

-   这个模式引出的进阶问题是如何在不同对象之间共享数据。以不同的方式解决同一个问题的是GOF设计模式中的原型模式（prototype pattern）。

-   类型对象是GOF设计模式中享元模式的亲兄弟。两者都让你在实例间分享代码。使用享元，意图是节约内存，而分享的数据也许不代表任何概念上对象的“类型”。而使用类型对象模式，焦点在组织性和灵活性。

-   这个模式和GOF设计模式中状态模式有很多相似之处，两者都是委托了对象的部分定义给另外一个对象。

-   本节内容相关的英文原文：<http://gameprogrammingpatterns.com/type-object.html>

-   本节内容相关的中文翻译：<http://gpp.tkchu.me/type-object.html>

<br>


<h1 id="04">四、解耦型模式 Decoupling Patterns</h1>

这一部分的三种模式，专注于解耦：

-   组件模式将一个实体拆成多个，解耦不同的领域。

-   事件队列解耦了两个互相通信的事物，稳定而且实时。

-   服务定位器让代码使用服务而无需绑定到提供服务的代码上。

<br>

<h2 id="13">13. 组件模式 Component</h2>

允许单一的实体跨越多个领域，无需这些领域彼此耦合。

### 要点

-   组件模式：在单一实体跨越了多个领域时，为了保持领域之间相互解耦，可以将每部分代码放入各自的组件类中，将实体简化为组件的容器。

-   Unity引擎在设计中频繁使用了这种设计方法，从而让其易于使用。

### 使用场合

组件通常在定义游戏实体的核心部分中使用，当然，它们在其他地方也适用。这个模式在如下情况下可以很好的适用：

-   有一个涉及了多个领域的类，而你想保持这些领域互相隔离。

-   一个类正在变大而且越来越难以使用。

-   想要能定义一系列分享不同能力的类，但是使用接口不足以得到足够的重用部分。

### 引申与参考

-   Unity核心架构中GameObject类完全根据此模式来进行设计。

-   这种模式与GOF设计模式中的策略模式类似。两种模式都是将对象的行为取出，委派到一个单独的从属对象中。两者的不同点在于：

-   策略模式中分离出的策略对象通常是无状态的——它封装的是算法，而不是数据。策略模式定义了对象的行为，而不是该对象是什么。

-   而组件模式就更加复杂。组件经常保存了对象的状态，这有助于确定其真正的身份。但是，其界限往往很模糊。有些情况下组件也许根本没有任何状态。在这种情况下，你可以在不同的容器对象中使用相同的组件实例。这样看来，它的行为确实更像一种策略。

-   本节内容相关的英文原文：<http://gameprogrammingpatterns.com/component.html>

-   本节内容相关的中文翻译：<http://gpp.tkchu.me/component.html>

<br>

<h2 id="14">14. 事件队列模式 Event Queue</h2>

事件队列模式，对消息或事件的发送与处理进行时间上的解耦。

### 要点

-   事件队列：在先入先出的队列中存储一系列通知或请求。发送通知时，将请求放入队列并返回。处理请求的系统在稍晚些的时候从队列中获取请求并进行处理。这样就解耦了发送者和接收者，既静态又及时。

-   事件队列很复杂，会对游戏架构引起广泛影响。中心事件队列是一个全局变量。这个模式的通常方法是一个大的交换站，游戏中的每个部分都能将消息送过这里。

-   事件队列是基础架构中很强大的存在，但有些时候强大并不代表好。事件队列模式将状态包裹在协议中，但是它还是全局的，仍然存在全局变量引发的一系列危险。

### 使用场合

-   如果你只是想解耦接收者和发送者，像观察者模式和命令模式都可以用较小的复杂度来进行处理。在需要解耦某些实时的内容时才建议使用事件队列。

-   不妨用推和拉来的情形来考虑。有一块代码A需要另一块代码B去做些事情。对A自然的处理方式是将请求推给B。同时，对B自然的处理方式是在B方便时将请求拉入。当一端有推模型另一端有拉模型时，你就需要在它们间放一个缓冲的区域。这就是队列比简单的解耦模式多出来的那一部分。队列给了代码对拉取的控制权——接收者可以延迟处理，合并或者忽视请求。发送者能做的就是向队列发送请求然后就完事了，并不能决定什么时候发送的请求会受到处理。

-   而当发送者需要一些回复反馈时，队列模式就不是一个好的选择。

### 引申与参考

-   很大程度上， 事件队列模式就是广为人知的GOF设计模式中观察者模式的异步实现。

-   就像其他很多模式一样，事件队列有很多别名。 其中一个是“消息队列”。消息队列通常指代一个更高层次的实现。可以这样理解，事件队列在应用中进行交流，而消息队列通常在应用间进行交流。另一个别名是“发布/提交”，有时被缩写为“pubsub”，这个别名通常指代更大的分布式系统中的应用。

-   在有限状态机与状态模式中，往往需要一个输入流。如果想要异步响应，可以考虑用队列模式来存储它们。

-   Go语言内建的“Channel”机制，其本质上就是事件队列。

-   本节内容相关的英文原文：<http://gameprogrammingpatterns.com/event-queue.html>

-   本节内容相关的中文翻译：<http://gpp.tkchu.me/event-queue.html>

<br>

<h2 id="15">15. 服务定位模式 Service Locator</h2>

提供服务的全局接入点，而不必让用户和实现它的具体类耦合。

### 要点

-   服务定位模式：服务类定义了一堆操作的抽象接口。具体的服务提供者实现这个接口。 分离的服务定位器提供了通过查询合适的提供者，获取服务的方法，同时隐藏了提供者的具体细节和需要定位它的进程。

-   一般通过使用单例或者静态类来实现服务定位模式，提供服务的全局接入点。

-   服务定位模式可以看做是更加灵活，更加可配置的单例模式。如果用得好，它能以很小的运行时开销，换取很大的灵活性。相反，如果用得不好，它会带来单例模式的所有缺点以及更多的运行时开销。

-   使用服务定位器的核心难点是它将依赖，也就是两块代码之间的一点耦合，推迟到运行时再连接。这有了更大的灵活度，但是代价是更难在阅读代码时理解其依赖的是什么。

### 使用场合

-   服务定位模式在很多方面是单例模式的亲兄弟，在应用前应该考虑看看哪个更适合你的需求。

-   让大量内容在程序的各处都能被访问时，就是在制造混乱。对何时使用服务定位模式的最简单的建议就是：尽量少用。

-   与其使用全局机制让某些代码直接接触到它，不妨先考虑将对象传过来。因为这样可以明显地保持解耦，而且可以满足我们大部分的需求。当然，有时候不方便手动传入对象，也可以使用单例的方式。

### 引申与参考

-   Unity引擎在它的GetComponent()方法中使用了这个模式，协助组件模式的使用，方便随时获取到指定的组件。

-   Microsoft的 XNA框架将这个模式内嵌到它的核心类Game中。每个实例有一个GameServices 对象，能够用来注册和定位任何类型的服务。

-   本节内容相关的英文原文：<http://gameprogrammingpatterns.com/service-locator.html>

-   本节内容相关的中文翻译：<http://gpp.tkchu.me/service-locator.html>

<br>


<h1 id="05">五、优化型模式 Optimization Patterns</h1>

这一部分，描述了几个优化和加速游戏的中间层模式:

-   数据局部性介绍了计算机的存储层次以及如何使用其以获得优势。

-   脏标识帮我们避开不必要的计算。

-   对象池帮我们避开不必要的分配。

-   空间分区加速了虚拟世界和其中内容的空间布局。


<h2 id="16">16. 数据局部性模式 Data Locality</h2>

合理组织数据，充分使用CPU的缓存来加速内存读取。

### 要点

现代的CPU有缓存来加速内存读取，其可以更快地读取最近访问过的内存毗邻的内存。
基于这一点，我们通过保证处理的数据排列在连续内存上，以提高内存局部性，从而提高性能。

为了保证数据局部性，就要避免的缓存不命中。也许你需要牺牲一些宝贵的抽象。你越围绕数据局部性设计程序，就越放弃继承、接口和它们带来的好处。没有银弹，只有权衡。

### 使用场合

-   使用数据局部性的第一准则是在遇到性能问题时使用。不要将其应用在代码库不经常使用的角落上。优化代码后其结果往往更加复杂，更加缺乏灵活性。

-   就本模式而言，还得确认你的性能问题确实由缓存不命中而引发的。如果代码是因为其他原因而缓慢，这个模式自然就不会有帮助。

-   简单的性能评估方法是手动添加指令，用计时器检查代码中两点间消耗的时间。而为了找到糟糕的缓存使用情况，知道缓存不命中有多少发生，又是在哪里发生的，则需要使用更加复杂的工具 ——profilers。

-   组件模式是为缓存优化的最常见例子。而任何需要接触很多数据的关键代码，考虑数据局部性都是很重要的。

### 引申与参考

-   Tony Albrecht的[《Pitfalls of Object-Oriented Programming》](http://harmful.cat-v.org/software/OO_programming/_pdf/Pitfalls_of_Object_Oriented_Programming_GCAP_09.pdf)[PDF]是传播广泛的内存友好设计游戏指南。

-   Noel Llopis一篇博客<http://gamesfromwithin.com/data-oriented-design>，也分析了内存友好的游戏设计。

-   本节内容相关的英文原文：<http://gameprogrammingpatterns.com/data-locality.html>

-   本节内容相关的中文翻译： <http://gpp.tkchu.me/data-locality.html>

<br>

<h2 id="17">17. 脏标识模式 Dirty Flag</h2>

将工作延期至需要其结果时才去执行，以避免不必要的工作。

### 要点

-   脏标记，就是用来表示被标记的内容是否有被修改过的一个标志位。

-   脏标识模式：考虑情况，当前有一组原始数据随着时间变化而改变。由这些原始数据计算出目标数据需要耗费一定的计算量。这个时候，可以用一个脏标识，来追踪目前的原始数据是否与之前的原始数据保持一致，而此脏标识会在被标记的原始数据改变时改变。那么，若这个标记没被改变，就可以使用之前缓存的目标数据，不用再重复计算。反之，若此标记已经改变，则需用新的原始数据计算目标数据。

### 使用场合

-   就像其他优化模式一样，此模式会增加代码复杂度。只在有足够大的性能问题时，再考虑使用这一模式。

-   脏标记在这两种情况下适用：

    -   当前任务有昂贵的计算开销

    -   当前任务昂贵的同步开销。

>   若满足这两者之一，也就是两者从原始数据转换到目标数据会消耗很多时间，都可以考虑使用脏标记模式来节省开销。

-   若原始数据的变化速度远高于目标数据的使用速度，此时数据会因为随后的修改而失效，此时就不适合使用脏标记模式。

### 引申与参考

-   脏标记模式在游戏外的领域也是常见的，比如像Angular这种browser-side web框架，其利用赃标记来跟踪浏览器中变动的数据以及需要提交到服务端的数据。

-   本节内容相关的英文原文：<http://gameprogrammingpatterns.com/dirty-flag.html>

-   本节内容相关的中文翻译： <http://gpp.tkchu.me/dirty-flag.html>

<br>

<h2 id="18">18. 对象池模式 Object Pool</h2>

放弃单独地分配和释放对象，从固定的池中重用对象，以提高性能和内存使用率

### 要点

-   对象池模式：定义一个包含了一组可重用对象的对象池。其中每个可重用对象都支持查询“使用中”状态，说明它是不是“正在使用”。对象池被初始化时，就创建了整个对象集合（通常使用一次连续的分配），然后初始化所有对象到“不在使用中”状态。

-   当我们需要新对象时，就从对象池中获取。从对象池取到一个可用对象，初始化为“使用中”然后返回给我们。当不再需要某对象时，将其设置回“不在使用中”状态。通过这种方式，便可以轻易地创建和销毁对象，而不必每次都分配内存或其他资源。

### 使用场合

-   这个模式广泛使用在可见事物上，比如游戏物体和特效。但是它也可在不那么视觉化的数据结构上使用，比如正在播放的声音。

-   满足以下情况可以使用对象池：

    -   需要频繁创建和销毁对象。

    -   对象大小相仿。

    -   在堆上分配对象缓慢或者会导致内存碎片。

    -   每个对象都封装了像数据库或者网络连接这样很昂贵又可以重用的资源。

#### 引申与参考

-   对象池模式与GOF设计模式中享元模式类似。两者都控制了一系列可重用的对象。不同在于重用的含义。

    -   享元对象分享实例间同时拥有的相同部分。享元模式在不同上下文中使用相同对象避免了重复内存使用。

    -   对象池中的对象也被重用了，但是是在不同的时间点上被重用的。重用在对象池中意味着对象在原先的对象用完之后再分配内存。对象池的对象不会在它的生命周期中与其他对象共享数据。

-   将内存中同样类型的对象进行整合，能确保在遍历对象时CPU缓存是满载的。这便是数据局部性模式中介绍的内容。

-   本节内容相关的英文原文：<http://gameprogrammingpatterns.com/object-pool.html>

-   本节内容相关的中文翻译： <http://gpp.tkchu.me/object-pool.html>



<h2 id="19">19. 空间分区模式Spatial Partition</h2>

将对象存储在基于位置组织的数据结构中，来有效的定位对象。

### 要点

-   对于一系列对象，每个对象都有空间上的位置。将它们存储在根据位置组织对象的空间数据结构中，让我们有效查询在某处或者附近的对象。当对象的位置改变时，更新空间数据结构，这样它可以继续找到对象。

-   最简单的空间分区：固定网格。想象某即时战略类游戏，一改在单独的数组中存储我们的游戏对象的常规思维，我们将它们存到网格的格子中。每个格子存储一组单位，它们的位置在格子的边界内部。当我们处理战斗时，一般只需考虑在同一格子或相邻格子中的单位，而不是将每个游戏中的单位与其他所有单位比较，这样就大大节约了计算量。

### 使用场合

-   空间分区模式在需要大量存储活跃、移动的游戏物体，和静态的美术模型的游戏中比较常用。因为复杂的游戏中不同的内容有不同的空间划分。

-   这个模式的基本适用场景是你有一系列有位置的对象，当做了大量通过位置寻找对象的查询而导致性能下降的时候。

-   空间分区的存在是为了将O(n)或者O(n²) 的操作降到更加可控的数量级。你拥有的对象越多，此模式就越好用。相反的，如果n足够小，也许就不需要使用此模式。

### 引申与参考

-	了解了空间分区模式，下一步应该是学习一下常见的结构。常见的有：

	-   [Grid](http://en.wikipedia.org/wiki/Grid_(spatial_index))
	
	-   [Quadtree](http://en.wikipedia.org/wiki/Quad_tree)
	
	-   [BSP](http://en.wikipedia.org/wiki/Binary_space_partitioning)
	
	-   [k-d tree](http://en.wikipedia.org/wiki/Kd-tree)
	
	-   [Bounding volume hierarchy](http://en.wikipedia.org/wiki/Bounding_volume_hierarchy)

-	每种空间划分数据结构基本上都是将一维数据结构扩展成更高维度的数据结构。知道它的直系子孙有助于分辨它是否适合解决当前的问题：

	-   网格其实是持续的[桶排序](http://en.wikipedia.org/wiki/Bucket_sort)。
	
	-   BSP，k-d tree，和层次包围盒是[线性搜索树](http://en.wikipedia.org/wiki/Binary_search_tree)。
	
	-   四叉树和八叉树是[多叉树](http://en.wikipedia.org/wiki/Trie)。

-	本节内容相关的英文原文：<http://gameprogrammingpatterns.com/spatial-partition.html>

-	本节内容相关的中文翻译： <http://gpp.tkchu.me/spatial-partition.html>


<h1 id="06">六、更多参考与学习资源</h1>

[1] 本书的英文Web原版目录：

<http://gameprogrammingpatterns.com/contents.html>

[2] 本书的中文翻译web版目录：<http://gpp.tkchu.me/>

[3] <https://www.youtube.com/playlist?list=PLF206E906175C7E07>

[4] <https://github.com/Naphier/unity-design-patterns>

[5] <http://www.dofactory.com/net/design-patterns>

[6] <https://sourcemaking.com/design_patterns>

[7] 《设计模式:可复用面向对象软件的基础》

```

`Content/在“绝世武功的目录”RTR4中译版出版前，先奉上“绝世武功秘籍的本体”/README.md`:

```md

<br>

本文的知乎专栏版本：https://zhuanlan.zhihu.com/p/418196347



![](media/rtr4.jpg)



本文提供了图形学全网学习资料的“半壁江山”——《Real-Time Rendering 4th》2000多份参考文献合集的开源Github Repo地址，以及更新了RTR4中译版的预期出版时间。


<br>



# 引言


“在游戏开发、实时渲染以及计算机图形学领域，《Real-Time Rendering》系列书籍一直备受推崇。有人说，它是实时渲染的圣经。也有人说，它是绝世武功的目录。”

众所周知，《Real-Time Rendering》之所以是“绝世武功的目录”，除了其精炼、综述式的行文方式，百科大全般的知识体系广度之外，主要在于其引用的丰富而事无巨细的参考文献。这些包含了详细技术细节的参考文献，才是“绝世武功秘籍的本体”所在。

![](media/b6280fd2f691a81f61489bc03efa2eff_.jpg)

《Real-Time Rendering》系列全家福（图片来自RTR系列作者之一Tomas Akenine-Möller）


时间来到2018年，《Real-Time Rendering》系列的第四版《Real-Time Rendering 4th》的参考文献的数量已经超过了2000条之多。这些参考文献散落于互联网各地，如果你有查阅过RTR4官网上放出的参考文献的链接（Real-Time Rendering Bibliography - 4th Edition），你会发现其中有不少链接已经失效。如果没有做及时的备份，且对应的文献没有其他提供源，则这些文献会面临着永久失传的风险。

所幸，本人在阅读以及翻译《Real-Time Rendering 4th》期间，花了不少业余时间，几乎详细地完全收集整理了《Real-Time Rendering 4th》2000多条的参考文献，将不少已经失效绝版的参考文献，提前备份保存了下来，构成了具有收藏价值的“绝世武功秘籍的本体”—— RTR4 2000多篇参考文献的典藏合集。

这2000多篇文献与paper，包含了大量近年来SIGGRAPH，GDC等顶会与行业盛会的核心技术paper与技术分享材料，可谓是图形学全网学习资料的“半壁江山”。

![](media/4f4aa77da8c51387919325924faf7ed5.png)


孟子有云，“独乐乐不如众乐乐”。

在这篇文章中，本人将个人收集整理的《Real-Time Rendering 4th》2000多条参考文献，即大家熟知的游戏开发与图形学业界“绝世武功秘籍的本体”，以GitHub开源的形式分享给每一位热爱游戏开发与图形学的朋友们，助力大家更好的学习和研究图形学知识，也希望能对游戏开发与图形学业界的蓬勃发展有所帮助。




<br>



#  RTR4参考文献典藏合集下载


首先，直接放出“绝世武功秘籍的本体”, 《Real-Time Rendering 4th》参考文献合集典藏的Github Repo地址:



​github.com/QianMo/Real-Time-Rendering-4th-Bibliography-Collection

以及部分内容的预览：

![](media/RTR4.gif)


这份RTR4参考文献典藏合集的特点：

几乎完全收集整理了RTR4 26章以及附录章节总计2000多项参考文献的全部内容。
其中收录了部分用常规方式无法获取的，几乎已经全网绝版的珍稀资料。
已包含《Real-Time Rendering 4th》所引用的部分IEEE，ACM Digital Library等付费文献库中的文献。
每条文献已按序号进行清晰地排序和分类，方便快捷地进行检索查阅。
每条文献都按照发表年份，以及发表的媒介对文件名进行标注，以方便快捷的辨识文献年份与参考价值。
已进行了较为完善的文件尺寸精简，将所有单个文件都控制于100M以内，方便更快地下载与本地存储。
已按照原书正文、补充章节第25章、补充章节第26章、附录四个主要部分进行文献的分类，便于查阅。
以下是《Real-Time Rendering 4th》参考文献典藏版的文件构成以及内容统计：


![](media/01ff59e67675643568627bddaf5df0b3.png)


一些说明：

互联网的记忆有时十分短暂。随着时间的流逝，越来越多的资料的原始链接会失效。而这个Github Repo会作为一个图形学系列资料留存和备份的大本营。
还有极个别文献还未在此Github Repo中收录，也欢迎大家的Pull Request。
建议大家下载后离线查阅，当然，Github对pdf等文件也有在线预览功能，也可以方便地进行在线浏览。
RTR4的行文有一个非常地道的地方，那便是除了第1章和第24之外，每章都提供了“延伸阅读与参考资料 Further Reading and Resources”，如果你希望在某一细分领域专研得比RTR4的某章节正文所讲述的内容更加深入，那这些被重点提名的文献和书籍，将是绝佳的进阶学习材料。对此，此Github Repo也额外分章节专门收集整理了RTR4每章结尾的“延伸阅读与参考资料 Further Reading and Resources”中的书籍和文献，方便大家对RTR4每章的进阶内容进行更深入的学习与研究。具体可见链接：

https://github.com/QianMo/Real-Time-Rendering-4th-Bibliography-Collection/tree/main/Further%20Reading



这一节末尾，为方便大家阅读，这里再一次贴出《Real-Time Rendering 4th》参考文献合集典藏的Github Repo地址:


https://github.com/QianMo/Real-Time-Rendering-4th-Bibliography-Collection
​github.com/QianMo/Real-Time-Rendering-4th-Bibliography-Collection


以及对应的下载链接：

https://codeload.github.com/QianMo/Real-Time-Rendering-4th-Bibliography-Collection/zip/refs/heads/main



正如上文提到的，这2000多篇参考资料，可谓是图形学全网学习资料的“半壁江山”。希望这一Github开源版本的《Real-Time Rendering 4th》参考文献合集，能对游戏开发与图形学业界的蓬勃发展有所裨益。


<br>

# 关于RTR4中译版的出版时间的Update


在之前的文章《两件 Big Thing：天美跨平台3A大作全球招聘令 & RTR4中译版出版时间预告》中，有提到过，“如果没有特殊的不可抗因素，《Real-Time Rendering 4th》的中译版会在年底与大家正式见面”。

而目前而言，还真有一些不可抗因素的发生，所以《Real-Time Rendering 4th》中译版可能需要到明年上半年再与大家见面。

最后，同样是感谢大家对《Real-Time Rendering 4th》中译版的热爱与关注。接下来的时间，我们依然会继续努力，将《Real-Time Rendering 4th》中译版的翻译品质在时间与能力范围内做到尽善尽美。

以上。

![](media/End.jpg)
图片来自 Horizon Forbidden West



<br>

# 招聘信息

对了，天美开放世界3A的全球热招依然在进行中，尤其是图形研发岗。
简历请发送至williammao#tencent.com

具体细节可见：
https://zhuanlan.zhihu.com/p/353527484




```

`Content/天美跨平台3A大作全球招聘令与RTR4中译版出版时间预告/README.md`:

```md


# 两件 Big Thing：天美跨平台3A大作全球招聘令 & RTR4中译版出版时间预告

![](media/703a0e8ac5a665bb6a1c0af769c23ad4.jpg)

本文的知乎专栏版本：https://zhuanlan.zhihu.com/p/353527484


<BR>

题图来自电影《头号玩家》。


这篇文章由两件Big Thing组成：

-   天美战略级跨平台3A大作全球招聘令

-   《Real-Time Rendering 4th》中译版预计将在年内出版



<BR>


# 第一件 Big Thing：天美战略级跨平台3A大作全球招聘令



是的，**天美工作室正在筹备3A主机游戏的研发**，而且是包括主机平台在内的跨平台战略级3A大作。

不妨先看看这款刚立项不久的产品的定位。

## 关于产品定位 

-   定位：天美战略级3A开放世界大作，包含射击在内的众多玩法元素

-   策略：多平台全球发行

    -   面向平台：Console/PC/移动端/下一代终端

-   架构：全球多地协同研发

    -   广纳全球范围内3A人才

-   引擎：Unreal Engine

    -   在充分挖掘Unreal Engine 5实力的同时，做引擎架构的进一步深度定制

-   画风：写实风格


<BR>

对于这款产品，电影《头号玩家》中的绿洲（Oasis），是比较远期的对标方向。

![](media/03559d0cee2b52a51fc73fc5aa492296.jpg)

图片来自电影《头号玩家》

![](media/a464ef290b9e3475943786dd36cd81ae.jpg)

图片来自电影《头号玩家》


<BR>

## 关于薪酬待遇

薪酬体系的细节在这里没办法详细透露，但可以简单提几点：

-   天美工作室可能是全球范围内薪酬待遇最好的工作室之一。

-   在天美，成功的团队以及潜力巨大的团队会获得丰厚的回报。

-   天美的姚老板在年会上提到过，“只要好好工作，买房买车都只是生活琐事”，一直被我们所津津乐道。

-   如果你有过硬的综合实力，或许我们可以开出让你无法拒绝的薪酬待遇。


<BR>


## 国产3A最好的时代可能已经来临

我们知道，在这之前，国内的3A游戏市场环境并不乐观，不受资本市场看好。很多怀揣3A大作开发梦想的同学，因为国内工作机会少、国外3A工作室的待遇一般等原因，被迫选择了其他工作岗位。

西游题材的国产3A《黑神话：悟空》的研发团队游戏科学可能就是一个极好的例子。在创业之初，他们为了团队能够生存下去，选择了开发手游，保持团队稳定的盈利能力。在解决团队温饱问题之后，我们才欣慰地看到了《黑神话：悟空》的问世。

![](media/e67252da39e9bc8aefa4671ee38be53e.png)

图片来自《黑神话：悟空》

现在，走过十二周年的天美，也选择了包括主机平台在内的跨平台3A大作的研发。有大量岗位虚位以待，一次就能够为业界提供几百个3A大作的工作岗位。

这一次，我们不仅可以追寻自己内心的声音，从事心仪的3A大作的研发，而且能在实现人生理想的同时，获得丰厚的物质回报，让家人衣食无忧，过上幸福美满的生活。就像天美的姚老板所说的，“只要好好工作，买房买车都只是生活琐事”。

国内的3A大作的研发环境正在渐入佳境，这是值得我们游戏行业的每一位从业者开心的事情。也期待更多国内的团队能加入3A游戏的研发当中，一起促进中国游戏行业的蓬勃发展。

是的，国产3A最好的时代，可能已经来临。



<BR>

### 关于列强雄踞的3A游戏领域 

在国际范围内，Console/PC端的原创3A大作基本上还处于被日韩欧美大厂所垄断的情形。最终幻想系列、上古卷轴系列、使命召唤系列、孤岛惊魂系列、战地系列、战争机器系列、GTA系列等大量的3A系列作品，无一不印证了这一点。

![](media/1498af9061855e37a71d2a5699631e05.jpg)

图片来自《使命召唤17：黑色行动 冷战》

而原创IP的国产游戏在Console/PC端还鲜有能与“欧美列强”抗衡的3A级产品。

天美的这款产品，剑指列强雄踞的Console/PC平台在内的诸多平台，将正面与日韩欧美列强交锋，希望能为国产3A在全球战场扳回一城，让世界对中国在3A游戏开发领域的实力刮目相看。


<BR>

## 招聘岗位JD

这里贴一个我负责跟进的招聘岗位的JD，可以作为参考：

### 工作内容

-   负责图形渲染管线及具体特性的技术研发，和技术美术紧密合作，增强画面品质，分析并解决相关性能问题；

-   帮助Gameplay程序员、美术、策划规范有效地使用引擎相关功能；

-   跟进业界技术发展，预研前沿方案，争取在项目落地并产生实际价值。

### 任职要求

-   三年以上C/C++及游戏引擎研发经验，对游戏研发相关技术有较为全面的掌握并保持学习和关注；

-   扎实的算法和数学基础，系统的软件研发领域知识(计算机系统、OS、数据结构等)；

-   熟悉图形渲染理论及常用实现技术, 对GPU的架构和特性有比较深入的理解;

-   有UE4引擎实践经验，掌握相关技术实现原理者优先；

-   出色的学习和技术研究应用能力，良好的问题分析与解决能力；

-   责任心强，有较好的团队协作和任务跟进能力，善于沟通，使命必达；

-   热爱游戏，关注用户体验(包括策划/运营/美术等内部用户体验)，有Geek精神，懂得以螺旋上升的方式追求极致。

以上的任职要求只是一个样例。如果你在某方面能力特别突出，这里列出的所有要求都不重要。英雄不问出处，只看能力。

**有意愿的同学，简历请发送至：williammao#tencent.com (#替换城@)**。我会在看到简历的第一时间进行处理。HC虽多，但也有限，所以如果可以请尽快。



<BR>


## 一些补充说明

-   我们十分欢迎有着日韩欧美3A大厂工作经历同学的加入。大家为国外3A产品工作多年，是时候回到祖国的怀抱，为国产3A贡献自己的薪火之力了。而且，如果你的能力符合岗位要求，我们应该能给出让你无法拒绝的薪酬待遇。：）

-   我们也十分欢迎想做出业界领先的产品，以及研发出引领游戏业界的技术成果，技术能力过硬或者拥有较好的数学基础，或在图形/通用引擎/物理/动画/AI/PCG等方向有深厚积累的同学的加入。

-   社招/校招/实习生均可。只要你有过硬的技术实力，英雄不问出处。

-   我们也会在全球范围内招聘大量日韩欧美等国籍，拥有3A大厂工作经历的员工，实施全球多地协同开发。如果你希望与这些全球范围内的顶尖人才共事，相互学习进步，我们也十分欢迎你的加入。

-   这款天美跨平台3A作为全球多地协作研发的产品，工作地点包括了国内（深圳、上海等）与海外多地。入职深圳腾讯天美总部自然是最佳的选择。这样我们就能够面对面，一起携手完成这款产品。而且理论上在深圳总部的待遇也会更优。

-   **招聘不限于引擎技术岗位，程序方向的GamePlay、系统开发等所有岗位，TA/策划/美术等3A大作必备的职能体系，都有大量岗位虚位以待。**简历请发送至邮箱williammao#tencent.com (#替换城@)。如果不是我负责跟进的岗位方向，也会第一时间推送给负责相关方向的同学**。**


-   当然，已经在鹅厂的小伙伴们如果有兴趣一起做国产3A大作，正面与日韩欧美列强交锋，我们也十分欢迎你的活水。具体可以内部通过企业微信联系到我。

- **本文的招聘信息长期有效。**

-   大家如果觉得用邮件发简历的形式太正式，也可以先通过在这篇文章的评论、或者知乎私信的方式做相关咨询和了解。

-   如果有什么疑问，也欢迎大家在评论区留言，一起讨论。



<BR>


## 结语

就像歌手Bob Dylan所写，《黑神话：悟空》团队也引用过的歌词所说的：

“曾经我如此苍老，如今才风华正茂。”

加入我们一起做国产3A，或许正是风华正茂的开始。

期待着这一天，我们一起研发出的产品能取得世界范围内的巨大成功，获得Console/PC/移动端/下一代终端在内所有平台全球玩家的认可，让曾经3A游戏界的日韩欧美列强们，都能对中国在3A领域的实力刮目相看。

也期待着这一天，我们可以一起出席SIGGRAPH，GDC等技术盛会，共同将研发出的先进游戏开发技术分享给全世界，重塑游戏行业的技术格局，为中国游戏行业在世界范围内的技术影响力添砖加瓦。

希望这一天，能够早日到来。


<BR>


# 第二件Big Thing：RTR4中译版将在年内出版


《Real-Time Rendering 4th》，豆瓣评分9.6，作为游戏开发和实时渲染领域的圣经级别的存在，相信很多同学都明白这本书之于高品质游戏开发的意义，也期望这本著作的中文版能早日出版，能为国内游戏开发领域提供宝贵的中文版进阶资料。

![](media/3c2637651e84af5995dde3060e7c79fb.jpg)

距《Real-Time Rendering 4th》英文原版出版时间2018年8月6日，已经过去了两年半，至今都没有中文版出版的确切消息。究其原因，其实是因为《Real-Time Rendering 4th》中文版的翻译权，曾经被默默“雪藏“了近两年。

2020年6月5日，《Real-Time Rendering 4th》中译版的责任编辑、清华大学出版社的文老师浏览到了我在知乎问题“如何评价《Real–time Rendering》第四版?”（<https://www.zhihu.com/question/290566100/answer/471199400>）下的回答。随后，我收到了文老师的知乎私信，她希望我能接手RTR4的翻译工作，并在一年左右的时间内完成，尽力挽回这两年时间的损失。收到文老师的私信时，出于对《Real-Time Rendering》系列书籍本身的热爱，我还来不及仔细思考，就接受了文老师的邀约。

读过《Real-Time Rendering 4th》的同学都应该知道，这本书旁征博引，信息量密集，需要海量的知识储备才能顺利完成阅读，要达到较高的翻译质量，难度可谓十分之高。而加之全书多达1000多页体量的巨大翻译工作量，一年之内难以一个人完成。所以，文老师随后还邀请到了另外两位小伙伴，并以我作为带头人，三人合力完成本书主体的翻译工作。

正式签订翻译合同之后，接下来就是工作之余夜以继日，争分夺秒地进行这本书的翻译工作。为了保证每天的翻译进度，在工作日晚上回家之后，我常常会翻译到凌晨1点半，每天晚上只能保证5个半小时的睡眠时间。

这大概是我出生以来，最夜以继日的一段时间，可能更甚于当年高三的备考冲刺阶段。2021年春节期间也几乎无休，每天都在电脑前起早贪黑地完成这天的翻译计划。这也是为什么本专栏已经8个月没有新增文章的原因。

比较令人欣慰的是，截止这篇文章发表的2021年2月28日，《Real-Time Rendering 4th》中译版的主体部分的全部26章（包括纸质版没有收录的第25章碰撞检测（Collision Detection），以及第26章实时光线追踪（Real-Time Ray Tracing）），共1129页的正文内容，已经完成了全书的初稿翻译工作，并已经完成了两轮的Refine，目前按计划正常处于全书的第三轮Refine阶段。

如果没有特殊的不可抗因素，《Real-Time Rendering 4th》的中译版会在年底与大家正式见面。

更多细节暂时可能还不方便透露。后续有进一步消息会及时与大家分享。大家如果有想知道的细节，也可以在本文评论区下方留言。

最后，感谢大家对《Real-Time Rendering 4th》中译版的热爱与关注。我们会继续努力，将《Real-Time Rendering 4th》中译版的翻译品质在时间与能力范围内做到尽善尽美。希望这本书的出版，能为国内的游戏行业与实时渲染领域的进步献上绵薄之力。



<BR>


# 尾声


OK，两件Big Thing说完了。还是回到最初的话题，天美战略级跨平台3A大作的全球招聘已经正式拉开序幕，所有3A大作必备的职能体系，都有大量岗位虚位以待，欢迎各位人才的加入。简历请发送至邮箱williammao#tencent.com (#替换城@)。

文章末尾，再引用一次歌手Bob Dylan所写，《黑神话：悟空》团队也引用过的歌词吧：

“曾经我如此苍老，如今才风华正茂。”

是的，加入我们，一起做国产3A，或许正是风华正茂的开始。

![](media/703a0eXXc5a665bb6a1c0af769c23ad4.jpg)

```

`Content/实时光线追踪技术：业界发展近况与未来挑战/README.md`:

```md
# 实时光线追踪技术：业界发展近况与未来挑战


![](media/ec782554f31f3c05b1c98545880c7e2c.jpg)

本文的知乎专栏版本：https://zhuanlan.zhihu.com/p/102397700

<br>

最近阅读了SIGGRAPH 2019中 EA SEED团队带来的，关于实时光线追踪相关很赞的一篇技术分享[1]。

本文将以此为引子，对实时光线追踪技术的发展近况，当前业界面对的挑战，以及未来的研究方向进行一个盘点。

主要涉及的要点有：

-   **一、实时光线追踪技术元年：2018年**

-   **二、实时光线追踪：当前业界产品应用情况**

    -   2.1 虚幻引擎：UE 4.22实时光线追踪特性正式面世

    -   2.2 Unity引擎：Unity 2019.3正式支持实时光线追踪特性

    -   2.3 3A游戏：部分产品已加入实时光线追踪技术

    -   2.4 主机平台：Play Station 5和Xbox Scarlett都将支持实时光线追踪

-   **三、实时光线追踪：当前业界技术发展近况盘点**

    -   3.1 实时光线追踪：混合渲染管线

    -   3.2 实时光线追踪：反射渲染

    -   3.3 实时光线追踪：环境光遮蔽

    -   3.4 实时光线追踪：阴影渲染

        -   3.4.1 解析直接光照+随机阴影

        -   3.4.2 透明阴影渲染

    -   3.5 实时光线追踪：透明渲染和半透明渲染

    -   3.6 实时光线追踪：多光源处理

    -   3.7 实时光线追踪：粒子系统渲染

    -   3.8 实时光线追踪：全局光照

    -   3.9 实时光线追踪：剔除

    -   3.10 实时光线追踪：Texture LOD

-   **四、实时光线追踪：业界当前面临的挑战**

    -   4.1 实时光线追踪处理透明渲染仍有不少问题需要攻克

    -   4.2 对多变的游戏内容环境的更好兼容

    -   4.3 实时光线追踪全局光照：广阔的空间等待探索

    -   4.4 探索新的实时光线追踪形态

    -   4.5 不断革新混合渲染管线的技术形态

    -   4.6 未来光线追踪领域的研究方向

<br>

OK，下面开始正文。


# 壹 · 实时光线追踪技术元年：2018年


**个人认为，可以将2018年定义为实时光线追踪技术元年。**

这一年，秘密开发了多年的实时光线追踪技术终于在GDC 2018上揭开面纱，进入大众视野，并引起广泛轰动。

这一年，微软宣布了DirectX Ray Tracing，DXR的问世；NVIDIA、ILMxLAB、UE4联合发布了基于实时光线追踪的具有电影级视觉效果的《星球大战》短片；NVIDIA发布了RTX Technology Demo以及Project Sol Cinematic Demo Part 1；EA SEED团队带来了PICA PICA实时光线追踪Demo；Remedy的Northlight引擎也带来了Ray Tracing in North Light Demo；Futuremark团队也发布了非常赞的DirectX Raytracing Tech Demo。

![](media/6222bcd3fdd9ce2274df2dccac83a722.png)

![](media/d1a46babdee712952fbd4f083e8d6d4c.png)

也是这一年，NVIDIA宣布了可加速硬件中光线追踪速度的新架构Turing，以及搭载实时光线追踪技术的RTX系列显卡。

![](media/e36c5c9456015553e30791ed1e23c651.jpg)

同样是这一年，第一款搭载RTX实时混合光线追踪技术的游戏《战地5（Battlefield V）》正式面世，基于EA的Frostbite引擎，带来了出色的混合光线追踪反射（Hybrid Ray-Traced Reflections）渲染表现。

![](media/7d41d593d56c778b925e76bb79da89e4.png)


<br>

时间来到2020年，自GDC 2018实时光线追踪技术正式面世以来已经经过了近两年时间，让我们看下当前实时光线追踪的业界产品应用情况。

<br>
<br>


# 贰 · 实时光线追踪：当前业界产品应用情况

<br>


## 2.1 虚幻引擎：UE 4.22实时光线追踪特性正式面世

<br>



![](media/13cbbf71e27aa76dc0cc0fba598d20ac.png)

自4.22版本以来，UE4的实时光线追踪功能已经正式面世。

UE4中的Ray Tracing技术目前有两种形态：

-   **混合光线追踪模式（Hybrid Ray Tracer Mode）**，用于将光线追踪功能与现有的光栅化效果相结合，进行混合渲染。

-   **路径追踪参考模式（Path Tracer Reference Mode）**，用于与Ground Truth进行比较。

UE4中的Ray Tracing的KeyFeature可以总结如下：

-   光线追踪阴影Ray Traced Shadows

-   光线追踪反射Ray Traced Reflections

-   光线追踪半透明渲染Ray Traced Translucency

-   光线追踪环境光遮蔽Ray Traced Ambient Occlusion

-   光线追踪全局光照 Ray Traced Global Illumination

这边放一个UE4、NVIDIA、保时捷合作的实时光线追踪911超跑概念车视频“The Speed of Light”：<https://www.youtube.com/watch?v=Z85aPqqJzs0>

<br>


## 2.2 Unity引擎：Unity 2019.3正式支持实时光线追踪特性

<br>

![](media/1bfbb1ebd9dac568789d60fe97bf4a73.png)

随后，Unity引擎也宣布对混合实时光线追踪（Hybrid Real-Time Ray Tracing）的支持，并在Unity 2019.3中正式发布。

Unity Ray Tracing的Key Feature可以总结为：

-   光线追踪环境光遮蔽 Ray-Traced Ambient Occlusion

-   光线追踪接触阴影 Ray-Traced Contact Shadows

-   光线追踪全局光照 Ray-Traced Global Illumination

-   光线追踪反射Ray-Traced Reflections

-   光线追踪阴影Ray-Traced Shadows

-   递归光线追踪Recursive Ray Tracing

Unity引擎2019年3月发布的《Reality vs illusion: Unity real-time ray tracing》Demo中，将CG汽车与现实世界的汽车同时放在画面中。对比起来，已经很难辨别CG和现实。

![](media/3094e2f8bc0778cd772468b84514e2c8.png)



## 2.3 3A游戏：部分产品已加入实时光线追踪技术


-   到目前为止，不少3A游戏已经加入了实时光线追踪技术，包括《战地5（Battlefield V）》、《使命召唤：现代战争（Call of Duty: Modern Warfare）》、《地铁:离去（Metro Exodus）》、《古墓丽影:暗影(Shadow of the Tomb Raider)》、《雷神之锤2 RTX版 （Quake II RTX）》、《德军总部：新血脉（Wolfenstein: Youngblood）》等。

![](media/a90e6fe178d010d72cccd7c1f7ed7da7.png)

未来将发布的更多的大作，也将具有实时光线追踪特性，比如《看门狗：军团 Watch Dogs Legion》、《赛博朋克2077（Cyberpunk 2077）》等。

![](media/e7c074eab1399b7114cdd7f1689adbf7.jpg)

甚至Minecraft都将发布RTX版：

![](media/a605aca9ebe3090a05f6b495d76eda22.jpg)

这边有一个当前所有支持RTX的所有游戏的List（统计自2019.10月）：

<https://www.digitaltrends.com/computing/games-support-nvidia-ray-tracing/>

这边也放一个NVIDIA出品的Project Sol Part 3实时光线追踪渲染的电影短片：

<https://www.youtube.com/watch?v=b2WOjo0C-xE&t>

总之，实时光线追踪技术刚刚开始进入游戏产品，未来将有更广泛的普及。


<br>

## 2.4 主机平台：Play Station 5和Xbox Scarlett都将支持实时光线追踪

![](media/262f9353deebc2fe32be88ed9f6bf4e3.png)


当然，两个主要主机制造商的下一代产品，索尼的Play Station 5和微软的Xbox Scarlett，都宣布了对实时光线追踪技术的支持。

-   Microsoft: E3 2019 Keynote：<https://www.youtube.com/watch?v=zeYQ-kPF0iQ>

-   SONY: What to Expect From SONY’s Next-Gen PlayStation
    ：<https://www.wired.com/story/exclusive-sony-next-gen-console>

OK，讲了那么多产品级的应用，下面开始正篇吧，实时光线追踪技术当前业界的发展近况，即 State-of-the-Art Real-Time Ray Tracing Technology。

<br>
<br>

# 叁 · 实时光线追踪：当前业界技术发展近况盘点

<br>

要点有：

-   混合渲染管线 Hybrid Rendering Pipeline

-   反射 Reflections

-   环境光遮蔽 Ambient Occlusion

-   阴影 Shadows

-   透明渲染Transparency

-   半透明渲染 Translucency

-   多光源处理 Many Lights

-   粒子渲染Particles

-   基于光线追踪的全局光照 Ray-traced GI

-   剔除 Culling

-   贴图LOD | Texture LOD

![](media/b8003c86959b736c2536a34039528fc5.jpg)


<br>

## 3.1 实时光线追踪：混合渲染管线

<br>

![](media/65d452ab1ebd1992a8948787786c3584.png)

当前业界主流的实时光线追踪技术都普遍采用了 **混合渲染管线（Hybrid Rendering Pipeline）** 架构。混合渲染管线能充分利用光栅化（Rasterization），计算着色器（Compute Shader）和光线追踪（Ray Tracing）各自的优势，对于管线的每一个渲染阶段，在光栅化，计算着色器和光线追踪中择优使用。

目前主流的混合渲染管线（Hybrid Rendering Pipeline）架构的渲染流程可以总结为：

-   延迟着色阶段（光栅化）Deferred Shading (rasterization)

-   直接阴影阶段（光线追踪或光栅化）Direct shadows (ray trace or rasterization)

-   光照阶段（计算着色器+光线追踪）Lighting (compute + ray trace)

-   反射阶段（光线追踪或计算着色器）Reflections(ray trace or compute)

-   全局光照阶段（计算着色器+光线追踪）Global Illumination (compute and ray trace)

-   环境光遮蔽阶段（光线追踪或计算着色器） Ambient occlusion (ray trace or compute)

-   透明与半透明渲染阶段（光线追踪+计算着色器）Transparency & Translucency (ray trace and compute)

-   后处理阶段（计算着色器）Post processing (compute)

<br>

## 3.2 实时光线追踪：反射渲染


![](media/f9fe0b404cfd2c64c23e63068a80321b.png)

众所周知，《战地5》具有非常赞的实时光线追踪反射渲染表现。

![](media/562ea1b425c680866b708d5796c6b884.png)

业界当前进行实时光线追踪反射的主流思路是，每像素需要多于1条光线才能完全表达基于物理的渲染管线可描述的从粗糙到光滑的材质范围。对于多层材质来说，则会更加复杂。

下图是实时光线追踪反射渲染管线（Real Time Ray Tracing Reflection Pipeline）的图示：

![](media/ee037b7f8ff1ccd335d4f077b2b33fa6.png)

根据上图，可以将混合光线追踪反射管线的渲染步骤总结为如下六步：

-   **Step 1**. 通过BRDF重要性采样生成光线，以提供符合材质特性的光线。。

-   **Step 2**. 通过屏幕空间光线步进（screen-space raymarching）或光线追踪（ray tracing）来完成场景相交运算。

-   **Step 3**. 在相交运算找到交点（intersections）之后，便可以重建反射图像。该过程可以就地完成，也可以分别完成，以提高一致性（coherency）。

-   **Step 4.** 内核跨像素重用ray hit信息，将图像采样到全分辨率。

-   **Step 5**. 为时域累积通道（temporal accumulation pass）计算有用信息

-   **Step 6**. 最终，以交叉双边滤波器（cross-bilateral filter）的形式对噪声进行最后的清理


<br>

## 3.3 实时光线追踪：环境光遮蔽


当然，另一种可以很好地迁移到实时光线追踪领域的技术是环境光遮蔽（Ambient Occlusion）。

![](media/30e5f419de063f0911519c3e2ab39e7e.png)

Ray Tracing AO可以通过对半球可见度函数的积分，获得更接近Ground Truth的结果，因为采样期间使用的所有随机方向实际上都最终出现在场景中的。

其实，这就是Ray Tracing AO与屏幕空间AO技术（如SSAO）的主要不同点，因为在屏幕空间技术中，光线会出射到屏幕之外或几何体的后方，而此时命中点是不可见的。

在Ray Tracing AO中，可以通过围绕法线进行余弦半球采样来完成运算。光线通常是从G-buffer发出的，miss
shader用于找出是否有击中目标。每帧可以发射多于1束光线，但是如果限制了光线的距离，即使每帧只有一条光线，也应该得到一些很好的渐变效果。

不过，可能最终需要过滤和重建，因为Ray Tracing AO可能会有一些噪声。

下图是Ray Tracing AO与SSAO对比，我们可以完全看到光线追踪AO将环境光遮蔽的渲染表现提升到了新的高度。

![](media/b5b0247c681f328d57720f432d7ed01a.png)

![](media/cef7dedb590971242cdca0e944c93476.png)


<br>

## 3.4 实时光线追踪：阴影渲染


阴影渲染显然是光线追踪另一个出彩的领域。

![](media/3cda89bae936e6484d06b0d6cd2c7f8d.png)

上图是基于UE4实时光线追踪渲染的场景，其展示了出色的实时光线追踪阴影表现如何让画面更加真实。

Ray Tracing Shadow 实现起来并不太复杂。 基本思想是向光源发射光线（launch a ray
towards the light），如果光线未命中，则不处于阴影中。

![](media/52991522705906c1c329693d63e72537.png)

而与硬阴影(Hard shadows)相比，软阴影(soft
shadows)可以更好地传达物体的真实感，更加Ground Truth。软阴影(soft
shadows)可以通过在朝向光的圆锥中按随机方向进行采样并将其视为区域光一样对待来实现。锥角（cone
angle）越宽，阴影越柔和，但噪点越大，因此我们必须对其进行过滤（filtering）。也可以发射多条光线，但仍需要进行一些过滤（filtering）操作。


<br>

### 3.4.1 解析直接光照+随机阴影

在基于物理的渲染领域颇有建树的学术大牛Eric Heitz加入Unity后，在Ray Tracing Shadow领域又有了新的突破性进展。

Eric Heitz于2018年提出了一种结合了解析直接光照（analytic direct illumination）和随机阴影（stochastic shadows）的新方法（Combining Analytic Direct Illumination and Stochastic Shadows[Heitz2018]）。在paper中，他们提出了一种比率估计器（ratio estimator），该比率估计器可以将解析光照技术（analytic illumination techniques）与随机光线追踪阴影（stochastic raytraced shadows）正确组合。

![](media/fa05c5d7edfff0dc4a854d405c10684c.png)

通过将阴影光照分为两个部分——解析部分（analytical part）和随机部分（stochastic
part），他们的方法演示了如何通过随机光线追踪在图像的阴影区域部分获得清晰和无噪声，且解析和视觉上逼真的阴影。

而仅在需要时进行随机求解的优点是，最终结果仅在阴影中有噪声，而其余部分则通过解析进行处理。该项技术还将阴影与光照分开，因此可以保留高频阴影细节。真的是很赞。

<br>

### 3.4.2 透明阴影渲染

![](media/418d624111eafde156257aa25a95d952.png)

在实时渲染领域，透明渲染一直都是难题，但是通过光线追踪，可以找到一些新的替代方法。

在SEED提供的Demo中，在对透明表面阴影进行渲染时，他们用递归光线追踪（recursive ray tracing）方法来替换常规的阴影光线追踪方法。当光穿过介质时，会成倍地进行积累吸收。并进行薄膜近似（thin film approximation），假设所有颜色都在表面上，以得到更好的性能。同时，就像不透明阴影渲染一样，使用类似的SVGF启发式过滤器对其进行过滤，可以让透明阴影也变得柔和。

![](media/a5eed51b8538324d5b641f87344f96c4.png)

![](media/0f127c5e9b475df59de8b26cc38a5535.png)

上图左侧为未过滤的结果，右侧为已过滤的结果。

![](media/5d8a860b3f656936f34d8ae9c5363e17.png)

同样，也能实现类似笔的墨水管的阴影从塑料外壳中传播出的光线的阴影渲染。


<br>

## 3.5 实时光线追踪：透明渲染和半透明渲染


![](media/b231bac948149c3d66dd68ed70486c47.png)

光线追踪可以准确地进行光的散射，从而在实现透明渲染和次表面半透明渲染（subsurface translucency）上有天生的优势。

对于**透明渲染（Transparency）**，目前业界的发展近况可以概括为：

-   正确表示顺序无关的透明渲染（Order-independent Transparency，OIT）

-   可变的粗糙度，折射和吸收（Variable roughness , refractions and absorption）

-   多IOR过渡（Multiple index-of-refraction transitions）

![](media/d939fc61829a5a5328e5382ca24ef583.png)

另外，对于粗糙玻璃，推荐使用Walter’s参数化（Walter’s parametrization）和GGX粗糙度重要性采样（importance sample GGX roughness）。而对于特别粗糙的材质，则需要更多的采样来进行降噪，也可以使用时域滤波。实践证明在纹理空间（texture-space）中进行渲染是不错的思路。

而对于**半透明渲染（Translucency）**，目前业界已可以很好地实现均匀介质内部的光散射（Light scattering inside homogeneous medium），在PICA PICA Demo，同样采用了在纹理空间（texture-space）中进行渲染的方案。

![](media/2f9d45d894247fa85c1ae57fcaef9437.png)

<br>

# 3.6 实时光线追踪：多光源处理


![](media/4f43c895e05027e5fff8a419027aadb9.png)

对于多光源的处理而言，业界现有方案可以总结如下两类：

-   基于加速结构的光源选择（Acceleration structure-based selection）

-   基于重要性采样的光源选择（Light Importance Sampling）

其中，基于加速结构的光源选择（Acceleration structure-based selection）方案的代表性思路可以总结为：

-   **Unity引擎的方案**。基于相机朝向的加速结构（camera-oriented acceleration structure ）[Benyoub 2019] [Tatarchuk 2019]

-   **《战地5》的方案**。水平面光源列表（horizontal plane light list）[Deligiannis 2019]

而基于重要性采样的光源选择（Light Importance Sampling）的代表性思路，都是HPG 2019的paper：

-   Dynamic Many-Light Sampling for Real-Time Ray Tracing [Moreau 2019]

-   Stochastic Lightcuts [Yuksel 2019]

其中，《Dynamic Many-Light Sampling for Real-Time Ray Tracing》描述了一种基于两层BVH的分层光源采样数据结构，该结构能够从10，000个发射三角形进行交互式直接光照。这使得未来的实时场景可以只用自发光网格（emissive
meshes）来进行光照，非常赞。

<br>

## 3.7 实时光线追踪：粒子系统渲染


![](media/944f62c473dcb5f2973fff0ee0d6ce26.png)

对于光线追踪粒子系统的渲染，《战地5》解决方案是将粒子朝向光线，有点类似billboard的思想。

而一般方案是维护两个顶层加速结构（Top Level Acceleration Structures, TLAS）：一个用于不透明几何体，一个用于粒子系统。

-   首先用不透明几何体的TLAS发射光线，如果有命中，则存储该长度

-   然后，在粒子系统的TLAS中发射另一条光线，并从不透明的命中长度限制该光线长度

-   然后，便可以相应地混合场景中的粒子系统

值得一提的是，另一个技巧是将奇数粒子旋转90度。

<br>

## 3.8 实时光线追踪：全局光照 


![](media/7f1468f7f9b3e2acd55fc8fa2ea56fa3.png)

光线追踪硬件的新特性可以给全局光照带来各种便利，诸如依靠各种缓存机制（caching mechanisms）在多个帧上累积渲染结果，并提高采样速度。

可以将业界主流的基于光线追踪的全局光照分为如下三类：

-   **基于面元（Surfels）**。Stochastic All The Things: Ray Tracing in Hybrid Real-Time Rendering [Stachowiak 2018]

-   **基于网格（Grid）**。Experiments with DirectX Raytracing in Remedy’s Northlight Engine [Aalto 2018]

-   **基于探针（Probes）**。Dynamic Diffuse Global Illumination with Ray-Traced Irradiance Fields [Majercik 2019]


<br>

## 3.9 实时光线追踪：剔除


![](media/982a99eda74fb19e302378186577b965.png)

因为光线追踪一般是在世界空间中进行的，所以无法使用光栅化方法中比较常用的“视锥剔除（Frustum Culling）”。

如果无法将所有对象都放在BVH中，则必须找到一种新的启发式剔除方法。《战地5》的方案是基于投影包围球（Projected Bounding Sphere）[Deligiannis 2019]，不失为一种有效的方法。

<br>

## 3.10 实时光线追踪：Texture LOD


![](media/487aa87eac891248f93343e3a1280c8d.png)

因为从2x2像素块（pixel quad）中求解出的导数（pixel quad derivatives），只能用于光栅化，所以光线追踪无法自动进行Texture LOD。

-   目前的主流方案是依赖于光线差分（Ray Differentials）方法，但其对性能有一定的影响。

-   在《光线追踪精粹 (Ray Tracing Gems)》[Akenine-Möller2019]一书中，有讨论到一种基于光线锥（Ray Cones）的替代技术，其虽有一些可改进的地方，但也算是当前不错的方案。

OK，盘点完十个细分领域目前的发展状况，下面接着盘点实时光线追踪业界当前面临的挑战，以及未来的发展方向。


<br>
<br>

# 肆 · 实时光线追踪：业界当前面临的挑战

<br>

## 4.1 实时光线追踪处理透明渲染仍有不少问题需要攻克


![](media/14346ab101400f1c0294623f8a6075d9.png)

在目前的实时光线追踪领域，在1-2 spp（sample per pixel）的情况下，大多数降噪技术通常对于透明渲染、粒子渲染、体积渲染的渲染效果虽说相较于光栅化有进步，但其实也并算不上特别理想。

PICA PICA Demo中，虽然采用了具有折射和散射的纹理空间OIT（texture-space OIT）技术，但也并不完美，有改进的空间。

对于粒子系统和体积特效而言，采用在miss shader中更新体积/裁剪图、或在hit shader中进行光线步进（Ray marching in hit shaders）、以及进行Non-trivial blending & filtering，都是值得尝试的方向。

当下业界需要研究出更好的降噪技术或者相关方案，以在低spp下带来更佳的透明渲染品质。

![](media/e1984036e480d9fe2b38e4a6050f2be5.png)

对于局部覆盖（Partial Coverage）效果的渲染方面，当前的降噪技术并不能很好地适用于实时的局部可见性。这是因为通常每像素只有1采样（1 spp），并假设所有内容都是不透明的。
也可以在hit shader中进行Alpha测试，并且可以使用一些预过滤方法。但是，一旦物体开始移动，在性能和视觉表现上就可能出现问题。

另外，一些去焦效果（Defocus effects ），例如运动模糊和景深，使用实时光线追踪也仍然比较棘手。


<br>

## 4.2 对多变的游戏内容环境的更好兼容


![](media/fb2e0ef799be1f2127e1264c938343e6.png)

对目前的实时光线追踪领域而言，需要更健壮的技术体系，来支持大量动画角色，丰富的植被，动态的环境，以及对开放大世界，用户生成内容的稳定处理。


<br>

## 4.3 实时光线追踪全局光照：广阔的空间等待探索


![](media/ac2705093a98f633f80ff369dedc4456.png)

首先，实时光线追踪进行全局光照，会遇到即使在离线渲染中也存在的开放性问题。比如离线渲染中暂未解决的过高的方差，小孔全局光照（Pinhole GI）等问题，在实时光线追踪领域目前同样是无法解决。

而且离线渲染方案中的许多解决方案，不一定都可以运用到实时渲染中。对于实时光线追踪，目前而言必须借助缓存技术摊销着色成本来达以交互速率进行渲染的性能要求。而在PICA PICA Demo中，基于面元缓存GI（caching of GI via surfels）的方案，也存在仅能从看到的内容生成面元的限制。

同样，业界也需要解决在不借助任何前期参数化行为的前提下，对用户生成的内容进行稳定的实时光线追踪全局光照的问题。

所以基于实时光线追踪技术的全局光照，目前仍然有很多探索空间。


<br>

## 4.4 探索新的实时光线追踪形态


![](media/24e7ce6cb181b6a51544cead794beb61.png)

当前的实时光线追踪模型假设光线是与三角形相交的（ray-triangle intersection），但是如果在树的上层结构就让光线停止，会怎样？基于这种思考，可以像体素一样来对待AABB，以扩展到新的追踪类型，比如光束追踪（beam
tracing）、射线束（ray bundles），这也就打开了实时光线追踪新的方向。

另外，实时光线追踪领域还可以解锁广义光线追踪领域一系列新的算法，比如：

-   Global Illumination Using Ray-Bundle Tracing [Tokuyoshi 2012]

-   Dynamic Diffuse Global Illumination with Ray-Traced Irradiance Fields
    [Majercik 2019]

-   Cone Tracing [Crassin 2011]

另外，也可以参考声音传播的方案来进行实时光线追踪。

<br>

## 4.5 不断革新混合渲染管线的技术形态 


![](media/c1a8ff13c3cc16958909d45a50137cf0.png)

对于目前面世的实时光线追踪的产品来说，《战地5》等第一批搭载实时光线追踪技术的游戏，以及Unity、UE4引擎的实时光线追踪功能，虽说听起来高大上，其实并不算完美。按照形象的比喻来说，可能有点像在现有渲染管线上打补丁，做了大量的缝缝补补。

![](media/b68d517b4af89c7532133267bb8990d8.jpg)

在引擎方面，业界还有很多工作要做，以改进现有的渲染方法，最大限度地发挥混合渲染管线的优势。

<br>

## 4.6 未来光线追踪领域的研究方向


![](media/07a30fa18436871bb8ef37fc18854134.png)

就未来的光线追踪研究而言，如果涉及到各类光线追踪的技术文献的使用和改进，须对文献的基础约束进行调整，以适应实时渲染的约束，而不仅仅是“正确的光线追踪”。主要的要点在于制定合理的实时渲染预算以及善用光照传输缓存（Light Transport Caches） 技术。
另外，未来实时光线追踪的一个大方向大概率是对 **纹理空间技术（texture space techniques）** 和 **可变速率光线追踪（variable rate ray tracing）** 的探索。如缓存材质（Caching of material）和局部解（partial solutions），以及BRDF拆分（Split the BRDF）。
而在 高效采样和积分策略（efficient sampling and integration strategies） 以及 重建（reconstruction）方面，业界也还有很多事情需要去完成。

<br>
<br>


# 伍 · 总结


总之，实时光线追踪技术，在图形学发展的长河中，目前刚刚起步，发展势头良好，未来的路还很长。

整个工业的发展和技术的普及，依然任重而道远。

同时也期待即将到来的GDC 2020，更多实时光线追踪技术新进展的发布。

<br>
<br>

# Reference


[1] SIGGRAPH 2019, State-of-the-Art and Challenges in Game Ray Tracing

[2] 题图来自UE4

[3] https://www.youtube.com/watch?v=zeYQ-kPF0iQ

[4] https://www.wired.com/story/exclusive-sony-next-gen-console

[5] https://www.rockpapershotgun.com/2019/04/11/nvidia-gtx-graphics-card-dxr-ray-tracing-driver/

[6] GDC 2018, Experiments with DirectX Raytracing in Remedy’s Northlight Engine

[7] GDC 2018, Shiny Pixels and Beyond: Real-Time Ray Tracing at SEED

[8] SIGGRAPH 2019, Leveraging Ray Tracing Hardware Acceleration In Unity

[9] Epic Games demonstrates real-time ray tracing in Unreal Engine 4 with ILMxLAB and NVIDIA

[10] https://docs.unrealengine.com/en-US/Engine/Rendering/RayTracing/index.html

[11] https://docs.unity3d.com/Packages/com.unity.render-pipelines.high-definition@7.1/manual/Ray-Tracing-Getting-Started.html

[11] https://devblogs.nvidia.com/ignacio-llamas-interview-unearthing-ray-tracing/

[12] GDC 2019, Towards Filmic Quality at 30 FPS: Real-Time Ray Tracing for Practical Game Engine Pipelines

[13] SIGGRAPH 2018, Combining Analytic Direct Illumination and Stochastic Shadows

[14] https://www.digitaltrends.com/computing/games-support-nvidia-ray-tracing/

[15] HPG 2019, Dynamic Many-Light Sampling for Real-Time Ray Tracing

[16] HPG 2019, Stochastic Lightcuts
```

`Content/真实感水体渲染技术总结/README.md`:

```md
# 真实感水体渲染技术总结


![](media/f9337c818762004c902ac45c66f56fc1.jpg)


本文的知乎专栏版本：https://zhuanlan.zhihu.com/p/95917609

之前在【GPU精粹与Shader编程】系列中写过一篇[《真实感皮肤渲染技术总结》](media/https://zhuanlan.zhihu.com/p/42433792)，这篇文章则是它的番外篇，主要关注于真实感水体渲染技术。

本文将对游戏开发以及电影业界的真实感水体渲染技术从发展史、知识体系、波形模拟技术以及着色技术等多个方面进行较为系统的总结，文末也对业界优秀的水体实时渲染开源库进行了盘点。




<br>

# 一、总览：水体渲染技术发展史


真实感水体的渲染和模拟，一直是计算机图形学和游戏开发领域的核心难点之一。而在水体渲染中，最核心的部分为波形的渲染技术，即如何模拟出逼真的水面波浪的流动变化。按时间分布，近50年水体波形渲染的主流技术发展可以总结列举如下：

1.  凹凸纹理贴图（Bump Mapping） [Schachters 1980]

2.  正弦波（Sinusoids Wave）[Max 1981]

3.  分形噪声（Fractal noise）[Perlin 1985]

4.  Gerstner 波（Gerstner Wave）[Fournier 1986]

5.  快速傅立叶变换（Fast Fourier Transform）[Mastin 1987]

6.  欧拉方法（Eulerian approaches）[Kass 1990]

7.  拉格朗日方法（Lagrangian approaches）[Stam 1995]

8.  欧拉-拉格朗日混合方法（Hybrid approaches）[Brien 1995]

9.  分形布朗运动（Fractal Brownian Motion，FBM）[Addison 1996]

10. 程序化形状（Procedural Shape）[Ebert 1999]

11. 空间-频谱混合方法（Spatial -Spectral Approaches） [Thon 2000]

12. 基于体素的方法（Voxel-Based NSE Solutions） [Yann 2003]

13. 顶点高度位移贴图（Vertex Height Map Displacement）[Yuri 2005]

14. 二维波动方程（2D Wave Equation）[Nishidate 2005]

15. 屏幕空间网格（Screen Space Mesh）[Muller 2007]

16. 波动粒子（Wave Particles）[Yuksel 2007]

17. 矢量位移贴图(Vector Displacement Map) [2009]

18. 流型图（Flow Map）[Vlachos 2010]

19. 离线FFT贴图烘焙（Offline FFT Texture）[Torres 2012]

20. 离线流体帧动画烘焙（bake to flipbook）[Bowles 2017]

21. 水波小包方法（Water Wave Packets）[Jeschke 2017]

22. 水面小波方法（（Water Surface Wavelets）[Jeschke 2018]

23. 浅水波浪模拟（Water Wave Simulation）[Grenier 2018]

需要注意的是，上面列出的时间点，可能并不是严格意义上的该技术提出的时间点，而是该技术在论文或会议上被提出，被大众熟知，被引入到水体渲染技术中的时间点。

接下来，先看一些近年游戏中的真实感水体渲染画面，然后对这里列出的水体主流渲染技术中的主要方法，按流派和内容分别进行总结。

<br>


# 二、近年游戏业界的真实感水体的渲染画面




首先是《神秘海域4》中清澈的海岛浅滩：

![](media/d3da711298b707c03ef27ef2836b7bde.jpg)

然后是《盗贼之海》中波涛汹涌的海洋：

![](media/f9336662004c902ac45c66f56fc1.png)

接着是《孤岛惊魂5》中阴天的池塘：

![](media/cc1a37cb528dcc8fd7575fcecd567d28.jpg)

还有《战神4》中深邃的海面：

![](media/d171d460a0a940a73dfcb01d6dbc8697.jpg)

以及《刺客信条：奥德赛》中平静的海滩：

![](media/0e798671dd9c8cab74310fec756b8947.jpg)

这边也放一个继承了《刺客信条》系列水体渲染技术的《怒海战记（Skull & Bones）》的gameplay视频：

<https://youtu.be/fCgYA65tAYY?t=125>

要实现如上3A游戏级别的水体渲染，其实是有章可循的，对应的核心方法在本文以及下面的这张思维导图中都有进行总结。


<br>

# 三、水体渲染的知识体系思维导图


本文配套的水体渲染的知识体系思维导图如下：

![](media/Water-Rendering-Knowledge-Architecture.png)

OK，下面开始正文。


<br>

# 四、水体渲染的波形模拟技术


按照流派进行分类，可将上文总结的水体渲染波形模拟的二十三种方法分为如下几类：

**1.线性波形叠加方法**

1. 正弦波（Sinusoids Wave）[Max 1981]

2.  Gerstner 波 （Gerstner Wave） [Fournier 1986]

**2.统计模型方法**

1.  快速傅立叶变换（Fast Fourier Transform）[Mastin 1987]

2.  空间-频谱混合方法（Spatial -Spectral Approaches）[Thon 2000]

**3.波动粒子方法**

1.  波动粒子方法（（Wave Particles） [Yuksel 2007]

2.  水波小包方法（Water Wave Packets）[Jeschke 2017]

3.  水面小波方法（Water Surface Wavelets）[Jeschke 2018]

**4. 基于物理的方法**

1.  欧拉方法（Eulerian approaches）[Kass 1990]

2.  拉格朗日方法（Lagrangian approaches） [Stam 1995]

3.  欧拉-拉格朗日混合方法（Hybrid approaches）[Brien 1995]

**5.预渲染方法**

1.  顶点高度位移贴图（Vertex Height Map Displacement） [Yuri 2005]

2.  流型图（Flow Map）[Vlachos 2010]

3.  离线FFT贴图烘焙（Offline FFT Texture） [Torres 2012]

4.  离线流体帧动画烘焙（bake to flipbook）[Bowles 2017]

**6.其他方法**

1.  凹凸纹理贴图（Bump Mapping）[Schachters 1980]

2.  分形噪声（Fractal Noise）[Perlin 1985]

3.  分形布朗运动（Fractal Brownian Motion，FBM）[Addison 1996]

4.  程序化形状（Procedural Shape）[Ebert 1999]

5.  基于体素的方法（Voxel-Based Solutions） [Yann 2003]

6.  二维波动方程（2D Wave Equation）[Nishidate 2005]

7.  屏幕空间网格（Screen Space Mesh）[Muller 2007]

8.  浅水波浪模拟（Water Wave Simulation）[Grenier 2018]

<br>

下面将对其中比较常见的方案进行盘点。

<br>

## 4.1 线性波形叠加方法


线性波形叠加方法的主要思路是累加不同的线性波形函数以构造波浪表面。可以将其理解为波动现象在深水中引起水颗粒运动的一种解析解。

![](media/1b5cc8c471c19acaf7c14ef464d620a0.gif)

图 水颗粒运动的图示。波浪中的任何点都沿圆形轨迹移动，靠近表面的半径较大，而在水中更深的半径呈指数减小。突出显示了两个橙色点，可以发现他们的运动轨迹都是圆形。（图片来自<https://wikischool.org/divided_light>）

业界主流的波形函数主要分为正弦波（Sinusoids Wave）和Gerstner波(Gerstner Wave)两种，下面分别进行说明。

<br>

### 4.1.1 正弦波（Sinusoids Wave）[Max 1981]

作为比较早期的水面波形模拟方案，正弦波（Sinusoids Wave）的特点是平滑，圆润，适合表达如池塘一样平静的水面。

![](media/2f5a16138b7ea35ff97964eb0083b073.gif)

图 Unity下实现的基于正弦波（Sinusoids Wave）的水体

1981年，Max[Max 1981]首先提出了采用高低振幅的正弦波曲线的序列组合来模拟水面起伏的想法。将水体表面采用高度进行建模，则基于正弦波（Sinusoids Wave）的方法在时间t的每个点（x，z）上计算的高度y = h（x，z，t）的通用公式为：

![](media/29afa8cb7c082da59f879920e41148f4.png)

-   其中Nw是波的总数

-   Ai是第i个波的振幅 

-  ![](media/a3a9ad5afe1cb5c5b0d85da93ff6160f.png)是波矢量

- ![](media/74215aad7e2b742784c294f66e1bffca.png) 是其脉冲值（pulsation）

-   y0是自由表面的高度

正弦波（Sinusoids Wave）目前在水体渲染领域已经很少直接使用，业界往往青睐于使用它的进化版Gerstner波。

<br>

### 4.1.2 Gerstner 波（Gerstner Wave） [Fournier 1986]

作为正弦波的进化版，Gerstner 波（Gerstner Wave）的特点是波峰尖锐，波谷宽阔，适合模拟海洋等较粗犷的水面。

![](media/daf43226edfa0f2ac2674cd5ddb6d07b.gif)

图 Unity下实现的基于Gerstner波的水体

Gerstner 波(Gerstner Wave)也常被称为Trochoidal Wave，在流体动力学中，其为周期表面重力波（periodic surface gravity waves）的欧拉方程的精确解，由Gerstner在1802 年初次发现，并在1863年由Ranine独立重新发现。在1986年由Fournier等人引入水体渲染领域。

![](media/dd43a67fd4ab46b150452ed7e864b5de.png)

图 Gerstner Waves波形

![](media/Gerstner-wave3.gif)

图 Gerstner Waves水颗粒的运动轨迹为圆形

选择一组波矢量ki，振幅Ai，频率ωi和相位φi，对于![](media/7ad644310aae035a960a8ee45d026878.png)，Gerstner Waves的通用公式为：

![](media/a1444c00510cffa25cd85017195f8748.png)

![](media/b44bd22505708fcbfa7475e2daba3a33.png)

Gerstner Waves由于计算量可控，性价比高，在游戏水体渲染领域的应用较为广泛。不少3A游戏了采用Gerstner Wave作为水体渲染的基础实现。如下文Wave Particles部分也会提到的《神秘海域3》，即是采用了Gerstner Wave + Wave Particles的水体渲染方案组合。

<br>

## 4.2 统计模型方法

<br>

### 4.2.1 快速傅立叶变换（Fast Fourier Transform , FFT）[Mastin 1987]

作为目前电影业界广泛采用的海洋表面渲染解决方案，基于快速傅立叶变换（Fast Fourier Transform , FFT）的水体渲染方法的特点是真实感出色，全局可控，细节丰富，但计算量相对较大。

自1986年[Mastin 1987]将基于FFT的水体渲染方法引入水体渲染领域，以及2001年Tessendorf著名的水体总结文章《Simulating Ocean Water》[Tessendorf 2001]对其的推广之后，至今其仍然是电影工业模拟海洋表面的标准解决方案。

![](media/a1010df7c688043cbe1ea20b91389bca.gif)

图 Unity下实现的基于FFT的水体


傅里叶变换（Fourier transform）是一种线性积分变换，用于信号在时域和频域之间的变换。而快速傅里叶变换 （Fast Fourier Transform，FFT）, 是一种可在O（nlogn）时间内完成离散傅里叶变换（Discrete Fourier transform，DFT）的高效、快速计算方法集的统称。最初的快速傅里叶变换方法早在1805年就已由高斯推导出来，并于1965年由Cooley和Tukey重新提出，并渐渐被大众所熟知。从此，对快速傅里叶变换（FFT）算法的研究便不断深入，数字信号处理这门新兴学科也随FFT的出现和发展而迅速发展。根据对序列分解与选取方法的不同而产生了FFT的多种算法。

FFT的基本思想是把原始的N点序列，依次分解成一系列的短序列。充分利用DFT计算式中指数因子 所具有的对称性质和周期性质，进而求出这些短序列相应的DFT并进行适当组合，达到删除重复计算，减少乘法运算和简化结构的目的。

关于FFT的算法细节这里就不展开讲了，放两张经典的总结图：
![](media/fft_infographic.jpg)

![](media/fft.jpg)

基于FFT的水体渲染方法，也常被各类文献称为基于频谱（spectrum-based）的方法，其核心思想是基于FFT构造出水体的表面高度。具体而言，该方法使用从理论或测量统计数据获得的海浪频谱（最常见的频谱为[Tessendorf 2001]使用的Phillips频谱）来描述海洋表面，结合大量的正弦波的叠加在频域中生成波型的分布，然后执行逆FFT，将数据转到空间域，经过运算生成位移贴图（displacement map）。最终，由位移贴图导出表面法线贴图，以及其他相关数据，如代表白沫区域的Folding Map。

![](media/1cb3d14ab4d525fb3ef01250b0409cc5.png)

图 基于FFT的水体渲染流程 [NVIDIA 2004]


采用FFT的水体渲染方法从90年代开始广泛用于电影制作（离线渲染），从2000年代开始广泛用于游戏（实时渲染）。离线渲染和实时渲染的选择，主要在于当时硬件计算能力可以承受多少分辨率的高度图的实时运算。早期的游戏，如Crysis，由于硬件计算量的限制，采用了64 x 64的高度图分辨率。而由于硬件的发展，目前512 x 512的分辨率的计算量已经在实时渲染中较为普遍。而电影工业中采用FFT生成的高度图，由于可以采用离线渲染，以及品质的要求，分辨率一般较大，如早在1997年的《泰坦尼克号》的海洋渲染的渲染，就已经采用了2048 x 2048分辨率的高度图。

![](media/6706dced4ba808378b30ad6ea07c94ad.jpg)

图 著名电影《泰坦尼克号》中，基于FFT方法离线渲染的海洋，采用2048 x 2048分辨率的高度图

<br>

## 4.3 波动粒子方法

<br>

### 4.3.1 波动粒子（Wave Particle） [2007]

波动粒子（Wave Particle）方法最初由Yuksel于2007年[Yuksel 2007]提出，该方法的核心思想是采用粒子代表每一个水波，并允许波反射以及与动态对象的相互作用。这种方法将动态模拟三维水波的复杂度降维到模拟在平面上运动的粒子系统的级别。

波动粒子（Wave Particle）方法结合了线性叠加方法的灵活性和基于FFT方法的稳定性和视觉细节，其可控制性和性能，以及出色的交互表现，是模拟实时水体交互的不错方案。

![](media/65a195446da34cbcdf968e25301afe40.gif)

![](media/19d3c94b611257d2077dd4992709586e.jpg)

图 Wave Particle （图片来自[Yuksel 2007]）

需要注意的是，波动粒子（Wave particles）的作用不只是代表波浪的位置。它们还可以带有描述其形状和行为的其他属性，例如振幅（amplitude）和半径（radius）。

当相邻波动粒子之间的距离大于半径的一半时，该方法会将一个波动粒子转换为三个新的波动粒子。新的波动粒子直接从现有波动粒子中吸收能量（即振幅）。从而减小了现有波动粒子的振幅，而整体波峰的总振幅保持不变。三个子粒子的振幅和扩散角度变为父粒子的三分之一，而新粒子的半径与父波动粒子保持相同。如下图所示。

![](media/7b01b4fcfb5692db907e37282d0b19ba.png)

图 （a）和（b）分别是波动粒子的初始位置和它们形成的波峰（c）和（d）是波粒经过一定距离后的位置和波动粒子形状（图片来自[Yuksel 2010]）

因为在波动粒子系统中，假设每个波动粒子在两侧都具有两个相同的相邻粒子，所以当一个波动粒子细分时，其会在两侧产生两个新的波动粒子，如下图所示。

![](media/c090dbc09e0b566c8a5257421741fa03.png)

图 具有相同扩散角度的两个相邻波动粒子之间的距离（图片来自[Yuksel 2010]）

另外，Wave Particles方法还可以与现有各种方案进行结合和改进。

2007年Yuksel提出的原版Wave Particles的波动粒子的生成源来自点状的粒子波源。对此，《神秘海域3》对其进行了改进方案。在《神秘海域3》中，并没有使用点状粒子波源，而是在环形区域中放置随机分布的粒子源，以近似开放水域的混沌运动，从而产生一个可平铺的向量位移场（vector displacement field）。

![](media/wave-particle.gif)

图 《神秘海域3》中基于随机分布wave particles粒子源的波浪模拟方法


《神秘海域4》中则采用了多分辨率Wave Particles方案，从另一个角度对Wave Particles方法进行了改进。

![](media/89d5f030e13e8a172cb07d6177891e68.png)

图 《神秘海域4》中的多分辨率wave particles

<br>

### 4.3.2 水波小包方法（Water Wave Packets）[SIGGRAPH 2017]

在波动粒子（Wave Particles）的基础上， Jeschke和Wojtan[2017]于SIGGRAPH 2017引入了以理论群速度（theoretical group speed）传播的水波小包（Water wave packets ）方法。该方法继承了基于频谱的方法的优点，如数值稳定性和理论上准确的波速。同时，他们通过将全局余弦波分解成一系列更短的波分量，从而避免了基于频谱的方法的复杂性。


![](media/wave2017-6.gif)
图 水波小包方法（Water Wave Packets）的paper demo [SIGGRPAPH 2017]

![](media/35071f67896903b9c795a2cd644d477a.png)

图 水波小包方法（Water Wave Packets）的原理图示


![](media/a42f7c3ca6ef1c17b8a70f37478b3fa9.jpg)
图 水波小包方法（Water Wave Packets）渲染效果图

<br>

### 4.3.3 水面小波方法（Water Surface Wavelets） [SIGGRAPH 2018]

随后的[SIGGRAPH 2018]，Jeschke等人对Water Wave Packets进行了改进，提出了新的水面小波方法（Water Surface Wavelets）。水面小波方法（Water Surface Wavelets）基于欧拉方法，自由度与空间区域有关，与波动本身无关。因此，该方法可以和GPU更好的结合，因为计算复杂度是恒定的，因为不随粒子的数量而变化。不过该方法由于提出时间较新，性能也没有太大优势，所以目前还没有听说有实际的实时渲染项目在使用。



![](media/8c1eeab1cf760dcd6b0cd186a81bc58b.gif)

图 Water Surface Wavelets paper Demo [SIGGRPAPH 2018]

![](media/Water-Surface-Wavelets.png)

图 水面小波方法（Water Surface Wavelets）渲染效果图 [SIGGRPAPH 2018]


<br>

# 4.4 基于物理的方法


基于物理的水体模拟方法一般比较昂贵，由于可以离线渲染，所以在电影工业中具有很好的运用。由于现阶段很难用于实时渲染，这边仅进行一个综述性的总结。

基于物理模型的水体模拟方法的核心是对Navier-Stokes方程（Navier-Stokes Equations,NS方程）进行求解。Navier-Stokes方程是一组描述液体和空气之类的流体物质的方程，描述作用于液体任意给定区域的力的动态平衡。除了水体模拟之外，其还可以用于模拟天气，水流，气流，恒星的运动。

Navier-Stokes方程如下：

![](media/c47959a66f114c8dccc845771081a73f.png)

-   u为流体速度矢量（fluid velocity vector）

-   p为流体压力（fluid pressure）

-   ρ为流体密度（fluid density）

-   ν为运动粘度系数（kinematic viscosity coefficient）

-   ∇为梯度微分（gradient differential）

-   ∇2为拉普拉斯算子（Laplacian operators）

常用的求解NS 方程的方法有欧拉方法（Eularian Method）和拉格朗日方法（Lagrangian Method）两种：

-   欧拉方法（Eularian Method）是一种基于网格的方法。它从研究流体所占据的空间中各个固定点处的运动着手，分析被运动流体所充满的空间中每一个固定点上流体的速度、压强、密度等参数随时间的变化，以及由某一空间点转到另一空间点时这些参数的变化。

-   拉格朗日方法（Lagrangian Method）是一种基于粒子的方法。它从分析流体各个微粒的运动着手，即研究流体中某一指定微粒的速度、压强、密度等参数随时间的变化，以及研究由一个流体微粒转到其他流体微粒时参数的变化，以此来研究整个流体的运动。最常用的拉格朗日方法是光滑粒子流体力学(Smoothed Particle Hydrodynamics，SPH)方法，其核心渲染思想为流体模拟产生粒子，然后多边形化粒子以产生波。

![](media/4fcc2a8b1753a1aabeecb8ab6c0735ee.gif)
图 基于SPH方法的水体渲染表现



![](media/Houdini-Fluids-Simulation.gif)
图 Houdini下的流体模拟 

除了独立的两种方法之外，还有结合两者的欧拉-拉格朗日混合方法（Eularian-Lagrangian Hybrid approaches），其主要思想是使用欧拉方法来模拟流体的主体，并使用拉格朗日方法来模拟诸如泡沫，喷雾或气泡之类的细小细节。

FX Guide上有一篇关于电影业界使用流体模拟方法的不错文章，感兴趣的朋友可以了解一下：https://www.fxguide.com/fxfeatured/the-science-of-fluid-sims/

另外，也可以采用bake to flipbook方法，将离线的流体模拟，烘焙成flipbook帧动画，用于实时渲染。

<br>

## 4.5 预渲染方法


### 4.5.1 流型图（Flow Map）

流型图（Flow Map），也常被称为矢量场图（Vector Field Map），本质上是一种基于矢量场平移法线贴图的着色技术，或者可以理解为一种UV动画，由VALVE的Vlachos在SIGGRAPH 2010上的talk《Water Flow in Portal 2》被大众所熟知。值得一提的是，VALVE在2010年就超前地使用了Houdini来制作flow map。

![](media/Flow-Map.png)
图 原版Flow Map的算法原理[SIGGRAPH 2010]

![](media/Flow-Map2.png)
图 基于Houdini的Flow Map创作工作流[SIGGRAPH 2010]

Flow Map除了用于水体的渲染以外，任何和流动相关的效果都可以采用Flow Map，如沙流，以及云的运动等效果。

![](media/flow-map.gif)

图 基于Flow Map的水体渲染 @Unity

![](media/Flow-Map-UDK.gif)

图 基于Flow Map的水体渲染 @UDK

Flow Map的核心思想是预烘焙2D方向信息到纹理，以在运行时基于UV采样，对流动感进行模拟。


![](media/Flow-Map-Example.jpg)
图 基于Flow Map的形变

Flow Map的典型使用代码如下所示：
```
//get and uncompress the flow vector for this pixel
float2 flowmap = tex2D( FlowMapS, tex0 ).rg * 2.0f - 1.0f;
float cycleOffset = tex2D( NoiseMapS, tex0 ).r;
float phase0 = cycleOffset * .5f + FlowMapOffset0;
float phase1 = cycleOffset * .5f + FlowMapOffset1;

// Sample normal map.
float3 normalT0 = tex2D(WaveMapS0, ( tex0 * TexScale ) + flowmap * phase0 );
float3 normalT1 = tex2D(WaveMapS1, ( tex0 * TexScale ) + flowmap * phase1 );
float flowLerp = ( abs( HalfCycle - FlowMapOffset0 ) / HalfCycle );
float3 offset = lerp( normalT0, normalT1, flowLerp );
```

<br>

#### 4.5.1.1 Flow Map变体：《神秘海域3》Flow Map + Displacement

另外，Flow Map可以和其他渲染技术结合使用，比如《神秘海域3》中的Flow Map + Displacement：

![](media/d957523662ca2f2c12855c75833458bb.png)

<br>

#### 4.5.1.2 Flow Map变体：《堡垒之夜》Flow Map + Distance Fields + Normal Maps

以及《堡垒之夜》中的Flow Map + Distance Fields + Normal Maps [GDC 2019, Technical Artist Bootcamp Distance Fields and Shader Simulation Tricks]
![](media/fornite-flowmap.png)

<br>

#### 4.5.1.3 Flow Map变体：《神秘海域4》Flow Map + Wave Particles

或者《神秘海域4》中的Flow Map + Wave Particles[SIGGRAPH 2016, Rendering Rapids in Uncharted 4]，都是进阶模拟水体表面流动与起伏效果的不错选择。

![](media/920ff7f35ceed08b08141e60b84dc228.png)

图 《神秘海域4》中的Flow Map + Wave Particles。通过将flow map与波浪粒子（wave particle grids）网格配合使用，可以非常精确地控制波浪的方向。在此示例中，采用一个循环的flow map来构成漩涡

如下为《神秘海域4》中Flow + Wave Particles的伪代码：

```
timeInt = time / (2.0 * interval)  
float2 fTime = frac(float2(timeInt, timeInt * .5)  
posA = pos.xz - (flowDir/2) * fTime.x * flowDir  
posB = pos.xz - (flowDir/2) * fTime.y * flowDir  
gridA0 = waveParticles(posA.xz, freq0,scale0)  
gridA1 = waveParticles(posA.xz, freq1,scale1)  
…  
gridB0 = waveParticles(posB.xz, freq2,scale0)  
gridB1 = waveParticles(posB.xz, freq3,scale1)  
…

float3 pos0 = gridA0 + gridA1 + gridA2 + gridA3  
float3 pos1 = gridB0 + gridB1 + gridB2 + gridB3  
pos = blend(pos0, pos1, abs((2*frac(timeInt)-1)))  
pos.y += heightMap.eval(uv)
```

<br>

### 4.5.2 离线FFT贴图烘焙（Offline FFT Texture）

离线FFT烘焙（Offline FFT Texture）方法最初由《刺客信条3》团队开始采用[Torres 2012]而进入大众视野，思路为基于离线FFT预渲染出一系列高度图，烘焙得出一系列法线贴图或矢量位移贴图（vector displacement maps），并在运行时进行采样。FFT的周期性质可以让烘焙得出的贴图非常适合做tiling。

![](media/c7efe9490bfecd9b5d181c43734b6abf.jpg)

图 基于离线FFT烘焙的《刺客信条4》的水面表现

![](media/AC3-offline-FFT.gif)

图 基于离线FFT烘焙的《刺客信条3》的水面表现

<br>

## 4.6 其他方法


除了上述5大类方法之外，还有一些其他的常见水体渲染方法，可以总结如下：

-   凹凸纹理贴图（Bump Mapping）[Schachters 1980]

-   分形布朗运动（Fractal Brownian Motion，FBM）[Addison 1996]

-   程序形状（Procedural Shape）[Ebert 1999]

-   分形噪声（Fractal Noise）[Gonzato 2000]

-   基于体素的方法（Voxel-Based Solutions） [Yann 2003]

-   屏幕空间方法（Screen Space Mesh）[Muller 2007]

-   矢量位移贴图（Vector Displacement Map）[2009]

其中，凹凸纹理贴图（Bump Mapping）比较早期的水体模拟方案，主要思想是扰动参与光照计算的法向量，并通过凹凸纹理的连续移动来模拟海浪的随机运动。目前凹凸纹理贴图几乎是实时水体渲染的必备贴图之一。

而分形噪声（Fractal Noise）方法核心思想是基于不同频率Perlin噪声的叠加，混合出分形噪声，以构建海面高度场。

矢量位移贴图（Vector Displacement Map）的核心思想则是使用空间中的向量的颜色通道在方向与大小上置换对应几何体的顶点。

![](media/vector-displacement-map.png)

图 一个标准的矢量位移贴图（Vector Displacement Map） @Arnold Render

![](media/vector-displacement-map.gif)

图 基于矢量位移贴图（Vector Displacement Map）的水体渲染 @Arnold Render


其他的方案相对而言比较小众，都有对应paper，篇幅原因这里就不展开总结了。

这边放一个令人印象深刻的SIGGRAPH 2017上 ,Crest Ocean System基于动态程序化形状（Procedural Shape）的水体渲染demo，可以允许玩家和海洋进行互动：


![](media/crest-2017-procedural-shape.gif)


<br>
<br>

# 五、水体渲染的着色技术


关于水体渲染的Shading部分，首先要提到的是，目前游戏业界的主流方案都不是基于物理的。


到达水面的光线除了在水体表面发生反射之外，还有部分光线进入水体内部，经过吸收和散射后再次从水体表面射出，即水体的次表面散射现象（Sub-Surface Scattering, SSS）。基于物理的渲染中，求解次表面散射最标准的方法是求解BSSRDF（Bidirectional Surface Scattering Reflectance Distribution Function，双向表面散射反射分布函数）。
![](media/BSSRDF.jpg)

但在光栅图形学中，求解BSSRDF需要很大的计算量，所以实时渲染业界大多数的水体渲染，依旧是非基于物理的经验型渲染方法。



《神秘海域3》在2012年SIGGRAPH上的技术分享中有一张分析水体渲染技术非常经典的图，如下。

![](media/5bd61f0f22cc734a250310c204b1799f.png)

对此，我们可以将水体渲染的要点总结为：

-   漫反射（Diffuse）

-   镜面反射（Specular）

-   法线贴图（Normal Map）

-   折射（Reflection）

-   通透感（Translucency）

    -   基于深度的查找表方法（Depth Based LUT Approach）

    -   次表面散射（Subsurface Scattering）

-   白沫（Foam/WhiteCap）

-   流动表现（Flow）

-   水下雾效（Underwater Haze）

其中，漫反射，镜面反射，法线贴图，折射等都是比较常见的技术，而流动表现（Flow）上文已有涉及，这里都不再赘述。

下文将对水体渲染的难点，通透感（Translucency），白沫（Foam/WhiteCap）渲染分别进行总结。

<br>


## 5.1 水体通透感（Translucency）的表现方案

关于水体通透感（Translucency）的表现方案，可以将业界主流方案总结为如下三个流派：

-   **LUT方法（Look-Up-Table Approach）**

-   **次表面散射近似方法（Sub-Surface Scattering,SSS Approximation Approach）**。

-   **混合型方案。** 即同时将LUT与次表面散射近似两种方案结合使用的方法。典型的例子如《刺客信条3》

![](media/be9b5771072d9b8f12754dd09572986f.jpg)

<br>

### 5.1.1 基于深度的查找表方法（Depth Based LUT Approach）

Depth Based-LUT方法的思路是，计算视线方向的水体像素深度，然后基于此深度值采样吸收/散射LUT（Absorb/Scatter LUT）纹理，以控制不同深度水体的上色，得到通透的水体质感表现。

![](media/51f3fb42fc45bb61f207dc2a981b28b1.jpg)

![](media/3b0b3b1569bd4b0e8cf0aa7edbd32211.jpg)

其中，视线方向的水体像素深度值计算思路如下图中的蓝色箭头所示的橘褐色区间：

![](media/a0baab932bed4ba7dc36d69c2d9e49f7.png)

图 蓝色箭头所示的橘褐色区间为视线方向的水体像素深度

<br>

### 5.1.2 次表面散射近似方法（Sub-Surface Scattering Approximation Approach）

可用于水体通透感表现的次表面散射（Sub-Surface Scattering，SSS）的近似方案有很多种，这边推荐两种：

-   [SIGGRAPH 2019] Crest Ocean System改进的《盗贼之海》SSS方案。

-   [GDC 2011] 寒霜引擎的Fast SSS方案。

![](media/77d6df448a37393793138e6aed31c453.png)

图 有无次表面散射的水体表现对比

<br>

#### 5.1.2.1 [SIGGRAPH 2019] Crest Ocean System改进的《盗贼之海》SSS方案

经过Crest Ocean System改进的《盗贼之海》的SSS方案可以总结如下：

-   假设光更有可能在波浪的一侧被水散射与透射。

-   基于FFT模拟产生的顶点偏移，为波的侧面生成波峰mask

-   根据视角，光源方向和波峰mask的组合，将深水颜色和次表面散射水体颜色之间进行混合，得到次表面散射颜色。

-   将位移值（Displacement）除以波长，并用此缩放后的新的位移值计算得出次表面散射项强度。

对应的核心实现代码如下：

```
float v = abs(i_view.y);

half towardsSun = pow(max(0., dot(i_lightDir, -i_view)),_SubSurfaceSunFallOff);

half3 subsurface = (_SubSurfaceBase + _SubSurfaceSun * towardsSun) *_SubSurfaceColour.rgb * _LightColor0 * shadow;

subsurface *= (1.0 - v * v) * sssIndensity;

col += subsurface;
```

其中，sssIndensity，即散射强度，由采样位移值计算得出。

![](media/37127e8f88345c7b4603d07bdfcf1169.png)

图 《Crest Ocean System》中基于次表面散射近似的水体表现

![](media/1b8b68602c4341b0635fb65aec3cbe62.png)

图 《盗贼之海（Sea of Thieves）》中基于次表面散射近似的水体表现

![](media/SSS.gif)
图 《盗贼之海（Sea of Thieves）》中基于次表面散射近似的水体表现

<br>

#### 5.1.2.2 [GDC 2011] 寒霜引擎的Fast SSS方案

[GDC 2011]上，Frostbite引擎提出的Fast Approximating Subsurface Scattering方案，也可以用于水体渲染的模拟。

![](media/48b4b55c258d3511bc5ad4adf91d6b2f.png)

具体方案和代码如下所示：

![](media/fd253aaccef1624e2de81c1e51409452.png)


<br>

## 5.2 白沫的渲染方案


白沫（Foam），在有些文献中也被称为Whitecap，White Water，是一种复杂的现象。即使白沫下方的材质具有其他颜色，白沫也通常看起来是白色的。出现这种现象的原因是因为白沫是由包含空气的流体薄膜组成的。随着每单位体积薄膜的数量增加，所有入射光都被反射而没有任何光穿透到其下方。这种光学现象使泡沫看起来比材质本身更亮，以至于看起来几乎是白色的。

![](media/45bd4e330ee85602305b6c0060318bf1.jpg)

图 海洋中的白沫

对于白沫的渲染而言，白沫可被视为水面上的纹理，其可直接由对象交互作用，浪花的飞溅，或气泡与水表面碰撞而产生。

白沫的渲染方案，按大的渲染思路而言，可以分为两类：

-   基于动态纹理（dynamic texture）

-   基于粒子系统（particle system）

按照类型，可以将白沫分为三种：

-   浪尖白沫

-   岸边白沫

-   交互白沫

而按照渲染方法，可将白沫渲染的主流方案总结如下：

-   基于粒子系统的方法[Tessendorf 2001]

-   基于Saturate高度的模拟方法 [GPU Gems 2]

-   基于雅可比矩阵的方法 [Tessendorf 2001]

-   屏幕空间方法 [Akinci 2013]

-   基于场景深度的方法 [Kozin 2018][Sea of Thieves]

-   基于有向距离场的方法 [GDC 2018][Far Cry 5]


这边对其中比较典型的几种进行说明。

<br>

### 5.2.1 浪尖白沫：[Tessendorf 2001] 基于雅克比矩阵的方法

Tessendorf在其著名的水体渲染paper《Simulating Ocean Water》[Tessendorf 2001]中提出了可以基于雅克比矩阵（Jacobian）为负的部分作为求解白沫分布区域的方案。据此，即可导出一张或多张标记了波峰白沫区域的Folding Map贴图。

![](media/232609b215fcd8e1df5ef26f7cf9cd28.png)

《战争雷霆（War Thunder）》团队在CGDC 2015上对此的改进方案为，取雅克比矩阵小于M的区域作为求解白沫的区域，其中M~0.3...05。

![](media/418aa434032174c42703cabcc28d3e7b.png)

另外，《盗贼之海（Sea of Thieves）》团队在SIGGRPAPH 2018上提出，可以对雅可比矩阵进行偏移，以获得更多白沫。且可以采用渐进模糊（Progressive Blur）来解决噪点（noisy）问题以及提供风格化的白沫表现。

![](media/9897da02e043694cba54f1997172a394.png)


![](media/foam.gif)

图 《盗贼之海》基于雅可比矩阵偏移 + 渐进模糊（Progressive Blur）的风格化白沫表现

<br>

### 5.2.2 浪尖白沫：[GPU Gems 2] 基于Saturate高度的方法

《GPU Gems 2》中提出的白沫渲染方案，思路是将一个预先创建的泡沫纹理在高于某一高度H0的顶点上进行混合。泡沫纹理的透明度根据以下公式进行计算：

![](media/b91c64e4c72d492a3a78683cb37e5d07.png)

-   其中，H_max是泡沫最大时的高度，H_0是基准高度，H是当前高度。

-   泡沫纹理可以做成序列帧来表示泡沫的产生和消失的演变过程。这个动画序列帧既可以由美术师进行制作，也可以由程序生成。

-   将上述结果和噪声图进行合理的结合，可以得到更真实的泡沫表现。

<br>

### 5.2.3 岸边白沫：[2012]《刺客信条3》基于Multi Ramp Map的方法

《刺客信条3》中的岸边白沫的渲染方案可以总结为：

-   以规则的间距对地形结构进行离线采样，标记出白沫出现的区域。

-   采用高斯模糊和Perlin噪声来丰富泡沫的表现形式，以模拟海岸上泡沫的褪色现象。

-   由于白沫是白色的，因此在R，G和B通道中的每个通道中都放置三张灰度图，然后颜色ramp图将定义三者之间的混合比率，来实现稠密、中等、稀疏三个级别的白沫。要修改白沫表现，美术师只需对ramp图进行颜色校正即可。如下图所示：

![](media/93a93b541535bb6ec58c30f2879bb9a9.jpg)

![](media/9f3cc03578fb3319a1dadff2e732ad84.jpg)

<br>


### 5.2.4 交互白沫：[SIGGRAPH 2018]《盗贼之海》基于场景深度的交互白沫渲染

《盗贼之海（Sea of Thieves）》团队在SIGGRPAPH 2018的talk上也提到了白沫的渲染方案，可以总结如下：

-   放置一个top-down的相机，用于渲染场景深度，通过比较场景深度和水深来得到白沫mask，即：
half4 foamMask =1 - saturate(_FoamThickness* (depth - i.screenPos.w ) ) ;

-   最终，将foamMask和基础texture做blend。

-   盗贼之海中，得到相对深度后，还会对白沫mask做渐进模糊（progressively blur），以得到风格化的白沫表现。

![](media/d2bacc53079129f4d49a221444af7ed7.png)

图 《盗贼之海（Sea of Thieves）》中的交互白沫

![](media/0af0355442767919f9aff9876432859f.png)

图 《盗贼之海（Sea of Thieves）》中的交互白沫

<br>

### 5.2.5 浪尖白沫&岸边白沫：[GDC 2018]《孤岛惊魂5》基于有向距离场的方法

GDC 2018上《孤岛惊魂5》团队分享的白沫渲染技术也不失为一种优秀的方案，主要思路是基于单张Noise贴图控制白沫颜色，结合两个offset采样Flow Map控制白沫的流动，并基于有向距离场（Signed Distance Field，SDF）控制岩石和海岸线处白沫的出现，然后根据位移对白沫进行混合。

![](media/769884eccc5f53075cf76f50cbe0a7be.png)


<br>
<br>

# 六、业界优秀水体渲染开源库盘点

时间来到2019年，已有不少3A级别的水体渲染技术以免费&开源的方式涌现了出来，这里将进行一个盘点。

如果要实现一个高品质的水体实时渲染解决方案，以下的这六个开源库会让你事半功倍。

<br>

# 6.1 Crest Ocean System


Crest Ocean System是Unity下开源的高品质海洋渲染框架，已经在两届SIGGRAPH（SIGGRAPH 2017、SIGGRAPH 2019）上进行了技术分享。

源代码传送门：<https://github.com/crest-ocean/crest>

demo视频：<https://www.youtube.com/watch?v=ekng3c43Y1E>
![](media/7e389f8e7b164d003fdf029a97f3848f.jpg)

除了开源免费版，Crest Ocean System目前也已推出LWRP的付费版：<https://assetstore.unity.com/packages/tools/particles-effects/crest-ocean-system-lwrp-urp-141674>



<br>

## 6.2 CryEngine内置水体

之前在【GPU精粹】系列文章中也提到过，CryEngine作为比较老牌的引擎，其内置的水体渲染表现在各大游戏引擎的内置水体中，可谓是顶尖级别的。CryEngine现在也已经开源。

源代码传送门：

<https://github.com/CRYTEK/CRYENGINE/blob/26524289c15a660965a447dcb22628643917c820/Engine/Shaders/HWScripts/CryFX/Water.cfx>

demo视频：<https://www.youtube.com/watch?v=tZthI6M07iM>

<br>

![](media/3e4204b7bc0bda540dc68d342a365fda.png)

<br>

## 6.3 UE4 Dynamic Water Project


Dynamic Water Project 是Unreal引擎下一款不错的开源水面交互解决方案，对于可交互水体而言是不错的参考。

源代码传送门：

<https://github.com/marvelmaster/UE4_Dynamic_Water_Project/tree/master/Reactive_Water_V3_4-20>

![](media/c84317062f5d4cf06961a0c0418eb5cf.gif)


<br>

## 6.4 Ceto Ocean system

Ceto也是Unity引擎下的另一个不错的水体渲染开源库。

源代码传送门：<https://github.com/Scrawk/Ceto>

![](media/cc7936ce27c4431778fab9b01f64c779.png)

<br>

## 6.5 NVIDIA UE4 WaveWorks 

GDC 2017上，NVIDIA和Unreal Engine合作推出了WaveWorks，以集成到Unreal Engine 4.15引擎中的形式放出。

源代码传送门：<https://github.com/NvPhysX/UnrealEngine/tree/WaveWorks>

demo视频：<https://www.youtube.com/watch?v=DhrNvZLPBGE&list=PLN8o8XBheMDxCCfKijfZ3IlTP3cUCH6Jq&index=11&t=0s>


![](media/nVidia-WaveWorks-UnrealEngine-4.15.png)


<br>

## 6.6 Unity LWRP BoatAttack


BoatAttack是Unity在2018年5月13日开源的基于LWRP的项目，经历了几个版本的开发周期，具有令人印象深刻的水体表现，可谓是Unity引擎下非常优质的水体渲染参考。

源代码传送门：<https://github.com/Verasl/BoatAttack>

demo视频：<https://www.youtube.com/watch?v=7v9gZK9HqqI>


![](media/b7edd1c78d459d3da3eef13f12fb4624.png)


<br>
<br>


# 七、总结


本文对游戏以及电影业界的真实感水体渲染技术从发展史、知识体系等多个方面进行了较为系统的总结，文末也对业界优秀的水体实时渲染开源库进行了盘点。

不妨用配套的思路导图作为本文的收尾：

![](media/Water-Rendering-Knowledge-Architecture.png)




<br>
<br>

# Reference


[1] FX Guide 2012, Assassins Creed III The tech behind or beneath the action,
<https://www.fxguide.com/fxfeatured/assassins-creed-iii-the-tech-behind-or-beneath-the-action/>

[2] SIGGRAPH 2001, Tessendorf J. Simulating ocean water[J]. Simulating nature:
realistic and interactive techniques.

[3] SIGGPRAPH 2019, Multi-resolution Ocean Rendering in Crest Ocean System

[4] GDC 2008, Fast Water Simulation for Games

[5] GDC 2012, Water Technology of Uncharted

[6] GDC 2018, Water Rendering in FarCry 5

[7] Jeschke S, Wojtan C. Water wave packets[J]. ACM Transactions on Graphics(TOG), 2017

[8] 2010, Yuksel C. Real-time water waves with wave particles[M]. Texas A&M University

[9] SIGGRAPH 2016, Rendering rapids in Uncharted 4

[10] GDC 2019, Technical Artist Bootcamp Distance Fields and Shader Simulation Tricks

[11] <https://zhuanlan.zhihu.com/p/21573239>

[12] SIGGRAPH 2010, Water Flow in Portal 2

[13] GPU Gems2, Using Vertex Texture Displacement for Realistic Water Rendering

[14] SIGGRAPH 2013, Oceans on a Shoestring Shape Representation, Meshing and Shading

[15] SIGGRAPH 2018, The Technical Art of Sea of Thieves

[16] GDC 2015, An Introduction to Realistic Ocean Rendering through FFT

[17] CGDC 2015, Ocean simulation and rendering in War Thunder

[18] NVIDIA 2004, Ocean Surface Simulation nvidia

[19] SIGGRAPH Asia 2012, Real-time Animation and Rendering of Ocean Whitecaps

[20] TOG 2017, Water Wave Packets

[21] NVIDIA 2004, Ocean Surface Simulation nvidia

[22] GDC 2017, From Shore to Horizon Creating a Practical Tessellation Based Solution

[23] https://www.tek.com/fft

[24] https://www.youtube.com/watch?v=hzw-NOKeSRY

[25] https://www.youtube.com/watch?v=iBBQzs-7Ac4

[26] https://www.fxguide.com/fxfeatured/the-science-of-fluid-sims/

[27] https://graphicsrunner.blogspot.com/2010/08/water-using-flow-maps.html

[28] 题图来自《盗贼之海》

```

`Content/高品质后处理：十种图像模糊算法的总结与实现/README.md`:

```md
![](media/b05cff0fb8d1036d1972f82d35c4da6f.jpg)

# 高品质后处理：十种图像模糊算法的总结与实现

本文的知乎专栏版本：https://zhuanlan.zhihu.com/p/125744132

<br>

后处理（Post-Processing），在图形学和游戏开发等领域是提升最终画面呈现品质的重要渲染技术。后处理渲染技术的好坏，往往决定了游戏画面是否能够达到令人惊艳的级别。

图像模糊算法在后处理渲染领域中占据着重要的地位。很多产品级后处理的实现，都会直接或间接依赖于图像模糊算法中的一种或多种。无论是基于高斯模糊（Gaussian Blur）或其改进算法的Bloom特效，还是基于径向模糊（Radial Blur）的Sun Shaft（God Ray），或是基于方向模糊（Directional Blur）的镜头眩光光晕（Glare Lens Flare），抑或是景深（Depth of Field）特效中摄影级失焦感的散景模糊（Bokeh Blur），都以模糊算法作为重要的支撑。所以说，后处理中所采用模糊算法的优劣，决定了后处理管线最终的渲染品质和消耗性能的多少。


本文将对后处理管线中会使用到的如下十种模糊算法进行总结、对比和盘点，以及提供了这十种模糊算法以及其衍生算法对应的Unity Post Processing Stack v2版本的实现：

-   高斯模糊（Gaussian Blur）

-   方框模糊（Box Blur）

-   Kawase模糊（Kawase Blur）

-   双重模糊（Dual Blur）

-   散景模糊（Bokeh Blur）

-   移轴模糊（Tilt Shift Blur）

-   光圈模糊（Iris Blur）

-   粒状模糊（Grainy Blur）

-   径向模糊（Radial Blur）

-   方向模糊（Directional Blur）


另外，本文暂不涉及运动模糊（Motion Blur），因为其主要作用于帧之间的运动变化，不属于静态型模糊。还有一些其他的模糊算法由于不太适用于实时渲染，本文也暂不涉及，如Moving Averages filter。


下面先放一组使用了依赖于模糊算法的后处理特效的实时渲染截图，然后开始我们的正文。

![](media/6b40938cfddc691005bb05822a5c398e.jpg)

图《巫师2》 中基于径向模糊（Radial Blur）的Sun Shaft

![](media/130ec1a6dbdee035c956306b98b39bcb.jpg)

图 UE4场景中，间接基于高斯模糊（Gaussian Blur）的Bloom特效给画面带了更好的光感 @ UE4 CyberNeon @Junliang Zhang

![](media/dc5b0bb30b61379a55a98b9d2cca8acf.jpg)

图 Sun Shaft Forest @UE4

![](media/513005a757dc352083a8cec5889259f2.png)

图 《鬼泣5》中的镜头眩光光晕（Glare Lens Flare）

![](media/bcac2c9252b814447e87f5bc88268be8.jpg)

图 Tom Clancys The Division中的基于散景模糊（Bokeh Blur）的景深

这里也放一个《赛博朋克:霓虹中国(CyberNeon)》的视频（ArtStation原贴：https://www.artstation.com/artwork/Z5RkbZ）
，其中对于赛博朋克风夜中国风城市的展现，如果缺少了Bloom和Glare Lens Flare等依赖于本文讲到的模糊算法的后处理特效，展现出来的品质将少了很多韵味：

<https://www.youtube.com/watch?v=CZ4MOBSx2xw>

![](media/8bc10ccaba3d1cb963c7c53e4c07ae96.jpg)

![](media/f20159279e99b4174740875b9e33a28b.jpg)




<br>

# 十种图像模糊算法横向对比


在展开全文，对这十种图像模糊算法进行分别介绍之前，这一节中先做一个总览，即一个横向的对比。要评判一种模糊算法的好坏，主要有三个标准：

-   **模糊品质（Quality）** 。模糊品质的好坏是模糊算法是否优秀的主要指标。

-   **模糊稳定性（Stability）** 。模糊的稳定性决定了在画面变化过程中，模糊是否稳定，不会出现跳变或者闪烁。

-   **性能（Performance）** 。性能的好坏是模糊算法是否能被广泛使用的关键所在。

以下是本文涉及的十种模糊算法在标准情况下以上述三个指标作为评判标准的横向对比：

![](media/b82ba2aaa60f290da438450a86ccb48f.png)

从上表的对比可以看到，除了Grainy Blur因其模糊质感的特殊性获得了“一般”的模糊品质评级之外，另外九种模糊算法在模糊品质和稳定性这两方面都获得了不错的评级。这是因为给到足够的迭代次数，且不做RT的DownSample，他们都可以收敛到一个高品质的模糊质感。

最终的分化在于性能，这才是评判一种算法性价比是否高，能否广泛用于实时渲染的关键因素。其中，可以看到仅双重模糊（Dual Blur）和粒状模糊（Grainy Blur）两种算法，获得了高的性能评级。当然，这是针对标准的算法而言，其他八种算法如果进行进一步的性能优化，也能具有更佳的性能。

<br>

# 关于X-PostProcessing Libray

X-PostProcessing Libray，简称XPL，是本人开发的Unity引擎下的高品质开源后处理算法库，旨在提供业界主流的高品质后处理特效的完整解决方案，目前已完美支持Unity
Post-processing Stack v2。后续也将提供对Unity引擎URP/LWRP/HDRP的兼容支持。

【GitHub地址】https://github.com/QianMo/X-PostProcessing-Library

![](media/e230629ffe1b2da2325caec0a6401b96.jpg)

截止本文发表，目前已以开源形式放出了17种Blur算法的后处理实现。而随着后续更多内容的公开，X-PostProcessing Libray将成型为一个具有100+种后处理特效的高品质后处理开源算法库。

<br>

OK，下面我们开始正文。先从最热门，最为大众所熟知的高斯模糊开始。

<br>

# 一、高斯模糊（Gaussian Blur）


高斯模糊（Gaussian Blur），也叫高斯平滑（Gaussian smoothing），作为最经典的模糊算法，一度成为模糊算法的代名词。

![](media/1623d27dec6f63ee9790dda63a60b125.jpg)

高斯模糊在图像处理领域，通常用于减少图像噪声以及降低细节层次，以及对图像进行模糊，其视觉效果就像是经过一个半透明屏幕在观察图像。

从数字信号处理的角度看，图像模糊的本质一个过滤高频信号，保留低频信号的过程。过滤高频的信号的一个常见可选方法是卷积滤波。从这个角度来说，图像的高斯模糊过程即图像与正态分布做卷积。由于正态分布又叫作“高斯分布”，所以这项技术就叫作高斯模糊。而由于高斯函数的傅立叶变换是另外一个高斯函数，所以高斯模糊对于图像来说就是一个低通滤波器。

用于高斯模糊的高斯核（Gaussian Kernel）是一个正方形的像素阵列，其中像素值对应于2D高斯曲线的值。

![](media/3ce94d027109baba427440e515a99999.png)

图 一个典型的高斯核

图像中的每个像素被乘以高斯核，然后将所有这些值相加，得到输出图像中此处的值。

![](media/4556f53e98a5ef378e1fa1926bd496cb.jpg)

N维空间高斯模糊方程可以表示为：

![](media/657a242a1f1beb689df33a82d88b6d5c.png)

在二维空间定义为：

![](media/9b214c420a347a25ac11f6e4edb236ef.png)

其中r是模糊半径

![](media/4da60429ba567bef2df17b9d38b65585.png)

下图为高斯函数的3维图示：

![](media/3aedd63b1819614bb73a76196ceec706.jpg)


高斯模糊也可以在二维图像上对两个独立的一维空间分别进行计算，即满足线性可分（Linearly separable）。这也就是说，使用二维矩阵变换得到的效果也可以通过在水平方向进行一维高斯矩阵变换加上竖直方向的一维高斯矩阵变换得到。从计算的角度来看，这是一项有用的特性，因为这样只需要

![](media/a5f93c9c118c0b991fc6a988e5a23d9e.png)的计算复杂度，而原先的计算复杂度为![](media/2f47eace291ac9e6217c0e124c395b92.png)，其中M,N是需要进行滤波的图像的维数，m、n是滤波器的维数。

以下为一个Gaussian Kernel的线性分解过程：

![](media/4101dff5d82408c4c404b5d90f6ab22c.png)


下图很好的对Gaussian Kernel的线性可分进行了描述：

![](media/1ad248b2a04bfe2d3791a3c89cd88656.png)

实现方面，可以采用经过线性分解的高斯核的方案，且用乒乓RT交互blit的方法。高斯模糊对应的Fragment Shader的实现为：

	float4 FragGaussianBlur(v2f i): SV_Target
	{
		half4 color = float4(0, 0, 0, 0);
		
		color += 0.40 * SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv);
		color += 0.15 * SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv01.xy);
		color += 0.15 * SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv01.zw);
		color += 0.10 * SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv23.xy);
		color += 0.10 * SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv23.zw);
		color += 0.05 * SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv45.xy);
		color += 0.05 * SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv45.zw);
		
		return color;
	}


篇幅原因，在这里以及后文中，对应后处理的Runtime + Shader的完整的实现就不贴了，但会给出X-PostProcessing Libray中的完整实现链接。

**完整的高斯模糊Runtime + Shader实现可见**：
https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GaussianBlur



<br>
以下是开启高斯模糊后处理前后的对比图：

![](media/3386e01c8b105ef7e8bf8427f426155c.png)

![](media/8a70626a23b1640b2a0a1ba74304541e.png)

以及展示了BlurRadius为3，Iteration为6，RTDownScale为1的设置下，经过横纵线性分解的高斯模糊的渲染过程的动图：

![](media/ef3648c8276d045ffcd8b58b7b23e624.gif)

对模糊半径（Blur Radius）参数的调节，可以控制高斯模糊的程度：

![](media/f5668bf755f6b60c22c596220253d3e8.gif)


<br>

# 二、方框模糊（Box Blur）

方框模糊（Box Blur），又常被称为盒式模糊，其中所得到的图像中的每个像素具有的值等于其邻近的像素的输入图像中的平均值。和高斯模糊一样，Box Blur也是低通滤波器的一种形式。在图像处理领域，Box Blur通常用于近似高斯模糊。因为根据中心极限定理，重复应用Box Blur可以得到和高斯模糊非常近似的模糊表现。

可以将3 x 3的box blur的kernel表示为如下矩阵

![](media/072d5a18279fac83dd465dfe20ccbc27.png)

而2x2的box blur的kernel表示为如下矩阵：

![](media/b86eda5e0fb7b8c0643adf78adf98925.png)

Box Blur和高斯模糊的性质对比可见下图：

![](media/328bcaa82bbb793c5ab72adad9f92bf1.png)

图 3D结构，2D结构和示例矩阵对比（a）Box Blur（b）Gaussian Blur

以下是Box Blur的作用过程：

![](media/6c89d617142422ac6c7b6b9a4129d983.png)

Box Blur也是线性可分的，如有需要，也可以借助其此性质，如下所示：

![](media/03872365a0d205fe7d1d9c05cf982709.png)

另外box blur也有不少扩展与变体，比如Tent Blur（两次Box Blur）、Quadratic Blur（三次Box Blur）等，具体本文暂时就不展开了。

其中，Tent Blur也已在XPL中进行了实现，具体可见：[https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/TentBlur](https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/TentBlur)



以下是一个4 x 4的box filter的shader实现，low level optimize方面，可以采用乘加组合的书写方式，即MAD指令友好的形式，以在部分GPU上实现指令数的优化：

	half4 BoxFilter_4Tap(TEXTURE2D_ARGS(tex, samplerTex), float2 uv, float2 texelSize)
	{
		float4 d = texelSize.xyxy * float4(-1.0, -1.0, 1.0, 1.0);
		
		half4 s = 0;
		s = SAMPLE_TEXTURE2D(tex, samplerTex, uv + d.xy) * 0.25h;  // 1 MUL
		s += SAMPLE_TEXTURE2D(tex, samplerTex, uv + d.zy) * 0.25h; // 1 MAD
		s += SAMPLE_TEXTURE2D(tex, samplerTex, uv + d.xw) * 0.25h; // 1 MAD
		s += SAMPLE_TEXTURE2D(tex, samplerTex, uv + d.zw) * 0.25h; // 1 MAD
		
		return s;
	}

**完整的Runtime + Shader实现可见：** [https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/BoxBlur](https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/BoxBlur)

另外也可以考虑将uv计算放到vertex层。

Box Blur的渲染效果接近高斯模糊，但性价比并不高，需要较多的迭代次数才能达到高品质的模糊效果：

![](media/9fe9182c3ccb44b95c4feaf5060307cf.png)


以下是Box Blur在BlurRadius为1.6，Iteration为6，RTDownScale为1的设置下模糊过程的动图：

![](media/ce27882013b6c4c1c5e2fc6c4e2feaf8.gif)


<br>

# 三、Kawase模糊（Kawase Blur）


Kawase Blur于Masaki Kawase 在GDC2003的分享《Frame Buffer Postprocessing Effects in DOUBLE-S.T.E.A.L (Wreckless)》中提出。Kawase Blur最初用于Bloom后处理特效，但其可以推广作为专门的模糊算法使用，且在模糊外观表现上与高斯模糊非常接近。
Kawase Blur的思路是对距离当前像素越来越远的地方对四个角进行采样，且在两个大小相等的纹理之间进行乒乓式的blit。创新点在于，采用了随迭代次数移动的blur kernel，而不是类似高斯模糊，或box blur一样从头到尾固定的blur kernel。

![](media/8833561d489ea70dc3e4a45d54e86c24.png)

![](media/7e04eb8d9007d9e91f5f6fe4e7770759.png)

实践数据表明，在相似的模糊表现下，Kawase Blur比经过优化的高斯模糊的性能约快1.5倍到3倍。

具体思路是在runtime层，基于当前迭代次数，对每次模糊的半径进行设置，而Shader层实现一个4 tap的Kawase Filter即可：

	half4 KawaseBlur(TEXTURE2D_ARGS(tex, samplerTex), float2 uv, float2 texelSize, half pixelOffset)
	{
		half4 o = 0;
		o += SAMPLE_TEXTURE2D(tex, samplerTex, uv + float2(pixelOffset +0.5, pixelOffset +0.5) * texelSize); 
		o += SAMPLE_TEXTURE2D(tex, samplerTex, uv + float2(-pixelOffset -0.5, pixelOffset +0.5) * texelSize); 
		o += SAMPLE_TEXTURE2D(tex, samplerTex, uv + float2(-pixelOffset -0.5, -pixelOffset -0.5) * texelSize); 
		o += SAMPLE_TEXTURE2D(tex, samplerTex, uv + float2(pixelOffset +0.5, -pixelOffset -0.5) * texelSize); 
		return o * 0.25;
	}

**完整的Runtime + Shader实现可见：** https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/KawaseBlur

Kawase Blur渲染效果接近高斯模糊，但具有更好的性能：

![](media/9baae89bbc953dd6431475a91df4d322.png)

以下是在初始RT DownScale为1、Iteration为6的设置下，Dual Kawase Blur的渲染步骤：

![](media/KawaseBlur-1.gif)

同样，对模糊半径（Blur Radius）参数的调节，可以控制Kawase模糊的程度：

![](media/KawaseBlur-2.gif)


<br>

# 四、双重模糊（Dual Blur）


Dual Kawase Blur，简称Dual Blur，是SIGGRAPH 2015上ARM团队提出的一种衍生自Kawase Blur的模糊算法。其由两种不同的Blur Kernel构成，如下图所示。

![](media/dbd46f6ebbe1a64e080f2667b55cdd8e.png)

相较于Kawase Blur在两个大小相等的纹理之间进行乒乓blit的的思路，Dual Kawase Blur的核心思路在于blit过程中进行降采样和升采样,即对RT进行了降采样以及升采样。如下图所示：

![](media/2ebf4981ecdc7d4c81bf5c2f02edfb31.png)

由于灵活的升降采样带来了blit RT所需计算量的减少等原因， Dual Kawase Blur相较于上文中提到的Gauusian Blur、Box Blur、Kawase Blur等Blur算法,有更好的性能，下图是相同条件下的性能对比。

![](media/c995ed9cebd5b0e2760b0556f36b2149.png)

可以看到，Dual Kawase Blur具有最佳的性能表现。

为了带来更好的性能表现，可以将uv的偏移放在Vert Shader中进行，而Fragment Shader中基本上仅进行采样即可。

Dual Kawase Blur的Fragment Shader实现为：

	
	half4 Frag_DownSample(v2f_DownSample i): SV_Target
	{
		half4 sum = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv) * 4;
		sum += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv01.xy);
		sum += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv01.zw);
		sum += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv23.xy);
		sum += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv23.zw);
		
		return sum * 0.125;
	}

	half4 Frag_UpSample(v2f_UpSample i): SV_Target
	{
		half4 sum = 0;
		sum += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv01.xy);
		sum += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv01.zw) * 2;
		sum += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv23.xy);
		sum += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv23.zw) * 2;
		sum += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv45.xy);
		sum += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv45.zw) * 2;
		sum += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv67.xy);
		sum += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.uv67.zw) * 2;
		
		return sum * 0.0833;
	}


**完整的Runtime + Shader实现可见：** https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/DualKawaseBlur


XPL中也提供了启发自Dual Kawase Blur的Dual Gaussian Blur、Dual Box Blur、Dual Tent Blur的实现。

- **Dual Gaussian Blur**：https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/DualGaussianBlur

- **Dual Box Blur**：https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/DualBoxBlur

- **Dual Tent Blur**：https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/DualTentBlur



Dual Kawase Blur最终的模糊效果截图如下，可以看到其与高斯模糊的模糊表现也非常接近：

![](media/ef952edc96ab383fa45bd443b24d84c4.png)

以下是在初始RT DownScale为1、Iteration为5的设置下，Dual Kawase Blur的渲染步骤：

![](media/734619e4f5594f567b6009d25ebb7c60.gif)

同样，对模糊半径（Blur Radius）参数的调节，可以控制Dual Kawase Blur模糊的程度：

![](media/7c81e8b40e8c86a286003012a2ef7eea.gif)


<br>

# 五、散景模糊（Bokeh Blur）


散景（Bokeh）亦称焦外成像，是一个摄影名词，一般表示在景深较浅的摄影成像中，落在景深以外的画面，会有逐渐产生松散模糊的效果。散景效果有可能因为摄影技巧或光圈孔形状的不同，而产生各有差异的效果。例如镜头本身的光圈叶片数不同（所形成的光圈孔形状不同），会让圆形散景呈现不同的多角形变化。此外，反射式镜头焦外的散景，会呈现独有的甜甜圈形状。

![](media/6e9680adbf5220b3abb9d20bdede07f3.jpg)

图 不同相机参数下得到的不同散景模糊（Bokeh Blur）

散景（Bokeh）在摄影学中被称为焦外成像，而在光学上被称为Circle of Confusion, CoC（弥散圆/散光圈/散射圆盘 ），即下图橙色Image Plane 中的蓝色C所示区域。由于不同的物距（物体到镜头的距离）投影到镜头所形成的焦点不同，但Image Plane 只能放在某个点上，所以就形成了Circle of Confusion, CoC（弥散圆）。

![](media/96f4ff7c533d389d523cddea4a62f2e6.jpg)

图 散景（Bokeh）成因 （图片来自GPU Gems 1）

![](media/b5b10ba32bec1e755e541cc4de8d015e.jpg)

图 散景（Bokeh）大小不同的成因，即Circle of Confusion,
CoC（弥散圆）的大小与人眼分辨率不同的区域。

镜头本身的光圈叶片数不同（所形成的光圈孔形状不同），会让散景形状呈现不同的多角形变化。从最初的多边形，过渡到最终的圆形。

![](media/d6fa04bb9b48e400b803adf63f42416a.jpg)

图 不同光圈叶片数的镜头，决定了不同的散景形状

![](media/f07c1990dbfce8bd3da82617de62c8f5.jpg)

图 不同光圈叶片数的镜头，决定了不同的散景形状

![](media/89eb65f434ae50051cb07cc3c802ca7d.jpg)

图 不同光圈数值的镜头形态，决定了不同的散景形态

从上图可以看出， 由于光圈大小和叶片数量的不同，散景（Bokeh）的形态各异。

在图形学领域模拟散景（Bokeh）的方法有很多，本文将以最标准的圆形散景为例，采用Golden angle(<https://en.wikipedia.org/wiki/Golden_angle>)的思路进行散景模糊（Bokeh Blur）算法的实现。

具体而言，算法思路是基于对大量离散螺旋型（spiral）分布的点的渲染，来模拟出圆形Bokeh的形状。

![](media/7f0e8d10c7e89fddba1ea3249fd2883a.png)

核心的Shader算法实现为：

	half4 BokehBlur(VaryingsDefault i)
	{
		half2x2 rot = half2x2(_GoldenRot);
		half4 accumulator = 0.0;
		half4 divisor = 0.0;

		half r = 1.0;
		half2 angle = half2(0.0, _Radius);

		for (int j = 0; j < _Iteration; j++)
		{
			r += 1.0 / r;
			angle = mul(rot, angle);
			half4 bokeh = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, float2(i.texcoord + _PixelSize * (r - 1.0) * angle));
			accumulator += bokeh * bokeh;
			divisor += bokeh;
		}
		return accumulator / divisor;
	}

即对于每一次迭代，让采样uv旋转一个角度，经过足够次数的迭代后，众多以圆形分散开来的点，将一起组成合适的Bokeh形状。

**完整的Runtime + Shader实现可见：**

https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/BokehBlur


下图为最终实现的效果图：

![](media/ba1760758cd9f00e7b65d12ecf8b7c8a.jpg)

不同模糊半径（Blur Radius）变化，可以控制不同的Bokeh半径的变化：

![](media/d920a7ba9b40b5511769db942c469371.gif)



<br>

# 六、移轴模糊 （Tilt Shift Blur）


移轴模糊（Tilt Shift Blur），又称镜头模糊（Lens Blur） ，是源自摄影领域的一种模糊算法。

在摄影领域，移轴摄影（Tilt-Shift
Photography）泛指利用移轴镜头创作的作品，所拍摄的照片效果就像是缩微模型一样，非常特别。移轴镜头的作用，本来主要是用来修正以普通广角镜拍照时所产生出的透视问题，但后来却被广泛利用来创作变化景深聚焦点位置的摄影作品。移轴镜摄影是将真实世界拍成像假的一样，使照片能够充分表现出“人造都市”的感觉。

![](media/0aca0e7a74b644d1a1232d7311ae8473.jpg)

图 移轴摄影作品

在后处理渲染中进行移轴摄影的模拟，可以采用Grident uv算法控制画面区域模糊强度，配合全屏模糊算法的方式来实现。

采用Grident uv算法控制画面区域模糊强度的Shader核心实现如下：

	float TiltShiftMask(float2 uv)
	{
		float centerY = uv.y * 2.0 - 1.0 + _Offset; // [0,1] -> [-1,1]
		return pow(abs(centerY * _Area), _Spread);
	}

得到的屏幕模糊强度的mask图如下：

![](media/b505f4fd7a72fc5b8b6b7be0b78229c8.png)

接着，配合合适的全屏图像模糊算法，如Bokeh Blur，便可以营造出移轴摄影的画面感：

![](media/28030aa3848315f385c9b9cb06807485.png)

**完整的Runtime + Shader实现可见：**
https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/TiltShiftBlurV2


**XPL中也提供了另一个版本的实现：**
https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/TiltShiftBlur


对模糊半径（Blur Radius）参数的调节，可以用于控制移轴Bokeh半径的变化：

![](media/736728074657aa9df6a2ec3d00a2a65a.gif)

在一定的区域平滑度（Area Smooth）设置下，调节区域尺寸（Area Size）可以控制移轴模糊区域的变化：

![](media/9b9c38f9730affe157566310955b80a3.gif)

<br>

# 七、光圈模糊（Iris Blur）


光圈模糊（Iris Blur）是Photoshop CS6中新增的功能，用于模拟浅景深的效果。

可以根据用户不同的输入参数，将普通照片模拟出景深以及散景的效果。（PS: Photoshop中也同样有Tilf-Shift Blur功能）

![](media/6216cbf3cdcb7ba42679545ca664e96a.jpg)

图 Photoshop中的光圈模糊（Iris Blur）功能

![](media/a6b05dac4ef3d1d4da0efed0a793baec.jpg)

Photoshop中的光圈模糊（Iris Blur）功能

在后处理渲染中进行光圈模糊的模拟，可以采用一个径向的Grident uv算法沿轴心控制画面区域模糊强度，并配合全屏模糊算法的方式来实现。

采用径向Grident uv算法控制画面区域模糊强度的Shader核心实现如下：

	float IrisMask(float2 uv)
	{
		float2 center = uv * 2.0 - 1.0 + _Offset; // [0,1] -> [-1,1] 
		return dot(center, center) * _AreaSize;
	}
	

得到的屏幕模糊强度的mask图如下：

![](media/357c5fae13a41a96cabc2c8e5cd27d20.png)

同样，配合合适的全屏图像模糊算法，如Bokeh Blur，便可以营造出移轴摄影的画面感：

![](media/ea82e6cf88735637243708803e393275.png)

**光圈模糊（Iris Blur）完整的Runtime + Shader实现可见：**
https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/IrisBlurV2



**XPL中也提供了另一个版本的实现：**
https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/IrisBlur


对模糊半径（Blur Radius）参数的调节，可以用于控制光圈Bokeh半径的变化：

![](media/9d7e3b7a0d89a504390557f88541961e.gif)

同样，调节区域尺寸（Area Size）可以控制光圈模糊区域的变化：

![](media/1eda0da557b6d9808c3f966b0f629490.gif)



<br>

# 八、粒状模糊（Grainy Blur）


粒状模糊（Grainy Blur）是一种低成本的模糊方法，在单pass下即可有合适的模糊表现，性能出色，且其模糊质感有点类似在画面上蒙了一层细碎的冰霜。

![](media/ef8abce69b1e9f7987f0e9d203d9e690.png)

其思路是基于随机uv进行采样的抖动，以对粗粒度的模糊进行模拟。核心算法的Shader实现如下：

	float Rand(float2 n)
	{
		return sin(dot(n, half2(1233.224, 1743.335)));
	}
	
	half4 GrainyBlur(VaryingsDefault i)
	{
		half2 randomOffset = float2(0.0, 0.0);
		half4 finalColor = half4(0.0, 0.0, 0.0, 0.0);
		float random = Rand(i.texcoord);
		
		for (int k = 0; k < int(_Iteration); k ++)
		{
			random = frac(43758.5453 * random + 0.61432);;
			randomOffset.x = (random - 0.5) * 2.0;
			random = frac(43758.5453 * random + 0.61432);
			randomOffset.y = (random - 0.5) * 2.0;
			
			finalColor += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, half2(i.texcoord + randomOffset * _BlurRadius));
		}
		return finalColor / _Iteration;
	}

**粒状模糊（Grainy Blur）完整的Runtime + Shader实现可见：**
https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GrainyBlur

这边是一个模糊半径更大的粒状模糊（Grainy Blur）的渲染效果：
![](media/61.1.png)

对模糊半径（Blur Radius）参数的调节，也可以控制粒状模糊的程度：

![](media/0c68c66628bfa24d6a4a60b291bf364b.gif)

<br>

# 九、径向模糊（Radial Blur）


径向模糊（Radial Blur）可以给画面带来很好的速度感，是各类游戏中后处理的常客，也常用于Sun Shaft等后处理特效中作为光线投射的模拟。

![](media/870224e670b3157d7082d9e37f468c8d.png)

径向模糊的原理比较直接，首先选取一个径向轴心（Radial
Center），然后将每一个采样点的uv基于此径向轴心进行偏移（offset），并进行一定次数的迭代采样，最终将采样得到的RGB值累加，并除以迭代次数。

其核心算法的Shader代码实现如下：

	half4 RadialBlur(VaryingsDefault i)
	{
		float2 blurVector = (_RadialCenter - i.texcoord.xy) * _BlurRadius;
		
		half4 acumulateColor = half4(0, 0, 0, 0);
		
		[unroll(30)]
		for (int j = 0; j < _Iteration; j ++)
		{
			acumulateColor += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.texcoord);
			i.texcoord.xy += blurVector;
		}
		
		return acumulateColor / _Iteration;
	}

**完整的Runtime + Shader实现可见：**
https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/RadialBlur



另外需要注意的是，如果迭代次数不够多，而又设置了较高的Offset值，则会在屏幕四周出现较为明显的折痕，但一般情况下都还可以接受：

![](media/7f0736f2cb5251bb41477f277d252bee.png)

同样，对模糊半径（Blur Radius）参数的调节，可以控制模糊的程度：

![](media/06f1d0823ec0a797fe4999778ade5a59.gif)

<br>

# 十、方向模糊（Directional Blur）


方向模糊（Directional Blur）可以看做是径向模糊（Radial Blur）的一个变体。其主要思路是传入一个角度，然后在runtime层计算出对应的矢量方向：

	float sinVal = (Mathf.Sin(settings.Angle) * settings.BlurRadius * 0.05f) / settings.Iteration;
	float cosVal = (Mathf.Cos(settings.Angle) * settings.BlurRadius * 0.05f) / settings.Iteration;
	sheet.properties.SetVector(ShaderIDs.Direction, new Vector2(sinVal, cosVal));

然后，在Shader层，将每一个采样点的uv基于此方向进行正负两次偏移（offset），接着进行一定次数的迭代采样，最终将采样得到的RGB值累加，并除以迭代次数，得到最终的输出。

核心算法的Shader代码实现如下：

	half4 DirectionalBlur(VaryingsDefault i)
	{
		half4 color = half4(0.0, 0.0, 0.0, 0.0);

		for (int k = -_Iteration; k < _Iteration; k++)
		{
			color += SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.texcoord - _Direction * k);
		}
		half4 finalColor = color / (_Iteration * 2.0);

		return finalColor;
	}


**完整的Runtime + Shader实现可见：**
https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/DirectionalBlur


方向模糊后处理的渲染效果如下：
![](media/7623f49a2849b081d674afffa3201fee.png)

同样，对模糊半径（Blur Radius）参数的调节，可以控制模糊的程度：

![](media/45bee7e1482fd0ea1a60ed71c0e5c854.gif)

而调节Angle参数，可以控制模糊旋转的方向：

![](media/bfc435caf5f6681f35a2bf9718a57c1e.gif)



<br>

# 总结


本文开头已经提到，模糊算法在后处理渲染领域占据着非常重要的地位。很多产品级后处理的实现，都会直接或间接依赖于一种或多种图像模糊算法。后处理管线中所采用的模糊算法的优劣，决定了产品最终的渲染品质和消耗的性能大小。

让我们重新看一下这十种模糊算法的横向对比，相信此时，大家对这十种模糊算法已经有了更全面的理解，以及自己的选择。

![](media/b82ba2aaa60f290da438450a86ccb48f.png)

The End.


<br>

# Reference

[1] GDC 2003, Frame Buffer Postprocessing Effects in DOUBLE-S.T.E.A.L (Wreckless)

[2] SIGGRAPH 2015, Bandwidth-Efficient Rendering

[3] SIGGRAPH 2001，Fast Image Convolutions

[4] Gonzalez R C, Woods R E. Digital image processing, 4th edn. ISBN: 9780133356724[J]. 2017.

[5] https://computergraphics.stackexchange.com/questions/39/how-is-gaussian-blur-implemented

[6] http://datahacker.rs/opencv-average-and-gaussian-filter/

[7] https://towardsdatascience.com/image-processing-class-egbe443-4-filters-aa1037676130


[8] https://www.zhihu.com/question/20813608/answer/261346592

[9] https://en.wikipedia.org/wiki/Box_blur

[10] https://en.wikipedia.org/wiki/Gaussian_blur

[11] http://blog.marmakoide.org/?p=1

[12] https://developer.nvidia.com/gpugems/gpugems/part-iv-image-processing/chapter-23-depth-field-survey-techniques

[13] https://www.flickr.com/photos/valpil58/9425151785

[14] https://en.wikipedia.org/wiki/Bokeh

[15] https://commons.wikimedia.org/wiki/File:Lenses_with_different_apertures.jpg

[16] https://improvephotography.com/29529/aperture-blades-many-best/

[17] https://www.webucator.com/how-to/how-apply-an-iris-blur-effect-adobe-photoshop.cfm

[18] 题图来自：https://www.artstation.com/artwork/Z5RkbZ


```

`Content/高品质后处理：十种故障艺术（Glitch Art）算法的总结与实现/README.md`:

```md
![](media/4a7aa22e312d1acf94773fd4aa743003.png)


# 高品质后处理：十种故障艺术（Glitch Art）算法的总结与实现

<br>

故障艺术（Glitch Art），作为赛博朋克（Cyberpunk）艺术风格的核心元素之一，是一种是将数字设备的软硬件故障引起的破碎变形图像，经过艺术加工而成的一种先锋视觉艺术表现形式。近年来，故障艺术已经成为了赛博朋克风格的电影和游戏作品中主要的艺术风格之一。

![](media/c51d84acf7377b3166219d313177f50d.gif)

图 《赛博朋克 2077》 带有强烈故障艺术风格的Logo @ CD Projekt @2019 E3展

<br>

而本文，对十种主流故障艺术（Glitch Art）系列后处理算法的原理和实现方式进行了总结，对故障艺术风格的算法实现要点进行了提炼，并提供了对应算法在Unity引擎下的一个或多个版本的实现源码。

这十种故障艺术（Glitch Art）后处理特效分别为：

1. RGB颜色分离故障（RGB Split Glitch）

2. 错位图块故障（Image Block Glitch）

3. 错位线条故障（Line Block Glitch）

4. 图块抖动故障（Tile Jitter Glitch）

5. 扫描线抖动故障（Scan Line Jitter Glitch）

6. 数字条纹故障（Digital Stripe Glitch）

7. 模拟噪点故障（Analog Noise Glitch）

8. 屏幕跳跃故障（Screen Jump Glitch）

9. 屏幕抖动故障（Screen Shake Glitch）

10. 波动抖动故障（Wave Jitter Glitch）


<br>

# 关于XPL : Unity引擎的高品质后处理库


另外，本文涉及的十种故障艺术（Glitch Art）后处理的实现源码，都收录于本人开源的后处理算法库XPL中。

X-PostProcessing Libray，简称XPL，是本人开发的Unity引擎下的高品质开源后处理算法库，旨在提供业界主流的高品质后处理特效的完整解决方案，目前已完美支持Unity Post-processing Stack v2。后续也将提供对Unity引擎URP/LWRP/HDRP的兼容支持。

**【GitHub地址】**： <https://github.com/QianMo/X-PostProcessing-Library>

![](media/debda36941aa6564c6b8b8b38ef9d318.jpg)

截止本文发表，目前已以开源的形式放出了17种图像模糊型后处理算法、10种像素化型后处理算法、9种边缘检测型后处理算法、17种故障艺术型后处理算法。而随着后续更多内容的公开，X-PostProcessing
Libray将成型为一个具有100+种后处理特效的高品质后处理开源算法库。

<br>

在开始正文之前，不妨先简单认识一下赛博朋克与故障艺术这两种带有强烈科技感的艺术风格,以及他们在电影和游戏行业中的应用情况。


<br>

# 零、赛博朋克与故障艺术

**赛博朋克（Cyberpunk）**，最早起源于上世纪六七十年代，作为未来主义科幻小说/电影/游戏的一个品类，核心理念在于低端生活与高等科技的结合。人工智能、虚拟现实、基因工程、黑客技术、反乌托邦、电脑生化、都市与贫民窟、故障艺术、霓虹灯等都是赛博朋克的主流艺术表现形式。

**故障艺术（Glitch Art）**，一种是将数字设备的软硬件故障引起的破碎变形图像，经过艺术加工而成的一种先锋视觉艺术表现。故障艺术的艺术表现核心形式在于图像的失真、破碎、错位、形变，以及颜色的失真、错位，并伴有条纹图形的辅助。

无论是电影领域的《黑客帝国》、《银翼杀手》、《银翼杀手2077》、《攻壳机动队》等作品，还是游戏领域的《赛博朋克2077》，《杀出重围》等作品，都带有非常浓厚的赛博朋克风格。而在这些作品中，都能找到故障艺术的身影。

![](media/ea3b9abb2228f18b6729dfb7a03727c2.jpg)

图 电影《攻壳机动队》中的故障艺术表现形式

![](media/79dbf132f67246692cb65dfecbea2d37.jpg)

图 电影《银翼杀手2049》中的故障艺术表现形式

![](media/d1f20ccdcc6028d9eccb1afd8a6b5c0c.jpg)

图《赛博朋克2077》中的故障艺术表现形式 @ CD Projekt

![](media/c064eeb45ec2b0edf941e941a430e2c1.jpg)

图 《看门狗2》中的故障艺术表现形式 @ Ubisoft

这里也放一段包含多种故障艺术（Glitch Art）元素的《赛博朋克2077》 2019 E3展预告片段：

【《赛博朋克2077》 2019 E3展预告片段】 <https://www.youtube.com/watch?v=qIcTM8WXFjk>


以及一个发布于2013年的《赛博朋克2077》早期宣传片：


【《赛博朋克2077》 2013预告片】 <https://www.youtube.com/watch?v=P99qJGrPNLs>


<br>
<br>

OK，下面开始正文，对10种主流故障艺术（Glitch Art）后处理的算法以及原理进行总结。



<br>

# 一、RGB颜色分离故障（RGB Split Glitch）


RGB颜色分离故障（RGB Split Glitch），也称颜色偏移故障（Color Shift Glitch），是故障艺术中比较常见的表达形式之一。例如，抖音短视频App的Icon，即是RGB颜色分离故障艺术风格影响下的作品，给整体产品带来了潮流与年轻的气息：

![](media/989397ce8ae4169220d381b1b6466995.jpg)

RGB颜色分离故障（RGB Split Glitch），实现算法的主要要点在于红绿蓝三个通道采用不同的uv偏移值进行分别采样。一般而言，会在RGB三个颜色通道中，选取一个通道采用原始uv值，另外两个通道进行uv抖动后再进行采样。一个经过性能优化的实现版本Shader代码如下：


	float randomNoise(float x, float y)
	{
		return frac(sin(dot(float2(x, y), float2(12.9898, 78.233))) * 43758.5453);
	}

	half4 Frag_Horizontal(VaryingsDefault i) : SV_Target
	{
		float splitAmount = _Indensity * randomNoise(_TimeX, 2);

		half4 ColorR = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, float2(i.texcoord.x + splitAmount, i.texcoord.y));
		half4 ColorG = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.texcoord);
		half4 ColorB = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, float2(i.texcoord.x - splitAmount, i.texcoord.y));

		return half4(ColorR.r, ColorG.g, ColorB.b, 1);
	}


上述代码中的randomNoise函数在之前的文章[《高品质后处理：十种图像模糊算法的总结与实现》](https://zhuanlan.zhihu.com/p/125744132)的粒状模糊（Grainy Blur）中有提到一个简化版的实现。本文在则采用了基于frac方法（返回输入数值的小数部分）和三角函数，配合dot方法的封装实现。

上述代码，得到的渲染表现如下：

![](media/c7347fc3eab1a6adbdcdcccf1dd0bd51.gif)

详细实现源码可见：

<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchRGBSplitV4>

另外，可以基于三角函数和pow方法控制抖动的间隔、幅度，以及抖动的曲线：

	half4 Frag_Horizontal(VaryingsDefault i): SV_Target
	{
		float splitAmout = (1.0 + sin(_TimeX * 6.0)) * 0.5;
		splitAmout *= 1.0 + sin(_TimeX * 16.0) * 0.5;
		splitAmout *= 1.0 + sin(_TimeX * 19.0) * 0.5;
		splitAmout *= 1.0 + sin(_TimeX * 27.0) * 0.5;
		splitAmout = pow(splitAmout, _Amplitude);
		splitAmout *= (0.05 * _Amount);
		
		half3 finalColor;
		finalColor.r = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, fixed2(i.texcoord.x + splitAmout, i.texcoord.y)).r;
		finalColor.g = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.texcoord).g;
		finalColor.b = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, fixed2(i.texcoord.x - splitAmout, i.texcoord.y)).b;
		
		finalColor *= (1.0 - splitAmout * 0.5);
		
		return half4(finalColor, 1.0);
	}


得到的渲染表现如下：

![](media/97fa0c1b7f14497c48ae9574e7d7ea8f.gif)

此版本的实现源码可见：

<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchRGBSplitV2>

另外，在XPL（X-PostProcessing-Library）中供实现了5种不同版本的Glitch RGB
Split后处理特效，以满足不同情形下RGB颜色抖动风格的需要。除了上文提到了两种，剩余三种的更多细节，篇幅原因这里就不展开了。以下整理了一个汇总列表，若有需要，可以直接转到XPL查看具体渲染表现以及源码:

-  **GlitchRGBSplitV1：**
<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchRGBSplit>

-  **GlitchRGBSplitV2:**
<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchRGBSplitV2>

-  **GlitchRGBSplitV3:**
<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchRGBSplitV3>

-  **GlitchRGBSplitV4:**
<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchRGBSplitV4>

-  **GlitchRGBSplitV5:**
<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchRGBSplitV5>

其中GlitchRGBSplitV1和GlitchRGBSplitV3具有相对而言较丰富可调参数：

![](media/42ad5db0ab8bdd8c04d349705cdfec70.png)

![](media/400d557b63b1d983e7c046704a8f7e1b.png)

以下是其中的一些效果图：

![](media/c04efc5ac94afa5172c6ce4b0275d1f2.gif)

![](media/48d2fefbedfb9c84975b587d6368824c.gif)



<br>


# 二、错位图块故障（Image Block Glitch）


![](media/b68c95b411b036f2d3cb19fae39c117b.png)

错位图块故障（Image Block Glitch）的核心要点在于生成随机强度且横纵交错的图块，随后基于图块的强度，进行uv的抖动采样，并可以加上RGB Split等元素提升渲染表现。

<br>

## 2.1 基础版本的错位图块故障（Image Block Glitch）

对于基础版本的实现，第一步，基于uv和噪声函数生成方格块。可以使用floor方法（对输入参数向下取整）以及低成本的噪声生成函数randomNoise进行实现，代码仅需一句：

	half2 block = randomNoise(floor(i.texcoord * _BlockSize));

基于这句代码可以生成随机强度的均匀Block图块：

![](media/a0ff7e1c447a3416e1466f75b1ca0a9b.gif)



第二步，基于第一步得到的均匀Block图块强度值做强度的二次筛选，增加随机性，代码如下：

half displaceNoise = pow(block.x, 8.0) * pow(block.x, 3.0);

得到的图块强度值如下：

![](media/8ee13659a31cf8b1afff7f223b79ae2e.gif)



第三步，将经过强度二次筛选的Block图块强度值，作为噪声强度的系数，分别对G和B颜色通道进行采样。实现如下：

	half ColorR = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.texcoord).r;
	half ColorG = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.texcoord + float2(displaceNoise * 0.05 * randomNoise(7.0), 0.0)).g;
	half ColorB = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.texcoord - float2(displaceNoise * 0.05 * randomNoise(13.0), 0.0)).b;

	return half4(ColorR, ColorG, ColorB, 1.0);


可以得到如下基础的错位图块故障（Image Block Glitch）的渲染表现：

![](media/d6248833de3a7111dbca499cdc955df9.gif)


以上基础版本的错位图块故障（Image Block Glitch）实现的完整源代码可见：

<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchImageBlockV3>


<br>

## 2.2 结合RGB Split的错位图块故障（Image Block Glitch）

另外，也可以加上RGB Split的元素，得到更丰富的渲染表现，实现代码如下：

	inline float randomNoise(float2 seed)
	{
		return frac(sin(dot(seed * floor(_Time.y * _Speed), float2(17.13, 3.71))) * 43758.5453123);
	}

	inline float randomNoise(float seed)
	{
		return randomNoise(float2(seed, 1.0));
	}

	half4 Frag(VaryingsDefault i) : SV_Target
	{
		half2 block = randomNoise(floor(i.texcoord * _BlockSize));

		float displaceNoise = pow(block.x, 8.0) * pow(block.x, 3.0);
		float splitRGBNoise = pow(randomNoise(7.2341), 17.0);
		float offsetX = displaceNoise - splitRGBNoise * _MaxRGBSplitX;
		float offsetY = displaceNoise - splitRGBNoise * _MaxRGBSplitY;

		float noiseX = 0.05 * randomNoise(13.0);
		float noiseY = 0.05 * randomNoise(7.0);
		float2 offset = float2(offsetX * noiseX, offsetY* noiseY);

		half4 colorR = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.texcoord);
		half4 colorG = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.texcoord + offset);
		half4 colorB = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.texcoord - offset);

		return half4(colorR.r , colorG.g, colorB.z, (colorR.a + colorG.a + colorB.a));
	}


对应的渲染表现如下：

![](media/ce0f22d2a51d470b499b27bb3da10d3a.gif)

实现的完整源代码可见：

<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchImageBlockV4>

<br>

## 2.3 进阶版的错位图块故障（Image Block Glitch）

进阶版的Image Block Glitch，核心要点在于双层blockLayer的生成，以及配合噪声生成函数randomNoise进行双层强度的二次筛选，对应的实现代码如下：

		float2 blockLayer1 = floor(uv * float2(_BlockLayer1_U, _BlockLayer1_V));
		float2 blockLayer2 = floor(uv * float2(_BlockLayer2_U, _BlockLayer2_V));
		
		float lineNoise1 = pow(randomNoise(blockLayer1), _BlockLayer1_Indensity);
		float lineNoise2 = pow(randomNoise(blockLayer2), _BlockLayer2_Indensity);
		float RGBSplitNoise = pow(randomNoise(5.1379), 7.1) * _RGBSplit_Indensity;
		float lineNoise = lineNoise1 * lineNoise2 * _Offset  - RGBSplitNoise;


上述代码可以得到更加丰富的Block图块强度：

![](media/633fcad89870e8858a2bcdadb33ebde4.gif)

最后，基于此Block强度进行RGB通道的分别采样，可以得到更加多样的错位图块故障（Image Block Glitch）渲染表现：

![](media/1791d0b28d6191a45c1235a39463ac5e.gif)

上述完整的实现代码可见：

<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchImageBlock>

此版本的Image Block Glitch参数较为丰富，可以根据需要，调出各种风格的Image Block渲染表现：

![](media/0f012c30e78082558166ceedbfeda729.png)

同样，在XPL（X-PostProcessing-Library）中分别实现了4种不同版本的Glitch Image Block后处理特效，以满足不同情形下的需要。部分算法的源码实现链接上文中已经有贴出一部分，这里是一个汇总列表:

- **Glitch Image Block V1**：<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchImageBlock>

- **Glitch Image Block V2**：<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchImageBlockV2>

- **Glitch Image Block V3**：<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchImageBlockV3>

- **Glitch Image Block V4**：<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchImageBlockV4>




<br>


# 三、错位线条故障（Line Block Glitch）


错位线条故障（Line Block Glitch）具有较强的表现力，在Glitch系列特效中的出镜率也较高。

![](media/8274a6410b525ed3240c342671c073c0.png)

![](media/4b96ce25c89d300d3bb7245bd8af2eec.gif)

该算法的实现思路在于随机宽度线条的生成。我们一步一步来，先从生成均匀宽度线条开始：

    float trunc(float x, float num_levels)
    {
        return floor(x * num_levels) / num_levels;
    }

    //生成随机强度梯度线条
    float truncTime = trunc(_TimeX, 4.0);		
    float uv_trunc = randomNoise(trunc(uv.yy, float2(8, 8)) + 100.0 * truncTime);



基于trunc函数以及randomNoise函数，配合上述调用代码，即可得到如下均匀宽度线条：

![](media/53a92c5ea340114cf8c11fb523c02180.gif)

接着，使用如下代码，将均匀渐变线条转为随机梯度的等宽线条：

	float uv_randomTrunc = 6.0 * trunc(_TimeX, 24.0 * uv_trunc);

![](media/2ef9438939a81cafa257cffbdbe493a9.gif)

然后，将随机梯度的等宽线条，经过多次randomNoise操作，转换为随机梯度的非等宽线条：

    //生成随机梯度的非等宽线条
    float blockLine_random = 0.5 * randomNoise(trunc(uv.yy + uv_randomTrunc, float2(8 * _LinesWidth, 8 * _LinesWidth)));
    blockLine_random += 0.5 * randomNoise(trunc(uv.yy + uv_randomTrunc, float2(7, 7)));
    blockLine_random = blockLine_random * 2.0 - 1.0;	
    blockLine_random = sign(blockLine_random) * saturate((abs(blockLine_random) - _Amount) / (0.4));
    blockLine_random = lerp(0, blockLine_random, _Offset);	

可以得到如下的渲染表现：

![](media/1689ba7c27383f6db417dd35b764cdf3.gif)


接着，通过随机梯度的非等宽线条，去抖动uv采样生成源色调的blockLine Glitch：

		// 生成源色调的blockLine Glitch
		float2 uv_blockLine = uv;
		uv_blockLine = saturate(uv_blockLine + float2(0.1 * blockLine_random, 0));
		float4 blockLineColor = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, abs(uv_blockLine));

对应的渲染表现如下：


![](media/4d170f6ed0453120c2f5b3a3b7b4c1a2.gif)

最终，将RGB颜色转换到YUV空间，进行色度（Chrominance）和浓度（Chroma）的偏移，得到最终的渲染表现：

	    // 将RGB转到YUV空间，并做色调偏移
		// RGB -> YUV
		float3 blockLineColor_yuv = rgb2yuv(blockLineColor.rgb);
		// adjust Chrominance | 色度
		blockLineColor_yuv.y /= 1.0 - 3.0 * abs(blockLine_random) * saturate(0.5 - blockLine_random);
		// adjust Chroma | 浓度
		blockLineColor_yuv.z += 0.125 * blockLine_random * saturate(blockLine_random - 0.5);
		float3 blockLineColor_rgb = yuv2rgb(blockLineColor_yuv);

		// 与源场景图进行混合
		float4 sceneColor = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, i.texcoord);
		return lerp(sceneColor, float4(blockLineColor_rgb, blockLineColor.a), _Alpha);



最终的渲染表现如下：

![](media/4b96ce25c89d300d3bb7245bd8af2eec.gif)

除了水平方向的Line Block，竖直方向的表现也独具特色:

![](media/921033407f4f0713f0d65926908dd8fd.gif)

当然，也可以将上述渲染效果与原始场景图进行插值混合，得到不同强度的渲染表现。

XPL中实现的错位线条故障（Line Block Glitch）后处理，有7个可供定制调节的参数：

![](media/322623af4b0591fbb81f7082104ef862.png)

错位线条故障（Line Block Glitch）的完整的源代码实现可见：

<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchLineBlock>


<br>

# 四、图块抖动故障（Tile Jitter Glitch）


图块抖动故障 (Tile Jitter Glitch)模拟了屏幕信号的块状抖动传输故障。

![](media/644ae2ffbaa0684a5c281c4b99493a0e.gif)

其核心算法思路在于基于uv的分层抖动。可以采用取余数的形式（fmod(x,y)方法可返回x/y的余数）来对uv进行分层，且对于层内的uv数值，进行三角函数形式的抖动。

核心实现Shader代码如下：

		#if USING_FREQUENCY_INFINITE
			strength = 1;
		#else
			strength = 0.5 + 0.5 * cos(_Time.y * _Frequency);
		#endif
		if(fmod(uv.y * _SplittingNumber, 2) < 1.0)
		{
			#if JITTER_DIRECTION_HORIZONTAL
				uv.x += pixelSizeX * cos(_Time.y * _JitterSpeed) * _JitterAmount * strength;
			#else
				uv.y += pixelSizeX * cos(_Time.y * _JitterSpeed) * _JitterAmount * strength;
			#endif
		}


上述代码经过计算后，得到的uv强度值如下：

![](media/f32cfdbbdde991f9c01a65f2c9939d59.gif)

得到上述分块抖动的uv后，便可以作为uv输入，对最终的场景图进行采样：

    half4 sceneColor = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, uv);

![](media/0e46e833408f134b4e60639f678c6e73.gif)

上图为左右抖动的表现，这边也有上下抖动的表现，以及左右分层+上下抖动，左右分层+左右抖动的各种不同表现：

![](media/7ecedf29afadde2e3f5f41240f835cdb.gif)

![](media/65c71e06c52ec28dc71931cd200efd6a.gif)

![](media/2f14f66f64bffcbf83a53adce4cdb69e.gif)

图块抖动故障 ( Glitch Tile Jitter) 后处理特效可调的参数同样也比较丰富，XPL内实现的此特效的可调参数面板如下：

![](media/3532f4a52070b0c1c0ae2640c1ae7801.png)

图块抖动故障 ( Glitch Tile Jitter)完整的实现源代码可见：

<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchTileJitter>


<br>

# 五、扫描线抖动故障（Scan Line Jitter Glitch）


扫描线抖动故障（Scan Line Jitter Glitch）算法较简单，但是得到的渲染表现却非常具有冲击力：

![](media/a9af498ec017da3e66dec7f71d0883a6.gif)

一个比较直接的实现是直接对横向或者纵向UV进行基于noise的抖动，Shader实现代码如下：

	float randomNoise(float x, float y)
	{
		return frac(sin(dot(float2(x, y), float2(12.9898, 78.233))) * 43758.5453);
	}

	half4 Frag_Horizontal(VaryingsDefault i): SV_Target
	{
		
		float jitter = randomNoise(i.texcoord.y, _Time.x) * 2 - 1;
		jitter *= step(_ScanLineJitter.y, abs(jitter)) * _ScanLineJitter.x;
		
		half4 sceneColor = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, frac(i.texcoord + float2(jitter, 0)));
		
		return sceneColor;
	}


得到的渲染表现如下：

![](media/f6645202c3717b8609086b3e92a3a750.gif)

也可以从竖直方向进行uv的抖动：
![](media/39.1.gif)


扫描线抖动故障（Scan Line Jitter Glitch）完整的实现源代码可见:

<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchScanLineJitter>


<br>

# 六、数字条纹故障（Digital Stripe Glitch）


数字条纹故障（Digital Stripe Glitch）同样是出镜率较高的Glitch系后处理特效之一。例如在《赛博朋克2077》的gameplay中，就可以到它的身影：

![](media/3d34f30356b1f00abb6b3c93ae2b43dc.png)

图 《赛博朋克2077》中的数字条纹故障（Digital Stripe Glitch）特效 @ CD Projekt

数字条纹故障（Digital Stripe Glitch）需在Runtime层完成noise Texture的生成，然后传入GPU中进行最终的运算和渲染呈现。

Runtime的核心思路为基于随机数进行随机颜色条纹贴图的生成，实现代码如下：

    for (int y = 0; y < _noiseTexture.height; y++)
    {
        for (int x = 0; x < _noiseTexture.width; x++)
        {
            //随机值若大于给定strip随机阈值，重新随机颜色
            if (UnityEngine.Random.value > stripLength)
            {
                color = XPostProcessingUtility.RandomColor();
            }
            //设置贴图像素值
            _noiseTexture.SetPixel(x, y, color);
        }
    }


生成的图片如下：

![](media/c555183415acbce177f0b96c3b090d9a.png)

Shader层面的实现则分为两个主要部分，分别是uv偏移，以及可选的基于废弃帧的插值不足：

	half4 Frag(VaryingsDefault i): SV_Target
	{
		// 基础数据准备
		 half4 stripNoise = SAMPLE_TEXTURE2D(_NoiseTex, sampler_NoiseTex, i.texcoord);
		 half threshold = 1.001 - _Indensity * 1.001;

		// uv偏移
		half uvShift = step(threshold, pow(abs(stripNoise.x), 3));
		float2 uv = frac(i.texcoord + stripNoise.yz * uvShift);
		half4 source = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, uv);

        #ifndef NEED_TRASH_FRAME
		    return source;
        #endif 	

		// 基于废弃帧插值
		half stripIndensity = step(threshold, pow(abs(stripNoise.w), 3)) * _StripColorAdjustIndensity;
		half3 color = lerp(source, _StripColorAdjustColor, stripIndensity).rgb;
		return float4(color, source.a);
	}


得到的不进行废弃帧插值的渲染表现如下：

![](media/b5d768ce574684a71147c32c3d79749d.gif)

进行废弃帧插值的渲染表现如下。除了下图中采用的类似反色的偏移颜色，也可以实现出基于RGB颜色随机，或者进行颜色空间转换后的色度校正后的偏移颜色：

![](media/9b8e47d4109237a8d500229895b170e3.gif)

数字条纹故障（Digital Stripe Glitch）后处理完整的实现源码可见：

<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchDigitalStripe>



<br>

# 七、模拟噪点故障（Analog Noise Glitch）


![](media/227015cf8d68bade6a90229a8d4bc4c0.gif)

模拟噪点故障（Analog Noise
Glitch）的主要思路，在于用noise去扰动原先场景图的颜色值。一种常规实现的核心代码如下：

    float noiseX = randomNoise(_TimeX * _Speed + i.texcoord / float2(-213, 5.53));
    float noiseY = randomNoise(_TimeX * _Speed - i.texcoord / float2(213, -5.53));
    float noiseZ = randomNoise(_TimeX * _Speed + i.texcoord / float2(213, 5.53));

    sceneColor.rgb += 0.25 * float3(noiseX,noiseY,noiseZ) - 0.125;


需要注意，0.25 * float3(noiseX,noiseY,noiseZ) - 0.125这句代码中的系数0.25和-0.125的作用，是让noise扰动后的画面的平均亮度和原先场景场景图相同，不能省略。但0.25和0.125两个系数可以进行合适的等幅度缩放，相对比例不变即可。

通过以上代码，可以得到如下带非均匀噪声的渲染表现：

![](media/295a770f97d3463c20e9358d93891fb3.gif)

另外，还可以加入greyScale灰度抖动，当某一刻的随机强度值大于亮度抖动阈值时，将原先的RGB颜色对应的luminance强度，呈现出黑白灰度的表现：

    half luminance = dot(noiseColor.rgb, fixed3(0.22, 0.707, 0.071));
    if (randomNoise(float2(_TimeX * _Speed, _TimeX * _Speed)) > _LuminanceJitterThreshold)
    {
        noiseColor = float4(luminance, luminance, luminance, luminance);
    }



最终，将noise扰动和随机灰度抖动两个特性相结合，得到Glitch Analog Noise最终的渲染表现：


![](media/9c0fad40cdfd5f8a9891274b3c562cc5.gif)

模拟噪点故障（Analog Noise Glitch）完整的实现源码可见：

<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchAnalogNoise>



<br>

# 八、屏幕跳跃故障（Screen Jump Glitch）



![](media/48.gif)

屏幕跳跃故障（Screen Jump Glitch）的算法原理在于取经过时间校正后的uv数值的小数部分，并于原始uv插值，得到均匀梯度式扰动屏幕空间uv，再用此uv进行采样即可得到跳动画面的表现。核心实现Shader代码如下：

	half4 Frag_Vertical(VaryingsDefault i): SV_Target
	{
		
		float jump = lerp(i.texcoord.y, frac(i.texcoord.y + _JumpTime), _JumpIndensity);		
		half4 sceneColor = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, frac(float2(i.texcoord.x, jump)));	
		return sceneColor;
	}

其中，扰动后的uv强度分布，随时间变化的数值如下：

![](media/9a7e15427e747a138b24955e4d8eb07f.gif)

基于此uv进行采样，得到的渲染表现如下：

![](media/798217fb92edbd778bca777b1159f860.gif)

以上为竖直方向的阶梯式uv采样，当然，我们也可以进行水平方向的阶梯式采样：

	half4 Frag_Horizontal(VaryingsDefault i): SV_Target
	{		
		float jump = lerp(i.texcoord.x, frac(i.texcoord.x + _JumpTime), _JumpIndensity);	
		half4 sceneColor = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, frac(float2(jump, i.texcoord.y)));		
		return sceneColor;
	}

得到的渲染表现如下：

![](media/496be98975fbb3dfda2acb0ed5e0e15b.gif)

屏幕跳跃故障（Screen Jump Glitch）完整的实现源码可见：

<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchScreenJump>

<br>

# 九、屏幕抖动故障（Screen Shake Glitch）


![](media/62fb4c1cbcb6d8d3599a356152096d85.gif)

类似上文的Screen Jump，Screen Shake屏幕抖动的算法原理也在于对屏幕空间uv的抖动，但不同的是，Screen Shake屏幕抖动需采用noise噪声函数来随机扰动uv，而不是均匀梯度式的形式。核心实现代码如下：

	half4 Frag_Horizontal(VaryingsDefault i): SV_Target
	{
		float shake = (randomNoise(_Time.x, 2) - 0.5) * _ScreenShake;
		
		half4 sceneColor = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, frac(float2(i.texcoord.x + shake, i.texcoord.y)));
		
		return sceneColor;
	}


得到扰动uv的可视化强度值如下：

![](media/328ab5b7882dec1251bc96e771be28f7.gif)

渲染表现则如下：

![](media/17fc92ce4cb3432d31f1abff2060e989.gif)

同样，也可以做竖直方向的抖动：

	half4 Frag_Vertical(VaryingsDefault i): SV_Target
	{
		
		float shake = (randomNoise(_Time.x, 2) - 0.5) * _ScreenShake;
		
		half4 sceneColor = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, frac(float2(i.texcoord.x, i.texcoord.y + shake)));
		
		return sceneColor;
	}


![](media/d287de98424bf1b8de486bf69ad697a4.gif)



屏幕抖动故障（Screen Shake Glitch）完整的实现源码可见：

<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchScreenShake>


<br>

# 十、波动抖动故障（Wave Jitter Glitch）


波动抖动故障（Wave Jitter Glitch）相较于上述的9种Glitch算法而言，用到了更为复杂的噪声生成函数。

## 10.1 噪声生成函数库 XNoiseLibrary

对此，XPL参考了[paper《Simplex noise demystified 》](http://www.itn.liu.se/\~stegu/simplexnoise/simplexnoise.pdf)、[webgl-noise库](https://github.com/ashima/webgl-noise)和[NoiseShader库](https://github.com/keijiro/NoiseShader)，实现一个单文件版的多维度噪声生成库 **[[XNoiseLibrary](https://github.com/QianMo/X-PostProcessing-Library/blob/master/Assets/X-PostProcessing/Shaders/XNoiseLibrary.hlsl)]**。

XNoiseLibrary具有如下三种类型的Noise噪声生成函数：

-   2D/3D/4D Simplex Noise

-   2D/3D textureless classic Noise

-   Re-oriented 4 / 8-Point BCC Noise

XNoiseLibrary的优势在于使用较为方便，直接include单个文件XNoiseLibrary.hlsl即可进行其中封装的多版本噪声函数的调用。

XNoiseLibrary的实现源码可见：

<https://github.com/QianMo/X-PostProcessing-Library/blob/master/Assets/X-PostProcessing/Shaders/XNoiseLibrary.hlsl>

<br>

# 10.2 波动抖动故障（Wave Jitter Glitch）的实现算法

OK，回到我们的波动抖动故障（Wave Jitter Glitch）后处理中来。

波动抖动故障（Wave Jitter Glitch）后处理的核心思路是用双层的noise实现波浪形扭动uv，核心代码如下：

    float uv_y = i.texcoord.y * _Resolution.y;
    float noise_wave_1 = snoise(float2(uv_y * 0.01, _Time.y * _Speed * 20)) * (strength * _Amount * 32.0);
    float noise_wave_2 = snoise(float2(uv_y * 0.02, _Time.y * _Speed * 10)) * (strength * _Amount * 4.0);
    float noise_wave_x = noise_wave_1 / _Resolution.x;
    float uv_x = i.texcoord.x + noise_wave_x;

    float4 color = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, float2(uv_x, i.texcoord.y));


若是单层的noise波浪，表现力会稍弱，具体表现如下：

![](media/c9c12de9bc072f2cbdcf547207dd49fe.gif)

而双层的noise波浪，表现力更强，具体表现如下：

![](media/6ece245744961b4423121341b646bfc2.gif)

所以XPL中的Wave Jitter实现，采用了双层的形式。

有了基于双层noise的Wave Jitter Glitch表现，还可以加上RGB Split算法，进一步提升表现力：

	float4 Frag_Horizontal(VaryingsDefault i): SV_Target
	{
		half strength = 0.0;
		#if USING_FREQUENCY_INFINITE
			strength = 1;
		#else
			strength = 0.5 + 0.5 *cos(_Time.y * _Frequency);
		#endif
		
		// Prepare UV
		float uv_y = i.texcoord.y * _Resolution.y;
		float noise_wave_1 = snoise(float2(uv_y * 0.01, _Time.y * _Speed * 20)) * (strength * _Amount * 32.0);
		float noise_wave_2 = snoise(float2(uv_y * 0.02, _Time.y * _Speed * 10)) * (strength * _Amount * 4.0);
		float noise_wave_x = noise_wave_1 * noise_wave_2 / _Resolution.x;
		float uv_x = i.texcoord.x + noise_wave_x;

		float rgbSplit_uv_x = (_RGBSplit * 50 + (20.0 * strength + 1.0)) * noise_wave_x / _Resolution.x;

		// Sample RGB Color
		half4 colorG = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, float2(uv_x, i.texcoord.y));
		half4 colorRB = SAMPLE_TEXTURE2D(_MainTex, sampler_MainTex, float2(uv_x + rgbSplit_uv_x, i.texcoord.y));
		
		return  half4(colorRB.r, colorG.g, colorRB.b, colorRB.a + colorG.a);
	}

得到的渲染表现如下：

![](media/6a76a60269920509dcb706a3c19f1cda.gif)

当然，除了横向的Wave Jitter，纵向的Wave Jitter也具有不错的效果：

![](media/2e43dee0491aaba8ee822bcf2ee45312.gif)

波动抖动故障（Wave Jitter Glitch） 后处理特效可调参数也比较丰富，XPL内实现的此特效的可调参数面板如下：

![](media/7921e7f2d840a0ab22ffc5c203c5a0f1.png)

波动抖动故障（Wave Jitter Glitch）详细的实现源码，可见：

<https://github.com/QianMo/X-PostProcessing-Library/tree/master/Assets/X-PostProcessing/Effects/GlitchWaveJitter>



<br>

# 总结


故障艺术追求“故障”带来的独特美感。近年来，故障艺术已经成为了赛博朋克风格电影和游戏作品中的核心艺术风格之一。而随着各种相关影视作品和游戏作品的不断发布，故障艺术的表现风格也引起了电商、综艺、快消等行业的广泛效仿。

在看完上述十种不同的故障艺术算法后，我们可以提炼一下，若要在屏幕空间实现故障艺术风格的渲染表现，算法核心在于四点：

-   **噪声函数的选择**：噪声函数是生成各式的干扰信号的源头。

-   **uv抖动方式的选择**：将噪声函数作用于屏幕空间uv后，基于新的uv进行采样，以产生故障的抖动表现。

-   **采样通道的选择**：对RGB分别采样，或者选取特定通道进行采样，以实现多种风格的故障表现。

-   **颜色空间的转换**：善用YUV、CMY、HSV、YIQ、YCbCr
    、YC1C2等空间与RGB空间之间的转换，以实现多种风格的故障表现。

熟知上述四种故障艺术的算法要点，加上一点创意，配合周边算法，则可以创造出更多富有表现力的故障艺术特效。


<br>

# Reference


[1] Jackson R. The Glitch Aesthetic[J]. 2011.
https://scholarworks.gsu.edu/cgi/viewcontent.cgi?article=1081&context=communication_theses

[2] den Heijer E. Evolving glitch art[C]//International Conference on
Evolutionary and Biologically Inspired Music and Art. Springer, Berlin,
Heidelberg, 2013: 109-120.

[3] https://zh.wikipedia.org/wiki/%E8%B5%9B%E5%8D%9A%E6%9C%8B%E5%85%8B

[4] https://github.com/keijiro/KinoGlitch

[5] https://github.com/ashima/webgl-noise

[6] https://github.com/keijiro/NoiseShader

[7] https://wallpaperswise.com/new-20-blade-runner-wallpapers/

[8] http://www.itn.liu.se/\~stegu/simplexnoise/simplexnoise.pdf

[9] 题图来自《Cyberpunk 2077》

```

`README.md`:

```md


![](Media/cover.jpg)



# Game-Programmer-Study-Notes

:anchor: 我的游戏程序员生涯的读书笔记合辑。

涉及游戏开发中的图形学、实时渲染、编程实践、GPU编程、设计模式、软件工程等内容。

Keep Reading , Keep Writing , Keep Coding.

# 目录

## 壹 · 渲染与计算机图形学
- [《Real-Time Rendering 3rd》提炼总结](https://github.com/QianMo/Programming-Reading-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/README.md)
-《Real-Time Rendering
3rd》可谓图形学界“九阴真经总纲”一般的存在，当世武功的心法口诀，尽数记载。此读书笔记是对这本神作一个系统而有特色的总结提炼。
   * [一 ) 全书知识点总览](https://github.com/QianMo/Game-Dev-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Content/BlogPost01/README.md)

   * [二 ) 第二章 · 图形渲染管线 The Graphics Rendering Pipeline](https://github.com/QianMo/Game-Dev-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Content/BlogPost02/README.md)

   * [三 ) 第三章 · GPU渲染管线与可编程着色器](https://github.com/QianMo/Game-Dev-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Content/BlogPost03/README.md)

   * [四 ) 第五章 · 图形渲染与视觉外观 The Visual Appearance](https://github.com/QianMo/Game-Dev-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Content/BlogPost04/README.md)

   * [五 ) 第六章 · 纹理贴图及相关技术](https://github.com/QianMo/Game-Dev-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Content/BlogPost05/README.md)

   * [六 ) 第七章 · 高级着色：BRDF及相关技术](https://github.com/QianMo/Game-Dev-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Content/BlogPost06/README.md)

   * [七 ) 第七章续 · 延迟渲染(Deferred Rendering)的前生今世](https://github.com/QianMo/Game-Dev-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Content/BlogPost07/README.md)

   * [八 ) 第九章 · 全局光照:光线追踪、路径追踪与GI技术进化编年史](https://github.com/QianMo/Game-Dev-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Content/BlogPost08/README.md)

   * [九 ) 第十章 · 游戏开发中基于图像的渲染技术总结](https://github.com/QianMo/Game-Dev-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Content/BlogPost09/README.md)

   * [十 ) 第十一章 · 非真实感渲染(NPR)相关技术总结](https://github.com/QianMo/Game-Dev-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Content/BlogPost10/README.md)

   * [十一 ) 第十四章 : 游戏开发中的渲染加速算法总结](https://github.com/QianMo/Game-Dev-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Content/BlogPost11/README.md)

   * [十二 ) 渲染管线优化方法论：从瓶颈定位到优化策略](https://github.com/QianMo/Game-Dev-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/Content/BlogPost12/README.md)


- [《Real-Time Rendering 3rd》知识网络图谱](https://github.com/QianMo/Game-Programmer-Study-Notes/tree/master/Content/%E3%80%8AReal-Time%20Rendering%203rd%E3%80%8B%E7%9F%A5%E8%AF%86%E7%BD%91%E7%BB%9C%E5%9B%BE%E8%B0%B1/README.md)

- [《GPU 编程与CG 语言之阳春白雪下里巴人》读书笔记](https://github.com/QianMo/Game-Dev-Reading-Notes/tree/master/Content/%E3%80%8AGPU%20%E7%BC%96%E7%A8%8B%E4%B8%8ECG%20%E8%AF%AD%E8%A8%80%E4%B9%8B%E9%98%B3%E6%98%A5%E7%99%BD%E9%9B%AA%E4%B8%8B%E9%87%8C%E5%B7%B4%E4%BA%BA%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/README.md)
-GPU 编程与Shader、CG编程的入门良书。

- [《GPU Gems 1》全书提炼总结](https://github.com/QianMo/Game-Programmer-Study-Notes/tree/master/Content/%E3%80%8AGPU%20Gems%201%E3%80%8B%E5%85%A8%E4%B9%A6%E6%8F%90%E7%82%BC%E6%80%BB%E7%BB%93/README.md) - 计算机图形学与渲染进阶的饕餮盛宴“GPU精粹三部曲”的第一本书。

- [《GPU Gems 2》全书提炼总结 · 上篇](https://github.com/QianMo/Game-Programmer-Study-Notes/tree/master/Content/%E3%80%8AGPU%20Gems%202%E3%80%8B%E5%85%A8%E4%B9%A6%E6%8F%90%E7%82%BC%E6%80%BB%E7%BB%93/Part1/README.md) - 计算机图形学与渲染进阶的饕餮盛宴“GPU精粹三部曲”的第二本书。虚幻引擎之父Tim Sweeney作序。
- [《GPU Gems 2》全书提炼总结 · 下篇](https://github.com/QianMo/Game-Programmer-Study-Notes/blob/master/Content/%E3%80%8AGPU%20Gems%202%E3%80%8B%E5%85%A8%E4%B9%A6%E6%8F%90%E7%82%BC%E6%80%BB%E7%BB%93/Part2/README.md) - 关于真实感水体渲染，以及真实感头发渲染、通用的折射模拟、改进的Perlin噪声等内容。
- [《GPU Gems 3》: 真实感皮肤渲染技术总结](https://github.com/QianMo/Game-Programmer-Study-Notes/blob/master/Content/%E3%80%8AGPU%20Gems%203%E3%80%8B%E5%85%A8%E4%B9%A6%E6%8F%90%E7%82%BC%E6%80%BB%E7%BB%93/Part1/README.md) - 对真实感皮肤渲染技术，进行了一个系统的总结和提炼。

- [《GPU Gems 3》全书核心内容提炼总结](https://github.com/QianMo/Game-Programmer-Study-Notes/blob/master/Content/%E3%80%8AGPU%20Gems%203%E3%80%8B%E5%85%A8%E4%B9%A6%E6%8F%90%E7%82%BC%E6%80%BB%E7%BB%93/Part2/README.md) - 盘点、提炼和总结了《GPU Gems 3》全书总计28章的核心内容。

- [《GPU Pro 1》全书核心内容提炼总结](https://github.com/QianMo/Game-Programmer-Study-Notes/blob/master/Content/%E3%80%8AGPU%20Pro%201%E3%80%8B%E5%85%A8%E4%B9%A6%E6%8F%90%E7%82%BC%E6%80%BB%E7%BB%93/README.md) - 盘点、提炼和总结了《GPU Pro 1 》全书总计22章的核心内容。
- [【真实感水体渲染技术总结】](https://github.com/QianMo/Game-Programmer-Study-Notes/blob/master/Content/%E7%9C%9F%E5%AE%9E%E6%84%9F%E6%B0%B4%E4%BD%93%E6%B8%B2%E6%9F%93%E6%8A%80%E6%9C%AF%E6%80%BB%E7%BB%93/README.md) - 文章对游戏以及电影业界的真实感水体渲染技术从发展史、知识体系、波形模拟技术以及着色技术等多个方面进行了较为系统的总结，文末也对业界优秀的水体实时渲染开源库进行了盘点。

- [【实时光线追踪技术：业界发展近况与未来挑战】](https://github.com/QianMo/Game-Programmer-Study-Notes/blob/master/Content/%E5%AE%9E%E6%97%B6%E5%85%89%E7%BA%BF%E8%BF%BD%E8%B8%AA%E6%8A%80%E6%9C%AF%EF%BC%9A%E4%B8%9A%E7%95%8C%E5%8F%91%E5%B1%95%E8%BF%91%E5%86%B5%E4%B8%8E%E6%9C%AA%E6%9D%A5%E6%8C%91%E6%88%98/README.md) - 文章对实时光线追踪技术的发展近况，当前业界面对的挑战，以及未来的研究方向进行了盘点。

- [【高品质后处理：十种图像模糊算法的总结与实现】](https://github.com/QianMo/Game-Programmer-Study-Notes/blob/master/Content/%E9%AB%98%E5%93%81%E8%B4%A8%E5%90%8E%E5%A4%84%E7%90%86%EF%BC%9A%E5%8D%81%E7%A7%8D%E5%9B%BE%E5%83%8F%E6%A8%A1%E7%B3%8A%E7%AE%97%E6%B3%95%E7%9A%84%E6%80%BB%E7%BB%93%E4%B8%8E%E5%AE%9E%E7%8E%B0/README.md) - 文章对后处理管线中会使用到的十种模糊算法进行了总结、对比与盘点，以及提供了这十种模糊算法对应的Unity Post Processing Stack v2版本的实现



- [【高品质后处理：十种故障艺术（Glitch Art）算法的总结与实现】](https://github.com/QianMo/Game-Programmer-Study-Notes/blob/master/Content/%E9%AB%98%E5%93%81%E8%B4%A8%E5%90%8E%E5%A4%84%E7%90%86%EF%BC%9A%E5%8D%81%E7%A7%8D%E6%95%85%E9%9A%9C%E8%89%BA%E6%9C%AF%EF%BC%88Glitch%20Art%EF%BC%89%E7%AE%97%E6%B3%95%E7%9A%84%E6%80%BB%E7%BB%93%E4%B8%8E%E5%AE%9E%E7%8E%B0/README.md) - 本文对十种主流故障艺术（Glitch Art）系列后处理算法的原理和实现方式进行了总结，对故障艺术风格的算法实现要点进行了提炼，并提供了对应算法在Unity引擎下的一个或多个版本的实现源码。


- [【两件 Big Thing：天美跨平台3A大作全球招聘令 & RTR4中译版出版时间预告】](https://github.com/QianMo/Game-Programmer-Study-Notes/tree/master/Content/%E5%A4%A9%E7%BE%8E%E8%B7%A8%E5%B9%B3%E5%8F%B03A%E5%A4%A7%E4%BD%9C%E5%85%A8%E7%90%83%E6%8B%9B%E8%81%98%E4%BB%A4%E4%B8%8ERTR4%E4%B8%AD%E8%AF%91%E7%89%88%E5%87%BA%E7%89%88%E6%97%B6%E9%97%B4%E9%A2%84%E5%91%8A/README.md) - 这篇文章聊到了两件Big Thing：天美战略级跨平台3A大作全球招聘令
，以及《Real-Time Rendering 4th》中译版预计将在2022年出版


- [【在“绝世武功的目录”RTR4中译版出版前，先奉上“绝世武功秘籍的本体”】](https://github.com/QianMo/Game-Programmer-Study-Notes/tree/master/Content/%E5%9C%A8%E2%80%9C%E7%BB%9D%E4%B8%96%E6%AD%A6%E5%8A%9F%E7%9A%84%E7%9B%AE%E5%BD%95%E2%80%9DRTR4%E4%B8%AD%E8%AF%91%E7%89%88%E5%87%BA%E7%89%88%E5%89%8D%EF%BC%8C%E5%85%88%E5%A5%89%E4%B8%8A%E2%80%9C%E7%BB%9D%E4%B8%96%E6%AD%A6%E5%8A%9F%E7%A7%98%E7%B1%8D%E7%9A%84%E6%9C%AC%E4%BD%93%E2%80%9D) - 这篇文章提供了图形学全网学习资料的“半壁江山”——《Real-Time Rendering 4th》2000多份参考文献合集的开源Github Repo地址，以及更新了RTR4中译版的预期出版时间。


<br>

## 贰 · 游戏设计模式、软件架构与编程实践

- [《游戏编程模式》读书笔记](https://github.com/QianMo/Reading-Notes/tree/master/Content/%E3%80%8A%E6%B8%B8%E6%88%8F%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%BC%8F%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/README.md)
-一篇超过万字读书笔记，总结了《游戏编程模式》一书中所有章节与内容的知识梗概。

- [《代码整洁之道（Clean Code)》读书笔记](https://github.com/QianMo/Reading-Notes/tree/master/Content/%E3%80%8A%E4%BB%A3%E7%A0%81%E6%95%B4%E6%B4%81%E4%B9%8B%E9%81%93%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/README.md)
-代码的整洁之道。
- [《Effective C# 第二版》读书笔记](https://github.com/QianMo/Reading-Notes/tree/master/Content/%E3%80%8AEffective%20C%23%20%E7%AC%AC%E4%BA%8C%E7%89%88%E3%80%8B%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/README.md)
-更好的使用C#。





<br>
<br>
:anchor: Keep Reading , Keep Writing , Keep Coding.



```

`process.dct`:

```dct
{'time_freq':3515620, 'bits':64}
```