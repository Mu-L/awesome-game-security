Project Path: arc_david942j_kvm-kernel-example_3rq687nt

Source Tree:

```txt
arc_david942j_kvm-kernel-example_3rq687nt
├── Makefile
├── README.md
├── hypervisor
│   ├── Makefile
│   ├── debug.h
│   ├── definition.h
│   ├── hypercall.c
│   ├── hypercall.h
│   ├── hypercall_table.h
│   └── hypervisor.c
├── kernel
│   ├── Makefile
│   ├── elf
│   │   ├── Makefile
│   │   └── elf.h
│   ├── entry.s
│   ├── hypercalls
│   │   ├── Makefile
│   │   ├── hp_close.c
│   │   ├── hp_close.h
│   │   ├── hp_lseek.c
│   │   ├── hp_lseek.h
│   │   ├── hp_open.c
│   │   ├── hp_open.h
│   │   ├── hp_read.c
│   │   ├── hp_read.h
│   │   ├── hp_write.c
│   │   ├── hp_write.h
│   │   ├── hypercall.c
│   │   ├── hypercall.h
│   │   └── hypercall_table.h
│   ├── kernel_main.c
│   ├── linker.script
│   ├── mm
│   │   ├── Makefile
│   │   ├── kmalloc.c
│   │   ├── kmalloc.h
│   │   ├── mmap.c
│   │   ├── mmap.h
│   │   ├── translate.c
│   │   ├── translate.h
│   │   ├── uaccess.c
│   │   └── uaccess.h
│   ├── syscalls
│   │   ├── Makefile
│   │   ├── sys_close.h
│   │   ├── sys_execve.c
│   │   ├── sys_execve.h
│   │   ├── sys_exit.c
│   │   ├── sys_exit.h
│   │   ├── sys_mmap.c
│   │   ├── sys_mmap.h
│   │   ├── sys_open.c
│   │   ├── sys_open.h
│   │   ├── sys_read.c
│   │   ├── sys_read.h
│   │   ├── sys_write.c
│   │   ├── sys_write.h
│   │   ├── syscall_entry.s
│   │   ├── syscall_handler.c
│   │   └── syscall_handler.h
│   ├── template.mk
│   └── utils
│       ├── Makefile
│       ├── errno.h
│       ├── misc.h
│       ├── panic.h
│       ├── panic.s
│       ├── string.c
│       └── string.h
└── user
    └── gen.py

```

`Makefile`:

```
DIRS := hypervisor kernel

all: $(DIRS)

$(DIRS): FORCE
	$(MAKE) -C $@

debug:
	echo $(DIRS) | xargs -n 1 $(MAKE) KVM_DEBUG=1 -C

test: all
	hypervisor/hypervisor.elf kernel/kernel.bin user/orw.elf /etc/os-release

clean:
	echo $(DIRS) | xargs -n 1 $(MAKE) clean -C
FORCE:

```

`README.md`:

```md
# KVM-Kernel Example

The source code are examples on my blog: [Learning KVM - implement your own kernel](https://david942j.blogspot.com/2018/10/note-learning-kvm-implement-your-own.html).

I've described how to implement a KVM-based hypervisor and the key points to implement a kernel on my blog.
You can leave comments in the blog or file issues here if you have questions or find any bug.

## Dir

### Hypervisor

The KVM-based hypervisor, its role is like qemu-system.

### Kernel

A extremely simple kernel, supports few syscalls.

### User

Simple ELF(s) for testing our kernel.
Pre-built user program was provided, and you can re-generate by the following commands:
```sh
$ pip3 install pwntools
$ user/gen.py
```
NOTE: You have to install Python 3.x in advance.

## Setup

### Check KVM support

Check if your CPU supports virtualization:
```
$ egrep '(vmx|svm)' /proc/cpuinfo
```
NOTE: CPUs in a VM might not support virtualization (i.e. no nested virtualization).
For example, EC2 on AWS doesn't support using KVM.

### Install KVM device

Check if the KVM device exists:
```
$ ls -la /dev/kvm
```

If `/dev/kvm` is not found, you can enable it (on Ubuntu) with:
```
$ sudo apt install qemu-kvm
```

If you are not root, you need to add yourself into the `kvm` group to have permission for accessing `/dev/kvm`.
```
$ sudo usermod -a -G kvm `whoami`
```
Remember to logout and login to have the group changing effective.


## How to run

```sh
$ git clone https://github.com/david942j/kvm-kernel-example
$ cd kvm-kernel-example && make
$ hypervisor/hypervisor.elf kernel/kernel.bin user/orw.elf /etc/os-release
# NAME="Ubuntu"
# VERSION="18.04.1 LTS (Bionic Beaver)"
# ID=ubuntu
# ID_LIKE=debian
# PRETTY_NAME="Ubuntu 18.04.1 LTS"
# VERSION_ID="18.04"
# HOME_URL="https://www.ubuntu.com/"
# SUPPORT_URL="https://help.ubuntu.com/"
# BUG_REPORT_URL="https://bugs.launchpad.net/ubuntu/"
# PRIVACY_POLICY_URL="https://www.ubuntu.com/legal/terms-and-policies/privacy-policy"
# VERSION_CODENAME=bionic
# UBUNTU_CODENAME=bionic
# +++ exited with 0 +++
```

### Environment

I only tested the code on Ubuntu 18.04, but I expect it to work on all KVM-supported x86 Linux distributions. Please file an issue if you find it's not true.

```

`hypervisor/Makefile`:

```
TARGET := hypervisor.elf
SRCS := hypervisor.c hypercall.c
DEPS := definition.h debug.h
CFLAGS := -Wall

ifdef KVM_DEBUG
CFLAGS += -DDEBUG
endif

all: $(TARGET)

$(TARGET): $(SRCS) $(DEPS)
	$(CC) $^ $(CFLAGS) -o $@

debug:
	$(MAKE) KVM_DEBUG=1

clean:
	$(RM) $(TARGET)

```

`hypervisor/debug.h`:

```h
#ifndef DEBUG_H
#define DEBUG_H

#ifdef DEBUG

#include <assert.h>
#include <linux/kvm.h>
#include <stdio.h>
#include <sys/ioctl.h>

#define debug(...) fprintf(stderr, __VA_ARGS__)
#define dump_seg(n, s) \
  debug("%3s base=0x%016llx limit=%08x selector=%#04x " \
    "type=0x%02x dpl=%d db=%d l=%d g=%d avl=%d\n", \
    (n), (s)->base, (s)->limit, (s)->selector, \
    (s)->type, (s)->dpl, (s)->db, (s)->l, (s)->g, (s)->avl)

void dump_regs(int vcpufd) {
  struct kvm_regs regs;
  int ret = ioctl(vcpufd, KVM_GET_REGS, &regs);
  assert(ret == 0);

  debug("\nDump regs\n");
  debug("rax\t0x%016llx rbx\t0x%016llx rcx\t0x%016llx rdx\t0x%016llx\n",
    regs.rax, regs.rbx, regs.rcx, regs.rdx);
  debug("rsp\t0x%016llx rbp\t0x%016llx rsi\t0x%016llx rdi\t0x%016llx\n",
    regs.rsp, regs.rbp, regs.rsi, regs.rdi);
  debug("rip\t0x%016llx r8\t0x%016llx r9\t0x%016llx r10\t0x%016llx\n",
    regs.rip, regs.r8, regs.r9, regs.r10);
  debug("r11\t0x%016llx r12\t0x%016llx r13\t0x%016llx r14\t0x%016llx\n",
    regs.r11, regs.r12, regs.r13, regs.r14);
  debug("r15\t0x%016llx rflags\t0x%08llx\n", regs.r15, regs.rflags);

  struct kvm_sregs sregs;
  ret = ioctl(vcpufd, KVM_GET_SREGS, &sregs);
  assert(ret == 0);

  dump_seg("cs", &sregs.cs);
  dump_seg("ds", &sregs.ds);
  dump_seg("es", &sregs.es);
  dump_seg("ss", &sregs.ss);
  dump_seg("fs", &sregs.fs);
  dump_seg("gs", &sregs.gs);

  debug("cr0\t0x%016llx\n", sregs.cr0);
  debug("cr3\t0x%016llx\n", sregs.cr3);
}

#else

#define dump_regs(...)

#endif /* DEBUG */

#endif /* DEBUG_H */

```

`hypervisor/definition.h`:

```h
#ifndef DEFINITION_H
#define DEFINITION_H

#include <stdint.h>

typedef struct VM {
  void *mem;
  uint64_t mem_size;
  /* Only supports one vCPU */
  int vcpufd;
  struct kvm_run *run;
} VM;

/* Common macros */
#define error(fmt, ...) do { \
  fprintf(stderr, fmt, ##__VA_ARGS__); \
  exit(EXIT_FAILURE); \
} while(0)

#define pexit(x) do { \
  perror(x); \
  exit(EXIT_FAILURE); \
} while(0)

/* CR0 bits */
#define CR0_PE 1u
#define CR0_MP (1u << 1)
#define CR0_EM (1u << 2)
#define CR0_TS (1u << 3)
#define CR0_ET (1u << 4)
#define CR0_NE (1u << 5)
#define CR0_WP (1u << 16)
#define CR0_AM (1u << 18)
#define CR0_NW (1u << 29)
#define CR0_CD (1u << 30)
#define CR0_PG (1u << 31)

/* CR4 bits */
#define CR4_VME 1u
#define CR4_PVI (1u << 1)
#define CR4_TSD (1u << 2)
#define CR4_DE (1u << 3)
#define CR4_PSE (1u << 4)
#define CR4_PAE (1u << 5)
#define CR4_MCE (1u << 6)
#define CR4_PGE (1u << 7)
#define CR4_PCE (1u << 8)
#define CR4_OSFXSR (1u << 9)
#define CR4_OSXMMEXCPT (1u << 10)
#define CR4_UMIP (1u << 11)
#define CR4_VMXE (1u << 13)
#define CR4_SMXE (1u << 14)
#define CR4_FSGSBASE (1u << 16)
#define CR4_PCIDE (1u << 17)
#define CR4_OSXSAVE (1u << 18)
#define CR4_SMEP (1u << 20)
#define CR4_SMAP (1u << 21)
#define CR4_PKE (1u << 22)

#define EFER_SCE 1
#define EFER_LME (1 << 8)
#define EFER_LMA (1 << 10)
#define EFER_NXE (1 << 11)
#define EFER_SVME (1 << 12)
#define EFER_LMSLE (1 << 13)
#define EFER_FFXSR (1 << 14)
#define EFER_TCE (1 << 15)

/* 64-bit page * entry bits */
#define PDE64_PRESENT 1
#define PDE64_RW (1 << 1)
#define PDE64_USER (1 << 2)
#define PDE64_ACCESSED (1 << 5)
#define PDE64_DIRTY (1 << 6)
#define PDE64_PS (1 << 7)
#define PDE64_G (1 << 8)

#endif

```

`hypervisor/hypercall.c`:

```c
#include <assert.h>
#include <errno.h>
#include <fcntl.h>
#include <linux/kvm.h>
#include <stdint.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <unistd.h>

#include "hypercall.h"

static int hp_handle_open(VM*);
static int hp_handle_read(VM*);
static int hp_handle_write(VM*);
static int hp_handle_close(VM*);
static int hp_handle_lseek(VM*);
static int hp_handle_exit(VM*);
static int hp_handle_panic(VM*);

int hp_handler(uint16_t nr, VM* vm) {
  switch(nr) {
#define handle(f) case NR_HP_##f: return hp_handle_##f(vm)

  handle(open);
  handle(read);
  handle(write);
  handle(close);
  handle(lseek);
  handle(exit);
  handle(panic);

#undef handle
  default:
    return -ENOSYS;
  }
}

typedef struct fd_handle {
  int real_fd;
  int opening;
} fd_handle;

#define MAX_FD 255

static fd_handle fd_map[MAX_FD + 1];

static inline void MAY_INIT_FD_MAP() {
  static int fd_map_init = 0;
  if(!fd_map_init) {
    fd_map_init = 1;
    fd_map[0].real_fd = 0; fd_map[0].opening = 1;
    fd_map[1].real_fd = 1; fd_map[1].opening = 1;
    fd_map[2].real_fd = 2; fd_map[2].opening = 1;
    for(int i = 3; i <= MAX_FD; i++)
      fd_map[i].opening = 0;
  }
}

#define UNUSED_VAR 0xdeadffffu

#define FETCH_U32 (*(uint32_t*)((uint8_t*)vm->run + vm->run->io.data_offset))

#define PROCESS if(vm->run->io.direction == KVM_EXIT_IO_OUT)
#define THEN_RETURN(var) else { \
    if(var == UNUSED_VAR) return -1; \
    FETCH_U32 = var; \
    var = UNUSED_VAR; \
  }

#define CHECK_OOB(var) assert(0 <= (var) && (var) < vm->mem_size)

#define MEM_AT(offset) ( \
    CHECK_OOB(offset), \
    (uint8_t*) vm->mem + (uint64_t) offset \
  )

static int hp_handle_open(VM *vm) {
  static int ret = UNUSED_VAR;
  PROCESS {
    uint32_t offset = FETCH_U32;
    const char *filename = (char*) MEM_AT(offset);
    uint32_t end = offset + strlen(filename);
    CHECK_OOB(end);

    MAY_INIT_FD_MAP();
    int min_fd;
    for(min_fd = 0; min_fd <= MAX_FD; min_fd++)
      if(fd_map[min_fd].opening == 0) break;
    if(min_fd > MAX_FD) ret = -ENFILE;
    else {
      int fd = open(filename, O_RDONLY, 0);
      if(fd < 0) ret = -errno;
      else {
        fd_map[min_fd].real_fd = fd;
        fd_map[min_fd].opening = 1;
        ret = min_fd;
      }
    }
  } THEN_RETURN(ret);
  return 0;
}

#define BADFD(fd) (fd < 0 || fd > MAX_FD || fd_map[fd].opening == 0)
#define PROCESS_ON_FD(work) do { \
    MAY_INIT_FD_MAP(); \
    if(BADFD(fd)) ret = -EBADF; \
    else { \
      ret = work; \
      if(ret < 0) ret = -errno; \
    } \
  } while(0)

static int handle_rw(VM* vm, typeof(read) fptr) {
  static int ret = UNUSED_VAR;
  PROCESS {
    uint32_t offset = FETCH_U32;
    const uint64_t *kbuf = (uint64_t*) MEM_AT(offset);
    int fd = (int) kbuf[0];
    uint64_t paddr = kbuf[1];
    uint64_t nbytes = kbuf[2];
    if(!(0 <= paddr && paddr <= paddr + nbytes && paddr + nbytes <= vm->mem_size))
      ret = -EACCES;
    else
      PROCESS_ON_FD(fptr(fd_map[fd].real_fd, MEM_AT(paddr), nbytes));

  } THEN_RETURN(ret);
  return 0;
}

static int hp_handle_read(VM* vm) {
  return handle_rw(vm, read);
}

static int hp_handle_write(VM* vm) {
#pragma GCC diagnostic push
#pragma GCC diagnostic ignored "-Wincompatible-pointer-types"
  /* Justification: here just cast write into typeof(read) */
  return handle_rw(vm, write);
#pragma GCC diagnostic pop
}

static inline int do_close(struct fd_handle *h) {
  h->opening = 0;
  return close(h->real_fd);
}

static int hp_handle_close(VM *vm) {
  static int ret = UNUSED_VAR;
  PROCESS {
    int fd = FETCH_U32;

    PROCESS_ON_FD(do_close(&fd_map[fd]));

  } THEN_RETURN(ret);
  return 0;
}

static int hp_handle_lseek(VM *vm) {
  static int ret = UNUSED_VAR;
  PROCESS {
    uint32_t offset = FETCH_U32;
    const uint32_t *kbuf = (uint32_t*) MEM_AT(offset);
    int fd = kbuf[0];
    uint32_t off = kbuf[1];
    int whence = kbuf[2];

    PROCESS_ON_FD(lseek(fd_map[fd].real_fd, off, whence));

  } THEN_RETURN(ret);
  return 0;
}
static int hp_handle_exit(VM *vm) {
  int status = FETCH_U32;
  fprintf(stderr, "+++ exited with %d +++\n", status);
  exit(0);
}

static int hp_handle_panic(VM *vm) {
  uint32_t offset = FETCH_U32;
  fprintf(stderr, "[\e[31mPANIC\e[0m] %s\n", MEM_AT(offset));
  exit(1);
  return -1;
}

```

`hypervisor/hypercall.h`:

```h
#ifndef HYPERCALL_H
#define HYPERCALL_H

#include "definition.h"
#include "hypercall_table.h"

int hp_handler(uint16_t nr, VM *vm);

#endif

```

`hypervisor/hypercall_table.h`:

```h
#ifndef HYPERCALL_TABLE_H
#define HYPE
```

`hypervisor/hypervisor.c`:

```c
#include <fcntl.h>
#include <linux/kvm.h>
#include <stdint.h>
#include <stdio.h>
#include <stdlib.h>
#include <string.h>
#include <sys/ioctl.h>
#include <sys/mman.h>

#include "debug.h"
#include "definition.h"
#include "hypercall.h"

#define PS_LIMIT (0x200000)
#define KERNEL_STACK_SIZE (0x4000)
/*
 * setup_paging() and init_pagetable() in kernel/mm/translate.c uses 5 pages in total
 */
#define PAGE_TABLE_SIZE (0x5000)
#define MAX_KERNEL_SIZE (PS_LIMIT - PAGE_TABLE_SIZE - KERNEL_STACK_SIZE)
#define MEM_SIZE (PS_LIMIT * 0x2)

void read_file(const char *filename, uint8_t** content_ptr, size_t* size_ptr) {
  FILE *f = fopen(filename, "rb");
  if(f == NULL) error("Open file '%s' failed.\n", filename);
  if(fseek(f, 0, SEEK_END) < 0) pexit("fseek(SEEK_END)");

  size_t size = ftell(f);
  if(size == 0) error("Empty file '%s'.\n", filename);
  if(fseek(f, 0, SEEK_SET) < 0) pexit("fseek(SEEK_SET)");

  uint8_t *content = (uint8_t*) malloc(size);
  if(content == NULL) error("read_file: Cannot allocate memory\n");
  if(fread(content, 1, size, f) != size) error("read_file: Unexpected EOF\n");

  fclose(f);
  *content_ptr = content;
  *size_ptr = size;
}

/* set rip = entry point
 * set rsp = PS_LIMIT (the max address can be used)
 *
 * set rdi = PS_LIMIT (start of free (unpaging) physical pages)
 * set rsi = MEM_SIZE - rdi (total length of free pages)
 * Kernel could use rdi and rsi to initialize its memory allocator.
 */
void setup_regs(VM *vm, size_t entry) {
  struct kvm_regs regs;
  if(ioctl(vm->vcpufd, KVM_GET_REGS, &regs) < 0) pexit("ioctl(KVM_GET_REGS)");
  regs.rip = entry;
  regs.rsp = PS_LIMIT; /* temporary stack */
  regs.rdi = PS_LIMIT; /* start of free pages */
  regs.rsi = MEM_SIZE - regs.rdi; /* total length of free pages */
  regs.rflags = 0x2;
  if(ioctl(vm->vcpufd, KVM_SET_REGS, &regs) < 0) pexit("ioctl(KVM_SET_REGS");
}

/* Maps:
 * 0 ~ 0x200000 -> 0 ~ 0x200000 with kernel privilege
 */
void setup_paging(VM *vm) {
  struct kvm_sregs sregs;
  if(ioctl(vm->vcpufd, KVM_GET_SREGS, &sregs) < 0) pexit("ioctl(KVM_GET_SREGS)");
  uint64_t pml4_addr = MAX_KERNEL_SIZE;
  uint64_t *pml4 = (void*) (vm->mem + pml4_addr);

  uint64_t pdp_addr = pml4_addr + 0x1000;
  uint64_t *pdp = (void*) (vm->mem + pdp_addr);

  uint64_t pd_addr = pdp_addr + 0x1000;
  uint64_t *pd = (void*) (vm->mem + pd_addr);

  pml4[0] = PDE64_PRESENT | PDE64_RW | PDE64_USER | pdp_addr;
  pdp[0] = PDE64_PRESENT | PDE64_RW | PDE64_USER | pd_addr;
  pd[0] = PDE64_PRESENT | PDE64_RW | PDE64_PS; /* kernel only, no PED64_USER */

  sregs.cr3 = pml4_addr;
  sregs.cr4 = CR4_PAE;
  sregs.cr4 |= CR4_OSFXSR | CR4_OSXMMEXCPT; /* enable SSE instruction */
  sregs.cr0 = CR0_PE | CR0_MP | CR0_ET | CR0_NE | CR0_WP | CR0_AM | CR0_PG;
  sregs.efer = EFER_LME | EFER_LMA;
  sregs.efer |= EFER_SCE; /* enable syscall instruction */

  if(ioctl(vm->vcpufd, KVM_SET_SREGS, &sregs) < 0) pexit("ioctl(KVM_SET_SREGS)");
}

void setup_seg_regs(VM *vm) {
  struct kvm_sregs sregs;
  if(ioctl(vm->vcpufd, KVM_GET_SREGS, &sregs) < 0) pexit("ioctl(KVM_GET_SREGS)");
  struct kvm_segment seg = {
    .base = 0,
    .limit = 0xffffffff,
    .selector = 1 << 3,
    .present = 1,
    .type = 0xb, /* Code segment */
    .dpl = 0, /* Kernel: level 0 */
    .db = 0,
    .s = 1,
    .l = 1, /* long mode */
    .g = 1
  };
  sregs.cs = seg;
  seg.type = 0x3; /* Data segment */
  seg.selector = 2 << 3;
  sregs.ds = sregs.es = sregs.fs = sregs.gs = sregs.ss = seg;
  if(ioctl(vm->vcpufd, KVM_SET_SREGS, &sregs) < 0) pexit("ioctl(KVM_SET_SREGS)");
}

/*
 * Switching to long mode usually done by kernel.
 * We put the task in hypervisor because we want our KVM be able to execute
 * normal x86-64 assembled code as well. Which let us easier to debug and test.
 *
 */
void setup_long_mode(VM *vm) {
  setup_paging(vm);
  setup_seg_regs(vm);
}

VM* kvm_init(uint8_t code[], size_t len) {
  int kvmfd = open("/dev/kvm", O_RDWR | O_CLOEXEC);
  if(kvmfd < 0) pexit("open(/dev/kvm)");

  int api_ver = ioctl(kvmfd, KVM_GET_API_VERSION, 0);
	if(api_ver < 0) pexit("KVM_GET_API_VERSION");
  if(api_ver != KVM_API_VERSION) {
    error("Got KVM api version %d, expected %d\n",
      api_ver, KVM_API_VERSION);
  }
  int vmfd = ioctl(kvmfd, KVM_CREATE_VM, 0);
  if(vmfd < 0) pexit("ioctl(KVM_CREATE_VM)");
  void *mem = mmap(0,
    MEM_SIZE,
    PROT_READ | PROT_WRITE,
    MAP_SHARED | MAP_ANONYMOUS,
    -1, 0);
  if(mem == NULL) pexit("mmap(MEM_SIZE)");
  size_t entry = 0;
  memcpy((void*) mem + entry, code, len);
  struct kvm_userspace_memory_region region = {
    .slot = 0,
    .flags = 0,
    .guest_phys_addr = 0,
    .memory_size = MEM_SIZE,
    .userspace_addr = (size_t) mem
  };
  if(ioctl(vmfd, KVM_SET_USER_MEMORY_REGION, &region) < 0) {
    pexit("ioctl(KVM_SET_USER_MEMORY_REGION)");
  }
  int vcpufd = ioctl(vmfd, KVM_CREATE_VCPU, 0);
  if(vcpufd < 0) pexit("ioctl(KVM_CREATE_VCPU)");
  size_t vcpu_mmap_size = ioctl(kvmfd, KVM_GET_VCPU_MMAP_SIZE, NULL);
  struct kvm_run *run = (struct kvm_run*) mmap(0,
    vcpu_mmap_size,
    PROT_READ | PROT_WRITE,
    MAP_SHARED,
    vcpufd, 0);

  VM *vm = (VM*) malloc(sizeof(VM));
  *vm = (struct VM){
    .mem = mem,
    .mem_size = MEM_SIZE,
    .vcpufd = vcpufd,
    .run = run
  };

  setup_regs(vm, entry);
  setup_long_mode(vm);

  return vm;
}

int check_iopl(VM *vm) {
  struct kvm_regs regs;
  struct kvm_sregs sregs;
  if(ioctl(vm->vcpufd, KVM_GET_REGS, &regs) < 0) pexit("ioctl(KVM_GET_REGS)");
  if(ioctl(vm->vcpufd, KVM_GET_SREGS, &sregs) < 0) pexit("ioctl(KVM_GET_SREGS)");
  return sregs.cs.dpl <= ((regs.rflags >> 12) & 3);
}

void execute(VM* vm) {
  while(1) {
    ioctl(vm->vcpufd, KVM_RUN, NULL);
    dump_regs(vm->vcpufd);
    switch (vm->run->exit_reason) {
    case KVM_EXIT_HLT:
      fprintf(stderr, "KVM_EXIT_HLT\n");
      return;
    case KVM_EXIT_IO:
      if(!check_iopl(vm)) error("KVM_EXIT_SHUTDOWN\n");
      if(vm->run->io.port & HP_NR_MARK) {
        if(hp_handler(vm->run->io.port, vm) < 0) error("Hypercall failed\n");
      }
      else error("Unhandled I/O port: 0x%x\n", vm->run->io.port);
      break;
    case KVM_EXIT_FAIL_ENTRY:
      error("KVM_EXIT_FAIL_ENTRY: hardware_entry_failure_reason = 0x%llx\n",
        vm->run->fail_entry.hardware_entry_failure_reason);
    case KVM_EXIT_INTERNAL_ERROR:
      error("KVM_EXIT_INTERNAL_ERROR: suberror = 0x%x\n",
        vm->run->internal.suberror);
    case KVM_EXIT_SHUTDOWN:
      error("KVM_EXIT_SHUTDOWN\n");
    default:
      error("Unhandled reason: %d\n", vm->run->exit_reason);
    }
  }
}

/* copy argv onto kernel's stack */
void copy_argv(VM* vm, int argc, char *argv[]) {
  struct kvm_regs regs;
  if(ioctl(vm->vcpufd, KVM_GET_REGS, &regs) < 0) pexit("ioctl(KVM_GET_REGS)");
  char *sp = (char*)vm->mem + regs.rsp;
  char **copy = (char**) malloc(argc * sizeof(char*));
#define STACK_ALLOC(sp, len) ({ sp -= len; sp; })
  for(int i = argc - 1; i >= 0; i--) {
    int len = strlen(argv[i]) + 1;
    copy[i] = STACK_ALLOC(sp, len);
    memcpy(copy[i], argv[i], len);
  }
  sp = (char*) ((uint64_t) sp & -0x10);
  /* push argv */
  *(uint64_t*) STACK_ALLOC(sp, sizeof(char*)) = 0;
  for(int i = argc - 1; i >= 0; i--)
    *(uint64_t*) STACK_ALLOC(sp, sizeof(char*)) = copy[i] - (char*)vm->mem;
  /* push argc */
  *(uint64_t*) STACK_ALLOC(sp, sizeof(uint64_t)) = argc;
  free(copy);
#undef STACK_ALLOC
  regs.rsp = sp - (char*) vm->mem;
  if(ioctl(vm->vcpufd, KVM_SET_REGS, &regs) < 0) pexit("ioctl(KVM_SET_REGS)");
}

int main(int argc, char *argv[]) {
  if(argc < 3) {
    printf("Usage: %s kernel.bin user.elf [user_args...]\n", argv[0]);
    exit(EXIT_FAILURE);
  }
  uint8_t *code;
  size_t len;
  read_file(argv[1], &code, &len);
  if(len > MAX_KERNEL_SIZE)
    error("Kernel size exceeded, %p > MAX_KERNEL_SIZE(%p).\n",
      (void*) len,
      (void*) MAX_KERNEL_SIZE);
  VM* vm = kvm_init(code, len);
  copy_argv(vm, argc - 2, &argv[2]);
  execute(vm);
}

```

`kernel/Makefile`:

```
TARGET := kernel.bin

SRCS := entry.s kernel_main.c
OBJS :=
DEPS := $(wildcard ./**/*.d)
SUBOBJS := syscalls/syscalls.a hypercalls/hypercalls.a mm/mm.a elf/elf.a utils/utils.a

CFLAGS := -Wall -Werror -fPIE -pie -masm=intel -nostdlib -Os -I.
LDFLAGS := -ffreestanding -fno-builtin -Tlinker.script

.PRECIOUS: %.o
all: $(TARGET)

%.bin: $(SRCS) $(OBJS) $(SUBOBJS)
	$(CC) $(CFLAGS) $^ -o $@ -Xlinker --oformat=binary $(LDFLAGS)

%.o: %.s
	$(AS) $^ -o $@

%.o: %.c
	$(CC) $(CFLAGS) -c -MMD -MP $< -o $@

$(SUBOBJS): FORCE
	$(MAKE) -C $(dir $@) $(notdir $@)

.PHONY: clean
clean:
	dirname $(SUBOBJS) | xargs -n 1 $(MAKE) clean -C
	$(RM) $(OBJS) $(TARGET) $(DEPS)

FORCE:

```

`kernel/elf/Makefile`:

```
TARGET := elf.a

include ../template.mk

```

`kernel/elf/elf.h`:

```h
#ifndef ELF_H
#define ELF_H

#include <stdint.h>

#define EI_NIDENT	16

typedef uint16_t __u16;
typedef uint32_t __u32;
typedef uint64_t __u64;
typedef int16_t __s16;
typedef int32_t __s32;
typedef int64_t __s64;

/* 64-bit ELF base types. */
typedef __u64	Elf64_Addr;
typedef __u16	Elf64_Half;
typedef __s16	Elf64_SHalf;
typedef __u64	Elf64_Off;
typedef __s32	Elf64_Sword;
typedef __u32	Elf64_Word;
typedef __u64	Elf64_Xword;
typedef __s64	Elf64_Sxword;

#define ET_EXEC 2
#define ET_DYN 3

typedef struct elf64_hdr {
  unsigned char	e_ident[EI_NIDENT];
  Elf64_Half e_type;
  Elf64_Half e_machine;
  Elf64_Word e_version;
  Elf64_Addr e_entry;
  Elf64_Off e_phoff;
  Elf64_Off e_shoff;
  Elf64_Word e_flags;
  Elf64_Half e_ehsize;
  Elf64_Half e_phentsize;
  Elf64_Half e_phnum;
  Elf64_Half e_shentsize;
  Elf64_Half e_shnum;
  Elf64_Half e_shstrndx;
} Elf64_Ehdr;

/* p_type */
#define PT_LOAD 1

/* p_flags */
#define PF_R		0x4
#define PF_W		0x2
#define PF_X		0x1

typedef struct elf64_phdr {
  Elf64_Word p_type;
  Elf64_Word p_flags;
  Elf64_Off p_offset;
  Elf64_Addr p_vaddr;
  Elf64_Addr p_paddr;
  Elf64_Xword p_filesz;
  Elf64_Xword p_memsz;
  Elf64_Xword p_align;
} Elf64_Phdr;

#endif

```

`kernel/entry.s`:

```s
.globl _start, hlt
.extern kernel_main
.intel_syntax noprefix
_start:
  mov rdx, [rsp] /* argc */
  lea rcx, [rsp + 8] /* argv */
  call kernel_main
hlt:
  hlt
  jmp hlt

```

`kernel/hypercalls/Makefile`:

```
TARGET := hypercalls.a

include ../template.mk

```

`kernel/hypercalls/hp_close.c`:

```c
#include <hypercalls/hp_close.h>

int hp_close(int fildes) {
  return hypercall(NR_HP_close, fildes);
}

```

`kernel/hypercalls/hp_close.h`:

```h
#ifndef HP_CLOSE_H
#define HP_CLOSE_H

#include <hypercalls/hypercall.h>

int hp_close(int fildes);

#endif

```

`kernel/hypercalls/hp_lseek.c`:

```c
#include <hypercalls/hp_lseek.h>
#include <mm/kmalloc.h>
#include <mm/translate.h>

int hp_lseek(int fildes, uint32_t offset, int whence) {
  uint32_t *kbuf = kmalloc(sizeof(int) * 3, MALLOC_NO_ALIGN);
  kbuf[0] = fildes;
  kbuf[1] = offset;
  kbuf[2] = whence;
  int ret = hypercall(NR_HP_lseek, physical(kbuf));
  kfree(kbuf);
  return ret;
}

```

`kernel/hypercalls/hp_lseek.h`:

```h
#ifndef HP_LSEEK_H
#define HP_LSEEK_H

#include <hypercalls/hypercall.h>

#define SEEK_SET 0
#define SEEK_CUR 1
#define SEEK_END 2

int hp_lseek(int fildes, uint32_t offset, int whence);

#endif

```

`kernel/hypercalls/hp_open.c`:

```c
#include <hypercalls/hp_open.h>
#include <mm/translate.h>

int hp_open(uint64_t paddr) {
  return hypercall(NR_HP_open, (uint32_t) paddr);
}

```

`kernel/hypercalls/hp_open.h`:

```h
#ifndef HP_OPEN_H
#define HP_OPEN_H

#include <hypercalls/hypercall.h>

int hp_open(uint64_t paddr);

#endif

```

`kernel/hypercalls/hp_read.c`:

```c
#include <hypercalls/hp_read.h>
#include <mm/kmalloc.h>
#include <mm/translate.h>

int hp_read(int fildes, uint64_t phy_addr, uint64_t nbyte) {
  uint64_t *kbuf = kmalloc(sizeof(uint64_t) * 3, MALLOC_NO_ALIGN);
  kbuf[0] = fildes;
  kbuf[1] = phy_addr;
  kbuf[2] = nbyte;
  int ret = hypercall(NR_HP_read, physical(kbuf));
  kfree(kbuf);
  return ret;
}

```

`kernel/hypercalls/hp_read.h`:

```h
#ifndef HP_READ_H
#define HP_READ_H

#include <stdint.h>

#include <hypercalls/hypercall.h>

int hp_read(int fildes, uint64_t phy_addr, uint64_t nbyte);

#endif

```

`kernel/hypercalls/hp_write.c`:

```c
#include <hypercalls/hp_write.h>
#include <mm/kmalloc.h>
#include <mm/translate.h>

int hp_write(int fildes, uint64_t phy_addr, uint64_t nbyte) {
  uint64_t *kbuf = kmalloc(sizeof(uint64_t) * 3, MALLOC_NO_ALIGN);
  kbuf[0] = fildes;
  kbuf[1] = phy_addr;
  kbuf[2] = nbyte;
  int ret = hypercall(NR_HP_write, physical(kbuf));
  kfree(kbuf);
  return ret;
}

```

`kernel/hypercalls/hp_write.h`:

```h
#ifndef HP_WRITE_H
#define HP_WRITE_H

#include <stdint.h>

#include <hypercalls/hypercall.h>

int hp_write(int fildes, uint64_t phy_addr, uint64_t nbyte);

#endif

```

`kernel/hypercalls/hypercall.c`:

```c
#include <hypercalls/hypercall.h>

int hypercall(uint16_t port, uint32_t data) {
  int ret = 0;
  asm(
    "mov dx, %[port];"
    "mov eax, %[data];"
    "out dx, eax;"
    "in eax, dx;"
    "mov %[ret], eax;"
    : [ret] "=r"(ret)
    : [port] "r"(port), [data] "r"(data)
    : "rax", "rdx"
    );
  return ret;
}

```

`kernel/hypercalls/hypercall.h`:

```h
#ifndef HYPERCALL_H
#define HYPERCALL_H

#include <stdint.h>

#include <hypercalls/hypercall_table.h>
#include <utils/panic.h>

int hypercall(unsigned short port, uint32_t data);

#endif

```

`kernel/hypercalls/hypercall_table.h`:

```h
#ifndef HYPERCALL_TABLE_H
#define HYPERCALL_TABLE_H

#define HP_NR_MARK 0x8000

#define NR_HP_open  (HP_NR_MARK | 0)
#define NR_HP_read  (HP_NR_MARK | 1)
#define NR_HP_write  (HP_NR_MARK | 2)
#define NR_HP_close  (HP_NR_MARK | 3)
#define NR_HP_lseek  (HP_NR_MARK | 4)
#define NR_HP_exit  (HP_NR_MARK | 5)

#define NR_HP_panic (HP_NR_MARK | 0x7fff)

#endif

```

`kernel/kernel_main.c`:

```c
#include <hypercalls/hp_open.h>
#include <mm/kmalloc.h>
#include <mm/translate.h>
#include <syscalls/sys_execve.h>
#include <utils/string.h>

#define MSR_STAR 0xc0000081 /* legacy mode SYSCALL target */
#define MSR_LSTAR 0xc0000082 /* long mode SYSCALL target */
#define MSR_CSTAR 0xc0000083 /* compat mode SYSCALL target */
#define MSR_SYSCALL_MASK 0xc0000084

int register_syscall() {
  asm(
    "xor rax, rax;"
    "mov rdx, 0x00200008;"
    "mov ecx, %[msr_star];"
    "wrmsr;"

    "mov eax, %[fmask];"
    "xor rdx, rdx;"
    "mov ecx, %[msr_fmask];"
    "wrmsr;"

    "lea rax, [rip + syscall_entry];"
    "mov rdx, %[base] >> 32;"
    "mov ecx, %[msr_syscall];"
    "wrmsr;"
    :: [msr_star]"i"(MSR_STAR),
       [fmask]"i"(0x3f7fd5), [msr_fmask]"i"(MSR_SYSCALL_MASK),
       [base]"i"(KERNEL_BASE_OFFSET), [msr_syscall]"i"(MSR_LSTAR)
    : "rax", "rdx", "rcx");
  return 0;
}

void switch_user(uint64_t argc, char *argv[]) {
  int total_len = (argv[argc - 1] + strlen(argv[argc - 1]) + 1) - (char*) argv;
  /* temporary area for putting user-accessible data */
  char *s = kmalloc(total_len, MALLOC_PAGE_ALIGN);
  uint64_t sp = physical(s);
  add_trans_user((void*) sp, (void*) sp, PROT_RW); /* sp is page aligned */

  /* copy strings and argv onto user-accessible area */
  for(int i = 0; i < argc; i++)
    argv[i] = (char*) (argv[i] - (char*) argv + sp);
  memcpy(s, argv, total_len);
  sys_execve(argv[0], (char**) sp, (char**) (sp + argc * sizeof(char*)));
}

int kernel_main(void* addr, uint64_t len, uint64_t argc, char *argv[]) {
  init_pagetable();
  /* new paging enabled! */
  init_allocator((void*) ((uint64_t) addr | KERNEL_BASE_OFFSET), len);
  if(register_syscall() != 0) return 1;
  switch_user(argc, argv);
  return 0;
}

```

`kernel/linker.script`:

```script
SECTIONS
{
  . = 0x0;
  .text : { *(.text) }
  . = 0x3000;
  .data : { *(.data) }
}

```

`kernel/mm/Makefile`:

```
TARGET := mm.a

include ../template.mk

```

`kernel/mm/kmalloc.c`:

```c
#include <mm/kmalloc.h>
#include <mm/translate.h>
#include <utils/panic.h>
#include <utils/string.h>

struct kmalloc_arena {
  void *top;
  uint64_t top_size;
  void *min_addr;
  struct chunk {
    uint64_t size;
    uint64_t pad;
    struct chunk *next;
  } sorted_bin;
};
static struct kmalloc_arena arena;

#define offsetof(TYPE, MEMBER) ((uint64_t) &((TYPE *)0)->MEMBER)

#define chunk2mem(c) ((void*) ((uint8_t*)(c) + offsetof(struct chunk, next)))
#define mem2chunk(m) ((struct chunk*) ((uint8_t*)(m) - offsetof(struct chunk, next)))

void init_allocator(void *addr, uint64_t len) {
  if(len == 0 || (len & 0xfff) != 0) panic("kmalloc.c#init_allocator: invalid length");

  arena.top = addr;
  arena.top_size = len;
  arena.min_addr = addr;
  memset(&arena.sorted_bin, 0, sizeof(arena.sorted_bin));
}

static inline int invalid_chunk_size(uint64_t s) {
  if(s == 0) return 1;
  if(s >= (1ull << 32)) return 1;
  if(s & 0xf) return 1;
  return 0;
}

static inline void insert_sorted(struct chunk *c) {
  struct chunk *now = arena.sorted_bin.next, *prev = &arena.sorted_bin;
  while(now != 0 && now->size < c->size) {
    prev = now;
    now = now->next;
  }
  // either now == 0 or now->size >= c->size
  prev->next = c;
  c->next = now;
}

static void *fetch_sorted_bin(uint64_t nb) {
  struct chunk *now = arena.sorted_bin.next, *prev = &arena.sorted_bin;
  while(now != 0) {
    if(invalid_chunk_size(now->size)) panic("kmalloc.c: invalid size of sorted bin");
    // best fit because this is the 'sorted' bin.
    if(now->size >= nb) {
      // remove it first
      prev->next = now->next;
      // exactly same size, just return it
      if(now->size == nb) {}
      else {
        // split!
        struct chunk *r = (struct chunk*) ((uint8_t*)now + nb);
        r->size = now->size - nb;
        insert_sorted(r);
      }
      memset(now, 0, sizeof(struct chunk));
      now->size = nb;
      return chunk2mem(now);
    }
    else {
      prev = now;
      now = now->next;
    }
  }
  return 0;
}

static void *malloc_top(uint64_t nb) {
  if(arena.top_size < nb) return 0;
  arena.top_size -= nb;
  struct chunk* c = (struct chunk*) arena.top;
  c->size = nb;
  arena.top += nb;
  return chunk2mem(c);
}

static void *int_kmalloc(uint64_t nb, int align) {
  if(align == MALLOC_NO_ALIGN) {
    void *ret = fetch_sorted_bin(nb);
    if(!ret) ret = malloc_top(nb);
    return ret;
  }
  if(align != MALLOC_PAGE_ALIGN) panic("kmalloc.c#kmalloc: invalid alignment");
  // address to be returned must be aligned
  // calculate the size of chunk to be split such that
  // remain_top & (ALIGN - 1) == ALIGN-offsetof(chunk, next)
  uint64_t cur = (uint64_t) arena.top & (align - 1);
  uint64_t consume = (((align - offsetof(struct chunk, next)) - cur) & (align - 1));
  void *gap = 0;
  if(consume == 0) ; /* already been fulfilled */
  else {
    gap = malloc_top(consume);
    if(gap == 0) return 0; // no enough memory
  }
  void *ret = malloc_top(nb); // this should satisfy the alignment
  kfree(gap);
  return ret;
}

#define alignup(v, p) (((v) & ((p)-1)) ? (((v) & (-(p))) + (p)) : (v))
void *kmalloc(uint64_t len, int align) {
  if(len >= (1ull << 32)) return 0; // fast fail
  uint64_t nb = alignup(len + offsetof(struct chunk, next), 0x80);
  void *victim = int_kmalloc(nb, align);
  if(align != MALLOC_NO_ALIGN &&
    ((uint64_t) victim & (align - 1))
    ) panic("kmalloc.c#kmalloc: alignment request failed");
  /* always clean up */
  memset(victim, 0, len);
  return victim;
}

void kfree(void *mem) {
  if(mem == 0) return;
  struct chunk* c = mem2chunk(mem);
  if(invalid_chunk_size(c->size)) panic("kmalloc.c#kfree: invalid size");
  if(c->size + (void*)c == arena.top) {
    arena.top = (void*) c;
    arena.top_size += c->size;
    c->size = 0;
  }
  else insert_sorted(c);
}

```

`kernel/mm/kmalloc.h`:

```h
#ifndef KMALLOC_H
#define KMALLOC_H

#include <stdint.h>

void init_allocator(void *addr, uint64_t len);

#define MALLOC_NO_ALIGN 0x0
#define MALLOC_PAGE_ALIGN 0x1000
void *kmalloc(uint64_t len, int align);
void kfree(void *addr);

#endif

```

`kernel/mm/mmap.c`:

```c
#include <mm/kmalloc.h>
#include <mm/mmap.h>
#include <mm/translate.h>
#include <utils/errno.h>
#include <utils/misc.h>
#include <utils/panic.h>

/* returns user-accessible page-aligned block
 * if addr == 0, use the last_mmapped address
 */
void *mmap(void *addr, uint64_t len, int prot) {
  if(len == 0 || len & 0xfff) panic("mmap.c: invalid length");
  void *ret = kmalloc(len, MALLOC_PAGE_ALIGN);
  if(ret == 0) return 0; // no memory

  static void *last_mmapped = (void*) -1;
  /* no ASLR */
  if(last_mmapped == (void*) -1) last_mmapped = (void*) 0x00007ffff7fff000ull;

  if(addr == 0) last_mmapped = addr = last_mmapped - len;
  for(uint64_t i = 0; i < len; i += 0x1000)
    add_trans_user(addr + i, ret + i, prot);
  return addr;
}

int mprotect(void *addr, uint64_t len, int prot) {
  if(!alignok(addr)) return -EINVAL;
  for(uint64_t i = 0; i < len; i += 0x1000) {
    if(!USER_MEM_RANGE_OK(addr + i) ||
      modify_permission(addr + i, prot) != 0)
      return -EACCES;
  }
  return 0;
}

```

`kernel/mm/mmap.h`:

```h
#ifndef MMAP_H
#define MMAP_H

#include <stdint.h>

void *mmap(void *addr, uint64_t len, int prot);
int mprotect(void *addr, uint64_t len, int prot);

#endif

```

`kernel/mm/translate.c`:

```c
#include <mm/kmalloc.h>
#include <mm/translate.h>
#include <utils/panic.h>

/* Maps
 *  0x8000000000 ~ 0x8040000000 -> 0 ~ 0x40000000
 */
void init_pagetable() {
  uint64_t* pml4;
  asm("mov %[pml4], cr3" : [pml4]"=r"(pml4));
  uint64_t* pdp = (uint64_t*) ((uint64_t) pml4 + 0x3000);
  pml4[1] = PDE64_PRESENT | PDE64_RW | (uint64_t) pdp; // 0x8000000000
  uint64_t* pd = (uint64_t*) ((uint64_t) pdp + 0x1000);
  pdp[0] = PDE64_PRESENT | PDE64_RW | (uint64_t) pd;
  for(uint64_t i = 0; i < 0x200; i++)
    pd[i] = PDE64_PRESENT | PDE64_RW | PDE64_PS | (i * KERNEL_PAGING_SIZE);
}

static inline uint64_t* get_pml4_addr() {
  uint64_t pml4;
  asm("mov %[pml4], cr3" : [pml4]"=r"(pml4));
  return (uint64_t*) (pml4 | KERNEL_BASE_OFFSET);
}

#define _OFFSET(v, bits) (((uint64_t)(v) >> (bits)) & 0x1ff)

#define PML4OFF(v) _OFFSET(v, 39)
#define PDPOFF(v) _OFFSET(v, 30)
#define PDOFF(v) _OFFSET(v, 21)
#define PTOFF(v) _OFFSET(v, 12)

/* if vaddr is already mapping to some address, overwrite it. */
void add_trans_user(void* vaddr_, void* paddr_, int prot) {
  uint64_t vaddr = (uint64_t) vaddr_;
  /* validation of vaddr should be done in sys_mmap, so we can simply panic here */
  if(!USER_MEM_RANGE_OK(vaddr)) panic("translate.c#add_trans_user: not allowed");
  uint64_t paddr = (uint64_t) paddr_ & ~KERNEL_BASE_OFFSET;
  uint64_t* pml4 = get_pml4_addr(), *pdp, *pd, *pt;
#define PAGING(p, c) do { \
    if(!(*p & PDE64_PRESENT)) { \
      c = (uint64_t*) kmalloc(0x1000, MALLOC_PAGE_ALIGN); \
      *p = PDE64_PRESENT | PDE64_RW | PDE64_USER | physical(c); \
    } else { \
      if(!(*p & PDE64_USER)) panic("translate.c#add_trans_user: invalid address"); \
      c = (uint64_t*) ((*p & -0x1000) | KERNEL_BASE_OFFSET); \
    } \
  } while(0);
  PAGING(&pml4[PML4OFF(vaddr)], pdp);
  PAGING(&pdp[PDPOFF(vaddr)], pd);
  PAGING(&pd[PDOFF(vaddr)], pt);
#undef PAGING
  pt[PTOFF(vaddr)] = PDE64_PRESENT | paddr;
  if(prot & PROT_R) pt[PTOFF(vaddr)] |= PDE64_USER;
  if(prot & PROT_W) pt[PTOFF(vaddr)] |= PDE64_RW;
}

int modify_permission(void *vaddr, int prot) {
  uint64_t *pml4 = get_pml4_addr(), *pdp, *pd, *pt;
#define PAGING(p, c) do { \
    if(!(*p & PDE64_PRESENT)) return -1; \
    c = (uint64_t*) ((*p & -0x1000) | KERNEL_BASE_OFFSET);\
  } while(0);
  PAGING(&pml4[PML4OFF(vaddr)], pdp);
  PAGING(&pdp[PDPOFF(vaddr)], pd);
  PAGING(&pd[PDOFF(vaddr)], pt);
#undef PAGING
  uint64_t* e = &pt[PTOFF(vaddr)];
  if(!(*e & PDE64_PRESENT)) return -1;
  *e &= ~(PDE64_USER | PDE64_RW);
  if(prot & PROT_R) *e |= PDE64_USER;
  if(prot & PROT_W) *e |= PDE64_RW;
  return 0;
}

/* translate the virtual address to physical address.
 * returns -1 if page not presented or permission not matched
 */
uint64_t translate(void *vaddr, int usermode, int writable) {
  uint64_t *pml4 = get_pml4_addr(), *pdp, *pd, *pt, *ret;
#define PAGING(p, c) do { \
    if(!(*p & PDE64_PRESENT)) return -1; \
    if(usermode && !(*p & PDE64_USER)) return -1; \
    if(writable && !(*p & PDE64_RW)) return -1; \
    c = (uint64_t*) ((*p & -0x1000) | KERNEL_BASE_OFFSET);\
  } while(0);
  PAGING(&pml4[PML4OFF(vaddr)], pdp);
  PAGING(&pdp[PDPOFF(vaddr)], pd);
  PAGING(&pd[PDOFF(vaddr)], pt);
  /* special handles 2MB paging */
  if(pd[PDOFF(vaddr)] & PDE64_PS)
    return (pd[PDOFF(vaddr)] & -0x200000) + ((uint64_t) vaddr & 0x1fffff);
  PAGING(&pt[PTOFF(vaddr)], ret);
#undef PAGING
  return physical(ret) + ((uint64_t) vaddr & 0xfff);
}

/* vaddr should always an address of kernel-space */
uint64_t physical(void *vaddr_) {
  uint64_t vaddr = (uint64_t) vaddr_;
  if(vaddr & KERNEL_BASE_OFFSET) return vaddr ^ KERNEL_BASE_OFFSET;
  panic("translate.c#physical: don't pass non-kernel based address");
}

int pf_to_prot(Elf64_Word pf) {
  int ret = 0;
  if(pf & PF_R) ret |= PROT_R;
  if(pf & PF_W) ret |= PROT_W;
  if(pf & PF_X) ret |= PROT_X;
  return ret;
}

```

`kernel/mm/translate.h`:

```h
#ifndef TRANSLATE_H
#define TRANSLATE_H

#include <stdint.h>

#include <elf/elf.h>

#define PROT_R 1
#define PROT_W 2
#define PROT_X 4
#define PROT_RW (PROT_R | PROT_W)
#define PROT_RWX (PROT_RW | PROT_X)

/* 64-bit page * entry bits */
#define PDE64_PRESENT 1
#define PDE64_RW (1 << 1)
#define PDE64_USER (1 << 2)
#define PDE64_ACCESSED (1 << 5)
#define PDE64_DIRTY (1 << 6)
#define PDE64_PS (1 << 7)
#define PDE64_G (1 << 8)

#define KERNEL_PAGING_SIZE (0x200000)
#define MIN_MMAP_ADDR KERNEL_PAGING_SIZE
#define KERNEL_BASE_OFFSET (0x8000000000llu)

#define MIN_USER_MEM MIN_MMAP_ADDR

#define USER_MEM_RANGE_OK(v) ((uint64_t)(v) >= MIN_USER_MEM && \
  ((uint64_t)(v) >> 48) == 0 && \
  ((uint64_t)(v) >> 39) != 1)

void init_pagetable();

uint64_t translate(void* vaddr, int usermode, int writable);
uint64_t physical(void *vaddr);
void add_trans_user(void* vaddr, void* paddr, int prot);
int modify_permission(void *vaddr, int prot);
int pf_to_prot(Elf64_Word pf);

#endif

```

`kernel/mm/uaccess.c`:

```c
#include <mm/kmalloc.h>
#include <mm/translate.h>
#include <mm/uaccess.h>
#include <utils/misc.h>
#include <utils/string.h>

int access_ok(int type, const void* addr_, uint64_t size) {
  uint64_t addr = (uint64_t) addr_;
  if(!USER_MEM_RANGE_OK(addr)) return 0;
  if(!USER_MEM_RANGE_OK(addr + size - 1)) return 0;
  for(uint64_t v = aligndown(addr); v < alignup(addr + size); v += 0x1000)
    if(translate((void*) v, 1, type) == (uint64_t) -1) return 0;
  return 1;
}

/* check if addr ~ addr+strlen(addr) are all accessible */
int access_string_ok(const void *addr_) {
  if(!access_ok(VERIFY_READ, addr_, 1)) return 0;
  uint64_t addr = (uint64_t) addr_;
  uint64_t remain_size = 0x1000 - (addr & 0xfff);
  /* we have checked the whole page of addr is accessible */
  uint64_t l = strnlen(addr_, remain_size);
  /* length not enough.. recursive it */
  if(l == remain_size) return access_string_ok((void*) (addr + l));
  return 1;
}

void *copy_str_from_user(const char *s) {
  int len = strlen(s);
  void *dst = kmalloc(len + 1, MALLOC_NO_ALIGN);
  if(dst == 0) return 0;
  memcpy(dst, s, len + 1);
  return dst;
}

```

`kernel/mm/uaccess.h`:

```h
#ifndef UACCESS_H
#define UACCESS_H

#include <stdint.h>

#define VERIFY_READ 0
#define VERIFY_WRITE 1

int access_ok(int type, const void* addr, uint64_t size);
int access_string_ok(const void *addr);
void *copy_str_from_user(const char *s);

#endif

```

`kernel/syscalls/Makefile`:

```
TARGET := syscalls.a

include ../template.mk

```

`kernel/syscalls/sys_close.h`:

```h
#ifndef SYS_CLOSE_H
#define SYS_CLOSE_H

#include <hypercalls/hp_close.h>

/* alias is enough */
#define sys_close hp_close

#endif

```

`kernel/syscalls/sys_execve.c`:

```c
#include <elf/elf.h>
#include <hypercalls/hp_read.h>
#include <mm/kmalloc.h>
#include <mm/mmap.h>
#include <mm/translate.h>
#include <mm/uaccess.h>
#include <syscalls/sys_close.h>
#include <syscalls/sys_execve.h>
#include <syscalls/sys_mmap.h>
#include <syscalls/sys_open.h>
#include <syscalls/sys_read.h>
#include <utils/errno.h>
#include <utils/misc.h>
#include <utils/string.h>

static int load_binary(int fd, process* p) {
  void *buf = kmalloc(0x1000, MALLOC_NO_ALIGN);
  hp_read(fd, physical(buf), 0x1000);
  Elf64_Ehdr *ehdr = (Elf64_Ehdr*) buf;
  if(memcmp(ehdr->e_ident, "\177ELF\x02\x01\x01\0\0\0\0\0\0\0\0\0", 16) != 0)
    return -ENOEXEC;
  p->entry = ehdr->e_entry;
  p->load_addr = 0;
  if(ehdr->e_type != ET_EXEC && ehdr->e_type != ET_DYN) return -ENOEXEC;
  if(ehdr->e_type == ET_DYN) p->load_addr = 0x0000555555554000ull; // who care ASLR
  if(ehdr->e_phoff != sizeof(*ehdr)) return -EINVAL;
  if(ehdr->e_phentsize != sizeof(Elf64_Phdr)) return -EINVAL;
  if(ehdr->e_phoff + (uint64_t) ehdr->e_phentsize * ehdr->e_phnum > 0x1000)
    return -EINVAL;
  Elf64_Phdr *phdr = (Elf64_Phdr*) ((uint8_t*) buf + ehdr->e_phoff);
  for(int i = 0; i < ehdr->e_phnum; i++, phdr++)
    if(phdr->p_type == PT_LOAD) {
      uint64_t sz = phdr->p_filesz;
      uint64_t st = p->load_addr + aligndown(phdr->p_vaddr),
               ed = p->load_addr + alignup(phdr->p_vaddr + sz);
      int prot = pf_to_prot(phdr->p_flags);
      /* not a good idea, but it works */
      void *r = sys_mmap(
        (void*) st, sz + (phdr->p_offset & 0xfff), prot,
        MAP_FIXED, fd, phdr->p_offset & -0x1000
      );
      if(r != (void*) st) return (int) (int64_t) r; // error returned by sys_mmap

      if(phdr->p_memsz > sz) {
        uint64_t bss_ed = p->load_addr + alignup(phdr->p_vaddr + phdr->p_memsz);
        if(bss_ed != ed) {
          if(mmap((void*) ed, bss_ed - ed, prot) != (void*) ed)
            return -ENOMEM;
        }
      }
    }
  /* set up stack */
  p->stack_base = 0x00007ffffffff000ull;
  p->stack_size = 0x40000;
  p->rsp = p->stack_base - 0x1000;
  void *st = (void*) (p->stack_base - p->stack_size);
  if(mmap(st, p->stack_size, PROT_RW) != st) return -ENOMEM;
  return 0;
}

static int check_and_get_count(char *const ary[]) {
  if(!access_ok(VERIFY_READ, ary, 8)) return -EFAULT;
  int i = 0;
  while(*ary != 0) {
    if(!access_string_ok(*ary)) return -EFAULT;
    ++ary;
    ++i;
    if(!access_ok(VERIFY_READ, ary, 8)) return -EFAULT;
  }
  return i;
}

#define STACK_ALLOC(sp, len) ({ sp -= len ; (uint64_t*) sp; })
#define ROUNDDOWN(sp) sp &= -0x10

static int create_elf_info(process *p, char *const argv[], char *const envp[]) {
  /* we must push strings first */
  int argc = check_and_get_count(argv);
  if(argc < 0) return argc;
  int envc = check_and_get_count(envp);
  if(envc < 0) return envc;

  char **copy = (char**) kmalloc((argc + envc + 2) * sizeof(char*), MALLOC_NO_ALIGN);
  for(int i = envc - 1; i >= 0; i--) {
    uint64_t len = strlen(envp[i]) + 1;
    copy[argc + 1 + i] = (char*) STACK_ALLOC(p->rsp, len);
    memcpy(copy[argc + 1 + i], envp[i], len);
  }

  for(int i = argc - 1; i >= 0; i--) {
    uint64_t len = strlen(argv[i]) + 1;
    copy[i] = (char*) STACK_ALLOC(p->rsp, len);
    memcpy(copy[i], argv[i], len);
  }

  /* program is happier if rsp is aligned */
  /* The final rsp must be 16-byte aligned, so we calculate how many bytes
   * will be copied later, and round the rsp here.
   */
  ROUNDDOWN(p->rsp);
  if((argc + 1 + envc + 1 + 1) & 1) STACK_ALLOC(p->rsp, 8);

  /* push envp and argv onto stack */
  for(int i = argc + envc + 1; i >= 0; i--)
    *(char**) STACK_ALLOC(p->rsp, 8) = copy[i];
  kfree(copy);

  /* last step, push argc onto it */
  *(uint64_t*) STACK_ALLOC(p->rsp, 8) = argc;
  return 0;
}

/* can only be used in kernel_main */
int sys_execve(const char *path, char *const argv[], char *const envp[]) {
  int fd = sys_open(path);
  if(fd < 0) return fd;
  process p;
  int ret = load_binary(fd, &p);
  if(ret < 0) return ret;
  sys_close(fd);
  if(create_elf_info(&p, argv, envp)) return -EFAULT;
  /* this is an execve call so we can ignore the saved registers (rip, rsp) */
  asm volatile(
    "mov [rip + kernel_stack], rsp;"
    "mov rcx, %[entry];" /* rip */
    "mov r11, 0x2;"      /* rflags */
    "mov rsp, %[rsp];"
    /* clean up registers */
    "xor rax, rax;"
    "xor rbx, rbx;"
    "xor rdx, rdx;"
    "xor rdi, rdi;"
    "xor rsi, rsi;"
    "xor rbp, rbp;"
    "xor r8, r8;"
    "xor r9, r9;"
    "xor r10, r10;"
    "xor r12, r12;"
    "xor r13, r13;"
    "xor r14, r14;"
    "xor r15, r15;"
    "xor rbp, rbp;"
    ".byte 0x48;"
    "sysretq"
    :: [entry]"r"(p.entry + p.load_addr), [rsp]"r"(p.rsp)
    : "r11", "rcx"
  );
  /* never reached */
  return -EPERM;
}

```

`kernel/syscalls/sys_execve.h`:

```h
#ifndef SYS_EXECVE_H
#define SYS_EXECVE_H

#include <stdint.h>

typedef struct process {
  uint64_t load_addr;
  uint64_t entry;
  uint64_t stack_base;
  uint64_t stack_size;
  uint64_t rsp;
} process;

int sys_execve(const char *path, char *const argv[], char *const envp[]);

#endif

```

`kernel/syscalls/sys_exit.c`:

```c
#include <hypercalls/hypercall.h>
#include <syscalls/sys_exit.h>

void sys_exit(int status) {
  hypercall(NR_HP_exit, status);
}

```

`kernel/syscalls/sys_exit.h`:

```h
#ifndef SYS_EXIT_H
#define SYS_EXIT_H

void sys_exit(int status);

#endif

```

`kernel/syscalls/sys_mmap.c`:

```c
#include <hypercalls/hp_lseek.h>
#include <hypercalls/hp_read.h>
#include <mm/mmap.h>
#include <mm/translate.h>
#include <syscalls/sys_mmap.h>
#include <utils/errno.h>
#include <utils/misc.h>

void *sys_mmap(
  void *addr, uint64_t len, int prot,
  int flags, int fd, uint64_t offset) {

  if(!alignok(addr)) return (void*) -EINVAL;
  if(len == 0) return (void*) -EINVAL;

  if(!(flags & MAP_FIXED)) addr = 0; // no MAP_FIXED, address decided by kernel
  else if(addr != 0 && !USER_MEM_RANGE_OK(addr)) return (void*) -EINVAL;

  uint64_t aligned_len = alignup(len);
  addr = mmap(addr, aligned_len, prot | PROT_RW); // temporary mark it read/writable
  if(addr == 0) return (void*) -ENOMEM;

  if(fd >= 0) {
    int ret = hp_lseek(fd, offset, SEEK_SET);
    if(ret < 0) return (void*) (int64_t) ret;
    hp_read(fd, translate(addr, 1, 1), len);
  }

  /* this should never fail */
  mprotect(addr, aligned_len, prot); // correct protection

  return addr;
}

```

`kernel/syscalls/sys_mmap.h`:

```h
#ifndef SYS_MMAP_H
#define SYS_MMAP_H

#include <stdint.h>

#define MAP_FIXED 0x10

void *sys_mmap(
  void *addr, uint64_t len, int prot,
  int flags, int fd, uint64_t offset);

#endif

```

`kernel/syscalls/sys_open.c`:

```c
#include <hypercalls/hp_open.h>
#include <mm/kmalloc.h>
#include <mm/translate.h>
#include <mm/uaccess.h>
#include <syscalls/sys_open.h>
#include <utils/errno.h>

int sys_open(const char *path) {
  if(!access_string_ok(path)) return -EFAULT;
  void *dst = copy_str_from_user(path);
  if(dst == 0) return -ENOMEM;
  int fd = hp_open(physical(dst));
  kfree(dst);
  return fd;
}

```

`kernel/syscalls/sys_open.h`:

```h
#ifndef SYS_OPEN_H
#define SYS_OPEN_H

int sys_open(const char *path);

#endif

```

`kernel/syscalls/sys_read.c`:

```c
#include <hypercalls/hp_read.h>
#include <mm/kmalloc.h>
#include <mm/translate.h>
#include <mm/uaccess.h>
#include <syscalls/sys_read.h>
#include <utils/errno.h>
#include <utils/string.h>

int64_t sys_read(int fildes, void *buf, uint64_t nbyte) {
  if(fildes < 0) return -EBADF;
  if(!access_ok(VERIFY_WRITE, buf, nbyte)) return -EFAULT;
  void *dst = kmalloc(nbyte, MALLOC_NO_ALIGN);
  int64_t ret = hp_read(fildes, physical(dst), nbyte);
  if(ret >= 0) memcpy(buf, dst, ret);
  kfree(dst);
  return ret;
}

```

`kernel/syscalls/sys_read.h`:

```h
#ifndef SYS_READ_H
#define SYS_READ_H

int64_t sys_read(int fildes, void *buf, uint64_t nbyte);

#endif

```

`kernel/syscalls/sys_write.c`:

```c
#include <hypercalls/hp_write.h>
#include <mm/kmalloc.h>
#include <mm/translate.h>
#include <mm/uaccess.h>
#include <syscalls/sys_write.h>
#include <utils/errno.h>
#include <utils/string.h>

int64_t sys_write(int fildes, void *buf, uint64_t nbyte) {
  if(fildes < 0) return -EBADF;
  if(!access_ok(VERIFY_READ, buf, nbyte)) return -EFAULT;
  void *dst = kmalloc(nbyte, MALLOC_NO_ALIGN);
  memcpy(dst, buf, nbyte);
  int64_t ret = hp_write(fildes, physical(dst), nbyte);
  kfree(dst);
  return ret;
}

```

`kernel/syscalls/sys_write.h`:

```h
#ifndef SYS_WRITE_H
#define SYS_WRITE_H

int64_t sys_write(int fildes, void *buf, uint64_t nbyte);

#endif

```

`kernel/syscalls/syscall_entry.s`:

```s
.globl syscall_entry, kernel_stack
.extern syscall_handler
.intel_syntax noprefix

kernel_stack: .quad 0
user_stack: .quad 0

syscall_entry:
  mov [rip + user_stack], rsp
  mov rsp, [rip + kernel_stack]
  /* save non-callee saved registers */
  push rdi
  push rsi
  push rdx
  push rcx
  push r8
  push r9
  push r10
  push r11

  /* the forth argument */
  mov rcx, r10
  call syscall_handler

  pop r11
  pop r10
  pop r9
  pop r8
  pop rcx
  pop rdx
  pop rsi
  pop rdi

  mov rsp, [rip + user_stack]
  .byte 0x48
  sysretq

```

`kernel/syscalls/syscall_handler.c`:

```c
#include <mm/translate.h>
#include <syscalls/syscall_handler.h>
#include <utils/errno.h>

static const void* syscall_table[MAX_SYS_NR + 1] = {
#define ENTRY(f) [SYS_##f]=sys_##f

  ENTRY(read),
  ENTRY(write),
  ENTRY(open),
  ENTRY(close),
  ENTRY(exit),

#undef ENTRY
};

uint64_t syscall_handler(
  uint64_t arg0, uint64_t arg1, uint64_t arg2,
  uint64_t arg3, uint64_t arg4, uint64_t arg5) {

  uint32_t nr;
  asm("mov %[nr], eax;"
    : [nr] "=r"(nr)
    );
  if(nr > MAX_SYS_NR || syscall_table[nr] == 0) return -ENOSYS;
  void *fptr = (void*) ((uint64_t) syscall_table[nr] | KERNEL_BASE_OFFSET);
  return ((uint64_t(*)(
        uint64_t, uint64_t, uint64_t,
        uint64_t, uint64_t, uint64_t)) fptr)(
    arg0, arg1, arg2,
    arg3, arg4, arg5
    );
}

```

`kernel/syscalls/syscall_handler.h`:

```h
#ifndef SYSCALL_HANDLER_H
#define SYSCALL_HANDLER_H

#include <stdint.h>

#include <syscalls/sys_close.h>
#include <syscalls/sys_exit.h>
#include <syscalls/sys_open.h>
#include <syscalls/sys_read.h>
#include <syscalls/sys_write.h>

#define SYS_read 0
#define SYS_write 1
#define SYS_open 2
#define SYS_close 3
#define SYS_exit 60

#define MAX_SYS_NR 60

uint64_t syscall_handler(uint64_t arg0, uint64_t arg1, uint64_t arg2,
  uint64_t arg3, uint64_t arg4, uint64_t arg5);

#endif

```

`kernel/template.mk`:

```mk
CSRCS	:= $(wildcard *.c)
SSRCS	:= $(wildcard *.s)
OBJS	:= $(SSRCS:.s=.o) $(CSRCS:.c=.o)
DEPS	:= $(CSRCS:.c=.d)

CFLAGS := -nostdlib -Os -Wall -Werror -fPIE -pie -masm=intel -I..

all: $(TARGET)

-include $(DEPS)

$(TARGET): $(OBJS)
	$(AR) rcs $@ $^

%.o: %.c %.h
	$(CC) $(CFLAGS) -c -MMD -MP $<

%.o: %.s
	$(AS) $^ -o $@

.PHONY: clean
clean:
	$(RM) $(DEPS) $(OBJS) $(TARGET)

```

`kernel/utils/Makefile`:

```
TARGET := utils.a

include ../template.mk

```

`kernel/utils/errno.h`:

```h
#ifndef ERRNO_H
#define ERRNO_H

/* ERROR NO */
#define EPERM 1
#define ENOEXEC 8
#define EBADF 9
#define ENOMEM 12
#define EACCES 13
#define EFAULT 14
#define EINVAL 22
#define ENFILE 23
#define ENOSYS 38
#define ENOHP ENOSYS

#endif

```

`kernel/utils/misc.h`:

```h
#ifndef MISC_H
#define MISC_H

#define aligndown(v) ((uint64_t) (v) & -0x1000)
#define alignup(v) (((uint64_t) (v) & 0xfff) ? aligndown(v) + 0x1000 : (uint64_t) (v))
#define alignok(v) ((uint64_t) (v) == aligndown(v))

#endif


```

`kernel/utils/panic.h`:

```h
#ifndef PANIC_H
#define PANIC_H

/* panic occurs when assertion fails in kernel */
void __attribute__((noreturn)) panic(const char *s);

#endif

```

`kernel/utils/panic.s`:

```s
.globl panic
.extern hlt
.intel_syntax noprefix
panic:
  mov eax, edi
  mov dx, 0xffff /* NR_HP_panic */
  out dx, eax
  jmp hlt

```

`kernel/utils/string.c`:

```c
#include <utils/string.h>

/* no memory accessibility checks in these string functions */

uint64_t strlen(const char *s) {
  return strnlen(s, (1ull << 63) - 1);
}

uint64_t strnlen(const char *s, uint64_t maxlen) {
  uint64_t i = 0;
  while(i < maxlen) {
    if(*s == 0) return i;
    i++; s++;
  }
  return maxlen;
}

void *memset(void *b, int c, uint64_t len) {
  for(int i=0;i<len;i++)
    ((uint8_t*)b)[i] = (uint8_t)c;
  return b;
}

void *memcpy(void *dst, const void *src, uint64_t n) {
  asm(
    "mov rcx, %[n];"
    "rep movsb byte ptr [%[dst]], byte ptr [%[src]];"
    :: [n]"r"(n), [dst]"D"(dst), [src]"S"(src) : "rcx"
    );
  return dst;
}

int memcmp(const void *s1, const void *s2, uint64_t n) {
  unsigned char u1, u2;
  for(; n--; s1++, s2++) {
    u1 = *(unsigned char *) s1;
    u2 = *(unsigned char *) s2;
    if (u1 != u2) return u1 - u2;
  }
  return 0;
}

```

`kernel/utils/string.h`:

```h
#ifndef STRING_H
#define STRING_H

#include <stdint.h>

uint64_t strlen(const char *s);
uint64_t strnlen(const char *s, uint64_t maxlen);
void *memset(void *b, int c, uint64_t len);
void *memcpy(void *dst, const void *src, uint64_t n);
int memcmp(const void *s1, const void *s2, uint64_t n);

#endif

```

`user/gen.py`:

```py
#!/usr/bin/env python3

from pathlib import Path
from pwn import asm, context, make_elf, shellcraft
import os

def generate(filename, data):
    elf = make_elf(data)
    path = os.path.join(Path().absolute(), filename)
    open(path, 'wb').write(elf)
    os.chmod(path, 0o755)

context.arch = 'amd64'

generate('orw.elf', asm(
    f'''
    mov rdi, [rsp]
    cmp rdi, 2
    jb exit
    mov rdi, [rsp + 16] /* argv[1] */
    {shellcraft.open('rdi', 'O_RDONLY', 0)}
    {shellcraft.read('rax', 'rsp', 0x1000)}
    {shellcraft.write(1, 'rsp', 'rax')}
exit:
    xor rdi, rdi
    mov rax, 60
    syscall

    /* should not reach here */
    hlt
    '''))

```