Project Path: arc_apkunpacker_IDA-Gepetto_q2jp3_u2

Source Tree:

```txt
arc_apkunpacker_IDA-Gepetto_q2jp3_u2
├── README.md
├── gepetto
│   ├── __init__.py
│   ├── __pycache__
│   │   ├── __init__.cpython-310.pyc
│   │   └── config.cpython-310.pyc
│   ├── config.ini
│   ├── config.py
│   ├── ida
│   │   ├── __init__.py
│   │   ├── __pycache__
│   │   │   ├── __init__.cpython-310.pyc
│   │   │   ├── handlers.cpython-310.pyc
│   │   │   └── ui.cpython-310.pyc
│   │   ├── handlers.py
│   │   └── ui.py
│   ├── locales
│   │   ├── ca_ES
│   │   │   └── LC_MESSAGES
│   │   │       ├── gepetto.mo
│   │   │       └── gepetto.po
│   │   ├── es_ES
│   │   │   └── LC_MESSAGES
│   │   │       ├── gepetto.mo
│   │   │       └── gepetto.po
│   │   ├── fr_FR
│   │   │   └── LC_MESSAGES
│   │   │       ├── gepetto.mo
│   │   │       └── gepetto.po
│   │   ├── gepetto.pot
│   │   ├── it_IT
│   │   │   └── LC_MESSAGES
│   │   │       ├── gepetto.mo
│   │   │       └── gepetto.po
│   │   ├── ko_KR
│   │   │   └── LC_MESSAGES
│   │   │       ├── gepetto.mo
│   │   │       └── gepetto.po
│   │   ├── ru
│   │   │   └── LC_MESSAGES
│   │   │       ├── gepetto.mo
│   │   │       └── gepetto.po
│   │   ├── tr
│   │   │   └── LC_MESSAGES
│   │   │       ├── gepetto.mo
│   │   │       └── gepetto.po
│   │   └── zh_CN
│   │       └── LC_MESSAGES
│   │           ├── gepetto.mo
│   │           └── gepetto.po
│   └── models
│       ├── __init__.py
│       ├── __pycache__
│       │   ├── __init__.cpython-310.pyc
│       │   ├── base.cpython-310.pyc
│       │   └── openai.cpython-310.pyc
│       ├── base.py
│       └── openai.py
└── gepetto.py

```

`README.md`:

```md
# Original Project
https://github.com/JusticeRage/Gepetto

All credit goes to original repo owner.

# IDA-Gepetto
Gepetto is a Python script which uses Local LLM to provide meaning to functions decompiled by IDA Pro. At the moment, it can ask any local model to explain what a function does, and to automatically rename its variables. Here is a simple example of what results it can provide in mere seconds:

<img width="595" alt="IDA" src="https://github.com/apkunpacker/IDA-Gepetto/assets/27184655/565daaaf-7c39-401d-b411-17b2dd90aad3">

<img width="1505" alt="LMStudio" src="https://github.com/apkunpacker/IDA-Gepetto/assets/27184655/cf99ba0f-7d2a-4ea4-8bb2-845e4a240844">



## Setup

Simply drop this script (as well as the `gepetto/` folder) into your IDA plugins folder (`$IDAUSR/plugins`). 
By default, on Windows, this should be `%AppData%\Hex-Rays\IDA Pro\plugins` (you may need to create the folder).

You will need to add the required packages to IDA's Python installation for the script to work.
Find which interpreter IDA is using by checking the following registry key: 
`Computer\HKEY_CURRENT_USER\Software\Hex-Rays\IDA` (default on Windows: `%LOCALAPPDATA%\Programs\Python\Python39`).

## Usage

Once the plugin is installed properly, you should be able to invoke it from the context menu of IDA's pseudocode window,
as shown in the screenshot below:
<img width="1410" alt="Use" src="https://github.com/apkunpacker/IDA-Gepetto/assets/27184655/f9d5d787-2ce7-4800-93e7-63ba7686a114">

You can also use the following hotkeys:

- Ask the model to explain the function: `Ctrl` + `Alt` + `H`
- Request better names for the function's variables: `Ctrl` + `Alt` + `R`

Initial testing shows that asking for better names works better if you ask for an explanation of the function first – I
assume because the model then uses its own comment to make more accurate suggestions.
There is an element of randomness to the AI's replies. If for some reason the initial response you get doesn't suit you,
you can always run the command again.


```

`gepetto.py`:

```py
import gepetto.config


def PLUGIN_ENTRY():
    gepetto.config.load_config()  # Loads configuration data from gepetto/config.ini

    # Only import the rest of the code after the translations have been loaded, because the _ function (gettext)
    # needs to have been imported in the namespace first.
    from gepetto.ida.ui import GepettoPlugin
    return GepettoPlugin()

```

`gepetto/config.ini`:

```ini
[Gepetto]
MODEL = Local LLM

# Specify the program language. It can be "fr_FR", "zh_CN", or any folder in locales. Defaults to English.
LANGUAGE = 

[OpenAI]
# Set your API key here, or put it in the OPENAI_API_KEY environment variable.
API_KEY = 

# Set your OpenAI proxy here. It will be used for all protocols.
# Can also be provided via the OPENAI_BASE_URL environment variable.
# Example: OPENAI_PROXY = 127.0.0.1:7890
OPENAI_PROXY =

# Base URL if you want to redirect requests to a different / local model.
# Leave blank unless you know what you are doing :)
BASE_URL =

```

`gepetto/config.py`:

```py
import configparser
import gettext
import os

from gepetto.models.base import get_model

translate = None
model = None
parsed_ini = None


def load_config():
    """
    Loads the configuration of the plugin from the INI file. Sets up the correct locale and language model.
    Also prepares an OpenAI client configured accordingly to the user specifications.
    :return:
    """
    global translate, model, parsed_ini
    parsed_ini = configparser.RawConfigParser()
    parsed_ini.read(os.path.join(os.path.abspath(os.path.dirname(__file__)), "config.ini"))

    # Set up translations
    language = parsed_ini.get('Gepetto', 'LANGUAGE')
    translate = gettext.translation('gepetto',
                                    os.path.join(os.path.abspath(os.path.dirname(__file__)), "locales"),
                                    fallback=True,
                                    languages=[language])

    # Select model
    requested_model = parsed_ini.get('Gepetto', 'MODEL')
    model = get_model(requested_model)


def update_config(section, option, new_value):
    """
    Updates a single entry in the configuration.
    :param section: The section in which the option is located
    :param option: The option to update
    :param new_value: The new value to set
    :return:
    """
    path = os.path.join(os.path.abspath(os.path.dirname(__file__)), "config.ini")
    config = configparser.RawConfigParser()
    config.read(path)
    config.set(section, option, new_value)
    with open(path, "w") as f:
        config.write(f)

```

`gepetto/ida/handlers.py`:

```py
import functools
import json
import re
import textwrap

import idaapi
import ida_hexrays
import idc

import gepetto.config
from gepetto.models.base import get_model

_ = gepetto.config.translate.gettext


def comment_callback(address, view, response):
    """
    Callback that sets a comment at the given address.
    :param address: The address of the function to comment
    :param view: A handle to the decompiler window
    :param response: The comment to add
    """
    response = "\n".join(textwrap.wrap(response, 80, replace_whitespace=False))

    # Add the response as a comment in IDA, but preserve any existing non-Gepetto comment
    comment = idc.get_func_cmt(address, 0)
    comment = re.sub(
        r'----- ' + _("Comment generated by Gepetto") + ' -----.*?----------------------------------------',
        r"",
        comment,
        flags=re.DOTALL)

    idc.set_func_cmt(address, '----- ' + _("Comment generated by Gepetto") +
                     f" -----\n\n"
                     f"{response.strip()}\n\n"
                     f"----------------------------------------\n\n"
                     f"{comment.strip()}", 0)
    # Refresh the window so the comment is displayed properly
    if view:
        view.refresh_view(False)
    print(_("{model} query finished!").format(model=str(gepetto.config.model)))


# -----------------------------------------------------------------------------

class ExplainHandler(idaapi.action_handler_t):
    """
    This handler is tasked with querying the model for an explanation of the
    given function. Once the reply is received, it is added as a function
    comment.
    """

    def __init__(self):
        idaapi.action_handler_t.__init__(self)

    def activate(self, ctx):
        decompiler_output = ida_hexrays.decompile(idaapi.get_screen_ea())
        v = ida_hexrays.get_widget_vdui(ctx.widget)
        gepetto.config.model.query_model_async(
            _("Can you explain what the following C function does and suggest a better name for "
              "it?\n{decompiler_output}").format(decompiler_output=str(decompiler_output)),
            functools.partial(comment_callback, address=idaapi.get_screen_ea(), view=v))
        return 1

    # This action is always available.
    def update(self, ctx):
        return idaapi.AST_ENABLE_ALWAYS


# -----------------------------------------------------------------------------

def rename_callback(address, view, response, retries=0):
    """
    Callback that extracts a JSON array of old names and new names from the
    response and sets them in the pseudocode.
    :param address: The address of the function to work on
    :param view: A handle to the decompiler window
    :param response: The response from the model
    :param retries: The number of times that we received invalid JSON
    """
    formatted_json = json.dumps(response, indent=4)
    names = json.loads(formatted_json)
    

    # The rename function needs the start address of the function
    function_addr = idaapi.get_func(address).start_ea
    # print("function addr :",names)

    replaced = []
    for n in names:
        if idaapi.IDA_SDK_VERSION < 760:
            lvars = {lvar.name: lvar for lvar in view.cfunc.lvars}
            if n in lvars:
                if view.rename_lvar(lvars[n], names[n], True):
                    replaced.append(n)
        else:
            if ida_hexrays.rename_lvar(function_addr, n, names[n]):
                replaced.append(n)

    # Update possible names left in the function comment
    comment = idc.get_func_cmt(address, 0)
    if comment and len(replaced) >= 0:
        for n in replaced:
            comment = re.sub(r'\b%s\b' % n, names[n], comment)
        idc.set_func_cmt(address, comment, 0)

    # Refresh the window to show the new names
    if view:
        view.refresh_view(True)
    print(_("{model} query finished! {replaced} variable(s) renamed.").format(model=str(gepetto.config.model),
                                                                              replaced=len(replaced)))


# -----------------------------------------------------------------------------

class RenameHandler(idaapi.action_handler_t):
    """
    This handler requests new variable names from the model and updates the
    decompiler's output.
    """

    def __init__(self):
        idaapi.action_handler_t.__init__(self)

    def activate(self, ctx):
        decompiler_output = ida_hexrays.decompile(idaapi.get_screen_ea())
        #print("Decompiler :",decompiler_output)
        v = ida_hexrays.get_widget_vdui(ctx.widget)
        gepetto.config.model.query_model_async(
            _("Analyze the following C function:\n{decompiler_output}"
              "\nSuggest better variable names(don't use space in name), reply with a JSON array where keys are the original"
              " names and values are the proposed names. Do not explain anything, only print the "
              "JSON dictionary without any comments. Strictly do not add any comments in JSON dictionary").format(decompiler_output=str(decompiler_output)),
            functools.partial(rename_callback, address=idaapi.get_screen_ea(), view=v),
            additional_model_options={"response_format": {"type": "json_object"}})
        return 1

    # This action is always available.
    def update(self, ctx):
        return idaapi.AST_ENABLE_ALWAYS


# -----------------------------------------------------------------------------

class SwapModelHandler(idaapi.action_handler_t):
    """
    This handler replaces the model currently in use with another one selected by the user,
    and updates the configuration.
    """

    def __init__(self, new_model, plugin):
        self.new_model = new_model
        self.plugin = plugin

    def activate(self, ctx):
        gepetto.config.model = get_model(self.new_model)
        gepetto.config.update_config("Gepetto", "MODEL", self.new_model)
        # Refresh the menus to reflect which model is currently selected.
        self.plugin.generate_plugin_select_menu()

    def update(self, ctx):
        return idaapi.AST_ENABLE_ALWAYS

```

`gepetto/ida/ui.py`:

```py
import random
import string

import idaapi
import ida_hexrays

import gepetto.config
from gepetto.ida.handlers import ExplainHandler, RenameHandler, SwapModelHandler
from gepetto.models.base import GPT4_MODEL_NAME, GPT3_MODEL_NAME

_ = gepetto.config.translate.gettext

# =============================================================================
# Setup the context menu and hotkey in IDA
# =============================================================================

class GepettoPlugin(idaapi.plugin_t):
    flags = 0
    explain_action_name = "gepetto:explain_function"
    explain_menu_path = "Edit/Gepetto/" + _("Explain function")
    rename_action_name = "gepetto:rename_function"
    rename_menu_path = "Edit/Gepetto/" + _("Rename variables")

    # Model selection menu
    select_gpt35_action_name = "gepetto:select_gpt35"
    select_gpt4_action_name = "gepetto:select_gpt4"
    select_gpt35_menu_path = "Edit/Gepetto/" + _("Select model") + f"/{GPT3_MODEL_NAME}"
    select_gpt4_menu_path = "Edit/Gepetto/" + _("Select model") + f"/{GPT4_MODEL_NAME}"

    wanted_name = 'Gepetto'
    wanted_hotkey = ''
    comment = _("Uses {model} to enrich the decompiler's output").format(model=str(gepetto.config.model))
    help = _("See usage instructions on GitHub")
    menu = None

    # -----------------------------------------------------------------------------

    def init(self):
        # Check whether the decompiler is available
        if not ida_hexrays.init_hexrays_plugin():
            return idaapi.PLUGIN_SKIP

        # Function explaining action
        explain_action = idaapi.action_desc_t(self.explain_action_name,
                                              _('Explain function'),
                                              ExplainHandler(),
                                              "Ctrl+Alt+G",
                                              _('Use {model} to explain the currently selected function').format(
                                                  model=str(gepetto.config.model)),
                                              201)
        idaapi.register_action(explain_action)
        idaapi.attach_action_to_menu(self.explain_menu_path, self.explain_action_name, idaapi.SETMENU_APP)

        # Variable renaming action
        rename_action = idaapi.action_desc_t(self.rename_action_name,
                                             _('Rename variables'),
                                             RenameHandler(),
                                             "Ctrl+Alt+R",
                                             _("Use {model} to rename this function's variables").format(
                                                 model=str(gepetto.config.model)),
                                             201)
        idaapi.register_action(rename_action)
        idaapi.attach_action_to_menu(self.rename_menu_path, self.rename_action_name, idaapi.SETMENU_APP)

        self.generate_plugin_select_menu()

        # Register context menu actions
        self.menu = ContextMenuHooks()
        self.menu.hook()

        return idaapi.PLUGIN_KEEP

    # -----------------------------------------------------------------------------

    def generate_plugin_select_menu(self):
        # Delete any possible previous entries
        idaapi.unregister_action(self.select_gpt35_action_name)
        idaapi.unregister_action(self.select_gpt4_action_name)
        idaapi.detach_action_from_menu(self.select_gpt35_menu_path, self.select_gpt35_action_name)
        idaapi.detach_action_from_menu(self.select_gpt4_menu_path, self.select_gpt4_action_name)

        # For some reason, IDA seems to have a bug when replacing actions by new ones with identical names.
        # The old action object appears to be reused, at least partially, leading to unwanted begavior?
        # The best workaround I have found is to generate random names each time.
        self.select_gpt35_action_name = f"gepetto:{''.join(random.choices(string.ascii_lowercase, k=7))}"
        self.select_gpt4_action_name = f"gepetto:{''.join(random.choices(string.ascii_lowercase, k=7))}"

        # Icon #208 is a check mark.
        select_gpt35_action = idaapi.action_desc_t(self.select_gpt35_action_name,
                                                   GPT3_MODEL_NAME,
                                                   None if str(gepetto.config.model) == GPT3_MODEL_NAME
                                                   else SwapModelHandler(GPT3_MODEL_NAME, self),
                                                   "",
                                                   "",
                                                   208 if str(gepetto.config.model) == GPT3_MODEL_NAME else 0)

        idaapi.register_action(select_gpt35_action)
        idaapi.attach_action_to_menu(self.select_gpt35_menu_path, self.select_gpt35_action_name, idaapi.SETMENU_APP)

        # Select gpt-4 action
        select_gpt4_action = idaapi.action_desc_t(self.select_gpt4_action_name,
                                                  GPT4_MODEL_NAME,
                                                  None if str(gepetto.config.model) == GPT4_MODEL_NAME
                                                  else SwapModelHandler(GPT4_MODEL_NAME, self),
                                                  "",
                                                  "",
                                                  208 if str(gepetto.config.model) == GPT4_MODEL_NAME else 0)
        idaapi.register_action(select_gpt4_action)
        idaapi.attach_action_to_menu(self.select_gpt35_menu_path, self.select_gpt4_action_name, idaapi.SETMENU_APP)

    # -----------------------------------------------------------------------------

    def run(self, arg):
        pass

    # -----------------------------------------------------------------------------

    def term(self):
        idaapi.detach_action_from_menu(self.explain_menu_path, self.explain_action_name)
        idaapi.detach_action_from_menu(self.rename_menu_path, self.rename_action_name)
        idaapi.detach_action_from_menu(self.select_gpt35_menu_path, self.select_gpt35_action_name)
        idaapi.detach_action_from_menu(self.select_gpt4_menu_path, self.select_gpt4_action_name)
        if self.menu:
            self.menu.unhook()
        return

# -----------------------------------------------------------------------------

class ContextMenuHooks(idaapi.UI_Hooks):
    def finish_populating_widget_popup(self, form, popup):
        # Add actions to the context menu of the Pseudocode view
        if idaapi.get_widget_type(form) == idaapi.BWN_PSEUDOCODE:
            idaapi.attach_action_to_popup(form, popup, GepettoPlugin.explain_action_name, "Gepetto/")
            idaapi.attach_action_to_popup(form, popup, GepettoPlugin.rename_action_name, "Gepetto/")

```

`gepetto/locales/ca_ES/LC_MESSAGES/gepetto.po`:

```po
# Translations template for Gepetto.
# This file is distributed under the same license as Gepetto (GPLv3).
# Ivan Kwiatkowski, 2023.
# 
# Translators:
# Ivan K., 2023
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Gepetto 1.1\n"
"Report-Msgid-Bugs-To: justicerage __at__ manalyzer(dot)org\n"
"POT-Creation-Date: 2023-03-02 15:14+0100\n"
"PO-Revision-Date: 2023-03-02 14:31+0000\n"
"Last-Translator: Ivan K., 2023\n"
"Language-Team: Catalan (Spain) (https://app.transifex.com/gepetto/teams/164045/ca_ES/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: ca_ES\n"
"Plural-Forms: nplurals=2; plural=(n != 1);\n"

msgid "Explain function"
msgstr "Explicar la funció"

msgid "Rename variables"
msgstr "Reanomenar les variables"

msgid "Select model"
msgstr ""

msgid "Uses {model} to enrich the decompiler's output"
msgstr "Utilitza {model} per enriquir la sortida del descompilador"

msgid "See usage instructions on GitHub"
msgstr "Veure instruccions d'ús a GitHub"

msgid "Use {model} to explain the currently selected function"
msgstr "Utilitzar {model} per explicar la funció seleccionada actualment"

msgid "Use {model} to rename this function's variables"
msgstr "Utilitzar {model} per reanomenar les variables d'aquesta funció"

msgid "Comment generated by Gepetto"
msgstr "Comentari generat per Gepetto"

msgid "{model} query finished!"
msgstr "Consulta de {model} acabada!"

msgid ""
"Can you explain what the following C function does and suggest a better name for it?\n"
"{decompiler_output}"
msgstr ""
"Podeu explicar què fa la següent funció en C i suggerir un millor nom per a ella?\n"
"{decompiler_output}"

msgid ""
"Could not obtain valid data from the model, giving up. Dumping the response "
"for manual import:"
msgstr ""
"No s'ha pogut obtenir dades vàlides del model, abandonant. Volcant la "
"resposta per a la importació manual:"

msgid ""
"Cannot extract valid JSON from the response. Asking the model to fix it..."
msgstr ""
"No es pot extreure un JSON vàlid de la resposta. Demanant al model que ho "
"arregli..."

msgid "The JSON document returned is invalid. Asking the model to fix it..."
msgstr ""
"El document JSON retornat no és vàlid. Demanant al model que ho arregli..."

msgid "Please fix the following JSON document:\n"
msgstr "Si us plau, arregleu el següent document JSON:\n"

msgid ""
"The JSON document provided in this response is invalid. Can you fix it?\n"
"{response}"
msgstr ""
"El document JSON proporcionat en aquesta resposta no és vàlid. Podeu arreglar-lo?\n"
"{response}"

msgid "{model} query finished! {replaced} variable(s) renamed."
msgstr "Consulta de {model} acabada! S'han reanomenat {replaced} variable(s)."

msgid ""
"Analyze the following C function:\n"
"{decompiler_output}\n"
"Suggest better variable names, reply with a JSON array where keys are the original names and values are the proposed names. Do not explain anything, only print the JSON dictionary."
msgstr ""
"Analitzar la següent funció en C:\n"
"{decompiler_output}\n"
"Suggerir millors noms de variables, respondre amb una matriu JSON on les claus són els noms originals i els valors són els noms proposats. No explicar res, només imprimir el diccionari JSON."

msgid "{model} could not complete the request: {error}"
msgstr "{model} no ha pogut completar la sol·licitud: {error}"

msgid ""
"Context length exceeded! Reducing the completion tokens to {max_tokens}..."
msgstr ""
"S'ha superat la longitud de context! Reduint el nombre de tokens de "
"finalització a {max_tokens}..."

msgid ""
"Unfortunately, this function is too big to be analyzed with the model's "
"current API limits."
msgstr ""
"Desafortunadament, aquesta funció és massa gran per ser analitzada amb els "
"límits actuals de l'API del model."

msgid "General exception encountered while running the query: {error}"
msgstr ""
"S'ha trobat una excepció general mentre s'executava la consulta: {error}"

msgid "Request to {model} sent..."
msgstr "Sol·licitud enviada a {model}..."

msgid "Please edit this script to insert your OpenAI API key!"
msgstr ""
"Si us plau, editeu aquest script per inserir la vostra clau d'API d'OpenAI!"

```

`gepetto/locales/es_ES/LC_MESSAGES/gepetto.po`:

```po
# Translations template for Gepetto.
# This file is distributed under the same license as Gepetto (GPLv3).
# Ivan Kwiatkowski, 2023.
# 
# Translators:
# Ivan K., 2023
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Gepetto 1.1\n"
"Report-Msgid-Bugs-To: justicerage __at__ manalyzer(dot)org\n"
"POT-Creation-Date: 2023-03-02 15:14+0100\n"
"PO-Revision-Date: 2023-03-02 14:31+0000\n"
"Last-Translator: Ivan K., 2023\n"
"Language-Team: Spanish (Spain) (https://app.transifex.com/gepetto/teams/164045/es_ES/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: es_ES\n"
"Plural-Forms: nplurals=3; plural=n == 1 ? 0 : n != 0 && n % 1000000 == 0 ? 1 : 2;\n"

msgid "Explain function"
msgstr "Explicar la función"

msgid "Rename variables"
msgstr "Renombrar las variables"

msgid "Select model"
msgstr ""

msgid "Uses {model} to enrich the decompiler's output"
msgstr "Utiliza {model} para enriquecer la salida del descompilador"

msgid "See usage instructions on GitHub"
msgstr "Ver instrucciones de uso en GitHub"

msgid "Use {model} to explain the currently selected function"
msgstr "Usar {model} para explicar la función seleccionada actualmente"

msgid "Use {model} to rename this function's variables"
msgstr "Usar {model} para renombrar las variables de esta función"

msgid "Comment generated by Gepetto"
msgstr "Comentario generado por Gepetto"

msgid "{model} query finished!"
msgstr "Consulta de {model} finalizada!"

msgid ""
"Can you explain what the following C function does and suggest a better name for it?\n"
"{decompiler_output}"
msgstr ""
"¿Puede explicar qué hace la siguiente función en C y sugerir un mejor nombre para ella?\n"
"{decompiler_output}"

msgid ""
"Could not obtain valid data from the model, giving up. Dumping the response "
"for manual import:"
msgstr ""
"No se pudo obtener datos válidos del modelo, abandonando. Volcando la "
"respuesta para la importación manual:"

msgid ""
"Cannot extract valid JSON from the response. Asking the model to fix it..."
msgstr ""
"No se puede extraer un JSON válido de la respuesta. Pidiendo al modelo que "
"lo arregle..."

msgid "The JSON document returned is invalid. Asking the model to fix it..."
msgstr ""
"El documento JSON devuelto no es válido. Pidiendo al modelo que lo "
"arregle..."

msgid "Please fix the following JSON document:\n"
msgstr "Por favor, arregle el siguiente documento JSON:\n"

msgid ""
"The JSON document provided in this response is invalid. Can you fix it?\n"
"{response}"
msgstr ""
"El documento JSON proporcionado en esta respuesta no es válido. ¿Puede arreglarlo?\n"
"{response}"

msgid "{model} query finished! {replaced} variable(s) renamed."
msgstr ""
"Consulta de {model} finalizada! Se renombraron {replaced} variable(s)."

msgid ""
"Analyze the following C function:\n"
"{decompiler_output}\n"
"Suggest better variable names, reply with a JSON array where keys are the original names and values are the proposed names. Do not explain anything, only print the JSON dictionary."
msgstr ""
"Analizar la siguiente función en C:\n"
"{decompiler_output}\n"
"Sugerir mejores nombres de variables, responder con una matriz JSON donde las claves son los nombres originales y los valores son los nombres propuestos. No explique nada, solo imprima el diccionario JSON."

msgid "{model} could not complete the request: {error}"
msgstr "{model} no pudo completar la solicitud: {error}"

msgid ""
"Context length exceeded! Reducing the completion tokens to {max_tokens}..."
msgstr ""
"¡Límite de longitud del contexto excedido! Reduciendo los tokens de "
"finalización a {max_tokens}..."

msgid ""
"Unfortunately, this function is too big to be analyzed with the model's "
"current API limits."
msgstr ""
"Desafortunadamente, esta función es demasiado grande para ser analizada con "
"los límites actuales de la API del modelo."

msgid "General exception encountered while running the query: {error}"
msgstr ""
"Se encontró una excepción general mientras se ejecutaba la consulta: {error}"

msgid "Request to {model} sent..."
msgstr "Solicitud enviada a {model}..."

msgid "Please edit this script to insert your OpenAI API key!"
msgstr "¡Edite este script para insertar su clave de API de OpenAI!"

```

`gepetto/locales/fr_FR/LC_MESSAGES/gepetto.po`:

```po
# Translations template for Gepetto.
# This file is distributed under the same license as Gepetto (GPLv3).
# Ivan Kwiatkowski, 2023.
# 
# Translators:
# Ivan K., 2023
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Gepetto 1.1\n"
"Report-Msgid-Bugs-To: justicerage __at__ manalyzer(dot)org\n"
"POT-Creation-Date: 2023-03-02 15:14+0100\n"
"PO-Revision-Date: 2023-03-02 14:31+0000\n"
"Last-Translator: Ivan K., 2023\n"
"Language-Team: French (https://app.transifex.com/gepetto/teams/164045/fr/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: fr\n"
"Plural-Forms: nplurals=3; plural=(n == 0 || n == 1) ? 0 : n != 0 && n % 1000000 == 0 ? 1 : 2;\n"

msgid "Explain function"
msgstr "Expliquer la fonction"

msgid "Rename variables"
msgstr "Renommer les variables"

msgid "Select model"
msgstr "Sélectionner le modèle"

msgid "Uses {model} to enrich the decompiler's output"
msgstr "Enrichit la sortie du décompilateur avec {model}"

msgid "See usage instructions on GitHub"
msgstr "Aide du programme disponible sur GitHub"

msgid "Use {model} to explain the currently selected function"
msgstr "Utiliser {model} pour expliquer la fonction sélectionnée"

msgid "Use {model} to rename this function's variables"
msgstr "Utiliser {model} pour renommer les variables de cette fonction"

msgid "Comment generated by Gepetto"
msgstr "Commentaire généré par Gepetto"

msgid "{model} query finished!"
msgstr "Requête vers {model} terminée !"

msgid ""
"Can you explain what the following C function does and suggest a better name for it?\n"
"{decompiler_output}"
msgstr ""
"Explique ce que fait la fonction en C suivante et suggère un meilleur nom "
"pour celle-ci : {decompiler_output}"

msgid ""
"Could not obtain valid data from the model, giving up. Dumping the response "
"for manual import:"
msgstr ""
"Impossible d'obtenir une réponse valide du modèle et abandon. La réponse est"
" reproduite ci-dessous pour import manuel :"

msgid ""
"Cannot extract valid JSON from the response. Asking the model to fix it..."
msgstr ""
"Impossible d'extraire un document JSON valide de la réponse. Envoi d'une "
"requête au modèle pour le réparer..."

msgid "The JSON document returned is invalid. Asking the model to fix it..."
msgstr ""
"Le document JSON retourné par le modèle est invalide. Envoi d'une requête "
"pour le réparer..."

msgid "Please fix the following JSON document:\n"
msgstr "Peux-tu réparer le document JSON suivant ?\n"

msgid ""
"The JSON document provided in this response is invalid. Can you fix it?\n"
"{response}"
msgstr ""
"Le document JSON fourni dans cette réponse est invalide. Peux-tu le réparer "
"? {response}"

msgid "{model} query finished! {replaced} variable(s) renamed."
msgstr "Requête vers {model} achevée ! {replaced} variable(s) remplacée(s)."

msgid ""
"Analyze the following C function:\n"
"{decompiler_output}\n"
"Suggest better variable names, reply with a JSON array where keys are the original names and values are the proposed names. Do not explain anything, only print the JSON dictionary."
msgstr ""
"Analyse la fonction C suivante :\n"
"{decompiler_output}\n"
"Suggère de meilleurs noms pour les variables, et renvoie un document JSON dont les clés sont les noms originaux, et les valeurs sont les noms proposés. N'explique rien, n'affiche que le document JSON."

msgid "{model} could not complete the request: {error}"
msgstr "{model} n'a pas pu satisfaire la requête : {error}"

msgid ""
"Context length exceeded! Reducing the completion tokens to {max_tokens}..."
msgstr ""
"Longueur maximale de contenu dépassée ! Nouvel essai en réduisant le nombre "
"de jetons de complétion demandés à {max_tokens}..."

msgid ""
"Unfortunately, this function is too big to be analyzed with the model's "
"current API limits."
msgstr ""
"Malheureusement, les limites de l'API du modèle ne permettent pas d'analyser"
" une fonction aussi grande."

msgid "General exception encountered while running the query: {error}"
msgstr ""
"Erreur générale rencontrée lors de l'exécution de la requête : {error}"

msgid "Request to {model} sent..."
msgstr "Requête envoyée à {model}..."

msgid "Please edit this script to insert your OpenAI API key!"
msgstr "Merci d'ajouter votre clé API OpenAI dans ce script !"

```

`gepetto/locales/gepetto.pot`:

```pot
# Translations template for Gepetto.
# This file is distributed under the same license as Gepetto (GPLv3).
# Ivan Kwiatkowski, 2023.
#
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Gepetto 1.1\n"
"Report-Msgid-Bugs-To: justicerage __at__ manalyzer(dot)org\n"
"POT-Creation-Date: 2023-03-02 15:14+0100\n"
"PO-Revision-Date: YEAR-MO-DA HO:MI+ZONE\n"
"Last-Translator: FULL NAME <EMAIL@ADDRESS>\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=utf-8\n"
"Content-Transfer-Encoding: 8bit\n"

msgid "Explain function"
msgstr "Explain function"

msgid "Rename variables"
msgstr "Rename variables"

msgid "Select model"
msgstr "Select model"

msgid "Uses {model} to enrich the decompiler's output"
msgstr "Uses {model} to enrich the decompiler's output"

msgid "See usage instructions on GitHub"
msgstr "See usage instructions on GitHub"

msgid "Use {model} to explain the currently selected function"
msgstr "Use {model} to explain the currently selected function"

msgid "Use {model} to rename this function's variables"
msgstr "Use {model} to rename this function's variables"

msgid "Comment generated by Gepetto"
msgstr "Comment generated by Gepetto"

msgid "{model} query finished!"
msgstr "{model} query finished!"

msgid "Can you explain what the following C function does and suggest a better name for it?\n{decompiler_output}"
msgstr "Can you explain what the following C function does and suggest a better name for it?\n{decompiler_output}"

msgid "Could not obtain valid data from the model, giving up. Dumping the response for manual import:"
msgstr "Could not obtain valid data from the model, giving up. Dumping the response for manual import:"

msgid "Cannot extract valid JSON from the response. Asking the model to fix it..."
msgstr "Cannot extract valid JSON from the response. Asking the model to fix it..."

msgid "The JSON document returned is invalid. Asking the model to fix it..."
msgstr "The JSON document returned is invalid. Asking the model to fix it..."

msgid "Please fix the following JSON document:\n"
msgstr "Please fix the following JSON document:\n"

msgid "The JSON document provided in this response is invalid. Can you fix it?\n{response}"
msgstr "The JSON document provided in this response is invalid. Can you fix it?\n{response}"

msgid "{model} query finished! {replaced} variable(s) renamed."
msgstr "{model} query finished! {replaced} variable(s) renamed."

msgid "Analyze the following C function:\n{decompiler_output}\nSuggest better variable names, reply with a JSON array where keys are the original names and values are the proposed names. Do not explain anything, only print the JSON dictionary."
msgstr "Analyze the following C function:\n{decompiler_output}\nSuggest better variable names, reply with a JSON array where keys are the original names and values are the proposed names. Do not explain anything, only print the JSON dictionary."

msgid "{model} could not complete the request: {error}"
msgstr "{model} could not complete the request: {error}"

msgid "Context length exceeded! Reducing the completion tokens to {max_tokens}..."
msgstr "Context length exceeded! Reducing the completion tokens to {max_tokens}..."

msgid "Unfortunately, this function is too big to be analyzed with the model's current API limits."
msgstr "Unfortunately, this function is too big to be analyzed with the model's current API limits."

msgid "General exception encountered while running the query: {error}"
msgstr "General exception encountered while running the query: {error}"

msgid "Request to {model} sent..."
msgstr "Request to {model} sent..."

msgid "Please edit this script to insert your OpenAI API key!"
msgstr "Please edit this script to insert your OpenAI API key!"


```

`gepetto/locales/it_IT/LC_MESSAGES/gepetto.po`:

```po
# Translations template for Gepetto.
# This file is distributed under the same license as Gepetto (GPLv3).
# Ivan Kwiatkowski, 2023.
# 
# Translators:
# Ivan K., 2023
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Gepetto 1.1\n"
"Report-Msgid-Bugs-To: justicerage __at__ manalyzer(dot)org\n"
"POT-Creation-Date: 2023-03-02 15:14+0100\n"
"PO-Revision-Date: 2023-03-02 14:31+0000\n"
"Last-Translator: Ivan K., 2023\n"
"Language-Team: Italian (Italy) (https://app.transifex.com/gepetto/teams/164045/it_IT/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: it_IT\n"
"Plural-Forms: nplurals=3; plural=n == 1 ? 0 : n != 0 && n % 1000000 == 0 ? 1 : 2;\n"

msgid "Explain function"
msgstr "Descrivi la funzione"

msgid "Rename variables"
msgstr "Rinomina le variabili"

msgid "Select model"
msgstr ""

msgid "Uses {model} to enrich the decompiler's output"
msgstr "Usa {model} per arricchire il codice decompilato"

msgid "See usage instructions on GitHub"
msgstr "Consulta le istruzioni d'uso su GitHub"

msgid "Use {model} to explain the currently selected function"
msgstr "Usa {model} per descrivere la funzione selezionata"

msgid "Use {model} to rename this function's variables"
msgstr "Usa {model} per rinominare le variabili di questa funzione"

msgid "Comment generated by Gepetto"
msgstr "Commento generato da Geppetto"

msgid "{model} query finished!"
msgstr "{model} query completata!"

msgid ""
"Can you explain what the following C function does and suggest a better name for it?\n"
"{decompiler_output}"
msgstr ""
"Potresti descrivere cosa fa la seguente funzione e suggerire un nome migliore?\n"
"{decompiler_output}"

msgid ""
"Could not obtain valid data from the model, giving up. Dumping the response "
"for manual import:"
msgstr ""
"Impossibile ottenere dati validi dal modello. L'operazione è stata "
"interrotta. Riporto di seguito la risposta per l'importazione manuale:"

msgid ""
"Cannot extract valid JSON from the response. Asking the model to fix it..."
msgstr ""
"Impossibile estrarre un JSON valido dalla risposta. Chiedo al modello di "
"aggiustarlo..."

msgid "The JSON document returned is invalid. Asking the model to fix it..."
msgstr ""
"Il documento JSON ottenuto non è valido. Chiedo al modello di aggiustarlo..."

msgid "Please fix the following JSON document:\n"
msgstr "Per favore aggiusta il seguente documento JSON:\n"

msgid ""
"The JSON document provided in this response is invalid. Can you fix it?\n"
"{response}"
msgstr ""
"Il documento JSON fornito in questa risposta non è valido. Potresti aggiustarlo?\n"
"{response}"

msgid "{model} query finished! {replaced} variable(s) renamed."
msgstr "{model} query terminata! {replaced} variabili rinominate."

msgid ""
"Analyze the following C function:\n"
"{decompiler_output}\n"
"Suggest better variable names, reply with a JSON array where keys are the original names and values are the proposed names. Do not explain anything, only print the JSON dictionary."
msgstr ""
"Analizza la funziona C:\n"
"{decompiler_output}\n"
"Suggerisci dei nomi variabili migliori, rispondi con un JSON array in cui le chiavi sono i nomi originali ed i valori sono i nomi suggeriti. Non spiegare nulla, limitati a stampare il dizionario JSON."

msgid "{model} could not complete the request: {error}"
msgstr "{model} non può soddisfare la richiesta: {error}"

msgid ""
"Context length exceeded! Reducing the completion tokens to {max_tokens}..."
msgstr ""
"Lunghezza massima del contenuto superata! Riprova riducendo il numero dei "
"token di completamento a {max_tokens}..."

msgid ""
"Unfortunately, this function is too big to be analyzed with the model's "
"current API limits."
msgstr ""
"Sfortunatamente, questa funzione è troppo grande per essere analizzata con "
"gli attuali limiti API del modello."

msgid "General exception encountered while running the query: {error}"
msgstr "Eccezione rilevata durante l'esecuzione della query: {error}"

msgid "Request to {model} sent..."
msgstr "Richiesta inviata a {model}..."

msgid "Please edit this script to insert your OpenAI API key!"
msgstr "Per favore, modifica lo script insendo la tua OpenAI API key!"

```

`gepetto/locales/ko_KR/LC_MESSAGES/gepetto.po`:

```po
# Translations template for Gepetto.
# This file is distributed under the same license as Gepetto (GPLv3).
# Ivan Kwiatkowski, 2023.
# 
# Translators:
# Ivan K., 2023
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Gepetto 1.1\n"
"Report-Msgid-Bugs-To: justicerage __at__ manalyzer(dot)org\n"
"POT-Creation-Date: 2023-03-02 15:14+0100\n"
"PO-Revision-Date: 2023-03-02 14:31+0000\n"
"Last-Translator: Ivan K., 2023\n"
"Language-Team: Korean (Korea) (https://app.transifex.com/gepetto/teams/164045/ko_KR/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: ko_KR\n"
"Plural-Forms: nplurals=1; plural=0;\n"

msgid "Explain function"
msgstr ""

msgid "Rename variables"
msgstr ""

msgid "Select model"
msgstr ""

msgid "Uses {model} to enrich the decompiler's output"
msgstr ""

msgid "See usage instructions on GitHub"
msgstr ""

msgid "Use {model} to explain the currently selected function"
msgstr ""

msgid "Use {model} to rename this function's variables"
msgstr ""

msgid "Comment generated by Gepetto"
msgstr ""

msgid "{model} query finished!"
msgstr ""

msgid ""
"Can you explain what the following C function does and suggest a better name for it?\n"
"{decompiler_output}"
msgstr ""
"이 C언어 함수는 무엇을 하는지 설명해 주세요. 그리고 이 함수의 이름을 추천해 주세요.\n"
"{decompiler_output}"

msgid ""
"Could not obtain valid data from the model, giving up. Dumping the response "
"for manual import:"
msgstr ""

msgid ""
"Cannot extract valid JSON from the response. Asking the model to fix it..."
msgstr ""

msgid "The JSON document returned is invalid. Asking the model to fix it..."
msgstr ""

msgid "Please fix the following JSON document:\n"
msgstr ""

msgid ""
"The JSON document provided in this response is invalid. Can you fix it?\n"
"{response}"
msgstr ""

msgid "{model} query finished! {replaced} variable(s) renamed."
msgstr ""

msgid ""
"Analyze the following C function:\n"
"{decompiler_output}\n"
"Suggest better variable names, reply with a JSON array where keys are the original names and values are the proposed names. Do not explain anything, only print the JSON dictionary."
msgstr ""

msgid "{model} could not complete the request: {error}"
msgstr ""

msgid ""
"Context length exceeded! Reducing the completion tokens to {max_tokens}..."
msgstr ""

msgid ""
"Unfortunately, this function is too big to be analyzed with the model's "
"current API limits."
msgstr ""

msgid "General exception encountered while running the query: {error}"
msgstr ""

msgid "Request to {model} sent..."
msgstr ""

msgid "Please edit this script to insert your OpenAI API key!"
msgstr ""

```

`gepetto/locales/ru/LC_MESSAGES/gepetto.po`:

```po
# Translations template for Gepetto.
# This file is distributed under the same license as Gepetto (GPLv3).
# Ivan Kwiatkowski, 2023.
# 
# Translators:
# Igor Kot, 2023
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Gepetto 1.1\n"
"Report-Msgid-Bugs-To: justicerage __at__ manalyzer(dot)org\n"
"POT-Creation-Date: 2023-03-02 15:14+0100\n"
"PO-Revision-Date: 2023-03-02 14:31+0000\n"
"Last-Translator: Igor Kot, 2023\n"
"Language-Team: Russian (https://app.transifex.com/gepetto/teams/164045/ru/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: ru\n"
"Plural-Forms: nplurals=4; plural=(n%10==1 && n%100!=11 ? 0 : n%10>=2 && n%10<=4 && (n%100<12 || n%100>14) ? 1 : n%10==0 || (n%10>=5 && n%10<=9) || (n%100>=11 && n%100<=14)? 2 : 3);\n"

msgid "Explain function"
msgstr "Объяснить функцию"

msgid "Rename variables"
msgstr "Переименовать переменные"

msgid "Select model"
msgstr "Выбрать модель"

msgid "Uses {model} to enrich the decompiler's output"
msgstr "Использует {model} для обогащения вывода декомпилятора"

msgid "See usage instructions on GitHub"
msgstr "См. инструкции по использованию на GitHub."

msgid "Use {model} to explain the currently selected function"
msgstr "Используйте {model} для объяснения выбранной функции"

msgid "Use {model} to rename this function's variables"
msgstr "Используйте {model} для переименования переменных этой функции"

msgid "Comment generated by Gepetto"
msgstr "Комментарий создан Gepetto"

msgid "{model} query finished!"
msgstr "Запрос {model} завершен!"

msgid ""
"Can you explain what the following C function does and suggest a better name for it?\n"
"{decompiler_output}"
msgstr ""
"Можете ли вы объяснить, что делает следующая функция C, и предложить для нее лучшее название?\n"
"{decompiler_output}"

msgid ""
"Could not obtain valid data from the model, giving up. Dumping the response "
"for manual import:"
msgstr ""
"Не удалось получить валидные данные от модели, сдаюсь. Выгружаю ответ для "
"ручного импорта:"

msgid ""
"Cannot extract valid JSON from the response. Asking the model to fix it..."
msgstr ""
"Не удается извлечь валидный JSON из ответа. Прошу модель исправить это.."

msgid "The JSON document returned is invalid. Asking the model to fix it..."
msgstr "Возвращенный документ JSON невалидный. Прошу модель исправить это..."

msgid "Please fix the following JSON document:\n"
msgstr "Пожалуйста, исправьте следующий документ JSON:\n"

msgid ""
"The JSON document provided in this response is invalid. Can you fix it?\n"
"{response}"
msgstr ""
"JSON-документ, предоставленный в этом ответе, невалидный. Вы можете его исправить?\n"
"{response}"

msgid "{model} query finished! {replaced} variable(s) renamed."
msgstr ""
"Запрос {model} завершен! Кол-во переименованных переменных: {replaced}."

msgid ""
"Analyze the following C function:\n"
"{decompiler_output}\n"
"Suggest better variable names, reply with a JSON array where keys are the original names and values are the proposed names. Do not explain anything, only print the JSON dictionary."
msgstr ""
"Проанализируйте следующую функцию на языке C:\n"
"{decompiler_output}\n"
"Предложите более подходящие имена переменных, ответьте JSON-массивом, где ключи - это исходные имена, а значения - предлагаемые имена. Не объясняйте ничего, просто выведите словарь JSON."

msgid "{model} could not complete the request: {error}"
msgstr "{model} не смогла выполнить запрос: {error}"

msgid ""
"Context length exceeded! Reducing the completion tokens to {max_tokens}..."
msgstr ""
"Превышена максимальная длина! Уменьшение количества токенов завершения до "
"{max_tokens}..."

msgid ""
"Unfortunately, this function is too big to be analyzed with the model's "
"current API limits."
msgstr ""
"К сожалению, данная функция слишком большая для анализа с текущими "
"ограничениями API модели."

msgid "General exception encountered while running the query: {error}"
msgstr "Общее исключение, возникшее при выполнении запроса: {error}"

msgid "Request to {model} sent..."
msgstr "Запрос к {model} отправлен..."

msgid "Please edit this script to insert your OpenAI API key!"
msgstr ""
"Пожалуйста, отредактируйте этот скрипт, чтобы добавить свой OpenAI API ключ!"

```

`gepetto/locales/tr/LC_MESSAGES/gepetto.po`:

```po
# Translations template for Gepetto.
# This file is distributed under the same license as Gepetto (GPLv3).
# Ivan Kwiatkowski, 2023.
# 
# Translators:
# rüzgar can, 2023
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Gepetto 1.1\n"
"Report-Msgid-Bugs-To: justicerage __at__ manalyzer(dot)org\n"
"POT-Creation-Date: 2023-03-02 15:14+0100\n"
"PO-Revision-Date: 2023-03-02 14:31+0000\n"
"Last-Translator: rüzgar can, 2023\n"
"Language-Team: Turkish (https://app.transifex.com/gepetto/teams/164045/tr/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: tr\n"
"Plural-Forms: nplurals=2; plural=(n > 1);\n"

msgid "Explain function"
msgstr "işlevi açıkla"

msgid "Rename variables"
msgstr "Değişkenleri yeniden adlandırın"

msgid "Select model"
msgstr "Model seçin"

msgid "Uses {model} to enrich the decompiler's output"
msgstr "Derleyicinin çıktısını zenginleştirmek için {model} kullanır"

msgid "See usage instructions on GitHub"
msgstr "GitHub'daki kullanım talimatlarına bakın"

msgid "Use {model} to explain the currently selected function"
msgstr "Seçili olan fonksiyonu açıklamak için {model} kullanın"

msgid "Use {model} to rename this function's variables"
msgstr ""
"Bu fonksiyonun değişkenlerini yeniden adlandırmak için {model} kullanın"

msgid "Comment generated by Gepetto"
msgstr "Gepetto tarafından oluşturulan yorum"

msgid "{model} query finished!"
msgstr "{model} sorgu tamamlandı!"

msgid ""
"Can you explain what the following C function does and suggest a better name for it?\n"
"{decompiler_output}"
msgstr ""
"Aşağıdaki C fonksiyonunun ne yaptığını açıklayabilir ve daha iyi bir isim önerebilir misiniz?\n"
"{decompiler_output}"

msgid ""
"Could not obtain valid data from the model, giving up. Dumping the response "
"for manual import:"
msgstr ""
"Modelden geçerli veriler alınamadı, vazgeçildi. Yanıtı manuel içe aktarma "
"için boşaltma:"

msgid ""
"Cannot extract valid JSON from the response. Asking the model to fix it..."
msgstr "Yanıttan geçerli JSON çıkarılamıyor. Modelden düzeltmesi isteniyor..."

msgid "The JSON document returned is invalid. Asking the model to fix it..."
msgstr "Döndürülen JSON belgesi geçersiz. Modelden düzeltmesi isteniyor..."

msgid "Please fix the following JSON document:\n"
msgstr ""
"Lütfen aşağıdaki JSON belgesini düzeltin:\n"
"\n"

msgid ""
"The JSON document provided in this response is invalid. Can you fix it?\n"
"{response}"
msgstr ""
"Bu yanıtta sağlanan JSON belgesi geçersiz. Tamir edebilir misin?\n"
"{response}"

msgid "{model} query finished! {replaced} variable(s) renamed."
msgstr ""
"{model} sorgusu tamamlandı! {replaced} değişken(s) yeniden adlandırıldı."

msgid ""
"Analyze the following C function:\n"
"{decompiler_output}\n"
"Suggest better variable names, reply with a JSON array where keys are the original names and values are the proposed names. Do not explain anything, only print the JSON dictionary."
msgstr ""
"Aşağıdaki C fonksiyonunu analiz edin:\n"
"{decompiler_output}\n"
"Daha iyi değişken adları önerin, anahtarların orijinal adlar ve değerlerin önerilen adlar olduğu bir JSON dizisiyle yanıt verin. Hiçbir şey açıklamayın, yalnızca JSON sözlüğünü yazdırın."

msgid "{model} could not complete the request: {error}"
msgstr "{model} istek tamamlanamadı: {error}"

msgid ""
"Context length exceeded! Reducing the completion tokens to {max_tokens}..."
msgstr ""
"Bağlam uzunluğu aşıldı! Tamamlama belirteçleri {max_tokens}'a indiriliyor..."

msgid ""
"Unfortunately, this function is too big to be analyzed with the model's "
"current API limits."
msgstr ""
"Ne yazık ki bu fonksiyon, modelin mevcut API limitleri ile analiz "
"edilemeyecek kadar büyüktür."

msgid "General exception encountered while running the query: {error}"
msgstr "Sorgu çalıştırılırken genel istisna ile karşılaşıldı: {error}"

msgid "Request to {model} sent..."
msgstr "{model}'a istek gönderildi..."

msgid "Please edit this script to insert your OpenAI API key!"
msgstr "OpenAI API anahtarınızı eklemek için lütfen bu betiği düzenleyin!"

```

`gepetto/locales/zh_CN/LC_MESSAGES/gepetto.po`:

```po
# Translations template for Gepetto.
# This file is distributed under the same license as Gepetto (GPLv3).
# Ivan Kwiatkowski, 2023.
# 
# Translators:
# Ivan K., 2023
# 
#, fuzzy
msgid ""
msgstr ""
"Project-Id-Version: Gepetto 1.1\n"
"Report-Msgid-Bugs-To: justicerage __at__ manalyzer(dot)org\n"
"POT-Creation-Date: 2023-03-02 15:14+0100\n"
"PO-Revision-Date: 2023-03-02 14:31+0000\n"
"Last-Translator: Ivan K., 2023\n"
"Language-Team: Chinese (China) (https://app.transifex.com/gepetto/teams/164045/zh_CN/)\n"
"MIME-Version: 1.0\n"
"Content-Type: text/plain; charset=UTF-8\n"
"Content-Transfer-Encoding: 8bit\n"
"Language: zh_CN\n"
"Plural-Forms: nplurals=1; plural=0;\n"

msgid "Explain function"
msgstr "解释函数"

msgid "Rename variables"
msgstr "重命名变量"

msgid "Select model"
msgstr ""

msgid "Uses {model} to enrich the decompiler's output"
msgstr ""

msgid "See usage instructions on GitHub"
msgstr ""

msgid "Use {model} to explain the currently selected function"
msgstr "使用 {model} 解释当前选择的函数"

msgid "Use {model} to rename this function's variables"
msgstr "使用 {model} 重命名函数的变量"

msgid "Comment generated by Gepetto"
msgstr ""

msgid "{model} query finished!"
msgstr ""

msgid ""
"Can you explain what the following C function does and suggest a better name for it?\n"
"{decompiler_output}"
msgstr ""
"你能解释一下下面的C函数是做什么的，并为它取一个更好的名字吗?\n"
"{decompiler_output}"

msgid ""
"Could not obtain valid data from the model, giving up. Dumping the response "
"for manual import:"
msgstr ""

msgid ""
"Cannot extract valid JSON from the response. Asking the model to fix it..."
msgstr "无法从响应中提取有效的JSON。正在使其修复…"

msgid "The JSON document returned is invalid. Asking the model to fix it..."
msgstr "返回的JSON无效。正在使其修复…"

msgid "Please fix the following JSON document:\n"
msgstr "请修复以下JSON:\n"

msgid ""
"The JSON document provided in this response is invalid. Can you fix it?\n"
"{response}"
msgstr ""
"此响应中提供的JSON是无效的。你能修复吗?\n"
"{response}"

msgid "{model} query finished! {replaced} variable(s) renamed."
msgstr ""

msgid ""
"Analyze the following C function:\n"
"{decompiler_output}\n"
"Suggest better variable names, reply with a JSON array where keys are the original names and values are the proposed names. Do not explain anything, only print the JSON dictionary."
msgstr ""
"分析下面的C函数:\n"
"{decompiler_output}\n"
"建议更好的变量名，回复一个JSON数组，其中键是原始名称，值是建议的名称。不解释任何事情，只输出JSON 字典."

msgid "{model} could not complete the request: {error}"
msgstr ""

msgid ""
"Context length exceeded! Reducing the completion tokens to {max_tokens}..."
msgstr ""

msgid ""
"Unfortunately, this function is too big to be analyzed with the model's "
"current API limits."
msgstr ""

msgid "General exception encountered while running the query: {error}"
msgstr ""

msgid "Request to {model} sent..."
msgstr ""

msgid "Please edit this script to insert your OpenAI API key!"
msgstr ""

```

`gepetto/models/base.py`:

```py
import abc

GPT3_MODEL_NAME = "Local LLM"
GPT4_MODEL_NAME = "LLama3"

class LanguageModel(abc.ABC):
    @abc.abstractmethod
    def query_model_async(self, query, cb):
        pass


def get_model(model):
    """
    Instantiates a model based on its name
    :param model: The model to use
    :param config: The object containing the configuration of the program
    :return:
    """
    if model == GPT3_MODEL_NAME or model == GPT4_MODEL_NAME:
        from gepetto.models.openai import GPT
        return GPT(model)
    else:
        print(f"Warning:  {model} does not exist! Using default model ({GPT3_MODEL_NAME}).")
        from gepetto.models.openai import GPT
        return GPT(GPT3_MODEL_NAME)

```

`gepetto/models/openai.py`:

```py
import functools
import threading
import httpx
import ida_kernwin
from gepetto.models.base import LanguageModel
import gepetto.config

_ = gepetto.config.translate.gettext

class GPT(LanguageModel):
    def __init__(self, model):
        self.model = model
        self.base_url = "http://localhost:1234/v1/chat/completions"

    def __str__(self):
        return self.model

    def query_model(self, query, cb, additional_model_options=None):
        if additional_model_options is None:
            additional_model_options = {}
        try:
            response = httpx.post(
                self.base_url,
                json={
                    "model": self.model,
                    "messages": [{"role": "user", "content": query}],
                    **additional_model_options
                },
                timeout=20
            )
            response.raise_for_status()
            content = response.json()
            if 'choices' in content and content['choices']:
                message_content = content['choices'][0]['message']['content']
                #print("Content :",message_content)
                ida_kernwin.execute_sync(functools.partial(cb, response=message_content),
                                         ida_kernwin.MFF_WRITE)
            else:
                print(_("Unexpected response format: {content}").format(content=content))
        except httpx.RequestError as e:
            print(_("Error while sending request to local LLM model: {error}").format(error=str(e)))
        except Exception as e:
            print(_("General exception encountered while running the query: {type} - {error}").format(
                type=type(e).__name__, error=str(e)))

    def query_model_async(self, query, cb, additional_model_options=None):
        if additional_model_options is None:
            additional_model_options = {}
        print(_("Request to {model} sent...").format(model=str(gepetto.config.model)))
        t = threading.Thread(target=self.query_model, args=[query, cb, additional_model_options])
        t.start()

```