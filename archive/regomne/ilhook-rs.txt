Project Path: arc_regomne_ilhook-rs_cnl_9n6w

Source Tree:

```txt
arc_regomne_ilhook-rs_cnl_9n6w
├── Cargo.toml
├── LICENSE
├── README.md
└── src
    ├── err.rs
    ├── lib.rs
    ├── x64
    │   ├── fixed_memory_unix.rs
    │   ├── fixed_memory_win.rs
    │   ├── move_inst.rs
    │   └── tests.rs
    ├── x64.rs
    └── x86.rs

```

`Cargo.toml`:

```toml
[package]
name = "ilhook"
description = "A library that provides methods to inline hook binary codes in x86 and x86_64 architecture"
version = "2.3.0"
authors = ["regomne <fallingsunz@gmail.com>"]
edition = "2024"
license = "MIT"
readme = "README.md"
repository = "https://github.com/regomne/ilhook-rs"
keywords = ["hook", "assemble", "disassemble"]
categories = ["hardware-support"]

[dependencies]
iced-x86 = { version = "1.21", default-features = false, features = ["std", "decoder", "block_encoder", "instr_info"] }
thiserror = "1.0"
bitflags = "2.0"

[target.'cfg(unix)'.dependencies]
libc = "0.2"
regex = "1"

[target.'cfg(windows)'.dependencies]
windows-sys = { version = "0.60", features = ["Win32_Foundation", "Win32_System_Memory"] }

[profile.release]
lto = true
codegen-units = 1
opt-level = 3

[features]
default = ["x86", "x64"]
x86 = []
x64 = []

```

`LICENSE`:

```
MIT License

Copyright (c) 2023 regomne

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

```

`README.md`:

```md
ilhook
----

[![](http://meritbadge.herokuapp.com/ilhook)](https://crates.io/crates/ilhook)

This crate provides methods to inline hook binary codes of `x86` and `x64` instruction sets.

HOOK is a mechanism that intercepts function calls and handles them by user-defined code.

# Installation

This crate works with Cargo and is on
[crates.io](https://crates.io/crates/ilhook). Add it to your `Cargo.toml`
like so:

```toml
[dependencies]
ilhook = "2"
```

# Hook Types

Ilhook supports 4 types of hooking.

## Jmp-back hook

This type is used when you want to get some information, or modify some values
(parameters, stack vars, heap vars, etc.) at the specified timing.

Assume we have a C++ function:

```cpp
void check_serial_number(std::string& sn){
    uint32_t machine_hash = get_machine_hash();
    uint32_t sn_hash = calc_hash(sn);

    // we want to modify the result of this comparison.
    if (sn_hash == machine_hash) {
        // success
    }
    // fail
}
```

And it compiles to the asm code:

```asm
0x401054 call get_machine_hash   ;get_machine_hash()
0x401059 mov ebx, eax

; ...

0x401070 lea eax, sn
0x401076 push eax
0x401077 call calc_hash          ;calc_hash(sn)
0x40107C add esp, 4
0x40107F cmp eax, ebx            ;we want to modify the eax here!
0x401081 jnz _check_fail

; check_success
```

Now let's start:

```rust
use ilhook::x86::{Hooker, HookType, Registers, CallbackOption, HookFlags};

unsafe extern "C" fn on_check_sn(
    reg: *mut Registers,
    _: usize
) {
    println!("m_hash: {}, sn_hash: {}", (*reg).ebx, (*reg).eax);
    (*reg).eax = (*reg).ebx; //we modify the sn_hash!
}

let hooker = Hooker::new(
    0x40107F,
    HookType::JmpBack(on_check_sn),
    CallbackOption::None,
    0,
    HookFlags::empty(),
);
hooker.hook().unwrap();
```

Then `check_serial_number` will always go to the successful path.

## Function hook

This type is used when you want to replace a function with your customized
function. Note that you should only hook at the beginning of a function.

Assume we have a function:

```rust
fn foo(x: u64) -> u64 {
    x * x
}

assert_eq!(foo(5), 25);
```

And you want to let it return `old_foo(x)+x`, which means foo(5)==30.

Now let's hook:

```rust
use ilhook::x64::{Hooker, HookType, Registers, CallbackOption, HookFlags};

unsafe extern "win64" fn new_foo(
    reg: *mut Registers,
    ori_func_ptr :usize,
    _ :usize
) -> usize {
    let x = (&*reg).rdi as u64;
    let ori_func: extern "win64" fn (u64) -> u64 =
        unsafe { std::mem::transmute(ori_func_ptr) };
    (ori_func(x) + x) as usize
}

let hooker = Hooker::new(
    foo as usize,
    HookType::Retn(new_foo),
    CallbackOption::None,
    0,
    HookFlags::empty(),
);
unsafe { hooker.hook().unwrap() };
assert_eq!(foo(5), 30);
```

## Jmp-addr hook

This type is used when you want to change the original run path to any other you wanted.

The first element of the enum `HookType::JmpToAddr` indicates where you want the EIP jump
to after the callback routine returns.

## Jmp-ret hook

This type is used when you want to change the original run path to any other you wanted, and
the destination address may change by the input arguments.

The EIP will jump to the value the callback routine returns.

# Closure Hooks

This crate provides utility functions for registering hooks that use Rust
closures as callbacks rather than `extern "C" fn`s. This involves more layers of
indirection, so it's slightly less efficient, especially when the callbacks
don't actually close over any data. However, it can be useful if you do have
additional data, especially since the closure's lifetime is automatically tied
to the `ClosureHookPoint` that controls when the hook is disposed of.

The closure hook functions are `Hooker::hook_closure_jmp_back`,
`Hooker::hook_closure_retn`, `Hooker::hook_closure_jmp_to_addr`, and
`Hooker::hook_closure_jmp_to_ret`. They match the behavior of the four
`HookType`s.

Here's the same `on_check_sn` example we used above, using a closure hook
instead:

```rust
use ilhook::x86::{Registers, CallbackOption, HookFlags, hook_closure_jmp_back};

let on_check_sn = |reg| {
    println!("m_hash: {}, sn_hash: {}", (*reg).ebx, (*reg).eax);
    (*reg).eax = (*reg).ebx;
};

hook_closure_jmp_back(
    0x40107F,
    on_check_sn,
    CallbackOption::None,
    HookFlags::empty(),
).unwrap();
```

# Notes

This crate is not thread-safe if you don't specify `HookFlags::NOT_MODIFY_MEMORY_PROTECT`. Of course,
you need to modify memory protection of the destination address by yourself if you specify that.

As rust's test run parrallelly, it may crash if not specify `--test-threads=1`.

```

`src/err.rs`:

```rs
use std::io;
use thiserror::Error;

/// Hook errors.
#[derive(Error, Debug)]
pub enum HookError {
    /// Invalid parameter
    #[error("invalid parameter")]
    InvalidParameter,

    /// Error occurs when modifying the memory protect
    #[error("memory protect error, code:{0}")]
    MemoryProtect(u32),

    /// Can't allocate memory
    #[error("memory allocation error, code:{0}")]
    MemoryAllocation(u32),

    /// Can't allocate a memory block between +/-2GB of hooking address
    #[error("searching memory failed")]
    MemorySearching,

    /// Can't get memory layout from /proc/${PID}/maps (only in linux)
    #[error("memory layout format error")]
    MemoryLayoutFormat,

    /// Can't disassemble in the specified address
    #[error("disassemble error")]
    Disassemble,

    /// Can't move code
    #[error("moving code error")]
    MoveCode,

    /// Not supported moving code
    #[error("not supported moving code")]
    MovingCodeNotSupported,

    /// The pre-hook callback failed
    #[error("pre hook failed")]
    PreHook,

    /// Some io error
    #[error("io error")]
    Io(#[from] io::Error),

    /// Unknown error
    #[error("unknown error")]
    Unknown,
}

```

`src/lib.rs`:

```rs
/*!
This crate provides methods to inline hook binary codes of `x86` and `x64` instruction sets.

HOOK is a mechanism that intercepts function calls and handles them by user-defined code.

# Installation

This crate works with Cargo and is on
[crates.io](https://crates.io/crates/ilhook). Add it to your `Cargo.toml`
like so:

```toml
[dependencies]
ilhook = "2"
```

# Hook Types

Ilhook supports 4 types of hooking.

## Jmp-back hook

This type is used when you want to get some information, or modify some values
(parameters, stack vars, heap vars, etc.) at the specified timing.

Assume we have a C++ function:

```cpp
void check_serial_number(std::string& sn){
    uint32_t machine_hash = get_machine_hash();
    uint32_t sn_hash = calc_hash(sn);

    // we want to modify the result of this comparison.
    if (sn_hash == machine_hash) {
        // success
    }
    // fail
}
```

And it compiles to the asm code:

```asm
0x401054 call get_machine_hash   ;get_machine_hash()
0x401059 mov ebx, eax

; ...

0x401070 lea eax, sn
0x401076 push eax
0x401077 call calc_hash          ;calc_hash(sn)
0x40107C add esp, 4
0x40107F cmp eax, ebx            ;we want to modify the eax here!
0x401081 jnz _check_fail

; check_success
```

Now let's start:

```rust
# #[cfg(target_arch = "x86")]
use ilhook::x86::{Hooker, HookType, Registers, CallbackOption, HookFlags};

# #[cfg(target_arch = "x86")]
unsafe extern "cdecl" fn on_check_sn(reg:*mut Registers, _:usize){
    println!("machine_hash: {}, sn_hash: {}", (*reg).ebx, (*reg).eax);
    (*reg).eax = (*reg).ebx; //we modify the sn_hash!
}

# #[cfg(target_arch = "x86")]
let hooker=Hooker::new(0x40107F, HookType::JmpBack(on_check_sn), CallbackOption::None, 0, HookFlags::empty());
//hooker.hook().unwrap(); //commented as hooking is not supported in doc tests
```

Then `check_serial_number` will always go to the successful path.

## Function hook

This type is used when you want to replace a function with your customized
function. Note that you should only hook at the beginning of a function.

Assume we have a function:

```rust
fn foo(x: u64) -> u64 {
    x * x
}

assert_eq!(foo(5), 25);
```

And you want to let it return `old_foo(x)+x`, which means foo(5)==30.

Now let's hook:

```rust
# #[cfg(target_arch = "x86_64")]
use ilhook::x64::{Hooker, HookType, Registers, CallbackOption, HookFlags};
# #[cfg(target_arch = "x86_64")]
# fn foo(x: u64) -> u64 {
#     x * x
# }
# #[cfg(target_arch = "x86_64")]
unsafe extern "win64" fn new_foo(reg:*mut Registers, ori_func_ptr:usize, _:usize)->usize{
    let x = (&*reg).rdi as u64;
    let ori_func: extern "win64" fn (u64) -> u64 =
        unsafe { std::mem::transmute(ori_func_ptr) };
    (ori_func(x) + x) as usize
}

# #[cfg(target_arch = "x86_64")]
let hooker=Hooker::new(foo as usize, HookType::Retn(new_foo), CallbackOption::None, 0, HookFlags::empty());
# #[cfg(target_arch = "x86_64")]
unsafe{hooker.hook().unwrap()};
//assert_eq!(foo(5), 30); //commented as hooking is not supported in doc tests
```

## Jmp-addr hook

This type is used when you want to change the original run path to any other you wanted.

The first element of the enum `HookType::JmpToAddr` indicates where you want the EIP jump
to after the callback routine returns.

## Jmp-ret hook

This type is used when you want to change the original run path to any other you wanted, and
the destination address may change by the input arguments.

The EIP will jump to the value the callback routine returns.

# Closure Hooks

This crate provides utility functions for registering hooks that use Rust
closures as callbacks rather than `extern "C" fn`s. This involves more layers of
indirection, so it's slightly less efficient, especially when the callbacks
don't actually close over any data. However, it can be useful if you do have
additional data, especially since the closure's lifetime is automatically tied
to the `ClosureHookPoint` that controls when the hook is disposed of.

The closure hook functions are `Hooker::hook_closure_jmp_back`,
`Hooker::hook_closure_retn`, `Hooker::hook_closure_jmp_to_addr`, and
`Hooker::hook_closure_jmp_to_ret`. They match the behavior of the four
`HookType`s.

Here's the same `on_check_sn` example we used above, using a closure hook
instead:

```rust
# #[cfg(target_arch = "x86")]
use ilhook::x86::{Registers, CallbackOption, HookFlags, hook_closure_jmp_back};

# #[cfg(target_arch = "x86")]
let on_check_sn = |reg:*mut Registers| {
    println!("m_hash: {}, sn_hash: {}", unsafe {(*reg).ebx}, unsafe {(*reg).eax});
    unsafe{ (*reg).eax = (*reg).ebx };
};

// unsafe { hook_closure_jmp_back(
//     0x40107F,
//     on_check_sn,
//     CallbackOption::None,
//     HookFlags::empty(),
// ) }.unwrap();
```

# Notes

This crate is not thread-safe if you don't specify `HookFlags::NOT_MODIFY_MEMORY_PROTECT`. Of course,
you need to modify memory protection of the destination address by yourself if you specify that.

As rust's test run parrallelly, it may crash if not specify `--test-threads=1`.

*/

#![warn(missing_docs)]

mod err;

pub use err::HookError;

#[cfg(feature = "x86")]
/// The x86 hooker
pub mod x86;

#[cfg(feature = "x64")]
/// The x64 hooker
pub mod x64;

```

`src/x64.rs`:

```rs
mod move_inst;
#[cfg(target_arch = "x86_64")]
mod tests;

use std::io::{Cursor, Seek, SeekFrom, Write};
use std::slice;

#[cfg(windows)]
use core::ffi::c_void;
#[cfg(unix)]
use libc::{__errno_location, c_void, mprotect, sysconf};
#[cfg(windows)]
use windows_sys::Win32::Foundation::GetLastError;
#[cfg(windows)]
use windows_sys::Win32::System::Memory::VirtualProtect;

use bitflags::bitflags;
use iced_x86::{Decoder, DecoderOptions, Instruction};

use crate::HookError;
use move_inst::move_code_to_addr;

const MAX_INST_LEN: usize = 15;

const TRAMPOLINE_MAX_LEN: usize = 1024;

/// This is the routine used in a `jmp-back hook`, which means the RIP will jump back to the
/// original position after the routine has finished running.
///
/// # Parameters
///
/// * `regs` - The registers.
/// * `user_data` - User data that was previously passed to [`Hooker::new`].
pub type JmpBackRoutine = unsafe extern "win64" fn(regs: *mut Registers, user_data: usize);

/// This is the routine used in a `function hook`, which means the routine will replace the
/// original function and the RIP will `retn` directly instead of jumping back.
/// Note that the address being hooked must be the start of a function.
///
/// # Parameters
///
/// * `regs` - The registers.
/// * `ori_func_ptr` - The original function pointer. Call this after converting it to the original function type.
/// * `user_data` - User data that was previously passed to [`Hooker::new`].
///
/// # Return value
///
/// Returns the new return value of the replaced function.
pub type RetnRoutine =
    unsafe extern "win64" fn(regs: *mut Registers, ori_func_ptr: usize, user_data: usize) -> usize;

/// This is the routine used in a `jmp-addr hook`, which means the RIP will jump to the specified
/// address after the routine has finished running.
///
/// # Parameters
///
/// * `regs` - The registers.
/// * `ori_func_ptr` - The original function pointer. Call this after converting it to the original function type.
/// * `user_data` - User data that was previously passed to [`Hooker::new`].
pub type JmpToAddrRoutine =
    unsafe extern "win64" fn(regs: *mut Registers, ori_func_ptr: usize, user_data: usize);

/// This is the routine used in a `jmp-ret hook`, which means the RIP will jump to the return
/// value of the routine.
///
/// # Parameters
///
/// * `regs` - The registers.
/// * `ori_func_ptr` - The original function pointer. Call this after converting it to the original function type.
/// * `user_data` - User data that was previously passed to [`Hooker::new`].
///
/// # Return value
///
/// Returns the address you want to jump to.
pub type JmpToRetRoutine =
    unsafe extern "win64" fn(regs: *mut Registers, ori_func_ptr: usize, user_data: usize) -> usize;

/// The hooking type.
pub enum HookType {
    /// Used in a jmp-back hook
    JmpBack(JmpBackRoutine),

    /// Used in a function hook
    Retn(RetnRoutine),

    /// Used in a jmp-addr hook. The first element is the destination address
    JmpToAddr(usize, JmpToAddrRoutine),

    /// Used in a jmp-ret hook.
    JmpToRet(JmpToRetRoutine),
}

/// Jmp type that the `jmp` instruction use.
pub enum JmpType {
    /// Direct long jump. `jmp` instruction use 5 bytes, but may fail as memory allocation near the 2GB space may fail.
    /// `jmp 0xXXXXXXXX`
    Direct,

    /// Mov rax and jump. Use 11 bytes.
    /// `mov rax, 0xXXXXXXXXXXXXXXXX; jmp rax;`
    MovJmp,

    /// Use 2 jmp instructions to jump. You have to specify the position of the second jmp.
    /// `jmp 0xXXXXXXXX; some codes; mov rax, 0xXXXXXXXX; jmp rax;`
    TrampolineJmp(usize),
}

/// The common registers.
#[repr(C)]
#[derive(Debug, Clone)]
pub struct Registers {
    /// The xmm0 register
    pub xmm0: u128,
    /// The xmm1 register
    pub xmm1: u128,
    /// The xmm2 register
    pub xmm2: u128,
    /// The xmm3 register
    pub xmm3: u128,
    /// The r15 register
    pub r15: u64,
    /// The r14 register
    pub r14: u64,
    /// The r13 register
    pub r13: u64,
    /// The r12 register
    pub r12: u64,
    /// The r11 register
    pub r11: u64,
    /// The r10 register
    pub r10: u64,
    /// The r9 register
    pub r9: u64,
    /// The r8 register
    pub r8: u64,
    /// The rbp register
    pub rbp: u64,
    /// The rdi register
    pub rdi: u64,
    /// The rsi register
    pub rsi: u64,
    /// The rdx register
    pub rdx: u64,
    /// The rcx register
    pub rcx: u64,
    /// The rbx register
    pub rbx: u64,
    /// The rsp register
    pub rsp: u64,
    /// The flags register
    pub rflags: u64,
    /// Unused var
    pub _no_use: u64,
    /// The rax register
    pub rax: u64,
}

impl Registers {
    /// Get the value by index.
    ///
    /// # Parameters
    ///
    /// * cnt - The index of the arguments.
    ///
    /// # Safety
    ///
    /// Process may crash if register `rsp` does not point to a valid stack.
    #[must_use]
    pub unsafe fn get_stack(&self, cnt: usize) -> u64 {
        unsafe { *((self.rsp as usize + cnt * 8) as *mut u64) }
    }
}

/// The trait which is called before and after the modifying of the `jmp` instruction.
/// Usually is used to suspend and resume all other threads, to avoid instruction colliding.
pub trait ThreadCallback {
    /// the callback before modifying `jmp` instruction, should return true if success.
    fn pre(&self) -> bool;
    /// the callback after modifying `jmp` instruction
    fn post(&self);
}

/// Option for thread callback
pub enum CallbackOption {
    /// Valid callback
    Some(Box<dyn ThreadCallback>),
    /// No callback
    None,
}

bitflags! {
    /// Hook flags
    pub struct HookFlags:u32 {
        /// If set, will not modify the memory protection of the destination address, so that
        /// the `hook` function could be ALMOST thread-safe.
        const NOT_MODIFY_MEMORY_PROTECT = 0x1;
    }
}

/// The entry struct in ilhook.
/// Please read the main doc to view usage.
pub struct Hooker {
    addr: usize,
    hook_type: HookType,
    thread_cb: CallbackOption,
    user_data: usize,
    jmp_inst_size: usize,
    flags: HookFlags,
}

/// The hook result returned by `Hooker::hook`.
pub struct HookPoint {
    addr: usize,
    #[allow(dead_code)] // we only use the drop trait of the trampoline
    trampoline: Box<[u8; TRAMPOLINE_MAX_LEN]>,
    trampoline_prot: u32,
    origin: Vec<u8>,
    thread_cb: CallbackOption,
    jmp_inst_size: usize,
    flags: HookFlags,
}

/// The hook result returned by [hook_closure_jmp_back], [hook_closure_retn],
/// [hook_closure_jmp_to_addr], and [hook_closure_jmp_to_ret]. This ensures
/// that the closure's lifetime lasts as long as the hook.
pub struct ClosureHookPoint<'a> {
    _inner: HookPoint,
    _callback: Box<dyn HookCallback + 'a>,
}

/// A dyn-compatible universal trait we use to be able to store all the
/// different types of closures in [ClosureHookPoint] without using generics.
trait HookCallback {}
impl<T> HookCallback for T {}

#[cfg(not(target_arch = "x86_64"))]
fn env_lock() {
    panic!("This crate should only be used in arch x86_32!")
}
#[cfg(target_arch = "x86_64")]
fn env_lock() {}

impl Hooker {
    /// Create a new Hooker.
    ///
    /// # Parameters
    ///
    /// * `addr` - The being-hooked address.
    /// * `hook_type` - The hook type and callback routine.
    /// * `thread_cb` - The callbacks before and after hooking.
    /// * `flags` - Hook flags
    #[must_use]
    pub fn new(
        addr: usize,
        hook_type: HookType,
        thread_cb: CallbackOption,
        user_data: usize,
        flags: HookFlags,
    ) -> Self {
        env_lock();
        Self {
            addr,
            hook_type,
            thread_cb,
            user_data,
            jmp_inst_size: 14,
            flags,
        }
    }

    /// Consumes self and execute hooking. Return the `HookPoint`.
    ///
    /// # Safety
    ///
    /// Process may crash (instead of panic!) if:
    ///
    /// 1. addr is not an accessible memory address, or is not long enough.
    /// 2. addr points to an incorrect position. (At the middle of an instruction, or where after it other instructions may jump to)
    /// 3. Set `NOT_MODIFY_MEMORY_PROTECT` where it should not be set.
    /// 4. hook or unhook from 2 or more threads at the same time without `HookFlags::NOT_MODIFY_MEMORY_PROTECT`. Because of memory protection colliding.
    /// 5. Other unpredictable errors.
    pub unsafe fn hook(self) -> Result<HookPoint, HookError> {
        let (moving_insts, origin) = get_moving_insts(self.addr, self.jmp_inst_size)?;
        let trampoline =
            generate_trampoline(&self, moving_insts, origin.len() as u8, self.user_data)?;
        let trampoline_prot = modify_mem_protect(trampoline.as_ptr() as usize, trampoline.len())?;
        if !self.flags.contains(HookFlags::NOT_MODIFY_MEMORY_PROTECT) {
            let old_prot = modify_mem_protect(self.addr, self.jmp_inst_size)?;
            let ret = modify_jmp_with_thread_cb(&self, trampoline.as_ptr() as usize);
            recover_mem_protect(self.addr, self.jmp_inst_size, old_prot);
            ret?;
        } else {
            modify_jmp_with_thread_cb(&self, trampoline.as_ptr() as usize)?;
        }
        Ok(HookPoint {
            addr: self.addr,
            trampoline,
            trampoline_prot,
            origin,
            thread_cb: self.thread_cb,
            jmp_inst_size: self.jmp_inst_size,
            flags: self.flags,
        })
    }
}


/// A high-level helper for hooking a function using the [JmpBackRoutine]
/// strategy. The [callback] is called before any calls to the function at
/// [address], and then the original function is called as normal
/// afterwards.
///
/// The callback is passed [Registers] that provide access to the original
/// function's arguments.
///
/// ## Safety
///
/// See [`Hooker::hook`] for details on when this is safe to call.
pub unsafe fn hook_closure_jmp_back<'a, T: Fn(*mut Registers) + Send + Sync + 'a>(
    address: usize,
    callback: T,
    callback_option: CallbackOption,
    hook_flags: HookFlags,
) -> Result<ClosureHookPoint<'a>, HookError> {
    let callback = Box::new(callback);
    let hooker = Hooker::new(
        address,
        HookType::JmpBack(run_jmp_back_closure::<T>),
        callback_option,
        &*callback as *const T as usize,
        hook_flags,
    );
    Ok(ClosureHookPoint {
        _inner: unsafe { hooker.hook()? },
        _callback: callback,
    })
}

/// A high-level helper for hooking a function using the [RetnRoutine]
/// strategy. All calls to the function at [address] are routed to
/// [callback] instead, and its return value is used in place of the
/// original function's return value.
///
/// The callback is passed [Registers] that provide access to the original
/// function's arguments, as well as a usize that can be cast to the
/// original function's signature using [std::mem::transmute].
///
/// ## Safety
///
/// See [`Hooker::hook`] for details on when this is safe to call.
pub unsafe fn hook_closure_retn<
    'a,
    T: (Fn(*mut Registers, usize) -> usize) + Send + Sync + 'a,
>(
    address: usize,
    callback: T,
    callback_option: CallbackOption,
    hook_flags: HookFlags,
) -> Result<ClosureHookPoint<'a>, HookError> {
    let callback = Box::new(callback);
    let hooker = Hooker::new(
        address,
        HookType::Retn(run_retn_closure::<T>),
        callback_option,
        &*callback as *const T as usize,
        hook_flags,
    );
    Ok(ClosureHookPoint {
        _inner: unsafe { hooker.hook()? },
        _callback: callback,
    })
}

/// A high-level helper for hooking a function using the [JmpToAddrRoutine]
/// strategy. All calls to the function at [address] are routed to
/// [callback] instead, then the function at [follow_up] is called and its
/// return value is used in place of the original function's.
///
/// The callback is passed [Registers] that provide access to the original
/// function's arguments, as well as a usize that can be cast to the
/// original function's signature using [std::mem::transmute].
///
/// ## Safety
///
/// See [`Hooker::hook`] for details on when this is safe to call.
pub unsafe fn hook_closure_jmp_to_addr<'a, T: Fn(*mut Registers, usize) + Send + Sync + 'a>(
    address: usize,
    follow_up: usize,
    callback: T,
    callback_option: CallbackOption,
    hook_flags: HookFlags,
) -> Result<ClosureHookPoint<'a>, HookError> {
    let callback = Box::new(callback);
    let hooker = Hooker::new(
        address,
        HookType::JmpToAddr(follow_up, run_jmp_to_addr_closure::<T>),
        callback_option,
        &*callback as *const T as usize,
        hook_flags,
    );
    Ok(ClosureHookPoint {
        _inner: unsafe { hooker.hook()? },
        _callback: callback,
    })
}

/// A high-level helper for hooking a function using the [JmpToRetRoutine]
/// strategy. All calls to the function at [address] are routed to
/// [callback] instead, then the function at the addressed returned by
/// [callback] is called and its return value is used in place of the
/// original function's
///
/// The callback is passed [Registers] that provide access to the original
/// function's arguments, as well as a usize that can be cast to the
/// original function's signature using [std::mem::transmute].
///
/// ## Safety
///
/// See [`Hooker::hook`] for details on when this is safe to call.
pub unsafe fn hook_closure_jmp_to_ret<
    'a,
    T: (Fn(*mut Registers, usize) -> usize) + Send + Sync + 'a,
>(
    address: usize,
    callback: T,
    callback_option: CallbackOption,
    hook_flags: HookFlags,
) -> Result<ClosureHookPoint<'a>, HookError> {
    let callback = Box::new(callback);
    let hooker = Hooker::new(
        address,
        HookType::JmpToRet(run_retn_closure::<T>),
        callback_option,
        &*callback as *const T as usize,
        hook_flags,
    );
    Ok(ClosureHookPoint {
        _inner: unsafe { hooker.hook()? },
        _callback: callback,
    })
}

/// The userdata trampoline for [Hooker::hook_closure_jmp_back].
unsafe extern "win64" fn run_jmp_back_closure<T: Fn(*mut Registers)>(
    reg: *mut Registers,
    callback: usize,
) {
    unsafe { (*(callback as *const T))(reg) };
}

/// The userdata trampoline for [Hooker::hook_closure_retn] *and*
/// [Hooker::hook_closure_jmp_to_ret].
unsafe extern "win64" fn run_retn_closure<T: Fn(*mut Registers, usize) -> usize>(
    reg: *mut Registers,
    original: usize,
    callback: usize,
) -> usize {
    unsafe { (*(callback as *const T))(reg, original) }
}

/// The userdata trampoline for [Hooker::hook_closure_jmp_to_addr].
unsafe extern "win64" fn run_jmp_to_addr_closure<T: Fn(*mut Registers, usize)>(
    reg: *mut Registers,
    original: usize,
    callback: usize,
) {
    unsafe { (*(callback as *const T))(reg, original) };
}

impl HookPoint {
    /// Consume self and unhook the address.
    pub unsafe fn unhook(self) -> Result<(), HookError> {
        self.unhook_by_ref()
    }

    fn unhook_by_ref(&self) -> Result<(), HookError> {
        let ret: Result<(), HookError>;
        if !self.flags.contains(HookFlags::NOT_MODIFY_MEMORY_PROTECT) {
            let old_prot = modify_mem_protect(self.addr, self.jmp_inst_size)?;
            ret = recover_jmp_with_thread_cb(self);
            recover_mem_protect(self.addr, self.jmp_inst_size, old_prot);
        } else {
            ret = recover_jmp_with_thread_cb(self)
        }
        recover_mem_protect(
            self.trampoline.as_ptr() as usize,
            self.trampoline.len(),
            self.trampoline_prot,
        );
        ret
    }
}

// When the HookPoint drops, it should unhook automatically.
impl Drop for HookPoint {
    fn drop(&mut self) {
        self.unhook_by_ref().unwrap_or_default();
    }
}

fn get_moving_insts(
    addr: usize,
    min_bytes: usize,
) -> Result<(Vec<Instruction>, Vec<u8>), HookError> {
    let code_slice = unsafe { slice::from_raw_parts(addr as *const u8, MAX_INST_LEN * 2) };
    let mut decoder = Decoder::new(64, code_slice, DecoderOptions::NONE);
    decoder.set_ip(addr as u64);

    let mut total_bytes = 0;
    let mut ori_insts: Vec<Instruction> = vec![];
    for inst in &mut decoder {
        if inst.is_invalid() {
            return Err(HookError::Disassemble);
        }
        ori_insts.push(inst);
        total_bytes += inst.len();
        if total_bytes >= min_bytes {
            break;
        }
    }

    Ok((ori_insts, code_slice[0..decoder.position()].into()))
}

fn write_trampoline_prolog(buf: &mut impl Write) -> Result<usize, std::io::Error> {
    // push rsp
    // pushfq
    // test rsp,8
    // je _stack_aligned_16
    // ; stack not aligned to 16
    // push rax
    // sub rsp,0x10
    // mov rax, [rsp+0x20] # rsp
    // mov [rsp], rax
    // mov rax, [rsp+0x18] # rflags
    // mov [rsp+8], rax
    // mov rax, [rsp+0x10] # rax
    // mov [rsp+0x18], rax
    // mov dword ptr [rsp+0x10],1 # stack flag
    // jmp _other_registers
    // _stack_aligned_16:
    // push rax
    // push rax
    // mov rax, [rsp+0x18] # rsp
    // mov [rsp], rax
    // mov rax, [rsp+8] # rax
    // mov [rsp+0x18], rax
    // mov rax,[rsp+0x10] # rflags
    // mov [rsp+8], rax
    // mov dword ptr [rsp+0x10], 0 # stack flag
    // _other_registers:
    // push rbx
    // push rcx
    // push rdx
    // push rsi
    // push rdi
    // push rbp
    // push r8
    // push r9
    // push r10
    // push r11
    // push r12
    // push r13
    // push r14
    // push r15
    // sub rsp,0x40
    // movaps xmmword ptr ss:[rsp],xmm0
    // movaps xmmword ptr ss:[rsp+0x10],xmm1
    // movaps xmmword ptr ss:[rsp+0x20],xmm2
    // movaps xmmword ptr ss:[rsp+0x30],xmm3
    buf.write(&[
        0x54, 0x9C, 0x48, 0xF7, 0xC4, 0x08, 0x00, 0x00, 0x00, 0x74, 0x2C, 0x50, 0x48, 0x83, 0xEC,
        0x10, 0x48, 0x8B, 0x44, 0x24, 0x20, 0x48, 0x89, 0x04, 0x24, 0x48, 0x8B, 0x44, 0x24, 0x18,
        0x48, 0x89, 0x44, 0x24, 0x08, 0x48, 0x8B, 0x44, 0x24, 0x10, 0x48, 0x89, 0x44, 0x24, 0x18,
        0xC7, 0x44, 0x24, 0x10, 0x01, 0x00, 0x00, 0x00, 0xEB, 0x27, 0x50, 0x50, 0x48, 0x8B, 0x44,
        0x24, 0x18, 0x48, 0x89, 0x04, 0x24, 0x48, 0x8B, 0x44, 0x24, 0x08, 0x48, 0x89, 0x44, 0x24,
        0x18, 0x48, 0x8B, 0x44, 0x24, 0x10, 0x48, 0x89, 0x44, 0x24, 0x08, 0xC7, 0x44, 0x24, 0x10,
        0x00, 0x00, 0x00, 0x00, 0x53, 0x51, 0x52, 0x56, 0x57, 0x55, 0x41, 0x50, 0x41, 0x51, 0x41,
        0x52, 0x41, 0x53, 0x41, 0x54, 0x41, 0x55, 0x41, 0x56, 0x41, 0x57, 0x48, 0x83, 0xEC, 0x40,
        0x0F, 0x29, 0x04, 0x24, 0x0F, 0x29, 0x4C, 0x24, 0x10, 0x0F, 0x29, 0x54, 0x24, 0x20, 0x0F,
        0x29, 0x5C, 0x24, 0x30,
    ])
}

fn write_trampoline_epilog1(buf: &mut impl Write) -> Result<usize, std::io::Error> {
    // movaps xmm0,xmmword ptr ss:[rsp]
    // movaps xmm1,xmmword ptr ss:[rsp+0x10]
    // movaps xmm2,xmmword ptr ss:[rsp+0x20]
    // movaps xmm3,xmmword ptr ss:[rsp+0x30]
    // add rsp,0x40
    // pop r15
    // pop r14
    // pop r13
    // pop r12
    // pop r11
    // pop r10
    // pop r9
    // pop r8
    // pop rbp
    // pop rdi
    // pop rsi
    // pop rdx
    // pop rcx
    // pop rbx
    // add rsp,8
    buf.write(&[
        0x0F, 0x28, 0x04, 0x24, 0x0F, 0x28, 0x4C, 0x24, 0x10, 0x0F, 0x28, 0x54, 0x24, 0x20, 0x0F,
        0x28, 0x5C, 0x24, 0x30, 0x48, 0x83, 0xC4, 0x40, 0x41, 0x5F, 0x41, 0x5E, 0x41, 0x5D, 0x41,
        0x5C, 0x41, 0x5B, 0x41, 0x5A, 0x41, 0x59, 0x41, 0x58, 0x5D, 0x5F, 0x5E, 0x5A, 0x59, 0x5B,
        0x48, 0x83, 0xC4, 0x08,
    ])
}

fn write_trampoline_epilog2_common(buf: &mut impl Write) -> Result<usize, std::io::Error> {
    // test dword ptr ss:[rsp+0x8],1
    // je _branch1
    // mov rax, [rsp+0x10]
    // mov [rsp+0x18], rax
    // popfq
    // pop rax
    // pop rax
    // pop rax
    // jmp _branch2
    // _branch1:
    // popfq
    // pop rax
    // pop rax
    // _branch2:
    buf.write(&[
        0xF7, 0x44, 0x24, 0x08, 0x01, 0x00, 0x00, 0x00, 0x74, 0x10, 0x48, 0x8B, 0x44, 0x24, 0x10,
        0x48, 0x89, 0x44, 0x24, 0x18, 0x9D, 0x58, 0x58, 0x58, 0xEB, 0x03, 0x9D, 0x58, 0x58,
    ])
}

fn write_trampoline_epilog2_jmp_ret(buf: &mut impl Write) -> Result<usize, std::io::Error> {
    // test dword ptr ss:[rsp+8],1
    // je _branch1
    // popfq
    // mov [rsp], rax
    // pop rax
    // pop rax
    // lea rsp, [rsp+8] # Not use 'add rsp, 8' as it will modify the rflags
    // jmp _branch2
    // _branch1:
    // popfq
    // mov [rsp-8],rax
    // pop rax
    // pop rax
    // _branch2:
    // jmp qword ptr ss:[rsp-0x18]
    buf.write(&[
        0xF7, 0x44, 0x24, 0x08, 0x01, 0x00, 0x00, 0x00, 0x74, 0x0E, 0x9D, 0x48, 0x89, 0x04, 0x24,
        0x58, 0x58, 0x48, 0x8D, 0x64, 0x24, 0x08, 0xEB, 0x08, 0x9D, 0x48, 0x89, 0x44, 0x24, 0xF8,
        0x58, 0x58, 0xFF, 0x64, 0x24, 0xE8
    ])
}

fn jmp_addr<T: Write>(addr: u64, buf: &mut T) -> Result<(), HookError> {
    buf.write(&[0xff, 0x25, 0, 0, 0, 0])?;
    buf.write(&addr.to_le_bytes())?;
    Ok(())
}

fn write_ori_func_addr<T: Write + Seek>(buf: &mut T, ori_func_addr_off: u64, ori_func_off: u64) {
    let pos = buf.stream_position().unwrap();
    buf.seek(SeekFrom::Start(ori_func_addr_off)).unwrap();
    buf.write(&ori_func_off.to_le_bytes()).unwrap();
    buf.seek(SeekFrom::Start(pos)).unwrap();
}

fn generate_jmp_back_trampoline<T: Write + Seek>(
    buf: &mut T,
    trampoline_base_addr: u64,
    moving_code: &Vec<Instruction>,
    ori_addr: usize,
    cb: JmpBackRoutine,
    ori_len: u8,
    user_data: usize,
) -> Result<(), HookError> {
    // mov rdx, user_data
    buf.write(&[0x48, 0xba])?;
    buf.write(&(user_data as u64).to_le_bytes())?;
    // mov rcx, rsp
    // sub rsp, 0x10
    // mov rax, cb
    buf.write(&[0x48, 0x89, 0xe1, 0x48, 0x83, 0xec, 0x10, 0x48, 0xb8])?;
    buf.write(&(cb as usize as u64).to_le_bytes())?;
    // call rax
    // add rsp, 0x10
    buf.write(&[0xff, 0xd0, 0x48, 0x83, 0xc4, 0x10])?;
    write_trampoline_epilog1(buf)?;
    write_trampoline_epilog2_common(buf)?;

    let cur_pos = buf.stream_position().unwrap();
    buf.write(&move_code_to_addr(
        moving_code,
        trampoline_base_addr + cur_pos,
    )?)?;

    jmp_addr(ori_addr as u64 + u64::from(ori_len), buf)?;
    Ok(())
}

fn generate_retn_trampoline<T: Write + Seek>(
    buf: &mut T,
    trampoline_base_addr: u64,
    moving_code: &Vec<Instruction>,
    ori_addr: usize,
    cb: RetnRoutine,
    ori_len: u8,
    user_data: usize,
) -> Result<(), HookError> {
    // mov r8, user_data
    buf.write(&[0x49, 0xb8])?;
    buf.write(&(user_data as u64).to_le_bytes())?;
    let ori_func_addr_off = buf.stream_position().unwrap() + 2;
    // mov rdx, ori_func
    // mov rcx, rsp
    // sub rsp,0x20
    // mov rax, cb
    buf.write(&[
        0x48, 0xba, 0, 0, 0, 0, 0, 0, 0, 0, 0x48, 0x89, 0xe1, 0x48, 0x83, 0xec, 0x20, 0x48, 0xb8,
    ])?;
    buf.write(&(cb as usize as u64).to_le_bytes())?;
    // call rax
    // add rsp, 0x20
    // mov [rsp + 0xc8], rax
    buf.write(&[
        0xff, 0xd0, 0x48, 0x83, 0xc4, 0x20, 0x48, 0x89, 0x84, 0x24, 0xc8, 0x00, 0x00, 0x00,
    ])?;
    write_trampoline_epilog1(buf)?;
    write_trampoline_epilog2_common(buf)?;
    // ret
    buf.write(&[0xc3])?;

    let ori_func_off = buf.stream_position().unwrap();
    buf.write(&move_code_to_addr(
        moving_code,
        trampoline_base_addr + ori_func_off,
    )?)?;
    jmp_addr(ori_addr as u64 + u64::from(ori_len), buf)?;

    write_ori_func_addr(buf, ori_func_addr_off, trampoline_base_addr + ori_func_off);

    Ok(())
}

fn generate_jmp_addr_trampoline<T: Write + Seek>(
    buf: &mut T,
    trampoline_base_addr: u64,
    moving_code: &Vec<Instruction>,
    ori_addr: usize,
    dest_addr: usize,
    cb: JmpToAddrRoutine,
    ori_len: u8,
    user_data: usize,
) -> Result<(), HookError> {
    // mov r8, user_data
    buf.write(&[0x49, 0xb8])?;
    buf.write(&(user_data as u64).to_le_bytes())?;
    let ori_func_addr_off = buf.stream_position().unwrap() + 2;
    // mov rdx, ori_func
    // mov rcx, rsp
    // sub rsp,0x20
    // mov rax, cb
    buf.write(&[
        0x48, 0xba, 0, 0, 0, 0, 0, 0, 0, 0, 0x48, 0x89, 0xe1, 0x48, 0x83, 0xec, 0x20, 0x48, 0xb8,
    ])?;
    buf.write(&(cb as usize as u64).to_le_bytes())?;
    // call rax
    // add rsp, 0x20
    buf.write(&[0xff, 0xd0, 0x48, 0x83, 0xc4, 0x20])?;
    write_trampoline_epilog1(buf)?;
    write_trampoline_epilog2_common(buf)?;
    jmp_addr(dest_addr as u64, buf)?;

    let ori_func_off = buf.stream_position().unwrap();
    buf.write(&move_code_to_addr(
        moving_code,
        trampoline_base_addr + ori_func_off,
    )?)?;
    jmp_addr(ori_addr as u64 + u64::from(ori_len), buf)?;

    write_ori_func_addr(buf, ori_func_addr_off, trampoline_base_addr + ori_func_off);

    Ok(())
}

fn generate_jmp_ret_trampoline<T: Write + Seek>(
    buf: &mut T,
    trampoline_base_addr: u64,
    moving_code: &Vec<Instruction>,
    ori_addr: usize,
    cb: JmpToRetRoutine,
    ori_len: u8,
    user_data: usize,
) -> Result<(), HookError> {
    // mov r8, user_data
    buf.write(&[0x49, 0xb8])?;
    buf.write(&(user_data as u64).to_le_bytes())?;
    let ori_func_addr_off = buf.stream_position().unwrap() + 2;
    // mov rdx, ori_func
    // mov rcx, rsp
    // sub rsp,0x20
    // mov rax, cb
    buf.write(&[
        0x48, 0xba, 0, 0, 0, 0, 0, 0, 0, 0, 0x48, 0x89, 0xe1, 0x48, 0x83, 0xec, 0x20, 0x48, 0xb8,
    ])?;
    buf.write(&(cb as usize as u64).to_le_bytes())?;
    // call rax
    // add rsp, 0x20
    buf.write(&[0xff, 0xd0, 0x48, 0x83, 0xc4, 0x20])?;
    write_trampoline_epilog1(buf)?;
    write_trampoline_epilog2_jmp_ret(buf)?;

    let ori_func_off = buf.stream_position().unwrap();
    buf.write(&move_code_to_addr(
        moving_code,
        trampoline_base_addr + ori_func_off,
    )?)?;
    jmp_addr(ori_addr as u64 + u64::from(ori_len), buf)?;

    write_ori_func_addr(buf, ori_func_addr_off, trampoline_base_addr + ori_func_off);

    Ok(())
}

fn generate_trampoline(
    hooker: &Hooker,
    moving_code: Vec<Instruction>,
    ori_len: u8,
    user_data: usize,
) -> Result<Box<[u8; TRAMPOLINE_MAX_LEN]>, HookError> {
    let mut trampoline_buffer = Box::new([0u8; TRAMPOLINE_MAX_LEN]);
    let trampoline_addr = trampoline_buffer.as_ptr() as u64;
    let mut buf = Cursor::new(&mut trampoline_buffer[..]);

    write_trampoline_prolog(&mut buf)?;

    match hooker.hook_type {
        HookType::JmpBack(cb) => generate_jmp_back_trampoline(
            &mut buf,
            trampoline_addr,
            &moving_code,
            hooker.addr,
            cb,
            ori_len,
            user_data,
        ),
        HookType::Retn(cb) => generate_retn_trampoline(
            &mut buf,
            trampoline_addr,
            &moving_code,
            hooker.addr,
            cb,
            ori_len,
            user_data,
        ),
        HookType::JmpToAddr(dest_addr, cb) => generate_jmp_addr_trampoline(
            &mut buf,
            trampoline_addr,
            &moving_code,
            hooker.addr,
            dest_addr,
            cb,
            ori_len,
            user_data,
        ),
        HookType::JmpToRet(cb) => generate_jmp_ret_trampoline(
            &mut buf,
            trampoline_addr,
            &moving_code,
            hooker.addr,
            cb,
            ori_len,
            user_data,
        ),
    }?;

    Ok(trampoline_buffer)
}

#[cfg(windows)]
fn modify_mem_protect(addr: usize, len: usize) -> Result<u32, HookError> {
    let mut old_prot: u32 = 0;
    let old_prot_ptr = std::ptr::addr_of_mut!(old_prot);
    // PAGE_EXECUTE_READWRITE = 0x40
    let ret = unsafe { VirtualProtect(addr as *const c_void, len, 0x40, old_prot_ptr) };
    if ret == 0 {
        Err(HookError::MemoryProtect(unsafe { GetLastError() }))
    } else {
        Ok(old_prot)
    }
}

#[cfg(unix)]
fn modify_mem_protect(addr: usize, len: usize) -> Result<u32, HookError> {
    let page_size = unsafe { sysconf(30) }; //_SC_PAGESIZE == 30
    if len > page_size.try_into().unwrap() {
        Err(HookError::InvalidParameter)
    } else {
        //(PROT_READ | PROT_WRITE | PROT_EXEC) == 7
        let ret = unsafe {
            mprotect(
                (addr & !(page_size as usize - 1)) as *mut c_void,
                page_size as usize,
                7,
            )
        };
        if ret != 0 {
            let err = unsafe { *(__errno_location()) };
            Err(HookError::MemoryProtect(err as u32))
        } else {
            // it's too complex to get the original memory protection
            Ok(7)
        }
    }
}
#[cfg(windows)]
fn recover_mem_protect(addr: usize, len: usize, old: u32) {
    let mut old_prot: u32 = 0;
    let old_prot_ptr = std::ptr::addr_of_mut!(old_prot);
    unsafe { VirtualProtect(addr as *const c_void, len, old, old_prot_ptr) };
}

#[cfg(unix)]
fn recover_mem_protect(addr: usize, _: usize, old: u32) {
    let page_size = unsafe { sysconf(30) }; //_SC_PAGESIZE == 30
    unsafe {
        mprotect(
            (addr & !(page_size as usize - 1)) as *mut c_void,
            page_size as usize,
            old as i32,
        )
    };
}
fn modify_jmp(dest_addr: usize, trampoline_addr: usize) {
    let buf = unsafe { slice::from_raw_parts_mut(dest_addr as *mut u8, 14) };
    let distance = trampoline_addr as i64 - (dest_addr as i64 + 5);
    if distance.abs() <= 0x7fff_ffff {
        // jmp xxx
        buf[0] = 0xe9;
        buf[1..5].copy_from_slice(&(distance as i32).to_le_bytes());
    } else {
        // jmp qword ptr [rip+0]
        buf[0..6].copy_from_slice(&[0xff, 0x25, 0, 0, 0, 0]);
        buf[6..14].copy_from_slice(&(trampoline_addr as u64).to_le_bytes());
    }
}

fn modify_jmp_with_thread_cb(hook: &Hooker, trampoline_addr: usize) -> Result<(), HookError> {
    if let CallbackOption::Some(cbs) = &hook.thread_cb {
        if !cbs.pre() {
            return Err(HookError::PreHook);
        }
        modify_jmp(hook.addr, trampoline_addr);
        cbs.post();
        Ok(())
    } else {
        modify_jmp(hook.addr, trampoline_addr);
        Ok(())
    }
}

fn recover_jmp(dest_addr: usize, origin: &[u8]) {
    let buf = unsafe { slice::from_raw_parts_mut(dest_addr as *mut u8, origin.len()) };
    // jmp trampoline_addr
    buf.copy_from_slice(origin);
}

fn recover_jmp_with_thread_cb(hook: &HookPoint) -> Result<(), HookError> {
    if let CallbackOption::Some(cbs) = &hook.thread_cb {
        if !cbs.pre() {
            return Err(HookError::PreHook);
        }
        recover_jmp(hook.addr, &hook.origin);
        cbs.post();
    } else {
        recover_jmp(hook.addr, &hook.origin);
    }
    Ok(())
}

```

`src/x64/fixed_memory_unix.rs`:

```rs
use super::{cmp, HookError};
use regex::Regex;
use std::format;
use std::fs::File;
use std::io::{BufRead, BufReader};
use std::process;
use std::sync::LazyLock;

use libc::{
    __errno_location, c_void, mmap, munmap, sysconf, MAP_ANONYMOUS, MAP_FIXED_NOREPLACE,
    MAP_PRIVATE,
};

pub(super) struct FixedMemory {
    pub addr: u64,
    pub len: u32,
}

impl Drop for FixedMemory {
    fn drop(&mut self) {
        unsafe { munmap(self.addr as *mut c_void, self.len as usize) };
    }
}

impl FixedMemory {
    pub fn allocate(hook_addr: u64) -> Result<Self, HookError> {
        let bound = Bound::new(hook_addr);
        let block = MemoryLayout::read_self_mem_layout()?.find_memory_with_bound(&bound)?;
        let len = block.end - block.begin;
        let mut addr = unsafe {
            mmap(
                block.begin as *mut c_void,
                len as usize,
                7,
                MAP_PRIVATE | MAP_FIXED_NOREPLACE | MAP_ANONYMOUS,
                -1,
                0,
            )
        } as usize as u64;
        // If kernel doesn't support MAP_FIXED_NOREPLACE
        if addr == u64::MAX && unsafe { *(__errno_location()) } == 95 {
            addr = unsafe {
                mmap(
                    block.begin as *mut c_void,
                    len as usize,
                    7,
                    MAP_PRIVATE | MAP_ANONYMOUS,
                    -1,
                    0,
                )
            } as usize as u64;
        }
        match addr {
            0xffff_ffff_ffff_ffff => Err(HookError::MemoryProtect(
                unsafe { *(__errno_location()) } as u32,
            )),
            x if x == block.begin || (x >= bound.min && x + len <= bound.max) => Ok(Self {
                addr,
                len: len as u32,
            }),
            _ => Err(HookError::MemoryProtect(0)),
        }
    }
}

struct MemoryLayout(Vec<MemoryBlock>);

impl MemoryLayout {
    fn read_self_mem_layout() -> Result<Self, HookError> {
        let maps = File::open(format!("/proc/{}/maps", process::id()))?;
        BufReader::new(maps)
            .lines()
            .map(|line| {
                line.map_err(|_| HookError::MemoryLayoutFormat)
                    .and_then(MemoryBlock::from_string)
            })
            .collect::<Result<Vec<_>, _>>()
            .map(Self)
    }

    fn find_memory_with_bound(&self, bnd: &Bound) -> Result<MemoryBlock, HookError> {
        //@todo fix: find memory block from middle to edge
        let page_size = unsafe { sysconf(30) } as u64; //_SC_PAGESIZE == 30
        let blocks = &self.0;
        if blocks.is_empty() {
            return Err(HookError::MemoryAllocation(0));
        }
        // test the first block
        if blocks[0].begin > page_size * 2 && bnd.min <= page_size {
            return Ok(MemoryBlock {
                begin: page_size,
                end: page_size * 2,
            });
        }
        for i in 1..blocks.len() {
            let gap = blocks[i].begin - blocks[i - 1].end;
            if gap >= page_size && blocks[i - 1].end >= bnd.min && blocks[i].begin < bnd.max {
                return Ok(MemoryBlock {
                    begin: blocks[i - 1].end,
                    end: blocks[i - 1].end + page_size,
                });
            }
        }
        Err(HookError::MemorySearching)
    }
}

#[derive(Debug)]
struct MemoryBlock {
    begin: u64,
    end: u64,
}
impl MemoryBlock {
    fn from_string(s: String) -> Result<Self, HookError> {
        static RE: LazyLock<Regex> = LazyLock::new(|| Regex::new("^([a-fA-F0-9]+)-([a-fA-F0-9]+)").unwrap());
        //let RE = Regex::new("").unwrap();
        RE.captures(&s)
            .ok_or(HookError::MemoryLayoutFormat)
            .and_then(|cap| {
                let begin = cap.get(1).unwrap().as_str();
                let end = cap.get(2).unwrap().as_str();
                Ok(Self {
                    begin: u64::from_str_radix(begin, 16).or(Err(HookError::MemoryLayoutFormat))?,
                    end: u64::from_str_radix(end, 16).or(Err(HookError::MemoryLayoutFormat))?,
                })
            })
    }
}

struct Bound {
    min: u64,
    max: u64,
}

impl Bound {
    fn new(init_addr: u64) -> Self {
        Self {
            min: init_addr.saturating_sub(i32::MAX as u64),
            max: init_addr.saturating_add(i32::MAX as u64),
        }
    }

    fn _to_new(self, dest: u64) -> Self {
        Self {
            min: cmp::max(self.min, dest.saturating_sub(i32::MAX as u64)),
            max: cmp::min(self.max, dest.saturating_add(i32::MAX as u64)),
        }
    }

    fn _check(&self) -> Result<(), HookError> {
        if self.min > self.max {
            Err(HookError::InvalidParameter)
        } else {
            Ok(())
        }
    }
}

```

`src/x64/fixed_memory_win.rs`:

```rs
use super::{cmp, HookError};

use core::ffi::c_void;
use std::mem::{size_of, MaybeUninit};
use windows_sys::Win32::Foundation::{GetLastError, ERROR_INVALID_PARAMETER};
use windows_sys::Win32::System::Memory::{VirtualAlloc, VirtualFree, VirtualQuery};
use windows_sys::Win32::System::Memory::{
    MEMORY_BASIC_INFORMATION, MEM_COMMIT, MEM_FREE, MEM_RELEASE, MEM_RESERVE,
    PAGE_EXECUTE_READWRITE,
};

enum QueryResult {
    Success(u64),
    NotUsable(u64, u64),
    OverLimit,
    Fail(u32),
}

pub(super) struct FixedMemory {
    pub addr: u64,
    pub len: u32,
}

impl Drop for FixedMemory {
    fn drop(&mut self) {
        unsafe { VirtualFree(self.addr as *mut c_void, 0, MEM_RELEASE) };
    }
}
impl FixedMemory {
    pub fn allocate(hook_addr: u64) -> Result<Self, HookError> {
        let addr = FixedMemory::allocate_internal(&Bound::new(hook_addr))?;

        Ok(Self { addr, len: 4096 })
    }

    fn query_and_alloc(addr: u64) -> QueryResult {
        #[allow(invalid_value)]
        let mut mbi: MEMORY_BASIC_INFORMATION = unsafe { MaybeUninit::uninit().assume_init() };
        let ret = unsafe {
            VirtualQuery(
                addr as *mut c_void,
                &mut mbi,
                size_of::<MEMORY_BASIC_INFORMATION>(),
            )
        };
        if ret == 0 {
            let last_err = unsafe { GetLastError() };
            if last_err == ERROR_INVALID_PARAMETER {
                // ERROR_INVALID_PARAMETER means lpAddress specifies an address above
                // the highest memory address accessible to the process. (from MSDN)
                QueryResult::OverLimit
            } else {
                QueryResult::Fail(last_err)
            }
        } else if mbi.State == MEM_FREE && mbi.RegionSize >= 4096 {
            let mem = unsafe {
                VirtualAlloc(
                    mbi.BaseAddress,
                    4096,
                    MEM_COMMIT | MEM_RESERVE,
                    PAGE_EXECUTE_READWRITE,
                )
            };
            if mem == std::ptr::null_mut() {
                QueryResult::NotUsable(mbi.BaseAddress as usize as u64, mbi.RegionSize as u64)
            } else {
                QueryResult::Success(mem as usize as u64)
            }
        } else {
            QueryResult::NotUsable(mbi.BaseAddress as usize as u64, mbi.RegionSize as u64)
        }
    }

    fn allocate_internal(bnd: &Bound) -> Result<u64, HookError> {
        let mut cur_addr = bnd.middle();
        while cur_addr < bnd.max {
            match FixedMemory::query_and_alloc(cur_addr) {
                QueryResult::Success(addr) => {
                    return Ok(addr);
                }
                QueryResult::NotUsable(_, size) => {
                    cur_addr += if size > 0 { size } else { 4096 };
                }
                QueryResult::OverLimit => {
                    break;
                }
                QueryResult::Fail(e) => {
                    return Err(HookError::MemoryAllocation(e));
                }
            }
        }
        cur_addr = bnd.middle();
        while cur_addr > bnd.min {
            match FixedMemory::query_and_alloc(cur_addr) {
                QueryResult::Success(addr) => {
                    return Ok(addr);
                }
                QueryResult::NotUsable(base, _) => {
                    cur_addr = base.saturating_sub(4096);
                }
                QueryResult::Fail(e) => {
                    return Err(HookError::MemoryAllocation(e));
                }
                QueryResult::OverLimit => {
                    return Err(HookError::MemoryAllocation(0));
                }
            }
        }
        Err(HookError::MemorySearching)
    }
}

struct Bound {
    min: u64,
    max: u64,
}

impl Bound {
    fn new(init_addr: u64) -> Self {
        Self {
            min: init_addr.saturating_sub(i32::MAX as u64),
            max: init_addr.saturating_add(i32::MAX as u64),
        }
    }

    fn _to_new(self, dest: u64) -> Self {
        Self {
            min: cmp::max(self.min, dest.saturating_sub(i32::MAX as u64)),
            max: cmp::min(self.max, dest.saturating_add(i32::MAX as u64)),
        }
    }

    fn _check(&self) -> Result<(), HookError> {
        if self.min > self.max {
            Err(HookError::InvalidParameter)
        } else {
            Ok(())
        }
    }

    fn middle(&self) -> u64 {
        self.min / 2 + self.max / 2
    }
}

```

`src/x64/move_inst.rs`:

```rs
use std::io::{Cursor, Seek, SeekFrom, Write};

use iced_x86::{
    BlockEncoder, BlockEncoderOptions, Code, Encoder, FlowControl, Instruction, InstructionBlock,
    MemoryOperand, Mnemonic, Register,
};

use crate::HookError;

struct JmpOffsetInfo {
    disp_offset: u64,
    relative_start_offset: u64,
    dest_addr: u64,
}

struct JmpRelocationInfo {
    offset_of_addr_to_relocate: u64,
    relative_start_offset: u64,
    is_jmp_to_new_insts: bool,
    dest_addr: u64, // index of new insts if jmps to new insts
}

struct NewInstInfo {
    offset: u64,
    reloc_info: Option<JmpRelocationInfo>,
}

pub(super) fn move_code_to_addr(
    ori_insts: &Vec<Instruction>,
    dest_addr: u64,
) -> Result<Vec<u8>, HookError> {
    if ori_insts[0].ip().abs_diff(dest_addr) < 0x7fff_f000 {
        // use iced_x86 to relocate instructions when new address is in +/- 2GB
        let block = InstructionBlock::new(ori_insts, dest_addr);
        let encoded = BlockEncoder::encode(64, block, BlockEncoderOptions::NONE)
            .map_err(|_| HookError::MoveCode)?;
        Ok(encoded.code_buffer)
    } else {
        let mut new_inst_info: Vec<NewInstInfo> = vec![];
        let mut buf = Cursor::new(Vec::<u8>::with_capacity(100));
        for inst in ori_insts {
            let cur_pos = buf.stream_position().unwrap();
            let off_info = relocate_inst_addr(inst, dest_addr + cur_pos, &mut buf)?;
            let reloc_info = if let Some(off_info) = off_info {
                let last_inst = ori_insts.last().unwrap();
                let (is_jmp_to_new_insts, dest_addr) = if off_info.dest_addr >= ori_insts[0].ip()
                    && off_info.dest_addr < last_inst.ip() + last_inst.len() as u64
                {
                    let idx = ori_insts
                        .iter()
                        .position(|i| i.ip() == off_info.dest_addr)
                        .ok_or(HookError::MovingCodeNotSupported)?;
                    (true, idx as u64)
                } else {
                    (false, off_info.dest_addr)
                };
                Some(JmpRelocationInfo {
                    offset_of_addr_to_relocate: cur_pos + off_info.disp_offset,
                    relative_start_offset: cur_pos + off_info.relative_start_offset,
                    is_jmp_to_new_insts,
                    dest_addr,
                })
            } else {
                None
            };
            new_inst_info.push(NewInstInfo {
                offset: cur_pos,
                reloc_info,
            });
        }
        let need_relocating_cnt = new_inst_info
            .iter()
            .filter(|i| i.reloc_info.is_some())
            .count();

        if need_relocating_cnt != 0 {
            // align the addresses to 8-byte
            let cur_addr = dest_addr + buf.stream_position().unwrap();
            let padding_cnt = ((cur_addr + 5 + 7) & !7) - (cur_addr + 5); // 5 bytes for jmp near below

            // jmp over the relocation address table
            let jmp_over_len = padding_cnt + need_relocating_cnt as u64 * 8;
            buf.write(&[0xe9])?;
            buf.write(&(jmp_over_len as u32).to_le_bytes())?;

            buf.write(&vec![0xCCu8; padding_cnt as usize])?;

            // write relocation table and relocate
            let mut table_offset = buf.stream_position().unwrap();
            for new_inst in &new_inst_info {
                if let Some(reloc_info) = &new_inst.reloc_info {
                    buf.seek(SeekFrom::Start(reloc_info.offset_of_addr_to_relocate))
                        .unwrap();
                    let disp = (table_offset - reloc_info.relative_start_offset) as u32;
                    buf.write(&disp.to_le_bytes()).unwrap();
                    buf.seek(SeekFrom::Start(table_offset)).unwrap();
                    if reloc_info.is_jmp_to_new_insts {
                        let real_dest_addr =
                            dest_addr + new_inst_info[reloc_info.dest_addr as usize].offset;
                        buf.write(&real_dest_addr.to_le_bytes())?;
                    } else {
                        buf.write(&reloc_info.dest_addr.to_le_bytes())?;
                    }
                    table_offset += 8;
                }
            }
        }
        Ok(buf.into_inner())
    }
}

fn relocate_inst_addr<T: Write>(
    inst: &Instruction,
    dest_addr: u64,
    buf: &mut T,
) -> Result<Option<JmpOffsetInfo>, HookError> {
    let mut encoder = Encoder::new(64);
    match inst.flow_control() {
        FlowControl::UnconditionalBranch => {
            // origin: jmp xxx
            // new: jmp qword ptr [rip+xxx]
            buf.write(&[0xff, 0x25, 0, 0, 0, 0])?;
            Ok(Some(JmpOffsetInfo {
                disp_offset: 2,
                relative_start_offset: 6,
                dest_addr: inst.near_branch_target(),
            }))
        }
        FlowControl::IndirectBranch if inst.is_ip_rel_memory_operand() => {
            // origin: jmp qword ptr [rip+xxx]
            // new:
            // mov [rsp-0x10], rax;
            // mov rax, xxx;
            // push [rax];
            // mov rax, [rsp-8];
            // ret
            buf.write(&[0x48, 0x89, 0x44, 0x24, 0xf0, 0x48, 0xb8])?;
            buf.write(&inst.ip_rel_memory_address().to_le_bytes())?;
            buf.write(&[0xff, 0x30, 0x48, 0x8b, 0x44, 0x24, 0xf8, 0xc3])?;
            Ok(None)
        }
        FlowControl::ConditionalBranch if inst.is_jcc_short_or_near() => {
            // origin: je a
            // new: jne @+6; jmp a;
            let mut new_inst = inst.clone();
            new_inst.negate_condition_code();
            new_inst.set_near_branch64(dest_addr + 8);
            new_inst.as_short_branch();
            encoder
                .encode(&new_inst, dest_addr)
                .map_err(|_| HookError::MoveCode)?;
            buf.write(&encoder.take_buffer())?;
            buf.write(&[0xff, 0x25, 0, 0, 0, 0])?;
            Ok(Some(JmpOffsetInfo {
                disp_offset: 4,
                relative_start_offset: 8,
                dest_addr: inst.near_branch_target(),
            }))
        }
        FlowControl::ConditionalBranch
            if inst.is_jcx_short() || inst.is_loop() || inst.is_loopcc() =>
        {
            // origin: jrcxz a
            // new: jrcxz @+2; jmp @+6; jmp a;
            let mut new_inst = inst.clone();
            new_inst.set_near_branch64(dest_addr + 4);
            encoder
                .encode(&new_inst, dest_addr)
                .map_err(|_| HookError::MoveCode)?;
            buf.write(&encoder.take_buffer())?;
            buf.write(&[0xeb, 0x06, 0xff, 0x25, 0, 0, 0, 0])?;
            Ok(Some(JmpOffsetInfo {
                disp_offset: 6,
                relative_start_offset: 10,
                dest_addr: inst.near_branch_target(),
            }))
        }
        FlowControl::Call if inst.is_call_near() || inst.is_call_far() => {
            // origin: call a
            // new: call qword ptr [rip+xxx]
            buf.write(&[0xff, 0x15, 0, 0, 0, 0])?;
            Ok(Some(JmpOffsetInfo {
                disp_offset: 2,
                relative_start_offset: 6,
                dest_addr: inst.near_branch_target(),
            }))
        }
        FlowControl::IndirectCall if inst.is_ip_rel_memory_operand() => {
            // origin: call qword ptr [rip+xxx]
            // new:
            // mov [rsp-0x18], rax
            // mov rax, xxx
            // push @retn_lower
            // mov dword ptr [rsp+4], @retn_higher
            // push qword ptr [rax]
            // mov rax, [rsp-8]
            // ret
            buf.write(&[0x48, 0x89, 0x44, 0x24, 0xe8, 0x48, 0xb8])?;
            buf.write(&inst.ip_rel_memory_address().to_le_bytes())?;
            let retn_addr = dest_addr + 0x24;
            buf.write(&[0x68])?;
            buf.write(&((retn_addr & 0xffffffff) as u32).to_le_bytes())?;
            buf.write(&[0xc7, 0x44, 0x24, 0x04])?;
            buf.write(&((retn_addr >> 32) as u32).to_le_bytes())?;
            buf.write(&[0xff, 0x30, 0x48, 0x8b, 0x44, 0x24, 0xf8, 0xc3])?;
            Ok(None)
        }
        _ if inst.is_ip_rel_memory_operand() => {
            if let Register::RSP = inst.op0_register() {
                // not support instructions writing rsp, like:
                // add rsp, qword ptr [rip+xxx]
                return Err(HookError::MovingCodeNotSupported);
            }
            let encoded = relocate_ip_rel_memory_inst(inst, dest_addr);
            buf.write(&encoded)?;
            Ok(None)
        }
        _ => {
            encoder.encode(inst, dest_addr).unwrap();
            buf.write(&encoder.take_buffer())?;
            Ok(None)
        }
    }
}

fn relocate_ip_rel_memory_inst(inst: &Instruction, dest_addr: u64) -> Vec<u8> {
    if let Mnemonic::Lea = inst.mnemonic() {
        // origin: lea eax, [rip+xxx]
        // new: mov eax, xxx
        let inst = Instruction::with2(
            Code::Mov_r64_imm64,
            inst.op0_register(),
            inst.ip_rel_memory_address(),
        )
        .unwrap();
        let mut encoder = Encoder::new(64);
        encoder.encode(&inst, dest_addr).unwrap();
        encoder.take_buffer()
    } else {
        // origin: add dword ptr [rip+xxx], rbx
        // new:
        // mov [rsp-0x10], r8
        // mov r8, xxx
        // add dword ptr [r8], rbx
        // mov r8, [rsp-0x10]
        let middle_register = if inst_not_use_rbx(inst) {
            Register::RBX
        } else if inst_not_use_r8(inst) {
            Register::R8
        } else {
            Register::R9 // An instruction uses rel memory operand may not use 3 registers
        };
        let new_inst1 = Instruction::with2(
            Code::Mov_rm64_r64,
            MemoryOperand::with_base_displ(Register::RSP, -16),
            middle_register,
        )
        .unwrap();
        let new_inst2 = Instruction::with2(
            Code::Mov_r64_imm64,
            middle_register,
            inst.ip_rel_memory_address(),
        )
        .unwrap();
        let mut new_inst3 = inst.clone();
        new_inst3.set_memory_base(middle_register);
        new_inst3.set_memory_displacement32(0);
        new_inst3.set_memory_displ_size(0);

        let stack_inc = inst.stack_pointer_increment() as i64;
        let new_inst4 = Instruction::with2(
            Code::Mov_r64_rm64,
            middle_register,
            MemoryOperand::with_base_displ(Register::RSP, -16 - stack_inc),
        )
        .unwrap();
        let new_insts = [new_inst1, new_inst2, new_inst3, new_inst4];
        let block = InstructionBlock::new(&new_insts, dest_addr);
        let encoded = BlockEncoder::encode(64, block, BlockEncoderOptions::NONE).unwrap();
        encoded.code_buffer
    }
}

fn inst_not_use_rbx(inst: &Instruction) -> bool {
    (0..inst.op_count()).map(|i| inst.op_register(i)).all(|r| {
        !matches!(r, Register::BL)
            && !matches!(r, Register::BH)
            && !matches!(r, Register::BX)
            && !matches!(r, Register::EBX)
            && !matches!(r, Register::RBX)
    })
}
fn inst_not_use_r8(inst: &Instruction) -> bool {
    (0..inst.op_count()).map(|i| inst.op_register(i)).all(|r| {
        !matches!(r, Register::R8D)
            && !matches!(r, Register::R8L)
            && !matches!(r, Register::R8W)
            && !matches!(r, Register::R8)
    })
}

```

`src/x64/tests.rs`:

```rs
#[allow(unused_imports)]
use super::*;

#[cfg(test)]
fn move_inst(inst: &[u8], ori_base_addr: u64, new_base_addr: u64) -> Vec<u8> {
    let mut decoder = Decoder::new(64, inst, DecoderOptions::NONE);
    decoder.set_ip(ori_base_addr);
    let insts: Vec<Instruction> = decoder.iter().collect();
    let moved = move_code_to_addr(&insts, new_base_addr);
    assert_eq!(moved.is_ok(), true);
    moved.unwrap()
}

#[test]
fn test_move_inst_short_1() {
    // jmp @+2
    let inst = [0xeb, 0x02];
    let addr = inst.as_ptr() as u64;
    let new_inst = move_inst(&inst, addr, addr + 300);
    assert_eq!(new_inst, [0xe9, 0xd3, 0xfe, 0xff, 0xff]);
}

#[test]
fn test_move_inst_short_2() {
    // call @+10
    let inst = [0xe8, 0xa, 0, 0, 0];
    let addr = inst.as_ptr() as u64;
    let new_inst = move_inst(&inst, addr, addr - 0x3333);
    assert_eq!(new_inst, [0xe8, 0x3d, 0x33, 0x0, 0x0])
}

#[test]
fn test_move_inst_short_3() {
    // mov rbx, [rip + 0x00000001]
    let inst = [0x48, 0x8b, 0x1d, 0x01, 0x00, 0x00, 0x00];
    let addr = inst.as_ptr() as u64;
    let new_inst = move_inst(&inst, addr, addr + 0x4000);
    assert_eq!(new_inst, [0x48, 0x8b, 0x1d, 0x1, 0xc0, 0xff, 0xff]);
}

#[test]
fn test_move_inst_long_1() {
    // jmp @+0
    let inst = [0xeb, 0x00];
    let addr = 0x40_0000;
    let new_inst = move_inst(&inst, addr, addr + 0x1_0000_0000);
    // jmp [rip@0x400002]
    // jmp @+13
    assert_eq!(
        new_inst,
        [
            0xff, 0x25, 0x0a, 0x00, 0x00, 0x00, 0xe9, 0x0d, 0x00, 0x00, 0x00, 0xcc, 0xcc, 0xcc,
            0xcc, 0xcc, 0x02, 0x00, 0x40, 0x00, 0x00, 0x00, 0x00, 0x00
        ]
    );
}

#[test]
fn test_move_inst_long_2() {
    // jmp qword ptr [rip@400006]
    let inst = [0xff, 0x25, 0, 0, 0, 0];
    let addr = 0x40_0000;
    let new_inst = move_inst(&inst, addr, addr + 0x1_0000_0000);
    // mov [rsp-0x10], rax;
    // mov rax, 400006;
    // push [rax];
    // mov rax, [rsp-8];
    // ret
    assert_eq!(
        new_inst,
        [
            0x48, 0x89, 0x44, 0x24, 0xf0, 0x48, 0xb8, 0x06, 0x00, 0x40, 0x00, 0x00, 0x00, 0x00,
            0x00, 0xff, 0x30, 0x48, 0x8b, 0x44, 0x24, 0xf8, 0xc3
        ]
    );
}

#[test]
fn test_move_inst_long_3() {
    // jne @+0
    let inst = [0x75, 0x00];
    let addr = 0x40_0000;
    let new_inst = move_inst(&inst, addr, addr + 0x1_0000_0000);
    // je @+6
    // jmp [rip@0x400002]
    // jmp @+11
    assert_eq!(
        new_inst,
        [
            0x74, 0x06, 0xff, 0x25, 0x08, 0x00, 0x00, 0x00, 0xe9, 0x0b, 0x00, 0x00, 0x00, 0xcc,
            0xcc, 0xcc, 0x02, 0x00, 0x40, 0x00, 0x00, 0x00, 0x00, 0x00
        ]
    );
}

#[test]
fn test_move_inst_long_4() {
    // jrcxz @+0
    let inst = [0xe3, 0x00];
    let addr = 0x40_0000;
    let new_inst = move_inst(&inst, addr, addr + 0x1_0000_0000);
    // jrcxz @+2
    // jmp @+6
    // jmp [rip@400002]
    // jmp @+9
    assert_eq!(
        new_inst,
        [
            0xe3, 0x02, 0xeb, 0x06, 0xff, 0x25, 0x06, 0x00, 0x00, 0x00, 0xe9, 0x09, 0x00, 0x00,
            0x00, 0xcc, 0x02, 0x00, 0x40, 0x00, 0x00, 0x00, 0x00, 0x00
        ]
    );
}

#[test]
fn test_move_inst_long_5() {
    // call @+0
    let inst = [0xe8, 0, 0, 0, 0];
    let addr = 0x40_0000;
    let new_inst = move_inst(&inst, addr, addr + 0x1_0000_0000);
    // call [rip@400005]
    // jmp @+13
    assert_eq!(
        new_inst,
        [
            0xff, 0x15, 0x0a, 0x00, 0x00, 0x00, 0xe9, 0x0d, 0x00, 0x00, 0x00, 0xcc, 0xcc, 0xcc,
            0xcc, 0xcc, 0x05, 0x00, 0x40, 0x00, 0x00, 0x00, 0x00, 0x00
        ]
    );
}

#[test]
fn test_move_inst_long_6() {
    // call [rip@400006]
    let inst = [0xff, 0x15, 0, 0, 0, 0];
    let addr = 0x40_0000;
    let new_inst = move_inst(&inst, addr, addr + 0x1_0000_0000);
    // mov [rsp-0x18], rax
    // mov rax, 400006
    // push 400024
    // mov dword ptr [rsp+4], 1
    // push qword ptr [rax]
    // mov rax, [rsp-8]
    // ret
    assert_eq!(
        new_inst,
        [
            0x48, 0x89, 0x44, 0x24, 0xe8, 0x48, 0xb8, 0x06, 0x00, 0x40, 0x00, 0x00, 0x00, 0x00,
            0x00, 0x68, 0x24, 0x00, 0x40, 0x00, 0xc7, 0x44, 0x24, 0x04, 0x01, 0x00, 0x00, 0x00,
            0xff, 0x30, 0x48, 0x8b, 0x44, 0x24, 0xf8, 0xc3
        ]
    );
}

#[test]
fn test_move_inst_long_7() {
    // lea r11, [rip@400007]
    let inst = [0x4c, 0x8d, 0x1d, 0, 0, 0, 0];
    let addr = 0x40_0000;
    let new_inst = move_inst(&inst, addr, addr + 0x1_0000_0000);
    // mov r11, 400007
    assert_eq!(
        new_inst,
        [0x49, 0xbb, 0x07, 0x00, 0x40, 0x00, 0x00, 0x00, 0x00, 0x00]
    );
}

#[test]
fn test_move_inst_long_8() {
    // add dword ptr [rip@400006], ebx
    let inst = [0x01, 0x1d, 0, 0, 0, 0];
    let addr = 0x40_0000;
    let new_inst = move_inst(&inst, addr, addr + 0x1_0000_0000);
    // mov [rsp-0x10], r8
    // mov r8, 400006
    // add [r8], ebx
    // mov r8, [rsp-0x10]
    assert_eq!(
        new_inst,
        [
            0x4c, 0x89, 0x44, 0x24, 0xf0, 0x49, 0xb8, 0x06, 0x00, 0x40, 0x00, 0x00, 0x00, 0x00,
            0x00, 0x41, 0x01, 0x18, 0x4c, 0x8b, 0x44, 0x24, 0xf0
        ]
    );
}

#[test]
fn test_move_inst_long_9() {
    // push qword ptr [rip@400006]
    let inst = [0xff, 0x35, 0, 0, 0, 0];
    let addr = 0x40_0000;
    let new_inst = move_inst(&inst, addr, addr + 0x1_0000_0000);
    // mov [rsp-0x10], rbx
    // mov rbx, 400006
    // push [rbx]
    // mov rbx, [rsp-8]
    assert_eq!(
        new_inst,
        [
            0x48, 0x89, 0x5c, 0x24, 0xf0, 0x48, 0xbb, 0x06, 0x00, 0x40, 0x00, 0x00, 0x00, 0x00,
            0x00, 0xff, 0x33, 0x48, 0x8b, 0x5c, 0x24, 0xf8
        ]
    );
}

#[test]
fn test_move_inst_long_all() {
    let inst = [
        0x74, 0x09, 0x48, 0x8B, 0x4D, 0x70, 0xE8, 0x72, 0x15, 0xF4, 0xFF, 0x8B, 0x1D, 0xEC, 0xFF,
        0xFF, 0xFF,
    ];
    let addr = 0x7fff_b81c_0a03;
    let new_inst = move_inst(&inst, addr, 0x400000);
    assert_eq!(
        new_inst,
        [
            0x75, 0x06, 0xff, 0x25, 0x28, 0x00, 0x00, 0x00, 0x48, 0x8b, 0x4d, 0x70, 0xff, 0x15,
            0x26, 0x00, 0x00, 0x00, 0x4c, 0x89, 0x44, 0x24, 0xf0, 0x49, 0xb8, 0x00, 0x0a, 0x1c,
            0xb8, 0xff, 0x7f, 0x00, 0x00, 0x41, 0x8b, 0x18, 0x4c, 0x8b, 0x44, 0x24, 0xf0, 0xe9,
            0x12, 0x00, 0x00, 0x00, 0xcc, 0xcc, 0x12, 0x00, 0x40, 0x00, 0x00, 0x00, 0x00, 0x00,
            0x80, 0x1f, 0x10, 0xb8, 0xff, 0x7f, 0x00, 0x00
        ]
    );
}

#[cfg(test)]
#[inline(never)]
// 5 arguments to ensure using stack instead of registers to pass parameter(s)
extern "win64" fn foo(x: u64, _: u64, _: u64, _: u64, y: u64) -> u64 {
    println!("original foo, x:{}, y:{}", x, y);
    x * x + y
}
#[cfg(test)]
unsafe extern "win64" fn new_foo(reg: *mut Registers, old_func: usize, user_data: usize) -> usize {
    let old_foo: extern "win64" fn(u64, u64, u64, u64, u64) -> u64 =
        unsafe { std::mem::transmute(old_func) };
    let arg_y = (unsafe { (*reg).rsp } + 0x28) as *const u64;
    old_foo(unsafe { (*reg).rcx }, 0, 0, 0, unsafe { *arg_y }) as usize + user_data
}
#[test]
fn test_hook_function() {
    assert_eq!(foo(5, 0, 0, 0, 3), 28);
    let hooker = Hooker::new(
        foo as usize,
        HookType::Retn(new_foo),
        CallbackOption::None,
        100,
        HookFlags::empty(),
    );
    let info = unsafe { hooker.hook().unwrap() };
    assert_eq!(foo(5, 0, 0, 0, 3), 128);
    unsafe { info.unhook().unwrap() };
    assert_eq!(foo(5, 0, 0, 0, 3), 28);
}

#[test]
fn test_hook_function_closure() {
    assert_eq!(foo(5, 0, 0, 0, 3), 28);

    let val_to_plus = 100;

    let new_foo = |reg: *mut Registers, old_func: usize| -> usize {
        let old_foo: extern "win64" fn(u64, u64, u64, u64, u64) -> u64 =
            unsafe { std::mem::transmute(old_func) };
        let arg_y = (unsafe { (*reg).rsp } + 0x28) as *const u64;
        old_foo(unsafe { (*reg).rcx }, 0, 0, 0, unsafe { *arg_y }) as usize + val_to_plus
    };

    let hook_point = unsafe {
        hook_closure_retn(foo as usize, new_foo, CallbackOption::None, HookFlags::empty())
    }.unwrap();
    assert_eq!(foo(5, 0, 0, 0, 3), 128);
    drop(hook_point);
    assert_eq!(foo(5, 0, 0, 0, 3), 28);
}
```

`src/x86.rs`:

```rs
use bitflags::bitflags;
use iced_x86::{
    BlockEncoder, BlockEncoderOptions, Decoder, DecoderOptions, Instruction, InstructionBlock,
};
use std::io::{Cursor, Seek, SeekFrom, Write};
use std::slice;

#[cfg(windows)]
use core::ffi::c_void;
#[cfg(windows)]
use windows_sys::Win32::Foundation::GetLastError;
#[cfg(windows)]
use windows_sys::Win32::System::Memory::VirtualProtect;

#[cfg(unix)]
use libc::{__errno_location, c_void, mprotect, sysconf};

use crate::err::HookError;

const MAX_INST_LEN: usize = 15;
const JMP_INST_SIZE: usize = 5;

/// This is the routine used in a `jmp-back hook`, which means the EIP will jump back to the
/// original position after the routine has finished running.
///
/// # Arguments
///
/// * `regs` - The registers
/// * `user_data` - User data that was previously passed to [`Hooker::new`].
pub type JmpBackRoutine = unsafe extern "cdecl" fn(regs: *mut Registers, user_data: usize);

/// This is the routine used in a `function hook`, which means the routine will replace the
/// original function and the EIP will `retn` directly instead of jumping back.
/// Note that the address being hooked must be the start of a function.
///
/// # Parameters
///
/// * `regs` - The registers.
/// * `ori_func_ptr` - The original function pointer. Call this after converting it to the original function type.
/// * `user_data` - User data that was previously passed to [`Hooker::new`].
///
/// # Return value
///
/// Returns the new return value of the replaced function.
pub type RetnRoutine =
    unsafe extern "cdecl" fn(regs: *mut Registers, ori_func_ptr: usize, user_data: usize) -> usize;

/// This is the routine used in a `jmp-addr hook`, which means the EIP will jump to the specified
/// address after the routine has finished running.
///
/// # Parameters
///
/// * `regs` - The registers.
/// * `ori_func_ptr` - The original function pointer. Call this after converting it to the original function type.
/// * `user_data` - User data that was previously passed to [`Hooker::new`].
pub type JmpToAddrRoutine =
    unsafe extern "cdecl" fn(regs: *mut Registers, ori_func_ptr: usize, src_addr: usize);

/// This is the routine used in a `jmp-ret hook`, which means the EIP will jump to the return
/// value of the routine.
///
/// # Parameters
///
/// * `regs` - The registers.
/// * `ori_func_ptr` - The original function pointer. Call this after converting it to the original function type.
/// * `user_data` - User data that was previously passed to [`Hooker::new`].
///
/// # Return value
///
/// Returns the address you want to jump to.
pub type JmpToRetRoutine =
    unsafe extern "cdecl" fn(regs: *mut Registers, ori_func_ptr: usize, src_addr: usize) -> usize;

/// The hooking type.
pub enum HookType {
    /// Used in a jmp-back hook
    JmpBack(JmpBackRoutine),

    /// Used in a function hook. The first element is the mnemonic of the `retn`
    /// instruction.
    Retn(usize, RetnRoutine),

    /// Used in a jmp-addr hook. The first element is the destination address
    JmpToAddr(usize, JmpToAddrRoutine),

    /// Used in a jmp-ret hook.
    JmpToRet(JmpToRetRoutine),
}

/// The common registers.
#[repr(C)]
#[derive(Debug)]
pub struct Registers {
    /// The flags register.
    pub eflags: u32,
    /// The edi register.
    pub edi: u32,
    /// The esi register.
    pub esi: u32,
    /// The ebp register.
    pub ebp: u32,
    /// The esp register.
    pub esp: u32,
    /// The ebx register.
    pub ebx: u32,
    /// The edx register.
    pub edx: u32,
    /// The ecx register.
    pub ecx: u32,
    /// The eax register.
    pub eax: u32,
}

impl Registers {
    /// Get the value by the index from register `esp`.
    ///
    /// # Parameters
    ///
    /// * cnt - The index of the arguments.
    ///
    /// # Safety
    ///
    /// Process may crash if register `esp` does not point to a valid stack.
    #[must_use]
    pub unsafe fn get_arg(&self, cnt: usize) -> u32 {
        unsafe { *((self.esp as usize + cnt * 4) as *mut u32) }
    }
}

/// The trait which is called before and after the modifying of the `jmp` instruction.
/// Usually is used to suspend and resume all other threads, to avoid instruction colliding.
pub trait ThreadCallback {
    /// the callback before modifying `jmp` instruction, should return true if success.
    fn pre(&self) -> bool;
    /// the callback after modifying `jmp` instruction
    fn post(&self);
}

/// Option for thread callback
pub enum CallbackOption {
    /// Valid callback
    Some(Box<dyn ThreadCallback>),
    /// No callback
    None,
}

bitflags! {
    /// Hook flags
    pub struct HookFlags:u32 {
        /// If set, will not modify the memory protection of the destination address
        const NOT_MODIFY_MEMORY_PROTECT = 0x1;
    }
}

/// The entry struct in ilhook.
/// Please read the main doc to view usage.
pub struct Hooker {
    addr: usize,
    hook_type: HookType,
    thread_cb: CallbackOption,
    flags: HookFlags,
    user_data: usize,
}

/// The hook result returned by `Hooker::hook`.
pub struct HookPoint {
    addr: usize,
    trampoline: Box<[u8; 100]>,
    trampoline_prot: u32,
    origin: Vec<u8>,
    thread_cb: CallbackOption,
    flags: HookFlags,
}

/// The hook result returned by [hook_closure_jmp_back], [hook_closure_retn],
/// [hook_closure_jmp_to_addr], and [hook_closure_jmp_to_ret]. This ensures
/// that the closure's lifetime lasts as long as the hook.
pub struct ClosureHookPoint<'a> {
    _inner: HookPoint,
    _callback: Box<dyn HookCallback + 'a>,
}

/// A dyn-compatible universal trait we use to be able to store all the
/// different types of closures in [ClosureHookPoint] without using generics.
trait HookCallback {}
impl<T> HookCallback for T {}

#[cfg(not(target_arch = "x86"))]
fn env_lock() {
    panic!("This crate should only be used in arch x86_32!")
}
#[cfg(target_arch = "x86")]
fn env_lock() {}

impl Hooker {
    /// Create a new Hooker.
    ///
    /// # Parameters
    ///
    /// * `addr` - The being-hooked address.
    /// * `hook_type` - The hook type and callback routine.
    /// * `thread_cb` - The callbacks before and after hooking.
    /// * `flags` - Hook flags
    #[must_use]
    pub fn new(
        addr: usize,
        hook_type: HookType,
        thread_cb: CallbackOption,
        user_data: usize,
        flags: HookFlags,
    ) -> Self {
        env_lock();
        Self {
            addr,
            hook_type,
            thread_cb,
            user_data,
            flags,
        }
    }

    /// Consumes self and execute hooking. Return the `HookPoint`.
    ///
    /// # Safety
    ///
    /// Process may crash (instead of panic!) if:
    ///
    /// 1. addr is not an accessible memory address, or is not long enough.
    /// 2. addr points to an incorrect position. (At the middle of an instruction, or where after it other instructions may jump to)
    /// 3. Wrong Retn-val if `hook_type` is `HookType::Retn`. i.e. A `cdecl` function with non-zero retn-val, or a `stdcall` function with wrong retn-val.
    /// 4. Set `NOT_MODIFY_MEMORY_PROTECT` where it should not be set.
    /// 5. hook or unhook from 2 or more threads at the same time without `HookFlags::NOT_MODIFY_MEMORY_PROTECT`. Because of memory protection colliding.
    /// 6. Other unpredictable errors.
    pub unsafe fn hook(self) -> Result<HookPoint, HookError> {
        let (moving_insts, origin) = get_moving_insts(self.addr)?;
        let trampoline =
            generate_trampoline(&self, moving_insts, origin.len() as u8, self.user_data)?;
        let trampoline_prot = modify_mem_protect(trampoline.as_ptr() as usize, trampoline.len())?;
        if !self.flags.contains(HookFlags::NOT_MODIFY_MEMORY_PROTECT) {
            let old_prot = modify_mem_protect(self.addr, JMP_INST_SIZE)?;
            let ret = modify_jmp_with_thread_cb(&self, trampoline.as_ptr() as usize);
            recover_mem_protect(self.addr, JMP_INST_SIZE, old_prot);
            ret?;
        } else {
            modify_jmp_with_thread_cb(&self, trampoline.as_ptr() as usize)?;
        }
        Ok(HookPoint {
            addr: self.addr,
            trampoline,
            trampoline_prot,
            origin,
            thread_cb: self.thread_cb,
            flags: self.flags,
        })
    }
}

/// A high-level helper for hooking a function using the [JmpBackRoutine]
/// strategy. The [callback] is called before any calls to the function at
/// [address], and then the original function is called as normal
/// afterwards.
///
/// The callback is passed [Registers] that provide access to the original
/// function's arguments.
///
/// ## Safety
///
/// See [`Hooker::hook`] for details on when this is safe to call.
pub unsafe fn hook_closure_jmp_back<'a, T: Fn(*mut Registers) + 'a>(
    address: usize,
    callback: T,
    callback_option: CallbackOption,
    hook_flags: HookFlags,
) -> Result<ClosureHookPoint<'a>, HookError> {
    let callback = Box::new(callback);
    let hooker = Hooker::new(
        address,
        HookType::JmpBack(run_jmp_back_closure::<T>),
        callback_option,
        &*callback as *const T as usize,
        hook_flags,
    );
    Ok(ClosureHookPoint {
        _inner: unsafe { hooker.hook()? },
        _callback: callback,
    })
}

/// A high-level helper for hooking a function using the [RetnRoutine]
/// strategy. All calls to the function at [address] are routed to
/// [callback] instead, and its return value is used in place of the
/// original function's return value.
///
/// The callback is passed [Registers] that provide access to the original
/// function's arguments, as well as a usize that can be cast to the
/// original function's signature using [std::mem::transmute].
///
/// The [mnemonic] is the mnemonic of the `retn` instruction.
///
/// ## Safety
///
/// See [`Hooker::hook`] for details on when this is safe to call.
pub unsafe fn hook_closure_retn<'a, T: (Fn(*mut Registers, usize) -> usize) + 'a>(
    address: usize,
    mnemonic: usize,
    callback: T,
    callback_option: CallbackOption,
    hook_flags: HookFlags,
) -> Result<ClosureHookPoint<'a>, HookError> {
    let callback = Box::new(callback);
    let hooker = Hooker::new(
        address,
        HookType::Retn(mnemonic, run_retn_closure::<T>),
        callback_option,
        &*callback as *const T as usize,
        hook_flags,
    );
    Ok(ClosureHookPoint {
        _inner: unsafe { hooker.hook()? },
        _callback: callback,
    })
}

/// A high-level helper for hooking a function using the [JmpToAddrRoutine]
/// strategy. All calls to the function at [address] are routed to
/// [callback] instead, then the function at [follow_up] is called and its
/// return value is used in place of the original function's.
///
/// The callback is passed [Registers] that provide access to the original
/// function's arguments, as well as a usize that can be cast to the
/// original function's signature using [std::mem::transmute].
///
/// ## Safety
///
/// See [`Hooker::hook`] for details on when this is safe to call.
pub unsafe fn hook_closure_jmp_to_addr<'a, T: Fn(*mut Registers, usize) + 'a>(
    address: usize,
    follow_up: usize,
    callback: T,
    callback_option: CallbackOption,
    hook_flags: HookFlags,
) -> Result<ClosureHookPoint<'a>, HookError> {
    let callback = Box::new(callback);
    let hooker = Hooker::new(
        address,
        HookType::JmpToAddr(follow_up, run_jmp_to_addr_closure::<T>),
        callback_option,
        &*callback as *const T as usize,
        hook_flags,
    );
    Ok(ClosureHookPoint {
        _inner: unsafe { hooker.hook()? },
        _callback: callback,
    })
}

/// A high-level helper for hooking a function using the [JmpToRetRoutine]
/// strategy. All calls to the function at [address] are routed to
/// [callback] instead, then the function at the addressed returned by
/// [callback] is called and its return value is used in place of the
/// original function's
///
/// The callback is passed [Registers] that provide access to the original
/// function's arguments, as well as a usize that can be cast to the
/// original function's signature using [std::mem::transmute].
///
/// ## Safety
///
/// See [`Hooker::hook`] for details on when this is safe to call.
pub unsafe fn hook_closure_jmp_to_ret<'a, T: (Fn(*mut Registers, usize) -> usize) + 'a>(
    address: usize,
    callback: T,
    callback_option: CallbackOption,
    hook_flags: HookFlags,
) -> Result<ClosureHookPoint<'a>, HookError> {
    let callback = Box::new(callback);
    let hooker = Hooker::new(
        address,
        HookType::JmpToRet(run_retn_closure::<T>),
        callback_option,
        &*callback as *const T as usize,
        hook_flags,
    );
    Ok(ClosureHookPoint {
        _inner: unsafe { hooker.hook()? },
        _callback: callback,
    })
}

/// The userdata trampoline for [Hooker::hook_closure_jmp_back].
unsafe extern "cdecl" fn run_jmp_back_closure<T: Fn(*mut Registers)>(
    reg: *mut Registers,
    callback: usize,
) {
    unsafe { (*(callback as *const T))(reg) };
}

/// The userdata trampoline for [Hooker::hook_closure_retn] *and*
/// [Hooker::hook_closure_jmp_to_ret].
unsafe extern "cdecl" fn run_retn_closure<T: Fn(*mut Registers, usize) -> usize>(
    reg: *mut Registers,
    original: usize,
    callback: usize,
) -> usize {
    unsafe { (*(callback as *const T))(reg, original) }
}

/// The userdata trampoline for [Hooker::hook_closure_jmp_to_addr].
unsafe extern "cdecl" fn run_jmp_to_addr_closure<T: Fn(*mut Registers, usize)>(
    reg: *mut Registers,
    original: usize,
    callback: usize,
) {
    unsafe { (*(callback as *const T))(reg, original) };
}

impl HookPoint {
    /// Consume self and unhook the address.
    pub unsafe fn unhook(self) -> Result<(), HookError> {
        self.unhook_by_ref()
    }

    fn unhook_by_ref(&self) -> Result<(), HookError> {
        let ret: Result<(), HookError>;
        if !self.flags.contains(HookFlags::NOT_MODIFY_MEMORY_PROTECT) {
            let old_prot = modify_mem_protect(self.addr, JMP_INST_SIZE)?;
            ret = recover_jmp_with_thread_cb(self);
            recover_mem_protect(self.addr, JMP_INST_SIZE, old_prot);
        } else {
            ret = recover_jmp_with_thread_cb(self)
        }
        recover_mem_protect(
            self.trampoline.as_ptr() as usize,
            self.trampoline.len(),
            self.trampoline_prot,
        );
        ret
    }
}

// When the HookPoint drops, it should unhook automatically.
impl Drop for HookPoint {
    fn drop(&mut self) {
        self.unhook_by_ref().unwrap_or_default();
    }
}

fn get_moving_insts(addr: usize) -> Result<(Vec<Instruction>, Vec<u8>), HookError> {
    let code_slice =
        unsafe { slice::from_raw_parts(addr as *const u8, MAX_INST_LEN * JMP_INST_SIZE) };
    let mut decoder = Decoder::new(32, code_slice, DecoderOptions::NONE);
    decoder.set_ip(addr as u64);

    let mut total_bytes = 0;
    let mut ori_insts: Vec<Instruction> = vec![];
    for inst in &mut decoder {
        if inst.is_invalid() {
            return Err(HookError::Disassemble);
        }
        ori_insts.push(inst);
        total_bytes += inst.len();
        if total_bytes >= JMP_INST_SIZE {
            break;
        }
    }

    Ok((ori_insts, code_slice[0..decoder.position()].into()))
}

#[cfg(windows)]
fn modify_mem_protect(addr: usize, len: usize) -> Result<u32, HookError> {
    let mut old_prot: u32 = 0;
    let old_prot_ptr = std::ptr::addr_of_mut!(old_prot);
    // PAGE_EXECUTE_READWRITE = 0x40
    let ret = unsafe { VirtualProtect(addr as *const c_void, len, 0x40, old_prot_ptr) };
    if ret == 0 {
        Err(HookError::MemoryProtect(unsafe { GetLastError() }))
    } else {
        Ok(old_prot)
    }
}

#[cfg(unix)]
fn modify_mem_protect(addr: usize, len: usize) -> Result<u32, HookError> {
    let page_size = unsafe { sysconf(30) }; //_SC_PAGESIZE == 30
    if len > page_size.try_into().unwrap() {
        Err(HookError::InvalidParameter)
    } else {
        //(PROT_READ | PROT_WRITE | PROT_EXEC) == 7
        let ret = unsafe {
            mprotect(
                (addr & !(page_size as usize - 1)) as *mut c_void,
                page_size as usize,
                7,
            )
        };
        if ret != 0 {
            let err = unsafe { *(__errno_location()) };
            Err(HookError::MemoryProtect(err as u32))
        } else {
            // it's too complex to get the original memory protection
            Ok(7)
        }
    }
}

#[cfg(windows)]
fn recover_mem_protect(addr: usize, len: usize, old: u32) {
    let mut old_prot: u32 = 0;
    let old_prot_ptr = std::ptr::addr_of_mut!(old_prot);
    unsafe { VirtualProtect(addr as *const c_void, len, old, old_prot_ptr) };
}

#[cfg(unix)]
fn recover_mem_protect(addr: usize, _: usize, old: u32) {
    let page_size = unsafe { sysconf(30) }; //_SC_PAGESIZE == 30
    unsafe {
        mprotect(
            (addr & !(page_size as usize - 1)) as *mut c_void,
            page_size as usize,
            old as i32,
        )
    };
}

fn write_relative_off<T: Write + Seek>(
    buf: &mut T,
    base_addr: u32,
    dst_addr: u32,
) -> Result<(), HookError> {
    let dst_addr = dst_addr as i32;
    let cur_pos = buf.stream_position().unwrap() as i32;
    let call_off = dst_addr - (base_addr as i32 + cur_pos + 4);
    buf.write(&call_off.to_le_bytes())?;
    Ok(())
}

fn move_code_to_addr(ori_insts: &Vec<Instruction>, dest_addr: u32) -> Result<Vec<u8>, HookError> {
    let block = InstructionBlock::new(ori_insts, u64::from(dest_addr));
    let encoded = BlockEncoder::encode(32, block, BlockEncoderOptions::NONE)
        .map_err(|_| HookError::MoveCode)?;
    Ok(encoded.code_buffer)
}

fn write_ori_func_addr<T: Write + Seek>(buf: &mut T, ori_func_addr_off: u32, ori_func_off: u32) {
    let pos = buf.stream_position().unwrap();
    buf.seek(SeekFrom::Start(u64::from(ori_func_addr_off)))
        .unwrap();
    buf.write(&ori_func_off.to_le_bytes()).unwrap();
    buf.seek(SeekFrom::Start(pos)).unwrap();
}

fn generate_jmp_back_trampoline<T: Write + Seek>(
    buf: &mut T,
    trampoline_base_addr: u32,
    moving_code: &Vec<Instruction>,
    ori_addr: u32,
    cb: JmpBackRoutine,
    ori_len: u8,
    user_data: usize,
) -> Result<(), HookError> {
    // push user_data
    buf.write(&[0x68])?;
    buf.write(&user_data.to_le_bytes())?;

    // push ebp (Registers)
    // call XXXX (dest addr)
    buf.write(&[0x55, 0xe8])?;
    write_relative_off(buf, trampoline_base_addr, cb as u32)?;

    // add esp, 0x8
    buf.write(&[0x83, 0xc4, 0x08])?;
    // popfd
    // popad
    buf.write(&[0x9d, 0x61])?;

    let cur_pos = buf.stream_position().unwrap() as u32;
    buf.write(&move_code_to_addr(
        moving_code,
        trampoline_base_addr + cur_pos,
    )?)?;
    // jmp back
    buf.write(&[0xe9])?;
    write_relative_off(buf, trampoline_base_addr, ori_addr + u32::from(ori_len))
}

fn generate_retn_trampoline<T: Write + Seek>(
    buf: &mut T,
    trampoline_base_addr: u32,
    moving_code: &Vec<Instruction>,
    ori_addr: u32,
    retn_val: u16,
    cb: RetnRoutine,
    ori_len: u8,
    user_data: usize,
) -> Result<(), HookError> {
    // push user_data
    buf.write(&[0x68])?;
    buf.write(&user_data.to_le_bytes())?;

    // push XXXX (original function addr)
    // push ebp (Registers)
    // call XXXX (dest addr)
    let ori_func_addr_off = buf.stream_position().unwrap() + 1;
    buf.write(&[0x68, 0, 0, 0, 0, 0x55, 0xe8])?;
    write_relative_off(buf, trampoline_base_addr, cb as u32)?;

    // add esp, 0xc
    buf.write(&[0x83, 0xc4, 0x0c])?;
    // mov [esp+20h], eax
    buf.write(&[0x89, 0x44, 0x24, 0x20])?;
    // popfd
    // popad
    buf.write(&[0x9d, 0x61])?;
    if retn_val == 0 {
        // retn
        buf.write(&[0xc3])?;
    } else {
        // retn XX
        buf.write(&[0xc2])?;
        buf.write(&retn_val.to_le_bytes())?;
    }
    let ori_func_off = buf.stream_position().unwrap() as u32;
    write_ori_func_addr(
        buf,
        ori_func_addr_off as u32,
        trampoline_base_addr + ori_func_off,
    );

    let cur_pos = buf.stream_position().unwrap() as u32;
    buf.write(&move_code_to_addr(
        moving_code,
        trampoline_base_addr + cur_pos,
    )?)?;

    // jmp ori_addr
    buf.write(&[0xe9])?;
    write_relative_off(buf, trampoline_base_addr, ori_addr + u32::from(ori_len))
}

fn generate_jmp_addr_trampoline<T: Write + Seek>(
    buf: &mut T,
    trampoline_base_addr: u32,
    moving_code: &Vec<Instruction>,
    ori_addr: u32,
    dest_addr: u32,
    cb: JmpToAddrRoutine,
    ori_len: u8,
    user_data: usize,
) -> Result<(), HookError> {
    // push user_data
    buf.write(&[0x68])?;
    buf.write(&user_data.to_le_bytes())?;

    // push XXXX (original function addr)
    // push ebp (Registers)
    // call XXXX (dest addr)
    let ori_func_addr_off = buf.stream_position().unwrap() + 1;
    buf.write(&[0x68, 0, 0, 0, 0, 0x55, 0xe8])?;
    write_relative_off(buf, trampoline_base_addr, cb as u32)?;

    // add esp, 0xc
    buf.write(&[0x83, 0xc4, 0x0c])?;
    // popfd
    // popad
    buf.write(&[0x9d, 0x61])?;
    // jmp back
    buf.write(&[0xe9])?;
    write_relative_off(buf, trampoline_base_addr, dest_addr + u32::from(ori_len))?;

    let ori_func_off = buf.stream_position().unwrap() as u32;
    write_ori_func_addr(
        buf,
        ori_func_addr_off as u32,
        trampoline_base_addr + ori_func_off,
    );

    let cur_pos = buf.stream_position().unwrap() as u32;
    buf.write(&move_code_to_addr(
        moving_code,
        trampoline_base_addr + cur_pos,
    )?)?;

    // jmp ori_addr
    buf.write(&[0xe9])?;
    write_relative_off(buf, trampoline_base_addr, ori_addr + u32::from(ori_len))
}

fn generate_jmp_ret_trampoline<T: Write + Seek>(
    buf: &mut T,
    trampoline_base_addr: u32,
    moving_code: &Vec<Instruction>,
    ori_addr: u32,
    cb: JmpToRetRoutine,
    ori_len: u8,
    user_data: usize,
) -> Result<(), HookError> {
    // push user_data
    buf.write(&[0x68])?;
    buf.write(&user_data.to_le_bytes())?;

    // push XXXX (original function addr)
    // push ebp (Registers)
    // call XXXX (dest addr)
    let ori_func_addr_off = buf.stream_position().unwrap() + 1;
    buf.write(&[0x68, 0, 0, 0, 0, 0x55, 0xe8])?;
    write_relative_off(buf, trampoline_base_addr, cb as u32)?;

    // add esp, 0xc
    buf.write(&[0x83, 0xc4, 0x0c])?;
    // mov [esp-4], eax
    buf.write(&[0x89, 0x44, 0x24, 0xfc])?;
    // popfd
    // popad
    buf.write(&[0x9d, 0x61])?;
    // jmp dword ptr [esp-0x28]
    buf.write(&[0xff, 0x64, 0x24, 0xd8])?;

    let ori_func_off = buf.stream_position().unwrap() as u32;
    write_ori_func_addr(
        buf,
        ori_func_addr_off as u32,
        trampoline_base_addr + ori_func_off,
    );

    let cur_pos = buf.stream_position().unwrap() as u32;
    buf.write(&move_code_to_addr(
        moving_code,
        trampoline_base_addr + cur_pos,
    )?)?;

    // jmp ori_addr
    buf.write(&[0xe9])?;
    write_relative_off(buf, trampoline_base_addr, ori_addr + u32::from(ori_len))
}

fn generate_trampoline(
    hooker: &Hooker,
    moving_code: Vec<Instruction>,
    ori_len: u8,
    user_data: usize,
) -> Result<Box<[u8; 100]>, HookError> {
    let mut raw_buffer = Box::new([0u8; 100]);
    let trampoline_addr = raw_buffer.as_ptr() as u32;
    let mut buf = Cursor::new(&mut raw_buffer[..]);

    // pushad
    // pushfd
    // mov ebp, esp
    buf.write(&[0x60, 0x9c, 0x8b, 0xec])?;

    match hooker.hook_type {
        HookType::JmpBack(cb) => generate_jmp_back_trampoline(
            &mut buf,
            trampoline_addr,
            &moving_code,
            hooker.addr as u32,
            cb,
            ori_len,
            user_data,
        ),
        HookType::Retn(val, cb) => generate_retn_trampoline(
            &mut buf,
            trampoline_addr,
            &moving_code,
            hooker.addr as u32,
            val as u16,
            cb,
            ori_len,
            user_data,
        ),
        HookType::JmpToAddr(dest, cb) => generate_jmp_addr_trampoline(
            &mut buf,
            trampoline_addr,
            &moving_code,
            hooker.addr as u32,
            dest as u32,
            cb,
            ori_len,
            user_data,
        ),
        HookType::JmpToRet(cb) => generate_jmp_ret_trampoline(
            &mut buf,
            trampoline_addr,
            &moving_code,
            hooker.addr as u32,
            cb,
            ori_len,
            user_data,
        ),
    }?;

    Ok(raw_buffer)
}

fn modify_jmp(dest_addr: usize, trampoline_addr: usize) -> Result<(), HookError> {
    let buf = unsafe { slice::from_raw_parts_mut(dest_addr as *mut u8, JMP_INST_SIZE) };
    // jmp trampoline_addr
    buf[0] = 0xe9;
    let rel_off = trampoline_addr as i32 - (dest_addr as i32 + 5);
    buf[1..5].copy_from_slice(&rel_off.to_le_bytes());
    Ok(())
}

fn modify_jmp_with_thread_cb(hook: &Hooker, trampoline_addr: usize) -> Result<(), HookError> {
    if let CallbackOption::Some(cbs) = &hook.thread_cb {
        if !cbs.pre() {
            return Err(HookError::PreHook);
        }
        let ret = modify_jmp(hook.addr, trampoline_addr);
        cbs.post();
        ret
    } else {
        modify_jmp(hook.addr, trampoline_addr)
    }
}

fn recover_jmp(dest_addr: usize, origin: &[u8]) {
    let buf = unsafe { slice::from_raw_parts_mut(dest_addr as *mut u8, origin.len()) };
    // jmp trampoline_addr
    buf.copy_from_slice(origin);
}

fn recover_jmp_with_thread_cb(hook: &HookPoint) -> Result<(), HookError> {
    if let CallbackOption::Some(cbs) = &hook.thread_cb {
        if !cbs.pre() {
            return Err(HookError::PreHook);
        }
        recover_jmp(hook.addr, &hook.origin);
        cbs.post();
    } else {
        recover_jmp(hook.addr, &hook.origin);
    }
    Ok(())
}

#[cfg(target_arch = "x86")]
mod tests {
    #[allow(unused_imports)]
    use super::*;

    #[cfg(test)]
    #[inline(never)]
    fn foo(x: u32) -> u32 {
        println!("original foo, x:{}", x);
        x * x
    }
    #[cfg(test)]
    unsafe extern "cdecl" fn on_foo(
        reg: *mut Registers,
        old_func: usize,
        user_data: usize,
    ) -> usize {
        let old_func = std::mem::transmute::<usize, fn(u32) -> u32>(old_func);
        old_func((*reg).get_arg(1)) as usize + user_data
    }

    #[test]
    fn test_hook_function_cdecl() {
        assert_eq!(foo(5), 25);
        let hooker = Hooker::new(
            foo as usize,
            HookType::Retn(0, on_foo),
            CallbackOption::None,
            100,
            HookFlags::empty(),
        );
        let info = unsafe { hooker.hook().unwrap() };
        assert_eq!(foo(5), 125);
        unsafe { info.unhook().unwrap() };
        assert_eq!(foo(5), 25);
    }

    #[cfg(test)]
    #[inline(never)]
    extern "stdcall" fn foo2(x: u32) -> u32 {
        println!("original foo, x:{}", x);
        x * x
    }
    #[cfg(test)]
    unsafe extern "cdecl" fn on_foo2(
        reg: *mut Registers,
        old_func: usize,
        user_data: usize,
    ) -> usize {
        let old_func = std::mem::transmute::<usize, extern "stdcall" fn(u32) -> u32>(old_func);
        old_func((*reg).get_arg(1)) as usize + user_data
    }
    #[test]
    fn test_hook_function_stdcall() {
        assert_eq!(foo2(5), 25);
        let hooker = Hooker::new(
            foo2 as usize,
            HookType::Retn(4, on_foo2),
            CallbackOption::None,
            100,
            HookFlags::empty(),
        );
        let info = unsafe { hooker.hook().unwrap() };
        assert_eq!(foo2(5), 125);
        unsafe { info.unhook().unwrap() };
        assert_eq!(foo2(5), 25);
    }

    #[test]
    fn test_hook_function_cdecl_closure() {
        assert_eq!(foo(5), 25);
        let val_to_plus = 100;
        let new_foo = |reg: *mut Registers, old_func: usize| -> usize {
            let old_foo: fn(u32) -> u32 = unsafe { std::mem::transmute(old_func) };
            old_foo(unsafe { (*reg).get_arg(1) }) as usize + val_to_plus
        };
        let hook_point = unsafe {
            hook_closure_retn(foo as usize, 0, new_foo, CallbackOption::None, HookFlags::empty())
        }.unwrap();
        assert_eq!(foo(5), 125);
        drop(hook_point);
        assert_eq!(foo(5), 25);
    }
}

```