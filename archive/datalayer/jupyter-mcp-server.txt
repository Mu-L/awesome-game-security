Project Path: arc_datalayer_jupyter-mcp-server_pjsr4k60

Source Tree:

```txt
arc_datalayer_jupyter-mcp-server_pjsr4k60
â”œâ”€â”€ .dockerignore
â”œâ”€â”€ .github
â”‚   â”œâ”€â”€ copilot-instructions.md
â”‚   â”œâ”€â”€ dependabot.yml
â”‚   â””â”€â”€ workflows
â”‚       â”œâ”€â”€ build.yml
â”‚       â”œâ”€â”€ fix-license-header.yml
â”‚       â”œâ”€â”€ lint.sh
â”‚       â”œâ”€â”€ release.yml
â”‚       â””â”€â”€ test.yml
â”œâ”€â”€ .gitignore
â”œâ”€â”€ ARCHITECTURE.md
â”œâ”€â”€ CODE_OF_CONDUCT.md
â”œâ”€â”€ CONTRIBUTING.md
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ LICENSE
â”œâ”€â”€ Makefile
â”œâ”€â”€ README.md
â”œâ”€â”€ RELEASE.md
â”œâ”€â”€ dev
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ content
â”‚       â”œâ”€â”€ README.md
â”‚       â”œâ”€â”€ new.ipynb
â”‚       â””â”€â”€ notebook.ipynb
â”œâ”€â”€ docs
â”‚   â”œâ”€â”€ .gitignore
â”‚   â”œâ”€â”€ .yarnrc.yml
â”‚   â”œâ”€â”€ LICENSE
â”‚   â”œâ”€â”€ Makefile
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ babel.config.js
â”‚   â”œâ”€â”€ docs
â”‚   â”‚   â”œâ”€â”€ _category_.yaml
â”‚   â”‚   â”œâ”€â”€ clients
â”‚   â”‚   â”‚   â”œâ”€â”€ _category_.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ claude_desktop
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ _category_.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ index.mdx
â”‚   â”‚   â”‚   â”œâ”€â”€ cline
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ _category_.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ index.mdx
â”‚   â”‚   â”‚   â”œâ”€â”€ cursor
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ _category_.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ index.mdx
â”‚   â”‚   â”‚   â”œâ”€â”€ index.mdx
â”‚   â”‚   â”‚   â”œâ”€â”€ vscode
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ _category_.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ index.mdx
â”‚   â”‚   â”‚   â””â”€â”€ windsurf
â”‚   â”‚   â”‚       â”œâ”€â”€ _category_.yaml
â”‚   â”‚   â”‚       â””â”€â”€ index.mdx
â”‚   â”‚   â”œâ”€â”€ community
â”‚   â”‚   â”‚   â”œâ”€â”€ _category_.yaml
â”‚   â”‚   â”‚   â””â”€â”€ community.mdx
â”‚   â”‚   â”œâ”€â”€ getting_started
â”‚   â”‚   â”‚   â”œâ”€â”€ _category_.yaml
â”‚   â”‚   â”‚   â””â”€â”€ index.mdx
â”‚   â”‚   â”œâ”€â”€ index.mdx
â”‚   â”‚   â”œâ”€â”€ providers
â”‚   â”‚   â”‚   â”œâ”€â”€ _category_.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ datalayer
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ _category_.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ index.mdx
â”‚   â”‚   â”‚   â”œâ”€â”€ google-colab
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ _category_.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ index.mdx
â”‚   â”‚   â”‚   â”œâ”€â”€ jupyter-stdio
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ _category_.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ index.mdx
â”‚   â”‚   â”‚   â”œâ”€â”€ jupyter-streamable-http-extension
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ _category_.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ index.mdx
â”‚   â”‚   â”‚   â”œâ”€â”€ jupyter-streamable-http-standalone
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ _category_.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ index.mdx
â”‚   â”‚   â”‚   â””â”€â”€ jupyterhub-streamable-http
â”‚   â”‚   â”‚       â”œâ”€â”€ _category_.yaml
â”‚   â”‚   â”‚       â””â”€â”€ index.mdx
â”‚   â”‚   â”œâ”€â”€ reference
â”‚   â”‚   â”‚   â”œâ”€â”€ _category_.yaml
â”‚   â”‚   â”‚   â”œâ”€â”€ configuration
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ _category_.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ index.mdx
â”‚   â”‚   â”‚   â”œâ”€â”€ multi-users
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ _category_.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ index.mdx
â”‚   â”‚   â”‚   â”œâ”€â”€ prompts
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ _category_.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ index.mdx
â”‚   â”‚   â”‚   â”œâ”€â”€ security
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ _category_.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ index.mdx
â”‚   â”‚   â”‚   â”œâ”€â”€ tools
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ _category_.yaml
â”‚   â”‚   â”‚   â”‚   â””â”€â”€ index.mdx
â”‚   â”‚   â”‚   â””â”€â”€ tools-additional
â”‚   â”‚   â”‚       â”œâ”€â”€ _category_.yaml
â”‚   â”‚   â”‚       â””â”€â”€ index.mdx
â”‚   â”‚   â”œâ”€â”€ releases
â”‚   â”‚   â”‚   â”œâ”€â”€ _category_.yaml
â”‚   â”‚   â”‚   â””â”€â”€ index.mdx
â”‚   â”‚   â””â”€â”€ resources
â”‚   â”‚       â”œâ”€â”€ _category_.yaml
â”‚   â”‚       â””â”€â”€ index.mdx
â”‚   â”œâ”€â”€ docusaurus.config.js
â”‚   â”œâ”€â”€ package.json
â”‚   â”œâ”€â”€ sidebars.js
â”‚   â”œâ”€â”€ src
â”‚   â”‚   â”œâ”€â”€ components
â”‚   â”‚   â”‚   â”œâ”€â”€ HomepageFeatures.js
â”‚   â”‚   â”‚   â”œâ”€â”€ HomepageFeatures.module.css
â”‚   â”‚   â”‚   â”œâ”€â”€ HomepageProducts.js
â”‚   â”‚   â”‚   â””â”€â”€ HomepageProducts.module.css
â”‚   â”‚   â”œâ”€â”€ css
â”‚   â”‚   â”‚   â””â”€â”€ custom.css
â”‚   â”‚   â”œâ”€â”€ pages
â”‚   â”‚   â”‚   â”œâ”€â”€ index.module.css
â”‚   â”‚   â”‚   â”œâ”€â”€ markdown-page.md
â”‚   â”‚   â”‚   â””â”€â”€ testimonials.tsx
â”‚   â”‚   â””â”€â”€ theme
â”‚   â”‚       â””â”€â”€ CustomDocItem.tsx
â”‚   â””â”€â”€ static
â”‚       â””â”€â”€ img
â”‚           â”œâ”€â”€ datalayer
â”‚           â”‚   â”œâ”€â”€ logo.png
â”‚           â”‚   â””â”€â”€ logo.svg
â”‚           â”œâ”€â”€ favicon.ico
â”‚           â”œâ”€â”€ feature_1.svg
â”‚           â”œâ”€â”€ feature_2.svg
â”‚           â”œâ”€â”€ feature_3.svg
â”‚           â”œâ”€â”€ product_1.svg
â”‚           â”œâ”€â”€ product_2.svg
â”‚           â””â”€â”€ product_3.svg
â”œâ”€â”€ jupyter-config
â”‚   â”œâ”€â”€ jupyter_notebook_config
â”‚   â”‚   â””â”€â”€ jupyter_mcp_server.json
â”‚   â””â”€â”€ jupyter_server_config.d
â”‚       â””â”€â”€ jupyter_mcp_server.json
â”œâ”€â”€ jupyter_mcp_server
â”‚   â”œâ”€â”€ CLI.py
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ __main__.py
â”‚   â”œâ”€â”€ __version__.py
â”‚   â”œâ”€â”€ config.py
â”‚   â”œâ”€â”€ enroll.py
â”‚   â”œâ”€â”€ jupyter_extension
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ backends
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”‚   â”œâ”€â”€ local_backend.py
â”‚   â”‚   â”‚   â””â”€â”€ remote_backend.py
â”‚   â”‚   â”œâ”€â”€ context.py
â”‚   â”‚   â”œâ”€â”€ extension.py
â”‚   â”‚   â”œâ”€â”€ handlers.py
â”‚   â”‚   â””â”€â”€ protocol
â”‚   â”‚       â”œâ”€â”€ __init__.py
â”‚   â”‚       â””â”€â”€ messages.py
â”‚   â”œâ”€â”€ log.py
â”‚   â”œâ”€â”€ models.py
â”‚   â”œâ”€â”€ notebook_manager.py
â”‚   â”œâ”€â”€ server.py
â”‚   â”œâ”€â”€ server_context.py
â”‚   â”œâ”€â”€ server_modes.py
â”‚   â”œâ”€â”€ tool_cache.py
â”‚   â”œâ”€â”€ tools
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ _base.py
â”‚   â”‚   â”œâ”€â”€ connect_jupyter_tool.py
â”‚   â”‚   â”œâ”€â”€ delete_cell_tool.py
â”‚   â”‚   â”œâ”€â”€ execute_cell_tool.py
â”‚   â”‚   â”œâ”€â”€ execute_code_tool.py
â”‚   â”‚   â”œâ”€â”€ insert_cell_tool.py
â”‚   â”‚   â”œâ”€â”€ jupyter_cite_prompt.py
â”‚   â”‚   â”œâ”€â”€ list_files_tool.py
â”‚   â”‚   â”œâ”€â”€ list_kernels_tool.py
â”‚   â”‚   â”œâ”€â”€ list_notebooks_tool.py
â”‚   â”‚   â”œâ”€â”€ overwrite_cell_source_tool.py
â”‚   â”‚   â”œâ”€â”€ read_cell_tool.py
â”‚   â”‚   â”œâ”€â”€ read_notebook_tool.py
â”‚   â”‚   â”œâ”€â”€ restart_notebook_tool.py
â”‚   â”‚   â”œâ”€â”€ unuse_notebook_tool.py
â”‚   â”‚   â””â”€â”€ use_notebook_tool.py
â”‚   â””â”€â”€ utils.py
â”œâ”€â”€ mcpb
â”‚   â”œâ”€â”€ .mcpbignore
â”‚   â”œâ”€â”€ README.md
â”‚   â”œâ”€â”€ manifest.json
â”‚   â”œâ”€â”€ pyproject.toml
â”‚   â””â”€â”€ src
â”‚       â””â”€â”€ server.py
â”œâ”€â”€ prompt
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ general
â”‚       â”œâ”€â”€ AGENT.md
â”‚       â””â”€â”€ README.md
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ pytest.ini
â”œâ”€â”€ smithery.yaml
â””â”€â”€ tests
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ conftest.py
    â”œâ”€â”€ test_common.py
    â”œâ”€â”€ test_config.py
    â”œâ”€â”€ test_jupyter_extension.py
    â”œâ”€â”€ test_prompts.py
    â””â”€â”€ test_tools.py

```

`.dockerignore`:

```
__pycache__
*.pyc
*.pyo
*.pyd
.Python
env
pip-log.txt
pip-delete-this-directory.txt
.tox
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.log
.git
.github
.mypy_cache
.pytest_cache
dev
docs
```

`.github/copilot-instructions.md`:

```md
# Jupyter MCP Server

**Always reference these instructions first and fallback to search or bash commands only when you encounter unexpected information that does not match the info here.**

Jupyter MCP Server is a Python-based Model Context Protocol (MCP) server implementation that enables real-time interaction with Jupyter Notebooks. The project uses a modern Python build system with hatch, and includes comprehensive testing, linting, and documentation.

## Working Effectively

### Environment Setup
- **Python Requirements**: Python 3.10 or higher (tested with 3.9-3.13)
- **Network Considerations**: PyPI installs may fail due to SSL certificate issues or timeout limitations. This is a known environment constraint.

### Build and Install (CRITICAL: Network Limitations)
```bash
# Standard installation (may fail with network issues)
pip install ".[test,lint,typing]"

# Alternative if pip install fails:
# 1. Install dependencies individually with longer timeouts
pip install --timeout=300 pytest
pip install --timeout=300 ruff  
pip install --timeout=300 mypy

# 2. Or use Docker approach (preferred for consistency)
docker build -t jupyter-mcp-server .
```

**NETWORK TIMEOUT WARNING**: pip install commands may fail with SSL certificate errors or read timeouts when connecting to PyPI. If installs fail:
- Try increasing timeout: `pip install --timeout=300`
- Use Docker build which handles dependencies internally
- Document the network limitation in any testing notes

### Core Development Commands
```bash
# Development installation (when network allows)
make dev
# Equivalent to: pip install ".[test,lint,typing]"

# Basic installation  
make install
# Equivalent to: pip install .

# Build the package
make build
# Equivalent to: pip install build && python -m build .
```

### Testing (CRITICAL: Use Long Timeouts)
```bash
# Run tests using hatch (when available)
make test
# Equivalent to: hatch test

# Run tests directly with pytest (when network allows install)
pytest .

# NEVER CANCEL: Test suite timing expectations
# - Full test suite: Allow 15-20 minutes minimum
# - Network-dependent tests may take longer
# - Set timeout to 30+ minutes for safety
```

**VALIDATION REQUIREMENT**: When testing is not possible due to network issues, verify at minimum:
```bash
# Syntax validation (always works)
python -m py_compile jupyter_mcp_server/server.py
find . -name "*.py" -exec python -m py_compile {} \;

# Import validation
PYTHONPATH=. python -c "import jupyter_mcp_server; print('Import successful')"
```

### Linting and Code Quality (CRITICAL: Use Long Timeouts)
```bash
# Full linting pipeline (when network allows)
bash ./.github/workflows/lint.sh

# Individual linting commands:
pip install -e ".[lint,typing]"
mypy --install-types --non-interactive .  # May take 10+ minutes, NEVER CANCEL
ruff check .                              # Quick, usually <1 minute  
mdformat --check *.md                     # Quick, usually <1 minute
pipx run 'validate-pyproject[all]' pyproject.toml  # 2-3 minutes

# TIMING WARNING: mypy type checking can take 10+ minutes on first run
# Set timeout to 20+ minutes for mypy operations
```

### Running the Application

#### Local Development Mode
```bash
# Start with streamable HTTP transport
make start
# Equivalent to:
jupyter-mcp-server start \
  --transport streamable-http \
  --document-url http://localhost:8888 \
  --document-id notebook.ipynb \
  --document-token MY_TOKEN \
  --runtime-url http://localhost:8888 \
  --start-new-runtime true \
  --runtime-token MY_TOKEN \
  --port 4040
```

#### JupyterLab Setup (Required for Testing)
```bash
# Start JupyterLab server for MCP integration
make jupyterlab
# Equivalent to:
pip uninstall -y pycrdt datalayer_pycrdt
pip install datalayer_pycrdt
jupyter lab \
  --port 8888 \
  --ip 0.0.0.0 \
  --ServerApp.root_dir ./dev/content \
  --IdentityProvider.token MY_TOKEN
```

#### Docker Deployment
```bash
# Build Docker image (NEVER CANCEL: Build takes 10-15 minutes)
make build-docker  # Takes 10-15 minutes, set timeout to 20+ minutes

# Run with Docker  
make start-docker
# Or manually:
docker run -i --rm \
  -e DOCUMENT_URL=http://localhost:8888 \
  -e DOCUMENT_ID=notebook.ipynb \
  -e DOCUMENT_TOKEN=MY_TOKEN \
  -e RUNTIME_URL=http://localhost:8888 \
  -e START_NEW_RUNTIME=true \
  -e RUNTIME_TOKEN=MY_TOKEN \
  --network=host \
  datalayer/jupyter-mcp-server:latest
```

### Manual Validation Scenarios

**When full testing is not possible due to network constraints, always verify:**

1. **Syntax and Import Validation**:
   ```bash
   # Validate all Python files compile
   find . -name "*.py" -exec python -m py_compile {} \;
   
   # Test local imports work
   PYTHONPATH=. python -c "import jupyter_mcp_server; print('SUCCESS')"
   ```

2. **Configuration Validation**:
   ```bash
   # Verify pyproject.toml is valid
   python -c "import tomllib; tomllib.load(open('pyproject.toml', 'rb'))"
   
   # Test module structure
   python -c "import jupyter_mcp_server.server, jupyter_mcp_server.models"
   ```

3. **Documentation Build** (when Node.js available):
   ```bash
   cd docs/
   npm install  # May have network issues
   npm run build  # 3-5 minutes, set timeout to 10+ minutes
   ```

## Project Structure and Navigation

### Key Directories
- **`jupyter_mcp_server/`**: Main Python package
  - `server.py`: Core MCP server implementation with FastMCP integration
  - `models.py`: Pydantic data models for document and runtime handling
  - `utils.py`: Utility functions for output extraction and processing
  - `tests/`: Unit tests (internal package tests)
- **`tests/`**: Integration tests using pytest-asyncio
- **`docs/`**: Docusaurus-based documentation site (Node.js/React)
- **`dev/content/`**: Development Jupyter notebook files for testing
- **`.github/workflows/`**: CI/CD pipeline definitions

### Important Files
- **`pyproject.toml`**: Build configuration, dependencies, and tool settings
- **`Makefile`**: Development workflow automation
- **`Dockerfile`**: Container build definition
- **`.github/workflows/lint.sh`**: Linting pipeline script
- **`pytest.ini`**: Test configuration

### Frequently Modified Areas
- **Server Logic**: `jupyter_mcp_server/server.py` - Main MCP server implementation
- **Data Models**: `jupyter_mcp_server/models.py` - When adding new MCP tools or changing data structures
- **Tests**: `tests/test_mcp.py` - Integration tests for MCP functionality
- **Documentation**: `docs/src/` - When updating API documentation or user guides

## Common Tasks and Gotchas

### Adding New MCP Tools
1. Add tool definition in `jupyter_mcp_server/server.py`
2. Update models in `jupyter_mcp_server/models.py` if needed
3. Add tests in `tests/test_mcp.py`
4. Update documentation in `docs/`

### Dependency Management
- **Core deps**: Defined in `pyproject.toml` dependencies section
- **Dev deps**: Use `[test,lint,typing]` optional dependencies
- **Special handling**: `datalayer_pycrdt` has specific version requirements (0.12.17)

### CI/CD Pipeline Expectations
- **Build Matrix**: Tests run on Ubuntu, macOS, Windows with Python 3.9, 3.13
- **Critical Timing**: Full CI pipeline takes 20-30 minutes
- **Required Checks**: pytest, ruff, mypy, mdformat, pyproject validation

### Environment Variables for Testing
```bash
# Required for MCP server operation
export DOCUMENT_URL="http://localhost:8888"
export DOCUMENT_TOKEN="MY_TOKEN"
export DOCUMENT_ID="notebook.ipynb"
export RUNTIME_URL="http://localhost:8888"
export RUNTIME_TOKEN="MY_TOKEN"
```

## Network Limitations and Workarounds

**CRITICAL CONSTRAINT**: This development environment has limited PyPI connectivity with SSL certificate issues and timeout problems.

### Known Working Commands
```bash
# These always work (no network required):
python -m py_compile <file>          # Syntax validation
PYTHONPATH=. python -c "import ..."  # Import testing  
python -c "import tomllib; ..."      # Config validation
git operations                       # Version control
docker build (when base images cached)
```

### Commands That May Fail
```bash
pip install <anything>               # Network timeouts/SSL issues
npm install                          # Network limitations  
mypy --install-types                 # Downloads type stubs
hatch test                           # May need PyPI for dependencies
```

### Required Workarounds
1. **Document network failures** when they occur: "pip install fails due to network limitations"
2. **Use syntax validation** instead of full testing when pip installs fail
3. **Prefer Docker approach** for consistent builds when possible
4. **Set generous timeouts** (60+ minutes) for any network operations
5. **Never cancel long-running commands** - document expected timing instead

## Timing Expectations

**NEVER CANCEL these operations - they are expected to take significant time:**

- **pip install ".[test,lint,typing]"**: 5-10 minutes (when network works)
- **mypy --install-types --non-interactive**: 10-15 minutes first run
- **Docker build**: 10-15 minutes
- **Full test suite**: 15-20 minutes  
- **Documentation build**: 3-5 minutes
- **CI pipeline**: 20-30 minutes total

Always set timeouts to at least double these estimates to account for network variability.
```

`.github/dependabot.yml`:

```yml
version: 2
updates:
  - package-ecosystem: "github-actions"
    directory: "/"
    schedule:
      interval: "monthly"
    groups:
      actions:
        patterns:
          - "*"
  - package-ecosystem: "pip"
    directory: "/"
    schedule:
      interval: "monthly"
    groups:
      pip:
        patterns:
          - "*"

```

`.github/workflows/build.yml`:

```yml
name: Build

on:
  push:
    branches: ["main"]
  pull_request:

defaults:
  run:
    shell: bash -eux {0}

jobs:
  build:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        python-version: ["3.10", "3.13"]

    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v6
        with:
          python-version: ${{ matrix.python-version }}

      - name: Base Setup
        uses: jupyterlab/maintainer-tools/.github/actions/base-setup@v1

      - name: Install the extension
        run: |
          python -m pip install ".[test]"

      - name: Build the extension
        run: |
          pip install build
          python -m build --sdist
          cp dist/*.tar.gz jupyter_mcp_server.tar.gz
          pip uninstall -y "jupyter_mcp_server"
          rm -rf "jupyter_mcp_server"

      - uses: actions/upload-artifact@v6
        if: startsWith(matrix.os, 'ubuntu')
        with:
          name: jupyter_mcp_server-sdist-${{ matrix.python-version }}
          path: jupyter_mcp_server.tar.gz

  # check_links:
  #   runs-on: ubuntu-latest
  #   steps:
  #     - uses: actions/checkout@v6
  #     - uses: jupyterlab/maintainer-tools/.github/actions/base-setup@v1
  #     - uses: jupyterlab/maintainer-tools/.github/actions/check-links@v1

  test_lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6
      - uses: jupyterlab/maintainer-tools/.github/actions/base-setup@v1
      - name: Run Linters
        run: |
          bash ./.github/workflows/lint.sh

  test_sdist:
    needs: build
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: ["3.13"]

    steps:
      - name: Checkout
        uses: actions/checkout@v6
      - name: Install Python
        uses: actions/setup-python@v6
        with:
          python-version: ${{ matrix.python-version }}
          architecture: "x64"
      - uses: actions/download-artifact@v7
        with:
          name: jupyter_mcp_server-sdist-${{ matrix.python-version }}
      - name: Install and Test
        run: |
          pip install jupyter_mcp_server.tar.gz
          pip list 2>&1 | grep -ie "jupyter_mcp_server"
          python -c "import jupyter_mcp_server"

```

`.github/workflows/fix-license-header.yml`:

```yml
name: Fix License Headers

on:
  pull_request_target:

concurrency:
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.ref }}
  cancel-in-progress: true
    
jobs:
  header-license-fix:
    runs-on: ubuntu-latest

    permissions:
      contents: write
      pull-requests: write

    steps:
      - name: Checkout
        uses: actions/checkout@v6
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Checkout the branch from the PR that triggered the job
        run: gh pr checkout ${{ github.event.pull_request.number }}
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

      - name: Fix License Header
        # pin to include https://github.com/apache/skywalking-eyes/pull/168
        uses: apache/skywalking-eyes/header@61275cc80d0798a405cb070f7d3a8aaf7cf2c2c1
        with:
          mode: fix

      - name: List files changed
        id: files-changed
        shell: bash -l {0}
        run: |
          set -ex
          export CHANGES=$(git status --porcelain | tee /tmp/modified.log | wc -l)
          cat /tmp/modified.log

          echo "N_CHANGES=${CHANGES}" >> $GITHUB_OUTPUT

          git diff

      - name: Commit any changes
        if: steps.files-changed.outputs.N_CHANGES != '0' && github.event.pull_request.head.repo.full_name == github.repository
        shell: bash -l {0}
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          git pull --no-tags

          git add *
          git commit -m "Automatic application of license header"

          git push origin HEAD:refs/heads/${{ github.event.pull_request.head.ref }}
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

```

`.github/workflows/lint.sh`:

```sh
#!/usr/bin/env bash
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

pip install -e ".[lint,typing]"
mypy --install-types --non-interactive .
ruff check .
mdformat --check *.md
pipx run 'validate-pyproject[all]' pyproject.toml

```

`.github/workflows/release.yml`:

```yml
name: Release

on:
  push:
    tags:
      - 'v*.*.*'  # Trigger condition: v0.15.2, v1.0.0, etc.

permissions:
  contents: write
  id-token: write  # For OIDC trusted publishing

jobs:
  # Job 1: Build Python Package
  build-python:
    name: Build Python Package
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v6

      - name: Set up Python
        uses: actions/setup-python@v6
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install build twine

      - name: Build package
        run: python -m build

      - name: Upload artifacts
        uses: actions/upload-artifact@v6
        with:
          name: python-package
          path: dist/*

  # Job 2: Publish to PyPI (using OIDC trusted publishing)
  publish-pypi:
    name: Publish to PyPI
    needs: build-python
    runs-on: ubuntu-latest
    environment:
      name: pypi
      url: https://pypi.org/p/jupyter-mcp-server
    permissions:
      id-token: write  # Required for OIDC
    steps:
      - name: Download artifacts
        uses: actions/download-artifact@v7
        with:
          name: python-package
          path: dist

      - name: Publish to PyPI
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          # No password needed, using OIDC trusted publishing
          skip-existing: true

  # Job 3: Build and Publish Docker Image
  build-docker:
    name: Build and Push Docker Image
    runs-on: ubuntu-latest
    permissions:
      contents: read
      packages: write  # For GHCR
      id-token: write  # For Docker Hub OIDC (optional)
    steps:
      - uses: actions/checkout@v6

      - name: Extract version from tag
        id: version
        run: echo "VERSION=${GITHUB_REF#refs/tags/v}" >> $GITHUB_OUTPUT

      - name: Set up QEMU
        uses: docker/setup-qemu-action@v3
        with:
          platforms: arm64

      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3

      - name: Log in to Docker Hub
        uses: docker/login-action@v3
        with:
          username: ${{ secrets.DOCKERHUB_USERNAME }}
          password: ${{ secrets.DOCKERHUB_TOKEN }}

      - name: Build and push Docker image
        uses: docker/build-push-action@v6
        with:
          context: .
          platforms: linux/amd64,linux/arm64
          push: true
          tags: |
            datalayer/jupyter-mcp-server:latest
            datalayer/jupyter-mcp-server:${{ steps.version.outputs.VERSION }}
          cache-from: type=gha
          cache-to: type=gha,mode=max

  # Job 4: Create GitHub Release
  create-release:
    name: Create GitHub Release
    needs: [publish-pypi, build-docker]
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - uses: actions/checkout@v6
        with:
          fetch-depth: 0  # Fetch complete history for release creation

      - name: Extract version
        id: version
        run: echo "VERSION=${GITHUB_REF#refs/tags/v}" >> $GITHUB_OUTPUT

      - name: Create Release with Auto-Generated Notes
        run: |
          gh release create ${{ github.ref_name }} \
            --title "Release ${{ steps.version.outputs.VERSION }}" \
            --generate-notes \
            --notes "## ğŸš€ Release ${{ steps.version.outputs.VERSION }}

          ### ğŸ”— Links

          - [PyPI](https://pypi.org/project/jupyter-mcp-server/${{ steps.version.outputs.VERSION }}/)
          - [Docker Hub](https://hub.docker.com/r/datalayer/jupyter-mcp-server)"
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}

```

`.github/workflows/test.yml`:

```yml
name: Test

on:
  push:
    branches: ["main"]
  pull_request:
    branches: ["main"]

defaults:
  run:
    shell: bash -eux {0}

jobs:
  test:
    runs-on: ${{ matrix.os }}
    strategy:
      fail-fast: false
      matrix:
        os: [ubuntu-latest, macos-latest, windows-latest]
        python-version: ["3.10", "3.13"]

    steps:
      - name: Checkout
        uses: actions/checkout@v6

      - name: Set up Python ${{ matrix.python-version }}
        uses: actions/setup-python@v6
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install the extension
        run: |
          python -m pip install ".[test]"
          pip uninstall -y pycrdt datalayer_pycrdt
          pip install datalayer_pycrdt==0.12.17

      - name: Test the extension
        run: |
          make test-mcp-server
          make test-jupyter-server

```

`.gitignore`:

```
*.egg-info/
.ipynb_checkpoints

# Created by https://www.gitignore.io/api/python
# Edit at https://www.gitignore.io/?templates=python

### Python ###
# Byte-compiled / optimized / DLL files
__pycache__/
*.py[cod]
*$py.class

# C extensions
*.so

# Distribution / packaging
.Python
build/
dist/
downloads/
lib/
lib64/
parts/
sdist/
var/
wheels/
pip-wheel-metadata/
share/python-wheels/
.installed.cfg

# PyInstaller
#  Usually these files are written by a python script from a template
#  before PyInstaller builds the exe, so as to inject date/other infos into it.
*.manifest
*.spec

# Installer logs
pip-log.txt
pip-delete-this-directory.txt

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
.hypothesis/
.pytest_cache/

# Translations
*.mo
*.pot

# Environment variables:
.env

# Scrapy stuff:
.scrapy

# Sphinx documentation
docs/_build/

# PyBuilder
target/

# pyenv
.python-version

# celery beat schedule file
celerybeat-schedule

# SageMath parsed files
*.sage.py

# Spyder project settings
.spyderproject
.spyproject

# Rope project settings
.ropeproject

# Mr Developer
.mr.developer.cfg
.project
.pydevproject

# mkdocs documentation
/site

# mypy
.mypy_cache/
.dmypy.json
dmypy.json

# ruff
.ruff_cache

# Pyre type checker
.pyre/

# End of https://www.gitignore.io/api/python

# OSX files
.DS_Store

# Include
!**/.*ignore
!**/.*rc
!**/.*rc.js
!**/.*rc.json
!**/.*rc.yml
!**/.*config
!*.*rc.json
!.github
!.devcontainer

untracked_notebooks/*
.jupyter_ystore
.jupyter_ystore.db
docs/.yarn/*

uv.lock
*-lock.json

```

`ARCHITECTURE.md`:

```md
<!--
  ~ Copyright (c) 2024- Datalayer, Inc.
  ~
  ~ BSD 3-Clause License
-->

# Jupyter MCP Server - Architecture

## Overview

The Jupyter MCP Server supports **dual-mode operation**:

1. **MCP_SERVER Mode** (Standalone) - Connects to remote Jupyter servers via HTTP/WebSocket
2. **JUPYTER_SERVER Mode** (Extension) - Runs embedded in Jupyter Server with direct API access

Both modes share the same tool implementations, with automatic backend selection based on configuration.

## High-Level Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       MCP Client                                â”‚
â”‚            (Claude Desktop, VS Code, Cursor, etc.)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â”‚                                    â”‚
             â”‚ stdio/SSE                          â”‚ HTTP/SSE
             â”‚                                    â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   MCP_SERVER Mode   â”‚          â”‚  JUPYTER_SERVER Mode     â”‚
    â”‚   (Standalone)      â”‚          â”‚  (Extension)             â”‚
    â”‚                     â”‚          â”‚                          â”‚
    â”‚   CLI Layer         â”‚          â”‚    Extension Handlers    â”‚
    â”‚  (CLI.py)           â”‚          â”‚  (handlers.py)           â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                                â”‚
               â”‚ Configuration                  â”‚ Configuration
               â”‚                                â”‚
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚   Server Layer      â”‚          â”‚   Extension Context     â”‚
    â”‚  (server.py)        â”‚          â”‚  (context.py)           â”‚
    â”‚                     â”‚          â”‚                         â”‚
    â”‚  - FastMCP Server   â”‚          â”‚  - ServerApp Access     â”‚
    â”‚  - Tool Wrappers    â”‚          â”‚  - Manager Access       â”‚
    â”‚  - Error Handling   â”‚          â”‚  - Backend Selection    â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜          â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚                                â”‚
               â”‚ Tool Delegation                â”‚ Tool Delegation
               â”‚                                â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
        â”‚          Tool Implementation Layer           â”‚
        â”‚         (jupyter_mcp_server/tools/)          â”‚
        â”‚                                              â”‚
        â”‚  14 Tools in 3 Categories:                   â”‚
        â”‚  â€¢ Server Management (2)                     â”‚
        â”‚  â€¢ Multi-Notebook Management (5)             â”‚
        â”‚  â€¢ Cell Operations (7)                       â”‚
        â”‚                                              â”‚
        â”‚  Each tool implements:                       â”‚
        â”‚  - Dual-mode execution logic                 â”‚
        â”‚  - Backend abstraction                       â”‚
        â”‚  - Error handling and recovery               â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚                       â”‚
                   â”‚ Mode Selection        â”‚ Backend Selection
                   â”‚                       â”‚
          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
          â”‚ Remote Backend  â”‚     â”‚  Local Backend  â”‚
          â”‚                 â”‚     â”‚                 â”‚
          â”‚ - HTTP Clients  â”‚     â”‚ - Direct API    â”‚
          â”‚ - WebSocket     â”‚     â”‚ - Zero Overhead â”‚
          â”‚ - Client Libs   â”‚     â”‚ - YDoc Support  â”‚
          â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚                       â”‚
                   â”‚ HTTP/WS               â”‚ Direct Python API
                   â”‚                       â”‚
            â”Œâ”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
            â”‚ Remote Jupyter  â”‚    â”‚ Local Jupyter  â”‚
            â”‚ Server          â”‚    â”‚ Server         â”‚
            â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Core Components

### 1. CLI Layer (`CLI.py`)

**Command-Line Interface** - Primary entry point for users and MCP clients:

**Key Features**:
- **Configuration Management**: Handles all startup configuration via command-line options and environment variables
- **Transport Selection**: Supports both `stdio` (for direct MCP client integration) and `streamable-http` (for HTTP-based clients)
- **Auto-Enrollment**: Automatically connects to specified notebooks on startup
- **Provider Support**: Supports both `jupyter` and `datalayer` providers
- **URL Resolution**: Intelligent URL and token resolution with fallback mechanisms

**Integration**:
- Calls `server.py` functions to initialize the MCP server
- Passes configuration to `ServerContext` for mode detection
- Handles kernel startup and notebook enrollment lifecycle

### 2. Backend Layer (`jupyter_mcp_server/jupyter_extension/backends/`)

**Backend Abstraction** - Unified interface for notebook and kernel operations:

**LocalBackend** - Complete implementation using local Jupyter Server APIs:
- Uses `serverapp.contents_manager` for file operations
- Uses `serverapp.kernel_manager` for kernel operations
- Direct Python API calls with minimal overhead
- Supports both file-based and YDoc collaborative editing

**RemoteBackend** - Placeholder implementation for HTTP/WebSocket access:
- Designed for `jupyter_server_client`, `jupyter_kernel_client`, `jupyter_nbmodel_client`
- Maintains 100% backward compatibility with existing MCP_SERVER mode
- Currently marked as "Not Implemented" - to be refactored from server.py

### 3. Server Context Layer

**Multiple Context Managers**:

**MCP Server Context** (`server_context.py::ServerContext`):
- Singleton managing server mode for standalone MCP_SERVER mode
- Provides HTTP clients for remote Jupyter server access
- Mode detection based on configuration

**Extension Context** (`jupyter_extension/context.py::ServerContext`):
- Singleton managing server mode for JUPYTER_SERVER extension mode
- Provides direct access to serverapp managers (contents_manager, kernel_manager)
- Handles configuration from Jupyter extension traits

**Mode Detection**:
- **JUPYTER_SERVER**: When running as extension, serverapp available
- **MCP_SERVER**: When running standalone, connects via HTTP

### 4. FastMCP Server Layer (`server.py`)

**FastMCP Integration** - Core MCP protocol implementation:

```python
# Global MCP server instance with CORS support
mcp = FastMCPWithCORS(name="Jupyter MCP Server", json_response=False, stateless_http=True)
notebook_manager = NotebookManager()
server_context = ServerContext.get_instance()

# Tool registration and execution
@mcp.tool()
async def list_files(path: str = "", max_depth: int = 1, ...) -> str:
    """List files and directories in Jupyter server filesystem"""
    return await safe_notebook_operation(
        lambda: ListFilesTool().execute(
            mode=server_context.mode,
            server_client=server_context.server_client,
            contents_manager=server_context.contents_manager,
            path=path,
            max_depth=max_depth,
            ...
        )
    )
```

**Key Responsibilities**:
- **Tool Registration**: All 14 MCP tools are registered as FastMCP decorators
- **Mode Detection**: Automatically detects and initializes appropriate server mode
- **Error Handling**: Provides `safe_notebook_operation()` wrapper with retry logic
- **Resource Management**: Manages notebook connections and kernel lifecycle
- **Protocol Bridge**: Translates between MCP protocol and internal tool implementations

**Transport Support**:
- **stdio**: Direct communication with MCP clients via standard input/output
- **streamable-http**: HTTP-based communication with SSE (Server-Sent Events) support
- **CORS Middleware**: Enables cross-origin requests for web-based MCP clients

### 5. Tool Implementation Layer (`jupyter_mcp_server/tools/`)

**Built-in Tool Implementations** - Complete set of Jupyter operations:

```python
# Tool Categories and Examples

# Server Management (2 tools)
class ListFilesTool(BaseTool):      # File system exploration
class ListKernelsTool(BaseTool):    # Kernel management

# Multi-Notebook Management (5 tools)
class UseNotebookTool(BaseTool):    # Connect/create notebooks
class ListNotebooksTool(BaseTool):  # List managed notebooks
class RestartNotebookTool(BaseTool): # Restart kernels
class UnuseNotebookTool(BaseTool):  # Disconnect notebooks
class ReadNotebookTool(BaseTool):   # Read notebook content

# Cell Operations (7 tools)
class InsertCellTool(BaseTool):     # Insert new cells
class DeleteCellTool(BaseTool):     # Delete cells
class OverwriteCellSourceTool(BaseTool): # Modify cell content
class ExecuteCellTool(BaseTool):    # Execute cells with streaming
class ReadCellTool(BaseTool):       # Read individual cells
class ExecuteCodeTool(BaseTool):    # Execute arbitrary code
class InsertExecuteCodeCellTool(BaseTool): # Combined insert+execute
```

**Implementation Architecture**:
- **BaseTool Abstract Class**: Defines `execute()` method signature with dual-mode support
- **ServerMode Enum**: Distinguishes between `MCP_SERVER` and `JUPYTER_SERVER` modes
- **Dual-Mode Logic**: Each tool implements both local and remote execution paths
- **Backend Integration**: Tools automatically select appropriate backend based on mode

**Tool Categories**:
1. **Server Management**: File system and kernel introspection
2. **Multi-Notebook Management**: Notebook lifecycle and connection management
3. **Cell Operations**: Fine-grained cell manipulation and execution

**Dynamic Tool Registry** (`get_registered_tools()`):
- Queries FastMCP's `list_tools()` to get all registered tools
- Returns tool metadata (name, description, parameters, inputSchema)
- Used by Jupyter extension to expose tools without hardcoding
- Supports both FastMCP tools and jupyter-mcp-tools integration

### 6. Jupyter Extension Layer (`jupyter_extension/`)

**Extension App** (`extension.py::JupyterMCPServerExtensionApp`):
```python
class JupyterMCPServerExtensionApp(ExtensionApp):
    name = "jupyter_mcp_server"
    
    # Configuration traits
    document_url = Unicode("local", config=True)
    runtime_url = Unicode("local", config=True)
    document_id = Unicode("notebook.ipynb", config=True)
    
    def initialize_settings(self):
        # Store config in Tornado settings
        # Initialize ServerContext with JUPYTER_SERVER mode
```

**Handlers** (`handlers.py`):
- `MCPHealthHandler`: GET /mcp/healthz
- `MCPToolsListHandler`: GET /mcp/tools/list (uses `get_registered_tools()`)
- `MCPToolsCallHandler`: POST /mcp/tools/call
- `MCPSSEHandler`: SSE endpoint for MCP protocol

**Extension Context** (`context.py::ServerContext`):
```python
class ServerContext:
    _serverapp: Optional[Any] = None
    _context_type: str = "unknown"
    
    def update(self, context_type: str, serverapp: Any):
        """Called by extension to register serverapp."""
    
    def is_local_document(self) -> bool:
        """Check if document operations use local access."""
    
    def get_contents_manager(self):
        """Get local contents_manager from serverapp."""
```

### 7. Notebook Manager (`notebook_manager.py`)

**Purpose**: Manages notebook connections and kernel lifecycle.

**Key Features**:
- Tracks managed notebooks with kernel associations
- Supports both local (JUPYTER_SERVER) and remote (MCP_SERVER) modes
- Provides `NotebookConnection` context manager for Y.js document access

**Local vs Remote**:
- **Local mode**: Notebooks tracked with `is_local=True`, no WebSocket connections
- **Remote mode**: Establishes WebSocket connections via `NbModelClient`

```python
class NotebookManager:
    def add_notebook(self, name, kernel, server_url="local", ...):
        """Add notebook with mode detection (local vs remote)."""
    
    def get_current_connection(self):
        """Get WebSocket connection (MCP_SERVER mode only)."""
```

## Configuration

### MCP_SERVER Mode (Standalone)

**Start Command**:
```bash
jupyter-mcp-server start \
  --transport streamable-http \
  --document-url http://localhost:8888 \
  --runtime-url http://localhost:8888 \
  --document-token MY_TOKEN \
  --runtime-token MY_TOKEN \
  --port 4040
```

**Behavior**:
- ServerContext initialized with `mode=ServerMode.MCP_SERVER`
- Tools use HTTP clients for remote Jupyter server access
- Notebook connections use `NbModelClient` for WebSocket (Y.js documents)
- Uses RemoteBackend (placeholder implementation)

### JUPYTER_SERVER Mode (Extension)

**Start Command**:
```bash
jupyter server \
  --JupyterMCPServerExtensionApp.document_url=local \
  --JupyterMCPServerExtensionApp.runtime_url=local \
  --JupyterMCPServerExtensionApp.document_id=notebook.ipynb
```

**Configuration File** (`jupyter_server_config.py`):
```python
c.ServerApp.jpserver_extensions = {"jupyter_mcp_server": True}
c.JupyterMCPServerExtensionApp.document_url = "local"
c.JupyterMCPServerExtensionApp.runtime_url = "local"
```

**Backend Selection**:
- **LocalBackend**: Used when `document_url="local"` or `runtime_url="local"`
  - Direct access to `serverapp.contents_manager`, `serverapp.kernel_manager`
  - No network overhead, maximum performance
  - Supports both file-based and YDoc collaborative editing
- **RemoteBackend**: Used when connecting to remote Jupyter servers
  - HTTP/WebSocket access via client libraries
  - Placeholder implementation (to be completed)

**Behavior**:
- Extension auto-enabled (via `jupyter-config/` file)
- ServerContext updated with `mode=ServerMode.JUPYTER_SERVER`
- Tools automatically select LocalBackend for optimal performance
- Cell reading tools parse notebook JSON from file system or YDoc

## Request Flow Examples

### Example 1: List Notebooks (JUPYTER_SERVER Mode with LocalBackend)

```
MCP Client
  â†’ POST /mcp/tools/call {"tool_name": "list_notebooks"}
    â†’ MCPSSEHandler (or MCPToolsCallHandler)
      â†’ FastMCP calls @mcp.tool() wrapper
        â†’ ListNotebooksTool().execute(
            mode=JUPYTER_SERVER,
            notebook_manager=notebook_manager
          )
          â†’ notebook_manager.list_all_notebooks()
            â†’ Returns managed notebooks from memory
          â† TSV-formatted table
        â† Tool result
      â† JSON-RPC response
    â† SSE message
  â† Tool result displayed
```

### Example 2: Read Cell (JUPYTER_SERVER Mode with LocalBackend)

```
MCP Client
  â†’ POST /mcp/tools/call {"tool_name": "read_cell", "arguments": {"cell_index": 0}}
    â†’ MCPSSEHandler (or MCPToolsCallHandler)
      â†’ FastMCP calls @mcp.tool() wrapper
        â†’ ReadCellTool().execute(
            mode=JUPYTER_SERVER,
            contents_manager=serverapp.contents_manager,
            notebook_manager=notebook_manager
          )
          â†’ LocalBackend.get_notebook_content(notebook_path)
            â†’ contents_manager.get(notebook_path, content=True, type='notebook')
              â†’ Direct file system access (no HTTP)
            â† Notebook JSON content
          â†’ Parse cells and format response
          â† Cell information with metadata and source
        â† Tool result
      â† JSON-RPC response
    â† SSE message
  â† Cell content displayed
```

### Example 3: Execute Cell (MCP_SERVER Mode with RemoteBackend)

```
MCP Client
  â†’ POST /mcp/tools/call {"tool_name": "execute_cell", "arguments": {"cell_index": 0}}
    â†’ FastMCP calls @mcp.tool() wrapper
      â†’ ExecuteCellTool().execute(
          mode=MCP_SERVER,
          notebook_manager=notebook_manager
        )
        â†’ notebook_manager.get_current_connection()
          â†’ NbModelClient establishes WebSocket to Y.js document
          â†’ Access collaborative Y.js document
        â†’ Execute code via kernel connection
          â†’ HTTP/WebSocket to remote kernel
          â†’ Real-time execution with progress updates
        â† Execution outputs with rich formatting
      â† Tool result
    â† Response
  â† Outputs displayed
```

## Tool Registration Flow

```
1. CLI startup (CLI.py)
   â†“
2. Configuration parsing and validation
   â†“
3. ServerContext initialization with mode detection
   â†“
4. FastMCP server initialization (server.py)
   â†“
5. Tool instance creation (14 tool implementations)
   â†“
6. @mcp.tool() wrapper registration
   â†“
7. FastMCP internal tool registry
   â†“
8. Dynamic tool discovery via get_registered_tools()
   â†“
9. Extension handlers expose tools via /mcp/tools/list
   â†“
10. MCP clients discover and invoke tools
```

## File Structure

```
jupyter_mcp_server/
â”œâ”€â”€ __init__.py                 # Package initialization
â”œâ”€â”€ __main__.py                 # Module entry point (imports CLI)
â”œâ”€â”€ __version__.py              # Version information (0.17.1)
â”‚
â”œâ”€â”€ CLI.py                      # ğŸ  Command-Line Interface (Primary Entry Point)
â”‚   â”œâ”€â”€ Command parsing and validation
â”‚   â”œâ”€â”€ Environment variable handling
â”‚   â”œâ”€â”€ Transport selection (stdio/streamable-http)
â”‚   â”œâ”€â”€ Provider support (jupyter/datalayer)
â”‚   â”œâ”€â”€ Auto-enrollment of notebooks
â”‚   â””â”€â”€ Server lifecycle management
â”‚
â”œâ”€â”€ server.py                   # ğŸ”§ FastMCP Server Layer
â”‚   â”œâ”€â”€ MCP protocol implementation
â”‚   â”œâ”€â”€ Tool registration (14 @mcp.tool decorators)
â”‚   â”œâ”€â”€ Error handling with safe_notebook_operation()
â”‚   â”œâ”€â”€ Resource management and cleanup
â”‚   â”œâ”€â”€ Dynamic tool registry (get_registered_tools())
â”‚   â””â”€â”€ Transport support (stdio + streamable-http)
â”‚
â”œâ”€â”€ tools/                      # ğŸ› ï¸ Built-in Tool Implementations
â”‚   â”œâ”€â”€ __init__.py            # Exports BaseTool, ServerMode
â”‚   â”œâ”€â”€ _base.py               # Abstract base class for all tools
â”‚   â”‚
â”‚   # Server Management Tools (2)
â”‚   â”œâ”€â”€ list_files_tool.py     # File system exploration
â”‚   â”œâ”€â”€ list_kernels_tool.py   # Kernel introspection
â”‚   â”‚
â”‚   # Multi-Notebook Management Tools (5)
â”‚   â”œâ”€â”€ use_notebook_tool.py   # Connect/create notebooks
â”‚   â”œâ”€â”€ list_notebooks_tool.py # List managed notebooks
â”‚   â”œâ”€â”€ restart_notebook_tool.py # Restart kernels
â”‚   â”œâ”€â”€ unuse_notebook_tool.py # Disconnect notebooks
â”‚   â”œâ”€â”€ read_notebook_tool.py  # Read notebook content
â”‚   â”‚
â”‚   # Cell Operation Tools (7)
â”‚   â”œâ”€â”€ read_cell_tool.py      # Read individual cells
â”‚   â”œâ”€â”€ insert_cell_tool.py    # Insert new cells
â”‚   â”œâ”€â”€ delete_cell_tool.py    # Delete cells
â”‚   â”œâ”€â”€ overwrite_cell_source_tool.py # Modify cell content
â”‚   â”œâ”€â”€ execute_cell_tool.py   # Execute cells with streaming
â”‚   â”œâ”€â”€ execute_code_tool.py   # Execute arbitrary code
â”‚   â””â”€â”€ insert_execute_code_cell # Combined insert+execute (inline in server.py)
â”‚
â”œâ”€â”€ config.py                   # âš™ï¸ Configuration Management
â”‚   â”œâ”€â”€ Singleton config object (JupyterMCPConfig)
â”‚   â”œâ”€â”€ Environment variable parsing
â”‚   â”œâ”€â”€ URL and token resolution
â”‚   â””â”€â”€ Provider-specific settings
â”‚
â”œâ”€â”€ notebook_manager.py         # ğŸ“š Notebook Lifecycle Management
â”‚   â”œâ”€â”€ Multi-notebook support
â”‚   â”œâ”€â”€ Kernel connection management
â”‚   â”œâ”€â”€ Context managers for resources
â”‚   â””â”€â”€ Dual-mode operation (local/remote)
â”‚
â”œâ”€â”€ server_context.py           # ğŸ¯ Server Context (MCP_SERVER mode)
â”‚   â”œâ”€â”€ Mode detection and initialization
â”‚   â”œâ”€â”€ HTTP client management
â”‚   â””â”€â”€ Configuration state management
â”‚
â”œâ”€â”€ utils.py                    # ğŸ§° Utility Functions
â”‚   â”œâ”€â”€ Execution utilities (local/remote)
â”‚   â”œâ”€â”€ Output processing and formatting
â”‚   â”œâ”€â”€ Kernel management helpers
â”‚   â””â”€â”€ YDoc integration support
â”‚
â”œâ”€â”€ enroll.py                   # ğŸ”— Auto-Enrollment System
â”‚   â”œâ”€â”€ Automatic notebook connection
â”‚   â”œâ”€â”€ Kernel startup and management
â”‚   â””â”€â”€ Configuration-based initialization
â”‚
â”œâ”€â”€ models.py                   # ğŸ“‹ Data Models
â”‚   â”œâ”€â”€ Pydantic models for API
â”‚   â”œâ”€â”€ Cell and Notebook structures
â”‚   â””â”€â”€ Configuration validation
â”‚
â””â”€â”€ jupyter_extension/          # ğŸ”Œ Jupyter Server Extension
    â”œâ”€â”€ extension.py           # Jupyter extension app
    â”œâ”€â”€ handlers.py            # HTTP request handlers
    â”œâ”€â”€ context.py             # Extension context manager
    â”œâ”€â”€ backends/              # Backend implementations
    â”‚   â”œâ”€â”€ base.py            # Backend interface
    â”‚   â”œâ”€â”€ local_backend.py   # Local API (Complete)
    â”‚   â””â”€â”€ remote_backend.py  # Remote API (Placeholder)
    â””â”€â”€ protocol/              # Protocol implementation
        â””â”€â”€ messages.py        # MCP message models
```

## References

- [MCP Specification](https://modelcontextprotocol.io/specification)
- [Jupyter Server Extension Guide](https://jupyter-server.readthedocs.io/en/latest/developers/extensions.html)
- [FastMCP Documentation](https://github.com/jlowin/fastmcp)
- [Y.js Collaborative Editing](https://github.com/yjs/yjs)

---

**Version**: 0.2.0
**Last Updated**: October 2025
**Status**: Complete implementation with dual-mode architecture and backend abstraction

```

`CODE_OF_CONDUCT.md`:

```md
<!--
  ~ Copyright (c) 2024- Datalayer, Inc.
  ~
  ~ BSD 3-Clause License
-->

# Contributor Covenant Code of Conduct

## Our Pledge

We as members, contributors, and leaders pledge to make participation in our
community a harassment-free experience for everyone, regardless of age, body
size, visible or invisible disability, ethnicity, sex characteristics, gender
identity and expression, level of experience, education, socio-economic status,
nationality, personal appearance, race, religion, or sexual identity
and orientation.

We pledge to act and interact in ways that contribute to an open, welcoming,
diverse, inclusive, and healthy community.

## Our Standards

Examples of behavior that contributes to a positive environment for our
community include:

*   Demonstrating empathy and kindness toward other people
*   Being respectful of differing opinions, viewpoints, and experiences
*   Giving and gracefully accepting constructive feedback
*   Accepting responsibility and apologizing to those affected by our mistakes,
    and learning from the experience
*   Focusing on what is best not just for us as individuals, but for the
    overall community

Examples of unacceptable behavior include:

*   The use of sexualized language or imagery, and sexual attention or
    advances of any kind
*   Trolling, insulting or derogatory comments, and personal or political attacks
*   Public or private harassment
*   Publishing others' private information, such as a physical or email
    address, without their explicit permission
*   Other conduct which could reasonably be considered inappropriate in a
    professional setting

## Enforcement Responsibilities

Community leaders are responsible for clarifying and enforcing our standards of
acceptable behavior and will take appropriate and fair corrective action in
response to any behavior that they deem inappropriate, threatening, offensive,
or harmful.

Community leaders have the right and responsibility to remove, edit, or reject
comments, commits, code, wiki edits, issues, and other contributions that are
not aligned to this Code of Conduct, and will communicate reasons for moderation
decisions when appropriate.

## Scope

This Code of Conduct applies within all community spaces, and also applies when
an individual is officially representing the community in public spaces.
Examples of representing our community include using an official e-mail address,
posting via an official social media account, or acting as an appointed
representative at an online or offline event.

## Enforcement

Instances of abusive, harassing, or otherwise unacceptable behavior may be
reported to the community leaders responsible for enforcement.
All complaints will be reviewed and investigated promptly and fairly.

All community leaders are obligated to respect the privacy and security of the
reporter of any incident.

## Attribution

This Code of Conduct is adapted from the [Contributor Covenant][homepage],
version 2.0, available at
[https://www.contributor-covenant.org/version/2/0/code_of_conduct.html][v2.0].

[homepage]: https://www.contributor-covenant.org
[v2.0]: https://www.contributor-covenant.org/version/2/0/code_of_conduct.html

```

`CONTRIBUTING.md`:

```md
<!--
  ~ Copyright (c) 2024- Datalayer, Inc.
  ~
  ~ BSD 3-Clause License
-->

# Contributing to Jupyter MCP Server

First off, thank you for considering contributing to Jupyter MCP Server! It's people like you that make this project great. Your contributions help us improve the project and make it more useful for everyone!

## Code of Conduct

This project and everyone participating in it is governed by the [Contributor Covenant Code of Conduct](CODE_OF_CONDUCT.md). By participating, you are expected to uphold this code. Please report unacceptable behavior.

## How Can I Contribute?

We welcome contributions of all kinds, including:
- ğŸ› Bug fixes
- ğŸ“ Improvements to existing features or documentation
- ğŸ”§ New feature development

### Reporting Bugs or Suggesting Enhancements

Before creating a new issue, please **ensure one does not already exist** by searching on GitHub under [Issues](https://github.com/datalayer/jupyter-mcp-server/issues).

- If you're reporting a bug, please include a **title and clear description**, as much relevant information as possible, and a **code sample** or an **executable test case** demonstrating the expected behavior that is not occurring.
- If you're suggesting an enhancement, clearly state the enhancement you are proposing and why it would be a good addition to the project.

## Development Setup

To get started with development, you'll need to set up your environment.

1.  **Clone the repository:**
    ```bash
    git clone https://github.com/datalayer/jupyter-mcp-server
    cd jupyter-mcp-server
    ```

2.  **Install dependencies:**
    ```bash
    # Install the project in editable mode with test dependencies
    pip install -e ".[test]"
    ```

3.  **Make Some Amazing Changes!**
    ```bash
    # Make some amazing changes to the source code!
    ```

4.  **Run Tests:**
    ```bash
    make test
    ```

5.  **Build Python Package/Docker Image:**
    ```bash
    # Build the Python package
    make build
    # Build the Docker image
    make build-docker
    ```

## Testing Guidelines

This section provides comprehensive guidance for adding and maintaining tests in the Jupyter MCP Server project.

### Test Architecture

The project supports testing in two deployment modes:

1. **MCP_SERVER Mode**: Standalone MCP server using HTTP/WebSocket to connect to Jupyter
2. **JUPYTER_SERVER Mode**: Jupyter extension with direct serverapp API access

Tests are parametrized to run against both modes using the same MCPClient, ensuring consistent behavior across deployment patterns.

### Test Data

Test notebooks are located in the `dev/content/` directory:

- `notebook.ipynb`: Main test notebook with matplotlib examples and various cell types
- `new.ipynb`: Additional test notebook for multi-notebook operations

### Tool Implementation and Output Matching

When adding tests for new features or modifying existing tools, ensure your tests match the actual implementation in `jupyter_mcp_server/tools/`

## (Recommended) Manual Agent Testing

1.  **Build Python Package:**
    ```bash
    make build
    ```

2. **Set Up Your Environment:**
    ```bash
    pip install jupyterlab==4.4.1 jupyter-collaboration==4.0.2 ipykernel
    pip uninstall -y pycrdt datalayer_pycrdt
    pip install datalayer_pycrdt==0.12.17
    ```

3.  **Start Jupyter Server:**
    ```bash
    jupyter lab --port 8888 --IdentityProvider.token MY_TOKEN --ip 0.0.0.0
    ```

4.  **Set Up Your MCP Client:**
    We recommend using `uvx` to start the MCP server, first install `uvx` with `pip install uv`.

    ```bash
    pip install uv
    uv --version
    # should be 0.6.14 or higher
    ```

    Then, set up your MCP client with the following configuration file.

    ```json
    {
        "mcpServers": {
            "Jupyter-MCP": {
                "command": "uvx",
                "args": [
                    "--from",
                    "your/path/to/jupyter-mcp-server/dist/jupyter_mcp_server-x.x.x-py3-none-any.whl",
                    "jupyter-mcp-server"
                ],
                "env": {
                    "JUPYTER_URL": "http://localhost:8888",
                    "JUPYTER_TOKEN": "MY_TOKEN",
                    "ALLOW_IMG_OUTPUT": "true"
                }
            }
        }
    }
    ```

5.  **Test Your Changes:**

    You Can Test Your Changes with your favorite MCP client(e.g. Cursor, Gemini CLI, etc.).

## Pull Request Process

1.  Once you are satisfied with your changes and tests, commit your code.
2.  Push your branch to your fork and attach with detailed description of the changes you made.
3.  Open a pull request to the `main` branch of the original repository.

We look forward to your contributions!

```

`Dockerfile`:

```
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

FROM python:3.12-slim

WORKDIR /app

COPY pyproject.toml LICENSE README.md ./
COPY jupyter_mcp_server/ jupyter_mcp_server/
COPY jupyter-config/ jupyter-config/

ENV PIP_NO_CACHE_DIR=1 \
    PIP_DEFAULT_TIMEOUT=120 \
    PIP_DISABLE_PIP_VERSION_CHECK=1
RUN python -m pip install --upgrade pip wheel setuptools && pip --version

RUN pip install --no-cache-dir -e . && \
    pip uninstall -y pycrdt datalayer_pycrdt && \
    pip install --no-cache-dir datalayer_pycrdt==0.12.17

EXPOSE 4040

ENTRYPOINT ["python", "-m", "jupyter_mcp_server"]

```

`LICENSE`:

```
BSD 3-Clause License

Copyright (c) 2025, Datalayer
All rights reserved.

Redistribution and use in source and binary forms, with or without
modification, are permitted provided that the following conditions are met:

1. Redistributions of source code must retain the above copyright notice, this
   list of conditions and the following disclaimer.

2. Redistributions in binary form must reproduce the above copyright notice,
   this list of conditions and the following disclaimer in the documentation
   and/or other materials provided with the distribution.

3. Neither the name of the copyright holder nor the names of its
   contributors may be used to endorse or promote products derived from
   this software without specific prior written permission.

THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.

```

`Makefile`:

```
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

SHELL=/bin/bash

.DEFAULT_GOAL := default

.PHONY: clean build

VERSION = 0.2

default: all ## default target is all

help: ## display this help
	@awk 'BEGIN {FS = ":.*##"; printf "\nUsage:\n  make \033[36m<target>\033[0m\n"} /^[a-zA-Z_-]+:.*?##/ { printf "  \033[36m%-15s\033[0m %s\n", $$1, $$2 } /^##@/ { printf "\n\033[1m%s\033[0m\n", substr($$0, 5) } ' $(MAKEFILE_LIST)

all: clean build ## clean and build

install:
	pip install .

dev:
	pip install ".[test,lint,typing]"

test: ## run the unit tests
	git checkout ./dev/content && \
	TEST_MCP_SERVER=true \
	TEST_JUPYTER_SERVER=true \
	pytest

test-mcp-server: ## run the unit tests for mcp server
	git checkout ./dev/content && \
	TEST_MCP_SERVER=true \
	TEST_JUPYTER_SERVER=false \
	pytest

test-jupyter-server: ## run the unit tests for jupyter server
	git checkout ./dev/content && \
	TEST_MCP_SERVER=false \
	TEST_JUPYTER_SERVER=true \
	pytest

test-integration: ## run the integration tests
	hatch test

build:
	pip install build
	python -m build .

clean: ## clean
	git clean -fdx

build-docker: ## build the docker image
	docker buildx build --platform linux/amd64,linux/arm64 --push -t datalayer/jupyter-mcp-server:${VERSION} .
	docker buildx build --platform linux/amd64,linux/arm64 --push -t datalayer/jupyter-mcp-server:latest .
#	docker image tag datalayer/jupyter-mcp-server:${VERSION} datalayer/jupyter-mcp-server:latest
	@exec echo open https://hub.docker.com/r/datalayer/jupyter-mcp-server/tags

start-docker: ## start the jupyter mcp server in docker
	docker run -i --rm \
	  -e JUPYTER_URL=http://localhost:8888 \
	  -e JUPYTER_TOKEN=MY_TOKEN \
	  -e START_NEW_RUNTIME=true \
	  --network=host \
	  datalayer/jupyter-mcp-server:latest

pull-docker: ## pull the latest docker image
	docker image pull datalayer/jupyter-mcp-server:latest

push-docker: ## push the docker image to the registry
	docker push datalayer/jupyter-mcp-server:${VERSION}
	docker push datalayer/jupyter-mcp-server:latest
	@exec echo open https://hub.docker.com/r/datalayer/jupyter-mcp-server/tags

claude-linux: ## run the claude desktop linux app using nix
	NIXPKGS_ALLOW_UNFREE=1 nix run github:k3d3/claude-desktop-linux-flake?rev=6d9eb2a653be8a6c06bc29a419839570e0ffc858 \
		--impure \
		--extra-experimental-features flakes \
		--extra-experimental-features nix-command

start: ## start the jupyter mcp server with streamable-http transport
	@exec echo
	@exec echo curl http://localhost:4040/api/healthz
	@exec echo
	@exec echo ğŸ‘‰ Define in your favorite mcp client the server http://localhost:4040/mcp
	@exec echo
	jupyter-mcp-server start \
	  --transport streamable-http \
	  --jupyter-url http://localhost:8888 \
	  --jupyter-token MY_TOKEN \
	  --start-new-runtime true \
	  --port 4040

start-empty: ## start the jupyter mcp server with streamable-http transport and no document nor runtime
	@exec echo
	@exec echo curl http://localhost:4040/api/healthz
	@exec echo
	@exec echo ğŸ‘‰ Define in your favorite mcp client the server http://localhost:4040/mcp
	@exec echo
	jupyter-mcp-server start \
	  --transport streamable-http \
	  --jupyter-url http://localhost:8888 \
	  --jupyter-token MY_TOKEN \
	  --start-new-runtime false \
	  --port 4040

start-jupyter-server-extension: ## start jupyter server with MCP extension
	@exec echo
	@exec echo ğŸš€ Starting Jupyter Server with MCP Extension
	@exec echo ğŸ“ Using local serverapp access - document_url=local, runtime_url=local
	@exec echo
	@exec echo ğŸ”— JupyterLab will be available at http://localhost:4040/lab
	@exec echo ğŸ”— MCP endpoints will be available at http://localhost:4040/mcp
	@exec echo
	@exec echo "Test with: curl http://localhost:4040/mcp/healthz"
	@exec echo
	jupyter lab \
	  --JupyterMCPServerExtensionApp.document_url local \
	  --JupyterMCPServerExtensionApp.runtime_url local \
	  --JupyterMCPServerExtensionApp.document_id notebook.ipynb \
	  --JupyterMCPServerExtensionApp.start_new_runtime True \
	  --ServerApp.disable_check_xsrf True \
	  --IdentityProvider.token MY_TOKEN \
	  --ServerApp.root_dir ./dev/content \
	  --port 4040

jupyterlab: ## start jupyterlab for the mcp server
	pip uninstall -y pycrdt datalayer_pycrdt
	pip install datalayer_pycrdt
	@exec echo
	@exec echo curl http://localhost:8888/lab?token=MY_TOKEN
	@exec echo
	jupyter lab \
		--port 8888 \
		--ip 0.0.0.0 \
		--ServerApp.root_dir ./dev/content \
		--IdentityProvider.token MY_TOKEN

publish-pypi: # publish the pypi package
	git clean -fdx && \
		python -m build
	@exec echo
	@exec echo twine upload ./dist/*-py3-none-any.whl
	@exec echo
	@exec echo https://pypi.org/project/jupyter-mcp-server/#history

```

`README.md`:

```md
<!--
  ~ Copyright (c) 2024- Datalayer, Inc.
  ~
  ~ BSD 3-Clause License
-->

[![Datalayer](https://images.datalayer.io/brand/logos/datalayer-horizontal.svg)](https://datalayer.io)

[![Become a Sponsor](https://img.shields.io/static/v1?label=Become%20a%20Sponsor&message=%E2%9D%A4&logo=GitHub&style=flat&color=1ABC9C)](https://github.com/sponsors/datalayer)

<div align="center">

<!-- omit in toc -->

# ğŸªğŸ”§ Jupyter MCP Server

**An [MCP](https://modelcontextprotocol.io) server developed for AI to connect and manage Jupyter Notebooks in real-time**

*Developed by [Datalayer](https://github.com/datalayer)*

[![PyPI - Version](https://img.shields.io/pypi/v/jupyter-mcp-server?style=for-the-badge&logo=pypi&logoColor=white)](https://pypi.org/project/jupyter-mcp-server)
[![Total PyPI downloads](https://img.shields.io/pepy/dt/jupyter-mcp-server?style=for-the-badge&logo=python&logoColor=white)](https://pepy.tech/project/jupyter-mcp-server)
[![Docker Pulls](https://img.shields.io/docker/pulls/datalayer/jupyter-mcp-server?style=for-the-badge&logo=docker&logoColor=white&color=2496ED)](https://hub.docker.com/r/datalayer/jupyter-mcp-server)
[![License](https://img.shields.io/badge/License-BSD_3--Clause-blue?style=for-the-badge&logo=open-source-initiative&logoColor=white)](https://opensource.org/licenses/BSD-3-Clause)


![Jupyter MCP Server Demo](https://images.datalayer.io/products/jupyter-mcp-server/mcp-demo-multimodal.gif)

</div>

> [!NOTE]
> **We Need Your Feedback!**
> 
> We're actively developing support for **JupyterHub** and **Google Colab** deployments. If you're using or planning to use Jupyter MCP Server with these platforms, we'd love to hear from you!
> 
> - ğŸ¢ **JupyterHub users**: Share your deployment setup and requirements
> - ğŸŒ **Google Colab users**: Help us understand your use cases and workflows
> 
> Join the conversation in our [Community page](https://jupyter-mcp-server.datalayer.tech/community) - your feedback will help us prioritize features and ensure these integrations work seamlessly for your needs.

## ğŸ“– Table of Contents

- [Key Features](#-key-features)
- [MCP Overview](#-mcp-overview)
- [Getting Started](#-getting-started)
- [Best Practices](#-best-practices)
- [Contributing](#-contributing)
- [Resources](#-resources)

## ğŸš€ Key Features

- âš¡ **Real-time control:** Instantly view notebook changes as they happen.
- ğŸ” **Smart execution:** Automatically adjusts when a cell run fails thanks to cell output feedback.
- ğŸ§  **Context-aware:** Understands the entire notebook context for more relevant interactions.
- ğŸ“Š **Multimodal support:** Support different output types, including images, plots, and text.
- ğŸ“š **Multi-notebook support:** Seamlessly switch between multiple notebooks.
- ğŸ¨ **JupyterLab integration:** Enhanced UI integration like automatic notebook opening.
- ğŸ¤ **MCP-compatible:** Works with any MCP client, such as Claude Desktop, Cursor, Windsurf, and more.

Compatible with any Jupyter deployment (local, JupyterHub, ...) and with [Datalayer](https://datalayer.ai) hosted Notebooks.


## ğŸ”§ MCP Overview

### ğŸ”§ Tools Overview

The server provides a rich set of tools for interacting with Jupyter notebooks, categorized as follows. 
For more details on each tool, their parameters, and return values, please refer to the [official Tools documentation](https://jupyter-mcp-server.datalayer.tech/tools).


#### Server Management Tools

| Name             | Description                                                                                |
| :--------------- | :----------------------------------------------------------------------------------------- |
| `list_files`     | List files and directories in the Jupyter server's file system.                            |
| `list_kernels`   | List all available and running kernel sessions on the Jupyter server.                      |
| `connect_to_jupyter` | Connect to a Jupyter server dynamically without restarting the MCP server. *Not available when running as Jupyter extension. Useful for switching servers dynamically or avoiding hardcoded configuration.* [Read more](https://jupyter-mcp-server.datalayer.tech/reference/tools/#3-connect_to_jupyter) |

#### Multi-Notebook Management Tools

| Name               | Description                                                                              |
| :----------------- | :--------------------------------------------------------------------------------------- |
| `use_notebook`     | Connect to a notebook file, create a new one, or switch between notebooks.               |
| `list_notebooks`   | List all notebooks available on the Jupyter server and their status                      |
| `restart_notebook` | Restart the kernel for a specific managed notebook.                                      |
| `unuse_notebook`   | Disconnect from a specific notebook and release its resources.                           |
| `read_notebook`    | Read notebook cells source content with brief or detailed format options.                |

#### Cell Operations and Execution Tools

| Name                       | Description                                                                      |
| :------------------------- | :------------------------------------------------------------------------------- |
| `read_cell`                | Read the full content (Metadata, Source and Outputs) of a single cell.           |
| `insert_cell`              | Insert a new code or markdown cell at a specified position.                      |
| `delete_cell`              | Delete a cell at a specified index.                                              |
| `overwrite_cell_source`    | Overwrite the source code of an existing cell.                                   |
| `execute_cell`             | Execute a cell with timeout, supports multimodal output including images.        |
| `insert_execute_code_cell` | Insert a new code cell and execute it in one step.                               |
| `execute_code`             | Execute code directly in the kernel, supports magic commands and shell commands. |

#### JupyterLab Integration

*Available only when JupyterLab mode is enabled. It is enabled by default.*

When running in JupyterLab mode, Jupyter MCP Server integrates with [jupyter-mcp-tools](https://github.com/datalayer/jupyter-mcp-tools) to expose additional JupyterLab commands as MCP tools. By default, the following tools are enabled:

| Name                          | Description                                                                        |
| :---------------------------- | :--------------------------------------------------------------------------------- |
| `notebook_run-all-cells`      | Execute all cells in the current notebook sequentially                             |
| `notebook_get-selected-cell`  | Get information about the currently selected cell                                   |

<details>
<summary><strong>ğŸ“š Learn how to customize additional tools</strong></summary>

You can now customize which tools from `jupyter-mcp-tools` are available using the `allowed_jupyter_mcp_tools` configuration parameter. This allows you to enable additional notebook operations, console commands, file management tools, and more.

```bash
# Example: Enable additional tools via command-line
jupyter lab --port 4040 --IdentityProvider.token MY_TOKEN --JupyterMCPServerExtensionApp.allowed_jupyter_mcp_tools="notebook_run-all-cells,notebook_get-selected-cell,notebook_append-execute,console_create"
```

For the complete list of available tools and detailed configuration instructions, please refer to the [Additional Tools documentation](https://jupyter-mcp-server.datalayer.tech/reference/tools-additional).

</details>

### ğŸ“ Prompt Overview

The server also supports [prompt feature](https://modelcontextprotocol.io/specification/2025-06-18/server/prompts) of MCP, providing a easy way for user to interact with Jupyter notebooks.

| Name           | Description                                                                        |
| :------------- | :--------------------------------------------------------------------------------- |
| `jupyter-cite` | Cite specific cells from specified notebook (like `@` in Coding IDE or CLI)        |

For more details on each prompt, their input parameters, and return content, please refer to the [official Prompt documentation](https://jupyter-mcp-server.datalayer.tech/reference/prompts).

## ğŸ Getting Started

For comprehensive setup instructionsâ€”including `Streamable HTTP` transport, running as a Jupyter Server extension and advanced configurationâ€”check out [our documentation](https://jupyter-mcp-server.datalayer.tech/). Or, get started quickly with `JupyterLab` and `STDIO` transport here below.

### 1. Set Up Your Environment

```bash
pip install jupyterlab==4.4.1 jupyter-collaboration==4.0.2 jupyter-mcp-tools>=0.1.4 ipykernel
pip uninstall -y pycrdt datalayer_pycrdt
pip install datalayer_pycrdt==0.12.17
```

> [!TIP]
> To confirm your environment is correctly configured:
> 1. Open a notebook in JupyterLab
> 2. Type some content in any cell (code or markdown)
> 3. Observe the tab indicator: you should see an "Ã—" appear next to the notebook name, indicating unsaved changes
> 4. Wait a few secondsâ€”the "Ã—" should automatically change to a "â—" without manually saving
> 
> This automatic saving behavior confirms that the real-time collaboration features are working properly, which is essential for MCP server integration.

### 2. Start JupyterLab

```bash
# Start JupyterLab on port 8888, allowing access from any IP and setting a token
jupyter lab --port 8888 --IdentityProvider.token MY_TOKEN --ip 0.0.0.0
```

> [!NOTE]
> If you are running notebooks through JupyterHub instead of JupyterLab as above, refer to our [JupyterHub setup guide](https://jupyter-mcp-server.datalayer.tech//providers/jupyterhub-streamable-http/).

### 3. Configure Your Preferred MCP Client

Next, configure your MCP client to connect to the server. We offer two primary methodsâ€”choose the one that best fits your needs:

- **ğŸ“¦ Using `uvx` (Recommended for Quick Start):** A lightweight and fast method using `uv`. Ideal for local development and first-time users.
- **ğŸ³ Using `Docker` (Recommended for Production):** A containerized approach that ensures a consistent and isolated environment, perfect for production or complex setups.

<details>
<summary><b>ğŸ“¦ Using uvx (Quick Start)</b></summary>

First, install `uv`:

```bash
pip install uv
uv --version
# should be 0.6.14 or higher
```

See more details on [uv installation](https://docs.astral.sh/uv/getting-started/installation/).

Then, configure your client:

```json
{
  "mcpServers": {
    "jupyter": {
      "command": "uvx",
      "args": ["jupyter-mcp-server@latest"],
      "env": {
        "JUPYTER_URL": "http://localhost:8888",
        "JUPYTER_TOKEN": "MY_TOKEN",
        "ALLOW_IMG_OUTPUT": "true"
      }
    }
  }
}
```

</details>

<details>
<summary><b>ğŸ³ Using Docker (Production)</b></summary>

**On macOS and Windows:**

```json
{
  "mcpServers": {
    "jupyter": {
      "command": "docker",
      "args": [
        "run", "-i", "--rm",
        "-e", "JUPYTER_URL",
        "-e", "JUPYTER_TOKEN",
        "-e", "ALLOW_IMG_OUTPUT",
        "datalayer/jupyter-mcp-server:latest"
      ],
      "env": {
        "JUPYTER_URL": "http://host.docker.internal:8888",
        "JUPYTER_TOKEN": "MY_TOKEN",
        "ALLOW_IMG_OUTPUT": "true"
      }
    }
  }
}
```

**On Linux:**

```json
{
  "mcpServers": {
    "jupyter": {
      "command": "docker",
      "args": [
        "run", "-i", "--rm",
        "-e", "JUPYTER_URL",
        "-e", "JUPYTER_TOKEN",
        "-e", "ALLOW_IMG_OUTPUT",
        "--network=host",
        "datalayer/jupyter-mcp-server:latest"
      ],
      "env": {
        "JUPYTER_URL": "http://localhost:8888",
        "JUPYTER_TOKEN": "MY_TOKEN",
        "ALLOW_IMG_OUTPUT": "true"
      }
    }
  }
}
```

</details>

> [!TIP]
>
> 1. **Port Configuration**: Ensure the `port` in your Jupyter URLs matches the one used in the `jupyter lab` command. For simplified config, set this in `JUPYTER_URL`.
> 1. **Server Separation**: Use `JUPYTER_URL` when both services are on the same server, or set individual variables for advanced deployments. The different URL variables exist because some deployments separate notebook storage (`DOCUMENT_URL`) from kernel execution (`RUNTIME_URL`).
> 1. **Authentication**: In most cases, document and runtime services use the same authentication token. Use `JUPYTER_TOKEN` for simplified config or set `DOCUMENT_TOKEN` and `RUNTIME_TOKEN` individually for different credentials.
> 1. **Notebook Path**: The `DOCUMENT_ID` parameter specifies the path to the notebook the MCP client default to connect. It should be relative to the directory where JupyterLab was started. If you omit `DOCUMENT_ID`, the MCP client can automatically list all available notebooks on the Jupyter server, allowing you to select one interactively via your prompts.
> 1. **Image Output**: Set `ALLOW_IMG_OUTPUT` to `false` if your LLM does not support mutimodel understanding.

For detailed instructions on configuring various MCP clientsâ€”including [Claude Desktop](https://jupyter-mcp-server.datalayer.tech/clients/claude_desktop), [VS Code](https://jupyter-mcp-server.datalayer.tech/clients/vscode), [Cursor](https://jupyter-mcp-server.datalayer.tech/clients/cursor), [Cline](https://jupyter-mcp-server.datalayer.tech/clients/cline), and [Windsurf](https://jupyter-mcp-server.datalayer.tech/clients/windsurf) â€” see the [Clients documentation](https://jupyter-mcp-server.datalayer.tech/clients).

## âœ… Best Practices

- Interact with LLMs that supports multimodal input (like Gemini 2.5 Pro) to fully utilize advanced multimodal understanding capabilities.
- Use a MCP client that supports returning image data and can parse it (like Cursor, Gemini CLI, etc.), as some clients may not support this feature.
- Break down complex task (like the whole data science workflow) into multiple sub-tasks (like data cleaning, feature engineering, model training, model evaluation, etc.) and execute them step-by-step.
- Provide clearly structured prompts and rules (ğŸ‘‰ Visit our [Prompt Templates](prompt/README.md) to get started)
- Provide as much context as possible (like already installed packages, field explanations for existing datasets, current working directory, detailed task requirements, etc.).

## ğŸ¤ Contributing

We welcome contributions of all kinds! Here are some examples:

- ğŸ› Bug fixes
- ğŸ“ Improvements to existing features
- ğŸ”§ New feature development
- ğŸ“š Documentation improvements and prompt templates

For detailed instructions on how to get started with development and submit your contributions, please see our [**Contributing Guide**](CONTRIBUTING.md).

### Our Contributors

[![Contributors](https://contrib.rocks/image?repo=datalayer/jupyter-mcp-server)](https://github.com/datalayer/jupyter-mcp-server/graphs/contributors)

## ğŸ“š Resources

Looking for blog posts, videos, or other materials about Jupyter MCP Server?

ğŸ‘‰ Visit the [**Resources section**](https://jupyter-mcp-server.datalayer.tech/resources) in our documentation for more!

[![Star History Chart](https://api.star-history.com/svg?repos=datalayer/jupyter-mcp-server&type=Date)](https://star-history.com/#datalayer/jupyter-mcp-server&type=Date)

______________________________________________________________________

<div align="center">

**If this project is helpful to you, please give us a â­ï¸**

Made with â¤ï¸ by [Datalayer](https://github.com/datalayer)

</div>

```

`RELEASE.md`:

```md
<!--
  ~ Copyright (c) 2024- Datalayer, Inc.
  ~
  ~ BSD 3-Clause License
-->

# ğŸš€ Jupyter MCP Server Release Guide

This document provides detailed instructions on how to release the Jupyter MCP Server project using GitHub Actions.

## ğŸ“‹ Release Process Overview

The release process is defined in the `.github/workflows/release.yml` file and includes the following automated steps:

1. **Python Package Build** - Build distribution packages (wheel and source distribution)
2. **PyPI Publishing** - Automatically publish to PyPI (using OIDC trusted publishing)
3. **Docker Image Build** - Build multi-platform Docker images
4. **GitHub Release Creation** - Automatically generate release notes (simplified version, without automatic changelog)

## ğŸ”– Version Management

### Semantic Versioning
The project uses semantic versioning format: `v{major}.{minor}.{patch}`

Examples:
- `v1.0.0` - Major version update
- `v1.1.0` - Minor feature update
- `v1.1.1` - Patch and bug fixes

### Version Tags
For releases, you need to push Git tags with version numbers:

```bash
# Create and push version tag
git tag v1.0.0
git push origin v1.0.0
```

## âš™ï¸ Release Workflow Trigger Conditions

The workflow is automatically triggered when:
- Pushing Git tags in the format `v*.*.*` (e.g., `v1.0.0`, `v2.1.3`)

**Configuration Steps:**

1. Configure Trusted Publisher in PyPI project settings
   - Go to https://pypi.org/manage/project/jupyter-mcp-server/settings/publishing/
   - Add GitHub Actions as a trusted publisher
   - Configure:
     - Owner: `datalayer`
     - Repository: `jupyter-mcp-server`
     - Workflow: `release.yml`
     - Environment: `pypi`

2. GitHub repository settings
   - Settings â†’ Environments â†’ New environment: `pypi`
   - Configure protection rules (optional):
     - Required reviewers (requires approval)
     - Branch protection (only allows main branch)

Creating access token in Docker Hub:
- Settings â†’ Security â†’ Access Tokens
- Create restricted token (read/write only specific repository)
- Store as GitHub Secret:
    - `DOCKERHUB_USERNAME` - Docker Hub username
    - `DOCKERHUB_TOKEN` - Docker Hub access token

### GitHub Release
- Uses built-in `GITHUB_TOKEN`, no additional configuration required

## ğŸ“¦ Release Artifacts

### Python Package
- **PyPI**: `https://pypi.org/project/jupyter-mcp-server/`
- **Formats**: wheel (`.whl`) and source distribution (`.tar.gz`)

### Docker Image
- **Repository**: `datalayer/jupyter-mcp-server`
- **Tags**:
  - `latest` - Latest stable version
  - `{version}` - Specific version number (e.g., `1.0.0`)

## ğŸ”„ Release Steps

1. **Update Version Number**
   ```bash
   # Edit version file
   vim jupyter_mcp_server/__version__.py
   ```

2. **Create Release Tag**
   ```bash
   git tag v1.0.0
   git push origin v1.0.0
   ```

3. **Monitor Release Progress**
   - Go to GitHub Actions page to view workflow run status
   - Check if PyPI has been updated
   - Verify Docker Hub has new images

## ğŸ”„ Version Rollback

If serious issues occur during release:

1. **Delete GitHub Release** (if created)
2. **Delete package from PyPI** (if published) - Requires admin privileges
3. **Delete Docker image tags from Docker Hub**
4. **Push new tag to re-release**

```

`dev/README.md`:

```md
<!--
  ~ Copyright (c) 2024- Datalayer, Inc.
  ~
  ~ BSD 3-Clause License
-->

[![Datalayer](https://images.datalayer.io/brand/logos/datalayer-horizontal.svg)](https://datalayer.io)

[![Become a Sponsor](https://img.shields.io/static/v1?label=Become%20a%20Sponsor&message=%E2%9D%A4&logo=GitHub&style=flat&color=1ABC9C)](https://github.com/sponsors/datalayer)

```

`dev/content/README.md`:

```md
<!--
  ~ Copyright (c) 2024- Datalayer, Inc.
  ~
  ~ BSD 3-Clause License
-->

[![Datalayer](https://images.datalayer.io/brand/logos/datalayer-horizontal.svg)](https://datalayer.io)

[![Become a Sponsor](https://img.shields.io/static/v1?label=Become%20a%20Sponsor&message=%E2%9D%A4&logo=GitHub&style=flat&color=1ABC9C)](https://github.com/sponsors/datalayer)

```

`dev/content/new.ipynb`:

```ipynb
Jupyter Notebook Summary:
Total cells: 3 (2 code, 1 markdown, 0 raw)

Code Cell #1:
```python
print("Hello, World!")
```

Code Cell #2:
```python

```


```

`dev/content/notebook.ipynb`:

```ipynb
Jupyter Notebook Summary:
Total cells: 10 (6 code, 4 markdown, 0 raw)

Code Cell #1:
```python
import matplotlib.pyplot as plt
import numpy as np
import pandas as pd

# Set up matplotlib for inline plotting
%matplotlib inline

print("Libraries imported successfully!")
```

Code Cell #2:
```python
# Generate sample data
x = np.linspace(0, 10, 100)
y = np.sin(x)

# Create a basic line plot
plt.figure(figsize=(10, 6))
plt.plot(x, y)
plt.title('Basic Sine Wave')
plt.xlabel('X values')
plt.ylabel('Y values')
plt.grid(True)
plt.show()
```

Code Cell #3:
```python
# Generate multiple datasets
x = np.linspace(0, 10, 100)
y1 = np.sin(x)
y2 = np.cos(x)
y3 = np.sin(x) * np.cos(x)

# Create customized plot
plt.figure(figsize=(12, 8))
plt.plot(x, y1, 'b-', linewidth=2, label='sin(x)', marker='o', markersize=4, alpha=0.8)
plt.plot(x, y2, 'r--', linewidth=2, label='cos(x)', marker='s', markersize=4, alpha=0.8)
plt.plot(x, y3, 'g:', linewidth=3, label='sin(x)*cos(x)', marker='^', markersize=4, alpha=0.8)

plt.title('Multiple Trigonometric Functions', fontsize=16, fontweight='bold')
plt.xlabel('X values', fontsize=12)
plt.ylabel('Y values', fontsize=12)
plt.legend(fontsize=12)
plt.grid(True, alpha=0.3)
plt.xlim(0, 10)
plt.ylim(-1.5, 1.5)
plt.show()
```

... [3 more code cells omitted]

```

`docs/.gitignore`:

```
# Dependencies
/node_modules

# Production
/build

# Generated files
.docusaurus
.cache-loader

# Misc
.DS_Store
.env.local
.env.development.local
.env.test.local
.env.production.local

npm-debug.log*
yarn-debug.log*
yarn-error.log*

*.lock

```

`docs/.yarnrc.yml`:

```yml
# Copyright (c) Datalayer, Inc. https://datalayer.io
# Distributed under the terms of the MIT License.

enableImmutableInstalls: false
enableInlineBuilds: false
enableTelemetry: false
httpTimeout: 60000
nodeLinker: node-modules
npmRegistryServer: "https://registry.yarnpkg.com"
checksumBehavior: update

# This will fix the build error with @lerna/legacy-package-management
# See https://github.com/lerna/repro/pull/11
packageExtensions:
  "@lerna/legacy-package-management@*":
    dependencies:
      "@lerna/child-process": "*"
      "js-yaml": "*"
      "rimraf": "*"
    peerDependencies:
      "nx": "*"
```

`docs/LICENSE`:

```
Copyright (c) 2021-2023 Datalayer, Inc.

MIT License

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED *AS IS*, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

```

`docs/Makefile`:

```
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

# Copyright (c) Datalayer, Inc. https://datalayer.io
# Distributed under the terms of the MIT License.

SHELL=/bin/bash

.DEFAULT_GOAL := deploy

CONDA_ACTIVATE=source $$(conda info --base)/etc/profile.d/conda.sh ; conda activate
CONDA_DEACTIVATE=source $$(conda info --base)/etc/profile.d/conda.sh ; conda deactivate
CONDA_REMOVE=source $$(conda info --base)/etc/profile.d/conda.sh ; conda remove -y --all -n

ENV_NAME=datalayer

.SILENT: init install

.PHONY: build deploy

help: ## display this help
	@awk 'BEGIN {FS = ":.*##"; printf "\nUsage:\n  make \033[36m<target>\033[0m\n"} /^[a-zA-Z_-]+:.*?##/ { printf "  \033[36m%-15s\033[0m %s\n", $$1, $$2 } /^##@/ { printf "\n\033[1m%s\033[0m\n", substr($$0, 5) } ' $(MAKEFILE_LIST)

default: help ## default target is help

env-rm:
	-conda remove -y --all -n ${ENV_NAME}

env:
	-conda env create -f environment.yml
	@echo 
	@echo --------------------------------------------------
	@echo ğŸ”§  Datalayer environment is created.
	@echo --------------------------------------------------
	@echo

clean: ## clear
	($(CONDA_ACTIVATE) ${ENV_NAME}; \
	  npm clear )

install: ## install
	($(CONDA_ACTIVATE) ${ENV_NAME}; \
	  npm install )

start: ## start
	($(CONDA_ACTIVATE) ${ENV_NAME}; \
	  npm start )

build: ## build
	($(CONDA_ACTIVATE) ${ENV_NAME}; \
	  npm run build )

deploy: build ## deploy
	($(CONDA_ACTIVATE) ${ENV_NAME}; \
	  aws s3 rm \
			s3://datalayer-jupyter-mcp-server/ \
			--recursive \
			--profile datalayer && \
	  aws s3 cp \
			./build \
			s3://datalayer-jupyter-mcp-server/ \
			--recursive \
			--profile datalayer && \
	  aws cloudfront create-invalidation \
			--distribution-id EP7AV0D2EWHSX \
			--paths "/*" \
			--profile datalayer && \
	echo open ğŸ”§  https://jupyter-mcp-server.datalayer.tech )

```

`docs/README.md`:

```md
<!--
  ~ Copyright (c) 2024- Datalayer, Inc.
  ~
  ~ BSD 3-Clause License
-->

[![Datalayer](https://images.datalayer.io/brand/logos/datalayer-horizontal.svg)](https://datalayer.io)

[![Become a Sponsor](https://img.shields.io/static/v1?label=Become%20a%20Sponsor&message=%E2%9D%A4&logo=GitHub&style=flat&color=1ABC9C)](https://github.com/sponsors/datalayer)

# Jupyter MCP Server Docs

> Source code for the [Jupyter MCP Server Documentation](https://datalayer.io), built with [Docusaurus](https://docusaurus.io).

```bash
# Install the dependencies.
conda install yarn
yarn
```

```bash
# Local Development: This command starts a local development server and opens up a browser window.
# Most changes are reflected live without having to restart the server.
npm start
```

```

`docs/babel.config.js`:

```js
/*
 * Copyright (c) 2024- Datalayer, Inc.
 *
 * BSD 3-Clause License
 */

module.exports = {
  presets: [require.resolve('@docusaurus/core/lib/babel/preset')],
};

```

`docs/docs/_category_.yaml`:

```yaml
label: "Overview"
position: 1

```

`docs/docs/clients/_category_.yaml`:

```yaml
label: "Clients"
position: 5

```

`docs/docs/clients/claude_desktop/_category_.yaml`:

```yaml
label: "Claude Desktop"
position: 1

```

`docs/docs/clients/claude_desktop/index.mdx`:

```mdx
# Claude Desktop

![Jupyter MCP Server](https://images.datalayer.io/products/jupyter-mcp-server/mcp-demo-multimodal.gif)

## Install Claude Desktop

Claude Desktop can be downloaded [from this page](https://claude.ai/download) for macOS and Windows.

For Linux, we had success using this [UNOFFICIAL build script based on nix](https://github.com/k3d3/claude-desktop-linux-flake)

```bash
# âš ï¸ UNOFFICIAL
# You can also run `make claude-linux`
NIXPKGS_ALLOW_UNFREE=1 nix run github:k3d3/claude-desktop-linux-flake \
  --impure \
  --extra-experimental-features flakes \
  --extra-experimental-features nix-command
```

## Configure Jupyter MCP Server

To use Jupyter MCP Server with Claude Desktop, add the [Jupyter MCP Server configuration](/providers/jupyter-stdio#2-setup-jupyter-mcp-server) to your `claude_desktop_config.json` file, read more on the [MCP documentation website](https://modelcontextprotocol.io/quickstart/user#2-add-the-filesystem-mcp-server).

**ğŸ“º Watch the setup demo**

<iframe width="560" height="315" src="https://www.youtube.com/embed/nPllCQxtaxQ" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen />

```

`docs/docs/clients/cline/_category_.yaml`:

```yaml
label: "Cline"
position: 4

```

`docs/docs/clients/cline/index.mdx`:

```mdx
# Cline

![](https://images.datalayer.io/products/jupyter-mcp-server/cline.png)

## Install Cline VS Code extension

Install the Cline VS Code extension from the [VS Code Marketplace](https://marketplace.visualstudio.com/items?itemName=saoudrizwan.claude-dev).

## Configure Jupyter MCP Server

To use Jupyter MCP Server with Cline, add the [Jupyter MCP Server configuration](/providers/jupyter-stdio#2-setup-jupyter-mcp-server) to your `.cline_mcp_settings.json` file, read more on the [Cline documentation](https://marketplace.visualstudio.com/items?itemName=saoudrizwan.claude-dev).

```

`docs/docs/clients/cursor/_category_.yaml`:

```yaml
label: "Cursor"
position: 3

```

`docs/docs/clients/cursor/index.mdx`:

```mdx
# Cursor

![](https://images.datalayer.io/products/jupyter-mcp-server/cursor.png)

## Install Cursor

Install the Cursor app from the [Cursor website](https://www.cursor.com/downloads).

## Configure Jupyter MCP Server

To use Jupyter MCP Server with Cursor, add the [Jupyter MCP Server configuration](/providers/jupyter-stdio#2-setup-jupyter-mcp-server) to your `.cursor/mcp.json` file, read more on the [MCP Cursor documentation website](https://docs.cursor.com/context/model-context-protocol#configuring-mcp-servers).

```

`docs/docs/clients/index.mdx`:

```mdx
# Clients

We have tested and validated the Jupyter MCP Server with the following clients:

- [Claude Desktop](./claude_desktop)
- [VS Code](./vscode)
- [Cursor](./cursor)
- [Cline](./cline)
- [Windsurf](./windsurf)

The Jupyter MCP Server is also compatible with **ANY** MCP client â€” see the growing list in [MCP clients](https://modelcontextprotocol.io/clients). This means that you are **NOT** limited to the clients listed above. Both [STDIO](https://modelcontextprotocol.io/specification/2025-06-18/basic/transports#stdio) and [streamable HTTP](https://modelcontextprotocol.io/specification/2025-06-18/basic/transports#streamable-http) transports are supported.

If you prefer a CLI approach as client, you can use for example the python [mcp-client-cli](https://github.com/adhikasp/mcp-client-cli) package.

```

`docs/docs/clients/vscode/_category_.yaml`:

```yaml
label: "VS Code"
position: 2

```

`docs/docs/clients/vscode/index.mdx`:

```mdx
# VS Code

You can find the complete VS Code MCP documentation [here](https://code.visualstudio.com/docs/copilot/chat/mcp-servers#_use-mcp-tools-in-agent-mode).

## Install VS Code

Download VS Code from the [official site](https://code.visualstudio.com/Download) and install it.

## Install GitHub Copilot Extension

To use MCP tools and Agent mode in VS Code, you need an active [GitHub Copilot](https://github.com/features/copilot) subscription. Then, install the [GitHub Copilot Chat](https://marketplace.visualstudio.com/items?itemName=GitHub.copilot-chat) extension from the VS Code Marketplace.

## Configure Jupyter MCP Server

There are two ways to configure the Jupyter MCP Server in VS Code: user settings or workspace settings. Once configured, restart VS Code.

:::note

We explicitely use the name `DatalayerJupyter` as VS Code has already a `Jupyter` MCP Server configured by default for the VS Code built-in notebooks.

:::

### As User Settings in `settings.json`

Open your `settings.json`:

- Press `Ctrl+Shift+P` (or `âŒ˜â‡§P` on macOS) to open the **Command Palette**
- Type and select: **Preferences: Open Settings (JSON)**
  [Or click this command link inside VS Code](command:workbench.action.openSettingsJson)

Then add the following configuration:

**Simplified Configuration (Recommended):**
```jsonc
{
  "mcp": {
    "servers": {
    "DatalayerJupyter": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "-e",
        "JUPYTER_URL",
        "-e",
        "JUPYTER_TOKEN",
        "-e",
        "DOCUMENT_ID",
        "-e",
        "ALLOW_IMG_OUTPUT",
        "datalayer/jupyter-mcp-server:latest"
      ],
      "env": {
        "JUPYTER_URL": "http://host.docker.internal:8888",
        "JUPYTER_TOKEN": "MY_TOKEN",
        "DOCUMENT_ID": "notebook.ipynb",
        "ALLOW_IMG_OUTPUT": "true"
      }
    }
  }
}
```

<details>
<summary><b>Advanced Configuration (Optional)</b></summary>

For advanced deployments with separate document and runtime servers:

```jsonc
{
  "mcp": {
    "servers": {
    "DatalayerJupyter": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "-e",
        "DOCUMENT_URL",
        "-e",
        "DOCUMENT_TOKEN",
        "-e",
        "DOCUMENT_ID",
        "-e",
        "RUNTIME_URL",
        "-e",
        "RUNTIME_TOKEN",
        "-e",
        "ALLOW_IMG_OUTPUT",
        "datalayer/jupyter-mcp-server:latest"
      ],
      "env": {
        "DOCUMENT_URL": "http://host.docker.internal:8888",
        "DOCUMENT_TOKEN": "MY_TOKEN",
        "DOCUMENT_ID": "notebook.ipynb",
        "RUNTIME_URL": "http://host.docker.internal:8888",
        "RUNTIME_TOKEN": "MY_TOKEN",
        "ALLOW_IMG_OUTPUT": "true"
      }
    }
  }
}
```

</details>

Update with the actual configuration details from the [Jupyter MCP Server configuration](/providers/jupyter-stdio#2-setup-jupyter-mcp-server).

###  As Workspace Settings in `.vscode/mcp.json`

Open or create a `.vscode/mcp.json` file in your workspace root directory. Then add the following example configuration:

**Simplified Configuration (Recommended):**
```jsonc
{
  "servers": {
    "DatalayerJupyter": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "-e",
        "JUPYTER_URL",
        "-e",
        "JUPYTER_TOKEN",
        "-e",
        "DOCUMENT_ID",
        "-e",
        "ALLOW_IMG_OUTPUT",
        "datalayer/jupyter-mcp-server:latest"
      ],
      "env": {
        "JUPYTER_URL": "http://host.docker.internal:8888",
        "JUPYTER_TOKEN": "MY_TOKEN",
        "DOCUMENT_ID": "notebook.ipynb",
        "ALLOW_IMG_OUTPUT": "true"
      }
    }
  }
}
```

<details>
<summary><b>Advanced Configuration (Optional)</b></summary>

For advanced deployments with separate document and runtime servers:

```jsonc
{
  "servers": {
    "DatalayerJupyter": {
      "command": "docker",
      "args": [
        "run",
        "-i",
        "--rm",
        "-e",
        "DOCUMENT_URL",
        "-e",
        "DOCUMENT_TOKEN",
        "-e",
        "DOCUMENT_ID",
        "-e",
        "RUNTIME_URL",
        "-e",
        "RUNTIME_TOKEN",
        "-e",
        "ALLOW_IMG_OUTPUT",
        "datalayer/jupyter-mcp-server:latest"
      ],
      "env": {
        "DOCUMENT_URL": "http://host.docker.internal:8888",
        "DOCUMENT_TOKEN": "MY_TOKEN",
        "DOCUMENT_ID": "notebook.ipynb",
        "RUNTIME_URL": "http://host.docker.internal:8888",
        "RUNTIME_TOKEN": "MY_TOKEN",
        "ALLOW_IMG_OUTPUT": "true"
      }
    }
  }
}
```

</details>

Update with the actual configuration details from the [Jupyter MCP Server configuration](/providers/jupyter-stdio#2-setup-jupyter-mcp-server).

This enables workspace-specific configuration and sharing.

## Use MCP Tools in Agent Mode

1. Launch Copilot Chat (`Ctrl+Alt+I` / `âŒƒâŒ˜I`)
2. Switch to **Agent** mode from the dropdown
3. Click the **Tools** âš™ï¸ icon to manage Jupyter MCP Server tools
4. Use `#toolName` to invoke tools manually, or let Copilot invoke them automatically
5. Confirm tool actions when prompted (once or always)

```

`docs/docs/clients/windsurf/_category_.yaml`:

```yaml
label: "Windsurf"
position: 5

```

`docs/docs/clients/windsurf/index.mdx`:

```mdx
# Windsurf

![](https://images.datalayer.io/products/jupyter-mcp-server/windsurf.png)

## Install Windsurf

Install the Windsurf app from the [Windsurf website](https://windsurf.com/download).

## Configure Jupyter MCP Server

To use Jupyter MCP Server with Windsurf, add the [Jupyter MCP Server configuration](/providers/jupyter-stdio#2-setup-jupyter-mcp-server) to your `mcp_config.json` file, read more on the [MCP Windsurf documentation website](https://docs.windsurf.com/windsurf/cascade/mcp).

```

`docs/docs/community/_category_.yaml`:

```yaml
label: "Community"
position: 9

```

`docs/docs/community/community.mdx`:

```mdx
# Community

## Join the Community

Join the ğŸ’¬ **[Discord](https://discord.gg/YQFwvmSSuR)** - Chat with the team and community in real-time

Connect with the Jupyter MCP Server community and stay updated:

- ğŸ› **[GitHub Issues](https://github.com/datalayer/jupyter-mcp-server/issues)** - Report bugs, request features, or get help
- ğŸ¦ **[X (Twitter)](https://x.com/datalayerio)** - Follow us for updates and announcements
- ğŸ¦‹ **[Bluesky](https://bsky.app/profile/datalayer.ai)** - Connect with us on Bluesky

We welcome everyone to join our growing community!

## Contribute

We invite you to contribute by [opening issues](https://github.com/datalayer/jupyter-mcp-server/issues) and submitting [pull requests](https://github.com/datalayer/jupyter-mcp-server/pulls) for any question, problem or to discuss adding your solution as a provider.

We welcome contributions of all kinds, including:

- ğŸ› Bug fixes
- ğŸ“ Improvements to existing features or documentation
- ğŸ”§ New feature development

Your contributions help us improve the project and make it more useful for everyone!

See more in [CONTRIBUTING.md](https://github.com/datalayer/jupyter-mcp-server/blob/main/CONTRIBUTING.md)

```

`docs/docs/getting_started/_category_.yaml`:

```yaml
label: "Getting Started"
position: 2

```

`docs/docs/getting_started/index.mdx`:

```mdx
# Getting Started 

To use Jupyter MCP Server, you first need to decide which setup fits your needs:

- **MCP Server Location** - It can be running as a [**Standalone MCP Server**](/providers/jupyter-streamable-http-standalone) or inside the Jupyter Server [**as a Jupyter Server Extension**](/providers/jupyter-streamable-http-extension) - The last one has for advantage to avoid running 2 separate servers (Jupyter server + MCP server) but only supports Streamable HTTP transport.
- **MCP Transport** - It supports both [**STDIO Transport**](/providers/jupyter-stdio) and **Streamable HTTP Transport**
- **Jupyter Provider** - It can connect to a **local or remote Jupyter server**, to [**JupyterHub**](/providers/jupyterhub-streamable-http), to [**Datalayer**](/providers/datalayer) or to [**Google Colab**](/providers/google-colab) hosted Notebooks.

This guide will help you set up a Jupyter MCP Server to connect your preferred MCP client to a JupyterLab instance.

The Jupyter MCP Server acts as a bridge between the MCP client and the JupyterLab server, allowing you to interact with Jupyter notebooks seamlessly.

You can customize the setup further based on your requirements. Refer to the [server configuration](/reference/configuration) for more details on the possible configurations.

## Choosing Your Transport

Jupyter MCP Server supports two types of transport to connect to your MCP client: **STDIO** and **Streamable HTTP**. Choose the one that best fits your needs.

For more details on the different transports, refer to the official MCP documentation [here](https://modelcontextprotocol.io/specification/2025-06-18/basic/transports).

### STDIO Transport

**Best for:** Desktop applications, Docker deployments, single-user setups

- âœ… Simple configuration
- âœ… Works with most MCP clients (Claude Desktop, Cursor, Windsurf, VS Code)
- âœ… No additional server ports needed
- âŒ One client connection at a time

ğŸ‘‰ [Get started with STDIO Transport](/providers/jupyter-stdio)

### Streamable HTTP Transport

**Best for:** Web applications, multiple concurrent clients, production deployments

- âœ… Multiple clients can connect simultaneously
- âœ… Web-based access
- âœ… Can run as Jupyter Server Extension (no separate MCP server process)
- âŒ Requires opening network ports

If you choose Streamable HTTP transport, you can also choose to run the MCP server:

- [**As a Jupyter Server Extension**](/providers/jupyter-streamable-http-extension) - MCP server runs inside Jupyter (recommended, simpler setup)
- [**As a Standalone Server**](/providers/jupyter-streamable-http-standalone) - MCP server runs as a separate process

## Provider Options

### Local/Remote Jupyter Server

Connect to any standard JupyterLab or Jupyter Notebook server.

ğŸ‘‰ Choose your transport:
- [STDIO Transport](/providers/jupyter-stdio)
- [Streamable HTTP (Standalone)](/providers/jupyter-streamable-http-standalone)
- [Streamable HTTP (Extension)](/providers/jupyter-streamable-http-extension)

### JupyterHub

Multi-user deployments with authentication and resource management.

ğŸ‘‰ [JupyterHub Setup Guide](/providers/jupyterhub-streamable-http)

:::tip Multi-User Deployments
If you're deploying for multiple users, see the [Multi-User Documentation](/reference/multi-users) for architecture patterns and best practices.
:::

### Datalayer Platform

Enterprise-grade hosted Jupyter with built-in collaboration and security features.

ğŸ‘‰ [Datalayer Provider Documentation](/providers/datalayer)

### Google Colab

Connect to Google Colab notebooks (experimental).

ğŸ‘‰ [Google Colab Provider Documentation](/providers/google-colab)

## MCP Client Configuration

Once you've set up your MCP server, you need to configure your MCP client. Choose your client:

- [Claude Desktop](/clients/claude_desktop) - Anthropic's desktop app
- [VS Code](/clients/vscode) - GitHub Copilot integration
- [Cursor](/clients/cursor) - AI-first code editor
- [Cline](/clients/cline) - VS Code extension
- [Windsurf](/clients/windsurf) - Collaborative coding environment

## Next Steps

After setting up your MCP server and client:

ğŸ”§ **Explore Available Tools** - Learn about the [MCP tools](/reference/tools) for interacting with notebooks

ğŸ“ **Use Prompts** - Discover [prompt features](/reference/prompts) for citing and referencing notebooks

ğŸ”’ **Secure Your Deployment** - Review [security best practices](/reference/security) for token management and authentication

ğŸ“š **Learn More** - Check out the [Resources](/resources) section for tutorials, videos, and community content

## Additional Resources

- [Configuration Reference](/reference/configuration) - Complete environment variable and CLI option documentation
- [Community](/community) - Join discussions, get help, and connect with other users
- [Releases](/releases) - See what's new in each version

```

`docs/docs/index.mdx`:

```mdx
---
title: Overview
sidebar_position: 1
hide_table_of_contents: false
slug: /
---

# About Jupyter MCP Server

**Jupyter MCP Server** is a [Model Context Protocol](https://modelcontextprotocol.io) (MCP) server implementation that enables **real-time** interaction with ğŸ““ Jupyter Notebooks, allowing AI to edit, document and execute code for data analysis, visualization etc.
It is compatible with any [Jupyter](https://jupyter.org) deployment (local, JupyterHub, ...) and with [Datalayer](https://datalayer.ai) hosted Notebooks. Key features include:

- âš¡ **Real-time control:** Instantly view notebook changes as they happen.
- ğŸ” **Smart execution:** Automatically adjusts when a cell run fails thanks to cell output feedback.
- ğŸ§  **Context-aware:** Understands the entire notebook context for more relevant interactions.
- ğŸ“Š **Multimodal support:** Support different output types, including images, plots, and text.
- ğŸ“ **Multi-notebook support:** Seamlessly switch between multiple notebooks.
- ğŸ›ï¸ **JupyterLab integration:** Enhanced UI integration like automatic notebook opening.
- ğŸ¤ **MCP-compatible:** Works with any MCP client, such as [Claude Desktop](/clients/claude_desktop), [Cursor](/clients/cursor), [Cline](/clients/cline), [Windsurf](/clients/windsurf) and more.

<div style={{textAlign: 'center', margin: '2rem 0'}}>
  <a href="./getting_started" className="button button--primary button--lg">
    Getting Started
  </a>
</div>

![Jupyter MCP Server Demo](https://images.datalayer.io/products/jupyter-mcp-server/mcp-demo-multimodal.gif)

```

`docs/docs/providers/_category_.yaml`:

```yaml
label: "Providers"
position: 3

```

`docs/docs/providers/datalayer/_category_.yaml`:

```yaml
label: "Datalayer"
position: 6

```

`docs/docs/providers/datalayer/index.mdx`:

```mdx
# Datalayer Provider

:::warning

ğŸš§ The documentation for the Datalayer provider is under construction.

:::

```

`docs/docs/providers/google-colab/_category_.yaml`:

```yaml
label: "Google Colab"
position: 7

```

`docs/docs/providers/google-colab/index.mdx`:

```mdx
# Google Colab Provider

:::warning

ğŸš§ The availability of the Google Colab provider depends on https://github.com/googlecolab/jupyter-kernel-client/pull/1 under development.

:::

```

`docs/docs/providers/jupyter-stdio/_category_.yaml`:

```yaml
label: "Jupyter STDIO"
position: 1

```

`docs/docs/providers/jupyter-stdio/index.mdx`:

```mdx
# Jupyter with STDIO Transport

## 1. Start JupyterLab

### Environment setup

Make sure you have the following packages installed in your environment. The collaboration package is needed as the modifications made on the notebook can be seen thanks to [Jupyter Real Time Collaboration](https://jupyterlab.readthedocs.io/en/stable/user/rtc.html).

```bash
pip install jupyterlab==4.4.1 jupyter-collaboration==4.0.2 jupyter-mcp-tools>=0.1.4 ipykernel
pip uninstall -y pycrdt datalayer_pycrdt
pip install datalayer_pycrdt==0.12.17
```

:::tip
To confirm your environment is correctly configured:
1. Open a notebook in JupyterLab
2. Type some content in any cell (code or markdown)
3. Observe the tab indicator: you should see an "Ã—" appear next to the notebook name, indicating unsaved changes
4. Wait a few secondsâ€”the "Ã—" should automatically change to a "â—" without manually saving

This automatic saving behavior confirms that the real-time collaboration features are working properly, which is essential for MCP server integration.
:::

### JupyterLab start

Then, start JupyterLab with the following command.

```bash
jupyter lab --port 8888 --IdentityProvider.token MY_TOKEN --ip 0.0.0.0
```

You can also run `make jupyterlab` if you cloned the repository.

:::note

The `--ip` is set to `0.0.0.0` to allow the MCP Server running in a Docker container to access your local JupyterLab.

:::

## 2. Setup Jupyter MCP Server

Choose your deployment method: **uvx** (lightweight, recommended for first try) or **Docker** (production-ready).

:::important
**Before You Start:**
- Ensure the port in your configuration matches your `jupyter lab` command port
- See the [server configuration guide](/reference/configuration) for all available options and detailed examples
:::

### Using UVX (Quick Start)

First, install `uv`:

```bash
pip install uv
uv --version  # should be 0.6.14 or higher
```

**Simplified Configuration (Recommended):**
```json
{
  "mcpServers": {
    "jupyter": {
      "command": "uvx",
      "args": ["jupyter-mcp-server@latest"],
      "env": {
        "JUPYTER_URL": "http://localhost:8888",
        "JUPYTER_TOKEN": "MY_TOKEN",
        "ALLOW_IMG_OUTPUT": "true"
      }
    }
  }
}
```

:::tip Dynamic Connection
The `JUPYTER_URL` and `JUPYTER_TOKEN` environment variables are optional thanks to the [`connect_to_jupyter`](/reference/tools/#3-connect_to_jupyter) tool. This tool allows you to connect to different Jupyter servers dynamically during your conversation.

Example usage:
- **Linux**: *"Connect to jupyter server http://localhost:8888 with token MY_TOKEN"*
- **Mac/Windows**: *"Connect to jupyter server http://host.docker.internal:8888 with token MY_TOKEN"*

âš ï¸ **Security Warning**: Using the `connect_to_jupyter` tool means providing the Jupyter token to the LLM, which is not secure in production environments.
:::

<details>
<summary><b>Advanced Configuration (Optional)</b></summary>

For deployments requiring separate document storage and runtime execution:

```json
{
  "mcpServers": {
    "jupyter": {
      "command": "uvx",
      "args": ["jupyter-mcp-server@latest"],
      "env": {
        "DOCUMENT_URL": "http://localhost:8888",
        "DOCUMENT_TOKEN": "MY_TOKEN",
        "DOCUMENT_ID": "notebook.ipynb",
        "RUNTIME_URL": "http://localhost:8888",
        "RUNTIME_TOKEN": "MY_TOKEN",
        "ALLOW_IMG_OUTPUT": "true"
      }
    }
  }
}
```

</details>

### Using Docker (Production)

Configuration varies by operating system. For complete configuration options, see the [server configuration guide](/reference/configuration).

#### For MacOS and Windows

**Simplified Configuration (Recommended):**
```json
{
  "mcpServers": {
    "jupyter": {
      "command": "docker",
      "args": [
        "run", "-i", "--rm",
        "-e", "JUPYTER_URL",
        "-e", "JUPYTER_TOKEN",
        "-e", "ALLOW_IMG_OUTPUT",
        "datalayer/jupyter-mcp-server:latest"
      ],
      "env": {
        "JUPYTER_URL": "http://host.docker.internal:8888",
        "JUPYTER_TOKEN": "MY_TOKEN",
        "ALLOW_IMG_OUTPUT": "true"
      }
    }
  }
}
```

<details>
<summary><b>Advanced Configuration (Optional)</b></summary>

For deployments requiring separate document storage and runtime execution:

```json
{
  "mcpServers": {
    "jupyter": {
      "command": "docker",
      "args": [
        "run", "-i", "--rm",
        "-e", "DOCUMENT_URL",
        "-e", "DOCUMENT_TOKEN",
        "-e", "DOCUMENT_ID",
        "-e", "RUNTIME_URL",
        "-e", "RUNTIME_TOKEN",
        "-e", "ALLOW_IMG_OUTPUT",
        "datalayer/jupyter-mcp-server:latest"
      ],
      "env": {
        "DOCUMENT_URL": "http://host.docker.internal:8888",
        "DOCUMENT_TOKEN": "MY_TOKEN",
        "DOCUMENT_ID": "notebook.ipynb",
        "RUNTIME_URL": "http://host.docker.internal:8888",
        "RUNTIME_TOKEN": "MY_TOKEN",
        "ALLOW_IMG_OUTPUT": "true"
      }
    }
  }
}
```

</details>

#### For Linux

**Simplified Configuration (Recommended):**
```json
{
  "mcpServers": {
    "jupyter": {
      "command": "docker",
      "args": [
        "run", "-i", "--rm",
        "-e", "JUPYTER_URL",
        "-e", "JUPYTER_TOKEN",
        "-e", "ALLOW_IMG_OUTPUT",
        "--network=host",
        "datalayer/jupyter-mcp-server:latest"
      ],
      "env": {
        "JUPYTER_URL": "http://localhost:8888",
        "JUPYTER_TOKEN": "MY_TOKEN",
        "ALLOW_IMG_OUTPUT": "true"
      }
    }
  }
}
```

<details>
<summary><b>Advanced Configuration (Optional)</b></summary>

For deployments requiring separate document storage and runtime execution:

```json
{
  "mcpServers": {
    "jupyter": {
      "command": "docker",
      "args": [
        "run", "-i", "--rm",
        "-e", "DOCUMENT_URL",
        "-e", "DOCUMENT_TOKEN",
        "-e", "DOCUMENT_ID",
        "-e", "RUNTIME_URL",
        "-e", "RUNTIME_TOKEN",
        "-e", "ALLOW_IMG_OUTPUT",
        "--network=host",
        "datalayer/jupyter-mcp-server:latest"
      ],
      "env": {
        "DOCUMENT_URL": "http://localhost:8888",
        "DOCUMENT_TOKEN": "MY_TOKEN",
        "DOCUMENT_ID": "notebook.ipynb",
        "RUNTIME_URL": "http://localhost:8888",
        "RUNTIME_TOKEN": "MY_TOKEN",
        "ALLOW_IMG_OUTPUT": "true"
      }
    }
  }
}
```

</details>

For advanced configurations with separate document storage and runtime execution, see the [complete configuration examples](/reference/configuration#configuration-examples).

## Troubleshooting

### Common Issues

**Connection refused or invalid JSON:**
- Verify Jupyter server is running: `curl http://localhost:8888`
- Check `JUPYTER_TOKEN` matches your server token
- For Docker on macOS/Windows: Use `http://host.docker.internal:8888`
- For Docker on Linux: Add `--network=host` flag

**Authentication errors:**
- Test token: `curl -H "Authorization: token YOUR_TOKEN" http://localhost:8888/api/sessions`
- Check token in Jupyter server logs or URL parameters

For detailed troubleshooting and advanced configuration, see the [configuration guide](/reference/configuration).

```

`docs/docs/providers/jupyter-streamable-http-extension/_category_.yaml`:

```yaml
label: "Jupyter Streamable HTTP (Extension)"
position: 3

```

`docs/docs/providers/jupyter-streamable-http-extension/index.mdx`:

```mdx
# Jupyter Server Extension with Streamable HTTP Transport

The following diagram illustrates how **Jupyter MCP Server** runs as an extension inside a **Jupyter server** and communicates with an MCP client.
In this configuration, you don't need to run a separate MCP server. It will start automatically when you start your Jupyter server.
Note that only **Streamable HTTP** transport is supported in this configuration.

<img
    src="https://images.datalayer.io/products/jupyter-mcp-server/diagram-jupyter-extension.png"
    alt="Jupyter MCP Diagram Jupyter Extension"
    style={{ width: "700px", marginBottom: "2rem" }}
/>

## 1. Start JupyterLab and the MCP Server

### Environment setup

Make sure you have the following packages installed in your environment. The collaboration package is needed as the modifications made on the notebook can be seen thanks to [Jupyter Real Time Collaboration](https://jupyterlab.readthedocs.io/en/stable/user/rtc.html).

```bash
pip install "jupyter-mcp-server>=0.15.0" "jupyterlab==4.4.1" "jupyter-collaboration==4.0.2" "ipykernel"
pip uninstall -y pycrdt datalayer_pycrdt
pip install datalayer_pycrdt==0.12.17
```

:::tip
To confirm your environment is correctly configured:
1. Open a notebook in JupyterLab
2. Type some content in any cell (code or markdown)
3. Observe the tab indicator: you should see an "Ã—" appear next to the notebook name, indicating unsaved changes
4. Wait a few secondsâ€”the "Ã—" should automatically change to a "â—" without manually saving

This automatic saving behavior confirms that the real-time collaboration features are working properly, which is essential for MCP server integration.
:::

### Start JupyterLab with MCP Extension

Start JupyterLab with the MCP server extension:

```bash
jupyter lab --port 4040 --IdentityProvider.token MY_TOKEN
```

This starts JupyterLab at [http://127.0.0.1:4040](http://127.0.0.1:4040) with the MCP server integrated.

For complete configuration options, see the [server configuration guide](/reference/configuration).

## 2. Configure your MCP Client

Use the following configuration to connect to the integrated MCP server:

```json
{
  "mcpServers": {
    "jupyter": {
      "command": "npx",
      "args": ["mcp-remote", "http://127.0.0.1:4040/mcp"]
    }
  }
}
```

## Troubleshooting

### Common Issues

**Extension not loading:**
- Verify `jupyter-mcp-server` is installed: `pip list | grep jupyter-mcp-server`
- Check JupyterLab logs for extension errors

**MCP endpoint not accessible:**
- Verify server is running at: `curl http://localhost:4040/mcp`
- Check that port 4040 is not blocked

For detailed configuration and troubleshooting, see the [configuration guide](/reference/configuration).

```

`docs/docs/providers/jupyter-streamable-http-standalone/_category_.yaml`:

```yaml
label: "Jupyter Streamable HTTP (Standalone)"
position: 2

```

`docs/docs/providers/jupyter-streamable-http-standalone/index.mdx`:

```mdx
# Jupyter as a Standalone MCP Server with Streamable HTTP Transport

The following diagram illustrates how **Jupyter MCP Server** connects to a **Jupyter server** or **Datalayer** and communicates with an MCP client.

<img
    src="https://images.datalayer.io/products/jupyter-mcp-server/diagram.png"
    alt="Jupyter MCP Diagram"
    style={{ width: "700px", marginBottom: "2rem" }}
/>

## 1. Start JupyterLab

### Environment setup

Make sure you have the following packages installed in your environment. The collaboration package is needed as the modifications made on the notebook can be seen thanks to [Jupyter Real Time Collaboration](https://jupyterlab.readthedocs.io/en/stable/user/rtc.html).

```bash
pip install jupyterlab==4.4.1 jupyter-collaboration==4.0.2 jupyter-mcp-tools>=0.1.4 ipykernel
pip uninstall -y pycrdt datalayer_pycrdt
pip install datalayer_pycrdt==0.12.17
```

:::tip
To confirm your environment is correctly configured:
1. Open a notebook in JupyterLab
2. Type some content in any cell (code or markdown)
3. Observe the tab indicator: you should see an "Ã—" appear next to the notebook name, indicating unsaved changes
4. Wait a few secondsâ€”the "Ã—" should automatically change to a "â—" without manually saving

This automatic saving behavior confirms that the real-time collaboration features are working properly, which is essential for MCP server integration.
:::

### JupyterLab start

Then, start JupyterLab with the following command.

```bash
jupyter lab --port 8888 --IdentityProvider.token MY_TOKEN
```

You can also run `make jupyterlab` if you cloned the repository.

:::note

If you wish to start the Jupyter MCP server using docker, add `--ip 0.0.0.0` to the jupyter lab command to allow the MCP Server running in a Docker container to access your local JupyterLab.

:::

## 2. Start Jupyter MCP Server

The server runs on port `4040` and provides a streamable HTTP endpoint at `http://localhost:4040/mcp`.

### Using Python

Install and start the server:

```bash
pip install jupyter-mcp-server
jupyter-mcp-server start \
  --transport streamable-http \
  --jupyter-url http://localhost:8888 \
  --jupyter-token MY_TOKEN \
  --port 4040
```

:::tip Dynamic Connection
The `--jupyter-url` and `--jupyter-token` parameters are optional thanks to the [`connect_to_jupyter`](/reference/tools/#3-connect_to_jupyter) tool. This tool allows you to connect to different Jupyter servers dynamically during your conversation without restarting the MCP server.

Example usage: *"Connect to jupyter server http://localhost:8888 with token MY_TOKEN"*

âš ï¸ **Security Warning**: Using the `connect_to_jupyter` tool means providing the Jupyter token to the LLM, which is not secure in production environments.
:::

### Using Docker

**MacOS/Windows:**
```bash
docker run \
  -e JUPYTER_URL="http://host.docker.internal:8888" \
  -e JUPYTER_TOKEN="MY_TOKEN" \
  -p 4040:4040 \
  datalayer/jupyter-mcp-server:latest \
  --transport streamable-http
```

**Linux:**
```bash
docker run \
  --network=host \
  -e JUPYTER_URL="http://localhost:8888" \
  -e JUPYTER_TOKEN="MY_TOKEN" \
  -p 4040:4040 \
  datalayer/jupyter-mcp-server:latest \
  --transport streamable-http
```

For advanced configuration options, see the [server configuration guide](/reference/configuration).

<!--

## Run with Smithery

To install Jupyter MCP Server for Claude Desktop automatically via [Smithery](https://smithery.ai/server/@datalayer/jupyter-mcp-server):

```bash
npx -y @smithery/cli install @datalayer/jupyter-mcp-server --client claude
```

-->

## 3. Configure your MCP Client

Use the following configuration to connect to the running server:

```json
{
  "mcpServers": {
    "jupyter": {
      "command": "npx",
      "args": ["mcp-remote", "http://127.0.0.1:4040/mcp"]
    }
  }
}
```

## Troubleshooting

### Common Issues

**Connection refused:**
- Verify the MCP server is running: `curl http://localhost:4040/mcp`
- Check that port 4040 is not blocked by firewall
- Ensure Docker port mapping is correct (`-p 4040:4040`)

**Authentication errors:**
- Verify `JUPYTER_TOKEN` matches your Jupyter server token
- Check Jupyter server is accessible from MCP server

For detailed configuration and troubleshooting, see the [configuration guide](/reference/configuration).

```

`docs/docs/providers/jupyterhub-streamable-http/_category_.yaml`:

```yaml
label: "JupyterHub Streamable HTTP"
position: 5

```

`docs/docs/providers/jupyterhub-streamable-http/index.mdx`:

```mdx
# JupyterHub with Streamable HTTP Transport

When running Jupyter MCP Server with JupyterHub, the server runs as a Jupyter Server extension in each user's single-user server. This provides seamless integration with JupyterHub's multi-user environment while maintaining all MCP functionality.

For general information about running Jupyter MCP Server as a Jupyter Server extension, see the [Jupyter Server Extension documentation](../jupyter-streamable-http-extension).

## JupyterHub-Specific Configuration

### 1. Environment Setup

Install the required packages in your JupyterHub single-user server environment:

```bash
pip install "jupyter-mcp-server>=0.15.0" "jupyterlab==4.4.1" "jupyter-collaboration==4.0.2" "ipykernel"
pip uninstall -y pycrdt datalayer_pycrdt
pip install datalayer_pycrdt==0.12.17
```

### 2. JupyterHub Configuration

Add the following configuration to your JupyterHub config file (`jupyterhub_config.py`):

```python
# Enable token authentication in URLs for API access
c.Spawner.environment = {
    'JUPYTERHUB_ALLOW_TOKEN_IN_URL': '1'
}

# Optional: Configure single-user server to start on a specific port
# c.Spawner.port = 8888

# Optional: Ensure the MCP server extension is enabled
c.ServerApp.jpserver_extensions = {
    'jupyter_mcp_server': True
}
```

### 3. API Token Configuration

MCP clients need to authenticate with JupyterHub. Create an API token with the `access:servers` scope:

1. In the JupyterHub admin panel, navigate to **Token** page
2. Create a new token with the following scope:
   - `access:servers` - Required for accessing user notebook servers

Alternatively, use the JupyterHub API or CLI:

```bash
# Using the JupyterHub API
jupyterhub token <username> --note "MCP Client Token" --scope access:servers
```

### 4. Configure Your MCP Client

Use the following configuration to connect to the JupyterHub-hosted MCP server:

```json
{
  "mcpServers": {
    "jupyter": {
      "command": "npx",
      "args": ["mcp-remote", "https://your-jupyterhub.domain/user/<username>/mcp"],
      "env": {
        "JUPYTERHUB_API_TOKEN": "your-api-token-here"
      }
    }
  }
}
```

Replace:
- `your-jupyterhub.domain` with your JupyterHub domain
- `<username>` with the JupyterHub username
- `your-api-token-here` with the API token created in step 3

:::tip
For single-user deployments or local testing, you can use the simpler URL format:
```
http://localhost:8000/user/<username>/mcp
```
:::

## Production Considerations

### Security

- **Use HTTPS**: Always use HTTPS in production to protect API tokens
- **Token Scope**: Limit tokens to only the `access:servers` scope
- **Token Rotation**: Regularly rotate API tokens
- **Network Isolation**: Consider restricting MCP endpoint access to trusted networks

### Multi-User Environment

- Each user's MCP server runs in their isolated single-user server
- Users can only access their own notebooks through the MCP interface
- JupyterHub's authentication and authorization apply to all MCP operations

### Performance

- The MCP server adds minimal overhead to the single-user server
- Real-time collaboration features require adequate server resources
- Consider resource limits per user in JupyterHub configuration

## Troubleshooting

### Common Issues

**API token not working:**
- Verify the token has `access:servers` scope
- Check that `JUPYTERHUB_ALLOW_TOKEN_IN_URL` is set to `1`
- Ensure the token is not expired

**MCP endpoint not accessible:**
- Verify the user's single-user server is running
- Check that the URL format matches your JupyterHub deployment
- Confirm `jupyter-mcp-server` is installed in the single-user environment

**Extension not loading:**
- Check JupyterHub logs: `journalctl -u jupyterhub`
- Verify extension installation: `jupyter server extension list`
- Ensure all required packages are installed in the single-user environment

For general extension troubleshooting, see the [Jupyter Server Extension documentation](../jupyter-streamable-http-extension).

```

`docs/docs/reference/_category_.yaml`:

```yaml
label: "Reference"
position: 6

```

`docs/docs/reference/configuration/_category_.yaml`:

```yaml
label: "Configuration"
position: 1

```

`docs/docs/reference/configuration/index.mdx`:

```mdx
# Configuration

## Overview

The Jupyter MCP Server supports flexible configuration through environment variables and command-line options to accommodate different deployment scenarios from simple local setups to complex distributed environments.

## Server Modes

The server automatically detects the appropriate mode based on deployment context:

| Mode | Description | When Used |
|------|-------------|-----------|
| **MCP_SERVER** | Standalone server connecting via HTTP | Docker, remote deployments |
| **JUPYTER_SERVER** | Runs as Jupyter extension with direct API access | Local deployments, high-performance |

### JupyterLab Mode
**Environment Variable:** `JUPYTERLAB=true` (default)

- **Enabled**: Automatic notebook opening, enhanced UI tools, `notebook_run-all-cells` tool
- **Disabled**: Basic operations only, headless usage

## Transport & Providers

### Transport Options

| Transport | Use Case | Configuration |
|-----------|----------|---------------|
| **STDIO** (default) | Desktop apps, Docker | `--transport stdio` |
| **Streamable HTTP** | Web apps, multiple clients | `--transport streamable-http --port 4040` |

### Providers

| Provider | Description | Configuration |
|----------|-------------|---------------|
| **jupyter** (default) | Standard JupyterLab/Hub | `--provider jupyter` |
| **datalayer** | Enterprise hosting | `--provider datalayer` |

## Environment Variables

The server supports both simplified and advanced configuration approaches:

### Simplified Configuration (Recommended)

For most users with standard JupyterLab setups:

| Variable | Description | Example | Default | Required |
|----------|-------------|---------|---------|----------|
| `JUPYTER_URL` | URL of your Jupyter server | `http://localhost:8888` | `http://localhost:8888` | No |
| `JUPYTER_TOKEN` | Authentication token for Jupyter server | `my-secret-token` | `None` | No* |
| `DOCUMENT_ID` | Default notebook path (relative to Jupyter root) | `notebook.ipynb` | `None` | No |
| `ALLOWED_JUPYTER_MCP_TOOLS` | Comma-separated list of jupyter-mcp-tools to enable | `notebook_run-all-cells,notebook_get-selected-cell` | `notebook_run-all-cells,notebook_get-selected-cell` | No |
| `ALLOW_IMG_OUTPUT` | Enable multimodal image support | `true` / `false` | `true` | No |

*Required for authentication when connecting to secured Jupyter servers

### Advanced Configuration (Complex Deployments)

For deployments requiring granular control over document storage and runtime execution:

#### Document Storage Variables
| Variable | Description | Example | Default |
|----------|-------------|---------|---------|
| `DOCUMENT_URL` | URL for notebook file operations | `http://notebook-storage:8888` | `http://localhost:8888` |
| `DOCUMENT_TOKEN` | Authentication for document operations | `storage-access-token` | `None` |
| `DOCUMENT_ID` | Notebook path/ID | `shared/analysis.ipynb` | `None` |

#### Runtime Execution Variables  
| Variable | Description | Example | Default |
|----------|-------------|---------|---------|
| `RUNTIME_URL` | URL for kernel/execution operations | `http://compute-cluster:8888` | `http://localhost:8888` |
| `RUNTIME_TOKEN` | Authentication for runtime operations | `compute-access-token` | `None` |
| `RUNTIME_ID` | Specific kernel ID to use | `kernel-abc123` | `None` |

#### Additional Configuration Variables
| Variable | Description | Example | Default |
|----------|-------------|---------|---------|
| `START_NEW_RUNTIME` | Create new runtime vs use existing | `true` / `false` | `false` |
| `PROVIDER` | Provider type for document and runtime | `jupyter` / `datalayer` | `jupyter` |
| `TRANSPORT` | Transport method for MCP | `stdio` / `streamable-http` | `stdio` |
| `PORT` | Port for streamable HTTP transport | `4040` | `4040` |
| `JUPYTERLAB` | Enable JupyterLab mode | `true` / `false` | `true` |

### Configuration Priority

Variables are resolved in this order:
1. **Individual variables** (`DOCUMENT_*`, `RUNTIME_*`) - highest priority
2. **Simplified variables** (`JUPYTER_*`) - fallback
3. **Default values** - when no variables are set

## Configuration Examples

### Standard JupyterLab Setup
```bash
JUPYTER_URL=http://localhost:8888
JUPYTER_TOKEN=my-token
DOCUMENT_ID=my-notebook.ipynb
ALLOWED_JUPYTER_MCP_TOOLS=notebook_run-all-cells,notebook_get-selected-cell
ALLOW_IMG_OUTPUT=true
```

### JupyterHub with Separate Services
```bash
DOCUMENT_URL=http://hub.example.com:8000
DOCUMENT_TOKEN=hub-api-token
RUNTIME_URL=http://user-server:8888
RUNTIME_TOKEN=user-server-token
DOCUMENT_ID=shared/analysis.ipynb
```

### Distributed Computing Setup  
```bash
DOCUMENT_URL=http://file-server:8888
DOCUMENT_TOKEN=file-access-token
RUNTIME_URL=http://compute-node:8888
RUNTIME_TOKEN=compute-access-token
ALLOW_IMG_OUTPUT=false
```

### Development Setup
```bash
JUPYTER_URL=http://localhost:8888
JUPYTER_TOKEN=dev-token
# DOCUMENT_ID omitted
```

## Command Line Options

For advanced use cases, you can configure the server using command-line flags:

```bash
jupyter-mcp-server start --help

Usage: jupyter-mcp-server start [OPTIONS]

Options:
  --transport [stdio|streamable-http]  Transport type (default: stdio)
  --provider [jupyter|datalayer]      Provider type (default: jupyter)  
  --jupyterlab BOOLEAN               Enable JupyterLab mode (default: true)
  --runtime-url TEXT                  Runtime URL for kernel operations (default: None)
  --runtime-token TEXT                Runtime authentication token (default: None)
  --runtime-id TEXT                   Specific kernel ID to use (default: None)
  --start-new-runtime BOOLEAN         Create new runtime vs use existing (default: true)
  --document-url TEXT                 Document URL for notebook operations (default: None)
  --document-id TEXT                  Notebook path/ID (default: None)
  --document-token TEXT               Document authentication token (default: None)
  --jupyter-url TEXT                  Jupyter URL as default for both document and runtime URLs (default: None)
  --jupyter-token TEXT                Jupyter token as default for both document and runtime tokens (default: None)
  --allowed-jupyter-mcp-tools TEXT    Comma-separated list of jupyter-mcp-tools to enable (default: notebook_run-all-cells,notebook_get-selected-cell)
  --port INTEGER                      Port for streamable-http transport (default: 4040)
```

### Additional Commands

The server also supports additional commands for advanced workflows:

#### Connect Command
```bash
jupyter-mcp-server connect --help

Usage: jupyter-mcp-server connect [OPTIONS]

Connect a Jupyter MCP Server to a document and a runtime.

Options:
  --provider [jupyter|datalayer]      Provider type (default: jupyter)
  --jupyterlab BOOLEAN               Enable JupyterLab mode (default: true)
  --runtime-url TEXT                  Runtime URL for kernel operations (default: None)
  --runtime-token TEXT                Runtime authentication token (default: None)
  --runtime-id TEXT                   Specific kernel ID to use (default: None)
  --document-url TEXT                 Document URL for notebook operations (default: None)
  --document-id TEXT                  Notebook path/ID (default: None)
  --document-token TEXT               Document authentication token (default: None)
  --jupyter-url TEXT                  Jupyter URL as default for both document and runtime URLs (default: None)
  --jupyter-token TEXT                Jupyter token as default for both document and runtime tokens (default: None)
  --jupyter-mcp-server-url TEXT       URL of the Jupyter MCP Server to connect to (default: http://localhost:4040)
```

#### Stop Command
```bash
jupyter-mcp-server stop --help

Usage: jupyter-mcp-server stop [OPTIONS]

Stop a running Jupyter MCP Server.

Options:
  --jupyter-mcp-server-url TEXT       URL of the Jupyter MCP Server to stop (default: http://localhost:4040)
```

### Usage Examples

```bash
jupyter-mcp-server start \
  --transport streamable-http \
  --jupyter-url http://localhost:8888 \
  --jupyter-token MY_TOKEN \
  --allowed-jupyter-mcp-tools "notebook_run-all-cells,notebook_get-selected-cell" \
  --port 4040
```

## Advanced Usage

### Connecting to Existing Runtime

Start server without creating new runtime:
```bash
jupyter-mcp-server start \
  --transport streamable-http \
  --runtime-url http://localhost:8888 \
  --runtime-token MY_TOKEN \
  --start-new-runtime false
```

Then connect via endpoint:
```bash
jupyter-mcp-server connect \
  --provider datalayer \
  --document-url <url> \
  --document-id <document> \
  --document-token <token> \
  --runtime-url <url> \
  --runtime-id <runtime-id> \
  --runtime-token <token> \
  --jupyter-mcp-server-url http://localhost:4040
```

## Multimodal Output Support

The server supports multimodal output, allowing AI agents to directly receive and analyze visual content such as images and charts generated by code execution.

### Supported Output Types

- **Text Output**: Standard text output from code execution
- **Image Output**: PNG images generated by matplotlib, seaborn, plotly, and other visualization libraries
- **Error Output**: Error messages and tracebacks

### Environment Variable Configuration

Control multimodal output behavior using environment variables:

#### `ALLOW_IMG_OUTPUT`

Controls whether to return actual image content or text placeholders.

- **Default**: `true`
- **Values**: `true`, `false`, `1`, `0`, `yes`, `no`, `on`, `off`, `enable`, `disable`, `enabled`, `disabled`


### Output Behavior

#### When `ALLOW_IMG_OUTPUT=true` (Default)
- Images are returned as `ImageContent` objects with actual PNG data
- AI agents can directly analyze visual content
- Supports advanced multimodal reasoning

#### When `ALLOW_IMG_OUTPUT=false`
- Images are returned as text placeholders: `"[Image Output (PNG) - Image display disabled]"`
- Maintains backward compatibility with text-only LLMs
- Reduces bandwidth and token usage

### Use Cases

**Data Visualization Analysis:**
```python
import matplotlib.pyplot as plt
import pandas as pd

df = pd.read_csv('sales_data.csv')
df.plot(kind='bar', x='month', y='revenue')
plt.title('Monthly Revenue')
plt.show()
# AI can now "see" and analyze the chart content
```

**Machine Learning Model Visualization:**
```python
import matplotlib.pyplot as plt

# Plot training curves
plt.plot(epochs, train_loss, label='Training Loss')
plt.plot(epochs, val_loss, label='Validation Loss')
plt.legend()
plt.show()
# AI can evaluate training effectiveness from the visual curves
```

```

`docs/docs/reference/multi-users/_category_.yaml`:

```yaml
label: "Multi Users"
position: 3

```

`docs/docs/reference/multi-users/index.mdx`:

```mdx
# Multi-User Deployments

Jupyter MCP Server can be deployed in multi-user environments where multiple people access Jupyter notebooks concurrently. This guide explains the architecture patterns, deployment options, and best practices for multi-user scenarios.

## Understanding Multi-User Challenges

### The Concurrency Problem

As described in [issue #181](https://github.com/datalayer/jupyter-mcp-server/issues/181), when multiple users share a single MCP server instance connected to a shared JupyterLab, they can interfere with each other's work:

**Example Scenario:**

1. User 1's agent activates `user1notebook.ipynb`
2. Simultaneously, User 2's agent activates `user2notebook.ipynb`
3. User 1's agent writes code to the **currently active notebook** (now `user2notebook.ipynb`)
4. **Result**: User 1's code appears in User 2's notebook

This happens because:
- MCP server maintains a single "active notebook" state
- Multiple agents share the same MCP server instance
- Notebook operations are context-dependent (operating on "current" notebook)

## Deployment Architectures

There are three primary architecture patterns for multi-user deployments:

### 1. One MCP Server Per User (Recommended)

**Best for:** Most multi-user scenarios, especially with JupyterHub

Each user gets their own isolated MCP server instance, preventing any cross-user interference.

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           JupyterHub / Multi-User           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  User 1                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ MCP Client  â”‚â”€â”€â”€â”€â”€â–¶â”‚ MCP Server      â”‚  â”‚
â”‚  â”‚  (Agent)    â”‚      â”‚ (Extension)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â†“             â”‚  â”‚
â”‚                       â”‚ JupyterLab      â”‚  â”‚
â”‚                       â”‚ Single-User     â”‚  â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  User 2                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ MCP Client  â”‚â”€â”€â”€â”€â”€â–¶â”‚ MCP Server      â”‚  â”‚
â”‚  â”‚  (Agent)    â”‚      â”‚ (Extension)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â”‚   â†“             â”‚  â”‚
â”‚                       â”‚ JupyterLab      â”‚  â”‚
â”‚                       â”‚ Single-User     â”‚  â”‚
â”‚                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**Advantages:**
- âœ… Complete isolation between users
- âœ… No state conflicts
- âœ… Scales naturally with JupyterHub
- âœ… Leverages existing JupyterHub authentication

**Implementation:** See [JupyterHub Deployment](#jupyterhub-deployment)

### 2. Stateless Tool Operations

**Best for:** Shared environments where one-MCP-per-user is not feasible

Make all notebook operations explicitly reference the target notebook by path.

**Current Status:**

:::info Under Development

Currently, some MCP tools maintain "active notebook" state. Work is ongoing to make operations fully stateless by requiring explicit notebook paths in all tool calls.

Track progress: [Issue #181](https://github.com/datalayer/jupyter-mcp-server/issues/181)

:::

**Future API (Planned):**

```json
{
  "tool": "execute_cell",
  "arguments": {
    "notebook": "user1/analysis.ipynb",
    "cell_index": 0
  }
}
```

### 3. Session-Based Isolation

**Best for:** Advanced scenarios with custom session management

Use unique session identifiers to isolate user contexts within a shared MCP server.

:::warning Experimental

This approach is not yet implemented in Jupyter MCP Server. Follow development discussions in [issue #181](https://github.com/datalayer/jupyter-mcp-server/issues/181).

:::

## JupyterHub Deployment

JupyterHub is the **recommended platform** for multi-user Jupyter deployments with MCP.

### Architecture

JupyterHub naturally provides user isolation:
- Each user gets a dedicated single-user Jupyter server
- MCP server runs as an extension inside each single-user server
- No shared state between users

### Setup Steps

#### 1. Install in Single-User Environment

Configure your JupyterHub spawner to install the required packages:

```python
# jupyterhub_config.py
c.Spawner.environment = {
    'JUPYTERHUB_ALLOW_TOKEN_IN_URL': '1'
}

# Install packages in the single-user image or environment
# Example for DockerSpawner:
c.DockerSpawner.image = 'your-custom-image:latest'
```

**Single-User Environment Requirements:**

```dockerfile
# Dockerfile for single-user image
FROM jupyter/minimal-notebook:latest

RUN pip install "jupyter-mcp-server>=0.15.0" \
                "jupyterlab==4.4.1" \
                "jupyter-collaboration==4.0.2" \
                "ipykernel"
RUN pip uninstall -y pycrdt datalayer_pycrdt && \
    pip install datalayer_pycrdt==0.12.17
```

#### 2. Configure MCP Extension

The MCP server extension loads automatically when the single-user server starts.

**Verify Installation:**

```bash
# Inside single-user server
jupyter server extension list
# Should show: jupyter_mcp_server enabled
```

#### 3. User Access Configuration

Each user needs:
1. A JupyterHub account
2. An API token with `access:servers` scope
3. MCP client configuration pointing to their unique URL

**Per-User MCP Client Configuration:**

```json
{
  "mcpServers": {
    "jupyter": {
      "command": "npx",
      "args": ["mcp-remote", "https://hub.example.com/user/alice/mcp"],
      "env": {
        "JUPYTERHUB_API_TOKEN": "alice-api-token"
      }
    }
  }
}
```

### Creating User Tokens

**Option 1: JupyterHub Admin UI**

1. Login as admin
2. Navigate to **Token** management
3. Create token for user with `access:servers` scope

**Option 2: JupyterHub API**

```bash
# Create token for specific user
jupyterhub token alice --note "MCP Client Token" --scope access:servers
```

**Option 3: User Self-Service**

```python
# Allow users to create their own tokens
c.JupyterHub.load_roles = [
    {
        "name": "user",
        "scopes": ["self", "access:servers"],
    }
]
```

### User Isolation

JupyterHub ensures:
- **File System Isolation**: Each user has separate home directory
- **Process Isolation**: Separate kernel processes per user
- **Network Isolation**: Each single-user server on different port/container
- **Authentication**: JupyterHub manages user identity and access

## Shared JupyterLab (Not Recommended)

:::danger Concurrency Issues

Sharing a single JupyterLab instance among multiple users with a shared MCP server causes the concurrency problems described in [issue #181](https://github.com/datalayer/jupyter-mcp-server/issues/181).

**This deployment pattern is NOT recommended.**

:::

### Why It Causes Problems

```
âŒ PROBLEMATIC SETUP:

User 1 Agent  â”€â”
               â”œâ”€â”€â–¶ Single MCP Server â”€â”€â–¶ Shared JupyterLab
User 2 Agent  â”€â”˜      (shared state)       (all users)

Problem: Both users' agents share the same "active notebook" state
```

### If You Must Share

If you absolutely must use a shared JupyterLab:

1. **Use Explicit Notebook Paths**: Always specify full notebook paths
2. **Implement Access Controls**: Use file system permissions to isolate user directories
3. **Monitor for Conflicts**: Log and alert on concurrent access
4. **Consider Alternatives**: Strongly recommend migrating to JupyterHub

## Datalayer Hosted Platform

For enterprise deployments, consider [Datalayer](https://datalayer.ai) which provides:

- **Built-in Multi-User Support**: Isolated notebook environments per user
- **Managed Authentication**: SSO, OAuth2, SAML integration
- **Resource Management**: CPU/memory limits per user
- **Collaboration Features**: Real-time notebook co-editing
- **Audit Logging**: Track all user actions

### Configuration

```json
{
  "mcpServers": {
    "datalayer": {
      "command": "uvx",
      "args": ["jupyter-mcp-server@latest"],
      "env": {
        "PROVIDER": "datalayer",
        "DATALAYER_URL": "https://app.datalayer.ai",
        "DATALAYER_TOKEN": "your-user-token"
      }
    }
  }
}
```

## Best Practices

### For Multi-User Deployments

#### 1. Use JupyterHub

âœ… **Do:**
- Deploy with JupyterHub for proper user isolation
- Run MCP server as extension in each single-user server
- Use JupyterHub's authentication and authorization

âŒ **Don't:**
- Share a single JupyterLab instance among multiple users
- Use a single MCP server instance for multiple users
- Rely on application-level isolation instead of OS-level

#### 2. Token Management

âœ… **Do:**
- Create unique API tokens for each user
- Use minimal token scopes (`access:servers` only)
- Implement token expiration policies
- Provide users with self-service token creation

âŒ **Don't:**
- Share tokens between users
- Use admin-scoped tokens for users
- Store tokens in shared configuration files

#### 3. Resource Management

```python
# jupyterhub_config.py
# Limit resources per user
c.Spawner.cpu_limit = 2
c.Spawner.mem_limit = '4G'
c.Spawner.cpu_guarantee = 1
c.Spawner.mem_guarantee = '1G'

# Limit concurrent servers
c.JupyterHub.concurrent_spawn_limit = 10

# Cull idle servers
c.JupyterHub.services = [
    {
        'name': 'idle-culler',
        'command': [
            'python3', '-m', 'jupyterhub_idle_culler',
            '--timeout=3600'
        ]
    }
]
```

#### 4. Monitoring and Logging

âœ… **Do:**
- Enable audit logging for all MCP operations
- Monitor resource usage per user
- Set up alerts for unusual activity
- Track concurrent user counts

**Example Logging Configuration:**

```python
# jupyterhub_config.py
import logging

c.JupyterHub.log_level = 'INFO'
c.Application.log_format = '%(asctime)s [%(name)s] %(levelname)s: %(message)s'

# Log to file
c.JupyterHub.extra_log_file = '/var/log/jupyterhub/jupyterhub.log'
```

## Scaling Considerations

### Small Teams (< 10 users)

**Recommended Setup:**
- Single JupyterHub server
- Local storage for notebooks
- Simple spawner (LocalProcessSpawner or DockerSpawner)

### Medium Organizations (10-100 users)

**Recommended Setup:**
- Kubernetes-based JupyterHub (Zero to JupyterHub)
- Shared network storage (NFS, EFS)
- KubeSpawner for pod management
- Load balancing for hub

### Large Enterprises (100+ users)

**Recommended Setup:**
- Multi-hub deployment with load balancing
- Distributed storage (Ceph, GlusterFS)
- Auto-scaling for user servers
- Integration with enterprise SSO
- Consider [Datalayer platform](https://datalayer.ai)

## Troubleshooting Multi-User Issues

### Users Seeing Each Other's Notebooks

**Symptom:** User A sees notebooks created by User B

**Causes:**
1. Shared JupyterLab instance (see [issue #181](https://github.com/datalayer/jupyter-mcp-server/issues/181))
2. Incorrect file permissions
3. Shared home directory

**Solutions:**
- âœ… Switch to JupyterHub with per-user isolation
- âœ… Verify file system permissions: `ls -la ~`
- âœ… Check spawner configuration for home directory isolation

### Concurrent Execution Conflicts

**Symptom:** Code from one user appears in another user's notebook

**Cause:** Shared MCP server with stateful "active notebook"

**Solutions:**
- âœ… Deploy one MCP server per user (JupyterHub extension mode)
- âœ… Wait for stateless tool operations (track [issue #181](https://github.com/datalayer/jupyter-mcp-server/issues/181))

### Authentication Failures in Multi-User Environment

**Symptom:** Users can't connect to their MCP server

**Causes:**
1. Missing or incorrect API tokens
2. Token lacking required scopes
3. `JUPYTERHUB_ALLOW_TOKEN_IN_URL` not set

**Solutions:**
- âœ… Verify token has `access:servers` scope
- âœ… Check `JUPYTERHUB_ALLOW_TOKEN_IN_URL=1` in spawner environment
- âœ… Test token with curl: `curl -H "Authorization: token TOKEN" https://hub.example.com/user/alice/api`

## Migration Guide

### From Shared JupyterLab to JupyterHub

1. **Setup JupyterHub**
   ```bash
   pip install jupyterhub
   jupyterhub --generate-config
   ```

2. **Create User Accounts**
   ```bash
   # Add system users
   sudo adduser alice
   sudo adduser bob
   ```

3. **Install MCP Server in Single-User Environment**
   - Create a conda/virtual environment for single-user servers
   - Install required packages (see [JupyterHub setup](#setup-steps))

4. **Configure Spawner**
   ```python
   # jupyterhub_config.py
   c.JupyterHub.spawner_class = 'dockerspawner.DockerSpawner'
   c.DockerSpawner.image = 'your-mcp-enabled-image:latest'
   ```

5. **Migrate User Notebooks**
   ```bash
   # Copy notebooks to user directories
   cp -r /shared/notebooks/alice/* /home/alice/
   chown -R alice:alice /home/alice/
   ```

6. **Update MCP Client Configurations**
   - Provide each user with their unique MCP endpoint URL
   - Generate individual API tokens

## Additional Resources

- [JupyterHub Documentation](https://jupyterhub.readthedocs.io/)
- [Zero to JupyterHub (Kubernetes)](https://z2jh.jupyter.org/)
- [JupyterHub Deployment Guide](https://jupyterhub.readthedocs.io/en/stable/reference/technical-overview.html)
- [JupyterHub Provider Documentation](/providers/jupyterhub-streamable-http)
- [Issue #181: Multi-user serving](https://github.com/datalayer/jupyter-mcp-server/issues/181)
- [Datalayer Platform](https://datalayer.ai)

```

`docs/docs/reference/prompts/_category_.yaml`:

```yaml
label: "Prompts"
position: 6

```

`docs/docs/reference/prompts/index.mdx`:

```mdx
# Prompts

The server currently offers 1 prompt for user.

:::warning

Not all MCP Clients support the Prompt Feature. You need to ensure that your MCP Client supports it to enable this feature.
Current known MCP Client support status for Prompt:
<br/>
- Supported: `Claude desktop`, [`Claude Code`](https://docs.claude.com/en/docs/claude-code/mcp#execute-mcp-prompts), [`Gemini CLI`](https://geminicli.com/docs/tools/mcp-server/#invoking-prompts)
- Not supported: `Cursor`

:::

## Jupyter Core Prompt (1 prompt)

This is the core Prompt component of Jupyter MCP, providing universal and powerful Prompt tools, all prefixed with `jupyter`.

### 1. `jupyter-cite`

This prompt allows users to cite specific cells in a notebook, enabling users to let LLM perform precise subsequent operations on specific cells.

#### Input Parameters

- `--prompt`: User prompt for the cited cells
- `--cell_indices`: Cell indices to cite (0-based), supporting flexible range format
    1. **Single Index**: Cite a single cell, such as `"0"` (cites the 1st cell)
    2. **Range Format**: Cite a continuous range of cells, such as `"0-2"` (cites cells 1 to 3)
    3. **Mixed Format**: Combine single index and range, such as `"0-2,4"` (cites cells 1-3 and cell 5)
    4. **Open-ended Range**: From specified index to the end of notebook, such as `"3-"` (cites from cell 4 to the last cell)
- `--notebook_path`: Name of the notebook to cite cells from, default ("") to current activated notebook

#### Output Format

```
USER Cite cells {cell_indices} from notebook {notebook_name}, here are the cells:
=====Cell {cell_index} | type: {cell_type} | execution count: {execution_count}=====
{cell_source}
...(other cells)
=====End of Cited Cells=====
USER's Instruction are follow: {prompt}
```
```

`docs/docs/reference/security/_category_.yaml`:

```yaml
label: "Security"
position: 2

```

`docs/docs/reference/security/index.mdx`:

```mdx
# Security

Jupyter MCP Server is designed to integrate with your existing Jupyter deployment's security infrastructure. This guide covers authentication methods, token management, and best practices for secure deployments.

## Authentication Overview

Jupyter MCP Server supports multiple authentication methods to work with various Jupyter deployment scenarios:

1. **Bearer Token Authentication** (Recommended for most deployments)
2. **XSRF Cookie-based Authentication** (For token-less environments)
3. **External Authentication** (SSO, OAuth, IAM in managed environments)

## Token Authentication

### Understanding Jupyter Tokens

Jupyter tokens are authentication credentials used to secure access to Jupyter servers. When you start JupyterLab with a token:

```bash
jupyter lab --IdentityProvider.token MY_TOKEN
```

This token acts as a password that must be provided in API requests to authenticate.

### How Tokens are Used

The MCP server authenticates to Jupyter using Bearer token authentication:

```http
Authorization: Bearer MY_TOKEN
```

Tokens are required for:
- Accessing the Jupyter API (`/api/sessions`, `/api/contents`, etc.)
- Establishing collaboration sessions (`/api/collaboration/session/`)
- Executing code in kernels
- Reading and writing notebook files

### Token Configuration

#### Simplified Configuration (Recommended)

Use `JUPYTER_TOKEN` when your document storage and runtime execution are on the same Jupyter server:

```json
{
  "env": {
    "JUPYTER_URL": "http://localhost:8888",
    "JUPYTER_TOKEN": "MY_TOKEN"
  }
}
```

#### Advanced Configuration (Separate Services)

For deployments where notebook storage and kernel execution are separate:

```json
{
  "env": {
    "DOCUMENT_URL": "http://storage-server:8888",
    "DOCUMENT_TOKEN": "storage-token",
    "RUNTIME_URL": "http://compute-server:8888",
    "RUNTIME_TOKEN": "compute-token"
  }
}
```

### Token Best Practices

:::warning Security Best Practices

1. **Never commit tokens to version control** - Use environment variables or secure secret management
2. **Use strong, unique tokens** - Generate random tokens with sufficient entropy
3. **Rotate tokens regularly** - Especially for production environments
4. **Limit token scope** - For JupyterHub, create tokens with minimal required scopes
5. **Use HTTPS in production** - Always encrypt token transmission over the network

:::

#### Generating Secure Tokens

```bash
# Generate a random secure token
python -c "import secrets; print(secrets.token_urlsafe(32))"
```

#### Storing Tokens Securely

- **Development**: Use environment variables in shell profiles (`.bashrc`, `.zshrc`)
- **CI/CD**: Use encrypted secrets (GitHub Secrets, GitLab CI Variables)
- **Production**: Use secret management systems (HashiCorp Vault, AWS Secrets Manager, Azure Key Vault)

## XSRF Protection

### What is XSRF?

Cross-Site Request Forgery (XSRF/CSRF) protection prevents unauthorized commands from being transmitted from a user that the web application trusts. Jupyter uses Tornado's built-in XSRF protection.

### Token-less Environments

As described in [issue #183](https://github.com/datalayer/jupyter-mcp-server/issues/183), some Jupyter deployments don't use Bearer tokens but rely on XSRF cookies for authentication:

**Affected Environments:**
- Jupyter servers started without a token: `jupyter lab --IdentityProvider.token ''`
- Enterprise deployments with SSO/OAuth/IAM
- Managed environments (AWS SageMaker Studio, Google Colab Enterprise, Azure ML)
- JupyterHub where authentication is handled by the Hub

### Current Limitations

:::info Current Status

**Bearer Token Required**: Currently, Jupyter MCP Server requires a Bearer token (`JUPYTER_TOKEN`) to authenticate with the Jupyter collaboration API.

**Issue**: The server fails with `403 Forbidden` when connecting to Jupyter deployments that use XSRF protection without Bearer tokens.

**Tracking**: We're working on automatic XSRF cookie handling - see [issue #183](https://github.com/datalayer/jupyter-mcp-server/issues/183) for details.

:::

### Workarounds for XSRF-only Environments

Until automatic XSRF handling is implemented, you have these options:

#### Option 1: Start Jupyter with a Token (Recommended)

```bash
jupyter lab --IdentityProvider.token YOUR_SECURE_TOKEN
```

Then configure MCP server with:

```json
{
  "env": {
    "JUPYTER_TOKEN": "YOUR_SECURE_TOKEN"
  }
}
```

#### Option 2: Disable XSRF (Development Only)

:::danger Not for Production

Only use this in isolated development environments. Never disable XSRF protection in production or shared environments.

:::

```bash
jupyter lab --ServerApp.disable_check_xsrf True
```

## JupyterHub Authentication

JupyterHub adds an additional layer of authentication complexity since it manages multiple user servers.

### Token Requirements for JupyterHub

When using Jupyter MCP Server with JupyterHub, you need:

1. **API Token with Proper Scope**: Create a token with the `access:servers` scope
2. **URL Token Parameter Support**: Enable `JUPYTERHUB_ALLOW_TOKEN_IN_URL` in the single-user environment

### Configuration Steps

#### 1. Enable Token in URL

In your JupyterHub configuration (`jupyterhub_config.py`):

```python
c.Spawner.environment = {
    'JUPYTERHUB_ALLOW_TOKEN_IN_URL': '1'
}
```

#### 2. Create API Token

Using JupyterHub admin interface or API:

```bash
# Create a token with access:servers scope
jupyterhub token <username> --note "MCP Client Token" --scope access:servers
```

#### 3. Configure MCP Client

```json
{
  "env": {
    "JUPYTER_URL": "https://jupyterhub.example.com/user/username",
    "JUPYTER_TOKEN": "your-api-token-here"
  }
}
```

### JupyterHub Token Scopes

| Scope | Purpose | Required for MCP |
|-------|---------|------------------|
| `access:servers` | Access user's notebook servers | **Yes** |
| `read:users` | Read user information | No |
| `admin:users` | Manage users (admin only) | No |

## Managed Jupyter Environments

### AWS SageMaker Studio

SageMaker uses IAM-based authentication combined with XSRF protection.

:::info Status

**Not Currently Supported**: SageMaker's authentication model is not yet supported. Follow [issue #183](https://github.com/datalayer/jupyter-mcp-server/issues/183) for updates.

:::

### Google Colab Enterprise

Colab Enterprise uses Google's OAuth2 authentication.

:::info Status

**Under Development**: We're evaluating support for Google Colab Enterprise environments.

:::

### Azure ML Notebooks

Azure ML uses Azure AD authentication.

:::info Status

**Under Development**: Azure ML support is being evaluated.

:::

## Network Security

### HTTPS/TLS

:::warning Production Requirement

**Always use HTTPS in production environments** to encrypt all communication, including authentication tokens.

:::

#### Example HTTPS Configuration

```json
{
  "env": {
    "JUPYTER_URL": "https://jupyter.example.com:8888",
    "JUPYTER_TOKEN": "your-token-here"
  }
}
```

### Firewall Configuration

Ensure appropriate firewall rules:

**STDIO Transport:**
- No inbound ports needed (uses standard input/output)
- Outbound access to Jupyter server required

**Streamable HTTP Transport:**
- Inbound port (default: 4040) for MCP client connections
- Outbound access to Jupyter server required

### Network Isolation

For sensitive deployments:

1. **Private Networks**: Run Jupyter and MCP server on private networks
2. **VPN Access**: Require VPN for accessing Jupyter infrastructure
3. **IP Whitelisting**: Restrict Jupyter server access to known IP ranges

## Docker Security

When running Jupyter MCP Server in Docker:

### Don't Expose Tokens in Logs

```bash
# âŒ BAD - Token visible in docker ps
docker run -e JUPYTER_TOKEN=my-secret-token ...

# âœ… GOOD - Use Docker secrets or environment file
docker run --env-file .env ...
```

### Use Docker Secrets (Docker Swarm/Kubernetes)

```bash
# Create secret
echo "my-secure-token" | docker secret create jupyter_token -

# Use in service
docker service create \
  --secret jupyter_token \
  datalayer/jupyter-mcp-server
```

### Least Privilege

Run containers with minimal privileges:

```bash
docker run \
  --read-only \
  --cap-drop=ALL \
  --security-opt=no-new-privileges:true \
  datalayer/jupyter-mcp-server
```

## Security Checklist

Use this checklist to ensure your deployment follows security best practices:

### Development

- [ ] Use unique tokens for each developer
- [ ] Rotate tokens periodically
- [ ] Don't commit tokens to version control
- [ ] Use `.env` files (add to `.gitignore`)
- [ ] Run Jupyter on `localhost` only

### Production

- [ ] Use HTTPS/TLS for all connections
- [ ] Generate strong random tokens (minimum 32 characters)
- [ ] Store tokens in secure secret management system
- [ ] Enable firewall rules to restrict access
- [ ] Use VPN or private networks when possible
- [ ] Implement token rotation policy
- [ ] Enable audit logging on Jupyter server
- [ ] Regular security updates for all components
- [ ] Monitor for unauthorized access attempts

### JupyterHub

- [ ] Use API tokens with minimal scopes (`access:servers` only)
- [ ] Enable `JUPYTERHUB_ALLOW_TOKEN_IN_URL` in single-user environment
- [ ] Configure token expiration policies
- [ ] Implement single sign-on (SSO) if available
- [ ] Regular token audits and cleanup

## Reporting Security Issues

If you discover a security vulnerability in Jupyter MCP Server:

:::danger Security Disclosure

**Do not open a public GitHub issue for security vulnerabilities.**

Instead, please email: **security@datalayer.io**

We will respond promptly to security reports.

:::

## Additional Resources

- [Jupyter Server Security](https://jupyter-server.readthedocs.io/en/latest/operators/security.html)
- [JupyterHub Security Overview](https://jupyterhub.readthedocs.io/en/stable/reference/websecurity.html)
- [Tornado XSRF Protection](https://www.tornadoweb.org/en/stable/guide/security.html)
- [OWASP Authentication Cheat Sheet](https://cheatsheetseries.owasp.org/cheatsheets/Authentication_Cheat_Sheet.html)
- [Issue #183: XSRF Support](https://github.com/datalayer/jupyter-mcp-server/issues/183)
```

`docs/docs/reference/tools-additional/_category_.yaml`:

```yaml
label: "Tools (Additionals)"
position: 5

```

`docs/docs/reference/tools-additional/index.mdx`:

```mdx
# Additional Tools

In JupyterLab mode, Jupyter MCP Server integrates with [jupyter-mcp-tools](https://github.com/datalayer/jupyter-mcp-tools) to expose additional JupyterLab-specific commands as MCP tools.

## Dependency on jupyter-mcp-tools

When running in JupyterLab mode (see [Configuration](/reference/configuration)), Jupyter MCP Server depends on **jupyter-mcp-tools** to provide enhanced UI integration capabilities. This extension enables the use of JupyterLab commands as MCP tools.

### Installation

The `jupyter-mcp-tools` package must be installed in your JupyterLab environment:

```bash
pip install jupyter-mcp-tools>=0.1.4
```

### How It Works

1. **JupyterLab Mode Detection**: When Jupyter MCP Server detects it's running in JupyterLab mode, it queries `jupyter-mcp-tools` for available commands
2. **Allowed Tools Filtering**: Only specific tools from `jupyter-mcp-tools` are exposed to MCP clients (see [Allowed Tools](#allowed-tools) below)
3. **Command Routing**: When an MCP client calls one of these tools, the request is routed to `jupyter-mcp-tools` which executes the corresponding JupyterLab command

## Allowed Tools

The following tools from `jupyter-mcp-tools` are enabled by default in Jupyter MCP Server:

| Tool Name | Description |
|-----------|-------------|
| `notebook_run-all-cells` | Execute all cells in the current notebook sequentially |
| `notebook_get-selected-cell` | Get information about the currently selected cell |

:::info Configuring Allowed Tools
The list of allowed `jupyter-mcp-tools` is now configurable! 

The complete **list of available tools** can be found in the **[jupyter-mcp-tools README](https://github.com/datalayer/jupyter-mcp-tools/blob/main/README.md#available-tools)**.
:::

You can specify which tools to enable using:

**When running jupyter-mcp-server as a Jupyter Server Extension:**
```bash
jupyter lab --port 4040 --IdentityProvider.token MY_TOKEN --JupyterMCPServerExtensionApp.allowed_jupyter_mcp_tools="notebook_run-all-cells,notebook_get-selected-cell,notebook_append-execute"
```

`--allowed-jupyter-mcp-tools` has no effect when running jupyter-mcp-server standalone.

For developers who want to modify the default list programmatically, you can still update the `allowed_jupyter_mcp_tools` configuration in:
- [`jupyter_mcp_server/server.py`](https://github.com/datalayer/jupyter-mcp-server/blob/main/jupyter_mcp_server/server.py) - for standalone/STDIO mode
- [`jupyter_mcp_server/jupyter_extension/handlers.py`](https://github.com/datalayer/jupyter-mcp-server/blob/main/jupyter_mcp_server/jupyter_extension/handlers.py) - for Jupyter server extension mode

## Architecture

```mermaid
graph LR
    A[MCP Client] --> B[Jupyter MCP Server]
    B --> C{JupyterLab Mode?}
    C -->|Yes| D[jupyter-mcp-tools]
    D --> E[JupyterLab Commands]
    C -->|No| F[FastMCP Tools Only]
```

When JupyterLab mode is enabled:
- Jupyter MCP Server queries `jupyter-mcp-tools` for available tools
- Only tools in the `allowed_jupyter_mcp_tools` configuration are exposed to MCP clients
- Tool execution is routed through `jupyter-mcp-tools` which communicates with the JupyterLab frontend via WebSocket

```

`docs/docs/reference/tools/_category_.yaml`:

```yaml
label: "Tools"
position: 4

```

`docs/docs/reference/tools/index.mdx`:

```mdx
# Tools

The server currently offers 15 tools organized into 3 categories:

## Server Management (3 tools)

#### 1. `list_files`

- List all files and directories recursively in the Jupyter server's file system.
- Used to explore the file system structure of the Jupyter server or to find specific files or directories.
- Input:
  - `path`(string, optional): The starting path to list from (empty string means root directory, default: "")
  - `max_depth`(int, optional): Maximum depth to recurse into subdirectories (default: 1, max: 3)
  - `start_index`(int, optional): Starting index for pagination (0-based, default: 0)
  - `limit`(int, optional): Maximum number of items to return (0 means no limit, default: 25)
  - `pattern`(string, optional): Glob pattern to filter file paths (default: "")
- Returns: Tab-separated table with columns: Path, Type, Size, Last_Modified. Includes pagination info header showing current range and total count.
  - **Path**: Full path to the file or directory
  - **Type**: File type ("file", "directory", "notebook", or "error" if inaccessible)
  - **Size**: File size formatted as B, KB, or MB (empty for directories)
  - **Last_Modified**: Last modification timestamp in YYYY-MM-DD HH:MM:SS format

#### 2. `list_kernels`

- List all available kernels in the Jupyter server.
- This tool shows all running and available kernel sessions on the Jupyter server, including their IDs, names, states, connection information, and kernel specifications. Useful for monitoring kernel resources and identifying specific kernels for connection.
- Input: None
- Returns: Tab-separated table with columns: ID, Name, Display_Name, Language, State, Connections, Last_Activity, Environment
  - **ID**: Unique kernel identifier
  - **Name**: Kernel name/type (e.g., "python3", "ir", etc.)
  - **Display_Name**: Human-readable kernel name from kernel spec
  - **Language**: Programming language supported by the kernel
  - **State**: Current execution state ("idle", "busy", "unknown")
  - **Connections**: Number of active connections to this kernel
  - **Last_Activity**: Timestamp of last kernel activity in YYYY-MM-DD HH:MM:SS format
  - **Environment**: Environment variables defined in the kernel spec (truncated if long)

#### 3. `connect_to_jupyter`

- Connect to a Jupyter server dynamically with URL and token.
- This tool allows you to connect to different Jupyter servers without needing to restart the MCP server or modify configuration files.
- Input:
  - `jupyter_url`(string): Jupyter server URL to connect to (e.g., "http://localhost:8888")
  - `jupyter_token`(string, optional): Jupyter server authentication token
  - `provider`(string, optional): Provider type (default: "jupyter")
- Returns: Connection status message confirming successful connection to the Jupyter server
- **Use Cases**: When working with multiple Jupyter servers with different ports/tokens and you want to switch between them dynamically during a conversation. Or you do not want to hardcode connection details in configuration.

:::warning Availability & Security
- **Not available** when running MCP server [as a Jupyter extension](/providers/jupyter-streamable-http-extension).
- **Alternative**: Pre-configure connection details in server configuration for production use as it is **not secure** to provide tokens to LLMs in production.
:::

## Multi-Notebook (5 tools)

#### 4. `use_notebook`

- Use a notebook and activate it for following cell operations.
- Input:
  - `notebook_name`(string): Unique identifier for the notebook
  - `notebook_path`(string): Path to the notebook file, relative to the Jupyter server root (e.g. "notebook.ipynb")
  - `mode`(string): Notebook operation mode: "connect" to connect to existing and activate it, "create" to create new and activate it (default: "connect")
  - `kernel_id`(string, optional): Specific kernel ID to use (will create new if skipped)
- Returns: Success message with notebook information including activation status, kernel details, and notebook overview

#### 5. `list_notebooks`

- List all notebooks that have been used via use_notebook tool.
- Input: None
- Returns: TSV formatted table with notebook information
  - **Name**: Unique identifier for the notebook
  - **Path**: Path to the notebook file
  - **Kernel_ID**: Kernel ID associated with the notebook
  - **Kernel_Status**: Current status of the kernel
  - **Activate**: "âœ“" if this is the currently active notebook, empty otherwise

#### 6. `restart_notebook`

- Restart the kernel for a specific notebook.
- Input:
  - `notebook_name`(string): Notebook identifier to restart
- Returns: Success message confirming the kernel has been restarted and memory state cleared

#### 7. `unuse_notebook`

- Unuse from a specific notebook and release its resources.
- Input:
  - `notebook_name`(string): Notebook identifier to disconnect
- Returns: Success message confirming the notebook has been disconnected and resources released

#### 8. `read_notebook`

- Read a notebook and return index, source content, type, execution count of each cell.
- Using brief format to get a quick overview of the notebook structure and it's useful for locating specific cells for operations like delete or insert.
- Using detailed format to get detailed information of the notebook and it's useful for debugging and analysis.
- It is recommended to use brief format with larger limit to get a overview of the notebook structure, then use detailed format with exact index and limit to get the detailed information of some specific cells.
- Input:
  - `notebook_name`(string): Notebook identifier to read
  - `response_format`(string): Response format: "brief" will return first line and lines number, "detailed" will return full cell source (default: "brief")
  - `start_index`(int, optional): Starting index for pagination (0-based, default: 0)
  - `limit`(int, optional): Maximum number of items to return (0 means no limit, default: 20)
- Returns: Notebook content in the requested format with cell details, metadata, and pagination information

## Cell Tools (7 tools)

#### 9. `insert_cell`

- Insert a cell to specified position from the currently activated notebook.
- Input:
  - `cell_index`(int): Target index for insertion (0-based), use -1 to append at end
  - `cell_type`(string): Type of cell to insert ("code" or "markdown")
  - `cell_source`(string): Source content for the cell
- Returns: Success message with insertion confirmation and the structure of surrounding cells (up to 5 cells above and below)

#### 10. `overwrite_cell_source`

- Overwrite the source of a specific cell from the currently activated notebook.
- It will return a diff style comparison (e.g. `+` for new lines, `-` for deleted lines) of the cell's content
- Input:
  - `cell_index`(int): Index of the cell to overwrite (0-based)
  - `cell_source`(string): New complete cell source
- Returns: Success message with diff style comparison showing changes made (e.g. `+` for new lines, `-` for deleted lines)

#### 11. `execute_cell`

- Execute a cell from the currently activated notebook with timeout and return it's outputs
- Input:
  - `cell_index`(int): Index of the cell to execute (0-based)
  - `timeout`(int, optional): Maximum seconds to wait for execution (default: 90)
  - `stream`(bool, optional): Enable streaming progress updates for long-running cells (default: false)
  - `progress_interval`(int, optional): Seconds between progress updates when stream=true (default: 5)
- Returns: `list[Union[str, ImageContent]]` - List of outputs from the executed cell including text, HTML, and images. Supports streaming mode with progress updates for long-running cells.

#### 12. `insert_execute_code_cell`

- Insert a cell at specified index from the currently activated notebook and then execute it with timeout and return it's outputs.
- It is a shortcut tool for insert_cell and execute_cell tools, recommended to use if you want to insert a cell and execute it at the same time
- Input:
  - `cell_index`(int): Index of the cell to insert and execute (0-based)
  - `cell_source`(string): Code source for the cell
  - `timeout`(int, optional): Maximum seconds to wait for execution (default: 90)
- Returns: `list[Union[str, ImageContent]]` - List of outputs from the executed cell including text, HTML, and images. Returns both insertion confirmation and execution results.

#### 13. `read_cell`

- Read a specific cell from the currently activated notebook and return it's metadata (index, type, execution count), source and outputs (for code cells)
- Input:
  - `cell_index`(int): Index of the cell to read (0-based)
  - `include_outputs`(bool, optional): Include outputs in the response (only for code cells, default: true)
- Returns: `list[Union[str, ImageContent]]` - List containing cell metadata (index, type, execution count), source code, and outputs (for code cells with include_outputs=true)

#### 14. `delete_cell`

- Delete a specific cell or multiple cells from the currently activated notebook and return the cell source of deleted cells (if include_source=True).
- When deleting many cells, MUST delete them in descending order of their index to avoid index shifting.
- Input:
  - `cell_indices`(list[int]): List of indices of the cells to delete (0-based)
  - `include_source`(bool, optional): Whether to include the source of deleted cells (default: true)
- Returns: Success message with deletion confirmation and the source code of the deleted cells (if include_source=True)

#### 15. `execute_code`

- Execute code directly in the kernel (not saved to notebook) on the current activated notebook.
- Recommended to use in following cases:
  1. Execute Jupyter magic commands (e.g., %timeit, %pip install xxx)
  2. Performance profiling and debugging
  3. View intermediate variable values (e.g., print(xxx), df.head())
  4. Temporary calculations and quick tests (e.g., np.mean(df['xxx']))
  5. Execute Shell commands in Jupyter server (e.g., !git xxx)
- Under no circumstances should you use this tool to:
  1. Import new modules or perform variable assignments that affect subsequent Notebook execution
  2. Execute dangerous code that may harm the Jupyter server or the user's data without permission
- Input:
  - `code`(string): Code to execute (supports magic commands with %, shell commands with !)
  - `timeout`(int, optional): Execution timeout in seconds (default: 30, max: 60)
- Returns: `list[Union[str, ImageContent]]` - List of outputs from the executed code including text, HTML, images, and shell command results. Supports magic commands and shell commands with ! prefix.

```

`docs/docs/releases/_category_.yaml`:

```yaml
label: "Releases"
position: 11

```

`docs/docs/releases/index.mdx`:

```mdx
# Releases

## Latest Release

See the latest release notes on the [GitHub Releases page](https://github.com/datalayer/jupyter-mcp-server/releases).

## Older Releases

### 0.16.x - 13 Oct 2025

- [Merge the three execute tools into a single unified tool](https://github.com/datalayer/jupyter-mcp-server/pull/111)
- [Docs: update readme and contributing](https://github.com/datalayer/jupyter-mcp-server/pull/112)
- CI: build Auto Releases CI/CD: [#114](https://github.com/datalayer/jupyter-mcp-server/pull/114), [#115](https://github.com/datalayer/jupyter-mcp-server/pull/115), [#119](https://github.com/datalayer/jupyter-mcp-server/pull/119), [#120](https://github.com/datalayer/jupyter-mcp-server/pull/120)
- [fix negative index](https://github.com/datalayer/jupyter-mcp-server/pull/116)
- [fix ressources and prompts list](https://github.com/datalayer/jupyter-mcp-server/pull/117)
- [Refactor: separate and simplify the server.py](https://github.com/datalayer/jupyter-mcp-server/pull/123)
- [Feat/add JUPYTER_URL and JUPYTER_TOKEN](https://github.com/datalayer/jupyter-mcp-server/pull/125)

### 0.15.x - 08 Oct 2025

- [Run as Jupyter Server Extension + Tool registry + Use tool](https://github.com/datalayer/jupyter-mcp-server/pull/95)
- [simplify tool implementations](https://github.com/datalayer/jupyter-mcp-server/pull/101)
- [add uvx as alternative MCP server startup method](https://github.com/datalayer/jupyter-mcp-server/pull/101)
- [document as a Jupyter Extension](https://github.com/datalayer/jupyter-mcp-server/pull/101)
- Fix Minor Bugs: [#108](https://github.com/datalayer/jupyter-mcp-server/pull/108),[#110](https://github.com/datalayer/jupyter-mcp-server/pull/110)

### 0.14.0 - 03 Oct 2025

- [Additional Tools & Bug fixes](https://github.com/datalayer/jupyter-mcp-server/pull/93).
- [Execute IPython](https://github.com/datalayer/jupyter-mcp-server/pull/90).
- [Multi notebook management](https://github.com/datalayer/jupyter-mcp-server/pull/88).

### 0.13.0 - 25 Sep 2025

- [Add multimodal output support for Jupyter cell execution](https://github.com/datalayer/jupyter-mcp-server/pull/75).
- [Unify cell insertion functionality](https://github.com/datalayer/jupyter-mcp-server/pull/73).

### 0.11.0 - 01 Aug 2025

- [Rename room to document](https://github.com/datalayer/jupyter-mcp-server/pull/35).

### 0.10.2 - 17 Jul 2025

- [Tools docstring improvements](https://github.com/datalayer/jupyter-mcp-server/pull/30).

### 0.10.1 - 11 Jul 2025

- [CORS Support](https://github.com/datalayer/jupyter-mcp-server/pull/29).

### 0.10.0 - 07 Jul 2025

- More [fixes](https://github.com/datalayer/jupyter-mcp-server/pull/28) issues for nbclient stop.

### 0.9.0 - 02 Jul 2025

- Fix issues with `nbmodel` stops.

### 0.6.0 - 01 Jul 2025

- Configuration change, see details on the [clients page](/clients) and [server configuration](/reference/configuration).

```

`docs/docs/resources/_category_.yaml`:

```yaml
label: "Resources"
position: 12

```

`docs/docs/resources/index.mdx`:

```mdx
# Resources

## Articles & Blog Posts

- [HuggingFace Blog - How to Install and Use Jupyter MCP Server](https://huggingface.co/blog/lynn-mikami/jupyter-mcp-server)
- [Analytics Vidhya - How to Use Jupyter MCP Server?](https://www.analyticsvidhya.com/blog/2025/05/jupyter-mcp-server/)
- [Medium AI Simplified in Plain English - How to Use Jupyter MCP Server?](https://medium.com/ai-simplified-in-plain-english/how-to-use-jupyter-mcp-server-87f68fea7471)
- [Medium Jupyter AI Agents - Jupyter MCP Server: How to Setup via Claude Desktop](https://jupyter-ai-agents.datalayer.blog/mcp-server-for-jupyter-heres-your-guide-2025-0b29d975b4e1)
- [Medium Data Science in Your Pocket - Best MCP Servers for Data Scientists](https://medium.com/data-science-in-your-pocket/best-mcp-servers-for-data-scientists-ee4fa6caf066)
- [Medium Coding Nexus - 6 Open Source MCP Servers Every Dev Should Try](https://medium.com/coding-nexus/6-open-source-mcp-servers-every-dev-should-try-b3cc6cf6a714)
- [Medium Joe Njenga - 8 Best MCP Servers & Tools Every Python Developer Should Try](https://medium.com/@joe.njenga/8-best-mcp-servers-tools-every-python-developer-should-try-3e69f435e99e)
- [Medium Sreekar Kashyap - MCP Servers + Ollama](https://medium.com/@sreekarkashyap7/mcp-servers-ollama-fad991461e88)
- [Medium Wenmin Wu - Agentic DS Workflow with Cursor and MCP Servers](https://medium.com/@wenmin_wu/agentic-ds-workflow-with-cursor-and-mcp-servers-2d90a102cf31)

## Videos

- [Data Science in your pocket - Jupyter MCP : AI for Jupyter Notebooks](https://www.youtube.com/watch?v=qkoEsqiWDOU)
- [Datalayer - How to Set Up the Jupyter MCP Server (via Claude Desktop)](https://www.youtube.com/watch?v=nPllCQxtaxQ)

## MCP Directories

- [Model Context Protocol Servers](https://github.com/modelcontextprotocol/servers)
- [Awesome MCP Servers](https://github.com/punkpeye/awesome-mcp-servers)

## MCP Registries

- [MCP.so](https://mcp.so/server/Integrating-the-Jupyter-server-with-claude-desktop-uisng-the-powerful-model-context-protocol/harshitha-8)
- [MCP Market](https://mcpmarket.com/server/jupyter)
- [MCP Servers Finder](https://www.mcpserverfinder.com/servers/ihrpr/mcp-server-jupyter)
- [Pulse MCP](https://www.pulsemcp.com/servers/datalayer-jupyter)
- [Playbooks](https://playbooks.com/mcp/datalayer-jupyter)
- [Know That AI](https://knowthat.ai/agents/jupyter-server)

<!--
- [Smithery](https://smithery.ai/server/@datalayer/jupyter-mcp-server)
-->

```

`docs/docusaurus.config.js`:

```js
/*
 * Copyright (c) 2024- Datalayer, Inc.
 *
 * BSD 3-Clause License
 */

/** @type {import('@docusaurus/types').DocusaurusConfig} */
module.exports = {
  title: 'ğŸª ğŸ”§ Jupyter MCP Server documentation',
  tagline: 'Tansform your Notebooks into an interactive, AI-powered workspace that adapts to your needs!',
  url: 'https://datalayer.ai',
  baseUrl: '/',
  onBrokenLinks: 'throw',
  onBrokenMarkdownLinks: 'warn',
  favicon: 'img/favicon.ico',
  organizationName: 'datalayer', // Usually your GitHub org/user name.
  projectName: 'jupyter-mcp-server', // Usually your repo name.
  markdown: {
    mermaid: true,
  },
  plugins: [
    '@docusaurus/theme-live-codeblock',
    'docusaurus-lunr-search',
  ],
  themes: [
    '@docusaurus/theme-mermaid',
  ],
  themeConfig: {
    colorMode: {
      defaultMode: 'light',
      disableSwitch: true,
    },
    navbar: {
      title: 'Jupyter MCP Server Docs',
      logo: {
        alt: 'Datalayer Logo',
        src: 'img/datalayer/logo.svg',
      },
      items: [
        {
          href: 'https://discord.gg/YQFwvmSSuR',
          position: 'right',
          className: 'header-discord-link',
          'aria-label': 'Discord',
        },
        {
          href: 'https://github.com/datalayer/jupyter-mcp-server',
          position: 'right',
          className: 'header-github-link',
          'aria-label': 'GitHub',
        },
        {
          href: 'https://bsky.app/profile/datalayer.ai',
          position: 'right',
          className: 'header-bluesky-link',
          'aria-label': 'Bluesky',
        },
        {
          href: 'https://x.com/DatalayerIO',
          position: 'right',
          className: 'header-x-link',
          'aria-label': 'X',
        },
        {
          href: 'https://www.linkedin.com/company/datalayer',
          position: 'right',
          className: 'header-linkedin-link',
          'aria-label': 'LinkedIn',
        },
        {
          href: 'https://tiktok.com/@datalayerio',
          position: 'right',
          className: 'header-tiktok-link',
          'aria-label': 'TikTok',
        },
        {
          href: 'https://www.youtube.com/@datalayer',
          position: 'right',
          className: 'header-youtube-link',
          'aria-label': 'YouTube',
        },
        {
          href: 'https://datalayer.ai',
          position: 'right',
          className: 'header-datalayer-io-link',
          'aria-label': 'Datalayer',
        },
      ],
    },
    footer: {
      style: 'dark',
      links: [
        {
          title: 'Docs',
          items: [
            {
              label: 'Jupyter MCP Server',
              to: '/',
            },
          ],
        },
        {
          title: 'Community',
          items: [
            {
              label: 'Discord',
              href: 'https://discord.gg/YQFwvmSSuR',
            },
            {
              label: 'GitHub',
              href: 'https://github.com/datalayer',
            },
            {
              label: 'Bluesky',
              href: 'https://bsky.app/profile/datalayer.ai',
            },
            {
              label: 'LinkedIn',
              href: 'https://www.linkedin.com/company/datalayer',
            },
          ],
        },
        {
          title: 'More',
          items: [
            {
              label: 'Datalayer',
              href: 'https://datalayer.ai',
            },
            {
              label: 'Datalayer Docs',
              href: 'https://docs.datalayer.app',
            },
            {
              label: 'Datalayer Guide',
              href: 'https://datalayer.guide',
            },
            {
              label: 'Datalayer Blog',
              href: 'https://datalayer.blog',
            },
          ],
        },
      ],
      copyright: `Copyright Â© ${new Date().getFullYear()} Datalayer, Inc.`,
    },
  },
  presets: [
    [
      '@docusaurus/preset-classic',
      {
        docs: {
          routeBasePath: '/',
          docItemComponent: '@theme/CustomDocItem',
          sidebarPath: require.resolve('./sidebars.js'),
          editUrl: 'https://github.com/datalayer/jupyter-mcp-server/edit/main/',
        },
        theme: {
          customCss: require.resolve('./src/css/custom.css'),
        },
        gtag: {
          trackingID: 'G-EYRGHH1GN6',
          anonymizeIP: false,
        },
      },
    ],
  ],
};

```

`docs/package.json`:

```json
{
  "name": "@datalayer/jupyter-mcp-server-docs",
  "version": "0.0.1",
  "private": true,
  "scripts": {
    "docusaurus": "docusaurus",
    "start": "docusaurus start",
    "build": "docusaurus build",
    "swizzle": "docusaurus swizzle",
    "deploy": "docusaurus deploy",
    "clear": "docusaurus clear",
    "serve": "docusaurus serve",
    "write-translations": "docusaurus write-translations",
    "write-heading-ids": "docusaurus write-heading-ids"
  },
  "dependencies": {
    "@datalayer/icons-react": "^1.0.0",
    "@datalayer/primer-addons": "^1.0.3",
    "@docusaurus/core": "^3.5.2",
    "@docusaurus/preset-classic": "^3.5.2",
    "@docusaurus/theme-live-codeblock": "^3.5.2",
    "@docusaurus/theme-mermaid": "^3.5.2",
    "@mdx-js/react": "^3.0.1",
    "@primer/react-brand": "^0.58.0",
    "clsx": "^2.1.1",
    "docusaurus-lunr-search": "^3.5.0",
    "react": "18.3.1",
    "react-calendly": "^4.1.0",
    "react-dom": "18.3.1",
    "react-modal-image": "^2.6.0"
  },
  "browserslist": {
    "production": [
      ">0.5%",
      "not dead",
      "not op_mini all"
    ],
    "development": [
      "last 1 chrome version",
      "last 1 firefox version",
      "last 1 safari version"
    ]
  }
}

```

`docs/sidebars.js`:

```js
/*
 * Copyright (c) 2024- Datalayer, Inc.
 *
 * BSD 3-Clause License
 */

/**
 * Creating a sidebar enables you to:
 - create an ordered group of docs
 - render a sidebar for each doc of that group
 - provide next/previous navigation

 The sidebars can be generated from the filesystem, or explicitly defined here.

 Create as many sidebars as you want.
 */

// @ts-check

/** @type {import('@docusaurus/plugin-content-docs').SidebarsConfig} */
const sidebars = {
  jupyterMCPServerSidebar: [
    {
      type: 'autogenerated',
      dirName: '.',
    },
  ]
};

module.exports = sidebars;

```

`docs/src/components/HomepageFeatures.js`:

```js
/*
 * Copyright (c) 2024- Datalayer, Inc.
 *
 * BSD 3-Clause License
 */

import React from 'react';
import clsx from 'clsx';
import styles from './HomepageFeatures.module.css';

const FeatureList = [
/*
  {
    title: 'Easy to Use',
    Svg: require('../../static/img/feature_1.svg').default,
    description: (
      <>
        Datalayer was designed from the ground up to be easily installed and
        used to get your data analysis up and running quickly.
      </>
    ),
  },
  {
    title: 'Focus on What Matters',
    Svg: require('../../static/img/feature_2.svg').default,
    description: (
      <>
        Datalayer lets you focus on your work, and we&apos;ll do the chores.
      </>
    ),
  },
  {
    title: 'Powered by Open Source',
    Svg: require('../../static/img/feature_3.svg').default,
    description: (
      <>
        Extend or customize your platform to your needs.
      </>
    ),
  },
*/
];

function Feature({Svg, title, description}) {
  return (
    <div className={clsx('col col--4')}>
      <div className="text--center">
        <Svg className={styles.featureSvg} alt={title} />
      </div>
      <div className="text--center padding-horiz--md">
        <h3>{title}</h3>
        <p>{description}</p>
      </div>
    </div>
  );
}

export default function HomepageFeatures() {
  return (
    <section className={styles.features}>
      <div className="container">
        <div className="row">
          {FeatureList.map((props, idx) => (
            <Feature key={idx} {...props} />
          ))}
        </div>
      </div>
    </section>
  );
}

```

`docs/src/components/HomepageFeatures.module.css`:

```css
/*
 * Copyright (c) 2024- Datalayer, Inc.
 *
 * BSD 3-Clause License
 */

/* stylelint-disable docusaurus/copyright-header */

.features {
  display: flex;
  align-items: center;
  padding: 2rem 0;
  width: 100%;
}

.featureSvg {
  height: 200px;
  width: 200px;
}

```

`docs/src/components/HomepageProducts.js`:

```js
/*
 * Copyright (c) 2024- Datalayer, Inc.
 *
 * BSD 3-Clause License
 */

import React from 'react';
import clsx from 'clsx';
import styles from './HomepageProducts.module.css';

const ProductList = [
/*
  {
    title: 'Jupyter MCP Server',
    Svg: require('../../static/img/product_1.svg').default,
    description: (
      <>
        Get started by creating a Jupyter platform in the cloud with Jupyter MCP Server. You will get Jupyter on Kubernetes with a cloud database and storage bucket to persist your notebooks and datasets.
      </>
    ),
  },
  {
    title: 'Jupyter',
    Svg: require('../../static/img/product_2.svg').default,
    description: (
      <>
        If you need more batteries for Jupyter, have a look to our Jupyter components. The components allow you to get the best of Jupyter notebooks, with features like authentication, authorization, React.js user interface, server and kernel instant start, administration...
      </>
    ),
  },
  {
    title: 'Sharebook',
    Svg: require('../../static/img/product_3.svg').default,
    description: (
      <>
        For a truly collaborative and accessible notebook, try Sharebook, a better better literate notebook, with built-in collaboration, accessibility...
      </>
    ),
  },
*/
];

function Product({Svg, title, description}) {
  return (
    <div className={clsx('col col--4')}>
      <div className="text--center">
        <Svg className={styles.productSvg} alt={title} />
      </div>
      <div className="text--center padding-horiz--md">
        <h3>{title}</h3>
        <p>{description}</p>
      </div>
    </div>
  );
}

export default function HomepageProducts() {
  return (
    <section className={styles.Products}>
      <div className="container">
        <div className="row">
          {ProductList.map((props, idx) => (
            <Product key={idx} {...props} />
          ))}
        </div>
      </div>
    </section>
  );
}

```

`docs/src/components/HomepageProducts.module.css`:

```css
/*
 * Copyright (c) 2024- Datalayer, Inc.
 *
 * BSD 3-Clause License
 */

/* stylelint-disable docusaurus/copyright-header */

.product {
  display: flex;
  align-items: center;
  padding: 2rem 0;
  width: 100%;
}

.productSvg {
  height: 200px;
  width: 200px;
}

```

`docs/src/css/custom.css`:

```css
/*
 * Copyright (c) 2024- Datalayer, Inc.
 *
 * BSD 3-Clause License
 */

/* stylelint-disable docusaurus/copyright-header */
/**
 * Any CSS included here will be global. The classic template
 * bundles Infima by default. Infima is a CSS framework designed to
 * work well for content-centric websites.
 */

/* You can override the default Infima variables here. */
:root {
  --ifm-color-primary: #25c2a0;
  --ifm-color-primary-dark: rgb(33, 175, 144);
  --ifm-color-primary-darker: rgb(31, 165, 136);
  --ifm-color-primary-darkest: rgb(26, 136, 112);
  --ifm-color-primary-light: rgb(70, 203, 174);
  --ifm-color-primary-lighter: rgb(102, 212, 189);
  --ifm-color-primary-lightest: rgb(146, 224, 208);
  --ifm-code-font-size: 95%;
}

.docusaurus-highlight-code-line {
  background-color: rgb(72, 77, 91);
  display: block;
  margin: 0 calc(-1 * var(--ifm-pre-padding));
  padding: 0 var(--ifm-pre-padding);
}

.header-datalayer-io-link::before {
  content: '';
  width: 24px;
  height: 24px;
  display: flex;
  background: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' fill='none' aria-hidden='true' viewBox='0 0 20 20'%3E%3Cpath fill='%232ECC71' d='M0 0h20v4H0zm0 0'/%3E%3Cpath fill='%231ABC9C' d='M0 8h20v4H0zm0 0'/%3E%3Cpath fill='%2316A085' d='M0 16h20v4H0zm0 0'/%3E%3C/svg%3E%0A")
    no-repeat;
}

.header-datalayer-io-link:hover {
  opacity: 0.6;
}

[data-theme='dark'] .header-datalayer-io-link::before {
  background: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' fill='none' aria-hidden='true' viewBox='0 0 20 20'%3E%3Cpath fill='%232ECC71' d='M0 0h20v4H0zm0 0'/%3E%3Cpath fill='%231ABC9C' d='M0 8h20v4H0zm0 0'/%3E%3Cpath fill='%2316A085' d='M0 16h20v4H0zm0 0'/%3E%3C/svg%3E%0A")
    no-repeat;
}

.header-github-link::before {
  content: '';
  width: 24px;
  height: 24px;
  display: flex;
  background: url("data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8' standalone='no'%3F%3E%3Csvg viewBox='0 0 80 80' version='1.1' id='svg4' xmlns='http://www.w3.org/2000/svg' xmlns:svg='http://www.w3.org/2000/svg'%3E%3Cdefs id='defs8' /%3E%3Cpath fill='%23959da5' d='M 40,0 C 17.9,0 0,17.900001 0,40 c 0,17.7 11.45,32.65 27.35,37.950001 2,0.35 2.75,-0.85 2.75,-1.9 0,-0.95 -0.05,-4.1 -0.05,-7.45 C 20,70.45 17.4,66.15 16.6,63.9 16.15,62.75 14.2,59.2 12.5,58.25 11.1,57.5 9.1,55.65 12.45,55.600001 c 3.15,-0.05 5.4,2.899999 6.15,4.1 3.6,6.05 9.35,4.35 11.65,3.3 0.35,-2.6 1.4,-4.35 2.55,-5.35 -8.9,-1 -18.2,-4.45 -18.2,-19.75 0,-4.35 1.55,-7.95 4.1,-10.75 -0.4,-1 -1.8,-5.1 0.4,-10.6 0,0 3.35,-1.05 11,4.1 3.2,-0.9 6.6,-1.35 10,-1.35 3.4,0 6.8,0.45 10,1.35 7.65,-5.2 11,-4.1 11,-4.1 2.2,5.5 0.8,9.6 0.4,10.6 2.55,2.8 4.1,6.35 4.1,10.75 0,15.35 -9.35,18.75 -18.25,19.75 1.45,1.25 2.7,3.65 2.7,7.4 0,5.349999 -0.05,9.65 -0.05,11 0,1.05 0.75,2.3 2.75,1.9 A 40.065,40.065 0 0 0 80,40 C 80,17.900001 62.1,0 40,0 Z' id='path2' style='stroke-width:5' /%3E%3C/svg%3E%0A")
    no-repeat;
}

.header-github-link:hover {
  opacity: 0.6;
}

[data-theme='dark'] .header-github-link::before {
  background: url("data:image/svg+xml,%3C%3Fxml version='1.0' encoding='UTF-8' standalone='no'%3F%3E%3Csvg viewBox='0 0 80 80' version='1.1' id='svg4' xmlns='http://www.w3.org/2000/svg' xmlns:svg='http://www.w3.org/2000/svg'%3E%3Cdefs id='defs8' /%3E%3Cpath fill='%23959da5' d='M 40,0 C 17.9,0 0,17.900001 0,40 c 0,17.7 11.45,32.65 27.35,37.950001 2,0.35 2.75,-0.85 2.75,-1.9 0,-0.95 -0.05,-4.1 -0.05,-7.45 C 20,70.45 17.4,66.15 16.6,63.9 16.15,62.75 14.2,59.2 12.5,58.25 11.1,57.5 9.1,55.65 12.45,55.600001 c 3.15,-0.05 5.4,2.899999 6.15,4.1 3.6,6.05 9.35,4.35 11.65,3.3 0.35,-2.6 1.4,-4.35 2.55,-5.35 -8.9,-1 -18.2,-4.45 -18.2,-19.75 0,-4.35 1.55,-7.95 4.1,-10.75 -0.4,-1 -1.8,-5.1 0.4,-10.6 0,0 3.35,-1.05 11,4.1 3.2,-0.9 6.6,-1.35 10,-1.35 3.4,0 6.8,0.45 10,1.35 7.65,-5.2 11,-4.1 11,-4.1 2.2,5.5 0.8,9.6 0.4,10.6 2.55,2.8 4.1,6.35 4.1,10.75 0,15.35 -9.35,18.75 -18.25,19.75 1.45,1.25 2.7,3.65 2.7,7.4 0,5.349999 -0.05,9.65 -0.05,11 0,1.05 0.75,2.3 2.75,1.9 A 40.065,40.065 0 0 0 80,40 C 80,17.900001 62.1,0 40,0 Z' id='path2' style='stroke-width:5' /%3E%3C/svg%3E%0A")
    no-repeat;
}

.header-bluesky-link::before {
  content: '';
  width: 24px;
  height: 24px;
  display: flex;
  background: url("data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22UTF-8%22%20standalone%3D%22no%22%3F%3E%0A%3Csvg%0A%20%20%20width%3D%2224%22%0A%20%20%20height%3D%2224%22%0A%20%20%20viewBox%3D%220%200%202.88%202.88%22%0A%20%20%20version%3D%221.1%22%0A%20%20%20id%3D%22svg4%22%0A%20%20%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%0A%20%20%20xmlns%3Asvg%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%20%20%3Cdefs%0A%20%20%20%20%20id%3D%22defs8%22%20%2F%3E%0A%20%20%3Cpath%0A%20%20%20%20%20fill%3D%22%23959da5%22%0A%20%20%20%20%20d%3D%22M%201.44%2C1.306859%20C%201.30956%2C1.053179%200.95447995%2C0.58049901%200.62423999%2C0.34745901%200.30791999%2C0.12413901%200.18732%2C0.16277901%200.10824%2C0.19865901%200.01668%2C0.23981901%200%2C0.38045901%200%2C0.46301901%20c%200%2C0.0828%200.04536%2C0.67799999%200.07488%2C0.77747999%200.0978%2C0.32832%200.44556%2C0.4392%200.76595999%2C0.4036799%200.01632%2C-0.0024%200.033%2C-0.00468%200.0498%2C-0.00672%20-0.01656%2C0.00264%20-0.03312%2C0.0048%20-0.0498%2C0.00672%20C%200.3714%2C1.7137789%20-0.0456%2C1.884779%200.50124%2C2.493539%201.1027999%2C3.1163391%201.3256399%2C2.359979%201.44%2C1.976579%201.55436%2C2.359979%201.686%2C3.0890991%202.36796%2C2.493539%202.88%2C1.976579%202.5086%2C1.713779%202.0391599%2C1.6441789%20a%201.04892%2C1.04892%200%200%201%20-0.0498%2C-0.00672%20c%200.0168%2C0.00204%200.03348%2C0.00432%200.0498%2C0.00672%20C%202.35956%2C1.6798189%202.7073199%2C1.5688189%202.80512%2C1.240499%202.8346401%2C1.141139%202.88%2C0.54569891%202.88%2C0.46313901%20c%200%2C-0.0828%20-0.01668%2C-0.22332%20-0.10824%2C-0.26472%20-0.07908%2C-0.03576%20-0.19968%2C-0.0744%20-0.516%2C0.1488%20C%201.92552%2C0.58061901%201.5704399%2C1.053299%201.44%2C1.306859%22%0A%20%20%20%20%20style%3D%22stroke-width%3A0.12%22%0A%20%20%20%20%20id%3D%22path2%22%20%2F%3E%0A%3C%2Fsvg%3E%0A")
    no-repeat;
}

.header-bluesky-link:hover {
  opacity: 0.6;
}

[data-theme='dark'] .header-bluesky-link::before {
  background: url("data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22UTF-8%22%20standalone%3D%22no%22%3F%3E%0A%3Csvg%0A%20%20%20width%3D%2224%22%0A%20%20%20height%3D%2224%22%0A%20%20%20viewBox%3D%220%200%202.88%202.88%22%0A%20%20%20version%3D%221.1%22%0A%20%20%20id%3D%22svg4%22%0A%20%20%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%0A%20%20%20xmlns%3Asvg%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%20%20%3Cdefs%0A%20%20%20%20%20id%3D%22defs8%22%20%2F%3E%0A%20%20%3Cpath%0A%20%20%20%20%20fill%3D%22%23959da5%22%0A%20%20%20%20%20d%3D%22M%201.44%2C1.306859%20C%201.30956%2C1.053179%200.95447995%2C0.58049901%200.62423999%2C0.34745901%200.30791999%2C0.12413901%200.18732%2C0.16277901%200.10824%2C0.19865901%200.01668%2C0.23981901%200%2C0.38045901%200%2C0.46301901%20c%200%2C0.0828%200.04536%2C0.67799999%200.07488%2C0.77747999%200.0978%2C0.32832%200.44556%2C0.4392%200.76595999%2C0.4036799%200.01632%2C-0.0024%200.033%2C-0.00468%200.0498%2C-0.00672%20-0.01656%2C0.00264%20-0.03312%2C0.0048%20-0.0498%2C0.00672%20C%200.3714%2C1.7137789%20-0.0456%2C1.884779%200.50124%2C2.493539%201.1027999%2C3.1163391%201.3256399%2C2.359979%201.44%2C1.976579%201.55436%2C2.359979%201.686%2C3.0890991%202.36796%2C2.493539%202.88%2C1.976579%202.5086%2C1.713779%202.0391599%2C1.6441789%20a%201.04892%2C1.04892%200%200%201%20-0.0498%2C-0.00672%20c%200.0168%2C0.00204%200.03348%2C0.00432%200.0498%2C0.00672%20C%202.35956%2C1.6798189%202.7073199%2C1.5688189%202.80512%2C1.240499%202.8346401%2C1.141139%202.88%2C0.54569891%202.88%2C0.46313901%20c%200%2C-0.0828%20-0.01668%2C-0.22332%20-0.10824%2C-0.26472%20-0.07908%2C-0.03576%20-0.19968%2C-0.0744%20-0.516%2C0.1488%20C%201.92552%2C0.58061901%201.5704399%2C1.053299%201.44%2C1.306859%22%0A%20%20%20%20%20style%3D%22stroke-width%3A0.12%22%0A%20%20%20%20%20id%3D%22path2%22%20%2F%3E%0A%3C%2Fsvg%3E%0A")
    no-repeat;
}

.header-linkedin-link::before {
  content: '';
  width: 24px;
  height: 24px;
  display: flex;
  background: url("data:image/svg+xml,%0A%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 19 18'%3E%3Cpath d='M3.94 2A2 2 0 1 1 2 0a2 2 0 0 1 1.94 2zM4 5.48H0V18h4zm6.32 0H6.34V18h3.94v-6.57c0-3.66 4.77-4 4.77 0V18H19v-7.93c0-6.17-7.06-5.94-8.72-2.91z' fill='rgb(149, 157, 165)'/%3E%3C/svg%3E")
    no-repeat;
}

.header-linkedin-link:hover {
  opacity: 0.6;
}

[data-theme='dark'] .header-linkedin-link::before {
  background-image: url("data:image/svg+xml,%0A%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 19 18'%3E%3Cpath d='M3.94 2A2 2 0 1 1 2 0a2 2 0 0 1 1.94 2zM4 5.48H0V18h4zm6.32 0H6.34V18h3.94v-6.57c0-3.66 4.77-4 4.77 0V18H19v-7.93c0-6.17-7.06-5.94-8.72-2.91z' fill='rgb(149, 157, 165)'/%3E%3C/svg%3E")
    no-repeat;
}

.header-x-link::before {
  content: '';
  width: 24px;
  height: 24px;
  display: flex;
  background: url("data:image/svg+xml,%3Csvg%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%20viewBox%3D%220%200%201200%201227%22%20fill%3D%22rgb(149%2C%20157%2C%20165)%22%3E%3Cpath%20d%3D%22M714.163%20519.284%201160.89%200h-105.86L667.137%20450.887%20357.328%200H0l468.492%20681.821L0%201226.37h105.866l409.625-476.152%20327.181%20476.152H1200L714.137%20519.284h.026ZM569.165%20687.828l-47.468-67.894-377.686-540.24h162.604l304.797%20435.991%2047.468%2067.894%20396.2%20566.721H892.476L569.165%20687.854v-.026Z%22%20%2F%3E%3C%2Fsvg%3E")
    no-repeat;
}

.header-x-link:hover {
  opacity: 0.6;
}

[data-theme='dark'] .header-x-link::before {
  background: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' fill='%231DA1F2' viewBox='0 0 20 20' aria-hidden='true'%3E%3Cpath d='M19.96 3.808a8.333 8.333 0 01-2.353.646 4.132 4.132 0 001.802-2.269 8.47 8.47 0 01-2.606.987 4.1 4.1 0 00-6.986 3.735c-3.409-.161-6.428-1.799-8.45-4.272a4.018 4.018 0 00-.555 2.063A4.1 4.1 0 002.635 8.11a4.087 4.087 0 01-1.857-.513v.05a4.102 4.102 0 003.289 4.022 4.162 4.162 0 01-1.844.07 4.114 4.114 0 003.837 2.848 8.223 8.223 0 01-5.085 1.755c-.325 0-.65-.02-.975-.056a11.662 11.662 0 006.298 1.84c7.544 0 11.665-6.246 11.665-11.654 0-.175 0-.35-.013-.525A8.278 8.278 0 0020 3.825l-.04-.017z'/%3E%3C/svg%3E%0A")
    no-repeat;
}

.header-discord-link::before {
  content: '';
  width: 24px;
  height: 18px;
  display: flex;
  background: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 127.14 96.36'%3E%3Cpath fill='rgb(149, 157, 165)' d='M107.7,8.07A105.15,105.15,0,0,0,81.47,0a72.06,72.06,0,0,0-3.36,6.83A97.68,97.68,0,0,0,49,6.83,72.37,72.37,0,0,0,45.64,0,105.89,105.89,0,0,0,19.39,8.09C2.79,32.65-1.71,56.6.54,80.21h0A105.73,105.73,0,0,0,32.71,96.36,77.7,77.7,0,0,0,39.6,85.25a68.42,68.42,0,0,1-10.85-5.18c.91-.66,1.8-1.34,2.66-2a75.57,75.57,0,0,0,64.32,0c.87.71,1.76,1.39,2.66,2a68.68,68.68,0,0,1-10.87,5.19,77,77,0,0,0,6.89,11.1A105.25,105.25,0,0,0,126.6,80.22h0C129.24,52.84,122.09,29.11,107.7,8.07ZM42.45,65.69C36.18,65.69,31,60,31,53s5-12.74,11.43-12.74S54,46,53.89,53,48.84,65.69,42.45,65.69Zm42.24,0C78.41,65.69,73.25,60,73.25,53s5-12.74,11.44-12.74S96.23,46,96.12,53,91.08,65.69,84.69,65.69Z'/%3E%3C/svg%3E%0A")
    no-repeat;
}

.header-discord-link:hover {
  opacity: 0.6;
}

[data-theme='dark'] .header-discord-link::before {
  background: url("data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 127.14 96.36'%3E%3Cpath fill='rgb(149, 157, 165)' d='M107.7,8.07A105.15,105.15,0,0,0,81.47,0a72.06,72.06,0,0,0-3.36,6.83A97.68,97.68,0,0,0,49,6.83,72.37,72.37,0,0,0,45.64,0,105.89,105.89,0,0,0,19.39,8.09C2.79,32.65-1.71,56.6.54,80.21h0A105.73,105.73,0,0,0,32.71,96.36,77.7,77.7,0,0,0,39.6,85.25a68.42,68.42,0,0,1-10.85-5.18c.91-.66,1.8-1.34,2.66-2a75.57,75.57,0,0,0,64.32,0c.87.71,1.76,1.39,2.66,2a68.68,68.68,0,0,1-10.87,5.19,77,77,0,0,0,6.89,11.1A105.25,105.25,0,0,0,126.6,80.22h0C129.24,52.84,122.09,29.11,107.7,8.07ZM42.45,65.69C36.18,65.69,31,60,31,53s5-12.74,11.43-12.74S54,46,53.89,53,48.84,65.69,42.45,65.69Zm42.24,0C78.41,65.69,73.25,60,73.25,53s5-12.74,11.44-12.74S96.23,46,96.12,53,91.08,65.69,84.69,65.69Z'/%3E%3C/svg%3E%0A")
    no-repeat;
}

.header-tiktok-link::before {
  content: '';
  width: 24px;
  height: 24px;
  display: flex;
  background: url("data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22UTF-8%22%20standalone%3D%22no%22%3F%3E%0A%3Csvg%0A%20%20%20fill%3D%22%23959da5%22%0A%20%20%20width%3D%2224%22%0A%20%20%20height%3D%2224%22%0A%20%20%20viewBox%3D%220%200%200.72%200.72%22%0A%20%20%20xml%3Aspace%3D%22preserve%22%0A%20%20%20version%3D%221.1%22%0A%20%20%20id%3D%22svg4%22%0A%20%20%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%0A%20%20%20xmlns%3Asvg%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%3Cdefs%0A%20%20%20%20%20id%3D%22defs8%22%20%2F%3E%3Cpath%0A%20%20%20%20%20d%3D%22M%200.63539429%2C0.16867393%20A%200.1725255%2C0.17252543%200%200%201%200.49969199%2C0.01587392%20V%200%20h%20-0.1240039%20v%200.49212763%20a%200.10424241%2C0.10424236%200%200%201%20-0.1872116%2C0.0627398%20l%20-7.2e-5%2C-3.6e-5%207.2e-5%2C3.6e-5%20A%200.10420641%2C0.10420637%200%200%201%200.30304959%2C0.39252865%20V%200.26654513%20A%200.22781429%2C0.2278142%200%200%200%200.10889089%2C0.65140678%200.22785029%2C0.2278502%200%200%200%200.49969199%2C0.4921636%20V%200.24070051%20a%200.2945136%2C0.29451347%200%200%200%200.1718056%2C0.0549288%20V%200.17241745%20a%200.17389332%2C0.17389325%200%200%201%20-0.0361033%2C-0.003744%20z%22%0A%20%20%20%20%20id%3D%22path2%22%0A%20%20%20%20%20style%3D%22stroke-width%3A0.0359952%22%20%2F%3E%3C%2Fsvg%3E%0A")
    no-repeat;
}

.header-tiktok-link:hover {
  opacity: 0.6;
}

.header-youtube-link::before {
  content: '';
  width: 24px;
  height: 20px;
  display: flex;
  background: url("data:image/svg+xml,%3C%3Fxml%20version%3D%221.0%22%20encoding%3D%22UTF-8%22%20standalone%3D%22no%22%3F%3E%0A%3Csvg%0A%20%20%20viewBox%3D%220%200%2024%2024%22%0A%20%20%20version%3D%221.1%22%0A%20%20%20id%3D%22svg4%22%0A%20%20%20width%3D%2224%22%0A%20%20%20height%3D%2224%22%0A%20%20%20xmlns%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%0A%20%20%20xmlns%3Asvg%3D%22http%3A%2F%2Fwww.w3.org%2F2000%2Fsvg%22%3E%0A%20%20%3Cdefs%0A%20%20%20%20%20id%3D%22defs8%22%20%2F%3E%0A%20%20%3Cpath%0A%20%20%20%20%20d%3D%22M%2023.496693%2C5.8315054%20A%203.0042862%2C3.0042862%200%200%200%2021.393692%2C3.6909515%20C%2019.516013%2C3.1652014%2011.992781%2C3.1652014%2011.992781%2C3.1652014%20A%2072.040279%2C72.040279%200%200%200%202.6043863%2C3.6659158%203.1169469%2C3.1169469%200%200%200%200.488868%2C5.8315054%2032.884416%2C32.884416%200%200%200%206.7149698e-4%2C11.677346%2032.734202%2C32.734202%200%200%200%200.488868%2C17.523186%203.0418398%2C3.0418398%200%200%200%202.6043863%2C19.663739%20c%201.9027146%2C0.525751%209.3883947%2C0.525751%209.3883947%2C0.525751%20a%2072.215529%2C72.215529%200%200%200%209.400911%2C-0.500715%203.0042862%2C3.0042862%200%200%200%202.103001%2C-2.140554%2032.083273%2C32.083273%200%200%200%200.500714%2C-5.845839%2030.042862%2C30.042862%200%200%200%20-0.500714%2C-5.8708766%20z%20M%209.6018695%2C15.320042%20V%208.0346486%20l%206.2589285%2C3.6426974%20z%22%0A%20%20%20%20%20fill%3D%22%23959da5%22%0A%20%20%20%20%20id%3D%22path2%22%0A%20%20%20%20%20style%3D%22stroke-width%3A1.25179%22%20%2F%3E%0A%3C%2Fsvg%3E%0A")
    no-repeat;
}

.header-youtube-link:hover {
  opacity: 0.6;
}

header .container {
  max-width: 9000px;
}

```

`docs/src/pages/index.module.css`:

```css
/*
 * Copyright (c) 2024- Datalayer, Inc.
 *
 * BSD 3-Clause License
 */

/* stylelint-disable docusaurus/copyright-header */

/**
 * CSS files with the .module.css suffix will be treated as CSS modules
 * and scoped locally.
 */

.heroBanner {
  padding: 4rem 0;
  text-align: center;
  position: relative;
  overflow: hidden;
}

@media screen and (max-width: 966px) {
  .heroBanner {
    padding: 2rem;
  }
}

.buttons {
  display: flex;
  align-items: center;
  justify-content: center;
}

.tag {
  font-size: small;
  padding: 4px;
  border-radius: 5px;
  border-width: thick;
  border-color: red;
  background: orange;
}

```

`docs/src/pages/markdown-page.md`:

```md
<!--
  ~ Copyright (c) 2024- Datalayer, Inc.
  ~
  ~ BSD 3-Clause License
-->

---
title: Markdown page example
---

# Markdown page example

You don't need React to write simple standalone pages.

```

`docs/src/pages/testimonials.tsx`:

```tsx
/*
 * Copyright (c) 2024- Datalayer, Inc.
 *
 * BSD 3-Clause License
 */

import React from 'react';
import Layout from '@theme/Layout';
import useDocusaurusContext from '@docusaurus/useDocusaurusContext';
import HomepageFeatures from '../components/HomepageFeatures';

export default function Home() {
  const {siteConfig} = useDocusaurusContext();
  return (
    <Layout
      title={`${siteConfig.title}`}
      description="Datalayer, cloud native Jupyter">
      <main>
        <HomepageFeatures />
      </main>
    </Layout>
  );
}

```

`docs/src/theme/CustomDocItem.tsx`:

```tsx
import React from "react";
import { ThemeProvider } from '@primer/react-brand';
import DocItem from "@theme/DocItem";

import '@primer/react-brand/lib/css/main.css'

export const CustomDocItem = (props: any) => {
  return (
    <>
      <ThemeProvider>
        <DocItem {...props}/>
      </ThemeProvider>
    </>
  )
}

export default CustomDocItem;

```

`docs/static/img/datalayer/logo.svg`:

```svg
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!--
  ~ Copyright (c) 2024- Datalayer, Inc.
  ~
  ~ BSD 3-Clause License
-->

<!-- Generator: Adobe Illustrator 15.0.0, SVG Export Plug-In . SVG Version: 6.00 Build 0)  -->

<svg
   xmlns:dc="http://purl.org/dc/elements/1.1/"
   xmlns:cc="http://creativecommons.org/ns#"
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:svg="http://www.w3.org/2000/svg"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   version="1.1"
   x="0px"
   y="0px"
   width="100"
   height="100"
   viewBox="0 0 99.999997 99.999999"
   enable-background="new 0 0 130.395 175.748"
   xml:space="preserve"
   id="svg1104"
   sodipodi:docname="logo_square.svg"
   inkscape:version="0.92.2 5c3e80d, 2017-08-06"
   inkscape:export-filename="/Users/echar4/private/marketing/datalayer/logo/corporate/png/logo_square.png"
   inkscape:export-xdpi="300"
   inkscape:export-ydpi="300"><metadata
     id="metadata1110"><rdf:RDF><cc:Work
         rdf:about=""><dc:format>image/svg+xml</dc:format><dc:type
           rdf:resource="http://purl.org/dc/dcmitype/StillImage" /><dc:title /></cc:Work></rdf:RDF></metadata><defs
     id="defs1108" /><sodipodi:namedview
     pagecolor="#ffffff"
     bordercolor="#666666"
     borderopacity="1"
     objecttolerance="10"
     gridtolerance="10"
     guidetolerance="10"
     inkscape:pageopacity="0"
     inkscape:pageshadow="2"
     inkscape:window-width="1406"
     inkscape:window-height="746"
     id="namedview1106"
     showgrid="false"
     inkscape:zoom="0.94952545"
     inkscape:cx="24.718555"
     inkscape:cy="60.203158"
     inkscape:window-x="0"
     inkscape:window-y="0"
     inkscape:window-maximized="0"
     inkscape:current-layer="svg1104" /><g
     id="g439"
     transform="matrix(0.88192626,0,0,0.88192547,4694.9029,20.001364)"><linearGradient
       y2="12.7559"
       x2="-5278.1094"
       y1="12.7559"
       x1="-5295.1172"
       gradientUnits="userSpaceOnUse"
       id="SVGID_43_"><stop
         id="stop397"
         style="stop-color:#28B899"
         offset="0" /><stop
         id="stop399"
         style="stop-color:#1B937B"
         offset="1" /></linearGradient><rect
       style="fill:url(#SVGID_43_)"
       id="rect402"
       height="14.173"
       width="17.007999"
       y="5.6690001"
       x="-5295.1172" /><linearGradient
       y2="12.7559"
       x2="-5238.4248"
       y1="12.7559"
       x1="-5278.1094"
       gradientUnits="userSpaceOnUse"
       id="SVGID_44_"><stop
         id="stop404"
         style="stop-color:#03594A"
         offset="0" /><stop
         id="stop406"
         style="stop-color:#128570"
         offset="1" /></linearGradient><rect
       style="fill:url(#SVGID_44_)"
       id="rect409"
       height="14.173"
       width="39.685001"
       y="5.6690001"
       x="-5278.1089" /><linearGradient
       y2="34.014599"
       x2="-5266.7715"
       y1="34.014599"
       x1="-5295.1172"
       gradientUnits="userSpaceOnUse"
       id="SVGID_45_"><stop
         id="stop411"
         style="stop-color:#28B899"
         offset="0" /><stop
         id="stop413"
         style="stop-color:#1B937B"
         offset="1" /></linearGradient><rect
       style="fill:url(#SVGID_45_)"
       id="rect416"
       height="14.173"
       width="28.346001"
       y="26.927999"
       x="-5295.1172" /><linearGradient
       y2="34.013699"
       x2="-5238.4248"
       y1="34.013699"
       x1="-5266.7715"
       gradientUnits="userSpaceOnUse"
       id="SVGID_46_"><stop
         id="stop418"
         style="stop-color:#03594A"
         offset="0" /><stop
         id="stop420"
         style="stop-color:#128570"
         offset="1" /></linearGradient><rect
       style="fill:url(#SVGID_46_)"
       id="rect423"
       height="14.171"
       width="28.347"
       y="26.927999"
       x="-5266.771" /><linearGradient
       y2="55.274399"
       x2="-5255.4326"
       y1="55.274399"
       x1="-5295.1172"
       gradientUnits="userSpaceOnUse"
       id="SVGID_47_"><stop
         id="stop425"
         style="stop-color:#28B899"
         offset="0" /><stop
         id="stop427"
         style="stop-color:#1B937B"
         offset="1" /></linearGradient><rect
       style="fill:url(#SVGID_47_)"
       id="rect430"
       height="14.174"
       width="39.685001"
       y="48.188"
       x="-5295.1172" /><linearGradient
       y2="55.274399"
       x2="-5238.4229"
       y1="55.274399"
       x1="-5255.4326"
       gradientUnits="userSpaceOnUse"
       id="SVGID_48_"><stop
         id="stop432"
         style="stop-color:#03594A"
         offset="0" /><stop
         id="stop434"
         style="stop-color:#128570"
         offset="1" /></linearGradient><rect
       style="fill:url(#SVGID_48_)"
       id="rect437"
       height="14.174"
       width="17.01"
       y="48.188"
       x="-5255.4331" /></g></svg>
```

`docs/static/img/feature_1.svg`:

```svg
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!--
  ~ Copyright (c) 2024- Datalayer, Inc.
  ~
  ~ BSD 3-Clause License
-->

<svg
   xmlns:dc="http://purl.org/dc/elements/1.1/"
   xmlns:cc="http://creativecommons.org/ns#"
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:svg="http://www.w3.org/2000/svg"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   viewBox="0 0 143.86 320.16998"
   version="1.1"
   id="svg1038"
   sodipodi:docname="feature_1.svg"
   inkscape:version="1.0.1 (c497b03c, 2020-09-10)"
   width="143.86"
   height="320.16998">
  <metadata
     id="metadata1042">
    <rdf:RDF>
      <cc:Work
         rdf:about="">
        <dc:format>image/svg+xml</dc:format>
        <dc:type
           rdf:resource="http://purl.org/dc/dcmitype/StillImage" />
        <dc:title>Startup_SVG</dc:title>
      </cc:Work>
    </rdf:RDF>
  </metadata>
  <sodipodi:namedview
     pagecolor="#ffffff"
     bordercolor="#666666"
     borderopacity="1"
     objecttolerance="10"
     gridtolerance="10"
     guidetolerance="10"
     inkscape:pageopacity="0"
     inkscape:pageshadow="2"
     inkscape:window-width="1440"
     inkscape:window-height="717"
     id="namedview1040"
     showgrid="false"
     inkscape:zoom="1.0226025"
     inkscape:cx="117.68707"
     inkscape:cy="153.04271"
     inkscape:window-x="0"
     inkscape:window-y="25"
     inkscape:window-maximized="0"
     inkscape:current-layer="svg1038"
     inkscape:document-rotation="0"
     fit-margin-top="0"
     fit-margin-left="0"
     fit-margin-right="0"
     fit-margin-bottom="0" />
  <defs
     id="defs835">
    <style
       id="style833">.cls-1,.cls-11,.cls-9{fill:#d6d8e5;}.cls-1{opacity:0.15;}.cls-2,.cls-3{fill:#edeff9;}.cls-2{opacity:0.5;}.cls-4{fill:#ffbc00;}.cls-5{fill:#8c50ff;}.cls-6{fill:#424956;}.cls-7{fill:#494949;}.cls-8{fill:#2b303f;}.cls-9{opacity:0.4;}.cls-10{fill:#b1b4c4;}.cls-12{fill:#9ea1af;}.cls-13{fill:#c4c7d6;}.cls-14{fill:#e4e7f2;}.cls-15{fill:#fff;}.cls-16{fill:#e9eaf2;}.cls-17{fill:#f5f6ff;}.cls-18,.cls-19{fill:none;stroke:#e9eaf2;stroke-miterlimit:10;}.cls-18{stroke-width:0.31px;}.cls-19{stroke-width:1.53px;}.cls-20{fill:#edf0f9;}.cls-21{fill:#e2e5f2;}.cls-22{fill:#6e48e5;}.cls-23{fill:#5e42d3;}.cls-24{fill:#ffcea9;}.cls-25{fill:#ededed;}.cls-26{fill:#38226d;}.cls-27{fill:#9c73ff;}.cls-28{fill:#f4f4f4;}.cls-29{fill:#3a2c6d;}.cls-30{isolation:isolate;}</style>
  </defs>
  <title
     id="title837">Startup_SVG</title>
  <ellipse
     class="cls-1"
     cx="71.93"
     cy="278.63998"
     rx="71.93"
     ry="41.529999"
     id="ellipse839" />
  <ellipse
     class="cls-2"
     cx="71.099998"
     cy="274.19998"
     rx="40.119999"
     ry="23.16"
     id="ellipse841" />
  <ellipse
     class="cls-3"
     cx="70.719994"
     cy="265.97998"
     rx="11.44"
     ry="6.6100001"
     id="ellipse843" />
  <rect
     class="cls-3"
     x="60.099998"
     y="178.34999"
     width="22"
     height="86.459999"
     id="rect845" />
  <path
     class="cls-4"
     d="m 59.05,177.37 c 0,0 0.6,17.78 13.25,49.67 0,0 11.78,-25.68 13,-50.21 1.22,-24.53 -26.25,0.54 -26.25,0.54 z"
     id="path847" />
  <polygon
     class="cls-5"
     points="10.85,219.48 46.25,201.73 52.69,156.37 43.6,153.81 14.33,182.29 "
     id="polygon849"
     transform="translate(-4.1748046e-7,-43.38)" />
  <polygon
     class="cls-5"
     points="133.75,219.48 98.22,200.5 91.91,156.37 101,153.81 130.26,182.29 "
     id="polygon851"
     transform="translate(-4.1748046e-7,-43.38)" />
  <ellipse
     class="cls-6"
     cx="71.93"
     cy="173.46001"
     rx="14.55"
     ry="8.3999996"
     id="ellipse853" />
  <polygon
     class="cls-7"
     points="93.94,208.72 49.87,208.44 49.87,200.88 93.94,200.88 "
     id="polygon855"
     transform="translate(-4.1748046e-7,-43.38)" />
  <ellipse
     class="cls-8"
     cx="71.93"
     cy="165.05"
     rx="22.059999"
     ry="12.74"
     id="ellipse857" />
  <ellipse
     class="cls-3"
     cx="71.859993"
     cy="153.58002"
     rx="26.92"
     ry="15.54"
     id="ellipse859" />
  <path
     class="cls-3"
     d="m 100.93,125.9 v 0 c 0,1.25 0,2.48 0,3.67 0,1 0,2 0,3 0,1.35 -0.07,2.64 -0.12,3.9 0,1.57 -0.11,3.06 -0.19,4.49 -0.08,1.43 -0.15,2.83 -0.25,4.12 -0.41,5.65 -0.4,9.81 -1.1,11.44 -3.81,8.91 -16.7,4 -23.06,0.8 -2.35,-1.18 -3.9,-2.15 -3.9,-2.15 h -0.58 c 0,0 -1.84,1 -4.56,2.08 -6.67,2.7 -18.56,7.49 -21.86,-0.76 -0.59,-1.48 -1.18,-6.37 -1.54,-11.49 -0.09,-1.28 -0.17,-2.65 -0.25,-4.11 -0.08,-1.46 -0.12,-2.91 -0.18,-4.48 0,-1.25 -0.07,-2.54 -0.1,-3.88 0,-1 0,-2 0,-3 v 0 -3.67 0 C 43.06,90.969997 46.76,35.179997 58.98,11.369997 c 3.53,-6.89 7.77,-11.1 12.84,-11.349997 v 0 h 0.58 v 0 c 5,0.259997 9.29,4.449997 12.83,11.309997 12.05,23.72 15.92,79.29 15.7,114.570003 z"
     id="path861" />
  <circle
     class="cls-8"
     cx="71.999992"
     cy="82.829994"
     r="10.17"
     id="circle863" />
  <path
     class="cls-6"
     d="m 72,94.489997 a 11.66,11.66 0 1 1 11.66,-11.66 11.67,11.67 0 0 1 -11.66,11.66 z m 0,-20.34 a 8.68,8.68 0 1 0 8.67,8.68 8.69,8.69 0 0 0 -8.67,-8.68 z"
     id="path865" />
  <circle
     class="cls-8"
     cx="71.999992"
     cy="52.930004"
     r="10.17"
     id="circle867" />
  <path
     class="cls-6"
     d="m 72,64.619997 a 11.67,11.67 0 1 1 11.66,-11.69 11.68,11.68 0 0 1 -11.66,11.69 z m 0,-20.34 a 8.68,8.68 0 1 0 8.67,8.67 8.68,8.68 0 0 0 -8.67,-8.69 z"
     id="path869" />
  <path
     class="cls-5"
     d="m 100.93,146.01 c 0,1.25 0,2.48 0,3.68 -1,3.3 -3.72,6.46 -8.14,9 -11.46,6.61 -30,6.61 -41.51,0 -4.42,-2.56 -7.13,-5.73 -8.14,-9 v 0 -3.67 c 1,3.36 3.7,6.56 8.18,9.15 11.47,6.61 30.05,6.61 41.51,0 4.39,-2.62 7.17,-5.81 8.1,-9.16 z"
     id="path871" />
  <path
     class="cls-5"
     d="m 100.84,151.83 c 0,1.34 -0.07,2.64 -0.12,3.89 -1.12,3.12 -3.78,6.09 -8,8.51 -11.46,6.62 -30,6.62 -41.51,0 -4.21,-2.44 -6.87,-5.43 -8,-8.57 0,-1.25 -0.07,-2.54 -0.1,-3.87 1,3.26 3.73,6.36 8.09,8.88 11.47,6.62 30.05,6.62 41.51,0 4.38,-2.51 7.08,-5.6 8.13,-8.84 z"
     id="path873" />
  <path
     class="cls-5"
     d="m 100.53,141.5 c -1.21,2.93 -3.81,5.72 -7.78,8 -11.46,6.61 -30,6.61 -41.51,0 -4,-2.32 -6.6,-5.12 -7.81,-8.08 0.08,1.46 0.16,2.83 0.25,4.11 1.29,2.76 3.81,5.36 7.56,7.53 a 39.77,39.77 0 0 0 15.84,4.72 50.54,50.54 0 0 0 9,0.07 40.14,40.14 0 0 0 16.63,-4.79 c 3.72,-2.15 6.23,-4.72 7.53,-7.45 z"
     id="path875" />
  <path
     class="cls-5"
     d="m 85.05,11.349997 a 44.73,44.73 0 0 1 -26.25,0 C 62.33,4.459997 66.57,0.249997 71.64,0 v 0 h 0.58 v 0 c 5.05,0.299997 9.29,4.489997 12.83,11.349997 z"
     id="path877" />
  <rect
     class="cls-5"
     x="69.799995"
     y="110.51"
     width="4.9899998"
     height="65.510002"
     id="rect879" />
</svg>

```

`docs/static/img/feature_2.svg`:

```svg
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!--
  ~ Copyright (c) 2024- Datalayer, Inc.
  ~
  ~ BSD 3-Clause License
-->

<svg
   xmlns:dc="http://purl.org/dc/elements/1.1/"
   xmlns:cc="http://creativecommons.org/ns#"
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:svg="http://www.w3.org/2000/svg"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   viewBox="0 0 215.52 220.8421"
   version="1.1"
   id="svg1242"
   sodipodi:docname="5.svg"
   inkscape:version="1.0.1 (c497b03c, 2020-09-10)"
   width="57.022999mm"
   height="58.431137mm">
  <metadata
     id="metadata1246">
    <rdf:RDF>
      <cc:Work
         rdf:about="">
        <dc:format>image/svg+xml</dc:format>
        <dc:type
           rdf:resource="http://purl.org/dc/dcmitype/StillImage" />
        <dc:title>Marketing_strategy_SVG</dc:title>
      </cc:Work>
    </rdf:RDF>
  </metadata>
  <sodipodi:namedview
     pagecolor="#ffffff"
     bordercolor="#666666"
     borderopacity="1"
     objecttolerance="10"
     gridtolerance="10"
     guidetolerance="10"
     inkscape:pageopacity="0"
     inkscape:pageshadow="2"
     inkscape:window-width="1440"
     inkscape:window-height="635"
     id="namedview1244"
     showgrid="false"
     inkscape:zoom="0.49908293"
     inkscape:cx="-364.03258"
     inkscape:cy="111.25926"
     inkscape:window-x="0"
     inkscape:window-y="25"
     inkscape:window-maximized="0"
     inkscape:current-layer="Ğ¡Ğ»Ğ¾Ğ¹_1-2"
     inkscape:document-rotation="0"
     units="mm"
     fit-margin-top="0"
     fit-margin-left="0"
     fit-margin-right="0"
     fit-margin-bottom="0" />
  <defs
     id="defs835">
    <style
       id="style833">.cls-1,.cls-15,.cls-4{fill:#d6d8e5;}.cls-1{opacity:0.4;}.cls-2{fill:#b1b4c4;}.cls-3{fill:#9ea2b2;}.cls-5{fill:#f4f4f4;}.cls-6{fill:#9acc12;}.cls-7{fill:#e8bc05;}.cls-8{fill:#ef6848;}.cls-9{fill:#be4aed;}.cls-10{fill:#543526;}.cls-11{fill:#1b96ea;}.cls-12{fill:#ff5050;}.cls-13{fill:#32cec3;}.cls-14{fill:none;stroke:#d6d8e5;stroke-miterlimit:10;stroke-width:1.42px;}.cls-15{opacity:0.3;}.cls-16{fill:#dd990e;}.cls-17{fill:#f9cb07;}.cls-18{fill:#cc8b09;}.cls-19{fill:#e8a30a;}.cls-20{fill:#f9ca06;}.cls-21{fill:#3a2c6d;}.cls-22{fill:#ffcea9;}.cls-23{fill:#38226d;}.cls-24{fill:#9c73ff;}.cls-25{fill:#8c50ff;}.cls-26{fill:#ededed;}.cls-27{fill:#d33d3d;}.cls-28{fill:#ff4d4d;}.cls-29{fill:#2b303f;}</style>
  </defs>
  <title
     id="title837">Marketing_strategy_SVG</title>
  <g
     id="Ğ¡Ğ»Ğ¾Ğ¹_1-2"
     data-name="Ğ¡Ğ»Ğ¾Ğ¹ 1"
     transform="translate(-88.126634,-152.59003)">
    <path
       class="cls-1"
       d="m 278.96663,372.54665 -113.6,-65.58 a 6.38,6.38 0 0 1 0,-11.05 v 0 a 6.38,6.38 0 0 1 6.38,0 l 113.6,65.63 a 6.38,6.38 0 0 1 -0.73,11.41 v 0 a 6.36,6.36 0 0 1 -5.65,-0.41 z"
       id="path1214" />
    <path
       class="cls-27"
       d="m 229.91663,332.87665 c -40.66,-23.47 -73.73,-80.76 -73.73,-127.7 0,-46.94 33.07,-66 73.73,-42.56 40.66,23.44 73.73,80.75 73.73,127.7 0,46.95 -33.08,66.03 -73.73,42.56 z m 0,-155 c -33.38,-19.27 -60.54,-3.59 -60.54,34.95 0,38.54 27.16,85.57 60.54,104.84 33.38,19.27 60.53,3.6 60.53,-34.94 0,-38.54 -27.15,-85.61 -60.53,-104.88 z"
       id="path1216" />
    <polygon
       class="cls-27"
       points="83.82,129.6 97.33,122.22 95.31,131.48 "
       id="polygon1218"
       transform="translate(83.866634,33.546654)" />
    <path
       class="cls-27"
       d="m 269.48663,344.82665 c 0.33,-0.15 14.77,-8.23 14.77,-8.23 l -11.16,-1.79 z"
       id="path1220" />
    <ellipse
       class="cls-5"
       cx="64.47393"
       cy="329.32858"
       rx="54.810001"
       ry="94.940002"
       transform="rotate(-30)"
       id="ellipse1222" />
    <path
       class="cls-28"
       d="m 220.50663,338.10665 c -40.64,-23.48 -73.73,-80.76 -73.73,-127.71 0,-46.95 33.08,-66 73.73,-42.56 40.65,23.44 73.73,80.76 73.73,127.7 0,46.94 -33.07,66.01 -73.73,42.57 z m 0,-155 c -33.37,-19.27 -60.53,-3.6 -60.53,34.94 0,38.54 27.16,85.58 60.53,104.85 33.37,19.27 60.54,3.59 60.54,-34.95 0,-38.54 -27.18,-85.6 -60.54,-104.87 z"
       id="path1224" />
    <path
       class="cls-28"
       d="m 220.50663,305.70665 c -25.18,-14.54 -45.64,-50.03 -45.64,-79.11 0,-29.08 20.49,-40.91 45.67,-26.37 25.18,14.54 45.68,50 45.68,79.11 0,29.11 -20.52,40.92 -45.71,26.37 z m 0,-90.24 c -17.91,-10.34 -32.48,-1.93 -32.48,18.75 0,20.68 14.57,45.92 32.48,56.26 17.91,10.34 32.48,1.92 32.48,-18.76 0,-20.68 -14.57,-45.91 -32.48,-56.25 z"
       id="path1226" />
    <path
       class="cls-28"
       d="m 220.50663,273.82665 c -10,-5.75 -18.06,-19.79 -18.06,-31.29 0,-11.5 8.1,-16.18 18.06,-10.43 9.96,5.75 18.07,19.79 18.07,31.29 0,11.5 -8.1,16.15 -18.07,10.43 z m 0,-26.48 c -2.68,-1.55 -4.87,-0.29 -4.87,2.81 a 10.79,10.79 0 0 0 4.87,8.43 c 2.69,1.55 4.87,0.29 4.87,-2.81 a 10.76,10.76 0 0 0 -4.87,-8.43 z"
       id="path1228" />
    <polygon
       class="cls-29"
       points="26.22,281.67 13.49,289.58 11.02,290.9 4.26,290.99 "
       id="polygon1230"
       transform="translate(83.866634,33.546654)" />
    <ellipse
       class="cls-19"
       cx="-79.061852"
       cy="330.15607"
       rx="1.41"
       ry="2.4400001"
       transform="rotate(-30)"
       id="ellipse1232" />
    <ellipse
       class="cls-19"
       cx="64.443764"
       cy="330.02509"
       rx="1.41"
       ry="2.4400001"
       transform="rotate(-30)"
       id="ellipse1234" />
    <polygon
       class="cls-29"
       points="31.69,282.7 30.92,284.29 15.64,300.69 14.03,293.96 "
       id="polygon1236"
       transform="translate(83.866634,33.546654)" />
    <path
       class="cls-19"
       d="m 97.866634,327.54665 c 0.15,-0.13 124.149996,-71.81 124.149996,-71.81 l -2.28,-4.3 -124.379996,72 z"
       id="path1238" />
  </g>
</svg>

```

`docs/static/img/feature_3.svg`:

```svg
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!--
  ~ Copyright (c) 2024- Datalayer, Inc.
  ~
  ~ BSD 3-Clause License
-->

<svg
   xmlns:dc="http://purl.org/dc/elements/1.1/"
   xmlns:cc="http://creativecommons.org/ns#"
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:svg="http://www.w3.org/2000/svg"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   viewBox="0 0 302.65826 398.12268"
   version="1.1"
   id="svg1054"
   sodipodi:docname="6.svg"
   inkscape:version="1.0.1 (c497b03c, 2020-09-10)"
   width="302.65826"
   height="398.12268">
  <metadata
     id="metadata1058">
    <rdf:RDF>
      <cc:Work
         rdf:about="">
        <dc:format>image/svg+xml</dc:format>
        <dc:type
           rdf:resource="http://purl.org/dc/dcmitype/StillImage" />
        <dc:title>Web_SVG</dc:title>
      </cc:Work>
    </rdf:RDF>
  </metadata>
  <sodipodi:namedview
     pagecolor="#ffffff"
     bordercolor="#666666"
     borderopacity="1"
     objecttolerance="10"
     gridtolerance="10"
     guidetolerance="10"
     inkscape:pageopacity="0"
     inkscape:pageshadow="2"
     inkscape:window-width="1256"
     inkscape:window-height="607"
     id="namedview1056"
     showgrid="false"
     inkscape:zoom="0.83484846"
     inkscape:cx="105.00162"
     inkscape:cy="149.95736"
     inkscape:window-x="0"
     inkscape:window-y="25"
     inkscape:window-maximized="0"
     inkscape:current-layer="svg1054"
     inkscape:document-rotation="0"
     fit-margin-top="0"
     fit-margin-left="0"
     fit-margin-right="0"
     fit-margin-bottom="0" />
  <defs
     id="defs843">
    <style
       id="style833">.cls-1{fill:none;}.cls-2,.cls-9{fill:#d6d8e5;}.cls-2{opacity:0.4;isolation:isolate;}.cls-3{fill:#d5d6e0;}.cls-4{fill:#e9eaf4;}.cls-5{fill:url(#Ğ‘ĞµĞ·Ñ‹Ğ¼ÑĞ½Ğ½Ñ‹Ğ¹_Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚_15);}.cls-6{clip-path:url(#clip-path);}.cls-7{fill:#8c50ff;}.cls-8{opacity:0.05;}.cls-9{opacity:0.4;}.cls-10{fill:#c5c7d3;}.cls-11{fill:#38226d;}.cls-12{fill:#9c73ff;}.cls-13{fill:#ffcea9;}.cls-14{fill:#ededed;}.cls-15{fill:#e5e5e5;}.cls-16{fill:#f4f4f4;}.cls-17{fill:#bfbfbf;}.cls-18{fill:#3a2c6d;}.cls-19{fill:#dceeff;}.cls-20{fill:#dbdbdb;}.cls-21{fill:#1e3779;}.cls-22{fill:#031f60;}</style>
    <linearGradient
       id="Ğ‘ĞµĞ·Ñ‹Ğ¼ÑĞ½Ğ½Ñ‹Ğ¹_Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚_15"
       x1="235.62"
       y1="356.16"
       x2="235.62"
       y2="256.92999"
       gradientUnits="userSpaceOnUse">
      <stop
         offset="0"
         stop-color="#e9eaf4"
         id="stop835" />
      <stop
         offset="0.63"
         stop-color="#e9eaf4"
         stop-opacity="0"
         id="stop837" />
    </linearGradient>
    <clipPath
       id="clip-path">
      <circle
         class="cls-1"
         cx="233.41"
         cy="151.32001"
         r="151.32001"
         id="circle840" />
    </clipPath>
  </defs>
  <title
     id="title845">Web_SVG</title>
  <path
     class="cls-2"
     d="m 146.09827,397.27001 -47.08,-27.18 c -2.19,-1.27 -1.92,-3.48 0.62,-4.94 l 45.84,-26.47 c 2.54,-1.46 6.37,-1.62 8.56,-0.36 l 47.07,27.18 c 2.2,1.27 1.92,3.48 -0.61,4.94 l -45.85,26.47 c -2.53,1.47 -6.36,1.62 -8.55,0.36 z"
     id="path847" />
  <path
     class="cls-3"
     d="m 205.92827,362.37001 -2.32,0.71 -46.23,-26.7 c -2.19,-1.26 -6,-1.1 -8.55,0.36 l -45.85,26.47 -0.11,0.07 -2,-0.61 v 3 c 0,0.11 0,0.22 0,0.34 v 0.24 0 a 2.68,2.68 0 0 0 1.44,1.86 l 47.08,27.18 c 2.19,1.26 6,1.11 8.56,-0.36 l 45.98,-26.43 a 3.62,3.62 0 0 0 2.08,-2.64 v 0 z"
     id="path851" />
  <path
     class="cls-4"
     d="m 149.47827,392.14001 -47.08,-27.14 c -2.19,-1.26 -1.91,-3.47 0.62,-4.93 l 45.85,-26.47 c 2.53,-1.47 6.36,-1.63 8.55,-0.36 l 47.08,27.18 c 2.19,1.27 1.92,3.48 -0.62,4.94 l -45.84,26.47 c -2.54,1.42 -6.37,1.58 -8.56,0.31 z"
     id="path853" />
  <path
     class="cls-3"
     d="m 173.30827,360.25001 v -4 l -5.7,1.5 -12.68,-7.35 a 3.58,3.58 0 0 0 -3.24,0.14 l -12.33,7.12 -5.83,-1.54 v 4.31 0 1 a 0.48,0.48 0 0 0 0,0.12 v 0.1 0 a 1,1 0 0 0 0.55,0.7 l 17.85,10.39 a 3.61,3.61 0 0 0 3.24,-0.13 l 17.38,-10 a 1.36,1.36 0 0 0 0.78,-1 v 0 -1.32 z"
     id="path855" />
  <path
     class="cls-4"
     d="m 151.92827,367.33001 -17.87,-10.33 c -0.83,-0.48 -0.73,-1.32 0.23,-1.87 l 17.38,-10 a 3.58,3.58 0 0 1 3.26,-0.13 l 17.84,10.3 c 0.83,0.48 0.73,1.32 -0.23,1.88 l -17.38,10 a 3.61,3.61 0 0 1 -3.23,0.15 z"
     id="path857" />
  <polygon
     class="cls-5"
     points="129.08,260.92 342.17,256.93 235.48,356.16 "
     id="polygon859"
     style="fill:url(#%D0%91%D0%B5%D0%B7%D1%8B%D0%BC%D1%8F%D0%BD%D0%BD%D1%8B%D0%B9_%D0%B3%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82_15)"
     transform="translate(-82.071732)" />
  <circle
     class="cls-4"
     cx="151.33827"
     cy="151.32001"
     r="151.32001"
     id="circle861" />
  <g
     class="cls-6"
     clip-path="url(#clip-path)"
     id="g865"
     transform="translate(-82.071732)">
    <path
       class="cls-7"
       d="m 193.61,61.31 0.51,-1.79 v -3.88 a 9.1,9.1 0 0 1 -2.17,0 c -0.38,-0.17 -0.12,-1.23 -0.12,-1.23 l 1.78,-1.53 -3.57,0.76 -1.28,2 -4,2.47 1.79,1 1.15,0.76 1.72,0.26 V 59 c 0,0 2,-0.51 2.49,0.25 l -0.25,1.41 z m -44.22,55.25 a 4,4 0 0 0 -3.28,0 2.7,2.7 0 0 1 -2.56,2.73 l 2.92,1.63 2.92,-1.09 3.82,-1.27 3.27,2.36 c 2.46,-3 0,-4.73 0,-4.73 z m 62.1,55.63 -2.83,-0.6 -4.92,-3.13 h -4.32 l -3.73,-1.93 h -1.49 c 0,0 0.3,-2.09 -0.15,-2.24 -0.45,-0.15 -3.72,-2.09 -3.72,-2.09 l -2.54,0.9 v -1.79 L 186,160.56 h -1.49 l 0.15,-1.49 c 0,0 1.34,-2.65 0.6,-3.11 -0.74,-0.46 -3.43,-6.43 -3.43,-6.43 l -4,-2.24 h -4.32 l -3.73,-3.57 -3.72,-3 -2.09,-4.17 -2.24,-1.49 c 0,0 -2.53,1.64 -3.13,1.49 -0.6,-0.15 -4.32,-1.49 -4.32,-1.49 l -3.13,-0.89 -3.91,1.83 v 4 l -1.49,-1 v -1.5 l 1.34,-2.53 0.6,-1.79 -1.34,-0.59 -1.79,2.08 -4.47,1.33 -0.9,1.94 -2.09,1.94 -0.59,1.64 -3.28,-2.68 a 25.86,25.86 0 0 1 -3.43,1.49 22.67,22.67 0 0 1 -3.43,-2.24 l -1.64,-3.13 0.9,-4.17 0.74,-4.33 -2.83,-1.79 h -3.88 l -3,-0.89 1.4,-2.24 1.64,-3.28 1.49,-2.38 c 0,0 0.42,-1.09 0.9,-1.34 1.9,-1 0,-1.94 0,-1.94 0,0 -4,-0.3 -4.62,0 -0.62,0.3 -2.24,1.19 -2.24,1.19 v 3.43 l -3,1.34 -4.62,1 -3.13,-3.14 c -0.45,-0.44 -1.49,-5.36 -1.49,-5.36 l 1.93,-1.79 0.9,-1.49 0.15,-3.58 1.93,-1.64 0.75,-1.94 2.22,-1.62 2.13,-1.95 1.94,-0.59 2.68,0.59 c 0.15,-1 5.07,-0.59 5.07,-0.59 l 1.94,-0.1 -0.15,-1.09 c 0.9,-0.75 3.88,0 3.88,0 l 4,-0.34 c 0.88,0.19 1.62,2 1.62,2 l -1.79,1.64 1.2,3.57 1.19,1.64 -0.45,1.64 2.87,-0.42 0.14,-2.84 0.15,-3.43 -0.44,-3.76 2.68,-5.78 10.88,-7 -0.15,-2.54 0.74,-3.65 1.94,0.67 3.43,-4.07 4.47,-1.48 2.68,-1.82 1.34,-2.69 4.92,-1.49 4.92,-2.53 -2.26,2.41 -0.3,2.09 2.68,-0.6 2.39,-1.34 2.08,-0.59 1.94,-0.6 0.6,-1.34 h -1.34 l -2.09,-0.75 c -1.34,-1 -3,-2.23 -3,-2.23 a 1.66,1.66 0 0 1 0.44,-1.35 l 1.35,-1.21 c 0,0 0.59,-0.72 0.15,-0.72 -0.44,0 -3.73,-0.72 -3.73,-0.72 l -3.58,1.44 H 168 l 2.54,-2.21 h 2.83 l 3.13,-0.75 h 6.5 l 3.58,-0.75 2.55,-1.37 3.13,-0.32 0.9,-3.35 -2.09,-1.79 -3,-1.55 -0.6,-3.52 -1.64,-3.58 h -1.49 l -0.15,1.94 h -2.38 l -0.6,1.19 -0.89,0.6 -1.49,0.3 -1.35,-1.35 1.79,-1.93 -2.08,-1.94 -2.54,-1.34 H 172 l -1.94,0.59 -2.68,3.13 -2.09,1.79 0.6,1.64 -0.76,2.49 0.45,1 -2.54,0.9 -2.83,0.59 -1.19,-0.3 -0.9,1.2 1.64,3.35 -1.64,1.12 h -2.23 l -1.89,-2.43 -0.45,-1.38 1.34,-0.74 -1,-1.79 -3.13,-0.15 -4.17,-2.59 h -1.94 l -0.45,-1.59 -1.34,-0.59 1.94,-2.24 2.83,-1.64 4.92,-1.79 1.79,-0.59 3.87,-0.9 2.6,-1.44 2.38,-2.09 h 3.13 l 3.73,-0.94 h 2.39 l 1,-2.78 h -4.77 l -1.79,1.37 h -3.13 a 5.39,5.39 0 0 0 -2.39,-1.37 v -1.1 L 163,24.6 165.13,23 a 12.52,12.52 0 0 0 1.79,-3.13 l 4.32,1.49 3.27,-0.17 2.25,-0.13 2.83,0.15 1.64,0.6 C 180.78,23 179,22.11 179,22.11 l -5.37,0.59 -2.39,1.3 0.75,-1.64 -2.54,0.15 -3,1.93 2.09,1.05 h 4.92 l 2.68,1 2.24,-0.89 2.38,0.89 2.84,0.9 -3.43,1.07 -3,1.41 -3,0.65 -2.38,0.89 1,2.09 6.26,-0.15 3.95,2.43 h 3.28 l 0.15,-1.34 0.74,-1.34 1.5,-0.3 -1.2,-1.64 -0.44,-1.24 h 1.78 l 1.5,1.09 c 1.19,0.9 3.72,-1.09 3.72,-1.09 l 3.73,-1.41 -4.62,-1.37 -1.49,-1.49 c 0.44,-0.9 -4.92,-2.24 -4.92,-2.24 l -4.18,-2.53 -1,-1.05 H 178 l 2.83,-1.19 7,0.74 3.58,-0.74 8.2,-2.09 5.51,-1.34 4,-1.49 -4.63,-0.72 c 0,0 -3.28,0.9 -3.73,0.9 -0.45,0 -4.32,0.3 -4.77,0.3 h -10.44 l -3.27,0.74 3,0.75 -1.79,1 h -3.13 l -1.79,0.6 2.38,-1.79 -2.53,-0.6 -3.13,0.75 -3.88,2.23 1.79,0.6 2.54,-1 2.08,0.44 -2.23,0.6 -0.9,1.19 1.49,0.45 -4,0.3 -7,-1.19 -2.83,3.42 -5.67,4 1.49,1.19 -1,0.63 -1.34,0.71 -3.88,-0.71 -5.36,1.41 -9.84,2.43 -32.89,31.65 -13.12,17.1 -7.6,45.62 13.41,-4.47 2.09,2.23 3.58,0.6 2.39,1.49 2.53,-1 2.09,2.09 4.62,2.53 4.47,0.6 1.34,4.47 c 0,0 3.13,2.83 3,3.43 -0.13,0.6 1,3.28 1.64,3.28 a 30.41,30.41 0 0 1 4.33,1.94 l 2.53,0.29 1,-2.23 h 2.24 v 2.23 l 0.9,1.2 0.29,3.42 0.9,2.54 -1.49,1.64 -2.39,3 -3,4.15 0.3,4 -0.75,2.68 2.24,0.75 -1.94,2.68 a 32.55,32.55 0 0 1 1,3.43 30.41,30.41 0 0 0 1.64,3.73 l 2.09,1.79 0.9,3 5.07,10.43 3.57,3 5.22,2.68 c 0,0 3.28,3.58 3.43,4 0.15,0.42 1.79,7 1.79,7 l -0.07,3.68 1,3.87 0.3,4.33 0.45,6 1.49,4.77 1.34,6.26 -1.64,2.09 1,3.09 1.2,4.51 2.08,2.24 -0.14,3.58 0.44,3.57 9.25,9.84 1.78,1.94 v -4.62 l 3,-1.73 V 260 l -3,-1.34 v -2.09 l 1.47,-1.34 1.48,-2.39 v -1.94 c 1.23,-0.44 0,-1.79 0,-1.79 h -2.05 l -0.15,-1.93 h 1.94 l 0.8,1.19 1.58,-1.19 -1.19,-2.39 c 0.3,-0.74 2.39,0 2.39,0 l 3.57,-2.09 1.49,-1.78 v -2.39 l -1.7,-1.53 -1.5,-2.39 h 1.79 c 0,0 2.69,1.35 3.58,0 0.89,-1.35 2.24,-3.13 2.24,-3.13 l 1.64,-3.87 c 0,0 3.13,-5.67 3.43,-6.12 0.3,-0.45 0,-6 0,-6 l 4.92,-4 h 3.28 l 2.68,-4.48 2.09,-2.94 v -5 l 0.74,-4.77 -1.17,-4.66 4.17,-5.52 3.13,-3 -1.19,-5.51 z m 33.22,-117.14 1,0.59 1.36,-1.18 H 249 l 1.78,-0.6 0.8,-1.1 -0.38,-1.52 0.76,-0.81 c 0.09,-1.23 -1.86,-2.12 -1.86,-2.12 H 249 l -1.36,1.57 h -1.44 l -0.51,1.78 0.21,1.34 -1.19,0.74 z m 9,-11.27 -1.52,0.68 v 2.29 l 0.17,0.59 a 6.36,6.36 0 0 1 0.17,1.44 l 1.1,0.76 1.1,0.68 0.51,1 c 0,0 -0.17,1 -0.76,1 l -1.36,0.43 0.51,0.93 c 0,0 -1,0.51 -1.1,0.93 l 0.93,0.68 -0.85,0.85 h -1.86 v 1 h 3.9 l 1.61,-1 2.37,0.42 c 0,0 1.95,-0.42 2.37,-0.42 l -0.34,-0.43 0.6,-0.76 0.93,-1.1 -1.19,-0.48 -1.35,-0.42 0.17,-1.44 -1.28,-1 -1.94,-1.06 -0.17,-1.95 0.17,-1.69 h -2 l -0.42,-0.85 1.18,-1.1 z m 11.1,7.29 v -0.64 h 1.36 l 0.76,-0.55 v -2.12 l 1,-0.51 -0.34,-1.69 L 266,45 263.63,45.76 V 47 l -1.44,0.17 -0.34,1.14 1,0.47 -1.61,0.93 -0.43,0.72 1.36,1.23 z m 85.4,51.37 5.6,3 2.89,-1.12 1.92,2.72 5.13,1.13 2.24,1.12 6.25,-16.5 L 372.45,84 344.45,38.18 336.09,32 H 326 l -4.49,0.64 -1.12,2.25 L 318,34 316.87,32 h -2.25 l 1,1 0.81,1.61 h -3.53 v 1.99 l -2.52,-0.37 -1.53,-0.23 -0.86,0.43 0.8,0.49 1.11,0.25 -1,0.37 -1.34,-0.54 -1.67,-0.56 -0.5,-1.11 -1.23,-1 -1.42,-0.19 -1,-1.17 2.18,0.19 1.92,0.86 1.6,0.19 c 0,0 1,-0.25 1.11,-0.07 a 12.12,12.12 0 0 0 2.35,0.5 l 1.3,-1 L 310,32 306.1,30.85 c 0,0 -6.55,-0.9 -6.86,-0.88 a 28.82,28.82 0 0 1 -2.78,-0.85 l -2.28,-0.56 h -5 l -7.6,1.41 -4.2,2.67 -5,4.51 c 0,0 -4.32,0.62 -4.57,0.68 a 20.44,20.44 0 0 0 -2,1.91 l 1,2.17 -0.25,1 0.68,0.55 0.5,1 0.68,1 2.53,-0.37 2.72,-1.54 2.1,1.11 1.61,2.78 0.3,1.67 1.92,0.37 1.3,-1.11 1.36,-0.31 0.74,-2.23 0.12,-1.73 1.86,-0.55 v -1.14 l -0.68,-0.49 -0.87,-0.56 -0.31,-2 2.83,-1.79 c 0,0 1.5,-1.36 1.5,-1.6 0,-0.24 0.74,-1.06 0.74,-1.06 0,0 1.18,0.07 1.55,0.13 0.37,0.06 2.34,0.74 2.34,0.74 l 0.75,0.56 -2.29,1.11 -1.35,1.36 -1,0.68 0.93,2.16 2.41,1.24 2.16,-0.44 3.43,-0.17 c 0,0 3.93,0.79 4.11,0.92 0.18,0.13 -1.13,0.55 -1.13,0.55 l -1.53,0.43 -0.86,0.56 -1.46,-0.74 a 3.78,3.78 0 0 0 -2,-0.68 4.09,4.09 0 0 0 -1.67,0.74 l 0.93,1.42 1.29,0.87 c 0,0 -0.55,1.6 -0.92,1.54 -0.37,-0.06 -1,-1.17 -1,-1.17 l -1.43,-0.56 -0.92,0.56 0.12,1.36 -0.4,1.92 -1.54,1 -1.12,0.87 -1.48,-0.87 -1.91,0.56 -3.34,-0.19 -0.74,0.68 -1.18,-0.49 c 0,0 -2.9,0.12 -3.09,0.18 a 10.62,10.62 0 0 1 -1.91,-0.86 l -0.74,-1.67 0.92,-1.11 -0.43,-0.5 -0.37,-0.92 0.62,-0.75 -0.93,-0.24 -1.54,1.54 -0.07,1.49 c 0,0 0.81,1.42 0.87,1.6 a 10.91,10.91 0 0 1 0.06,1.3 l -1.54,0.62 -1.67,0.49 0.31,0.62 1.73,0.31 -0.56,1 -1,0.06 -0.49,1.24 -0.31,0.68 -1.36,-0.37 0.06,-0.87 0.06,-1.11 -0.55,-0.56 -0.81,0.87 -0.86,1.11 -2,0.37 -0.93,0.74 -0.62,1.36 -1.48,0.68 -1.17,0.74 -1.8,-0.92 -0.24,0.43 0.37,0.92 -0.43,0.5 -2.35,-0.19 -1.3,-0.18 -0.19,1.73 2.29,0.37 1.11,1 c 0,0 0.87,1.05 1.05,1.05 0.18,0 1.43,0.31 1.43,0.31 l -0.5,2.72 -1.11,2.53 -4.64,-0.06 -5.06,-0.12 -1.61,0.61 -0.5,1.42 0.44,1.49 -0.9,2.79 -0.37,1.49 A 7,7 0 0 0 245,79 c 0.13,0.18 0.87,1.48 0.87,1.48 l -0.56,2.1 1.67,0.5 2.78,0.18 1.48,0.81 1.12,0.18 1.85,-0.8 2.78,-0.37 2.6,-2.17 -0.43,-2.65 1.6,-2 3.4,-2.16 1.48,-0.5 -0.18,-2.22 2,-1.18 2,0.68 1.36,-0.74 4.18,-1.28 4.14,3.84 5.68,3.89 c 0,0 1.18,2.35 1.24,2.53 a 7.8,7.8 0 0 1 -0.87,1.61 H 282 L 280.8,81 c 0,0 0.37,0.92 0.61,0.92 0.24,0 2.79,1.18 2.79,1.18 l 0.8,0.62 0.43,-0.13 -0.06,-1.17 0.25,-1.11 0.86,0.12 a 7.77,7.77 0 0 0 0.93,-1.24 17.93,17.93 0 0 1 0.86,-1.6 l -0.68,-1.3 0.38,-0.87 1,0.13 0.12,1.29 h 0.37 l -0.12,-1.6 -1,-0.62 -1.34,-0.89 -0.93,-1.35 -1.61,-0.44 -1.85,-1.3 -0.43,-1.48 -1.73,-0.86 -0.45,-1.36 0.5,-1.42 1.11,-0.19 0.06,1.36 1.11,0.37 0.75,-0.43 1.11,2 2.28,1.29 1.8,1 1.11,0.13 1.85,2 0.44,2.59 3.46,3.59 0.49,2.53 2.47,1.73 0.68,-0.56 -0.37,-1.6 1.36,-0.74 -0.43,-1.12 -1.37,-0.47 -0.56,-1.11 0.25,-1.8 -0.8,-0.92 0.74,0.12 0.55,0.68 0.87,-1.17 1.48,0.06 1.49,0.62 1.11,1.52 1.11,1.73 c 0,0 -0.74,0.43 -0.8,0.62 a 5.76,5.76 0 0 0 0.62,1.36 l 1.42,1.29 1.11,1.56 2.22,-0.06 0.25,1 1.61,0.18 1.54,-0.37 0.44,-1 0.68,0.93 1.79,0.62 1.54,-0.12 1.3,-1.43 1.17,0.5 0.87,0.55 -0.31,1.24 0.77,2.54 -1.12,2.57 v 3.36 H 313 l -2.56,1 -4.15,-2.07 -2.72,0.32 -4.65,-1.68 h -3.68 l -1.12,1 0.64,1.76 -1.44,1.44 -3.69,-2.24 -2.88,0.32 -1.12,-1.92 -4.33,-1.28 -3,-1.45 -2.3,-1.13 2.72,-3.2 -0.8,-2.72 -1.92,-1.13 -11.38,1.29 -4.48,1.76 -2.89,0.16 -3,1.12 -3.68,-0.8 -2.41,2.88 -2.88,1.92 -2.6,5.45 0.68,2.4 -3.36,3.21 -3.36,1.28 -1.6,3 c 0,0 -3.53,7.85 -3.85,8.49 -0.32,0.64 0,4.65 0,4.65 l 1.44,4.64 -3.36,7.85 1.28,3.85 1.76,3.52 4.65,6.57 -0.14,3.3 9.58,7.29 6.42,-2.58 6.18,1.96 7.68,-4.16 c 0,0 2.57,0 3.37,1.44 0.8,1.44 1.28,2.72 4.16,2.72 2.88,0 4.33,3.21 4.33,3.21 l -1.28,3.68 0.64,1.92 -1.28,3 3,6.24 2.24,4.81 2.09,4.65 0.48,5.92 -0.48,3.37 -3.69,6.41 1.12,9.93 1.28,2.24 -0.48,1.6 2.25,2.41 1.44,5.6 -1.28,5.29 1.92,4 c 0,0 1.76,4.33 1.92,4.81 0.16,0.48 1.28,2.08 1.12,2.88 -0.16,0.8 -0.64,2.89 -0.64,2.89 l 0.64,3.2 h 8.17 l 3.85,-1.28 9.45,-9.61 a 33.38,33.38 0 0 0 2.4,-3.21 c 0.16,-0.48 1.44,-6.4 1.44,-6.4 l 6.73,-2.73 v -5.23 l -1.44,-4.17 3.52,-3.36 9.46,-5.45 0.8,-4.17 v -7.2 l -1.77,-5.45 0.48,-3.36 -1.64,-1.45 3.05,-4.48 1.12,-5.93 4.48,-2.72 1,-2.73 8.17,-8.47 2.57,-8.06 2.4,-4.45 v -4.81 l -2.24,-0.8 -2.57,2.08 -3.52,0.32 -3.68,1 -3.05,-1.93 0.32,-2.4 -3.84,-4.32 -3.85,-2.25 -1.76,-5.76 -3.76,-3.58 -0.32,-4.48 -2.73,-4 -3.36,-7.52 -3.53,-3.52 -0.32,-2.89 1.45,0.65 1.6,1.28 0.64,2.4 c 1.28,0 1.76,-2.4 1.76,-2.4 l 1.12,2.4 1.12,3 3.53,5.29 1.92,0.32 2.24,4.65 -0.16,2.08 6.41,6.57 1.12,6.08 1.12,2.73 2.09,2.08 9.61,-2.56 1.76,-1.61 4.16,-1.28 v -1.92 l 4.81,-3.2 2,-3.72 1.16,-1.89 1.61,-2.24 -2.65,-3.65 -3.7,-3.13 -1.18,-3 -1.36,0.32 -1,2.88 -3.68,1 -1.92,-1.28 -0.64,-2.72 -1.28,0.32 -1.93,-3.53 -1.76,-1 -2.24,-3.68 1.6,-1.77 z m -75,-23.58 0.34,-1.53 v -2.2 a 2.47,2.47 0 0 0 -1.23,-0.59 1.34,1.34 0 0 0 -0.89,0.34 v 2.45 a 4.55,4.55 0 0 1 0,1.53 z m 0,-6.61 a 1,1 0 0 0 -1.19,-1.1 l -0.59,1.69 0.59,1.27 h 1.19 z m -43.7,-43.74 h 6 l 3.27,-4.71 h 7.53 l 1.21,-3 4.63,-2.45 c 2.19,-1.91 0,-5.37 0,-5.37 l -9.44,-1.18 -9.38,1.2 -13.64,-2.54 -8.41,3.82 c 0,0 -6.05,3.27 -6.87,3 a 29.17,29.17 0 0 0 -4.91,0 c 0,0 3,2.72 4.36,3 a 9.87,9.87 0 0 0 3,0 c 0,0 0,2.66 0.55,3.27 1.91,2.19 -2,3.82 -2,3.82 v 2.58 c 0,0 0.43,4.87 1.24,4.65 0.81,-0.22 2.14,2.59 2.14,2.59 l 2.51,2.73 h 4.59 l 5.73,-6.82 5.64,-2.45 z m 117.85,163.14 -0.74,-2 -0.85,0.84 -0.74,1.7 -1.69,1 -0.74,2.23 -1.06,2.64 -4.13,1.27 -1.8,3.07 -0.42,5.08 -1.48,2.52 -1.69,1.8 0.63,3 1.17,1.38 -1.17,1.58 1.17,1 h 3.91 l 2.22,-3.28 c 0,0 1.8,-3.81 1.8,-4.13 0,-0.32 0.85,-3.81 0.85,-3.81 l 3.06,-4 V 198 h 2.12 l -0.63,-3.92 z m -213.61,-81.15 -4.64,-1.58 c 0,0 -1.29,0.18 -2.8,0.54 a 16.83,16.83 0 0 0 -3.24,1 l 6.58,2.24 h 2.66 l 4.44,3.82 h 3 c 0,0 2.45,-1.09 1.63,-3 l -3.81,-1.37 z"
       id="path863" />
  </g>
  <path
     class="cls-8"
     d="M 166.04827,269.00001 A 151.41,151.41 0 0 1 21.048268,74.340006 151.34,151.34 0 1 0 296.34827,194.65001 a 151.23,151.23 0 0 1 -130.3,74.35 z"
     id="path867" />
  <ellipse
     class="cls-3"
     cx="153.54826"
     cy="356.16"
     rx="4.0900002"
     ry="2.3599999"
     id="ellipse1050" />
</svg>

```

`docs/static/img/product_1.svg`:

```svg
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!--
  ~ Copyright (c) 2024- Datalayer, Inc.
  ~
  ~ BSD 3-Clause License
-->

<svg
   xmlns:dc="http://purl.org/dc/elements/1.1/"
   xmlns:cc="http://creativecommons.org/ns#"
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:svg="http://www.w3.org/2000/svg"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   viewBox="0 0 222.55631 184.29483"
   version="1.1"
   id="svg1377"
   sodipodi:docname="1.svg"
   inkscape:version="1.0.1 (c497b03c, 2020-09-10)"
   width="222.5563"
   height="184.29483">
  <metadata
     id="metadata1381">
    <rdf:RDF>
      <cc:Work
         rdf:about="">
        <dc:format>image/svg+xml</dc:format>
        <dc:type
           rdf:resource="http://purl.org/dc/dcmitype/StillImage" />
        <dc:title>Cloud_database_SVG</dc:title>
      </cc:Work>
    </rdf:RDF>
  </metadata>
  <sodipodi:namedview
     pagecolor="#ffffff"
     bordercolor="#666666"
     borderopacity="1"
     objecttolerance="10"
     gridtolerance="10"
     guidetolerance="10"
     inkscape:pageopacity="0"
     inkscape:pageshadow="2"
     inkscape:window-width="1349"
     inkscape:window-height="694"
     id="namedview1379"
     showgrid="false"
     inkscape:zoom="0.81391066"
     inkscape:cx="246.97899"
     inkscape:cy="87.469146"
     inkscape:window-x="173"
     inkscape:window-y="109"
     inkscape:window-maximized="0"
     inkscape:current-layer="svg1377"
     inkscape:document-rotation="0"
     fit-margin-top="0"
     fit-margin-left="0"
     fit-margin-right="0"
     fit-margin-bottom="0" />
  <defs
     id="defs847">
    <style
       id="style833">.cls-1{fill:none;}.cls-2{clip-path:url(#clip-path);}.cls-3{fill:#d3d3dd;}.cls-4{fill:#e0dee9;}.cls-5{fill:#eaeaf4;}.cls-6{fill:#2a313f;}.cls-7{fill:#9052fe;}.cls-8{opacity:0.4;isolation:isolate;}.cls-9{clip-path:url(#clip-path-3);}.cls-10{fill:#d6d8e5;}.cls-11{clip-path:url(#clip-path-4);}.cls-12{fill:#3a2c6d;}.cls-13{fill:#ffcea9;}.cls-14{fill:#f4f4f4;}.cls-15{fill:#38226d;}.cls-16{fill:#9c73ff;}.cls-17{fill:#ff7b7b;}.cls-18{fill:#ededed;}.cls-19{fill:#8c50ff;}.cls-20{fill:#bfbfbf;}.cls-21{fill:#e5e5e5;}.cls-22{clip-path:url(#clip-path-5);}</style>
    <clipPath
       id="clip-path"
       transform="translate(-28.33 0)">
      <rect
         class="cls-1"
         width="500"
         height="500"
         id="rect835"
         x="0"
         y="0" />
    </clipPath>
    <clipPath
       id="clip-path-3"
       transform="translate(-28.33 0)">
      <rect
         class="cls-1"
         x="375.23999"
         y="440.37"
         width="36.549999"
         height="22.549999"
         id="rect838" />
    </clipPath>
    <clipPath
       id="clip-path-4"
       transform="translate(-28.33 0)">
      <rect
         class="cls-1"
         x="273.67001"
         y="353.35001"
         width="39.59"
         height="26.34"
         id="rect841" />
    </clipPath>
    <clipPath
       id="clip-path-5"
       transform="translate(-28.33 0)">
      <rect
         class="cls-1"
         x="321.47"
         y="473.66"
         width="39.59"
         height="26.34"
         id="rect844" />
    </clipPath>
  </defs>
  <title
     id="title849">Cloud_database_SVG</title>
  <path
     class="cls-5"
     d="m 199.73301,51.578526 0.37501,-0.16811 c 0.49137,-0.2069 0.98275,-0.38793 1.47413,-0.55603 h 0.0905 c 0.45259,-0.15518 0.90517,-0.28449 1.29311,-0.4138 h 0.28448 a 19.396569,19.396569 0 0 1 2.14655,-0.46551 h 0.15518 c 0.55603,-0.0776 1.11207,-0.12931 1.65517,-0.15518 h 0.32328 c 0.51724,0 1.02155,0 1.52586,0 h 0.32328 c 0.38793,0 0.76293,0.0776 1.13793,0.12931 h 0.34914 c 0.43965,0.0776 0.87931,0.18104 1.2931,0.29742 h 0.15517 a 10.538802,10.538802 0 0 1 1.07328,0.375 l 0.34914,0.15517 0.94396,0.45259 0.32328,0.1681 v 0 l -44.96125,-26.13364 -0.14224,-0.0776 -0.18103,-0.0905 -0.94397,-0.45258 -0.18103,-0.0905 -0.15518,-0.0647 c -0.36207,-0.14224 -0.72413,-0.27155 -1.0862,-0.375 h -0.12931 v 0 c -0.42673,-0.11638 -0.85345,-0.21982 -1.29311,-0.29741 h -0.12931 -0.21983 c -0.375,0 -0.75,-0.10345 -1.13793,-0.12931 h -0.21983 -0.10345 c -0.50431,0 -1.00862,0 -1.52586,0 h -0.11638 -0.2069 c -0.5431,0 -1.0862,0.0776 -1.65517,0.15517 h -0.12931 a 19.396569,19.396569 0 0 0 -2.14655,0.46552 h -0.16811 -0.11638 c -0.45258,0.12931 -0.90517,0.25862 -1.2931,0.41379 h -0.0905 c -0.49138,0.16811 -0.98276,0.34914 -1.47414,0.55604 h -0.11638 l -0.25862,0.12931 c -0.45258,0.19396 -0.9181,0.40086 -1.38362,0.63362 -0.15517,0.0776 -0.32328,0.14224 -0.47845,0.23276 -0.5819,0.28448 -1.16379,0.59483 -1.74569,0.94396 l 45.03883,26.17244 c 0.5819,-0.34914 1.1638,-0.65948 1.74569,-0.94396 l 0.47845,-0.23276 c 0.46552,-0.23276 0.91811,-0.43966 1.38363,-0.63362"
     id="path1059"
     style="stroke-width:1.2931" />
  <path
     class="cls-5"
     d="m 173.41834,41.906096 c 0.75,-0.3362 1.5,-0.64655 2.22414,-0.90517 h 0.10344 a 18.439671,18.439671 0 0 1 1.9138,-0.53017 q 0.5431,-0.14224 1.08621,-0.23276 a 12.788804,12.788804 0 0 1 1.2931,-0.2069 l 0.77586,-0.0776 q 0.85345,0 1.66811,0 h 0.375 a 15.168117,15.168117 0 0 1 1.91379,0.24568 l 0.46552,0.10345 a 13.745702,13.745702 0 0 1 1.42242,0.4138 l 0.43965,0.15517 a 11.340527,11.340527 0 0 1 1.69397,0.81466 l -44.90952,-26.25003 -0.14224,-0.0776 a 13.47415,13.47415 0 0 0 -1.29311,-0.63363 l -0.25862,-0.0905 -0.43965,-0.15518 -0.67242,-0.24569 -0.76293,-0.15517 -0.46552,-0.10345 h -0.24569 a 15.20691,15.20691 0 0 0 -1.56466,-0.19396 h -0.47844 c -0.40087,0 -0.81466,0 -1.29311,0 -0.14224,0 -0.28448,0 -0.43965,0 l -0.77587,0.0905 c -0.23276,0 -0.46551,0 -0.7112,0 l -0.64656,0.14224 q -0.5431,0.0905 -1.0862,0.23276 l -0.56897,0.11638 c -0.43966,0.11637 -0.89224,0.25862 -1.2931,0.41379 h -0.10345 c -0.50431,0.18103 -1.02156,0.375 -1.55173,0.59483 l -0.67241,0.29741 -0.63362,0.29741 c -0.7888,0.36207 -1.57759,0.76294 -2.37932,1.22845 -0.80172,0.46552 -1.93965,1.18966 -2.89655,1.87501 l 45.03883,26.17243 c 0.94397,-0.67241 1.9138,-1.2931 2.89656,-1.875 0.98276,-0.5819 1.59051,-0.86638 2.37931,-1.22845 l 0.63362,-0.28448"
     id="path1061"
     style="stroke-width:1.2931" />
  <path
     class="cls-5"
     d="m 130.8752,29.143156 0.68534,-0.29741 c 0.67242,-0.27156 1.29311,-0.53018 2.00431,-0.76294 l 0.375,-0.14224 c 0.7888,-0.25862 1.56466,-0.50431 2.34052,-0.7112 0.43966,-0.12931 0.89224,-0.23276 1.29311,-0.33621 l 0.65948,-0.15517 c 0.63362,-0.14225 1.29311,-0.24569 1.875,-0.34914 h 0.10345 c 0.62069,-0.0905 1.29311,-0.15517 1.83621,-0.21983 h 0.5819 1.07327 a 23.379331,23.379331 0 0 1 2.52156,0 h 0.43965 c 0.65949,0 1.29311,0.12931 1.96552,0.23276 l 0.60776,0.10345 a 19.668121,19.668121 0 0 1 2.19828,0.50431 h 0.0905 a 19.875018,19.875018 0 0 1 1.97845,0.69827 l 0.55603,0.23276 c 0.55604,0.24569 1.08621,0.50431 1.61638,0.7888 l 0.51724,0.27155 v 0 l -45.0259,-26.2112301 -0.23276,-0.12931 -0.28448,-0.14224 c -0.51724,-0.28449 -1.06035,-0.54311 -1.61638,-0.7888 l -0.27155,-0.14224 -0.25862,-0.0905 a 19.875018,19.875018 0 0 0 -1.97845,-0.69826999 h -0.0647 v 0 a 19.668121,19.668121 0 0 0 -2.22414,-0.53017 h -0.25862 -0.34914 c -0.64655,-0.10345 -1.2931,-0.18104 -1.96552,-0.23276 a 2.7543128,2.7543128 0 0 1 -0.32327,0 h -0.10345 a 23.637952,23.637952 0 0 0 -2.58621,0 h -0.23276 -0.82759 -0.58189 c -0.59483,0.0647 -1.21552,0.12931 -1.82328,0.21982 v 0 h -0.0905 c -0.62069,0.0905 -1.2931,0.2069 -1.875,0.34914 -0.23276,0 -0.45259,0.10345 -0.67241,0.15517 -0.21983,0.0517 -0.80173,0.18104 -1.20259,0.29741999 h -0.12931 c -0.77587,0.2069 -1.55173,0.45259 -2.34052,0.71121 l -0.375,0.14224 c -0.65949,0.23276 -1.29311,0.49138 -2.00431,0.76293 l -0.21983,0.0776 c -0.15517,0 -0.31035,0.15517 -0.46552,0.20689 -0.71121,0.31035 -1.42241,0.63362 -2.14655,0.98276 l -0.7888,0.38793 c -0.93103,0.46552 -1.86207,0.9569 -2.7931,1.5 -1.29311,0.73707 -2.58621,1.5388 -3.80173,2.37932 -0.43966,0.29741 -0.85345,0.63362 -1.2931,0.94396 -0.80173,0.56897 -1.61639,1.1379401 -2.40518,1.7456901 -0.50431,0.38794 -0.98276,0.81466 -1.47414,1.29311 -0.71121,0.56897 -1.42241,1.13793 -2.12069,1.74569 -0.69828,0.60776 -1.00862,0.94397 -1.52586,1.42242 -0.51725,0.47844 -1.29311,1.18965 -1.95259,1.82327 l -0.0905,0.0776 q -1.44828,1.46121 -2.87069,2.98707 l -0.77586,0.86638 c -0.36207,0.40086 -0.72414,0.78879 -1.08621,1.20259 -0.36207,0.41379 -0.46552,0.56896 -0.69828,0.85345 -0.67241,0.80172 -1.2931,1.60345 -1.99138,2.4181 -0.25862,0.33621 -0.5431,0.64656 -0.81466,0.99569 -0.27155,0.34914 -0.375,0.51725 -0.56896,0.77587 -0.49138,0.63362 -0.9569,1.2931 -1.43535,1.93965 -0.29741,0.4138 -0.60776,0.80173 -0.89224,1.21552 -0.28448,0.4138 -0.38793,0.59483 -0.59483,0.87931 -0.38793,0.56897 -0.77586,1.15087 -1.15086,1.73276 -0.375,0.5819 -0.5431,0.77587 -0.80173,1.17673 l -0.69827,1.15086 -0.98276,1.60345 -0.56897,0.94397 c -0.32327,0.5431 -0.60776,1.0862 -0.9181,1.62931 l -0.81466,1.47414 -0.32327,0.5819 c -0.43966,0.82758 -0.85345,1.6681 -1.29311,2.50862 l -0.50431,1.00862 -0.10345,0.2069 c -0.60776,1.2931 -1.17672,2.50862 -1.73276,3.77586 l -0.0776,0.19397 c -0.15518,0.34914 -0.28449,0.71121 -0.43966,1.07327 -0.36207,0.87932 -0.73707,1.7457 -1.07328,2.58621 -0.0776,0.18104 -0.12931,0.34914 -0.19396,0.53018 -0.21983,0.56896 -0.4138,1.15086 -0.62069,1.71983 -0.2069,0.56896 -0.46552,1.2931 -0.67242,1.86207 -0.0776,0.25862 -0.14224,0.50431 -0.21982,0.75 -0.23276,0.7112 -0.43966,1.42241 -0.65949,2.13362 -0.21983,0.71121 -0.3362,1.04741 -0.47845,1.57759 -0.0647,0.24569 -0.11638,0.49138 -0.18103,0.75 -0.24569,0.93103 -0.46552,1.84914 -0.68535,2.78017 -0.11638,0.49138 -0.25862,0.98276 -0.36207,1.46121 -0.10344,0.47845 -0.1681,0.80173 -0.24569,1.20259 -0.45258,0.25862 -0.9181,0.49138 -1.38362,0.76293 -0.98276,0.56897 -1.93965,1.18966 -2.89655,1.82328 l -0.49138,0.32327 c -0.91811,0.62069 -1.82328,1.29311 -2.71552,1.96552 l -0.51724,0.4138 c -0.90518,0.7112 -1.79742,1.43534 -2.67673,2.2112 l -0.23276,0.2069 c -0.85345,0.75 -1.68103,1.5388 -2.50862,2.34052 l -0.25862,0.23276 -0.15517,0.1681 c -0.63363,0.62069 -1.29311,1.29311 -1.87501,1.9138 l -0.0905,0.10345 c -0.5819,0.63362 -1.1638,1.2931 -1.73276,1.91379 l -0.15518,0.18104 -0.20689,0.24569 c -0.91811,1.07327 -1.82328,2.17241 -2.70259,3.29741 l -0.0776,0.0905 -0.19396,0.27155 c -0.69828,0.90517 -1.38363,1.83621 -2.04311,2.76725 l -0.2069,0.28448 a 0.53017288,0.53017288 0 0 0 -0.0905,0.14224 c -0.64656,0.90517 -1.29311,1.83621 -1.86207,2.76724 l -0.18104,0.27156 a 4.3577625,4.3577625 0 0 0 -0.24569,0.41379 q -0.73707,1.15086 -1.43534,2.32759 a 3.375003,3.375003 0 0 1 -0.21983,0.36207 l -0.0776,0.14224 c -0.53017,0.90517 -1.03448,1.82328 -1.52586,2.74138 l -0.11638,0.21983 -0.23276,0.45258 q -0.5819,1.099144 -1.125,2.211214 l -0.23276,0.46552 a 2.5862092,2.5862092 0 0 1 -0.12931,0.27155 c -0.43966,0.94397 -0.87931,1.875 -1.2931,2.8319 v 0.0776 l -0.11638,0.31034 c -0.375,0.85345 -0.72414,1.7069 -1.06035,2.58621 l -0.1681,0.42673 c 0,0.10345 -0.0776,0.23276 -0.12931,0.34914 -0.38794,1.00862 -0.75,2.03017 -1.09914,3.05172 v 0 l -0.0647,0.18104 c -0.34914,1.06034 -0.65948,2.12069 -0.96983,3.1681 a 3.6206929,3.6206929 0 0 1 -0.11638,0.40087 1.7586222,1.7586222 0 0 1 0,0.21982 c -0.3362,1.21552 -0.63362,2.44397 -0.90517,3.67242 l -0.0776,0.32328 c 0,0.1681 -0.0647,0.32327 -0.0905,0.47844 -0.10345,0.47845 -0.19397,0.96983 -0.27155,1.44828 -0.0776,0.47845 -0.12932,0.65949 -0.18104,0.99569 -0.0517,0.33621 -0.15517,0.98276 -0.23276,1.48707 0,0.23276 -0.0647,0.46552 -0.10345,0.69828 a 0.91810426,0.91810426 0 0 1 0,0.18103 c -0.12931,1.04742 -0.23276,2.10776 -0.31034,3.14225 v 0.67241 c 0,1.07328 -0.10345,2.14656 -0.10345,3.19397 0,7.97846 1.96552,14.3276 5.31466,18.76295 a 18.607775,18.607775 0 0 0 5.40518,4.83621 l 45.03883,26.15951 c -6.59483,-3.87932 -10.69398,-11.98708 -10.71984,-23.58623 0,-1.04742 0,-2.12069 0.10345,-3.19397 v -0.65948 c 0.0776,-1.04742 0.18104,-2.10776 0.31035,-3.15518 l 0.11638,-0.87931 c 0.0776,-0.50431 0.14224,-0.99569 0.23275,-1.48707 0.0905,-0.49138 0.11638,-0.65948 0.16811,-0.99569 0.0517,-0.33621 0.18103,-0.96983 0.28448,-1.44828 0,-0.27155 0.11638,-0.53017 0.1681,-0.80172 0.27156,-1.21552 0.56897,-2.44397 0.90518,-3.67242 0,-0.2069 0.11638,-0.41379 0.1681,-0.62069 0.31035,-1.06035 0.62069,-2.12069 0.96983,-3.16811 l 0.0776,-0.23276 c 0.3362,-1.03448 0.7112,-2.0431 1.09914,-3.06465 0.0905,-0.25862 0.19396,-0.51725 0.29741,-0.77587 0.33621,-0.85345 0.68534,-1.71983 1.04741,-2.58621 0.0647,-0.12931 0.11638,-0.25862 0.16811,-0.38793 0.41379,-0.95689 0.85345,-1.88793 1.2931,-2.8319 l 0.36207,-0.73707 q 0.54311,-1.09913 1.125,-2.2112 l 0.34914,-0.67242 c 0.49138,-0.9181 0.99569,-1.83621 1.52586,-2.72845 l 0.31035,-0.51724 c 0.45259,-0.78879 0.93103,-1.56466 1.42241,-2.34052 l 0.42673,-0.67241 c 0.59483,-0.93104 1.21552,-1.86208 1.86207,-2.78018 l 0.28448,-0.40086 c 0.67242,-0.94397 1.35776,-1.875 2.05604,-2.78018 l 0.27155,-0.36207 c 0.87931,-1.125 1.78448,-2.22414 2.70259,-3.29741 l 0.36207,-0.42673 c 0.56896,-0.64655 1.15086,-1.2931 1.73276,-1.90086 l 0.0905,-0.11638 c 0.62069,-0.64655 1.2931,-1.29311 1.875,-1.9138 l 0.41379,-0.40086 c 0.82759,-0.80172 1.66811,-1.59052 2.50862,-2.34052 l 0.23276,-0.20689 q 1.29311,-1.15087 2.67673,-2.211214 l 0.51724,-0.4138 c 0.89224,-0.68534 1.79742,-1.2931 2.71552,-1.96552 l 0.47845,-0.32327 c 0.9569,-0.63362 1.92673,-1.29311 2.89655,-1.81035 l 1.39656,-0.77586 c 0.18103,-0.87931 0.40086,-1.77155 0.60776,-2.6638 0.20689,-0.89224 0.43965,-1.84914 0.68534,-2.78017 0.24569,-0.93104 0.42673,-1.55173 0.65948,-2.32759 0.23276,-0.77586 0.42673,-1.42241 0.65949,-2.13362 0.23276,-0.71121 0.5819,-1.73276 0.89224,-2.58621 0.2069,-0.5819 0.40086,-1.16379 0.62069,-1.73276 0.40086,-1.06035 0.82759,-2.10776 1.2931,-3.15518 0.15518,-0.36207 0.28449,-0.73707 0.43966,-1.0862 0.60776,-1.40949 1.29311,-2.79311 1.9138,-4.17673 l 0.51724,-1.00862 c 0.50431,-1.03449 1.03448,-2.06897 1.59052,-3.09052 0.27155,-0.49138 0.5431,-0.98276 0.82758,-1.47414 q 0.72414,-1.29311 1.47414,-2.58621 c 0.32328,-0.54311 0.64655,-1.08621 0.98276,-1.61638 0.49138,-0.7888 0.98276,-1.56466 1.5,-2.32759 0.51724,-0.76293 0.76293,-1.16379 1.15087,-1.73276 0.38793,-0.56897 0.85344,-1.3319 1.38362,-1.97845 0.53017,-0.64655 0.94396,-1.29311 1.43534,-1.95259 0.49138,-0.65948 0.91811,-1.17672 1.38363,-1.75862 0.65948,-0.81466 1.2931,-1.61638 1.99138,-2.41811 0.69827,-0.80172 1.17672,-1.38362 1.78448,-2.05603 0.25862,-0.29742 0.51724,-0.5819 0.78879,-0.86638 q 1.43535,-1.57759 2.94828,-3.06466 c 0.64656,-0.63362 1.29311,-1.29311 1.97845,-1.84914 0.68535,-0.55604 0.98276,-0.94397 1.5,-1.38362 0.51725,-0.43966 1.42242,-1.18966 2.13363,-1.78449 0.49138,-0.40086 0.96983,-0.81465 1.46121,-1.20258 0.78879,-0.60776 1.60345,-1.17673 2.4181,-1.75863 l 1.29311,-0.93103 c 1.2931,-0.84052 2.5862,-1.64224 3.80172,-2.37931 0.93104,-0.54311 1.86207,-1.03449 2.79311,-1.50001 l 0.78879,-0.38793 c 0.72414,-0.34913 1.43535,-0.67241 2.14656,-0.96983"
     id="path1063"
     style="stroke-width:1.2931" />
  <path
     class="cls-3"
     d="m 125.14674,32.000916 c 20.3664,-11.75432 37.50004,-5.59914 42.41383,13.29312 a 33.426754,33.426754 0 0 1 2.89656,-1.875 c 12.84053,-7.40949 23.50864,-2.84483 25.66812,10.00862 14.79312,-8.56035 26.43106,-1.84913 26.43106,14.61209 0,15.28449 -9.91811,33.620724 -22.81036,42.866414 -1.06035,0.75 -2.06897,1.42242 -3.10346,2.01725 a 30.750027,30.750027 0 0 1 -2.97414,1.51293 l -111.90527,64.8104 c -20.31467,11.72846 -36.82762,2.32759 -36.89227,-21.02588 -0.0647,-23.35347 16.33191,-51.72418 36.64658,-63.478504 0.47845,-0.28449 0.93104,-0.51725 1.39656,-0.77587 4.81035,-24.40088 21.85346,-50.22418 42.18107,-61.96557"
     id="path1065"
     style="stroke-width:1.2931" />
</svg>

```

`docs/static/img/product_2.svg`:

```svg
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!--
  ~ Copyright (c) 2024- Datalayer, Inc.
  ~
  ~ BSD 3-Clause License
-->

<svg
   xmlns:figma="http://www.figma.com/figma/ns"
   xmlns:dc="http://purl.org/dc/elements/1.1/"
   xmlns:cc="http://creativecommons.org/ns#"
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:svg="http://www.w3.org/2000/svg"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   viewBox="0 0 335.67566 308.79167"
   version="1.1"
   id="svg1327"
   sodipodi:docname="2.svg"
   inkscape:version="1.0.1 (c497b03c, 2020-09-10)"
   width="335.67566"
   height="308.79166">
  <metadata
     id="metadata1331">
    <rdf:RDF>
      <cc:Work
         rdf:about="">
        <dc:format>image/svg+xml</dc:format>
        <dc:type
           rdf:resource="http://purl.org/dc/dcmitype/StillImage" />
        <dc:title>Web_hosting_SVG</dc:title>
      </cc:Work>
    </rdf:RDF>
  </metadata>
  <sodipodi:namedview
     pagecolor="#ffffff"
     bordercolor="#666666"
     borderopacity="1"
     objecttolerance="10"
     gridtolerance="10"
     guidetolerance="10"
     inkscape:pageopacity="0"
     inkscape:pageshadow="2"
     inkscape:window-width="1357"
     inkscape:window-height="701"
     id="namedview1329"
     showgrid="false"
     inkscape:zoom="0.98691435"
     inkscape:cx="142.90769"
     inkscape:cy="115.1505"
     inkscape:window-x="0"
     inkscape:window-y="25"
     inkscape:window-maximized="0"
     inkscape:current-layer="svg1327"
     inkscape:document-rotation="0"
     fit-margin-top="0"
     fit-margin-left="0"
     fit-margin-right="0"
     fit-margin-bottom="0" />
  <defs
     id="defs835">
    <style
       id="style833">.cls-1,.cls-7{fill:#d6d8e5;}.cls-1{opacity:0.4;}.cls-2{fill:#d5d6e0;}.cls-3{fill:#e9eaf4;}.cls-4{fill:#dfe0ea;}.cls-5{fill:#2b303f;}.cls-6{fill:#8c50ff;}.cls-8{fill:#edf0f9;}.cls-9{fill:#e2e5f2;}.cls-10{fill:#e5e5e5;}.cls-11{fill:#f4f4f4;}.cls-12{fill:#bfbfbf;}.cls-13{fill:#dceeff;}.cls-14{fill:#dbdbdb;}.cls-15{fill:#1e212d;}.cls-16{fill:#ffcea9;}.cls-17{fill:#ededed;}.cls-18{fill:#38226d;}.cls-19{fill:#9c73ff;}.cls-20{fill:#3a2c6d;}</style>
  </defs>
  <title
     id="title837">Web_hosting_SVG</title>
  <polygon
     class="cls-1"
     points="249.36,272.19 251.14,273.21 107.37,356.22 106.48,354.68 "
     id="polygon839"
     transform="translate(0.00186273,-119.51243)" />
  <path
     class="cls-1"
     d="m 49.311863,306.76757 -45.8000003,-26.45 c -5.2,-3 -4.55,-8.23 1.45,-11.69 l 23.2500003,-13.43 c 6,-3.46 15.07,-3.84 20.26,-0.84 l 45.8,26.45 c 5.2,3 4.54,8.23 -1.45,11.69 l -23.25,13.43 c -6,3.46 -15.07,3.84 -20.26,0.84 z"
     id="path1155" />
  <path
     class="cls-7"
     d="m 118.10186,273.76757 v -63.94 l -97.749997,-11 v 64.34 0 c -0.07,2 1.06,3.84 3.48,5.24 l 45.8,26.44 c 5.19,3 14.27,2.62 20.26,-0.84 l 23.249997,-13.42 c 3.38,-2 5.06,-4.46 5,-6.82 z"
     id="path1157" />
  <path
     class="cls-8"
     d="m 118.08186,216.80757 v -7 h -7.52 l -41.759997,-24.1 c -5.19,-3 -14.26,-2.62 -20.26,0.84 l -23.25,13.42 a 13.81,13.81 0 0 0 -1.2,0.78 l -3.74,-1.92 c 0,0 0,7.37 0,7.62 v 0 c -0.05,2 1.08,3.83 3.49,5.22 l 45.8,26.44 c 5.19,3 14.27,2.63 20.26,-0.84 l 23.249997,-13.42 c 3.48,-2 5.15,-4.61 4.93,-7 z"
     id="path1159" />
  <path
     class="cls-9"
     d="m 69.631863,230.48757 -45.8,-26.44 c -5.19,-3 -4.54,-8.23 1.46,-11.7 l 23.25,-13.42 c 6,-3.46 15.07,-3.84 20.26,-0.84 l 45.799997,26.44 c 5.19,3 4.54,8.24 -1.46,11.7 l -23.249997,13.44 c -5.99,3.47 -15.07,3.82 -20.26,0.82 z"
     id="path1161" />
  <g
     id="_Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ°_"
     data-name="&lt;Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ°&gt;"
     transform="translate(0.00186273,-119.51243)">
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-10"
       d="m 93.16,326 v 0 A 2.25,2.25 0 0 1 92,328 l -21.1,12.18 a 2.26,2.26 0 0 1 -2.25,0 L 39.13,323.07 A 2.24,2.24 0 0 1 38,321.12 V 321 Z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_2"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-10"
       d="m 92,328 -21.1,12.18 a 2.24,2.24 0 0 1 -1.12,0.3 V 326 H 93.16 A 2.25,2.25 0 0 1 92,328 Z" />
    <g
       id="_Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ°_2"
       data-name="&lt;Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ°&gt;">
      <path
         id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_3"
         data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
         class="cls-11"
         d="M 70.61,339 A 1.59,1.59 0 0 1 69,339 L 38.3,321.29 a 0.43,0.43 0 0 1 0,-0.82 L 60.93,307.4 93.16,326 Z" />
    </g>
    <g
       id="_Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ°_3"
       data-name="&lt;Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ°&gt;">
      <polygon
         id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_4"
         data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
         class="cls-12"
         points="50.92,326.01 51.08,326.1 60.93,331.79 66.33,328.67 66.48,328.58 56.48,322.8 " />
      <polygon
         id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_5"
         data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
         class="cls-10"
         points="66.33,328.67 56.48,322.98 51.08,326.1 60.93,331.79 " />
    </g>
    <path
       class="cls-5"
       d="M 84.61,327.13 86,328 a 0.48,0.48 0 0 0 0.45,0 l 1.35,-0.78 c 0.14,-0.08 0.15,-0.19 0,-0.26 l -1.42,-0.82 a 0.48,0.48 0 0 0 -0.45,0 l -1.35,0.78 c -0.07,0.08 -0.08,0.14 0.03,0.21 z"
       id="path1170" />
    <path
       class="cls-5"
       d="m 82.6,326 1.42,0.82 a 0.5,0.5 0 0 0 0.46,0 l 1.35,-0.78 c 0.14,-0.08 0.15,-0.2 0,-0.26 l -1.42,-0.82 a 0.48,0.48 0 0 0 -0.45,0 l -1.35,0.78 c -0.11,0.05 -0.12,0.16 -0.01,0.26 z"
       id="path1172" />
    <path
       class="cls-5"
       d="m 80.59,324.81 1.42,0.82 a 0.5,0.5 0 0 0 0.46,0 l 1.35,-0.78 c 0.13,-0.08 0.15,-0.2 0,-0.26 l -1.42,-0.82 a 0.48,0.48 0 0 0 -0.45,0 l -1.35,0.78 c -0.11,0.08 -0.12,0.19 -0.01,0.26 z"
       id="path1174" />
    <path
       class="cls-5"
       d="m 78.58,323.65 1.42,0.82 a 0.5,0.5 0 0 0 0.46,0 l 1.35,-0.78 c 0.13,-0.08 0.15,-0.2 0,-0.26 l -1.42,-0.82 a 0.48,0.48 0 0 0 -0.45,0 l -1.35,0.78 c -0.11,0.07 -0.12,0.19 -0.01,0.26 z"
       id="path1176" />
    <path
       class="cls-5"
       d="m 76.57,322.49 1.42,0.82 a 0.51,0.51 0 0 0 0.45,0 l 1.36,-0.78 c 0.13,-0.08 0.15,-0.2 0,-0.26 l -1.42,-0.82 a 0.51,0.51 0 0 0 -0.45,0 l -1.36,0.79 c -0.1,0.06 -0.11,0.18 0,0.25 z"
       id="path1178" />
    <path
       class="cls-5"
       d="m 74.56,321.33 1.42,0.82 a 0.51,0.51 0 0 0 0.45,0 l 1.36,-0.78 c 0.13,-0.08 0.15,-0.2 0,-0.27 l -1.42,-0.82 a 0.55,0.55 0 0 0 -0.45,0 l -1.36,0.79 c -0.1,0.07 -0.11,0.19 0,0.26 z"
       id="path1180" />
    <path
       class="cls-5"
       d="M 72.55,320.17 74,321 a 0.55,0.55 0 0 0 0.45,0 l 1.36,-0.79 c 0.13,-0.07 0.15,-0.19 0,-0.26 l -1.42,-0.82 a 0.55,0.55 0 0 0 -0.45,0 l -1.36,0.78 c -0.13,0.09 -0.15,0.19 -0.03,0.26 z"
       id="path1182" />
    <path
       class="cls-5"
       d="m 70.54,319 1.42,0.82 a 0.55,0.55 0 0 0 0.45,0 l 1.36,-0.79 c 0.13,-0.07 0.15,-0.19 0,-0.26 l -1.42,-0.82 a 0.51,0.51 0 0 0 -0.45,0 l -1.36,0.78 c -0.1,0.09 -0.12,0.21 0,0.27 z"
       id="path1184" />
    <path
       class="cls-5"
       d="m 68.53,317.84 1.42,0.82 a 0.51,0.51 0 0 0 0.45,0 l 1.36,-0.79 c 0.13,-0.07 0.15,-0.19 0,-0.26 l -1.42,-0.82 a 0.51,0.51 0 0 0 -0.45,0 l -1.36,0.78 c -0.1,0.09 -0.12,0.21 0,0.27 z"
       id="path1186" />
    <path
       class="cls-5"
       d="m 66.52,316.68 1.42,0.82 a 0.48,0.48 0 0 0 0.45,0 l 1.36,-0.78 c 0.13,-0.08 0.14,-0.19 0,-0.26 l -1.42,-0.82 a 0.48,0.48 0 0 0 -0.45,0 l -1.36,0.78 c -0.1,0.08 -0.12,0.2 0,0.26 z"
       id="path1188" />
    <path
       class="cls-5"
       d="m 64.51,315.52 1.42,0.82 a 0.48,0.48 0 0 0 0.45,0 l 1.36,-0.78 c 0.13,-0.08 0.14,-0.19 0,-0.26 l -1.42,-0.82 a 0.48,0.48 0 0 0 -0.45,0 l -1.36,0.78 c -0.1,0.08 -0.12,0.2 0,0.26 z"
       id="path1190" />
    <path
       class="cls-5"
       d="m 62.5,314.36 1.42,0.82 a 0.48,0.48 0 0 0 0.45,0 l 1.35,-0.78 c 0.14,-0.08 0.15,-0.19 0,-0.26 l -1.42,-0.82 a 0.5,0.5 0 0 0 -0.46,0 l -1.35,0.78 c -0.09,0.08 -0.11,0.19 0.01,0.26 z"
       id="path1192" />
    <path
       class="cls-5"
       d="m 60.49,313.2 1.42,0.82 a 0.48,0.48 0 0 0 0.45,0 l 1.35,-0.78 c 0.14,-0.08 0.15,-0.19 0,-0.26 l -1.42,-0.82 a 0.5,0.5 0 0 0 -0.46,0 l -1.35,0.78 c -0.09,0.06 -0.11,0.19 0.01,0.26 z"
       id="path1194" />
    <path
       class="cls-5"
       d="m 57.51,311.48 2.39,1.38 a 0.48,0.48 0 0 0 0.45,0 l 1.35,-0.78 c 0.14,-0.08 0.15,-0.2 0,-0.26 l -2.39,-1.38 a 0.48,0.48 0 0 0 -0.45,0 l -1.36,0.78 c -0.09,0.08 -0.11,0.19 0.01,0.26 z"
       id="path1196" />
    <path
       class="cls-5"
       d="m 79.68,326.53 1.42,0.82 a 0.53,0.53 0 0 0 0.46,0 l 1.35,-0.79 c 0.13,-0.07 0.15,-0.19 0,-0.26 l -1.42,-0.82 a 0.51,0.51 0 0 0 -0.45,0 l -1.35,0.78 c -0.11,0.09 -0.12,0.21 -0.01,0.27 z"
       id="path1198" />
    <path
       class="cls-5"
       d="m 77.67,325.37 1.42,0.82 a 0.48,0.48 0 0 0 0.45,0 l 1.36,-0.78 c 0.13,-0.08 0.15,-0.19 0,-0.26 l -1.42,-0.82 a 0.48,0.48 0 0 0 -0.45,0 l -1.36,0.78 c -0.1,0.08 -0.12,0.19 0,0.26 z"
       id="path1200" />
    <path
       class="cls-5"
       d="m 75.65,324.21 1.43,0.82 a 0.48,0.48 0 0 0 0.45,0 l 1.35,-0.78 c 0.14,-0.08 0.15,-0.2 0,-0.26 l -1.43,-0.82 a 0.48,0.48 0 0 0 -0.45,0 l -1.35,0.78 c -0.1,0.05 -0.11,0.19 0,0.26 z"
       id="path1202" />
    <path
       class="cls-5"
       d="m 73.64,323.05 1.42,0.82 a 0.55,0.55 0 0 0 0.45,0 l 1.36,-0.79 c 0.13,-0.07 0.15,-0.19 0,-0.26 L 75.48,322 a 0.51,0.51 0 0 0 -0.45,0 l -1.36,0.78 c -0.13,0.08 -0.15,0.22 -0.03,0.27 z"
       id="path1204" />
    <path
       class="cls-5"
       d="m 71.64,321.89 1.42,0.82 a 0.5,0.5 0 0 0 0.46,0 l 1.35,-0.78 c 0.13,-0.08 0.15,-0.19 0,-0.26 l -1.42,-0.82 a 0.48,0.48 0 0 0 -0.45,0 l -1.35,0.78 c -0.11,0.08 -0.12,0.2 -0.01,0.26 z"
       id="path1206" />
    <path
       class="cls-5"
       d="m 69.63,320.73 1.42,0.82 a 0.48,0.48 0 0 0 0.45,0 l 1.36,-0.78 c 0.13,-0.08 0.14,-0.2 0,-0.26 l -1.42,-0.82 a 0.48,0.48 0 0 0 -0.45,0 l -1.36,0.78 c -0.1,0.08 -0.12,0.19 0,0.26 z"
       id="path1208" />
    <path
       class="cls-5"
       d="m 67.61,319.57 1.42,0.82 a 0.57,0.57 0 0 0 0.46,0 l 1.35,-0.78 c 0.14,-0.08 0.15,-0.2 0,-0.27 l -1.42,-0.82 a 0.55,0.55 0 0 0 -0.45,0 l -1.35,0.79 c -0.11,0.07 -0.12,0.19 -0.01,0.26 z"
       id="path1210" />
    <path
       class="cls-5"
       d="m 65.6,318.4 1.42,0.82 a 0.48,0.48 0 0 0 0.45,0 l 1.36,-0.78 c 0.13,-0.07 0.15,-0.19 0,-0.26 l -1.42,-0.82 a 0.48,0.48 0 0 0 -0.45,0 l -1.36,0.78 c -0.1,0.08 -0.12,0.2 0,0.26 z"
       id="path1212" />
    <path
       class="cls-5"
       d="m 63.59,317.24 1.42,0.82 a 0.48,0.48 0 0 0 0.45,0 l 1.35,-0.78 c 0.14,-0.08 0.15,-0.19 0,-0.26 l -1.42,-0.82 a 0.5,0.5 0 0 0 -0.46,0 l -1.35,0.78 c -0.1,0.08 -0.11,0.19 0.01,0.26 z"
       id="path1214" />
    <path
       class="cls-5"
       d="m 61.57,316.08 1.42,0.82 a 0.51,0.51 0 0 0 0.45,0 l 1.36,-0.78 c 0.13,-0.08 0.15,-0.2 0,-0.26 L 63.41,315 a 0.51,0.51 0 0 0 -0.45,0 l -1.36,0.79 c -0.13,0.1 -0.14,0.21 -0.03,0.29 z"
       id="path1216" />
    <path
       class="cls-5"
       d="m 59.56,314.91 1.42,0.82 a 0.51,0.51 0 0 0 0.45,0 l 1.36,-0.79 c 0.13,-0.07 0.14,-0.19 0,-0.26 l -1.42,-0.82 a 0.51,0.51 0 0 0 -0.45,0 l -1.36,0.78 c -0.1,0.09 -0.12,0.21 0,0.27 z"
       id="path1218" />
    <path
       class="cls-5"
       d="m 57.54,313.75 1.42,0.82 a 0.5,0.5 0 0 0 0.46,0 l 1.35,-0.78 c 0.14,-0.08 0.15,-0.19 0,-0.26 l -1.42,-0.82 a 0.48,0.48 0 0 0 -0.45,0 l -1.35,0.78 c -0.11,0.08 -0.12,0.2 -0.01,0.26 z"
       id="path1220" />
    <path
       class="cls-5"
       d="m 81.7,327.7 2.39,1.38 a 0.55,0.55 0 0 0 0.45,0 l 1.35,-0.78 c 0.14,-0.08 0.15,-0.2 0,-0.27 l -2.39,-1.38 a 0.55,0.55 0 0 0 -0.45,0 l -1.36,0.79 c -0.09,0.07 -0.11,0.19 0.01,0.26 z"
       id="path1222" />
    <path
       class="cls-5"
       d="m 57.38,311.54 1.42,0.82 c 0.11,0.06 0.11,0.17 0,0.24 l -1.44,0.83 a 0.48,0.48 0 0 1 -0.42,0 l -0.11,-0.07 a 0.45,0.45 0 0 0 -0.39,0 l -1.51,0.88 a 0.45,0.45 0 0 1 -0.42,0 l -0.91,-0.52 a 0.14,0.14 0 0 1 0,-0.25 l 1.42,-0.81 0.29,-0.17 0.21,-0.13 0.22,-0.12 1.22,-0.7 a 0.45,0.45 0 0 1 0.42,0 z"
       id="path1224" />
    <path
       class="cls-5"
       d="m 76.81,331.63 1.42,0.82 a 0.51,0.51 0 0 0 0.45,0 l 1.36,-0.78 c 0.13,-0.08 0.15,-0.2 0,-0.27 l -1.42,-0.82 a 0.55,0.55 0 0 0 -0.45,0 l -1.36,0.79 c -0.1,0.07 -0.11,0.19 0,0.26 z"
       id="path1226" />
    <path
       class="cls-5"
       d="m 74.81,330.47 1.42,0.82 a 0.48,0.48 0 0 0 0.45,0 l 1.35,-0.78 c 0.14,-0.08 0.15,-0.2 0,-0.26 l -1.42,-0.82 a 0.5,0.5 0 0 0 -0.46,0 l -1.35,0.78 c -0.1,0.08 -0.11,0.19 0.01,0.26 z"
       id="path1228" />
    <path
       class="cls-5"
       d="m 72.8,329.31 1.42,0.82 a 0.48,0.48 0 0 0 0.45,0 l 1.36,-0.78 c 0.13,-0.08 0.15,-0.19 0,-0.26 l -1.42,-0.82 a 0.48,0.48 0 0 0 -0.45,0 l -1.36,0.78 c -0.1,0.08 -0.11,0.2 0,0.26 z"
       id="path1230" />
    <path
       class="cls-5"
       d="m 55.73,319.45 1.42,0.82 a 0.51,0.51 0 0 0 0.45,0 l 1.35,-0.79 c 0.14,-0.07 0.15,-0.19 0,-0.26 l -1.42,-0.82 a 0.5,0.5 0 0 0 -0.46,0 l -1.35,0.78 c -0.09,0.09 -0.11,0.21 0.01,0.27 z"
       id="path1232" />
    <path
       class="cls-5"
       d="m 53.72,318.3 1.42,0.82 a 0.51,0.51 0 0 0 0.45,0 l 1.36,-0.78 c 0.13,-0.08 0.15,-0.2 0,-0.27 l -1.42,-0.82 a 0.55,0.55 0 0 0 -0.45,0 l -1.36,0.79 c -0.1,0.07 -0.11,0.19 0,0.26 z"
       id="path1234" />
    <path
       class="cls-5"
       d="m 51.72,317.14 1.42,0.82 a 0.48,0.48 0 0 0 0.45,0 l 1.35,-0.78 c 0.14,-0.08 0.15,-0.2 0,-0.26 l -1.42,-0.82 a 0.5,0.5 0 0 0 -0.46,0 l -1.35,0.78 c -0.09,0.12 -0.11,0.19 0.01,0.26 z"
       id="path1236" />
    <path
       class="cls-5"
       d="m 49.71,316 1.42,0.82 a 0.48,0.48 0 0 0 0.45,0 l 1.36,-0.78 c 0.13,-0.08 0.15,-0.19 0,-0.26 l -1.42,-0.82 a 0.48,0.48 0 0 0 -0.45,0 l -1.36,0.78 c -0.1,0.06 -0.11,0.17 0,0.26 z"
       id="path1238" />
    <path
       class="cls-5"
       d="m 70.28,327.86 1.94,1.14 a 0.51,0.51 0 0 0 0.45,0 l 1.35,-0.79 c 0.14,-0.07 0.15,-0.19 0,-0.26 l -1.94,-1.12 a 0.55,0.55 0 0 0 -0.45,0 l -1.36,0.79 c -0.09,0.05 -0.11,0.17 0.01,0.24 z"
       id="path1240" />
    <path
       class="cls-5"
       d="m 57.73,320.61 1.94,1.12 a 0.48,0.48 0 0 0 0.45,0 l 1.36,-0.78 c 0.13,-0.08 0.14,-0.2 0,-0.26 l -1.94,-1.12 a 0.48,0.48 0 0 0 -0.45,0 l -1.36,0.78 c -0.1,0.08 -0.11,0.19 0,0.26 z"
       id="path1242" />
    <path
       class="cls-5"
       d="m 60.25,322.07 9.45,5.45 a 0.48,0.48 0 0 0 0.45,0 l 1.35,-0.78 c 0.14,-0.08 0.15,-0.2 0,-0.26 L 62.09,321 a 0.51,0.51 0 0 0 -0.45,0 l -1.35,0.79 c -0.14,0.09 -0.15,0.21 -0.04,0.28 z"
       id="path1244" />
    <path
       class="cls-5"
       d="m 77.19,327.34 1.42,0.82 a 0.48,0.48 0 0 0 0.45,0 l 1.36,-0.78 c 0.13,-0.07 0.14,-0.19 0,-0.26 L 79,326.28 a 0.48,0.48 0 0 0 -0.45,0 l -1.36,0.78 c -0.1,0.1 -0.12,0.22 0,0.28 z"
       id="path1246" />
    <path
       class="cls-5"
       d="M 75.18,326.18 76.6,327 a 0.51,0.51 0 0 0 0.45,0 l 1.36,-0.79 c 0.13,-0.07 0.15,-0.19 0,-0.26 L 77,325.12 a 0.48,0.48 0 0 0 -0.45,0 l -1.36,0.78 c -0.11,0.1 -0.13,0.22 -0.01,0.28 z"
       id="path1248" />
    <path
       class="cls-5"
       d="m 73.17,325 1.42,0.82 a 0.51,0.51 0 0 0 0.45,0 L 76.4,325 c 0.13,-0.07 0.15,-0.19 0,-0.26 L 75,324 a 0.51,0.51 0 0 0 -0.45,0 l -1.36,0.78 c -0.12,0.06 -0.14,0.22 -0.02,0.22 z"
       id="path1250" />
    <path
       class="cls-5"
       d="m 71.16,323.86 1.42,0.82 a 0.51,0.51 0 0 0 0.45,0 l 1.36,-0.79 c 0.13,-0.07 0.15,-0.19 0,-0.26 L 73,322.8 a 0.51,0.51 0 0 0 -0.45,0 l -1.36,0.78 c -0.13,0.1 -0.14,0.22 -0.03,0.28 z"
       id="path1252" />
    <path
       class="cls-5"
       d="m 69.15,322.71 1.42,0.82 a 0.57,0.57 0 0 0 0.46,0 l 1.35,-0.79 c 0.14,-0.07 0.15,-0.19 0,-0.26 L 71,321.64 a 0.51,0.51 0 0 0 -0.45,0 l -1.35,0.78 c -0.15,0.1 -0.2,0.22 -0.05,0.29 z"
       id="path1254" />
    <path
       class="cls-5"
       d="m 67.15,321.55 1.42,0.82 a 0.55,0.55 0 0 0 0.45,0 l 1.35,-0.79 c 0.14,-0.07 0.15,-0.19 0,-0.26 L 69,320.48 a 0.57,0.57 0 0 0 -0.46,0 l -1.35,0.78 c -0.19,0.1 -0.19,0.22 -0.04,0.29 z"
       id="path1256" />
    <path
       class="cls-5"
       d="m 65.14,320.39 1.42,0.82 a 0.55,0.55 0 0 0 0.45,0 l 1.35,-0.78 c 0.14,-0.08 0.15,-0.2 0,-0.27 L 67,319.32 a 0.57,0.57 0 0 0 -0.46,0 l -1.35,0.79 C 65,320.2 65,320.32 65.14,320.39 Z"
       id="path1258" />
    <path
       class="cls-5"
       d="m 63.13,319.23 1.42,0.82 a 0.51,0.51 0 0 0 0.45,0 l 1.36,-0.78 c 0.13,-0.08 0.14,-0.2 0,-0.27 L 65,318.16 a 0.55,0.55 0 0 0 -0.45,0 l -1.36,0.79 C 63,319 63,319.16 63.13,319.23 Z"
       id="path1260" />
    <path
       class="cls-5"
       d="m 61.12,318.07 1.42,0.82 a 0.51,0.51 0 0 0 0.45,0 l 1.36,-0.78 c 0.13,-0.08 0.15,-0.2 0,-0.27 L 63,317 a 0.55,0.55 0 0 0 -0.45,0 l -1.36,0.79 C 61,317.88 61,318 61.12,318.07 Z"
       id="path1262" />
    <path
       class="cls-5"
       d="m 59.11,316.91 1.42,0.82 a 0.51,0.51 0 0 0 0.45,0 l 1.36,-0.78 c 0.13,-0.08 0.15,-0.2 0,-0.26 L 61,315.85 a 0.51,0.51 0 0 0 -0.45,0 l -1.36,0.79 c -0.19,0.08 -0.19,0.2 -0.08,0.27 z"
       id="path1264" />
    <path
       class="cls-5"
       d="m 57.1,315.75 1.42,0.82 a 0.53,0.53 0 0 0 0.46,0 l 1.35,-0.78 c 0.13,-0.08 0.15,-0.2 0,-0.26 l -1.42,-0.82 a 0.51,0.51 0 0 0 -0.45,0 l -1.35,0.79 C 57,315.56 57,315.68 57.1,315.75 Z"
       id="path1266" />
    <path
       class="cls-5"
       d="m 55.09,314.59 1.42,0.82 a 0.5,0.5 0 0 0 0.46,0 l 1.35,-0.78 c 0.14,-0.08 0.15,-0.2 0,-0.26 l -1.42,-0.82 a 0.51,0.51 0 0 0 -0.45,0 l -1.35,0.79 c -0.1,0.06 -0.1,0.18 -0.01,0.25 z"
       id="path1268" />
    <path
       class="cls-5"
       d="m 79.2,328.5 2.93,1.7 a 0.5,0.5 0 0 0 0.46,0 l 1.35,-0.78 c 0.13,-0.08 0.15,-0.2 0,-0.26 L 81,327.44 a 0.5,0.5 0 0 0 -0.46,0 l -1.35,0.78 c -0.1,0.1 -0.11,0.22 0.01,0.28 z"
       id="path1270" />
    <path
       class="cls-5"
       d="m 76.24,329 1.42,0.82 a 0.51,0.51 0 0 0 0.45,0 l 1.35,-0.79 c 0.14,-0.07 0.15,-0.19 0,-0.26 L 78.08,328 a 0.53,0.53 0 0 0 -0.46,0 l -1.35,0.78 c -0.14,0.08 -0.15,0.22 -0.03,0.22 z"
       id="path1272" />
    <path
       class="cls-5"
       d="m 74.23,327.89 1.42,0.82 a 0.55,0.55 0 0 0 0.45,0 l 1.36,-0.79 c 0.13,-0.07 0.14,-0.19 0,-0.26 l -1.42,-0.82 a 0.51,0.51 0 0 0 -0.45,0 l -1.36,0.78 c -0.1,0.08 -0.12,0.2 0,0.27 z"
       id="path1274" />
    <path
       class="cls-5"
       d="m 72.22,326.73 1.42,0.82 a 0.55,0.55 0 0 0 0.45,0 l 1.36,-0.79 c 0.13,-0.07 0.15,-0.19 0,-0.26 l -1.42,-0.82 a 0.51,0.51 0 0 0 -0.45,0 l -1.36,0.78 c -0.1,0.08 -0.12,0.2 0,0.27 z"
       id="path1276" />
    <path
       class="cls-5"
       d="m 70.21,325.57 1.42,0.82 a 0.55,0.55 0 0 0 0.45,0 l 1.36,-0.78 c 0.13,-0.08 0.15,-0.2 0,-0.27 l -1.42,-0.82 a 0.55,0.55 0 0 0 -0.45,0 l -1.36,0.79 c -0.1,0.07 -0.11,0.19 0,0.26 z"
       id="path1278" />
    <path
       class="cls-5"
       d="m 68.2,324.41 1.42,0.82 a 0.53,0.53 0 0 0 0.46,0 l 1.35,-0.78 c 0.13,-0.08 0.15,-0.2 0,-0.27 L 70,323.34 a 0.55,0.55 0 0 0 -0.45,0 l -1.35,0.79 c -0.1,0.09 -0.11,0.21 0,0.28 z"
       id="path1280" />
    <path
       class="cls-5"
       d="m 66.19,323.25 1.43,0.82 a 0.51,0.51 0 0 0 0.45,0 l 1.35,-0.78 c 0.14,-0.08 0.15,-0.2 0,-0.26 L 68,322.19 a 0.51,0.51 0 0 0 -0.45,0 l -1.35,0.79 c -0.11,0.08 -0.12,0.2 -0.01,0.27 z"
       id="path1282" />
    <path
       class="cls-5"
       d="m 64.19,322.09 1.42,0.82 a 0.48,0.48 0 0 0 0.45,0 l 1.35,-0.78 c 0.14,-0.08 0.15,-0.2 0,-0.26 L 66,321 a 0.53,0.53 0 0 0 -0.46,0 l -1.35,0.79 c -0.1,0.11 -0.12,0.21 0,0.3 z"
       id="path1284" />
    <path
       class="cls-5"
       d="m 62.18,320.93 1.42,0.82 a 0.48,0.48 0 0 0 0.45,0 l 1.36,-0.78 c 0.13,-0.08 0.14,-0.2 0,-0.26 L 64,319.87 a 0.48,0.48 0 0 0 -0.45,0 l -1.36,0.78 c -0.11,0.1 -0.13,0.21 -0.01,0.28 z"
       id="path1286" />
    <path
       class="cls-5"
       d="m 60.17,319.77 1.42,0.82 a 0.48,0.48 0 0 0 0.45,0 l 1.36,-0.78 c 0.13,-0.08 0.15,-0.2 0,-0.26 L 62,318.71 a 0.48,0.48 0 0 0 -0.45,0 l -1.36,0.78 c -0.12,0.1 -0.14,0.21 -0.02,0.28 z"
       id="path1288" />
    <path
       class="cls-5"
       d="m 58.16,318.61 1.42,0.82 a 0.48,0.48 0 0 0 0.45,0 l 1.36,-0.78 c 0.13,-0.08 0.15,-0.2 0,-0.26 L 60,317.55 a 0.48,0.48 0 0 0 -0.45,0 l -1.35,0.78 c -0.14,0.1 -0.15,0.21 -0.04,0.28 z"
       id="path1290" />
    <path
       class="cls-5"
       d="m 56.15,317.45 1.42,0.82 a 0.5,0.5 0 0 0 0.46,0 l 1.35,-0.78 c 0.14,-0.08 0.15,-0.19 0,-0.26 L 58,316.39 a 0.48,0.48 0 0 0 -0.45,0 l -1.35,0.78 c -0.15,0.1 -0.2,0.21 -0.05,0.28 z"
       id="path1292" />
    <path
       class="cls-5"
       d="m 51.66,314.86 3.91,2.25 a 0.48,0.48 0 0 0 0.45,0 l 1.35,-0.78 c 0.14,-0.08 0.15,-0.19 0,-0.26 l -3.91,-2.26 a 0.55,0.55 0 0 0 -0.45,0 l -1.36,0.79 c -0.09,0.07 -0.11,0.19 0.01,0.26 z"
       id="path1294" />
    <path
       class="cls-5"
       d="m 78.24,330.2 1.94,1.12 a 0.48,0.48 0 0 0 0.45,0 l 1.36,-0.78 c 0.13,-0.08 0.15,-0.19 0,-0.26 l -1.94,-1.12 a 0.48,0.48 0 0 0 -0.45,0 l -1.35,0.78 c -0.11,0.06 -0.12,0.2 -0.01,0.26 z"
       id="path1296" />
  </g>
  <g
     id="_Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ°_4"
     data-name="&lt;Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ°&gt;"
     transform="translate(0.00186273,-119.51243)">
    <g
       id="_Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ°_5"
       data-name="&lt;Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ°&gt;">
      <path
         id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_6"
         data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
         class="cls-10"
         d="m 93.16,326 v 0 L 60.93,307.4 v -25.35 l 0.25,-0.56 0.26,-0.14 v 0 a 2.27,2.27 0 0 1 2.23,0 l 29.49,17 a 2.22,2.22 0 0 1 1.11,1.93 v 23.78 c -0.2,1.26 -0.42,1.55 -1.11,1.94 z" />
      <path
         id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_7"
         data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
         class="cls-10"
         d="M 90.2,301.45 60.93,282.9 v -0.85 l 0.25,-0.56 0.26,-0.14 a 2.27,2.27 0 0 1 2.23,0 l 29.49,17 a 2.25,2.25 0 0 1 0.85,0.88 z" />
      <path
         id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_8"
         data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
         class="cls-13"
         d="m 61.67,281.48 31,17.87 a 1.08,1.08 0 0 1 0.54,0.94 V 326 L 60.93,307.4 v -25.49 a 0.49,0.49 0 0 1 0.74,-0.43 z" />
      <path
         id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_9"
         data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
         class="cls-11"
         d="m 61.67,281.48 31,17.87 a 1.08,1.08 0 0 1 0.54,0.94 V 326 L 60.93,307.4 v -25.49 a 0.49,0.49 0 0 1 0.74,-0.43 z" />
      <polygon
         id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_10"
         data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
         class="cls-14"
         points="60.93,306.48 60.93,307.4 93.16,326.01 93.16,325.09 " />
    </g>
    <polygon
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_11"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-15"
       points="92.12,323.11 92.12,300.34 62.16,283.04 62.16,305.86 " />
  </g>
  <g
     id="Men_2"
     transform="translate(0.00186273,-119.51243)">
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_12"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-16"
       d="m 8.66,303.64 c -0.27,2.4 -3.13,12.72 -2.51,16.25 0.62,3.53 10.36,9.45 10.36,9.45 l 1.35,-6 -5.4,-5.34 1.46,-10 z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_13"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-17"
       d="m 16.21,293.47 a 4.27,4.27 0 0 0 -5.43,1.64 c -1.44,2.38 -2.93,10.53 -3.06,11.89 0,0 2,2.78 5,2.32 z" />
    <path
       class="cls-18"
       d="m 27.34,408.56 a 8.36,8.36 0 0 0 6.31,-0.77 c 1.52,0 9.78,-3.48 10.9,-0.52 1,2.6 -2.59,5 -4.5,5.47 -4.17,1 -7.25,3.09 -8.93,3.44 -1.25,0.26 -2.86,0.43 -3.85,-0.55 -1.2,-1.17 -1.09,-5.52 0.07,-7.07 z"
       id="path1309" />
    <path
       class="cls-19"
       d="m 31.12,415.46 c 1.68,-0.35 4.76,-2.43 8.93,-3.44 1.6,-0.39 4.35,-2.14 4.63,-4.23 0.37,2.4 -2.85,4.52 -4.63,4.95 -4.17,1 -7.25,3.09 -8.93,3.44 -1.25,0.26 -2.86,0.43 -3.85,-0.55 a 2.34,2.34 0 0 1 -0.55,-1 5,5 0 0 0 4.4,0.83 z"
       id="path1311" />
    <path
       class="cls-18"
       d="m 14,402.55 a 8.38,8.38 0 0 0 6.31,-0.77 c 1.52,0.05 9.77,-3.48 10.89,-0.52 1,2.6 -2.59,5 -4.5,5.47 -4.16,1 -7.25,3.09 -8.92,3.44 -1.25,0.26 -2.86,0.43 -3.86,-0.55 -1.23,-1.17 -1.13,-5.52 0.08,-7.07 z"
       id="path1313" />
    <path
       class="cls-19"
       d="m 17.74,409.45 c 1.67,-0.35 4.76,-2.43 8.92,-3.44 1.6,-0.39 4.36,-2.14 4.64,-4.23 0.37,2.4 -2.85,4.52 -4.64,5 -4.16,1 -7.25,3.09 -8.92,3.44 -1.25,0.26 -2.86,0.43 -3.86,-0.55 a 2.33,2.33 0 0 1 -0.54,-1 5,5 0 0 0 4.4,0.78 z"
       id="path1315" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_14"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-6"
       d="m 13.8,380.13 a 49.34,49.34 0 0 1 1.9,-9 c 0,0 -0.57,-7.8 -0.85,-15.2 -0.33,-8.39 -3.24,-15.77 -0.94,-22.47 l 25.89,5.76 c 0,0 -1.56,33.45 -1.91,37.5 a 76.61,76.61 0 0 1 -1.16,9.4 c -1.18,6.49 -3.1,21.94 -3.1,21.94 -2.74,1.59 -6.34,0.71 -6.34,0.71 0,0 0.2,-19.54 0.38,-24.22 0.21,-5.71 0.39,-5.27 0.39,-5.27 L 27.2,365 26.64,357.92 c 0,0 -0.72,5.2 -1.18,9.84 -0.41,4.05 -1.39,7.71 -2.48,15.24 -0.94,6.54 -2.48,19.67 -2.48,19.67 -2.74,1.59 -6.46,0.27 -6.46,0.27 0,0 -0.98,-17.14 -0.24,-22.81 z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_15"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-16"
       d="m 17.58,293.61 c 2,0.1 3.44,0.61 3.68,0 a 24,24 0 0 0 0.45,-3.08 c -0.22,-0.57 -0.42,-1.18 -0.42,-1.18 -2.48,-1.53 -3.26,-4.2 -3.58,-7.32 -0.56,-5.33 2.32,-10 7.65,-10.55 5,-0.52 8.69,3 9.67,7.83 0.53,2.39 1.58,6.9 0.16,10.82 -0.8,2.2 -1.82,3.94 -2.85,4.28 a 26.44,26.44 0 0 1 -3,-0.26 v 0 c 0,0 -0.27,1.48 -0.45,2.43 -0.18,0.95 -0.11,1.45 1.78,2.61 1.89,1.16 -2.86,3.56 -6,3.33 -3.14,-0.23 -6.6,-2.11 -7.55,-4.12 -0.99,-2.22 -0.9,-4.85 0.46,-4.79 z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_16"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-11"
       d="m 20.43,293.9 c -0.55,1.37 0.84,3 4.55,4.2 3.71,1.2 4,-0.34 4,-0.34 a 74.4,74.4 0 0 1 7.2,3.71 c 2.22,1.56 3.21,6 3.51,13.64 0.34,8.79 0.37,21.82 0.08,24.07 0,0 -4.15,4.14 -9.47,3.7 -5.32,-0.44 -14.26,-5.14 -16.43,-8.77 0.06,-7.7 1,-9 -0.28,-13.4 -2.86,-10.15 -4.36,-14.31 -3,-21.06 1.14,-5.57 2.74,-6.26 4.94,-6.2 a 45.35,45.35 0 0 1 4.9,0.45 z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_17"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-16"
       d="m 48.07,322.38 c -4.36,1.1 -5.38,-1.66 -6,-3.93 -1.38,-5.52 -2.13,-10.5 -3.17,-13.63 -1.21,-3.69 -2.49,-4.28 -4.29,-5 -2.1,-0.84 -3.91,0.94 -3.21,5.64 a 94.91,94.91 0 0 0 4,16 c 0.55,1.72 1.77,4.77 3.59,6.25 2.25,1.82 5.64,1.74 10.77,0.46 2.18,-0.54 4.58,-1.85 8.72,-3.78 1.11,-0.52 2,-0.86 4.11,-1.85 a 14.64,14.64 0 0 0 5.47,-4.27 c 1.11,-1.62 1.26,-2.38 1,-2.75 -0.26,-0.37 -0.79,-0.36 -1.38,0.32 a 12.12,12.12 0 0 1 -3.14,2.91 c 0,0 1.37,-1.43 2.12,-2.35 a 12,12 0 0 0 1.65,-2.7 c 0.39,-0.94 -0.42,-2.22 -1,-1.55 -0.58,0.67 -0.92,1.36 -2,2.71 a 11.58,11.58 0 0 1 -2,1.93 22.06,22.06 0 0 0 1.87,-3 5,5 0 0 0 0.68,-2.71 c 0,-0.49 -0.73,-1.08 -1.39,-0.14 a 17.61,17.61 0 0 1 -2.34,3.58 c -1,1 -1.84,1.63 -1.87,1.34 -0.03,-0.29 0.61,-0.86 1,-2.06 0.39,-1.2 0,-2.48 -0.66,-2.61 -0.66,-0.13 -0.54,-0.11 -1.08,1 a 35.32,35.32 0 0 0 -2,3.6 7.42,7.42 0 0 1 -1.79,3.09 c -1.14,1.19 -3.51,2.45 -7.66,3.5 z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_18"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-17"
       d="m 33,299.07 c 2.91,-0.43 5,0.88 6.26,5.29 1.26,4.41 2.18,8 2.18,8 a 7.89,7.89 0 0 1 -4.88,3.24 c -3.48,0.85 -4.74,-0.82 -4.74,-0.82 0,0 -1,-4.62 -1.57,-7.77 -0.57,-3.15 -0.81,-7.41 2.75,-7.94 z" />
    <path
       class="cls-20"
       d="m 34.86,278.63 c 0,0 4.6,-7 -5.37,-8.43 -7.19,-1 -11.81,3.6 -12.35,8.61 -0.51,4.79 2.44,9.77 4.57,11.74 1,0.37 3.28,0.59 6.22,-0.75 a 35.4,35.4 0 0 0 0.14,-3.92 c 0,0 -3.51,-7.38 6.79,-7.25 z"
       id="path1322" />
  </g>
  <g
     id="Canvas"
     transform="matrix(4.0495342,0,0,4.0495342,-6480.5841,-9936.3011)"
     figma:type="canvas">
    <g
       id="g2566"
       style="mix-blend-mode:normal"
       figma:type="group">
      <g
         id="g2564"
         style="mix-blend-mode:normal"
         figma:type="group">
        <g
           id="Group"
           style="mix-blend-mode:normal"
           figma:type="group">
          <g
             id="g"
             style="mix-blend-mode:normal"
             figma:type="group">
            <g
               id="path"
               style="mix-blend-mode:normal"
               figma:type="group">
              <g
                 id="path9 fill"
                 style="mix-blend-mode:normal"
                 figma:type="vector">
                <path
                   id="use2501"
                   d="m 1642.285,2479.8353 c 0,1.5581 -0.1247,2.0655 -0.4452,2.4394 -0.3567,0.3213 -0.8198,0.4989 -1.2998,0.4986 l 0.1246,0.8903 c 0.7442,0.01 1.4664,-0.2528 2.0299,-0.7389 0.3033,-0.3698 0.5289,-0.7969 0.6635,-1.2558 0.1346,-0.4588 0.1754,-0.9401 0.12,-1.4151 v -5.8938 h -1.193 v 5.4397 z"
                   style="mix-blend-mode:normal;fill:#4e4e4e" />
              </g>
            </g>
            <g
               id="g2508"
               style="mix-blend-mode:normal"
               figma:type="group">
              <g
                 id="path10 fill"
                 style="mix-blend-mode:normal"
                 figma:type="vector">
                <path
                   id="use2505"
                   d="m 1651.182,2479.1331 c 0,0.6677 0,1.2642 0.053,1.7806 h -1.0595 l -0.071,-1.0595 c -0.2216,0.3749 -0.5385,0.6844 -0.9185,0.897 -0.38,0.2127 -0.8095,0.321 -1.2449,0.3138 -1.0328,0 -2.2614,-0.5609 -2.2614,-2.8489 v -3.8016 h 1.193 v 3.5612 c 0,1.2375 0.3828,2.0655 1.4601,2.0655 0.2216,0 0.4415,-0.04 0.6467,-0.1232 0.2053,-0.084 0.3917,-0.2076 0.5484,-0.3643 0.1567,-0.1568 0.2806,-0.3432 0.3643,-0.5484 0.084,-0.2053 0.1256,-0.4251 0.1233,-0.6468 v -3.9885 h 1.1929 v 4.7275 z"
                   style="mix-blend-mode:normal;fill:#4e4e4e" />
              </g>
            </g>
            <g
               id="g2513"
               style="mix-blend-mode:normal"
               figma:type="group">
              <g
                 id="path11 fill"
                 style="mix-blend-mode:normal"
                 figma:type="vector">
                <path
                   id="use2510"
                   d="m 1653.4434,2476.5326 c 0,-0.8279 0,-1.5046 -0.053,-2.1189 h 1.0684 l 0.053,1.1129 c 0.238,-0.4021 0.5807,-0.732 0.9915,-0.9546 0.4107,-0.2227 0.8742,-0.3297 1.3411,-0.3096 1.5847,0 2.7777,1.3265 2.7777,3.303 0,2.3326 -1.4334,3.49 -2.9825,3.49 -0.3965,0.018 -0.7909,-0.067 -1.1449,-0.2467 -0.3541,-0.1793 -0.6558,-0.447 -0.8761,-0.7772 v 0 3.5612 h -1.1752 v -7.0333 z m 1.1752,1.7361 c 0,0.1616 0.021,0.3225 0.053,0.4808 0.101,0.3953 0.331,0.7456 0.6535,0.9956 0.3225,0.2499 0.7191,0.3852 1.1271,0.3843 1.2553,0 1.9943,-1.0238 1.9943,-2.5106 0,-1.2998 -0.6944,-2.4127 -1.9498,-2.4127 -0.4967,0.041 -0.9616,0.2612 -1.3074,0.6201 -0.3459,0.3589 -0.5489,0.8317 -0.5711,1.3297 z"
                   style="mix-blend-mode:normal;fill:#4e4e4e" />
              </g>
            </g>
            <g
               id="g2518"
               style="mix-blend-mode:normal"
               figma:type="group">
              <g
                 id="path12 fill"
                 style="mix-blend-mode:normal"
                 figma:type="vector">
                <path
                   id="use2515"
                   d="m 1661.7476,2474.4078 1.4334,3.8372 c 0.1514,0.4273 0.3116,0.9437 0.4185,1.3265 0.1246,-0.3917 0.2581,-0.8903 0.4184,-1.3532 l 1.2998,-3.8105 h 1.2554 l -1.7806,4.6296 c -0.8903,2.2257 -1.4334,3.3742 -2.2525,4.0686 -0.4125,0.3768 -0.9155,0.6406 -1.4601,0.7657 l -0.2938,-0.9972 c 0.3808,-0.1251 0.7343,-0.3215 1.0417,-0.5787 0.4343,-0.3539 0.779,-0.8054 1.006,-1.3176 0.049,-0.089 0.082,-0.1851 0.098,-0.2849 -0.01,-0.1074 -0.037,-0.2126 -0.08,-0.3116 l -2.4216,-5.9917 h 1.2998 z"
                   style="mix-blend-mode:normal;fill:#4e4e4e" />
              </g>
            </g>
            <g
               id="g2523"
               style="mix-blend-mode:normal"
               figma:type="group">
              <g
                 id="path13 fill"
                 style="mix-blend-mode:normal"
                 figma:type="vector">
                <path
                   id="use2520"
                   d="m 1669.7401,2472.54 v 1.8696 h 1.7094 v 0.8903 h -1.7094 v 3.5078 c 0,0.8013 0.2315,1.2642 0.8903,1.2642 0.234,0 0.4675,-0.023 0.6945,-0.08 l 0.053,0.8903 c -0.3404,0.1179 -0.6995,0.1722 -1.0595,0.1602 -0.2384,0.015 -0.4772,-0.022 -0.7,-0.1079 -0.2229,-0.086 -0.4244,-0.2193 -0.5909,-0.3906 -0.3626,-0.4851 -0.5281,-1.0895 -0.463,-1.6916 v -3.5612 h -1.0149 v -0.8903 h 1.0327 v -1.5847 z"
                   style="mix-blend-mode:normal;fill:#4e4e4e" />
              </g>
            </g>
            <g
               id="g2528"
               style="mix-blend-mode:normal"
               figma:type="group">
              <g
                 id="path14 fill"
                 style="mix-blend-mode:normal"
                 figma:type="vector">
                <path
                   id="use2525"
                   d="m 1673.6472,2477.869 c -0.024,0.3019 0.017,0.6055 0.1221,0.8898 0.1047,0.2842 0.2698,0.5423 0.484,0.7565 0.2142,0.2142 0.4723,0.3793 0.7566,0.484 0.2842,0.1046 0.5878,0.1463 0.8897,0.1222 0.6107,0.014 1.2175,-0.1017 1.7806,-0.3384 l 0.2048,0.8903 c -0.6911,0.2847 -1.4341,0.4212 -2.1812,0.4007 -0.4356,0.03 -0.8724,-0.035 -1.2806,-0.1898 -0.4081,-0.1549 -0.778,-0.3962 -1.0841,-0.7074 -0.3062,-0.3112 -0.5414,-0.685 -0.6895,-1.0956 -0.1481,-0.4107 -0.2057,-0.8485 -0.1687,-1.2835 0,-1.9587 1.1663,-3.5078 3.0715,-3.5078 2.1367,0 2.6709,1.8696 2.6709,3.0626 0.011,0.1838 0.011,0.3682 0,0.552 h -4.6028 z m 3.4899,-0.8903 c 0.034,-0.238 0.017,-0.4806 -0.05,-0.7115 -0.067,-0.2309 -0.1834,-0.4447 -0.3403,-0.6269 -0.1569,-0.1822 -0.3511,-0.3287 -0.5694,-0.4296 -0.2183,-0.1008 -0.4557,-0.1537 -0.6962,-0.155 -0.4892,0.035 -0.9475,0.2522 -1.2851,0.6079 -0.3376,0.3558 -0.5302,0.8248 -0.54,1.3151 z"
                   style="mix-blend-mode:normal;fill:#4e4e4e" />
              </g>
            </g>
            <g
               id="g2533"
               style="mix-blend-mode:normal"
               figma:type="group">
              <g
                 id="path15 fill"
                 style="mix-blend-mode:normal"
                 figma:type="vector">
                <path
                   id="use2530"
                   d="m 1680.0334,2476.4323 c 0,-0.7657 0,-1.4245 -0.053,-2.0299 h 1.0684 v 1.2731 h 0.053 c 0.1121,-0.3929 0.3438,-0.7412 0.6629,-0.9965 0.3191,-0.2552 0.7097,-0.4048 1.1177,-0.4279 0.1123,-0.015 0.226,-0.015 0.3383,0 v 1.1128 c -0.1361,-0.016 -0.2735,-0.016 -0.4096,0 -0.4041,0.016 -0.7887,0.1779 -1.082,0.4565 -0.2933,0.2785 -0.4751,0.6542 -0.5116,1.057 -0.033,0.1822 -0.051,0.3668 -0.053,0.552 v 3.4633 h -1.1752 v -4.4515 z"
                   style="mix-blend-mode:normal;fill:#4e4e4e" />
              </g>
            </g>
          </g>
        </g>
        <g
           id="g2562"
           style="mix-blend-mode:normal"
           figma:type="group">
          <g
             id="g2540"
             style="mix-blend-mode:normal"
             figma:type="group">
            <g
               id="path16 fill"
               style="mix-blend-mode:normal"
               figma:type="vector">
              <path
                 id="use2537"
                 d="m 1679.5106,2456.5257 c 0.037,0.5981 -0.1057,1.1935 -0.4088,1.7105 -0.303,0.5169 -0.7531,0.9319 -1.2929,1.1922 -0.5397,0.2602 -1.1447,0.3539 -1.7379,0.2691 -0.5932,-0.085 -1.1477,-0.3442 -1.593,-0.7453 -0.4452,-0.4011 -0.7609,-0.9256 -0.907,-1.5067 -0.146,-0.5812 -0.1158,-1.1927 0.087,-1.7566 0.2027,-0.5639 0.5686,-1.0547 1.0513,-1.4099 0.4826,-0.3551 1.06,-0.5586 1.6586,-0.5845 0.3926,-0.022 0.7855,0.035 1.1562,0.1654 0.3707,0.1308 0.7119,0.3336 1.0039,0.5967 0.2921,0.2631 0.5293,0.5813 0.6979,0.9364 0.1687,0.3551 0.2654,0.74 0.2848,1.1327 z"
                 style="mix-blend-mode:normal;fill:#767677" />
            </g>
          </g>
          <g
             id="g2545"
             style="mix-blend-mode:normal"
             figma:type="group">
            <g
               id="path17 fill"
               style="mix-blend-mode:normal"
               figma:type="vector">
              <path
                 id="use2542"
                 d="m 1661.9062,2491.3924 c -8.0126,0 -15.0549,-2.8757 -18.6962,-7.1224 1.4128,3.8204 3.9622,7.1163 7.3048,9.444 3.3426,2.3278 7.3182,3.5756 11.3914,3.5756 4.0733,0 8.0488,-1.2478 11.3915,-3.5756 3.3426,-2.3277 5.8919,-5.6236 7.3048,-9.444 -3.6324,4.2467 -10.648,7.1224 -18.6963,7.1224 z"
                 style="mix-blend-mode:normal;fill:#f37726" />
            </g>
          </g>
          <g
             id="g2550"
             style="mix-blend-mode:normal"
             figma:type="group">
            <g
               id="path18 fill"
               style="mix-blend-mode:normal"
               figma:type="vector">
              <path
                 id="use2547"
                 d="m 1661.9062,2463.7773 c 8.0127,0 15.055,2.8756 18.6963,7.1223 -1.4129,-3.8204 -3.9622,-7.1163 -7.3048,-9.444 -3.3427,-2.3277 -7.3182,-3.5756 -11.3915,-3.5756 -4.0732,0 -8.0488,1.2479 -11.3914,3.5756 -3.3426,2.3277 -5.892,5.6236 -7.3048,9.444 3.6413,-4.2556 10.648,-7.1223 18.6962,-7.1223 z"
                 style="mix-blend-mode:normal;fill:#f37726" />
            </g>
          </g>
          <g
             id="g2555"
             style="mix-blend-mode:normal"
             figma:type="group">
            <g
               id="path19 fill"
               style="mix-blend-mode:normal"
               figma:type="vector">
              <path
                 id="use2552"
                 d="m 1650.8758,2499.6566 c 0.047,0.7533 -0.1314,1.5036 -0.5123,2.1553 -0.381,0.6516 -0.9473,1.1751 -1.6268,1.5037 -0.6796,0.3286 -1.4415,0.4475 -2.1889,0.3416 -0.7473,-0.106 -1.4462,-0.4321 -2.0076,-0.9367 -0.5614,-0.5046 -0.9598,-1.1649 -1.1446,-1.8967 -0.1847,-0.7319 -0.1474,-1.5022 0.1072,-2.2128 0.2546,-0.7106 0.715,-1.3293 1.3224,-1.7773 0.6075,-0.448 1.3347,-0.705 2.0887,-0.7383 0.494,-0.026 0.9884,0.045 1.4549,0.2094 0.4665,0.1647 0.8959,0.4197 1.2638,0.7504 0.368,0.3307 0.6671,0.7306 0.8804,1.177 0.2133,0.4464 0.3366,0.9304 0.3628,1.4244 z"
                 style="mix-blend-mode:normal;fill:#9e9e9e" />
            </g>
          </g>
          <g
             id="g2560"
             style="mix-blend-mode:normal"
             figma:type="group">
            <g
               id="path20 fill"
               style="mix-blend-mode:normal"
               figma:type="vector">
              <path
                 id="use2557"
                 d="m 1644.1206,2462.8094 c -0.4317,0.012 -0.8574,-0.1041 -1.2234,-0.3334 -0.366,-0.2293 -0.656,-0.5618 -0.8336,-0.9555 -0.1775,-0.3937 -0.2347,-0.8312 -0.1643,-1.2573 0.07,-0.4261 0.2652,-0.822 0.5599,-1.1377 0.2948,-0.3157 0.6763,-0.5372 1.0966,-0.6366 0.4203,-0.099 0.8606,-0.072 1.2656,0.078 0.405,0.1501 0.7566,0.4166 1.0105,0.766 0.2539,0.3494 0.3988,0.7661 0.4165,1.1977 0.017,0.5835 -0.1971,1.1501 -0.5955,1.5768 -0.3984,0.4268 -0.949,0.6791 -1.5323,0.7023 z"
                 style="mix-blend-mode:normal;fill:#616262" />
            </g>
          </g>
        </g>
      </g>
    </g>
  </g>
</svg>

```

`docs/static/img/product_3.svg`:

```svg
<?xml version="1.0" encoding="UTF-8" standalone="no"?>
<!--
  ~ Copyright (c) 2024- Datalayer, Inc.
  ~
  ~ BSD 3-Clause License
-->

<svg
   xmlns:dc="http://purl.org/dc/elements/1.1/"
   xmlns:cc="http://creativecommons.org/ns#"
   xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
   xmlns:svg="http://www.w3.org/2000/svg"
   xmlns="http://www.w3.org/2000/svg"
   xmlns:sodipodi="http://sodipodi.sourceforge.net/DTD/sodipodi-0.dtd"
   xmlns:inkscape="http://www.inkscape.org/namespaces/inkscape"
   viewBox="0 0 491.85 500"
   version="1.1"
   id="svg1738"
   sodipodi:docname="3.svg"
   inkscape:version="1.0.2 (e86c8708, 2021-01-15)">
  <metadata
     id="metadata1742">
    <rdf:RDF>
      <cc:Work
         rdf:about="">
        <dc:format>image/svg+xml</dc:format>
        <dc:type
           rdf:resource="http://purl.org/dc/dcmitype/StillImage" />
        <dc:title>Business_SVG</dc:title>
      </cc:Work>
    </rdf:RDF>
  </metadata>
  <sodipodi:namedview
     pagecolor="#ffffff"
     bordercolor="#666666"
     borderopacity="1"
     objecttolerance="10"
     gridtolerance="10"
     guidetolerance="10"
     inkscape:pageopacity="0"
     inkscape:pageshadow="2"
     inkscape:window-width="1393"
     inkscape:window-height="670"
     id="namedview1740"
     showgrid="false"
     inkscape:zoom="0.72568603"
     inkscape:cx="225.17067"
     inkscape:cy="274.16457"
     inkscape:window-x="0"
     inkscape:window-y="23"
     inkscape:window-maximized="0"
     inkscape:current-layer="svg1738" />
  <defs
     id="defs840">
    <style
       id="style833">.cls-1{fill:#b1b4c4;}.cls-2{fill:#e4e7f2;}.cls-15,.cls-3,.cls-6{fill:#d6d8e5;}.cls-4{fill:#fff;}.cls-5{opacity:0.5;fill:url(#Ğ‘ĞµĞ·Ñ‹Ğ¼ÑĞ½Ğ½Ñ‹Ğ¹_Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚_15);}.cls-6{opacity:0.4;}.cls-7{fill:#2b303f;}.cls-8{fill:#c3c6d1;}.cls-9{fill:#e9eaf2;}.cls-10{fill:#8c50ff;}.cls-11{fill:#f5f6ff;}.cls-12,.cls-13{fill:none;stroke:#e9eaf2;stroke-miterlimit:10;}.cls-12{stroke-width:0.22px;}.cls-13{stroke-width:1.09px;}.cls-14{fill:#fafbff;}.cls-15{opacity:0.3;}.cls-16,.cls-30{opacity:0.1;}.cls-17{opacity:0.15;}.cls-18{fill:#2b2a30;}.cls-19{fill:#ffcea9;}.cls-20{fill:#f4f4f4;}.cls-21{fill:#bf4b4b;}.cls-22{fill:#e26161;}.cls-23{fill:#ededed;}.cls-24{fill:#3a2c6d;}.cls-25{fill:#bfbfbf;}.cls-26{fill:#e5e5e5;}.cls-27{fill:#38226d;}.cls-28{fill:#9c73ff;}.cls-29{fill:#a1a5b5;}.cls-30{fill:#3e7eff;}</style>
    <linearGradient
       id="Ğ‘ĞµĞ·Ñ‹Ğ¼ÑĞ½Ğ½Ñ‹Ğ¹_Ğ³Ñ€Ğ°Ğ´Ğ¸ĞµĞ½Ñ‚_15"
       x1="-275.98"
       y1="2331.78"
       x2="-275.98"
       y2="2193.53"
       gradientTransform="matrix(0.87,0.5,0,1.15,511.49,-2300.61)"
       gradientUnits="userSpaceOnUse">
      <stop
         offset="0.21"
         stop-color="#fff"
         stop-opacity="0"
         id="stop835" />
      <stop
         offset="1"
         stop-color="#fff"
         stop-opacity="0.2"
         id="stop837" />
    </linearGradient>
  </defs>
  <title
     id="title842">Business_SVG</title>
  <g
     id="Laptop">
    <path
       class="cls-1"
       d="M 378.18,323.54 171.46,204.19 c -2.9,-1.67 -5.25,-6.16 -5.25,-10 V 34.25 c 0,-3.86 2.35,-5.64 5.25,-4 l 206.72,119.39 c 2.9,1.67 5.25,6.16 5.25,10 v 159.9 c 0,3.9 -2.35,5.68 -5.25,4 z"
       id="path844" />
    <polygon
       class="cls-1"
       points="381.54,323.87 380.54,317.08 379.24,325.19 "
       id="polygon846" />
    <path
       class="cls-1"
       d="m 165.84,31.27 2.25,-1.3 3.24,1.85 c 0,0 -3.45,0.52 -3.53,0.5 -0.08,-0.02 -1.96,-1.05 -1.96,-1.05 z"
       id="path848" />
    <path
       class="cls-2"
       d="M 376.29,324.64 169.56,205.29 c -2.9,-1.68 -5.25,-6.17 -5.25,-10 V 35.35 c 0,-3.87 2.35,-5.64 5.25,-4 l 206.73,119.38 c 2.9,1.67 5.25,6.17 5.25,10 v 159.94 c 0,3.86 -2.35,5.64 -5.25,3.97 z"
       id="path850" />
    <path
       class="cls-3"
       d="M 375.92,324.85 169.2,205.49 c -2.9,-1.67 -5.25,-6.16 -5.25,-10 V 35.56 c 0,-3.87 2.35,-5.65 5.25,-4 l 206.72,119.38 c 2.9,1.67 5.25,6.16 5.25,10 v 159.94 c 0,3.86 -2.35,5.64 -5.25,3.97 z"
       id="path852" />
    <path
       class="cls-4"
       d="M 378.33,315.12 166.57,192.86 166.68,36.2 c 0,-1.61 1.13,-2.26 2.52,-1.46 L 375.92,154.1 a 5.55,5.55 0 0 1 2.52,4.35 z"
       id="path854" />
    <path
       class="cls-5"
       d="M 378.31,315 166.55,192.75 166.66,36.08 c 0,-1.6 1.13,-2.25 2.52,-1.45 L 375.9,154 a 5.56,5.56 0 0 1 2.52,4.36 z"
       id="path856"
       style="fill:url(#%D0%91%D0%B5%D0%B7%D1%8B%D0%BC%D1%8F%D0%BD%D0%BD%D1%8B%D0%B9_%D0%B3%D1%80%D0%B0%D0%B4%D0%B8%D0%B5%D0%BD%D1%82_15)" />
    <path
       class="cls-6"
       d="M 220,417.77 13.28,298.41 c -2.9,-1.67 -2.53,-4.59 0.82,-6.53 l 138.48,-79.95 c 3.35,-1.93 8.41,-2.14 11.31,-0.47 l 206.72,119.35 c 2.9,1.68 2.54,4.6 -0.81,6.53 l -138.48,80 c -3.32,1.89 -8.41,2.1 -11.32,0.43 z"
       id="path858" />
    <path
       class="cls-1"
       d="M 224.52,415.06 17.8,295.7 c -2.9,-1.67 -2.54,-4.59 0.81,-6.53 l 138.49,-80 c 3.34,-1.93 8.41,-2.14 11.31,-0.47 l 206.72,119.4 c 2.9,1.68 2.54,4.6 -0.81,6.53 l -138.48,80 c -3.35,1.89 -8.42,2.1 -11.32,0.43 z"
       id="path860" />
    <polygon
       class="cls-1"
       points="15.84,289.11 20.22,290.94 15.84,293 "
       id="polygon862" />
    <polygon
       class="cls-1"
       points="377.09,331.02 377.09,327.21 373.85,328.32 376,331.48 "
       id="polygon864" />
    <path
       class="cls-2"
       d="M 224.52,411.77 17.8,292.42 c -2.9,-1.67 -2.54,-4.6 0.81,-6.53 L 157.1,205.94 c 3.34,-1.94 8.41,-2.15 11.31,-0.47 l 206.72,119.35 c 2.9,1.67 2.54,4.6 -0.81,6.53 L 235.84,411.3 c -3.35,1.94 -8.42,2.15 -11.32,0.47 z"
       id="path866" />
    <path
       class="cls-3"
       d="M 224.52,411.27 17.8,291.91 c -2.9,-1.67 -2.54,-4.59 0.81,-6.53 L 157.1,205.43 c 3.34,-1.93 8.41,-2.14 11.31,-0.47 l 206.72,119.35 c 2.9,1.68 2.54,4.6 -0.81,6.53 l -138.48,80 c -3.35,1.89 -8.42,2.1 -11.32,0.43 z"
       id="path868" />
    <path
       class="cls-7"
       d="m 153.26,232.4 -9.63,-5.56 c -0.78,-0.45 -0.68,-1.24 0.22,-1.77 l 9.19,-5.3 a 3.42,3.42 0 0 1 3.06,-0.13 l 9.63,5.56 c 0.78,0.45 0.69,1.25 -0.22,1.77 l -9.19,5.3 a 3.39,3.39 0 0 1 -3.06,0.13 z"
       id="path870" />
    <path
       class="cls-7"
       d="m 166.89,240.27 -9.63,-5.56 c -0.78,-0.45 -0.69,-1.25 0.22,-1.77 l 9.19,-5.3 a 3.39,3.39 0 0 1 3.06,-0.13 l 9.62,5.56 c 0.79,0.45 0.69,1.24 -0.22,1.77 l -9.18,5.3 a 3.42,3.42 0 0 1 -3.06,0.13 z"
       id="path872" />
    <path
       class="cls-7"
       d="M 180.67,248.22 171,242.67 c -0.78,-0.46 -0.68,-1.25 0.22,-1.77 l 9.19,-5.31 a 3.39,3.39 0 0 1 3.06,-0.12 l 9.63,5.55 c 0.78,0.46 0.68,1.25 -0.22,1.77 l -9.19,5.31 a 3.39,3.39 0 0 1 -3.02,0.12 z"
       id="path874" />
    <path
       class="cls-7"
       d="m 194.14,256 -9.63,-5.56 c -0.78,-0.45 -0.68,-1.24 0.22,-1.77 l 9.19,-5.3 a 3.42,3.42 0 0 1 3.06,-0.13 l 9.63,5.56 c 0.78,0.45 0.68,1.25 -0.22,1.77 l -9.19,5.3 a 3.39,3.39 0 0 1 -3.06,0.13 z"
       id="path876" />
    <path
       class="cls-7"
       d="m 207.76,263.87 -9.62,-5.56 c -0.79,-0.45 -0.69,-1.25 0.22,-1.77 l 9.18,-5.3 a 3.41,3.41 0 0 1 3.07,-0.13 l 9.62,5.56 c 0.79,0.45 0.69,1.24 -0.22,1.77 l -9.18,5.3 a 3.44,3.44 0 0 1 -3.07,0.13 z"
       id="path878" />
    <path
       class="cls-7"
       d="m 221.39,271.73 -9.63,-5.55 c -0.78,-0.46 -0.68,-1.25 0.22,-1.77 l 9.19,-5.31 a 3.39,3.39 0 0 1 3.06,-0.12 l 9.63,5.55 c 0.78,0.46 0.68,1.25 -0.22,1.77 l -9.19,5.31 a 3.39,3.39 0 0 1 -3.06,0.12 z"
       id="path880" />
    <path
       class="cls-7"
       d="m 235,279.6 -9.61,-5.6 c -0.79,-0.45 -0.69,-1.24 0.22,-1.77 l 9.18,-5.3 a 3.44,3.44 0 0 1 3.07,-0.13 l 9.62,5.56 c 0.79,0.45 0.69,1.25 -0.22,1.77 l -9.18,5.3 A 3.39,3.39 0 0 1 235,279.6 Z"
       id="path882" />
    <path
       class="cls-7"
       d="M 248.64,287.47 239,281.91 c -0.79,-0.45 -0.69,-1.25 0.22,-1.77 l 9.18,-5.3 a 3.39,3.39 0 0 1 3.06,-0.13 l 9.63,5.56 c 0.79,0.45 0.69,1.24 -0.22,1.77 l -9.19,5.3 a 3.42,3.42 0 0 1 -3.04,0.13 z"
       id="path884" />
    <path
       class="cls-7"
       d="m 262.27,295.33 -9.63,-5.55 c -0.78,-0.46 -0.68,-1.25 0.22,-1.77 l 9.19,-5.3 a 3.36,3.36 0 0 1 3.06,-0.13 l 9.63,5.56 c 0.78,0.45 0.68,1.24 -0.22,1.76 l -9.19,5.31 a 3.39,3.39 0 0 1 -3.06,0.12 z"
       id="path886" />
    <path
       class="cls-7"
       d="m 275.89,303.2 -9.62,-5.56 c -0.79,-0.45 -0.69,-1.24 0.22,-1.77 l 9.18,-5.3 a 3.41,3.41 0 0 1 3.07,-0.12 l 9.62,5.55 c 0.79,0.46 0.69,1.25 -0.22,1.77 l -9.18,5.3 a 3.41,3.41 0 0 1 -3.07,0.13 z"
       id="path888" />
    <path
       class="cls-7"
       d="m 289.52,311.07 -9.63,-5.56 c -0.78,-0.45 -0.68,-1.24 0.22,-1.77 l 9.19,-5.3 a 3.42,3.42 0 0 1 3.06,-0.13 l 9.63,5.56 c 0.78,0.45 0.68,1.24 -0.22,1.77 l -9.19,5.3 a 3.42,3.42 0 0 1 -3.06,0.13 z"
       id="path890" />
    <path
       class="cls-7"
       d="m 303.14,318.93 -9.62,-5.55 c -0.79,-0.46 -0.69,-1.25 0.22,-1.77 l 9.18,-5.3 a 3.41,3.41 0 0 1 3.07,-0.13 l 9.62,5.56 c 0.79,0.45 0.69,1.24 -0.22,1.76 l -9.18,5.31 a 3.41,3.41 0 0 1 -3.07,0.12 z"
       id="path892" />
    <path
       class="cls-7"
       d="m 316.77,326.8 -9.62,-5.56 c -0.79,-0.45 -0.69,-1.24 0.22,-1.76 l 9.18,-5.31 a 3.39,3.39 0 0 1 3.06,-0.12 l 9.63,5.55 c 0.78,0.46 0.69,1.25 -0.22,1.77 l -9.19,5.3 a 3.36,3.36 0 0 1 -3.06,0.13 z"
       id="path894" />
    <path
       class="cls-7"
       d="m 337,338.46 -16.19,-9.35 c -0.78,-0.45 -0.69,-1.24 0.22,-1.77 l 9.19,-5.3 a 3.42,3.42 0 0 1 3.06,-0.13 l 16.19,9.35 c 0.78,0.45 0.68,1.24 -0.22,1.77 l -9.19,5.3 a 3.42,3.42 0 0 1 -3.06,0.13 z"
       id="path896" />
    <path
       class="cls-7"
       d="m 160.27,251.69 -9.63,-5.55 c -0.79,-0.46 -0.69,-1.25 0.22,-1.77 l 9.18,-5.31 a 3.41,3.41 0 0 1 3.07,-0.12 l 9.62,5.55 c 0.79,0.46 0.69,1.25 -0.22,1.77 l -9.18,5.31 a 3.39,3.39 0 0 1 -3.06,0.12 z"
       id="path898" />
    <path
       class="cls-7"
       d="M 173.91,259.57 164.29,254 c -0.79,-0.46 -0.69,-1.25 0.22,-1.77 l 9.18,-5.31 a 3.41,3.41 0 0 1 3.07,-0.12 l 9.62,5.55 c 0.79,0.46 0.69,1.25 -0.22,1.77 l -9.16,5.33 a 3.41,3.41 0 0 1 -3.09,0.12 z"
       id="path900" />
    <path
       class="cls-7"
       d="m 187.56,267.45 -9.62,-5.55 c -0.79,-0.46 -0.69,-1.25 0.22,-1.77 l 9.18,-5.3 a 3.38,3.38 0 0 1 3.07,-0.13 l 9.62,5.56 c 0.79,0.45 0.69,1.24 -0.22,1.76 l -9.18,5.31 a 3.41,3.41 0 0 1 -3.07,0.12 z"
       id="path902" />
    <path
       class="cls-7"
       d="m 201.21,275.33 -9.62,-5.55 c -0.79,-0.46 -0.69,-1.25 0.22,-1.77 l 9.18,-5.3 a 3.41,3.41 0 0 1 3.07,-0.13 l 9.62,5.56 c 0.79,0.45 0.69,1.24 -0.22,1.76 l -9.18,5.31 a 3.41,3.41 0 0 1 -3.07,0.12 z"
       id="path904" />
    <path
       class="cls-7"
       d="m 214.75,283.15 -9.62,-5.56 c -0.79,-0.45 -0.69,-1.24 0.22,-1.76 l 9.18,-5.31 a 3.41,3.41 0 0 1 3.07,-0.12 l 9.62,5.55 c 0.79,0.46 0.69,1.25 -0.22,1.77 l -9.18,5.3 a 3.38,3.38 0 0 1 -3.07,0.13 z"
       id="path906" />
    <path
       class="cls-7"
       d="m 228.4,291 -9.62,-5.55 c -0.79,-0.46 -0.69,-1.25 0.22,-1.77 l 9.18,-5.31 a 3.41,3.41 0 0 1 3.07,-0.12 l 9.62,5.55 c 0.79,0.46 0.69,1.25 -0.22,1.77 l -9.18,5.31 A 3.41,3.41 0 0 1 228.4,291 Z"
       id="path908" />
    <path
       class="cls-7"
       d="m 242.05,298.91 -9.62,-5.55 c -0.79,-0.46 -0.69,-1.25 0.22,-1.77 l 9.18,-5.31 a 3.41,3.41 0 0 1 3.07,-0.12 l 9.62,5.55 c 0.79,0.46 0.69,1.25 -0.22,1.77 l -9.18,5.31 a 3.41,3.41 0 0 1 -3.07,0.12 z"
       id="path910" />
    <path
       class="cls-7"
       d="m 255.7,306.79 -9.62,-5.55 c -0.79,-0.46 -0.69,-1.25 0.22,-1.77 l 9.18,-5.31 a 3.39,3.39 0 0 1 3.06,-0.12 l 9.63,5.55 c 0.79,0.46 0.69,1.25 -0.22,1.77 l -9.18,5.31 a 3.41,3.41 0 0 1 -3.07,0.12 z"
       id="path912" />
    <path
       class="cls-7"
       d="m 269.35,314.67 -9.62,-5.55 c -0.79,-0.46 -0.69,-1.25 0.22,-1.77 l 9.18,-5.31 a 3.39,3.39 0 0 1 3.06,-0.12 l 9.63,5.56 c 0.78,0.45 0.69,1.24 -0.22,1.76 l -9.19,5.31 a 3.39,3.39 0 0 1 -3.06,0.12 z"
       id="path914" />
    <path
       class="cls-7"
       d="M 283,322.55 273.37,317 c -0.78,-0.46 -0.68,-1.25 0.22,-1.77 l 9.19,-5.3 a 3.39,3.39 0 0 1 3.06,-0.13 l 9.63,5.56 c 0.78,0.45 0.69,1.24 -0.22,1.76 l -9.19,5.31 a 3.39,3.39 0 0 1 -3.06,0.12 z"
       id="path916" />
    <path
       class="cls-7"
       d="M 296.65,330.43 287,324.88 c -0.78,-0.46 -0.68,-1.25 0.22,-1.77 l 9.19,-5.3 a 3.39,3.39 0 0 1 3.06,-0.13 l 9.63,5.56 c 0.78,0.45 0.68,1.24 -0.22,1.76 l -9.19,5.31 a 3.39,3.39 0 0 1 -3.04,0.12 z"
       id="path918" />
    <path
       class="cls-7"
       d="m 310.3,338.32 -9.63,-5.56 c -0.78,-0.46 -0.68,-1.25 0.22,-1.77 l 9.19,-5.3 a 3.39,3.39 0 0 1 3.06,-0.13 l 9.63,5.56 c 0.78,0.45 0.68,1.24 -0.22,1.77 l -9.19,5.3 a 3.42,3.42 0 0 1 -3.06,0.13 z"
       id="path920" />
    <path
       class="cls-7"
       d="m 146.62,243.81 -16.19,-9.34 c -0.79,-0.46 -0.69,-1.25 0.22,-1.77 l 9.18,-5.3 a 3.38,3.38 0 0 1 3.07,-0.13 l 16.18,9.34 c 0.79,0.46 0.69,1.25 -0.22,1.77 l -9.18,5.31 a 3.39,3.39 0 0 1 -3.06,0.12 z"
       id="path922" />
    <path
       class="cls-7"
       d="m 336.3,339 -9.62,-5.55 a 3.17,3.17 0 0 0 -2.86,0 l -9.71,5.55 a 0.87,0.87 0 0 0 0,1.65 l 0.77,0.44 a 0.8,0.8 0 0 1 0,1.52 l -10.26,5.92 c -0.8,0.46 -0.8,1.2 0,1.65 l 6.13,3.54 a 3.17,3.17 0 0 0 2.86,0 l 9.59,-5.54 2,-1.15 1.43,-0.82 1.44,-0.83 8.27,-4.78 c 0.74,-0.45 0.75,-1.18 -0.04,-1.6 z"
       id="path924" />
    <path
       class="cls-7"
       d="m 100.49,262.93 -9.63,-5.56 c -0.78,-0.45 -0.68,-1.24 0.22,-1.77 l 9.19,-5.3 a 3.42,3.42 0 0 1 3.06,-0.13 l 9.63,5.56 c 0.78,0.46 0.68,1.25 -0.22,1.77 l -9.19,5.3 a 3.39,3.39 0 0 1 -3.06,0.13 z"
       id="path926" />
    <path
       class="cls-7"
       d="m 114.07,270.78 -9.62,-5.56 c -0.79,-0.46 -0.69,-1.25 0.22,-1.77 l 9.18,-5.3 a 3.41,3.41 0 0 1 3.07,-0.13 l 9.62,5.56 c 0.79,0.45 0.69,1.24 -0.22,1.77 l -9.18,5.3 a 3.44,3.44 0 0 1 -3.07,0.13 z"
       id="path928" />
    <path
       class="cls-7"
       d="M 127.66,278.62 118,273.06 c -0.79,-0.45 -0.69,-1.24 0.22,-1.77 l 9.18,-5.3 a 3.42,3.42 0 0 1 3.06,-0.13 l 9.63,5.56 c 0.79,0.45 0.69,1.25 -0.22,1.77 l -9.18,5.3 a 3.41,3.41 0 0 1 -3.03,0.13 z"
       id="path930" />
    <path
       class="cls-7"
       d="m 243.37,345.42 -9.63,-5.55 c -0.78,-0.46 -0.68,-1.25 0.22,-1.77 l 9.19,-5.3 a 3.36,3.36 0 0 1 3.06,-0.13 l 9.63,5.56 c 0.78,0.45 0.69,1.24 -0.22,1.76 l -9.19,5.31 a 3.39,3.39 0 0 1 -3.06,0.12 z"
       id="path932" />
    <path
       class="cls-7"
       d="m 257,353.27 -9.63,-5.56 c -0.78,-0.45 -0.68,-1.24 0.22,-1.77 l 9.19,-5.3 a 3.42,3.42 0 0 1 3.06,-0.13 l 9.63,5.56 c 0.78,0.45 0.68,1.25 -0.22,1.77 l -9.19,5.3 a 3.39,3.39 0 0 1 -3.06,0.13 z"
       id="path934" />
    <path
       class="cls-7"
       d="m 270.54,361.11 -9.62,-5.55 c -0.79,-0.46 -0.69,-1.25 0.22,-1.77 l 9.18,-5.31 a 3.41,3.41 0 0 1 3.07,-0.12 l 9.62,5.55 c 0.79,0.46 0.69,1.25 -0.22,1.77 l -9.18,5.32 a 3.41,3.41 0 0 1 -3.07,0.11 z"
       id="path936" />
    <path
       class="cls-7"
       d="m 284.13,369 -9.62,-5.56 c -0.79,-0.45 -0.69,-1.24 0.22,-1.77 l 9.18,-5.3 a 3.42,3.42 0 0 1 3.06,-0.13 l 9.63,5.56 c 0.79,0.45 0.69,1.24 -0.22,1.77 l -9.18,5.3 a 3.44,3.44 0 0 1 -3.07,0.13 z"
       id="path938" />
    <path
       class="cls-7"
       d="m 144.75,288.48 -13.13,-7.57 c -0.78,-0.46 -0.68,-1.25 0.22,-1.77 l 9.19,-5.3 a 3.36,3.36 0 0 1 3.06,-0.13 l 13.13,7.58 c 0.78,0.45 0.68,1.24 -0.22,1.76 l -9.19,5.31 a 3.39,3.39 0 0 1 -3.06,0.12 z"
       id="path940" />
    <path
       class="cls-7"
       d="M 229.78,337.58 216.66,330 c -0.79,-0.45 -0.69,-1.24 0.22,-1.77 l 9.18,-5.3 a 3.44,3.44 0 0 1 3.07,-0.13 l 13.12,7.58 c 0.79,0.45 0.69,1.25 -0.22,1.77 l -9.18,5.3 a 3.41,3.41 0 0 1 -3.07,0.13 z"
       id="path942" />
    <path
       class="cls-7"
       d="m 212.7,327.71 -64,-36.94 c -0.78,-0.45 -0.69,-1.24 0.22,-1.77 l 9.19,-5.3 a 3.42,3.42 0 0 1 3.06,-0.13 l 64,36.95 c 0.79,0.45 0.69,1.24 -0.22,1.76 l -9.18,5.31 a 3.39,3.39 0 0 1 -3.07,0.12 z"
       id="path944" />
    <path
       class="cls-7"
       d="m 150.77,261.46 -9.63,-5.56 c -0.78,-0.45 -0.69,-1.24 0.22,-1.77 l 9.19,-5.3 a 3.42,3.42 0 0 1 3.06,-0.13 l 9.62,5.56 c 0.79,0.45 0.69,1.25 -0.22,1.77 l -9.18,5.3 a 3.39,3.39 0 0 1 -3.06,0.13 z"
       id="path946" />
    <path
       class="cls-7"
       d="m 164.38,269.32 -9.63,-5.56 c -0.78,-0.45 -0.69,-1.25 0.22,-1.77 l 9.19,-5.3 a 3.39,3.39 0 0 1 3.06,-0.13 l 9.62,5.56 c 0.79,0.45 0.69,1.24 -0.22,1.77 l -9.18,5.3 a 3.42,3.42 0 0 1 -3.06,0.13 z"
       id="path948" />
    <path
       class="cls-7"
       d="m 178,277.17 -9.63,-5.55 c -0.78,-0.46 -0.69,-1.25 0.22,-1.77 l 9.19,-5.3 a 3.39,3.39 0 0 1 3.06,-0.13 l 9.63,5.56 c 0.78,0.45 0.68,1.24 -0.22,1.77 l -9.19,5.3 a 3.39,3.39 0 0 1 -3.06,0.12 z"
       id="path950" />
    <path
       class="cls-7"
       d="m 191.6,285 -9.6,-5.52 c -0.78,-0.46 -0.68,-1.25 0.22,-1.77 l 9.19,-5.31 a 3.39,3.39 0 0 1 3.06,-0.12 l 9.63,5.55 c 0.78,0.46 0.68,1.25 -0.22,1.77 l -9.19,5.31 A 3.39,3.39 0 0 1 191.6,285 Z"
       id="path952" />
    <path
       class="cls-7"
       d="m 205.21,292.89 -9.63,-5.56 c -0.78,-0.45 -0.68,-1.24 0.22,-1.76 l 9.19,-5.31 a 3.39,3.39 0 0 1 3.06,-0.12 l 9.63,5.55 c 0.78,0.46 0.68,1.25 -0.22,1.77 l -9.19,5.3 a 3.39,3.39 0 0 1 -3.06,0.13 z"
       id="path954" />
    <path
       class="cls-7"
       d="m 218.82,300.75 -9.63,-5.56 c -0.78,-0.45 -0.68,-1.24 0.22,-1.77 l 9.19,-5.3 a 3.42,3.42 0 0 1 3.06,-0.13 l 9.63,5.56 c 0.78,0.45 0.68,1.25 -0.22,1.77 l -9.19,5.3 a 3.39,3.39 0 0 1 -3.06,0.13 z"
       id="path956" />
    <path
       class="cls-7"
       d="m 232.43,308.61 -9.63,-5.56 c -0.78,-0.45 -0.68,-1.25 0.22,-1.77 l 9.19,-5.3 a 3.39,3.39 0 0 1 3.06,-0.13 l 9.63,5.56 c 0.78,0.45 0.68,1.24 -0.22,1.77 l -9.19,5.3 a 3.42,3.42 0 0 1 -3.06,0.13 z"
       id="path958" />
    <path
       class="cls-7"
       d="m 246,316.47 -9.63,-5.56 c -0.78,-0.46 -0.68,-1.25 0.22,-1.77 l 9.19,-5.3 a 3.39,3.39 0 0 1 3.06,-0.13 l 9.63,5.56 c 0.78,0.45 0.69,1.24 -0.22,1.77 l -9.19,5.3 a 3.42,3.42 0 0 1 -3.06,0.13 z"
       id="path960" />
    <path
       class="cls-7"
       d="M 259.65,324.32 250,318.77 c -0.79,-0.46 -0.69,-1.25 0.22,-1.77 l 9.18,-5.31 a 3.39,3.39 0 0 1 3.06,-0.12 l 9.63,5.55 c 0.78,0.46 0.69,1.25 -0.22,1.77 l -9.19,5.31 a 3.39,3.39 0 0 1 -3.03,0.12 z"
       id="path962" />
    <path
       class="cls-7"
       d="m 273.26,332.18 -9.62,-5.56 c -0.79,-0.45 -0.69,-1.24 0.22,-1.76 l 9.18,-5.31 a 3.39,3.39 0 0 1 3.06,-0.12 l 9.63,5.55 c 0.79,0.46 0.69,1.25 -0.22,1.77 l -9.18,5.3 a 3.38,3.38 0 0 1 -3.07,0.13 z"
       id="path964" />
    <path
       class="cls-7"
       d="m 286.87,340 -9.62,-5.56 c -0.79,-0.45 -0.69,-1.24 0.22,-1.77 l 9.18,-5.3 a 3.44,3.44 0 0 1 3.07,-0.13 l 9.62,5.56 c 0.79,0.45 0.69,1.25 -0.22,1.77 l -9.18,5.3 a 3.41,3.41 0 0 1 -3.07,0.13 z"
       id="path966" />
    <path
       class="cls-7"
       d="m 300.48,347.9 -9.62,-5.56 c -0.79,-0.45 -0.69,-1.24 0.22,-1.77 l 9.18,-5.3 a 3.44,3.44 0 0 1 3.07,-0.13 l 9.67,5.56 c 0.79,0.45 0.69,1.24 -0.22,1.77 l -9.18,5.3 a 3.44,3.44 0 0 1 -3.12,0.13 z"
       id="path968" />
    <path
       class="cls-7"
       d="m 137.16,253.6 -19.91,-11.49 c -0.79,-0.46 -0.69,-1.25 0.22,-1.77 l 9.18,-5.3 a 3.41,3.41 0 0 1 3.07,-0.13 l 19.9,11.49 c 0.79,0.46 0.69,1.25 -0.22,1.77 l -9.18,5.3 a 3.39,3.39 0 0 1 -3.06,0.13 z"
       id="path970" />
    <path
       class="cls-7"
       d="m 130.8,265.18 -9.62,-5.55 c -0.79,-0.46 -0.69,-1.25 0.22,-1.77 l 9.18,-5.31 a 3.41,3.41 0 0 1 3.07,-0.12 l 9.62,5.55 c 0.79,0.46 0.69,1.25 -0.22,1.77 l -9.18,5.31 a 3.41,3.41 0 0 1 -3.07,0.12 z"
       id="path972" />
    <path
       class="cls-7"
       d="m 144.41,273 -9.62,-5.56 c -0.79,-0.45 -0.69,-1.24 0.22,-1.77 l 9.18,-5.3 a 3.42,3.42 0 0 1 3.06,-0.13 l 9.63,5.56 c 0.78,0.45 0.69,1.25 -0.22,1.77 l -9.19,5.3 a 3.39,3.39 0 0 1 -3.06,0.13 z"
       id="path974" />
    <path
       class="cls-7"
       d="m 158,280.9 -9.63,-5.56 c -0.78,-0.45 -0.68,-1.25 0.22,-1.77 l 9.19,-5.3 a 3.39,3.39 0 0 1 3.06,-0.13 l 9.63,5.56 c 0.78,0.45 0.68,1.24 -0.22,1.77 l -9.19,5.3 A 3.42,3.42 0 0 1 158,280.9 Z"
       id="path976" />
    <path
       class="cls-7"
       d="M 171.63,288.75 162,283.2 c -0.78,-0.46 -0.68,-1.25 0.22,-1.77 l 9.19,-5.31 a 3.39,3.39 0 0 1 3.06,-0.12 l 9.63,5.55 c 0.78,0.46 0.68,1.25 -0.22,1.77 l -9.19,5.31 a 3.39,3.39 0 0 1 -3.06,0.12 z"
       id="path978" />
    <path
       class="cls-7"
       d="m 185.24,296.61 -9.63,-5.56 c -0.78,-0.45 -0.69,-1.24 0.22,-1.77 L 185,284 a 3.42,3.42 0 0 1 3.06,-0.13 l 9.62,5.56 c 0.79,0.45 0.69,1.25 -0.22,1.77 l -9.18,5.3 a 3.39,3.39 0 0 1 -3.04,0.11 z"
       id="path980" />
    <path
       class="cls-7"
       d="m 198.84,304.47 -9.62,-5.56 c -0.79,-0.45 -0.69,-1.25 0.22,-1.77 l 9.18,-5.3 a 3.41,3.41 0 0 1 3.07,-0.13 l 9.62,5.56 c 0.79,0.45 0.69,1.24 -0.22,1.77 l -9.18,5.3 a 3.44,3.44 0 0 1 -3.07,0.13 z"
       id="path982" />
    <path
       class="cls-7"
       d="m 212.45,312.32 -9.62,-5.55 c -0.79,-0.46 -0.69,-1.25 0.22,-1.77 l 9.18,-5.31 a 3.41,3.41 0 0 1 3.07,-0.12 l 9.62,5.55 c 0.79,0.46 0.69,1.25 -0.22,1.77 l -9.18,5.31 a 3.41,3.41 0 0 1 -3.07,0.12 z"
       id="path984" />
    <path
       class="cls-7"
       d="m 226.06,320.18 -9.62,-5.56 c -0.79,-0.45 -0.69,-1.24 0.22,-1.77 l 9.18,-5.3 a 3.42,3.42 0 0 1 3.06,-0.13 l 9.63,5.56 c 0.78,0.46 0.69,1.25 -0.22,1.77 l -9.19,5.3 a 3.39,3.39 0 0 1 -3.06,0.13 z"
       id="path986" />
    <path
       class="cls-7"
       d="M 239.67,328 230,322.48 c -0.78,-0.45 -0.68,-1.25 0.22,-1.77 l 9.19,-5.3 a 3.39,3.39 0 0 1 3.06,-0.13 l 9.63,5.56 c 0.78,0.45 0.68,1.24 -0.22,1.77 l -9.19,5.3 a 3.42,3.42 0 0 1 -3.02,0.09 z"
       id="path988" />
    <path
       class="cls-7"
       d="m 253.28,335.89 -9.63,-5.55 c -0.78,-0.46 -0.68,-1.25 0.22,-1.77 l 9.19,-5.3 a 3.36,3.36 0 0 1 3.06,-0.13 l 9.63,5.56 c 0.78,0.45 0.68,1.24 -0.22,1.76 l -9.19,5.31 a 3.39,3.39 0 0 1 -3.06,0.12 z"
       id="path990" />
    <path
       class="cls-7"
       d="m 266.89,343.75 -9.63,-5.56 c -0.78,-0.45 -0.69,-1.24 0.22,-1.77 l 9.19,-5.3 a 3.42,3.42 0 0 1 3.06,-0.13 l 9.62,5.56 c 0.79,0.46 0.69,1.25 -0.22,1.77 l -9.18,5.3 a 3.39,3.39 0 0 1 -3.06,0.13 z"
       id="path992" />
    <path
       class="cls-7"
       d="m 297.34,361.33 -26.47,-15.28 c -0.79,-0.45 -0.69,-1.24 0.22,-1.77 l 9.18,-5.3 a 3.44,3.44 0 0 1 3.07,-0.13 l 26.47,15.28 c 0.78,0.46 0.68,1.25 -0.22,1.77 l -9.19,5.31 a 3.39,3.39 0 0 1 -3.06,0.12 z"
       id="path994" />
    <path
       class="cls-7"
       d="m 117.19,257.33 -13.12,-7.58 c -0.79,-0.45 -0.69,-1.25 0.22,-1.77 l 9.18,-5.3 a 3.41,3.41 0 0 1 3.07,-0.13 l 13.12,7.58 c 0.79,0.45 0.69,1.24 -0.22,1.77 l -9.18,5.3 a 3.44,3.44 0 0 1 -3.07,0.13 z"
       id="path996" />
    <path
       class="cls-7"
       d="M 350.63,330.56 157.36,219 c -0.78,-0.45 -0.69,-1.25 0.22,-1.77 l 4.59,-2.65 a 3.44,3.44 0 0 1 3.07,-0.13 L 358.51,326 c 0.78,0.45 0.68,1.24 -0.22,1.77 l -4.6,2.65 a 3.39,3.39 0 0 1 -3.06,0.14 z"
       id="path998" />
    <path
       class="cls-1"
       d="m 230.9,343.25 a 2.91,2.91 0 0 1 -1.33,1.39 l -53.19,30.7 a 6.54,6.54 0 0 1 -5.89,0.25 L 79.6,323.11 a 2,2 0 0 1 -0.92,-1 c -0.33,-0.8 0.13,-1.74 1.34,-2.44 L 133.21,289 a 6.57,6.57 0 0 1 5.89,-0.24 l 90.9,52.48 a 1.58,1.58 0 0 1 0.9,2.01 z"
       id="path1000" />
    <path
       class="cls-8"
       d="m 230.9,343.25 a 2.91,2.91 0 0 1 -1.33,1.39 l -53.19,30.7 a 6.54,6.54 0 0 1 -5.89,0.25 L 79.6,323.11 a 2,2 0 0 1 -0.92,-1 2.92,2.92 0 0 1 1.32,-1.34 l 53.19,-30.7 a 6.54,6.54 0 0 1 5.89,-0.25 L 230,342.3 a 2.05,2.05 0 0 1 0.9,0.95 z"
       id="path1002" />
    <path
       class="cls-7"
       d="M 365.34,322.1 172.07,210.52 a 3.43,3.43 0 0 1 -1.42,-2.72 v -2.27 c 0,-1.05 0.64,-1.53 1.42,-1.08 L 365.34,316 a 3.39,3.39 0 0 1 1.42,2.72 V 321 c 0,1.07 -0.63,1.55 -1.42,1.1 z"
       id="path1004" />
    <path
       class="cls-9"
       d="m 249.58,103.76 -67,-38.66 a 2.43,2.43 0 0 1 -1,-1.94 v -4.67 c 0,-0.75 0.46,-1.1 1,-0.77 l 67,38.66 a 2.43,2.43 0 0 1 1,1.94 V 103 c 0.02,0.74 -0.44,1.09 -1,0.76 z"
       id="path1006" />
    <path
       class="cls-9"
       d="M 232.38,104.88 182.93,76.33 a 2.44,2.44 0 0 1 -1,-2 v -2.27 c 0,-0.75 0.45,-1.1 1,-0.77 l 49.45,28.55 a 2.44,2.44 0 0 1 1,2 v 2.32 c 0.02,0.7 -0.38,1.04 -1,0.72 z"
       id="path1008" />
    <path
       class="cls-9"
       d="M 232.38,113.69 182.93,85.14 a 2.44,2.44 0 0 1 -1,-2 v -2.27 c 0,-0.75 0.45,-1.09 1,-0.77 l 49.45,28.56 a 2.4,2.4 0 0 1 1,1.94 v 2.32 c 0.02,0.75 -0.38,1.08 -1,0.77 z"
       id="path1010" />
    <path
       class="cls-10"
       d="M 223.06,117.12 182.93,94 a 2.4,2.4 0 0 1 -1,-1.94 v -2.38 c 0,-0.75 0.45,-1.09 1,-0.77 l 40.13,23.17 a 2.45,2.45 0 0 1 1,2 v 2.32 c 0.01,0.7 -0.44,1.04 -1,0.72 z"
       id="path1012" />
    <path
       class="cls-9"
       d="m 249.58,196.28 -67,-38.66 a 2.46,2.46 0 0 1 -1,-2 V 151 c 0,-0.75 0.46,-1.09 1,-0.77 l 67,38.66 a 2.46,2.46 0 0 1 1,2 v 4.67 c 0.02,0.7 -0.44,1.04 -1,0.72 z"
       id="path1014" />
    <path
       class="cls-9"
       d="m 232.38,197.4 -49.45,-28.56 a 2.4,2.4 0 0 1 -1,-1.94 v -2.32 c 0,-0.75 0.45,-1.1 1,-0.77 l 49.45,28.55 a 2.42,2.42 0 0 1 1,1.94 v 2.33 c 0.02,0.75 -0.38,1.09 -1,0.77 z"
       id="path1016" />
    <path
       class="cls-9"
       d="m 232.38,206.21 -49.45,-28.55 a 2.44,2.44 0 0 1 -1,-1.95 v -2.32 c 0,-0.75 0.45,-1.1 1,-0.77 l 49.45,28.55 a 2.44,2.44 0 0 1 1,2 v 2.32 c 0.02,0.7 -0.38,1.04 -1,0.72 z"
       id="path1018" />
    <path
       class="cls-10"
       d="m 223.06,209.64 -40.13,-23.17 a 2.44,2.44 0 0 1 -1,-1.95 v -2.32 c 0,-0.75 0.45,-1.09 1,-0.77 l 40.13,23.17 a 2.42,2.42 0 0 1 1,1.94 v 2.33 c 0.01,0.75 -0.44,1.13 -1,0.77 z"
       id="path1020" />
    <path
       class="cls-11"
       d="m 267.5,207.76 c 0,0 7.39,6.2 18.05,-2.27 7.62,-6.25 14.43,-2.68 18.22,-0.52 3.79,2.16 9.31,3.45 19.71,22.29 a 27.9,27.9 0 0 0 9,9.14 c 5.61,3.23 8.3,1.66 12.71,-5 4.41,-6.66 7.29,-14 15.39,-9.2 V 289 l -93.8,-54.15 v -27.53 z"
       id="path1022" />
    <path
       class="cls-9"
       d="m 247.12,179.44 -64.19,-37.06 a 2.44,2.44 0 0 1 -1,-1.95 v -37 c 0,-0.75 0.45,-1.09 1,-0.77 l 64.19,37.06 a 2.45,2.45 0 0 1 1,1.95 v 37 c 0.01,0.75 -0.44,1.09 -1,0.77 z"
       id="path1024" />
    <polyline
       class="cls-12"
       points="266.77 206.2 266.77 234.88 360.57 289.03 360.57 222.22"
       id="polyline1026" />
    <line
       class="cls-12"
       x1="303.64001"
       y1="205.28999"
       x2="303.64001"
       y2="256.09"
       id="line1028" />
    <line
       class="cls-12"
       x1="332.32999"
       y1="237.42"
       x2="332.32999"
       y2="272.66"
       id="line1030" />
    <path
       class="cls-13"
       d="m 266.77,207.32 c 16.64,10.32 19,-13 37.13,-2.54 18.13,10.46 15.63,24.11 29,31.84 13.37,7.73 13.7,-22.46 27.66,-14.4"
       id="path1032" />
    <ellipse
       class="cls-10"
       cx="303.64001"
       cy="205.28999"
       rx="1.8099999"
       ry="3.1300001"
       transform="rotate(-30,303.65434,205.28393)"
       id="ellipse1034" />
    <ellipse
       class="cls-10"
       cx="360.57001"
       cy="222.22"
       rx="1.8099999"
       ry="3.1300001"
       transform="matrix(0.87,-0.5,0.5,0.87,-62.81,210.07)"
       id="ellipse1036" />
    <ellipse
       class="cls-10"
       cx="332.32999"
       cy="236.78999"
       rx="1.8099999"
       ry="3.1300001"
       transform="matrix(0.87,-0.5,0.5,0.87,-73.87,197.9)"
       id="ellipse1038" />
    <ellipse
       class="cls-10"
       cx="266.76999"
       cy="207.32001"
       rx="1.8099999"
       ry="3.1300001"
       transform="matrix(0.87,-0.5,0.5,0.87,-67.92,161.17)"
       id="ellipse1040" />
    <path
       class="cls-9"
       d="m 269.42,158.05 -3.84,-2.22 a 2.43,2.43 0 0 1 -1,-1.94 v -18.57 c 0,-0.75 0.46,-1.09 1,-0.77 l 3.84,2.22 a 2.44,2.44 0 0 1 1,1.94 v 18.58 c 0.02,0.71 -0.42,1.09 -1,0.76 z"
       id="path1042" />
    <path
       class="cls-10"
       d="M 278.28,163.17 274.43,161 a 2.46,2.46 0 0 1 -1,-1.95 v -37.83 c 0,-0.75 0.46,-1.09 1,-0.77 l 3.85,2.22 a 2.45,2.45 0 0 1 1,2 v 37.73 c 0.01,0.75 -0.44,1.09 -1,0.77 z"
       id="path1044" />
    <path
       class="cls-9"
       d="m 296,173.39 -3.84,-2.22 a 2.44,2.44 0 0 1 -1,-1.95 v -34.11 c 0,-0.75 0.45,-1.09 1,-0.77 l 3.84,2.22 a 2.46,2.46 0 0 1 1,1.95 v 34.11 c 0,0.75 -0.46,1.09 -1,0.77 z"
       id="path1046" />
    <path
       class="cls-10"
       d="M 304.83,178.5 301,176.28 a 2.44,2.44 0 0 1 -1,-1.94 v -28.27 c 0,-0.75 0.46,-1.09 1,-0.77 l 3.84,2.22 a 2.44,2.44 0 0 1 1,1.95 v 28.26 c 0.01,0.75 -0.44,1.09 -1.01,0.77 z"
       id="path1048" />
    <path
       class="cls-9"
       d="m 322.46,188.68 -3.84,-2.22 a 2.46,2.46 0 0 1 -1,-2 v -14 c 0,-0.75 0.46,-1.09 1,-0.77 l 3.84,2.22 a 2.44,2.44 0 0 1 1,1.95 v 14 c 0.02,0.8 -0.46,1.14 -1,0.82 z"
       id="path1050" />
    <path
       class="cls-10"
       d="m 331.32,193.79 -3.85,-2.22 a 2.46,2.46 0 0 1 -1,-1.95 v -47.5 c 0,-0.75 0.46,-1.1 1,-0.77 l 3.85,2.22 a 2.42,2.42 0 0 1 1,1.94 V 193 c 0.01,0.77 -0.44,1.11 -1,0.79 z"
       id="path1052" />
    <path
       class="cls-9"
       d="M 352.92,206.26 349.07,204 a 2.46,2.46 0 0 1 -1,-1.95 v -14 c 0,-0.75 0.46,-1.1 1,-0.77 l 3.85,2.22 a 2.42,2.42 0 0 1 1,1.94 v 14 c 0.01,0.8 -0.44,1.14 -1,0.82 z"
       id="path1054" />
    <path
       class="cls-10"
       d="m 361.77,211.37 -3.85,-2.22 a 2.42,2.42 0 0 1 -1,-1.94 v -18.57 c 0,-0.75 0.45,-1.1 1,-0.77 l 3.85,2.22 a 2.43,2.43 0 0 1 1,1.94 v 18.57 c 0.02,0.75 -0.44,1.09 -1,0.77 z"
       id="path1056" />
  </g>
  <polygon
     class="cls-6"
     points="352.27,486.9 253.29,429.75 389.26,351.25 488.24,408.39 "
     id="polygon1059" />
  <polygon
     class="cls-1"
     points="256.9,427.74 355.88,484.88 491.85,406.38 491.85,402.62 488.59,404.5 392.88,349.23 260.16,425.86 256.9,423.98 "
     id="polygon1061" />
  <polygon
     class="cls-14"
     points="355.88,481.12 256.9,423.98 392.88,345.47 491.85,402.62 "
     id="polygon1063" />
  <polygon
     class="cls-9"
     points="462.63,408.68 383.27,362.86 391.13,358.32 470.5,404.14 "
     id="polygon1065" />
  <polygon
     class="cls-9"
     points="454.26,413.52 374.9,367.7 378.83,365.43 458.19,411.25 "
     id="polygon1067" />
  <polygon
     class="cls-9"
     points="447.77,417.26 368.41,371.44 372.34,369.17 451.7,414.99 "
     id="polygon1069" />
  <polygon
     class="cls-9"
     points="441.29,421.01 361.93,375.19 365.86,372.92 445.22,418.74 "
     id="polygon1071" />
  <polygon
     class="cls-9"
     points="393.73,448.47 314.36,402.65 322.23,398.11 401.58,443.93 "
     id="polygon1073" />
  <polygon
     class="cls-9"
     points="379.92,450.17 305.99,407.48 309.92,405.21 383.85,447.9 "
     id="polygon1075" />
  <polygon
     class="cls-9"
     points="371.96,453.06 299.5,411.23 303.43,408.96 375.89,450.79 "
     id="polygon1077" />
  <polygon
     class="cls-9"
     points="354.27,450.34 293.02,414.97 296.95,412.7 358.2,448.07 "
     id="polygon1079" />
  <polygon
     class="cls-9"
     points="353.65,405.53 331.51,392.75 353.65,379.97 375.79,392.75 "
     id="polygon1081" />
  <polygon
     class="cls-9"
     points="382.26,422.05 360.12,409.27 382.26,396.48 404.4,409.27 "
     id="polygon1083" />
  <polygon
     class="cls-9"
     points="410.87,438.57 388.73,425.78 410.87,413 433.01,425.79 "
     id="polygon1085" />
  <polygon
     class="cls-15"
     points="19,259.21 0.23,248.38 19,237.54 37.76,248.38 "
     id="polygon1111" />
  <g
     id="Girl_12">
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-18"
       d="m 221.65,1.33 c 0.86,-1.37 7.4,-2.28 9.55,3.27 0.82,2.1 0.69,7.47 1.37,10.85 0.68,3.38 2.3,5.29 2.87,8 0.57,2.71 -0.36,7.33 -7,8.14 -6.64,0.81 -11.64,-1.48 -13.2,-3.59 -1.56,-2.11 -1.59,-6.58 0,-9 1.59,-2.42 2.85,-4.35 2.81,-7.48 z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_2"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-18"
       d="m 226,0.38 c 0,0 -5,-1.38 -7.95,1.24 a 7.3,7.3 0 0 0 -2.1,7.3 c 0.4,1.56 1.19,3.68 2.43,3.8 C 219.62,12.84 226,0.38 226,0.38 Z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_3"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-19"
       d="m 227.85,13.81 c 0,0 -0.32,5.5 -0.22,5.9 0.1,0.4 2.15,0.79 2.73,1.27 0.58,0.48 -3,6.05 -4.8,6.88 -1.8,0.83 -7.42,-1.29 -7.81,-4.08 -0.36,-2.56 1.61,-4.56 2.37,-5.26 a 10.67,10.67 0 0 1 1.54,0 l 0.17,-2.66 c 2.45,-0.86 6.02,-2.05 6.02,-2.05 z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_4"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-19"
       d="m 211.7,43.12 a 29.19,29.19 0 0 1 -5.47,5.69 27.1,27.1 0 0 0 -1.87,2.19 8.24,8.24 0 0 1 -3.68,2.44 c -1.24,0.32 -1.76,0.24 -2,0 -0.24,-0.24 -0.11,-0.58 0.43,-0.8 a 6.74,6.74 0 0 0 2.41,-1.29 c 0,0 -1.15,0.53 -1.88,0.78 a 7.46,7.46 0 0 1 -2,0.4 c -0.69,0 -1.4,-0.79 -0.86,-1 0.54,-0.21 1,-0.26 2.1,-0.65 a 6.73,6.73 0 0 0 1.59,-0.82 14.2,14.2 0 0 1 -2.26,0.47 3.47,3.47 0 0 1 -1.89,-0.22 c -0.32,-0.14 -0.6,-0.72 0.12,-0.91 a 10.71,10.71 0 0 0 2.72,-0.63 c 0.84,-0.38 1.37,-0.78 1.18,-0.86 -0.19,-0.08 -0.66,0.18 -1.5,0.12 -0.84,-0.06 -1.63,-0.6 -1.62,-1 0.01,-0.4 0.18,-0.2 1,-0.27 a 18.48,18.48 0 0 1 2.65,-0.45 8.49,8.49 0 0 0 2.62,-0.31 c 0.89,-0.27 2.9,-2.68 4.44,-4.89 a 32.4,32.4 0 0 0 3.94,-8 c 0.92,-3 2,-8.73 2.81,-10.71 0.81,-1.98 2.14,-2.87 3.43,-2.91 1.51,-0.05 2.16,1.94 1.76,3.66 -0.7,2.95 -4.06,14.57 -8.17,19.97 z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_5"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-20"
       d="m 228.61,20.24 c 1.54,0.24 3.3,1.06 3.54,1.91 a 18.07,18.07 0 0 1 -0.44,9.16 c -1.33,3.54 -2.85,9.91 -3.61,11.44 A 18,18 0 0 1 216.6,40.5 c 0,0 -0.32,-6.14 -0.34,-8.17 -5,-4.33 -0.72,-9.68 3.48,-13.83 a 9.67,9.67 0 0 1 1.52,0 c 0,0 -3.75,4.44 -1.15,7 5.6,-1.75 6.71,-4.26 8.5,-5.26 z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_6"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-19"
       d="m 217.59,7 v 0 c 0.56,-3.53 3.11,-6.19 6.75,-6 a 7,7 0 0 1 6.59,7.42 7,7 0 0 1 -3.08,5.36 7.13,7.13 0 0 1 -0.56,1.55 c -1.29,1.5 -4.71,2.45 -5.84,2.46 -1,0 -1.82,-0.9 -2.74,-2.41 -1.9,-3.13 -1.42,-6.63 -1.12,-8.38 z" />
    <path
       class="cls-18"
       d="m 225.46,1.1 c 2.55,0.49 4.65,1.21 5.34,3.72 0.48,1.72 1.1,5 0.51,6.4 l -0.37,1 -3.09,1.59 c 0,0 -1.44,-1.2 -1,-4.72 A 2.49,2.49 0 0 0 226.42,7.76 3.64,3.64 0 0 1 226,6.69 a 4,4 0 0 0 -2,-2.16 6.9,6.9 0 0 0 -6.14,0.28 6.7,6.7 0 0 1 7.6,-3.71 z"
       id="path1129" />
    <path
       class="cls-18"
       d="m 211.41,85.54 c -1.29,1 -3.3,0.32 -3.4,0.42 a 54.13,54.13 0 0 1 -4.73,3.61 c -0.8,0.63 -2.06,1.48 -1.83,2.7 0.41,2.17 3.89,1.5 5.21,0.84 1.32,-0.66 2.38,-1.77 3.63,-2.54 0.88,-0.55 1.76,-0.84 1.89,-2 0.09,-0.64 -0.54,-3.06 -0.77,-3.03 z"
       id="path1131" />
    <path
       class="cls-21"
       d="m 212.17,88.16 c -0.17,1.07 -1,1.37 -1.91,1.91 -1.27,0.79 -2.38,1.92 -3.7,2.59 -1.32,0.67 -4.24,1.22 -5.09,-0.33 0.46,2.1 3.88,1.44 5.19,0.78 1.31,-0.66 2.38,-1.77 3.63,-2.54 0.88,-0.55 1.76,-0.84 1.89,-2 a 1.74,1.74 0 0 0 -0.01,-0.41 z"
       id="path1133" />
    <path
       class="cls-18"
       d="m 205.12,82 c -1.18,1 -3,0.42 -3.06,0.51 a 49.65,49.65 0 0 1 -4.32,3.29 c -0.74,0.58 -1.89,1.36 -1.68,2.47 0.37,2 3.56,1.38 4.77,0.77 1.21,-0.61 2.18,-1.62 3.32,-2.32 0.81,-0.51 1.61,-0.77 1.74,-1.8 A 6.77,6.77 0 0 0 205.12,82 Z"
       id="path1135" />
    <path
       class="cls-21"
       d="m 205.88,84.52 c -0.16,1 -0.95,1.25 -1.76,1.75 C 203,87 202,88 200.74,88.64 c -1.26,0.64 -3.88,1.12 -4.66,-0.3 0.42,1.92 3.55,1.32 4.75,0.71 1.2,-0.61 2.18,-1.62 3.32,-2.32 0.81,-0.51 1.61,-0.77 1.74,-1.8 a 2,2 0 0 0 -0.01,-0.41 z"
       id="path1137" />
    <path
       class="cls-19"
       d="m 223,44.1 a 19.07,19.07 0 0 1 -10.29,-1.49 c 0.06,1.1 0.12,2.07 0.12,2.07 -4.19,3 -12.59,7.94 -13.14,11.38 0.55,10.86 2.2,26.38 2.67,26.6 1.31,0.63 2.23,0.53 2.85,-0.1 0,0 2.64,-9.2 1.87,-22.7 0,0 14.65,-6.49 15.61,-10 a 11.15,11.15 0 0 0 0.4,-4.42 C 223.08,45 223.05,44.53 223,44.1 Z"
       id="path1139" />
    <path
       class="cls-19"
       d="M 227.86,42.69 A 15.69,15.69 0 0 1 219,43.88 c 0,1.45 0.21,4.18 0.21,4.18 C 215,51 206.63,56 206.09,59.44 c 0.54,10.87 1.56,26.6 2,26.8 a 3.55,3.55 0 0 0 3.47,-0.41 c 0,0 2.65,-9.09 1.88,-22.59 0,-0.25 12.56,-6.44 14.15,-8.07 1.59,-1.63 1.9,-4.07 1.86,-6.38 a 15.6,15.6 0 0 0 -1.59,-6.1 z"
       id="path1141" />
    <path
       class="cls-22"
       d="m 230.94,45 c 0,0 4.65,8.23 -3.09,12.46 -8.17,4.46 -13.14,5.5 -13.14,5.5 l -1.23,0.29 a 31.78,31.78 0 0 1 0,8.55 c 0,0 -5.83,2 -13.26,-4.51 l -2.46,-7.93 -0.29,-2.1 a 4.41,4.41 0 0 1 1.24,-4 c 1.78,-1.62 7.43,-5.76 10.94,-8.12 3.51,-2.36 6.35,-4.64 6.35,-4.64 l 0.61,-0.57 c 0,0 4.17,3.32 11.78,2.21 a 11.83,11.83 0 0 1 2.55,2.86 z"
       id="path1143" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_7"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-19"
       d="m 226.34,57.2 a 22,22 0 0 1 2.24,-1.77 9.3,9.3 0 0 0 2.27,-1.62 c 0.71,-0.71 1.76,-3.7 2.31,-6.61 A 28.87,28.87 0 0 0 233,37.39 68.56,68.56 0 0 0 229.11,26.09 c -1,-2.18 -0.45,-3.51 0.49,-4.48 1.11,-1.13 2.26,-1.1 3.58,1.94 a 62.5,62.5 0 0 1 4.08,13.3 29.43,29.43 0 0 1 -0.14,10 36.5,36.5 0 0 1 -2.66,8.4 c -0.34,0.79 -0.4,1.45 -0.87,3 a 10.15,10.15 0 0 1 -2.4,4.21 c -1,0.94 -1.52,1.12 -1.79,1 -0.27,-0.12 -0.33,-0.52 0.08,-1 A 8.4,8.4 0 0 0 231.17,60 c 0,0 -0.85,1.09 -1.41,1.7 a 7.88,7.88 0 0 1 -1.7,1.42 c -0.61,0.37 -1.58,-0.07 -1.18,-0.56 0.4,-0.49 0.85,-0.77 1.67,-1.69 a 8,8 0 0 0 1.13,-1.59 15.08,15.08 0 0 1 -1.88,1.59 3.53,3.53 0 0 1 -1.81,0.75 c -0.34,0 -0.82,-0.4 -0.24,-0.95 a 12.21,12.21 0 0 0 2.24,-2 c 0.62,-0.79 0.94,-1.44 0.74,-1.42 -0.2,0.02 -0.53,0.5 -1.32,0.87 -0.79,0.37 -1.72,0.24 -1.88,-0.2 -0.16,-0.44 0.08,-0.24 0.81,-0.72 z" />
    <path
       class="cls-23"
       d="m 235.2,27.66 c 0,0 -2.81,2.5 -5.94,2 L 228,24.41 c 0,0 -0.83,-2.75 1.53,-3.8 2.36,-1.05 4.65,1.7 5.67,7.05 z"
       id="path1146" />
    <path
       class="cls-23"
       d="m 219.74,18.5 c 0,0 -3.05,-0.93 -6.28,5.82 l 1.21,0.73 a 51.49,51.49 0 0 1 5.07,-6.55 z"
       id="path1148" />
    <g
       id="_Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ°_"
       data-name="&lt;Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ°&gt;">
      <g
         id="_Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ°_2"
         data-name="&lt;Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ°&gt;">
        <path
           id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_8"
           data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
           class="cls-20"
           d="m 198.7,47.63 10.86,-6.27 a 0.62,0.62 0 0 1 0.62,0 l 19,11 -11.17,6.45 z" />
        <path
           class="cls-24"
           d="m 218.34,56.32 0.83,0.48 c 0.07,0 0.06,0.11 0,0.16 l -0.79,0.45 a 0.3,0.3 0 0 1 -0.26,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.8,-0.45 a 0.3,0.3 0 0 1 0.25,0 z"
           id="path1151" />
        <path
           class="cls-24"
           d="m 217.17,55.65 0.83,0.48 c 0.06,0 0.06,0.1 0,0.15 l -0.79,0.46 a 0.32,0.32 0 0 1 -0.27,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.79,-0.45 a 0.29,0.29 0 0 1 0.27,0 z"
           id="path1153" />
        <path
           class="cls-24"
           d="m 216,55 0.83,0.48 c 0.07,0 0.06,0.11 0,0.15 l -0.79,0.46 a 0.32,0.32 0 0 1 -0.27,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.15 L 215.73,55 a 0.32,0.32 0 0 1 0.27,0 z"
           id="path1155" />
        <path
           class="cls-24"
           d="m 214.82,54.29 0.83,0.48 c 0.06,0 0,0.11 0,0.15 l -0.8,0.46 a 0.3,0.3 0 0 1 -0.26,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.15 l 0.79,-0.46 a 0.29,0.29 0 0 1 0.27,0 z"
           id="path1157" />
        <path
           class="cls-24"
           d="m 213.64,53.61 0.83,0.48 c 0.07,0 0.06,0.11 0,0.15 l -0.79,0.46 a 0.32,0.32 0 0 1 -0.27,0 l -0.83,-0.48 c -0.06,0 -0.06,-0.11 0,-0.15 l 0.8,-0.46 a 0.3,0.3 0 0 1 0.26,0 z"
           id="path1159" />
        <path
           class="cls-24"
           d="m 212.46,52.93 0.83,0.48 c 0.07,0 0.06,0.11 0,0.15 l -0.8,0.46 a 0.27,0.27 0 0 1 -0.26,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.1 0,-0.15 l 0.79,-0.46 a 0.3,0.3 0 0 1 0.27,0 z"
           id="path1161" />
        <path
           class="cls-24"
           d="m 211.29,52.25 0.83,0.48 c 0.07,0 0.06,0.11 0,0.15 l -0.79,0.46 a 0.29,0.29 0 0 1 -0.27,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.1 0,-0.15 l 0.79,-0.46 a 0.32,0.32 0 0 1 0.27,0 z"
           id="path1163" />
        <path
           class="cls-24"
           d="m 210.11,51.57 0.83,0.48 c 0.07,0 0.06,0.11 0,0.16 l -0.79,0.45 a 0.27,0.27 0 0 1 -0.26,0 L 209,52.2 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.79,-0.46 a 0.3,0.3 0 0 1 0.32,-0.01 z"
           id="path1165" />
        <path
           class="cls-24"
           d="m 208.94,50.9 0.83,0.47 c 0.07,0 0.06,0.11 0,0.16 L 209,52 a 0.32,0.32 0 0 1 -0.27,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.79,-0.45 a 0.29,0.29 0 0 1 0.25,-0.01 z"
           id="path1167" />
        <path
           class="cls-24"
           d="m 207.76,50.22 0.83,0.48 c 0.07,0 0.06,0.1 0,0.15 l -0.79,0.46 a 0.3,0.3 0 0 1 -0.26,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.15 l 0.79,-0.46 a 0.27,0.27 0 0 1 0.26,0 z"
           id="path1169" />
        <path
           class="cls-24"
           d="m 206.59,49.54 0.83,0.48 c 0.06,0 0.06,0.1 0,0.15 l -0.79,0.46 a 0.32,0.32 0 0 1 -0.27,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.15 l 0.79,-0.46 a 0.29,0.29 0 0 1 0.27,0 z"
           id="path1171" />
        <path
           class="cls-24"
           d="m 205.41,48.86 0.83,0.48 c 0.07,0 0.06,0.11 0,0.15 l -0.79,0.46 a 0.3,0.3 0 0 1 -0.26,0 l -0.84,-0.48 c -0.06,0 -0.05,-0.11 0,-0.15 l 0.8,-0.46 a 0.3,0.3 0 0 1 0.26,0 z"
           id="path1173" />
        <path
           class="cls-24"
           d="m 204.24,48.18 0.83,0.48 c 0.06,0 0.05,0.11 0,0.15 l -0.8,0.46 a 0.27,0.27 0 0 1 -0.26,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.15 l 0.79,-0.46 a 0.32,0.32 0 0 1 0.27,0 z"
           id="path1175" />
        <path
           class="cls-24"
           d="m 202.49,47.17 1.4,0.81 c 0.07,0 0.06,0.11 0,0.15 l -0.79,0.46 a 0.29,0.29 0 0 1 -0.27,0 l -1.39,-0.8 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.79,-0.45 a 0.3,0.3 0 0 1 0.26,-0.01 z"
           id="path1177" />
        <path
           class="cls-24"
           d="m 217.74,54.66 0.83,0.48 c 0.07,0 0.06,0.11 0,0.15 l -0.79,0.46 a 0.29,0.29 0 0 1 -0.27,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.15 l 0.79,-0.46 a 0.32,0.32 0 0 1 0.27,0 z"
           id="path1179" />
        <path
           class="cls-24"
           d="m 216.56,54 0.83,0.48 c 0.07,0 0.06,0.11 0,0.15 l -0.79,0.46 a 0.29,0.29 0 0 1 -0.27,0 l -0.83,-0.48 c -0.06,0 -0.06,-0.11 0,-0.15 L 216.3,54 a 0.3,0.3 0 0 1 0.26,0 z"
           id="path1181" />
        <path
           class="cls-24"
           d="m 215.38,53.3 0.83,0.48 c 0.07,0 0.06,0.11 0,0.15 l -0.79,0.46 a 0.27,0.27 0 0 1 -0.26,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.15 l 0.79,-0.46 a 0.3,0.3 0 0 1 0.26,0 z"
           id="path1183" />
        <path
           class="cls-24"
           d="m 214.2,52.62 0.84,0.48 c 0.06,0 0.05,0.11 0,0.15 l -0.8,0.46 a 0.27,0.27 0 0 1 -0.26,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.15 l 0.79,-0.46 a 0.3,0.3 0 0 1 0.26,0 z"
           id="path1185" />
        <path
           class="cls-24"
           d="m 213,52 0.83,0.48 c 0.06,0 0.06,0.1 0,0.15 l -0.79,0.46 a 0.32,0.32 0 0 1 -0.27,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.16 L 212.73,52 a 0.29,0.29 0 0 1 0.27,0 z"
           id="path1187" />
        <path
           class="cls-24"
           d="m 211.86,51.27 0.83,0.48 c 0.07,0 0.06,0.1 0,0.15 l -0.79,0.46 a 0.32,0.32 0 0 1 -0.27,0 l -0.83,-0.48 c -0.06,0 -0.06,-0.11 0,-0.16 l 0.79,-0.45 a 0.29,0.29 0 0 1 0.27,0 z"
           id="path1189" />
        <path
           class="cls-24"
           d="m 210.68,50.59 0.83,0.48 c 0.07,0 0.06,0.1 0,0.15 l -0.79,0.46 a 0.3,0.3 0 0 1 -0.26,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.15 l 0.8,-0.46 a 0.27,0.27 0 0 1 0.25,0 z"
           id="path1191" />
        <path
           class="cls-24"
           d="m 209.5,49.91 0.83,0.48 c 0.07,0 0.06,0.1 0,0.15 l -0.8,0.46 a 0.3,0.3 0 0 1 -0.26,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.15 l 0.79,-0.46 a 0.27,0.27 0 0 1 0.27,0 z"
           id="path1193" />
        <path
           class="cls-24"
           d="m 208.33,49.23 0.83,0.48 c 0.06,0 0.06,0.1 0,0.15 l -0.79,0.46 a 0.32,0.32 0 0 1 -0.27,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.15 l 0.79,-0.46 a 0.29,0.29 0 0 1 0.27,0 z"
           id="path1195" />
        <path
           class="cls-24"
           d="M 207.15,48.55 208,49 c 0.07,0 0.06,0.1 0,0.15 l -0.79,0.46 a 0.32,0.32 0 0 1 -0.27,0 l -0.83,-0.48 c -0.06,0 -0.06,-0.11 0,-0.15 l 0.79,-0.46 a 0.29,0.29 0 0 1 0.25,0.03 z"
           id="path1197" />
        <path
           class="cls-24"
           d="m 206,47.87 0.83,0.48 c 0.07,0 0.06,0.1 0,0.15 L 206,49 a 0.3,0.3 0 0 1 -0.26,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.15 l 0.8,-0.46 A 0.27,0.27 0 0 1 206,47.87 Z"
           id="path1199" />
        <path
           class="cls-24"
           d="m 204.79,47.19 0.83,0.48 c 0.07,0 0.06,0.1 0,0.15 l -0.79,0.46 a 0.3,0.3 0 0 1 -0.26,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.15 l 0.79,-0.46 a 0.27,0.27 0 0 1 0.26,0 z"
           id="path1201" />
        <path
           class="cls-24"
           d="m 218.91,55.34 1.4,0.81 c 0.07,0 0.06,0.1 0,0.15 l -0.79,0.46 a 0.3,0.3 0 0 1 -0.26,0 l -1.4,-0.81 c -0.07,0 -0.06,-0.11 0,-0.15 l 0.79,-0.46 a 0.3,0.3 0 0 1 0.26,0 z"
           id="path1203" />
        <path
           class="cls-24"
           d="m 202.55,47.13 0.83,0.48 a 0.28,0.28 0 0 0 0.25,0 l 0.83,-0.48 a 0.08,0.08 0 0 0 0,-0.15 h -0.07 a 0.08,0.08 0 0 1 0,-0.14 l 0.89,-0.51 a 0.08,0.08 0 0 0 0,-0.14 l -0.53,-0.3 a 0.28,0.28 0 0 0 -0.25,0 l -0.83,0.48 -0.17,0.09 -0.12,0.08 -0.13,0.07 -0.71,0.41 c -0.06,-0.02 -0.06,0.07 0.01,0.11 z"
           id="path1205" />
        <path
           class="cls-24"
           d="m 222.89,53.69 0.84,0.48 c 0.06,0 0.05,0.11 0,0.15 l -0.8,0.46 a 0.27,0.27 0 0 1 -0.26,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.15 l 0.79,-0.46 a 0.3,0.3 0 0 1 0.26,0 z"
           id="path1207" />
        <path
           class="cls-24"
           d="m 221.72,53 0.83,0.48 c 0.07,0 0.06,0.11 0,0.16 l -0.79,0.45 a 0.27,0.27 0 0 1 -0.26,0 l -0.83,-0.47 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.79,-0.45 A 0.3,0.3 0 0 1 221.72,53 Z"
           id="path1209" />
        <path
           class="cls-24"
           d="m 220.55,52.34 0.83,0.48 c 0.07,0 0.06,0.1 0,0.15 l -0.79,0.46 a 0.32,0.32 0 0 1 -0.27,0 l -0.83,-0.48 c -0.06,0 -0.05,-0.11 0,-0.15 l 0.8,-0.46 a 0.27,0.27 0 0 1 0.26,0 z"
           id="path1211" />
        <path
           class="cls-24"
           d="m 210.57,46.57 0.83,0.48 c 0.07,0 0.06,0.11 0,0.16 l -0.79,0.45 a 0.29,0.29 0 0 1 -0.27,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.1 0,-0.15 l 0.79,-0.46 a 0.32,0.32 0 0 1 0.27,0 z"
           id="path1213" />
        <path
           class="cls-24"
           d="m 209.4,45.9 0.83,0.48 c 0.06,0 0.06,0.1 0,0.15 l -0.8,0.46 a 0.3,0.3 0 0 1 -0.26,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.15 l 0.79,-0.46 a 0.29,0.29 0 0 1 0.27,0 z"
           id="path1215" />
        <path
           class="cls-24"
           d="m 208.22,45.22 0.83,0.48 c 0.07,0 0.06,0.11 0,0.15 l -0.79,0.46 a 0.27,0.27 0 0 1 -0.26,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.15 l 0.79,-0.46 a 0.3,0.3 0 0 1 0.26,0 z"
           id="path1217" />
        <path
           class="cls-24"
           d="m 207.05,44.54 0.83,0.48 c 0.07,0 0.06,0.11 0,0.16 l -0.79,0.45 a 0.27,0.27 0 0 1 -0.26,0 L 206,45.15 c -0.07,0 -0.06,-0.1 0,-0.15 l 0.8,-0.46 a 0.3,0.3 0 0 1 0.25,0 z"
           id="path1219" />
        <path
           class="cls-24"
           d="m 219.08,51.49 1.13,0.65 c 0.07,0 0.06,0.11 0,0.15 l -0.79,0.46 a 0.29,0.29 0 0 1 -0.27,0 L 218,52.11 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.79,-0.45 a 0.29,0.29 0 0 1 0.29,-0.01 z"
           id="path1221" />
        <path
           class="cls-24"
           d="m 211.74,47.25 1.13,0.65 c 0.07,0 0.06,0.11 0,0.16 l -0.79,0.45 a 0.3,0.3 0 0 1 -0.26,0 l -1.14,-0.66 c -0.06,0 -0.06,-0.11 0,-0.15 l 0.8,-0.46 a 0.3,0.3 0 0 1 0.26,0.01 z"
           id="path1223" />
        <path
           class="cls-24"
           d="m 213.21,48.1 5.52,3.19 c 0.07,0 0.06,0.11 0,0.15 l -0.8,0.46 a 0.3,0.3 0 0 1 -0.26,0 l -5.52,-3.19 c -0.07,0 -0.06,-0.1 0,-0.15 l 0.79,-0.46 a 0.3,0.3 0 0 1 0.27,0 z"
           id="path1225" />
        <path
           class="cls-24"
           d="m 218.56,53.82 0.83,0.48 c 0.07,0 0.06,0.1 0,0.15 l -0.79,0.46 a 0.32,0.32 0 0 1 -0.27,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.15 l 0.79,-0.46 a 0.29,0.29 0 0 1 0.27,0 z"
           id="path1227" />
        <path
           class="cls-24"
           d="m 217.38,53.14 0.83,0.48 c 0.07,0 0.06,0.11 0,0.15 l -0.79,0.46 a 0.3,0.3 0 0 1 -0.26,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.15 l 0.79,-0.46 a 0.3,0.3 0 0 1 0.26,0 z"
           id="path1229" />
        <path
           class="cls-24"
           d="m 216.21,52.46 0.83,0.48 c 0.07,0 0.06,0.11 0,0.15 l -0.79,0.46 a 0.29,0.29 0 0 1 -0.27,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.1 0,-0.15 l 0.79,-0.46 a 0.32,0.32 0 0 1 0.27,0 z"
           id="path1231" />
        <path
           class="cls-24"
           d="m 215,51.78 0.83,0.48 c 0.07,0 0.06,0.11 0,0.16 l -0.8,0.45 a 0.27,0.27 0 0 1 -0.26,0 l -0.83,-0.47 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.79,-0.46 a 0.3,0.3 0 0 1 0.27,0 z"
           id="path1233" />
        <path
           class="cls-24"
           d="m 213.86,51.11 0.83,0.48 c 0.07,0 0.06,0.1 0,0.15 l -0.79,0.46 a 0.32,0.32 0 0 1 -0.27,0 l -0.83,-0.48 c -0.06,0 -0.06,-0.11 0,-0.16 l 0.8,-0.45 a 0.27,0.27 0 0 1 0.26,0 z"
           id="path1235" />
        <path
           class="cls-24"
           d="m 212.69,50.43 0.83,0.48 c 0.06,0 0.06,0.11 0,0.15 l -0.8,0.46 a 0.3,0.3 0 0 1 -0.26,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.15 l 0.79,-0.46 a 0.29,0.29 0 0 1 0.27,0 z"
           id="path1237" />
        <path
           class="cls-24"
           d="m 211.51,49.75 0.83,0.48 c 0.07,0 0.06,0.11 0,0.15 l -0.79,0.46 a 0.3,0.3 0 0 1 -0.26,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.15 l 0.8,-0.46 a 0.3,0.3 0 0 1 0.25,0 z"
           id="path1239" />
        <path
           class="cls-24"
           d="m 210.34,49.07 0.83,0.48 c 0.07,0 0.06,0.11 0,0.15 l -0.79,0.46 a 0.29,0.29 0 0 1 -0.27,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.1 0,-0.15 l 0.79,-0.46 a 0.32,0.32 0 0 1 0.27,0 z"
           id="path1241" />
        <path
           class="cls-24"
           d="m 209.16,48.39 0.83,0.48 c 0.07,0 0.06,0.11 0,0.16 l -0.79,0.45 a 0.27,0.27 0 0 1 -0.26,0 l -0.83,-0.47 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.79,-0.45 a 0.3,0.3 0 0 1 0.26,-0.01 z"
           id="path1243" />
        <path
           class="cls-24"
           d="m 208,47.72 0.83,0.48 c 0.07,0 0.06,0.1 0,0.15 l -0.79,0.46 a 0.32,0.32 0 0 1 -0.27,0 l -0.83,-0.48 c -0.06,0 -0.06,-0.11 0,-0.16 l 0.79,-0.45 a 0.29,0.29 0 0 1 0.27,0 z"
           id="path1245" />
        <path
           class="cls-24"
           d="m 206.81,47 0.83,0.48 c 0.07,0 0.06,0.11 0,0.15 l -0.8,0.46 a 0.3,0.3 0 0 1 -0.26,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.15 L 206.54,47 a 0.27,0.27 0 0 1 0.27,0 z"
           id="path1247" />
        <path
           class="cls-24"
           d="m 205.64,46.36 0.83,0.48 c 0.07,0 0.06,0.11 0,0.15 l -0.79,0.46 a 0.29,0.29 0 0 1 -0.27,0 l -0.83,-0.48 c -0.06,0 -0.05,-0.11 0,-0.15 l 0.8,-0.46 a 0.3,0.3 0 0 1 0.26,0 z"
           id="path1249" />
        <path
           class="cls-24"
           d="m 219.73,54.5 1.72,1 c 0.07,0 0.06,0.1 0,0.15 l -0.79,0.46 a 0.32,0.32 0 0 1 -0.27,0 l -1.71,-1 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.8,-0.45 a 0.27,0.27 0 0 1 0.25,0 z"
           id="path1251" />
        <path
           class="cls-24"
           d="m 220.28,53.5 0.83,0.48 c 0.07,0 0.06,0.1 0,0.15 l -0.79,0.46 a 0.32,0.32 0 0 1 -0.27,0 l -0.83,-0.48 c -0.06,0 -0.06,-0.11 0,-0.15 l 0.79,-0.46 a 0.29,0.29 0 0 1 0.27,0 z"
           id="path1253" />
        <path
           class="cls-24"
           d="m 219.11,52.82 0.83,0.48 c 0.06,0 0.05,0.11 0,0.15 l -0.8,0.46 a 0.3,0.3 0 0 1 -0.26,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.15 l 0.79,-0.46 a 0.29,0.29 0 0 1 0.27,0 z"
           id="path1255" />
        <path
           class="cls-24"
           d="m 217.93,52.14 0.83,0.48 c 0.07,0 0.06,0.11 0,0.15 l -0.79,0.46 a 0.27,0.27 0 0 1 -0.26,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.15 l 0.8,-0.46 a 0.3,0.3 0 0 1 0.25,0 z"
           id="path1257" />
        <path
           class="cls-24"
           d="m 216.76,51.46 0.83,0.48 c 0.07,0 0.06,0.11 0,0.16 l -0.79,0.45 a 0.29,0.29 0 0 1 -0.27,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.1 0,-0.15 l 0.79,-0.46 a 0.32,0.32 0 0 1 0.27,0 z"
           id="path1259" />
        <path
           class="cls-24"
           d="m 215.58,50.79 0.83,0.47 c 0.07,0 0.06,0.11 0,0.16 l -0.79,0.45 a 0.3,0.3 0 0 1 -0.26,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.79,-0.45 a 0.27,0.27 0 0 1 0.26,0.01 z"
           id="path1261" />
        <path
           class="cls-24"
           d="m 214.41,50.11 0.83,0.48 c 0.07,0 0.06,0.1 0,0.15 l -0.79,0.46 a 0.32,0.32 0 0 1 -0.27,0 l -0.83,-0.48 c -0.06,0 -0.06,-0.11 0,-0.15 l 0.79,-0.46 a 0.29,0.29 0 0 1 0.27,0 z"
           id="path1263" />
        <path
           class="cls-24"
           d="m 213.23,49.43 0.84,0.48 c 0.06,0 0.05,0.11 0,0.15 l -0.8,0.46 a 0.3,0.3 0 0 1 -0.26,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.15 l 0.79,-0.46 a 0.3,0.3 0 0 1 0.26,0 z"
           id="path1265" />
        <path
           class="cls-24"
           d="m 212.06,48.75 0.83,0.48 c 0.07,0 0.06,0.11 0,0.15 l -0.79,0.46 a 0.27,0.27 0 0 1 -0.26,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.1 0,-0.15 l 0.8,-0.46 a 0.3,0.3 0 0 1 0.25,0 z"
           id="path1267" />
        <path
           class="cls-24"
           d="m 210.89,48.07 0.83,0.48 c 0.07,0 0.06,0.11 0,0.16 l -0.79,0.45 a 0.29,0.29 0 0 1 -0.27,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.1 0,-0.15 l 0.79,-0.46 a 0.32,0.32 0 0 1 0.27,0 z"
           id="path1269" />
        <path
           class="cls-24"
           d="m 209.71,47.4 0.83,0.48 c 0.07,0 0.06,0.1 0,0.15 l -0.79,0.46 a 0.3,0.3 0 0 1 -0.26,0 l -0.83,-0.48 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.79,-0.45 a 0.27,0.27 0 0 1 0.26,0 z"
           id="path1271" />
        <path
           class="cls-24"
           d="m 208.54,46.72 0.83,0.48 c 0.07,0 0.06,0.11 0,0.15 l -0.79,0.46 a 0.32,0.32 0 0 1 -0.27,0 l -0.83,-0.48 c -0.06,0 -0.06,-0.11 0,-0.15 l 0.79,-0.46 a 0.29,0.29 0 0 1 0.27,0 z"
           id="path1273" />
        <path
           class="cls-24"
           d="m 205.91,45.2 2.29,1.32 c 0.06,0 0.05,0.11 0,0.15 l -0.8,0.46 a 0.27,0.27 0 0 1 -0.26,0 l -2.28,-1.32 c -0.07,0 -0.06,-0.1 0,-0.15 l 0.8,-0.46 a 0.3,0.3 0 0 1 0.25,0 z"
           id="path1275" />
        <path
           class="cls-24"
           d="m 221.45,54.17 1.14,0.66 c 0.06,0 0,0.11 0,0.15 l -0.8,0.46 a 0.3,0.3 0 0 1 -0.26,0 l -1.13,-0.65 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.79,-0.45 a 0.3,0.3 0 0 1 0.26,-0.01 z"
           id="path1277" />
        <path
           class="cls-24"
           d="M 201.31,47.86 218,57.48 c 0.07,0 0.06,0.11 0,0.16 l -0.4,0.22 a 0.27,0.27 0 0 1 -0.26,0 l -16.68,-9.62 c -0.06,0 0,-0.11 0,-0.15 l 0.4,-0.23 a 0.27,0.27 0 0 1 0.25,0 z"
           id="path1279" />
        <polygon
           id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_9"
           data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
           class="cls-25"
           points="212.85,47.2 215.83,45.48 221.04,48.49 220.93,48.55 218.06,50.21 212.96,47.26 " />
        <polygon
           id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_10"
           data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
           class="cls-26"
           points="220.93,48.55 218.06,50.21 212.96,47.26 215.83,45.6 " />
        <path
           id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_11"
           data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
           class="cls-26"
           d="m 229.23,52.36 v 0.25 a 1.05,1.05 0 0 1 -0.52,0.91 l -10.13,5.84 a 1,1 0 0 1 -1,0 L 199.23,48.79 a 1,1 0 0 1 -0.53,-0.91 v -0.25 l 19.36,11.17 z" />
        <path
           id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_12"
           data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
           class="cls-26"
           d="m 218.06,58.8 v 0.7 a 1.07,1.07 0 0 1 -0.52,-0.14 L 199.23,48.79 a 1,1 0 0 1 -0.53,-0.91 v -0.25 z" />
        <path
           id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_13"
           data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
           class="cls-20"
           d="M 217.77,59 A 1.25,1.25 0 0 1 216.7,58.92 L 198.46,48.35 a 1.22,1.22 0 0 1 -0.6,-0.87 l -2,-11.9 a 1.36,1.36 0 0 1 0,-0.2 1.22,1.22 0 0 1 0.37,-0.88 l 18.94,10.94 a 0.91,0.91 0 0 1 0.45,0.64 z" />
        <path
           id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_14"
           data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
           class="cls-26"
           d="m 218.06,58.81 -0.12,0.07 -0.17,0.08 -2.16,-12.88 a 0.91,0.91 0 0 0 -0.45,-0.64 L 196.22,34.5 a 1.22,1.22 0 0 1 0.25,-0.2 l 19,11 a 1,1 0 0 1 0.45,0.65 z" />
      </g>
    </g>
  </g>
  <g
     id="Girl_8">
    <ellipse
       class="cls-6"
       cx="455.85001"
       cy="360.19"
       rx="22.690001"
       ry="13.1"
       id="ellipse1449" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_27"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-24"
       d="m 454.85,237.69 c 0.91,-1.46 7.86,-2.42 10.15,3.47 0.86,2.23 0.73,7.94 1.46,11.52 0.73,3.58 2.43,5.62 3,8.53 0.57,2.91 -0.38,7.78 -7.39,8.65 -7.01,0.87 -12.4,-1.6 -14.06,-3.84 -1.66,-2.24 -1.69,-7 0,-9.53 1.69,-2.53 3,-4.63 3,-8 z" />
    <path
       class="cls-19"
       d="m 446.53,262.33 c 0,0 -1.65,11.67 1.47,19.88 3.12,8.21 2.25,-2.13 2.25,-2.13 l -0.75,-2.46 c 0,0 -0.62,-9.5 -0.36,-11.83 0.26,-2.33 0.2,-4.33 0.36,-4.52 0.16,-0.19 -0.61,-0.56 -0.94,-0.61 -0.33,-0.05 -2.03,1.67 -2.03,1.67 z"
       id="path1452" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_28"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-24"
       d="m 459.44,236.68 c 0,0 -5.23,-1.51 -8.4,1.32 a 7.77,7.77 0 0 0 -2.24,7.75 c 0.42,1.65 1.27,3.91 2.58,4 1.31,0.09 8.06,-13.07 8.06,-13.07 z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_29"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-19"
       d="m 461.44,251 c 0,0 -0.34,5.83 -0.23,6.26 0.11,0.43 2.28,0.84 2.9,1.35 0.62,0.51 -3.17,6.42 -5.1,7.3 -1.93,0.88 -7.88,-1.36 -8.29,-4.33 -0.38,-2.72 1.7,-4.84 2.51,-5.58 a 12.41,12.41 0 0 1 1.64,0 l 0.17,-2.82 c 2.61,-0.93 6.4,-2.18 6.4,-2.18 z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_30"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-20"
       d="m 462.24,257.77 c 1.64,0.26 3.51,1.13 3.77,2 a 19.33,19.33 0 0 1 -0.47,9.73 c -1.42,3.75 -2.37,6.14 -3.19,7.76 0,0 -7.09,3 -12.8,-0.51 0,0 -0.4,-4 -0.42,-6.17 -5.28,-4.6 -0.77,-10.28 3.7,-14.69 a 10.85,10.85 0 0 1 1.61,0 c 0,0 -4,4.72 -1.21,7.4 5.93,-1.79 7.11,-4.45 9.01,-5.52 z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_31"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-19"
       d="m 450.55,243.72 v 0 c 0.59,-3.75 3.29,-6.58 7.16,-6.35 a 7.43,7.43 0 0 1 3.73,13.63 7.54,7.54 0 0 1 -0.59,1.63 c -1.37,1.6 -5,2.61 -6.21,2.62 -1,0 -1.93,-0.95 -2.9,-2.56 -2.03,-3.4 -1.51,-7.12 -1.19,-8.97 z" />
    <path
       class="cls-24"
       d="m 458.9,237.44 c 2.71,0.53 4.94,1.29 5.68,3.95 0.5,1.84 1.16,5.33 0.53,6.8 l -0.38,1.07 -3.29,1.74 c 0,0 -1.53,-1.28 -1.05,-5 a 2.8,2.8 0 0 0 -0.46,-1.42 4.12,4.12 0 0 1 -0.46,-1.13 4.25,4.25 0 0 0 -2.12,-2.3 c -2.45,-1.37 -6,-0.19 -6.52,0.31 a 7.11,7.11 0 0 1 8.07,-4.02 z"
       id="path1458" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_32"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-19"
       d="m 466.2,285 c 0.61,-3.8 1.75,-6.26 1.22,-8.35 a 75.85,75.85 0 0 0 -4.62,-12.3 c -1.2,-2.36 -0.83,-4 0.41,-4.94 1.4,-1 2.73,-0.59 4,2 1.59,3.29 3.37,6.67 4.24,11.57 a 25.78,25.78 0 0 1 -0.12,9.57 c -0.54,3.41 -1.62,5.33 -2.91,8.53 -0.36,0.92 -2.74,-2.84 -2.22,-6.08 z" />
    <path
       class="cls-27"
       d="m 463.83,355.83 c -1.37,1.11 -3.51,0.34 -3.61,0.44 a 55.48,55.48 0 0 1 -5,3.84 c -0.86,0.67 -2.19,1.57 -1.95,2.87 0.43,2.31 4.13,1.6 5.53,0.89 1.4,-0.71 2.53,-1.88 3.85,-2.7 0.95,-0.59 1.87,-0.89 2,-2.08 0.09,-0.72 -0.58,-3.29 -0.82,-3.26 z"
       id="path1461" />
    <path
       class="cls-28"
       d="m 464.63,358.61 c -0.18,1.14 -1.09,1.46 -2,2 -1.34,0.83 -2.52,2 -3.92,2.74 -1.4,0.74 -4.51,1.3 -5.41,-0.35 0.49,2.23 4.13,1.53 5.51,0.83 1.38,-0.7 2.53,-1.88 3.85,-2.7 0.95,-0.59 1.87,-0.89 2,-2.08 a 2.88,2.88 0 0 0 -0.03,-0.44 z"
       id="path1463" />
    <path
       class="cls-27"
       d="m 454.2,353.9 c -1.25,1 -3.15,0.45 -3.24,0.55 a 52.4,52.4 0 0 1 -4.59,3.5 c -0.79,0.61 -2,1.44 -1.79,2.62 0.4,2.12 3.79,1.47 5.07,0.82 1.28,-0.65 2.32,-1.72 3.53,-2.47 0.86,-0.54 1.71,-0.82 1.85,-1.91 0.08,-0.66 -0.6,-3.13 -0.83,-3.11 z"
       id="path1465" />
    <path
       class="cls-28"
       d="m 455,356.57 c -0.17,1.05 -1,1.33 -1.86,1.87 -1.23,0.76 -2.31,1.86 -3.59,2.51 -1.28,0.65 -4.13,1.19 -5,-0.32 0.45,2 3.78,1.4 5,0.76 1.22,-0.64 2.32,-1.72 3.53,-2.47 0.86,-0.54 1.71,-0.82 1.85,-1.91 a 2.41,2.41 0 0 0 0.07,-0.44 z"
       id="path1467" />
    <path
       class="cls-19"
       d="m 446.81,290.1 c 0.61,-4.73 2.35,-11.6 2.35,-11.6 a 14,14 0 0 0 5.25,1.31 43.54,43.54 0 0 0 7.93,-0.78 47.67,47.67 0 0 0 2.8,4.33 c 1.36,1.89 4,6 3.37,13.29 -0.41,4.73 -3.07,24.84 -3.07,24.84 a 37.47,37.47 0 0 1 1.63,10.43 84,84 0 0 1 -1.66,12.49 l -1.58,11.42 c 0,0 -2.11,1.52 -3.61,0.44 l 0.19,-11.17 c -0.18,-2.73 -0.45,-6.76 -0.63,-9.34 -0.28,-4.19 -1,-10.85 -1.25,-12.52 -0.25,-1.67 -0.75,-4.57 -1,-7.83 -0.25,-3.26 -1.48,-19.8 -1.48,-19.8 l -0.17,3.1 c 0,0 -0.17,5 -0.89,11.24 -0.72,6.24 -1,9 -1,9 a 13.34,13.34 0 0 1 1.42,4 c 0.13,1.34 1.66,12 0.74,17.36 L 454.29,354 a 3.61,3.61 0 0 1 -3.25,0.43 l -1.11,-13.84 c -0.74,-5.27 -2.31,-16.43 -2.55,-17.88 a 59.48,59.48 0 0 1 -0.94,-8.85 c -0.37,-5.99 -0.23,-19.03 0.37,-23.76 z"
       id="path1469" />
    <path
       class="cls-10"
       d="m 462.35,277.29 4.07,8.18 c 0,0 6.22,9.1 -0.22,32.48 l 1.21,7.21 c 0,0 -12.19,7.83 -20.35,0 0,0 -2.83,-21.61 -1.32,-31.57 a 113.26,113.26 0 0 1 3.8,-16.93 c 0,0 2,2.21 12.27,0.75"
       id="path1471" />
    <path
       class="cls-23"
       d="m 469.66,266.05 c 0,0 -2.83,2.82 -6.19,2.47 L 461.86,263 c 0,0 -1,-2.87 1.4,-4.13 2.4,-1.26 4.99,1.56 6.4,7.18 z"
       id="path1473" />
    <path
       class="cls-23"
       d="m 452.83,255.92 c 0,0 -3.24,-1 -6.67,6.19 l 1.28,0.77 a 54.66,54.66 0 0 1 5.39,-6.96 z"
       id="path1475" />
  </g>
  <g
     id="Girl_4">
    <ellipse
       class="cls-6"
       cx="85.389999"
       cy="486.89999"
       rx="22.690001"
       ry="13.1"
       id="ellipse1478" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_33"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-19"
       d="m 98.48,386.23 c 2,0.57 3.12,2.76 4.86,7.45 a 39.25,39.25 0 0 1 2.09,13.22 c -0.56,4.42 -2.39,7.86 -6.81,11.44 l -2.11,-3.87 c 0,0 4.33,-3.82 4.77,-8.24 0.25,-2.48 -2.66,-10.84 -2.66,-11.07 0,-0.23 -0.14,-8.93 -0.14,-8.93 z" />
    <path
       class="cls-27"
       d="m 81.17,488.09 a 4.85,4.85 0 0 1 -4,-0.54 c -1.08,0 -7.43,-2.49 -8.23,-0.38 -0.7,1.85 1.85,3.57 3.2,3.9 3,0.71 5.16,2.19 6.36,2.44 a 3,3 0 0 0 2.74,-0.38 c 0.83,-0.84 0.76,-3.94 -0.07,-5.04 z"
       id="path1481" />
    <path
       class="cls-28"
       d="m 78.48,493 c -1.2,-0.25 -3.39,-1.73 -6.36,-2.45 -1.13,-0.27 -3.1,-1.52 -3.29,-3 -0.27,1.7 2,3.21 3.29,3.52 3,0.71 5.16,2.19 6.36,2.44 a 3,3 0 0 0 2.74,-0.38 1.91,1.91 0 0 0 0.39,-0.71 3.56,3.56 0 0 1 -3.13,0.58 z"
       id="path1483" />
    <path
       class="cls-27"
       d="m 97.29,479.71 a 3.81,3.81 0 0 1 -3.49,-0.53 c -1,0 -7.53,-2.38 -8.3,-0.35 -0.67,1.78 1.78,3.42 3.08,3.74 2.86,0.69 5,2.12 6.12,2.36 a 2.9,2.9 0 0 0 2.64,-0.37 c 0.82,-0.81 0.75,-3.79 -0.05,-4.85 z"
       id="path1485" />
    <path
       class="cls-28"
       d="m 94.7,484.44 c -1.15,-0.25 -3.26,-1.67 -6.12,-2.36 -1.09,-0.27 -3,-1.47 -3.17,-2.9 -0.25,1.64 2,3.1 3.17,3.39 2.86,0.69 5,2.12 6.12,2.36 a 2.9,2.9 0 0 0 2.64,-0.37 1.67,1.67 0 0 0 0.37,-0.69 3.4,3.4 0 0 1 -3.01,0.57 z"
       id="path1487" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_34"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-19"
       d="m 99.42,463.6 a 21.09,21.09 0 0 0 -1.24,-7.15 c 0,0 0.82,-9.79 1.45,-16.22 0.92,-9.48 2.38,-10.42 2,-16.18 -0.38,-5.34 -3.42,-8.8 -4.21,-12.42 l -15.47,1.22 c 0,0 -1.35,4.39 -3.09,13.13 -1.74,8.74 -1.86,19.13 -1.72,32.89 0,3.55 -0.6,6.63 -0.4,15.47 0.14,5.94 0.48,13.22 0.48,13.22 2.26,1.94 3.83,0.51 3.83,0.51 0,0 4,-17.6 4.55,-21.64 a 12.73,12.73 0 0 0 -0.54,-6.68 c 0,0 1.16,-5.53 2,-9.88 1,-5.31 3.65,-16.77 3.65,-16.77 0,0 -0.45,17.61 0.32,21.08 0.77,3.47 0.9,6.49 1.56,11.21 0.79,5.7 1.15,14.05 1.15,14.05 2.36,1.5 3.41,0.35 3.41,0.35 0,0 2.27,-11.2 2.27,-16.19 z" />
    <path
       class="cls-10"
       d="m 97.38,411.63 c 1.62,1.66 4.3,6.71 4.3,14.35 0,8.6 -1.25,6.86 -1.85,16.33 l -0.6,9.47 c 0,0 -12.93,6.17 -22.15,0.45 -0.82,-1.79 0.31,-21.71 1.93,-28.79 1.62,-7.08 2.73,-10.55 2.73,-10.55 0,0 11.89,3.21 15.64,-1.26 z"
       id="path1490" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_35"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-19"
       d="m 97.57,386.14 c -3.3,-0.2 -3.62,0.35 -3.88,-0.82 C 93.6,384.9 93.41,382 93.41,382 a 10.61,10.61 0 0 0 0.83,-1.22 8.37,8.37 0 0 0 4,-6.29 8.47,8.47 0 0 0 -7.54,-9.3 c -4.37,-0.45 -7.59,2.62 -8.45,6.84 -0.46,2.08 -0.94,6.33 0.36,9.74 0.73,1.93 1.41,3.28 3.15,3.21 a 10.47,10.47 0 0 0 1.72,-0.3 16.18,16.18 0 0 1 0.1,2.41 c 0,0.85 0.1,1.27 -1.56,2.29 -1.66,1.02 2.5,3.1 5.21,2.9 2.71,-0.2 5.75,-1.84 6.59,-3.59 0.92,-1.96 1.3,-2.46 -0.25,-2.55 z" />
    <path
       class="cls-23"
       d="m 100,400.75 c 0,0 3.73,-0.84 5.44,-2.5 0,0 -2.22,-7 -3.64,-8.74 C 100.38,387.77 99,399 99,399 Z"
       id="path1493" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_36"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-20"
       d="m 94.29,386.07 c 0.61,0.76 0.68,1.71 -1.67,2.31 a 7.44,7.44 0 0 1 -5.15,-0.4 34.52,34.52 0 0 0 -5.32,2.82 c -2,6.6 -0.39,7.45 -1.23,12.18 0.33,2.38 0.72,8.52 0.82,9.91 4.49,3.14 13.6,2.07 15.64,-1.26 a 27.55,27.55 0 0 1 0.31,-3.31 c 2.14,-7.94 3.81,-10 3.22,-16 -0.34,-3.42 -0.61,-5.14 -2.43,-6.06 a 16.1,16.1 0 0 0 -4.19,-0.19 z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_37"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-19"
       d="m 53.07,411.89 a 23.07,23.07 0 0 1 3,0.86 10,10 0 0 0 2.93,1 c 1.1,0.17 2.82,-0.4 5.79,-1.8 a 32,32 0 0 0 8.7,-6.54 75.44,75.44 0 0 0 7.6,-10.85 c 1.29,-2.35 2.92,-2.94 4.34,-2.48 1.7,0.56 1.91,2.25 0,5.41 a 60.5,60.5 0 0 1 -8.7,11.39 32.63,32.63 0 0 1 -9.07,6.4 27.87,27.87 0 0 1 -7.63,2.65 c -0.93,0.2 -1.56,0.59 -3.28,1.19 a 11.36,11.36 0 0 1 -5.35,0.59 c -1.49,-0.29 -2,-0.63 -2.06,-1 -0.06,-0.37 0.24,-0.63 0.94,-0.58 a 9.18,9.18 0 0 0 3.32,-0.08 c 0,0 -1.54,-0.05 -2.45,-0.16 a 8.86,8.86 0 0 1 -2.38,-0.6 c -0.73,-0.31 -1,-1.46 -0.26,-1.42 0.74,0.04 1.24,0.26 2.6,0.4 a 9,9 0 0 0 2.16,0 16.91,16.91 0 0 1 -2.65,-0.66 3.76,3.76 0 0 1 -1.85,-1.14 c -0.25,-0.29 -0.18,-1 0.69,-0.82 a 13.89,13.89 0 0 0 3.24,0.71 c 1.11,0 1.9,-0.09 1.76,-0.26 -0.14,-0.17 -0.8,-0.15 -1.64,-0.62 -0.84,-0.47 -1.34,-1.38 -1,-1.82 0.34,-0.44 0.34,-0.11 1.25,0.23 z" />
    <path
       class="cls-23"
       d="m 83.64,401.31 a 12,12 0 0 1 -6.84,-3.47 l 4.14,-5.74 c 0,0 2.33,-2.94 5.41,-1.28 0,0 2.32,0.25 0,5.11 a 47.84,47.84 0 0 1 -2.71,5.38 z"
       id="path1497" />
    <path
       class="cls-24"
       d="m 81.45,369.54 a 3.83,3.83 0 0 1 4.32,-3.16 7.31,7.31 0 0 1 4.92,-1.19 c 3.93,0.41 6.5,3 7.69,6.9 a 30.94,30.94 0 0 1 1.16,6 c 1.18,8.75 4.36,15.69 1.39,18.29 -2.97,2.6 -11.11,4.25 -14.51,2.62 -3.4,-1.63 2.8,-16.71 -3.93,-25.09 -1.58,-1.99 -1.73,-3.38 -1.04,-4.37 z"
       id="path1499" />
  </g>
  <g
     id="Men_13">
    <ellipse
       class="cls-6"
       cx="22.690001"
       cy="454.91"
       rx="22.690001"
       ry="13.1"
       id="ellipse1502" />
    <path
       class="cls-18"
       d="m 12,451.62 c 1.55,1.26 3.83,0.11 3.94,0.23 a 72.22,72.22 0 0 0 5.71,4.75 c 1,0.76 2.47,1.77 2.19,3.23 -0.48,2.6 -4.65,1.8 -6.23,1 -1.58,-0.8 -2.86,-2.11 -4.35,-3 -1.06,-0.66 -2.1,-1 -2.27,-2.34 -0.14,-0.85 0.7,-3.9 1.01,-3.87 z"
       id="path1504" />
    <path
       class="cls-21"
       d="m 11,454.91 c 0.21,1.28 1.24,1.64 2.29,2.29 1.52,0.94 2.85,2.3 4.42,3.09 1.57,0.79 5.08,1.47 6.1,-0.39 -0.55,2.51 -4.65,1.72 -6.21,0.93 -1.56,-0.79 -2.86,-2.11 -4.35,-3 -1.06,-0.66 -2.1,-1 -2.27,-2.34 A 3.6,3.6 0 0 1 11,454.91 Z"
       id="path1506" />
    <path
       class="cls-18"
       d="m 25.38,446.63 c 1.55,1.26 4.25,-0.11 4.37,0 a 60,60 0 0 0 5.09,4.61 c 1,0.75 2.47,1.77 2.2,3.23 -0.49,2.6 -4.66,1.8 -6.23,1 -1.57,-0.8 -2.86,-2.12 -4.35,-3 -1.06,-0.66 -2.11,-1 -2.27,-2.34 -0.1,-0.85 0.92,-3.53 1.19,-3.5 z"
       id="path1508" />
    <path
       class="cls-21"
       d="m 24.23,449.73 c 0.21,1.28 1.24,1.64 2.29,2.29 1.52,0.94 2.85,2.3 4.42,3.1 1.57,0.8 5.08,1.46 6.1,-0.4 -0.55,2.51 -4.65,1.73 -6.21,0.94 -1.56,-0.79 -2.85,-2.12 -4.34,-3.05 -1.07,-0.66 -2.11,-1 -2.28,-2.34 a 3.6,3.6 0 0 1 0.02,-0.54 z"
       id="path1510" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_38"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-22"
       d="m 11.87,394.54 c 0.08,2.34 0.8,12.5 1.13,17.87 0.33,5.37 0.4,12 0.4,12 0,0 -0.93,3.91 -1.53,8.52 -0.6,4.61 0,19.13 0,19.13 a 3.67,3.67 0 0 0 4,0 c 0,0 2.48,-11.63 3.62,-16.87 1.14,-5.24 1.35,-8.26 1.94,-11.5 0.72,-3.93 2.27,-22.26 2.27,-22.26 h 0.62 l 1.66,20.69 a 23.16,23.16 0 0 0 -1.05,4.7 c -0.45,3.37 0.48,20.33 0.48,20.33 a 4.1,4.1 0 0 0 4.28,-0.18 c 0,0 4.13,-22.46 4.13,-25.87 0,-2.27 -0.38,-32.07 -0.38,-32.07 z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_39"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-19"
       d="m 17.48,349.35 c 0,0 0.26,5.1 0.15,5.55 -0.11,0.45 -2.34,1.94 -3,2.48 -0.66,0.54 3.53,4.62 5.56,5.62 2.03,1 8.46,-1.52 8.57,-4.68 0.11,-3.16 -1.1,-5.81 -2.08,-5.95 -0.98,-0.14 -9.2,-3.02 -9.2,-3.02 z" />
    <path
       class="cls-19"
       d="m 31.44,358.81 c 0.3,-2.25 -1.18,-4.39 0.25,-6.18 5,4.94 4.4,18 5.54,26.35 3.74,3.9 11.25,7.75 13.36,8.7 0.38,0.18 0.72,0.37 0.64,0.78 a 9.26,9.26 0 0 1 -1.75,3.82 c -5,-2.14 -8.55,-3.37 -14.76,-9.27 a 13.59,13.59 0 0 1 -1.57,-2.07 c -1.77,-5.32 -2.22,-18.25 -1.71,-22.13 z"
       id="path1514" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_40"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-20"
       d="m 16.91,355.78 c 0,0 3.7,5.51 8.86,6 1.63,-1.6 1.77,-7.31 -0.48,-9.14 0,0 2.07,-1.67 3.49,-1.35 a 7.35,7.35 0 0 1 3.22,4.1 33.52,33.52 0 0 1 1.82,11.8 c -0.09,5.41 0,21.94 0,21.94 0,0 -0.72,3.49 -5.39,6.09 -4.67,2.6 -8.14,2.86 -11.31,2.12 -2.61,-0.61 -4.77,-1.53 -5.67,-3.42 0.24,-3.8 1.93,-13.69 1.3,-18.46 -0.63,-4.77 -1.64,-8.32 -1.9,-12.18 -0.26,-3.86 0.5,-3.78 2.44,-5.15 a 29.62,29.62 0 0 1 3.62,-2.35 z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_41"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-19"
       d="m 29,341.75 v 0 c -0.61,-4 -3.46,-7 -7.55,-6.73 a 7.85,7.85 0 0 0 -4,14.33 7.82,7.82 0 0 0 0.63,1.73 c 1.44,1.69 5.81,2.73 7.06,2.55 A 3.74,3.74 0 0 0 28.42,351 c 1.36,-3.14 0.93,-7.3 0.58,-9.25 z" />
    <path
       class="cls-18"
       d="m 17.48,349.35 v 0 l 0.37,-3.46 c 0,0 -2.85,-7.3 3.85,-5.89 4.4,0.93 5.5,1.33 6.84,-1.62 1.34,-2.95 -3.38,-5.61 -9,-4.87 a 7.75,7.75 0 0 0 -6.94,7.86 c 0.16,2.16 0.74,6.56 4.88,7.98 z"
       id="path1518" />
    <path
       class="cls-19"
       d="m 9.67,361 c 1.93,-0.55 0.46,-0.1 1.93,-0.55 5,4.93 4.41,13.39 5.55,21.74 2.78,4.61 13.09,10.81 13.09,10.81 0.13,0.89 -0.18,1.15 -1.3,3 A 44.43,44.43 0 0 1 13.61,386.11 C 13.36,385.88 13,385.81 12.9,385.5 11.13,380.14 9.16,364.89 9.67,361 Z"
       id="path1520" />
    <polygon
       class="cls-20"
       points="55.55,371.31 48.06,396.93 31.61,403.5 37.61,378.54 "
       id="polygon1522" />
    <path
       class="cls-19"
       d="m 27.65,393.21 c 0.24,-0.88 0.87,-0.66 1.59,-0.44 a 4.13,4.13 0 0 0 2.43,0.21 7.52,7.52 0 0 0 1.74,-1.18 2.15,2.15 0 0 1 1.1,-0.31 c 0,0.22 -0.38,1.52 -0.38,1.52 0,0 3.61,0 4,0 a 0.61,0.61 0 0 1 0.57,1 h 0.25 c 0.73,-0.16 1,1 0.31,1.14 l -0.6,0.09 c 0.48,0.19 0.6,1 0,1.1 h -0.19 a 0.78,0.78 0 0 1 -0.26,0 H 38 a 0.63,0.63 0 0 1 -0.54,0.76 c -1.76,0.23 -4.35,0.93 -5.94,-0.52 a 9.88,9.88 0 0 1 -3.19,-0.86 c -0.95,-0.48 -0.98,-1.47 -0.68,-2.51 z"
       id="path1524" />
    <path
       class="cls-19"
       d="m 45.63,391.11 h 0.25 a 0.6,0.6 0 0 1 0.35,-1.09 c 0.37,0 4.08,-0.78 4.08,-0.78 l 0.45,-1.52 c 0,-0.09 0.64,0.3 0.66,0.32 a 2.46,2.46 0 0 1 1.12,1.85 4,4 0 0 1 -1.07,2.87 3.66,3.66 0 0 1 -2.47,1.06 c -0.45,0 -0.88,0.05 -1.27,0.09 a 0.65,0.65 0 0 1 -0.69,-0.64 h -0.12 a 0.47,0.47 0 0 1 -0.26,0 h -0.19 c -0.63,0 -0.68,-0.78 -0.25,-1.06 h -0.61 c -0.8,0.07 -0.73,-1.11 0.02,-1.1 z"
       id="path1526" />
    <path
       class="cls-23"
       d="m 33.54,362.15 a 4,4 0 0 0 2.68,-1.2 c -0.14,-1.9 -2.56,-9.09 -7.44,-9.63 a 9.09,9.09 0 0 1 3,3.68 48.52,48.52 0 0 1 1.76,7.15 z"
       id="path1528" />
    <path
       class="cls-23"
       d="m 8.79,371.65 c 0,0 4.85,1.68 8.27,-1.14 0.38,-0.64 -2,-8.9 -2,-8.9 0,0 -2,-4.22 -5.22,-2.54 -3.22,1.68 -1.05,12.58 -1.05,12.58 z"
       id="path1530" />
  </g>
  <g
     id="Men_12">
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_42"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-19"
       d="m 304.31,86.43 a 39.89,39.89 0 0 1 -5.7,7.75 c -0.62,0.72 -5.35,-1.09 -4.36,-1.6 0.99,-0.51 4.09,-4.84 5.65,-7.72 a 95.18,95.18 0 0 0 3.31,-10.53 c 1,-3.53 1.82,-8.71 2.53,-11.15 a 4.76,4.76 0 0 1 3.63,-3.69 c 1.7,-0.39 2.81,0.07 2.5,2.14 -0.55,3.62 -3.38,17.68 -7.56,24.8 z" />
    <path
       class="cls-27"
       d="m 307,141.53 c -1.46,1.19 -3.63,0.1 -3.74,0.21 a 63.19,63.19 0 0 1 -5.42,4.51 c -0.92,0.72 -2.34,1.69 -2.09,3.07 0.47,2.48 4.43,1.72 5.92,1 1.49,-0.72 2.72,-2 4.13,-2.89 1,-0.63 2,-0.95 2.16,-2.23 0.12,-0.81 -0.68,-3.7 -0.96,-3.67 z"
       id="path1534" />
    <path
       class="cls-28"
       d="m 308,144.65 c -0.19,1.22 -1.17,1.55 -2.17,2.18 -1.44,0.89 -2.71,2.18 -4.2,2.93 -1.49,0.75 -4.83,1.4 -5.8,-0.37 0.53,2.39 4.42,1.64 5.9,0.89 1.48,-0.75 2.72,-2 4.13,-2.89 1,-0.63 2,-0.95 2.16,-2.23 A 1.84,1.84 0 0 0 308,144.65 Z"
       id="path1536" />
    <path
       class="cls-27"
       d="m 292.13,133 c -1.47,1.19 -4,-0.11 -4.15,0 a 58.9,58.9 0 0 1 -4.84,4.37 c -0.92,0.72 -2.35,1.68 -2.09,3.07 0.46,2.47 4.43,1.71 5.92,1 1.49,-0.71 2.72,-2 4.13,-2.89 1,-0.62 2,-0.95 2.16,-2.22 0.1,-0.87 -0.87,-3.41 -1.13,-3.33 z"
       id="path1538" />
    <path
       class="cls-28"
       d="m 293.22,135.89 c -0.2,1.22 -1.18,1.55 -2.18,2.18 -1.44,0.89 -2.7,2.18 -4.2,2.93 -1.5,0.75 -4.82,1.4 -5.79,-0.37 0.52,2.39 4.42,1.64 5.9,0.89 1.48,-0.75 2.71,-2 4.13,-2.89 1,-0.63 2,-0.95 2.16,-2.23 a 3.23,3.23 0 0 0 -0.02,-0.51 z"
       id="path1540" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_43"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-10"
       d="m 326.66,94.45 c 1.63,10.17 -2.89,14 -8.76,16.13 -4.21,1.55 -10.26,3.94 -10.26,3.94 0,0 0.09,2.23 0.13,7.24 0.05,4.41 -0.54,20.52 -0.54,20.52 a 4.9,4.9 0 0 1 -4.49,-0.05 c 0,0 -2.37,-12.34 -2.87,-17.9 -0.68,-7.55 -1.84,-12.49 -1.46,-14.11 0.34,-1.43 8.59,-5.49 11.21,-7.66 l -17.28,5.79 a 30.79,30.79 0 0 1 0.5,5.68 c -0.16,6 -0.49,18.95 -0.49,18.95 0,0 -2.37,1.71 -4.39,0 0,0 -4.35,-25.65 -3.82,-29 0.5,-3.22 15.73,-9.81 18.41,-12.08 a 4.3,4.3 0 0 1 3.38,-0.91 z" />
    <g
       id="_Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ°_5"
       data-name="&lt;Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ°&gt;">
      <g
         id="_Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ°_6"
         data-name="&lt;Ğ“Ñ€ÑƒĞ¿Ğ¿Ğ°&gt;">
        <path
           id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_44"
           data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
           class="cls-20"
           d="M 285.23,98.68 296.84,92 a 0.67,0.67 0 0 1 0.67,0 l 20.36,11.76 -11.94,6.9 z" />
        <path
           class="cls-24"
           d="m 306.47,108.17 0.89,0.51 c 0.07,0 0.06,0.12 0,0.16 l -0.85,0.49 a 0.28,0.28 0 0 1 -0.28,0 l -0.88,-0.51 c -0.08,0 -0.07,-0.11 0,-0.16 l 0.84,-0.49 a 0.31,0.31 0 0 1 0.28,0 z"
           id="path1544" />
        <path
           class="cls-24"
           d="m 305.22,107.45 0.88,0.51 c 0.08,0 0.07,0.11 0,0.16 l -0.84,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.85,-0.49 a 0.31,0.31 0 0 1 0.28,0 z"
           id="path1546" />
        <path
           class="cls-24"
           d="m 304,106.72 0.89,0.51 c 0.07,0 0.06,0.11 0,0.16 l -0.85,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -0.88,-0.51 c -0.08,0 -0.07,-0.12 0,-0.16 l 0.84,-0.49 a 0.28,0.28 0 0 1 0.28,0 z"
           id="path1548" />
        <path
           class="cls-24"
           d="m 302.71,106 0.89,0.51 c 0.07,0 0.06,0.12 0,0.16 l -0.85,0.49 a 0.28,0.28 0 0 1 -0.28,0 l -0.88,-0.51 c -0.07,0 -0.07,-0.11 0,-0.16 l 0.84,-0.49 a 0.31,0.31 0 0 1 0.28,0 z"
           id="path1550" />
        <path
           class="cls-24"
           d="m 301.46,105.28 0.89,0.51 c 0.07,0 0.06,0.11 0,0.16 l -0.85,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.85,-0.49 a 0.31,0.31 0 0 1 0.28,0 z"
           id="path1552" />
        <path
           class="cls-24"
           d="m 300.21,104.55 0.88,0.52 c 0.08,0 0.07,0.11 0,0.16 l -0.84,0.49 a 0.34,0.34 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.12 0,-0.17 l 0.85,-0.48 a 0.31,0.31 0 0 1 0.28,-0.01 z"
           id="path1554" />
        <path
           class="cls-24"
           d="m 299,103.83 0.88,0.51 c 0.07,0 0.06,0.12 0,0.16 L 299,105 a 0.3,0.3 0 0 1 -0.29,0 l -0.88,-0.51 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.84,-0.49 a 0.33,0.33 0 0 1 0.33,-0.01 z"
           id="path1556" />
        <path
           class="cls-24"
           d="m 297.7,103.11 0.89,0.51 c 0.07,0 0.06,0.11 0,0.16 l -0.85,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -0.88,-0.51 c -0.08,0 -0.07,-0.11 0,-0.16 l 0.84,-0.49 a 0.31,0.31 0 0 1 0.28,0 z"
           id="path1558" />
        <path
           class="cls-24"
           d="m 296.45,102.38 0.88,0.52 c 0.08,0 0.07,0.11 0,0.16 l -0.84,0.49 a 0.34,0.34 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.12 0,-0.17 l 0.85,-0.48 a 0.31,0.31 0 0 1 0.28,-0.01 z"
           id="path1560" />
        <path
           class="cls-24"
           d="m 295.2,101.66 0.88,0.51 c 0.07,0 0.07,0.12 0,0.16 l -0.84,0.49 a 0.28,0.28 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.85,-0.49 a 0.31,0.31 0 0 1 0.28,0 z"
           id="path1562" />
        <path
           class="cls-24"
           d="m 293.94,100.94 0.89,0.51 c 0.07,0 0.06,0.11 0,0.16 l -0.85,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -0.88,-0.51 c -0.07,0 -0.07,-0.11 0,-0.16 l 0.84,-0.49 a 0.31,0.31 0 0 1 0.28,0 z"
           id="path1564" />
        <path
           class="cls-24"
           d="m 292.69,100.21 0.89,0.52 c 0.07,0 0.06,0.11 0,0.16 l -0.85,0.49 a 0.34,0.34 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.12 0,-0.17 l 0.84,-0.48 a 0.31,0.31 0 0 1 0.29,-0.01 z"
           id="path1566" />
        <path
           class="cls-24"
           d="m 291.44,99.49 0.88,0.51 c 0.08,0 0.07,0.12 0,0.16 l -0.84,0.49 a 0.28,0.28 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.85,-0.49 a 0.31,0.31 0 0 1 0.28,0 z"
           id="path1568" />
        <path
           class="cls-24"
           d="m 289.58,98.42 1.49,0.86 c 0.07,0 0.06,0.11 0,0.16 l -0.84,0.49 a 0.33,0.33 0 0 1 -0.29,0 l -1.48,-0.86 c -0.08,0 -0.07,-0.11 0,-0.16 l 0.84,-0.49 a 0.31,0.31 0 0 1 0.28,0 z"
           id="path1570" />
        <path
           class="cls-24"
           d="m 305.83,106.4 0.88,0.51 c 0.08,0 0.07,0.11 0,0.16 l -0.84,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.12 0,-0.16 l 0.85,-0.49 a 0.31,0.31 0 0 1 0.28,0 z"
           id="path1572" />
        <path
           class="cls-24"
           d="m 304.57,105.67 0.89,0.51 c 0.07,0 0.06,0.12 0,0.17 l -0.85,0.48 a 0.31,0.31 0 0 1 -0.28,0 l -0.88,-0.52 c -0.08,0 -0.07,-0.11 0,-0.16 l 0.84,-0.49 a 0.34,0.34 0 0 1 0.28,0.01 z"
           id="path1574" />
        <path
           class="cls-24"
           d="m 303.32,105 0.88,0.51 c 0.08,0 0.07,0.11 0,0.16 l -0.84,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.11 0,-0.16 L 303,105 a 0.31,0.31 0 0 1 0.32,0 z"
           id="path1576" />
        <path
           class="cls-24"
           d="m 302.06,104.22 0.89,0.51 c 0.07,0 0.06,0.12 0,0.17 l -0.85,0.48 a 0.31,0.31 0 0 1 -0.28,0 l -0.88,-0.51 c -0.08,0 -0.07,-0.12 0,-0.17 l 0.84,-0.48 a 0.31,0.31 0 0 1 0.28,0 z"
           id="path1578" />
        <path
           class="cls-24"
           d="m 300.82,103.5 0.88,0.52 c 0.08,0 0.07,0.11 0,0.16 l -0.84,0.49 a 0.34,0.34 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.12 0,-0.17 l 0.85,-0.48 a 0.31,0.31 0 0 1 0.28,-0.01 z"
           id="path1580" />
        <path
           class="cls-24"
           d="m 299.56,102.78 0.89,0.51 c 0.07,0 0.06,0.12 0,0.16 l -0.85,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -0.88,-0.51 c -0.08,0 -0.07,-0.11 0,-0.16 l 0.84,-0.49 a 0.31,0.31 0 0 1 0.28,0 z"
           id="path1582" />
        <path
           class="cls-24"
           d="m 298.31,102.06 0.88,0.51 c 0.08,0 0.07,0.11 0,0.16 l -0.84,0.49 a 0.34,0.34 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.12 0,-0.17 l 0.85,-0.48 a 0.28,0.28 0 0 1 0.28,0 z"
           id="path1584" />
        <path
           class="cls-24"
           d="m 297.05,101.33 0.89,0.51 c 0.07,0 0.06,0.12 0,0.16 l -0.85,0.49 a 0.28,0.28 0 0 1 -0.28,0 l -0.88,-0.51 c -0.08,0 -0.07,-0.11 0,-0.16 l 0.84,-0.49 a 0.31,0.31 0 0 1 0.28,0 z"
           id="path1586" />
        <path
           class="cls-24"
           d="m 295.8,100.61 0.88,0.51 c 0.08,0 0.07,0.11 0,0.16 l -0.84,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.12 0,-0.16 l 0.85,-0.49 a 0.28,0.28 0 0 1 0.28,0 z"
           id="path1588" />
        <path
           class="cls-24"
           d="m 294.54,99.88 0.89,0.51 c 0.07,0 0.06,0.12 0,0.17 l -0.85,0.48 a 0.28,0.28 0 0 1 -0.28,0 l -0.88,-0.51 c -0.08,0 -0.07,-0.11 0,-0.16 l 0.84,-0.49 a 0.34,0.34 0 0 1 0.28,0 z"
           id="path1590" />
        <path
           class="cls-24"
           d="m 293.29,99.16 0.88,0.51 c 0.08,0 0.07,0.11 0,0.16 l -0.84,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.12 0,-0.16 l 0.85,-0.49 a 0.31,0.31 0 0 1 0.28,0 z"
           id="path1592" />
        <path
           class="cls-24"
           d="m 292,98.43 0.89,0.51 c 0.07,0 0.06,0.12 0,0.17 l -0.85,0.48 a 0.31,0.31 0 0 1 -0.28,0 l -0.88,-0.52 c -0.08,0 -0.07,-0.11 0,-0.16 l 0.84,-0.49 a 0.34,0.34 0 0 1 0.28,0.01 z"
           id="path1594" />
        <path
           class="cls-24"
           d="m 307.08,107.12 1.49,0.86 c 0.07,0 0.06,0.12 0,0.16 l -0.84,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -1.49,-0.86 c -0.08,0 -0.07,-0.11 0,-0.16 l 0.84,-0.49 a 0.34,0.34 0 0 1 0.28,0 z"
           id="path1596" />
        <path
           class="cls-24"
           d="m 289.64,98.37 0.89,0.51 a 0.24,0.24 0 0 0 0.26,0 l 0.89,-0.51 c 0.08,0 0.08,-0.11 0,-0.15 h -0.07 a 0.08,0.08 0 0 1 0,-0.14 l 0.95,-0.55 a 0.08,0.08 0 0 0 0,-0.15 L 292,97 a 0.29,0.29 0 0 0 -0.27,0 l -0.88,0.5 -0.18,0.11 -0.13,0.08 -0.14,0.07 -0.76,0.44 a 0.085,0.085 0 0 0 0,0.17 z"
           id="path1598" />
        <path
           class="cls-24"
           d="m 311.32,105.36 0.89,0.51 c 0.07,0 0.06,0.12 0,0.17 l -0.85,0.49 a 0.34,0.34 0 0 1 -0.28,0 l -0.88,-0.51 c -0.07,0 -0.07,-0.12 0,-0.17 l 0.84,-0.48 a 0.31,0.31 0 0 1 0.28,-0.01 z"
           id="path1600" />
        <path
           class="cls-24"
           d="m 310.08,104.64 0.88,0.51 c 0.07,0 0.06,0.12 0,0.17 l -0.84,0.48 a 0.33,0.33 0 0 1 -0.29,0 l -0.88,-0.52 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.84,-0.49 a 0.37,0.37 0 0 1 0.29,0.01 z"
           id="path1602" />
        <path
           class="cls-24"
           d="m 308.83,103.92 0.88,0.51 c 0.07,0 0.06,0.12 0,0.16 l -0.84,0.49 a 0.3,0.3 0 0 1 -0.29,0 l -0.88,-0.51 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.84,-0.49 a 0.33,0.33 0 0 1 0.29,0 z"
           id="path1604" />
        <path
           class="cls-24"
           d="m 298.19,97.78 0.88,0.51 c 0.07,0 0.07,0.11 0,0.16 l -0.84,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.85,-0.49 a 0.31,0.31 0 0 1 0.28,0 z"
           id="path1606" />
        <path
           class="cls-24"
           d="m 296.94,97.06 0.88,0.51 c 0.08,0 0.07,0.11 0,0.16 l -0.84,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.85,-0.49 a 0.31,0.31 0 0 1 0.28,0 z"
           id="path1608" />
        <path
           class="cls-24"
           d="m 295.69,96.34 0.88,0.51 c 0.08,0 0.07,0.11 0,0.16 l -0.84,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.12 0,-0.16 l 0.85,-0.49 a 0.28,0.28 0 0 1 0.28,0 z"
           id="path1610" />
        <path
           class="cls-24"
           d="m 294.44,95.62 0.88,0.51 c 0.08,0 0.07,0.11 0,0.16 l -0.84,0.49 a 0.34,0.34 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.12 0,-0.17 l 0.85,-0.48 a 0.28,0.28 0 0 1 0.28,0 z"
           id="path1612" />
        <path
           class="cls-24"
           d="m 307.25,103 1.21,0.7 c 0.07,0 0.06,0.12 0,0.16 l -0.84,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -1.21,-0.69 c -0.07,-0.05 -0.06,-0.12 0,-0.17 L 307,103 a 0.31,0.31 0 0 1 0.25,0 z"
           id="path1614" />
        <path
           class="cls-24"
           d="m 299.44,98.5 1.2,0.7 c 0.08,0 0.07,0.11 0,0.16 l -0.84,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -1.21,-0.7 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.84,-0.49 a 0.33,0.33 0 0 1 0.29,0 z"
           id="path1616" />
        <path
           class="cls-24"
           d="m 301,99.41 5.88,3.39 c 0.07,0 0.06,0.12 0,0.17 l -0.84,0.48 a 0.33,0.33 0 0 1 -0.29,0 l -5.88,-3.4 c -0.07,0 -0.06,-0.12 0,-0.16 l 0.85,-0.49 a 0.31,0.31 0 0 1 0.28,0.01 z"
           id="path1618" />
        <path
           class="cls-24"
           d="m 306.7,105.5 0.89,0.51 c 0.07,0 0.06,0.11 0,0.16 l -0.85,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -0.88,-0.51 c -0.08,0 -0.07,-0.11 0,-0.16 l 0.84,-0.49 a 0.31,0.31 0 0 1 0.28,0 z"
           id="path1620" />
        <path
           class="cls-24"
           d="m 305.45,104.78 0.89,0.51 c 0.07,0 0.06,0.11 0,0.16 l -0.84,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.12 0,-0.16 l 0.85,-0.49 a 0.28,0.28 0 0 1 0.27,0 z"
           id="path1622" />
        <path
           class="cls-24"
           d="m 304.2,104.05 0.88,0.52 c 0.08,0 0.07,0.11 0,0.16 l -0.84,0.49 a 0.34,0.34 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.12 0,-0.17 l 0.85,-0.48 a 0.31,0.31 0 0 1 0.28,-0.01 z"
           id="path1624" />
        <path
           class="cls-24"
           d="m 303,103.33 0.88,0.51 c 0.07,0 0.07,0.12 0,0.17 l -0.84,0.48 a 0.28,0.28 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.85,-0.49 a 0.34,0.34 0 0 1 0.28,0 z"
           id="path1626" />
        <path
           class="cls-24"
           d="m 301.7,102.61 0.88,0.51 c 0.07,0 0.06,0.11 0,0.16 l -0.84,0.49 a 0.33,0.33 0 0 1 -0.29,0 l -0.88,-0.51 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.84,-0.49 a 0.33,0.33 0 0 1 0.29,0 z"
           id="path1628" />
        <path
           class="cls-24"
           d="m 300.44,101.89 0.89,0.51 c 0.07,0 0.06,0.11 0,0.16 l -0.85,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -0.88,-0.51 c -0.07,0 -0.07,-0.12 0,-0.16 l 0.84,-0.49 a 0.28,0.28 0 0 1 0.28,0 z"
           id="path1630" />
        <path
           class="cls-24"
           d="m 299.19,101.16 0.89,0.52 c 0.07,0 0.06,0.11 0,0.16 l -0.85,0.49 a 0.34,0.34 0 0 1 -0.28,0 l -0.88,-0.51 c -0.08,0 -0.07,-0.12 0,-0.17 l 0.84,-0.48 a 0.31,0.31 0 0 1 0.28,-0.01 z"
           id="path1632" />
        <path
           class="cls-24"
           d="m 297.94,100.44 0.89,0.51 c 0.07,0 0.06,0.12 0,0.17 l -0.85,0.48 a 0.28,0.28 0 0 1 -0.28,0 l -0.88,-0.51 c -0.08,0 -0.07,-0.11 0,-0.16 l 0.84,-0.49 a 0.34,0.34 0 0 1 0.28,0 z"
           id="path1634" />
        <path
           class="cls-24"
           d="m 296.69,99.72 0.89,0.51 c 0.07,0 0.06,0.11 0,0.16 l -0.85,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.85,-0.49 a 0.31,0.31 0 0 1 0.28,0 z"
           id="path1636" />
        <path
           class="cls-24"
           d="m 295.44,99 0.88,0.51 c 0.08,0 0.07,0.11 0,0.16 l -0.84,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.12 0,-0.16 L 295.16,99 a 0.28,0.28 0 0 1 0.28,0 z"
           id="path1638" />
        <path
           class="cls-24"
           d="m 294.19,98.27 0.88,0.52 c 0.07,0 0.07,0.11 0,0.16 l -0.84,0.49 a 0.34,0.34 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.12 0,-0.17 l 0.85,-0.48 a 0.31,0.31 0 0 1 0.28,-0.01 z"
           id="path1640" />
        <path
           class="cls-24"
           d="m 292.94,97.55 0.88,0.51 c 0.07,0 0.06,0.12 0,0.17 l -0.84,0.48 a 0.3,0.3 0 0 1 -0.29,0 l -0.88,-0.51 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.84,-0.49 a 0.37,0.37 0 0 1 0.29,0 z"
           id="path1642" />
        <path
           class="cls-24"
           d="m 308,106.22 1.83,1.06 c 0.08,0 0.07,0.11 0,0.16 l -0.84,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -1.83,-1.06 c -0.08,0 -0.07,-0.11 0,-0.16 l 0.84,-0.49 a 0.34,0.34 0 0 1 0.28,0 z"
           id="path1644" />
        <path
           class="cls-24"
           d="m 308.54,105.16 0.88,0.51 c 0.07,0 0.07,0.11 0,0.16 l -0.84,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.12 0,-0.16 l 0.85,-0.49 a 0.31,0.31 0 0 1 0.28,0 z"
           id="path1646" />
        <path
           class="cls-24"
           d="m 307.29,104.43 0.88,0.52 c 0.07,0 0.06,0.11 0,0.16 l -0.84,0.49 a 0.37,0.37 0 0 1 -0.29,0 l -0.88,-0.51 c -0.07,0 -0.06,-0.12 0,-0.17 l 0.84,-0.48 a 0.33,0.33 0 0 1 0.29,-0.01 z"
           id="path1648" />
        <path
           class="cls-24"
           d="m 306,103.71 0.89,0.51 c 0.07,0 0.06,0.12 0,0.17 l -0.85,0.48 a 0.28,0.28 0 0 1 -0.28,0 l -0.88,-0.51 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.84,-0.49 a 0.34,0.34 0 0 1 0.28,0 z"
           id="path1650" />
        <path
           class="cls-24"
           d="m 304.78,103 0.89,0.51 c 0.07,0 0.06,0.12 0,0.16 l -0.85,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -0.88,-0.51 c -0.08,0 -0.07,-0.11 0,-0.16 L 304.5,103 a 0.31,0.31 0 0 1 0.28,0 z"
           id="path1652" />
        <path
           class="cls-24"
           d="m 303.53,102.27 0.89,0.51 c 0.07,0 0.06,0.11 0,0.16 l -0.85,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -0.88,-0.51 c -0.08,0 -0.07,-0.12 0,-0.16 l 0.84,-0.49 a 0.31,0.31 0 0 1 0.28,0 z"
           id="path1654" />
        <path
           class="cls-24"
           d="m 302.28,101.54 0.89,0.52 c 0.07,0 0.06,0.11 0,0.16 l -0.85,0.49 a 0.34,0.34 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.12 0,-0.17 l 0.85,-0.48 a 0.31,0.31 0 0 1 0.28,-0.01 z"
           id="path1656" />
        <path
           class="cls-24"
           d="m 301,100.82 0.88,0.51 c 0.08,0 0.07,0.12 0,0.17 l -0.84,0.48 a 0.31,0.31 0 0 1 -0.28,0 l -0.89,-0.52 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.85,-0.49 a 0.34,0.34 0 0 1 0.28,0.01 z"
           id="path1658" />
        <path
           class="cls-24"
           d="m 299.78,100.1 0.88,0.51 c 0.08,0 0.07,0.12 0,0.16 l -0.84,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.85,-0.49 a 0.31,0.31 0 0 1 0.28,0 z"
           id="path1660" />
        <path
           class="cls-24"
           d="m 298.53,99.38 0.88,0.51 c 0.07,0 0.07,0.11 0,0.16 l -0.84,0.49 a 0.31,0.31 0 0 1 -0.28,0 l -0.89,-0.51 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.85,-0.49 a 0.31,0.31 0 0 1 0.28,0 z"
           id="path1662" />
        <path
           class="cls-24"
           d="m 297.28,98.66 0.88,0.51 c 0.07,0 0.06,0.11 0,0.16 l -0.84,0.49 a 0.37,0.37 0 0 1 -0.29,0 l -0.88,-0.51 c -0.07,0 -0.06,-0.12 0,-0.17 l 0.84,-0.48 a 0.3,0.3 0 0 1 0.29,0 z"
           id="path1664" />
        <path
           class="cls-24"
           d="m 296,97.93 0.88,0.51 c 0.07,0 0.06,0.12 0,0.17 l -0.84,0.48 a 0.33,0.33 0 0 1 -0.29,0 l -0.88,-0.52 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.84,-0.49 a 0.37,0.37 0 0 1 0.29,0.01 z"
           id="path1666" />
        <path
           class="cls-24"
           d="m 293.23,96.32 2.43,1.4 c 0.07,0 0.06,0.12 0,0.16 l -0.85,0.49 a 0.28,0.28 0 0 1 -0.28,0 L 292.08,97 c -0.07,0 -0.06,-0.12 0,-0.16 l 0.84,-0.49 a 0.3,0.3 0 0 1 0.31,-0.03 z"
           id="path1668" />
        <path
           class="cls-24"
           d="m 309.79,105.88 1.21,0.7 c 0.07,0 0.06,0.11 0,0.16 l -0.84,0.49 a 0.34,0.34 0 0 1 -0.28,0 l -1.21,-0.7 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.85,-0.49 a 0.31,0.31 0 0 1 0.27,0 z"
           id="path1670" />
        <path
           class="cls-24"
           d="m 288.33,99.15 17.77,10.25 c 0.07,0 0.06,0.12 0,0.17 l -0.42,0.24 a 0.31,0.31 0 0 1 -0.28,0 L 287.6,99.56 c -0.07,0 -0.06,-0.11 0,-0.16 l 0.42,-0.24 a 0.3,0.3 0 0 1 0.31,-0.01 z"
           id="path1672" />
        <polygon
           id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_45"
           data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
           class="cls-25"
           points="300.36,98.23 303.55,96.39 309.12,99.6 309,99.67 305.93,101.44 300.47,98.29 " />
        <polygon
           id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_46"
           data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
           class="cls-26"
           points="309,99.67 305.93,101.44 300.47,98.29 303.55,96.52 " />
        <path
           id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_47"
           data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
           class="cls-26"
           d="M 317.87,103.74 V 104 a 1.12,1.12 0 0 1 -0.55,1 l -10.83,6.25 a 1.09,1.09 0 0 1 -0.56,0.15 1.15,1.15 0 0 1 -0.56,-0.15 l -19.58,-11.3 a 1.11,1.11 0 0 1 -0.56,-1 v -0.28 l 20.7,12 z" />
        <path
           id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_48"
           data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
           class="cls-20"
           d="m 305.62,110.8 a 1.33,1.33 0 0 1 -1.15,-0.09 L 285,99.46 a 1.33,1.33 0 0 1 -0.65,-0.93 L 282.2,85.8 a 1.5,1.5 0 0 1 0,-0.22 1.33,1.33 0 0 1 0.39,-0.94 l 20.26,11.7 a 1,1 0 0 1 0.48,0.69 z" />
        <path
           id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_49"
           data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
           class="cls-26"
           d="m 305.93,110.64 -0.13,0.07 a 0.76,0.76 0 0 1 -0.18,0.09 L 303.31,97 a 1,1 0 0 0 -0.48,-0.69 l -20.26,-11.7 a 1.05,1.05 0 0 1 0.27,-0.2 l 20.31,11.72 a 1,1 0 0 1 0.47,0.68 z" />
      </g>
    </g>
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_50"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-19"
       d="m 320.65,56.16 c 0,0 -0.25,4.85 -0.14,5.28 0.11,0.43 2.22,1.85 2.84,2.35 0.62,0.5 -3.35,4.42 -5.28,5.31 -1.93,0.89 -8,-1.45 -8.14,-4.45 -0.14,-3 1,-5.52 2,-5.65 1,-0.13 8.72,-2.84 8.72,-2.84 z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_51"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-20"
       d="m 321.19,62.27 c 0,0 -3.51,5.24 -8.42,5.73 -1.54,-1.52 -1.68,-7 0.46,-8.68 0,0 -2,-1.59 -3.32,-1.28 a 6.93,6.93 0 0 0 -3,3.87 31.33,31.33 0 0 0 -1.73,11.21 c 0.08,5.14 0,18.13 0,18.13 a 11,11 0 0 0 5.17,7.43 16,16 0 0 0 11.65,1.61 c 2.48,-0.58 3.4,-2 4.26,-3.77 -0.22,-3.6 -1.65,-11 -1.05,-15.55 0.6,-4.55 1.56,-7.91 1.81,-11.57 0.25,-3.66 -0.49,-3.59 -2.32,-4.89 a 28.56,28.56 0 0 0 -3.51,-2.24 z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_52"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-19"
       d="m 315.55,104 a 28.93,28.93 0 0 1 2.76,-1.58 5.59,5.59 0 0 0 2.35,-1.42 c 0.87,-0.85 2.28,-4 3.28,-7.15 A 32,32 0 0 0 325.13,83 c -0.43,-4.36 -2,-10.47 -2.4,-13 -0.4,-2.53 0.41,-3.52 1.58,-4.44 1.37,-1.09 3.27,-0.61 4.28,2.91 a 68.3,68.3 0 0 1 2.26,14.92 34.15,34.15 0 0 1 -1.71,11 40.2,40.2 0 0 1 -4.2,8.65 c -0.48,0.82 -0.64,1.54 -1.38,3.2 a 11.17,11.17 0 0 1 -3.21,4.27 c -1.24,0.89 -1.82,1 -2.11,0.84 -0.29,-0.16 -0.29,-0.6 0.23,-1.07 a 9.29,9.29 0 0 0 2.2,-2.46 c 0,0 -1.08,1.08 -1.78,1.67 a 9.48,9.48 0 0 1 -2.06,1.31 c -0.72,0.32 -1.72,-0.29 -1.21,-0.78 0.51,-0.49 1,-0.72 2.06,-1.61 a 9.31,9.31 0 0 0 1.46,-1.59 16.94,16.94 0 0 1 -2.29,1.48 3.79,3.79 0 0 1 -2.08,0.56 c -0.38,0 -0.84,-0.54 -0.13,-1.06 a 13.87,13.87 0 0 0 2.73,-1.86 c 0.79,-0.78 1.23,-1.44 1,-1.46 -0.23,-0.02 -0.65,0.48 -1.57,0.77 -0.92,0.29 -1.91,0 -2,-0.48 -0.09,-0.48 -0.11,-0.33 0.75,-0.77 z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_53"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-19"
       d="m 309.69,48.94 v 0 c 0.58,-3.76 3.28,-6.6 7.16,-6.39 a 7.45,7.45 0 0 1 3.8,13.61 8,8 0 0 1 -0.6,1.65 c -1.37,1.6 -5.52,2.59 -6.71,2.42 a 3.56,3.56 0 0 1 -3.09,-2.53 c -1.25,-2.95 -0.88,-6.9 -0.56,-8.76 z" />
    <path
       class="cls-24"
       d="m 320.65,56.16 v 0 l -0.36,-3.28 c 0,0 2.68,-6.94 -3.65,-5.6 -4.18,0.88 -5.23,1.26 -6.5,-1.55 -1.27,-2.81 3.21,-5.32 8.54,-4.62 a 7.36,7.36 0 0 1 6.59,7.47 c -0.14,2.06 -0.69,6.24 -4.62,7.58 z"
       id="path1685" />
    <path
       class="cls-23"
       d="m 331.49,75 c 0,0 -3.46,3.44 -7.55,2.45 -0.58,-0.4 -2,-8.43 -2,-8.43 0,0 0,-4.45 3.41,-4.34 3.41,0.11 6.14,10.32 6.14,10.32 z"
       id="path1687" />
    <path
       class="cls-23"
       d="m 305.39,68.33 a 3.81,3.81 0 0 1 -2.55,-1.15 c 0.14,-1.79 2.44,-8.63 7.07,-9.14 a 8.61,8.61 0 0 0 -2.89,3.5 45.75,45.75 0 0 0 -1.63,6.79 z"
       id="path1689" />
  </g>
  <path
     class="cls-1"
     d="m 425.06,388.31 a 28.43,28.43 0 0 0 -5.1,-3.71 c -13.85,-8 -36.37,-8 -50.21,0 a 27.19,27.19 0 0 0 -5.84,4.44 c -7.61,7.81 -5.66,17.91 5.84,24.55 13.84,8 36.37,8 50.21,0 11.86,-6.85 13.56,-17.38 5.1,-25.28 z M 415.55,411 c -11.41,6.59 -30,6.59 -41.38,0 -8,-4.62 -10.4,-11.28 -7.17,-17.12 a 18.64,18.64 0 0 1 7.17,-6.77 c 11.41,-6.58 30,-6.58 41.38,0 a 18.5,18.5 0 0 1 7.15,6.77 v 0 c 3.24,5.88 0.85,12.53 -7.15,17.12 z"
     id="path1692" />
  <path
     class="cls-29"
     d="m 422.7,393.92 v 0 a 18.5,18.5 0 0 0 -7.15,-6.77 c -11.41,-6.58 -30,-6.58 -41.38,0 a 18.64,18.64 0 0 0 -7.17,6.77 l -3.09,-4.92 -0.56,-0.89 4,-9.55 13.89,-7.72 25.86,0.45 17.57,10.42 c 0,0 0.32,3.3 0.36,6.56 0.07,4.08 -0.33,8.05 -2.33,5.65 z"
     id="path1694" />
  <polygon
     class="cls-1"
     points="359.38,388.15 364.76,397.26 359.37,399 "
     id="polygon1696" />
  <polygon
     class="cls-1"
     points="430.34,388.21 425.6,393.58 430.34,399 "
     id="polygon1698" />
  <ellipse
     class="cls-30"
     cx="395.17999"
     cy="393.57999"
     rx="29.540001"
     ry="17.049999"
     id="ellipse1700" />
  <path
     class="cls-1"
     d="m 362.07,400.83 c 0,0 4.55,17.92 38.48,17 23.55,0 26.56,-20.24 26,-23.12 a 28.24,28.24 0 0 1 -20.81,11.58 c -14.33,1.25 -24.91,1.09 -30.57,-1.65 -5.66,-2.74 -13.09,-9.93 -13.09,-9.93 z"
     id="path1702" />
  <path
     class="cls-3"
     d="m 369.75,403.25 c -13.84,-8 -13.84,-21 0,-29 13.84,-8 36.37,-8 50.21,0 13.84,8 13.84,21 0,29 -13.84,8 -36.37,7.99 -50.21,0 z m 45.79,-26.44 c -11.41,-6.58 -30,-6.59 -41.37,0 -11.37,6.59 -11.41,17.3 0,23.89 11.41,6.59 30,6.59 41.37,0 11.37,-6.59 11.46,-17.3 0,-23.89 z"
     id="path1704" />
  <ellipse
     class="cls-16"
     cx="57.30394"
     cy="539.87817"
     rx="3.9000001"
     ry="6.75"
     transform="rotate(-30)"
     id="ellipse1706" />
  <polygon
     class="cls-1"
     points="373.39,407.78 358.45,416.41 353.84,413.74 368.78,405.12 "
     id="polygon1708" />
  <polygon
     class="cls-29"
     points="373.39,413.1 358.45,421.72 358.45,416.4 373.39,407.77 "
     id="polygon1710" />
  <path
     class="cls-10"
     d="m 361.5,420.18 a 10.56,10.56 0 0 0 -4.77,-8.27 3.38,3.38 0 0 0 -3.33,-0.36 v 0 l -37.18,21.45 6.78,11.64 36.72,-21.2 c 1.09,-0.39 1.78,-1.53 1.78,-3.26 z"
     id="path1712" />
  <ellipse
     class="cls-10"
     cx="57.30394"
     cy="539.87817"
     rx="3.9000001"
     ry="6.75"
     transform="rotate(-30)"
     id="ellipse1714" />
  <g
     id="Men_1">
    <ellipse
       class="cls-6"
       cx="423.92999"
       cy="486.82001"
       rx="22.690001"
       ry="13.1"
       id="ellipse1716" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_54"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-19"
       d="m 439.85,392.73 c 0.24,2.11 2.76,11.21 2.22,14.32 -0.54,3.11 -9.14,8.33 -9.14,8.33 l -1.19,-5.33 4.76,-4.67 -1.29,-8.83 z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_55"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-23"
       d="m 433.2,383.76 a 3.77,3.77 0 0 1 4.79,1.45 c 1.26,2.09 2.57,9.28 2.69,10.5 0,0 -1.77,2.46 -4.43,2.05 z" />
    <path
       class="cls-18"
       d="m 423.38,485.22 a 7.4,7.4 0 0 1 -5.56,-0.68 c -1.34,0 -8.62,-3.07 -9.61,-0.46 -0.86,2.3 2.29,4.42 4,4.82 3.68,0.89 6.39,2.73 7.87,3 1.1,0.23 2.52,0.38 3.4,-0.48 1.02,-1 0.93,-4.84 -0.1,-6.2 z"
       id="path1720" />
    <path
       class="cls-21"
       d="m 420.05,491.3 c -1.48,-0.31 -4.19,-2.14 -7.87,-3 -1.41,-0.34 -3.84,-1.89 -4.09,-3.73 -0.32,2.11 2.52,4 4.09,4.36 3.68,0.89 6.39,2.73 7.87,3 1.1,0.23 2.52,0.38 3.4,-0.48 a 2.22,2.22 0 0 0 0.48,-0.88 4.41,4.41 0 0 1 -3.88,0.73 z"
       id="path1722" />
    <path
       class="cls-18"
       d="m 435.18,479.92 a 7.35,7.35 0 0 1 -5.56,-0.67 c -1.34,0 -8.62,-3.08 -9.61,-0.46 -0.86,2.29 2.29,4.41 4,4.82 3.67,0.89 6.39,2.72 7.87,3 1.1,0.23 2.52,0.38 3.4,-0.48 1.02,-1.01 0.93,-4.85 -0.1,-6.21 z"
       id="path1724" />
    <path
       class="cls-21"
       d="m 431.85,486 c -1.48,-0.31 -4.2,-2.14 -7.87,-3 -1.41,-0.34 -3.84,-1.88 -4.09,-3.72 -0.32,2.11 2.52,4 4.09,4.36 3.67,0.89 6.39,2.72 7.87,3 1.1,0.23 2.52,0.38 3.4,-0.48 a 2.22,2.22 0 0 0 0.48,-0.88 4.38,4.38 0 0 1 -3.88,0.72 z"
       id="path1726" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_56"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-22"
       d="m 435.32,460.15 a 44.45,44.45 0 0 0 -1.67,-8 c 0,0 0.5,-6.88 0.75,-13.4 0.28,-7.4 2.85,-13.91 0.82,-19.81 l -22.82,5.07 c 0,0 1.38,29.5 1.68,33.07 a 66.94,66.94 0 0 0 1,8.28 c 1,5.73 2.73,19.35 2.73,19.35 a 8.52,8.52 0 0 0 5.58,0.62 c 0,0 -0.17,-17.22 -0.33,-21.35 -0.19,-5 -0.34,-4.65 -0.34,-4.65 l 0.76,-12.55 0.49,-6.24 c 0,0 0.63,4.58 1,8.67 0.36,3.57 1.22,6.8 2.18,13.44 0.84,5.76 2.19,17.34 2.19,17.34 2.42,1.4 5.69,0.24 5.69,0.24 0,0 0.97,-15.08 0.29,-20.08 z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_57"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-19"
       d="m 432,383.88 c -1.74,0.09 -3,0.54 -3.25,0 a 24.73,24.73 0 0 1 -0.4,-2.71 c 0.2,-0.51 0.38,-1.05 0.38,-1.05 2.18,-1.34 2.87,-3.7 3.16,-6.45 0.49,-4.7 -2.05,-8.81 -6.75,-9.3 -4.41,-0.46 -7.66,2.65 -8.53,6.91 -0.46,2.1 -1.39,6.07 -0.14,9.53 0.71,1.94 1.61,3.47 2.52,3.77 a 20.09,20.09 0 0 0 2.61,-0.23 v 0 c 0,0 0.23,1.3 0.39,2.14 0.16,0.84 0.1,1.28 -1.57,2.3 -1.67,1.02 2.52,3.14 5.26,2.93 2.74,-0.21 5.81,-1.86 6.66,-3.62 0.93,-1.95 0.84,-4.27 -0.34,-4.22 z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_58"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-20"
       d="m 429.48,384.14 c 0.48,1.2 -0.75,2.67 -4,3.7 -3.25,1.03 -3.56,-0.3 -3.56,-0.3 a 66.49,66.49 0 0 0 -6.35,3.27 c -2,1.37 -2.82,5.34 -3.09,12 -0.3,7.74 -0.33,19.23 -0.07,21.21 0,0 3.66,3.65 8.35,3.27 4.69,-0.38 12.57,-4.53 14.48,-7.74 -0.05,-6.79 -0.85,-7.89 0.25,-11.8 2.52,-9 3.84,-12.62 2.62,-18.57 -1,-4.91 -2.42,-5.52 -4.36,-5.47 a 41.07,41.07 0 0 0 -4.27,0.43 z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_59"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-19"
       d="m 405.1,409.24 c 3.85,1 4.75,-1.45 5.26,-3.46 1.22,-4.86 1.88,-9.25 2.79,-12 1.08,-3.26 2.2,-3.78 3.79,-4.41 1.85,-0.75 3.45,0.82 2.83,5 a 82.82,82.82 0 0 1 -3.52,14.13 c -0.48,1.52 -1.55,4.21 -3.16,5.51 -2,1.6 -5,1.53 -9.5,0.41 -1.92,-0.48 -4,-1.63 -7.69,-3.33 -1,-0.46 -1.74,-0.76 -3.62,-1.64 a 12.94,12.94 0 0 1 -4.82,-3.76 c -1,-1.43 -1.11,-2.1 -0.91,-2.42 0.2,-0.32 0.7,-0.32 1.22,0.28 a 10.72,10.72 0 0 0 2.77,2.56 c 0,0 -1.22,-1.26 -1.87,-2.07 a 10.55,10.55 0 0 1 -1.46,-2.38 c -0.35,-0.83 0.37,-2 0.91,-1.37 0.54,0.63 0.81,1.2 1.8,2.39 a 10.35,10.35 0 0 0 1.78,1.7 19.53,19.53 0 0 1 -1.64,-2.64 4.45,4.45 0 0 1 -0.6,-2.39 c 0,-0.43 0.65,-0.95 1.22,-0.12 a 16.2,16.2 0 0 0 2.07,3.15 c 0.88,0.91 1.62,1.44 1.64,1.18 0.02,-0.26 -0.53,-0.75 -0.84,-1.81 -0.31,-1.06 0,-2.18 0.59,-2.31 0.59,-0.13 0.47,-0.09 0.94,0.91 a 28.49,28.49 0 0 1 1.75,3.17 6.56,6.56 0 0 0 1.58,2.73 c 0.95,0.96 3.04,2.07 6.69,2.99 z" />
    <path
       id="_ĞšĞ¾Ğ½Ñ‚ÑƒÑ€_60"
       data-name="&lt;ĞšĞ¾Ğ½Ñ‚ÑƒÑ€&gt;"
       class="cls-23"
       d="m 418.36,388.69 c -2.57,-0.37 -4.38,0.78 -5.52,4.67 -1.14,3.89 -1.92,7.09 -1.92,7.09 a 7,7 0 0 0 4.3,2.86 c 3.07,0.74 4.18,-0.73 4.18,-0.73 0,0 0.85,-4.08 1.38,-6.85 0.53,-2.77 0.76,-6.57 -2.42,-7.04 z" />
    <path
       class="cls-18"
       d="m 416.75,370.67 c 0,0 -4.05,-6.16 4.74,-7.42 6.34,-0.91 10.41,3.17 10.88,7.59 0.45,4.22 -2.15,8.61 -4,10.35 a 7.68,7.68 0 0 1 -5.48,-0.67 33.14,33.14 0 0 1 -0.12,-3.45 c 0,0 3.06,-6.51 -6.02,-6.4 z"
       id="path1733" />
  </g>
</svg>

```

`jupyter-config/jupyter_notebook_config/jupyter_mcp_server.json`:

```json
{
  "ServerApp": {
    "nbserver_extensions": {
      "jupyter_mcp_server": true
    }
  }
}

```

`jupyter-config/jupyter_server_config.d/jupyter_mcp_server.json`:

```json
{
  "ServerApp": {
    "jpserver_extensions": {
      "jupyter_mcp_server": true
    }
  }
}

```

`jupyter_mcp_server/CLI.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""
Jupyter MCP Server CLI Layer
"""

import click
import httpx
import uvicorn

from jupyter_mcp_server.log import logger
from jupyter_mcp_server.models import DocumentRuntime
from jupyter_mcp_server.config import get_config, set_config
from jupyter_mcp_server.server_context import ServerContext

# Import the server instance and helper functions from server layer
from jupyter_mcp_server.server import (
    mcp,
    __start_kernel,
    __auto_enroll_document,
)

# Shared options decorator to reduce code duplication
def _common_options(f):
    """Decorator that adds common start options to a command."""
    options = [
        click.option(
            "--provider",
            envvar="PROVIDER",
            type=click.Choice(["jupyter", "datalayer"]),
            default="jupyter",
            help="The provider to use for the document and runtime. Defaults to 'jupyter'.",
        ),
        click.option(
            "--jupyterlab",
            envvar="JUPYTERLAB",
            type=click.BOOL,
            default=True,
            help="Enable JupyterLab mode. Defaults to True.",
        ),
        click.option(
            "--runtime-url",
            envvar="RUNTIME_URL",
            type=click.STRING,
            default=None,
            help="The runtime URL to use. For the jupyter provider, this is the Jupyter server URL. For the datalayer provider, this is the Datalayer runtime URL.",
        ),
        click.option(
            "--runtime-id",
            envvar="RUNTIME_ID",
            type=click.STRING,
            default=None,
            help="The kernel ID to use. If not provided, a new kernel should be started.",
        ),
        click.option(
            "--runtime-token",
            envvar="RUNTIME_TOKEN",
            type=click.STRING,
            default=None,
            help="The runtime token to use for authentication with the provider. If not provided, the provider should accept anonymous requests.",
        ),
        click.option(
            "--document-url",
            envvar="DOCUMENT_URL",
            type=click.STRING,
            default=None,
            help="The document URL to use. For the jupyter provider, this is the Jupyter server URL. For the datalayer provider, this is the Datalayer document URL.",
        ),
        click.option(
            "--document-id",
            envvar="DOCUMENT_ID",
            type=click.STRING,
            default=None,
            help="The document id to use. For the jupyter provider, this is the notebook path. For the datalayer provider, this is the notebook path. Optional - if omitted, you can list and select notebooks interactively.",
        ),
        click.option(
            "--document-token",
            envvar="DOCUMENT_TOKEN",
            type=click.STRING,
            default=None,
            help="The document token to use for authentication with the provider. If not provided, the provider should accept anonymous requests.",
        ),
        click.option(
            "--jupyter-url",
            envvar="JUPYTER_URL",
            type=click.STRING,
            default=None,
            help="The Jupyter URL to use as default for both document and runtime URLs. If not provided, individual URL settings take precedence.",
        ),
        click.option(
            "--jupyter-token",
            envvar="JUPYTER_TOKEN",
            type=click.STRING,
            default=None,
            help="The Jupyter token to use as default for both document and runtime tokens. If not provided, individual token settings take precedence.",
        ),
        click.option(
            "--allowed-jupyter-mcp-tools",
            envvar="ALLOWED_JUPYTER_MCP_TOOLS",
            type=click.STRING,
            default="notebook_run-all-cells,notebook_get-selected-cell",
            help="Comma-separated list of jupyter-mcp-tools to enable. Defaults to 'notebook_run-all-cells,notebook_get-selected-cell' - Only applicable when run as jupyter server extension.",
        )
    ]
    # Apply decorators in reverse order
    for option in reversed(options):
        f = option(f)
    return f


def _resolve_url_and_token_variables(
    jupyter_url, jupyter_token,
    document_url, document_token,
    runtime_url, runtime_token,
) -> tuple[str, str | None, str, str | None]:
    """Resolve URL and token variables based on priority logic.

    Priority order:
    1. Individual URL/token variables take precedence if set
    2. JUPYTER_URL/JUPYTER_TOKEN used as fallback if individual variables are None
    3. Keep original default values if neither individual nor merged variables are set

    Args:
        jupyter_url: The merged Jupyter URL variable
        jupyter_token: The merged Jupyter token variable
        document_url: The individual document URL (takes precedence if set)
        document_token: The individual document token (takes precedence if set)
        runtime_url: The individual runtime URL (takes precedence if set)
        runtime_token: The individual runtime token (takes precedence if set)

    Returns:
        Tuple of (resolved_document_url, resolved_document_token, resolved_runtime_url, resolved_runtime_token)
    """

    # Resolve document_url
    if document_url is not None:
        resolved_document_url = document_url
    elif jupyter_url is not None:
        resolved_document_url = jupyter_url
    else:
        resolved_document_url = "http://localhost:8888"

    # Resolve runtime_url
    if runtime_url is not None:
        resolved_runtime_url = runtime_url
    elif jupyter_url is not None:
        resolved_runtime_url = jupyter_url
    else:
        resolved_runtime_url = "http://localhost:8888"

    # Resolve document_token
    resolved_document_token = document_token or jupyter_token

    # Resolve runtime_token
    resolved_runtime_token = runtime_token or jupyter_token

    return resolved_document_url, resolved_document_token, resolved_runtime_url, resolved_runtime_token


def _do_start(
    transport: str,
    start_new_runtime: bool,
    runtime_url: str,
    runtime_id: str,
    runtime_token: str,
    document_url: str,
    document_id: str,
    document_token: str,
    port: int,
    provider: str,
    jupyterlab: bool,
    allowed_jupyter_mcp_tools: str,
):
    """Internal function to execute the start logic."""

    # Log the received configuration for diagnostics
    # Note: set_config() will automatically normalize string "None" values
    logger.info(
        f"Start command received - runtime_url: {repr(runtime_url)}, "
        f"document_url: {repr(document_url)}, provider: {provider}, "
        f"transport: {transport}"
    )

    # Set configuration using the singleton
    # String "None" values will be automatically normalized by set_config()
    config = set_config(
        transport=transport,
        provider=provider,
        runtime_url=runtime_url,
        start_new_runtime=start_new_runtime,
        runtime_id=runtime_id,
        runtime_token=runtime_token,
        document_url=document_url,
        document_id=document_id,
        document_token=document_token,
        port=port,
        jupyterlab=jupyterlab,
        allowed_jupyter_mcp_tools=allowed_jupyter_mcp_tools
    )

    # Reset ServerContext to pick up new configuration
    ServerContext.reset()
    
    # Also update the jupyter_extension ServerContext with the jupyterlab flag
    # This is critical for MCP_SERVER mode to propagate the config properly
    try:
        from jupyter_mcp_server.jupyter_extension.context import get_server_context
        extension_context = get_server_context()
        extension_context.update(
            context_type="MCP_SERVER",
            serverapp=None,
            document_url=config.document_url,
            runtime_url=config.runtime_url,
            jupyterlab=config.jupyterlab
        )
        logger.info(f"Updated jupyter_extension ServerContext with jupyterlab={config.jupyterlab}")
    except Exception as e:
        logger.warning(f"Failed to update jupyter_extension ServerContext: {e}")

    # Determine startup behavior based on configuration
    if config.document_id:
        # If document_id is provided, auto-enroll the notebook
        # Kernel creation depends on start_new_runtime and runtime_id flags
        try:
            import asyncio
            # Run the async enrollment in the event loop
            asyncio.run(__auto_enroll_document())
        except Exception as e:
            logger.error(f"Failed to auto-enroll document '{config.document_id}': {e}")
            # Fallback to legacy kernel-only mode if enrollment fails
            if config.start_new_runtime or config.runtime_id:
                try:
                    __start_kernel()
                except Exception as e2:
                    logger.error(f"Failed to start kernel on startup: {e2}")
    elif config.start_new_runtime or config.runtime_id:
        # If no document_id but start_new_runtime/runtime_id is set, just create kernel
        # This is for backward compatibility - kernel without managed notebook
        try:
            __start_kernel()
        except Exception as e:
            logger.error(f"Failed to start kernel on startup: {e}")
    # else: No startup action - user must manually enroll notebooks or create kernels

    logger.info(f"Starting Jupyter MCP Server with transport: {transport}")

    if transport == "stdio":
        mcp.run(transport="stdio")
    elif transport == "streamable-http":
        uvicorn.run(mcp.streamable_http_app, host="0.0.0.0", port=port)  # noqa: S104
    else:
        raise Exception("Transport should be `stdio` or `streamable-http`.")


@click.group(invoke_without_command=True)
@_common_options
@click.option(
    "--transport",
    envvar="TRANSPORT",
    type=click.Choice(["stdio", "streamable-http"]),
    default="stdio",
    help="The transport to use for the MCP server. Defaults to 'stdio'.",
)
@click.option(
    "--start-new-runtime",
    envvar="START_NEW_RUNTIME",
    type=click.BOOL,
    default=True,
    help="Start a new runtime or use an existing one.",
)
@click.option(
    "--port",
    envvar="PORT",
    type=click.INT,
    default=4040,
    help="The port to use for the Streamable HTTP transport. Ignored for stdio transport.",
)
@click.pass_context
def server(
    ctx,
    transport: str,
    start_new_runtime: bool,
    runtime_url: str,
    runtime_id: str,
    runtime_token: str,
    document_url: str,
    document_id: str,
    document_token: str,
    jupyter_url: str,
    jupyter_token: str,
    port: int,
    provider: str,
    jupyterlab: bool,
    allowed_jupyter_mcp_tools: str,
):
    """Manages Jupyter MCP Server.

    When invoked without subcommands, starts the MCP server directly.
    This allows for quick startup with: uvx jupyter-mcp-server

    Subcommands (start, connect, stop) are still available for advanced use cases.
    """
    # If a subcommand is invoked, let it handle the execution
    if ctx.invoked_subcommand is not None:
        return

    # No subcommand provided - execute the default start behavior
    # Resolve URL and token variables based on priority logic
    resolved_document_url, resolved_document_token, resolved_runtime_url, resolved_runtime_token = _resolve_url_and_token_variables(
        jupyter_url=jupyter_url,
        jupyter_token=jupyter_token,
        document_url=document_url,
        document_token=document_token,
        runtime_url=runtime_url,
        runtime_token=runtime_token,
    )

    _do_start(
        transport=transport,
        start_new_runtime=start_new_runtime,
        runtime_url=resolved_runtime_url,
        runtime_id=runtime_id,
        runtime_token=resolved_runtime_token,
        document_url=resolved_document_url,
        document_id=document_id,
        document_token=resolved_document_token,
        port=port,
        provider=provider,
        jupyterlab=jupyterlab,
        allowed_jupyter_mcp_tools=allowed_jupyter_mcp_tools,
    )


@server.command("connect")
@_common_options
@click.option(
    "--jupyter-mcp-server-url",
    envvar="JUPYTER_MCP_SERVER_URL",
    type=click.STRING,
    default="http://localhost:4040",
    help="The URL of the Jupyter MCP Server to connect to. Defaults to 'http://localhost:4040'.",
)
def connect_command(
    jupyter_mcp_server_url: str,
    runtime_url: str,
    runtime_id: str,
    runtime_token: str,
    document_url: str,
    document_id: str,
    document_token: str,
    provider: str,
    jupyterlab: bool,
):
    """Command to connect a Jupyter MCP Server to a document and a runtime."""

    # Set configuration using the singleton
    config = set_config(
        provider=provider,
        runtime_url=runtime_url,
        runtime_id=runtime_id,
        runtime_token=runtime_token,
        document_url=document_url,
        document_id=document_id,
        document_token=document_token,
        jupyterlab=jupyterlab
    )
    
    # Also update the jupyter_extension ServerContext with the jupyterlab flag
    # This is critical for MCP_SERVER mode to propagate the config properly
    try:
        from jupyter_mcp_server.jupyter_extension.context import get_server_context
        extension_context = get_server_context()
        extension_context.update(
            context_type="MCP_SERVER",
            serverapp=None,
            document_url=config.document_url,
            runtime_url=config.runtime_url,
            jupyterlab=config.jupyterlab
        )
        logger.info(f"Updated jupyter_extension ServerContext with jupyterlab={config.jupyterlab}")
    except Exception as e:
        logger.warning(f"Failed to update jupyter_extension ServerContext: {e}")

    config = get_config()

    document_runtime = DocumentRuntime(
        provider=config.provider,
        runtime_url=config.runtime_url,
        runtime_id=config.runtime_id,
        runtime_token=config.runtime_token,
        document_url=config.document_url,
        document_id=config.document_id,
        document_token=config.document_token,
    )

    r = httpx.put(
        f"{jupyter_mcp_server_url}/api/connect",
        headers={
            "Content-Type": "application/json",
            "Accept": "application/json",
        },
        content=document_runtime.model_dump_json(),
    )
    r.raise_for_status()


@server.command("stop")
@click.option(
    "--jupyter-mcp-server-url",
    envvar="JUPYTER_MCP_SERVER_URL",
    type=click.STRING,
    default="http://localhost:4040",
    help="The URL of the Jupyter MCP Server to stop. Defaults to 'http://localhost:4040'.",
)
def stop_command(jupyter_mcp_server_url: str):
    r = httpx.delete(
        f"{jupyter_mcp_server_url}/api/stop",
    )
    r.raise_for_status()


@server.command("start")
@_common_options
@click.option(
    "--transport",
    envvar="TRANSPORT",
    type=click.Choice(["stdio", "streamable-http"]),
    default="stdio",
    help="The transport to use for the MCP server. Defaults to 'stdio'.",
)
@click.option(
    "--start-new-runtime",
    envvar="START_NEW_RUNTIME",
    type=click.BOOL,
    default=True,
    help="Start a new runtime or use an existing one.",
)
@click.option(
    "--port",
    envvar="PORT",
    type=click.INT,
    default=4040,
    help="The port to use for the Streamable HTTP transport. Ignored for stdio transport.",
)
def start_command(
    transport: str,
    start_new_runtime: bool,
    runtime_url: str,
    runtime_id: str,
    runtime_token: str,
    document_url: str,
    document_id: str,
    document_token: str,
    jupyter_url: str,
    jupyter_token: str,
    port: int,
    provider: str,
    jupyterlab: bool,
    allowed_jupyter_mcp_tools: str,
):
    """Start the Jupyter MCP server with a transport."""
    # Resolve URL and token variables based on priority logic
    resolved_document_url, resolved_document_token, resolved_runtime_url, resolved_runtime_token = _resolve_url_and_token_variables(
        jupyter_url=jupyter_url,
        jupyter_token=jupyter_token,
        document_url=document_url,
        document_token=document_token,
        runtime_url=runtime_url,
        runtime_token=runtime_token,
    )

    _do_start(
        transport=transport,
        start_new_runtime=start_new_runtime,
        runtime_url=resolved_runtime_url,
        runtime_id=runtime_id,
        runtime_token=resolved_runtime_token,
        document_url=resolved_document_url,
        document_id=document_id,
        document_token=resolved_document_token,
        port=port,
        provider=provider,
        jupyterlab=jupyterlab,
        allowed_jupyter_mcp_tools=allowed_jupyter_mcp_tools,
    )


if __name__ == "__main__":
    """Start the Jupyter MCP Server."""
    server()

```

`jupyter_mcp_server/__init__.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""Jupyter MCP Server."""

from jupyter_mcp_server.__version__ import __version__
from jupyter_mcp_server.jupyter_extension.extension import _jupyter_server_extension_points


__all__ = [
    "__version__",
    "_jupyter_server_extension_points",
]

```

`jupyter_mcp_server/__main__.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""
Entry point for running jupyter_mcp_server as a module.

This allows the package to be run with: python -m jupyter_mcp_server
"""

from jupyter_mcp_server.CLI import server

if __name__ == "__main__":
    server()


```

`jupyter_mcp_server/__version__.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""Jupyter MCP Server."""

__version__ = "0.22.1"

```

`jupyter_mcp_server/config.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

import os
from typing import Optional
from pydantic import BaseModel, Field


class JupyterMCPConfig(BaseModel):
    """Singleton configuration object for Jupyter MCP Server."""
    
    # Transport configuration
    transport: str = Field(default="stdio", description="The transport to use for the MCP server")
    
    # Provider configuration  
    provider: str = Field(default="jupyter", description="The provider to use for the document and runtime")
    
    # Runtime configuration
    runtime_url: str = Field(default="http://localhost:8888", description="The runtime URL to use, or 'local' for direct serverapp access")
    start_new_runtime: bool = Field(default=False, description="Start a new runtime or use an existing one")
    runtime_id: Optional[str] = Field(default=None, description="The kernel ID to use")
    runtime_token: Optional[str] = Field(default=None, description="The runtime token to use for authentication")
    
    # Document configuration
    document_url: str = Field(default="http://localhost:8888", description="The document URL to use, or 'local' for direct serverapp access")
    document_id: Optional[str] = Field(default=None, description="The document id to use. Optional - if omitted, can list and select notebooks interactively")
    document_token: Optional[str] = Field(default=None, description="The document token to use for authentication")
    
    # Server configuration
    port: int = Field(default=4040, description="The port to use for the Streamable HTTP transport")
    jupyterlab: bool = Field(default=True, description="Enable JupyterLab mode (defaults to True)")
    allowed_jupyter_mcp_tools: str = Field(default="notebook_run-all-cells,notebook_get-selected-cell", description="Comma-separated list of jupyter-mcp-tools to enable")
    
    class Config:
        """Pydantic configuration."""
        validate_assignment = True
        arbitrary_types_allowed = True
    
    def is_local_document(self) -> bool:
        """Check if document URL is set to local."""
        return self.document_url == "local"
    
    def is_local_runtime(self) -> bool:
        """Check if runtime URL is set to local."""
        return self.runtime_url == "local"
    
    def is_jupyterlab_mode(self) -> bool:
        """Check if JupyterLab mode is enabled."""
        return self.jupyterlab
    
    def get_allowed_jupyter_mcp_tools(self) -> list[str]:
        """Get allowed jupyter mcp tools as a list."""
        if not self.allowed_jupyter_mcp_tools:
            return []
        return [tool.strip() for tool in self.allowed_jupyter_mcp_tools.split(",") if tool.strip()]

def _get_env_bool(env_name: str, default_value: bool = True) -> bool:
    """
    Get boolean value from environment variable, supporting multiple formats.
    
    Args:
        env_name: Environment variable name
        default_value: Default value
        
    Returns:
        bool: Boolean value
    """
    env_value = os.getenv(env_name)
    if env_value is None:
        return default_value
    
    # Supported true value formats
    true_values = {'true', '1', 'yes', 'on', 'enable', 'enabled'}
    # Supported false value formats  
    false_values = {'false', '0', 'no', 'off', 'disable', 'disabled'}
    
    env_value_lower = env_value.lower().strip()
    
    if env_value_lower in true_values:
        return True
    elif env_value_lower in false_values:
        return False
    else:
        return default_value

# Singleton instance
_config_instance: Optional[JupyterMCPConfig] = None
# Multimodal Output Configuration
# Environment variable controls whether to return actual image content or text placeholder
ALLOW_IMG_OUTPUT: bool = _get_env_bool("ALLOW_IMG_OUTPUT", True)

def get_config() -> JupyterMCPConfig:
    """Get the singleton configuration instance."""
    global _config_instance
    if _config_instance is None:
        _config_instance = JupyterMCPConfig()
    return _config_instance


def set_config(**kwargs) -> JupyterMCPConfig:
    """Set configuration values and return the config instance.
    
    Automatically handles string representations of None by removing them from kwargs,
    allowing defaults to be used instead. This handles cases where environment variables
    or MCP clients pass "None" as a string.
    """
    def should_skip(value):
        """Check if value is a string representation of None that should be skipped."""
        return isinstance(value, str) and value.lower() in ("none", "null", "")
    
    # Filter out string "None" values and let defaults be used instead
    # For optional fields (tokens, runtime_id, document_id), convert to actual None
    normalized_kwargs = {}
    for key, value in kwargs.items():
        if should_skip(value):
            # For optional fields, set to None; for required fields, skip (use default)
            if key in ("runtime_token", "document_token", "runtime_id", "document_id"):
                normalized_kwargs[key] = None
            # For required string fields like runtime_url, document_url, skip the key
            # to let the default value be used
            # Do nothing - skip this key
        else:
            normalized_kwargs[key] = value
    
    global _config_instance
    if _config_instance is None:
        _config_instance = JupyterMCPConfig(**normalized_kwargs)
    else:
        for key, value in normalized_kwargs.items():
            if hasattr(_config_instance, key):
                setattr(_config_instance, key, value)
    return _config_instance


def reset_config() -> JupyterMCPConfig:
    """Reset configuration to defaults."""
    global _config_instance
    _config_instance = JupyterMCPConfig()
    return _config_instance

```

`jupyter_mcp_server/enroll.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""Auto-enrollment functionality for Jupyter MCP Server."""

import logging
from typing import Any

from jupyter_mcp_server.notebook_manager import NotebookManager
from jupyter_mcp_server.tools.use_notebook_tool import UseNotebookTool

logger = logging.getLogger(__name__)


async def auto_enroll_document(
    config: Any,
    notebook_manager: NotebookManager,
    use_notebook_tool: UseNotebookTool,
    server_context: Any,
) -> None:
    """Automatically enroll the configured document_id as a managed notebook.
    
    Handles kernel creation/connection based on configuration:
    - If runtime_id is provided: Connect to that specific kernel
    - If start_new_runtime is True: Create a new kernel
    - If both are False/None: Enroll notebook WITHOUT kernel (notebook-only mode)
    
    Args:
        config: JupyterMCPConfig instance with configuration parameters
        notebook_manager: NotebookManager instance for managing notebooks
        use_notebook_tool: UseNotebookTool instance for enrolling notebooks
        server_context: ServerContext instance with server state
    """
    # Check if document_id is configured and not already managed
    if not config.document_id:
        logger.debug("No document_id configured, skipping auto-enrollment")
        return
        
    if "default" in notebook_manager:
        logger.debug("Default notebook already enrolled, skipping auto-enrollment")
        return
    
    # Check if we should skip kernel creation entirely
    if not config.runtime_id and not config.start_new_runtime:
        # Enroll notebook without kernel - just register the notebook path
        try:
            logger.info(f"Auto-enrolling document '{config.document_id}' without kernel (notebook-only mode)")
            # Add notebook to manager without kernel
            notebook_manager.add_notebook(
                "default",
                None,  # No kernel
                server_url=config.document_url,
                token=config.document_token,
                path=config.document_id
            )
            notebook_manager.set_current_notebook("default")
            logger.info(f"Auto-enrollment result: Successfully enrolled notebook 'default' at path '{config.document_id}' without kernel.")
            return
        except Exception as e:
            logger.warning(f"Failed to auto-enroll document without kernel: {e}")
            return
    
    # Otherwise, enroll with kernel
    try:
        # Determine kernel_id based on configuration
        kernel_id_to_use = None
        if config.runtime_id:
            # User explicitly provided a kernel ID to connect to
            kernel_id_to_use = config.runtime_id
            logger.info(f"Auto-enrolling document '{config.document_id}' with existing kernel '{kernel_id_to_use}'")
        elif config.start_new_runtime:
            # User wants a new kernel created
            kernel_id_to_use = None  # Will trigger new kernel creation in use_notebook_tool
            logger.info(f"Auto-enrolling document '{config.document_id}' with new kernel")
        
        # Use the use_notebook_tool to properly enroll the notebook with kernel
        result = await use_notebook_tool.execute(
            mode=server_context.mode,
            server_client=server_context.server_client,
            notebook_name="default",
            notebook_path=config.document_id,
            use_mode="connect",
            kernel_id=kernel_id_to_use,
            contents_manager=server_context.contents_manager,
            kernel_manager=server_context.kernel_manager,
            session_manager=server_context.session_manager,
            notebook_manager=notebook_manager,
            runtime_url=config.runtime_url if config.runtime_url != "local" else None,
            runtime_token=config.runtime_token,
        )
        logger.info(f"Auto-enrollment result: {result}")
    except Exception as e:
        logger.warning(f"Failed to auto-enroll document: {e}. You can manually use it with use_notebook tool.")

```

`jupyter_mcp_server/jupyter_extension/__init__.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""
Jupyter to MCP Adapter Package

This package provides the adapter layer to expose MCP server tools as a Jupyter Server extension.
It supports dual-mode operation: standalone MCP server and embedded Jupyter server extension.
"""

from jupyter_mcp_server.jupyter_extension.context import ServerContext, get_server_context

__all__ = ["ServerContext", "get_server_context"]

```

`jupyter_mcp_server/jupyter_extension/backends/__init__.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""Backend implementations for notebook and kernel operations"""

```

`jupyter_mcp_server/jupyter_extension/backends/base.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""
Abstract Backend Interface

Defines the contract for all backend implementations (Remote and Local).
"""

from abc import ABC, abstractmethod
from typing import Optional, Any, Union, Literal
from mcp.types import ImageContent


class Backend(ABC):
    """
    Abstract backend for notebook and kernel operations.
    
    Implementations:
    - RemoteBackend: Uses jupyter_nbmodel_client, jupyter_kernel_client, jupyter_server_client
    - LocalBackend: Uses local serverapp.contents_manager and serverapp.kernel_manager
    """
    
    # Notebook operations
    
    @abstractmethod
    async def get_notebook_content(self, path: str) -> dict[str, Any]:
        """
        Retrieve notebook content.
        
        Args:
            path: Path to the notebook file
            
        Returns:
            Dictionary with notebook content (cells, metadata)
        """
        pass
    
    @abstractmethod
    async def list_notebooks(self, path: str = "") -> list[str]:
        """
        List all notebooks in a directory.
        
        Args:
            path: Directory path (empty string for root)
            
        Returns:
            List of notebook paths
        """
        pass
    
    @abstractmethod
    async def notebook_exists(self, path: str) -> bool:
        """
        Check if a notebook exists.
        
        Args:
            path: Path to the notebook file
            
        Returns:
            True if notebook exists
        """
        pass
    
    @abstractmethod
    async def create_notebook(self, path: str) -> dict[str, Any]:
        """
        Create a new notebook.
        
        Args:
            path: Path for the new notebook
            
        Returns:
            Created notebook content
        """
        pass
    
    # Cell operations (via notebook connection)
    
    @abstractmethod
    async def read_cells(
        self, 
        path: str, 
        start_index: Optional[int] = None,
        end_index: Optional[int] = None
    ) -> list[dict[str, Any]]:
        """
        Read cells from a notebook.
        
        Args:
            path: Notebook path
            start_index: Start cell index (None for all)
            end_index: End cell index (None for all)
            
        Returns:
            List of cell dictionaries
        """
        pass
    
    @abstractmethod
    async def append_cell(
        self, 
        path: str, 
        cell_type: Literal["code", "markdown"],
        source: Union[str, list[str]]
    ) -> int:
        """
        Append a cell to notebook.
        
        Args:
            path: Notebook path
            cell_type: Type of cell
            source: Cell source code/markdown
            
        Returns:
            Index of appended cell
        """
        pass
    
    @abstractmethod
    async def insert_cell(
        self,
        path: str,
        cell_index: int,
        cell_type: Literal["code", "markdown"],
        source: Union[str, list[str]]
    ) -> int:
        """
        Insert a cell at specific index.
        
        Args:
            path: Notebook path
            cell_index: Where to insert
            cell_type: Type of cell
            source: Cell source
            
        Returns:
            Index of inserted cell
        """
        pass
    
    @abstractmethod
    async def delete_cell(self, path: str, cell_index: int) -> None:
        """
        Delete a cell from notebook.
        
        Args:
            path: Notebook path
            cell_index: Index of cell to delete
        """
        pass
    
    @abstractmethod
    async def overwrite_cell(
        self,
        path: str,
        cell_index: int,
        new_source: Union[str, list[str]]
    ) -> tuple[str, str]:
        """
        Overwrite cell content.
        
        Args:
            path: Notebook path
            cell_index: Index of cell to overwrite
            new_source: New source content
            
        Returns:
            Tuple of (old_source, new_source) for diff generation
        """
        pass
    
    # Kernel operations
    
    @abstractmethod
    async def get_or_create_kernel(self, path: str, kernel_id: Optional[str] = None) -> str:
        """
        Get existing kernel or create new one for a notebook.
        
        Args:
            path: Notebook path
            kernel_id: Specific kernel ID (None to create new)
            
        Returns:
            Kernel ID
        """
        pass
    
    @abstractmethod
    async def execute_cell(
        self,
        path: str,
        cell_index: int,
        kernel_id: str,
        timeout_seconds: int = 300
    ) -> list[Union[str, ImageContent]]:
        """
        Execute a cell and return outputs.
        
        Args:
            path: Notebook path
            cell_index: Index of cell to execute
            kernel_id: Kernel to use
            timeout_seconds: Execution timeout
            
        Returns:
            List of cell outputs
        """
        pass
    
    @abstractmethod
    async def interrupt_kernel(self, kernel_id: str) -> None:
        """
        Interrupt a running kernel.
        
        Args:
            kernel_id: Kernel to interrupt
        """
        pass
    
    @abstractmethod
    async def restart_kernel(self, kernel_id: str) -> None:
        """
        Restart a kernel.
        
        Args:
            kernel_id: Kernel to restart
        """
        pass
    
    @abstractmethod
    async def shutdown_kernel(self, kernel_id: str) -> None:
        """
        Shutdown a kernel.
        
        Args:
            kernel_id: Kernel to shutdown
        """
        pass
    
    @abstractmethod
    async def list_kernels(self) -> list[dict[str, Any]]:
        """
        List all running kernels.
        
        Returns:
            List of kernel information dictionaries
        """
        pass
    
    @abstractmethod
    async def kernel_exists(self, kernel_id: str) -> bool:
        """
        Check if a kernel exists.
        
        Args:
            kernel_id: Kernel ID to check
            
        Returns:
            True if kernel exists
        """
        pass

```

`jupyter_mcp_server/jupyter_extension/backends/local_backend.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""
Local Backend Implementation

This backend uses the Jupyter Server's local API directly when running as an extension.
It provides efficient local access to contents_manager and kernel_manager.
"""

from typing import Optional, Any, Union, Literal, TYPE_CHECKING
import asyncio
from mcp.types import ImageContent
from jupyter_mcp_server.jupyter_extension.backends.base import Backend
from jupyter_mcp_server.utils import safe_extract_outputs

if TYPE_CHECKING:
    from jupyter_server.serverapp import ServerApp


class LocalBackend(Backend):
    """
    Backend that uses local Jupyter Server API directly.
    
    Uses:
    - serverapp.contents_manager for notebook file operations
    - serverapp.kernel_manager for kernel management
    - serverapp.kernel_spec_manager for kernel specs
    
    This backend is only available when running as a Jupyter Server extension
    with document_url="local" or runtime_url="local".
    """
    
    def __init__(self, serverapp: 'ServerApp'):
        """
        Initialize local backend with direct serverapp access.
        
        Args:
            serverapp: Jupyter ServerApp instance
        """
        self.serverapp = serverapp
        self.contents_manager = serverapp.contents_manager
        self.kernel_manager = serverapp.kernel_manager
        self.kernel_spec_manager = serverapp.kernel_spec_manager
    
    # Notebook operations
    
    async def get_notebook_content(self, path: str) -> dict[str, Any]:
        """
        Get notebook content using local contents_manager.
        
        Args:
            path: Path to notebook file
            
        Returns:
            Notebook content dictionary
        """
        model = await asyncio.to_thread(
            self.contents_manager.get,
            path,
            type='notebook',
            content=True
        )
        return model['content']
    
    async def list_notebooks(self, path: str = "") -> list[str]:
        """
        List all notebooks recursively using local contents_manager.
        
        Args:
            path: Directory path to search
            
        Returns:
            List of notebook paths
        """
        notebooks = []
        await self._list_notebooks_recursive(path, notebooks)
        return notebooks
    
    async def _list_notebooks_recursive(self, path: str, notebooks: list[str]) -> None:
        """Helper to recursively list notebooks."""
        try:
            model = await asyncio.to_thread(
                self.contents_manager.get,
                path,
                content=True
            )
            
            if model['type'] == 'directory':
                for item in model['content']:
                    item_path = f"{path}/{item['name']}" if path else item['name']
                    
                    if item['type'] == 'directory':
                        await self._list_notebooks_recursive(item_path, notebooks)
                    elif item['type'] == 'notebook' or item['name'].endswith('.ipynb'):
                        notebooks.append(item_path)
        except Exception:
            # Skip directories we can't access
            pass
    
    async def notebook_exists(self, path: str) -> bool:
        """
        Check if notebook exists using local contents_manager.
        
        Args:
            path: Path to notebook
            
        Returns:
            True if exists
        """
        try:
            await asyncio.to_thread(
                self.contents_manager.get,
                path,
                content=False
            )
            return True
        except Exception:
            return False
    
    async def create_notebook(self, path: str) -> dict[str, Any]:
        """
        Create a new notebook using local contents_manager.
        
        Args:
            path: Path for new notebook
            
        Returns:
            Created notebook content
        """
        model = await asyncio.to_thread(
            self.contents_manager.new,
            path=path
        )
        return model['content']
    
    # Cell operations
    
    async def read_cells(
        self, 
        path: str, 
        start_index: Optional[int] = None,
        end_index: Optional[int] = None
    ) -> list[dict[str, Any]]:
        """
        Read cells from notebook.
        
        Args:
            path: Notebook path
            start_index: Start index
            end_index: End index
            
        Returns:
            List of cells
        """
        content = await self.get_notebook_content(path)
        cells = content.get('cells', [])
        
        if start_index is not None or end_index is not None:
            start = start_index or 0
            end = end_index if end_index is not None else len(cells)
            cells = cells[start:end]
        
        return cells
    
    async def append_cell(
        self, 
        path: str, 
        cell_type: Literal["code", "markdown"],
        source: Union[str, list[str]]
    ) -> int:
        """
        Append a cell to notebook.
        
        Args:
            path: Notebook path
            cell_type: Cell type
            source: Cell source
            
        Returns:
            Index of appended cell
        """
        content = await self.get_notebook_content(path)
        cells = content.get('cells', [])
        
        # Normalize source to list of strings
        if isinstance(source, str):
            source = source.splitlines(keepends=True)
        
        new_cell = {
            'cell_type': cell_type,
            'metadata': {},
            'source': source
        }
        
        if cell_type == 'code':
            new_cell['outputs'] = []
            new_cell['execution_count'] = None
        
        cells.append(new_cell)
        content['cells'] = cells
        
        # Save updated notebook
        await asyncio.to_thread(
            self.contents_manager.save,
            {
                'type': 'notebook',
                'content': content
            },
            path
        )
        
        return len(cells) - 1
    
    async def insert_cell(
        self,
        path: str,
        cell_index: int,
        cell_type: Literal["code", "markdown"],
        source: Union[str, list[str]]
    ) -> int:
        """
        Insert a cell at specific index.
        
        Args:
            path: Notebook path
            cell_index: Insert position
            cell_type: Cell type
            source: Cell source
            
        Returns:
            Index of inserted cell
        """
        content = await self.get_notebook_content(path)
        cells = content.get('cells', [])
        
        # Normalize source
        if isinstance(source, str):
            source = source.splitlines(keepends=True)
        
        new_cell = {
            'cell_type': cell_type,
            'metadata': {},
            'source': source
        }
        
        if cell_type == 'code':
            new_cell['outputs'] = []
            new_cell['execution_count'] = None
        
        cells.insert(cell_index, new_cell)
        content['cells'] = cells
        
        # Save updated notebook
        await asyncio.to_thread(
            self.contents_manager.save,
            {
                'type': 'notebook',
                'content': content
            },
            path
        )
        
        return cell_index
    
    async def delete_cell(self, path: str, cell_index: int) -> None:
        """
        Delete a cell from notebook.
        
        Args:
            path: Notebook path
            cell_index: Index to delete
        """
        content = await self.get_notebook_content(path)
        cells = content.get('cells', [])
        
        if 0 <= cell_index < len(cells):
            cells.pop(cell_index)
            content['cells'] = cells
            
            await asyncio.to_thread(
                self.contents_manager.save,
                {
                    'type': 'notebook',
                    'content': content
                },
                path
            )
    
    async def overwrite_cell(
        self,
        path: str,
        cell_index: int,
        new_source: Union[str, list[str]]
    ) -> tuple[str, str]:
        """
        Overwrite cell content.
        
        Args:
            path: Notebook path
            cell_index: Cell index
            new_source: New source
            
        Returns:
            Tuple of (old_source, new_source)
        """
        content = await self.get_notebook_content(path)
        cells = content.get('cells', [])
        
        if cell_index < 0 or cell_index >= len(cells):
            raise ValueError(f"Cell index {cell_index} out of range")
        
        cell = cells[cell_index]
        old_source = ''.join(cell['source']) if isinstance(cell['source'], list) else cell['source']
        
        # Normalize new source
        if isinstance(new_source, str):
            new_source_str = new_source
            new_source = new_source.splitlines(keepends=True)
        else:
            new_source_str = ''.join(new_source)
        
        cell['source'] = new_source
        content['cells'] = cells
        
        await asyncio.to_thread(
            self.contents_manager.save,
            {
                'type': 'notebook',
                'content': content
            },
            path
        )
        
        return (old_source, new_source_str)
    
    # Kernel operations
    
    async def get_or_create_kernel(self, path: str, kernel_id: Optional[str] = None) -> str:
        """
        Get existing kernel or create new one.
        
        Args:
            path: Notebook path (for context)
            kernel_id: Specific kernel ID
            
        Returns:
            Kernel ID
        """
        if kernel_id and kernel_id in self.kernel_manager:
            return kernel_id
        
        # Start new kernel
        kernel_id = await self.kernel_manager.start_kernel()
        return kernel_id
    
    async def execute_cell(
        self,
        path: str,
        cell_index: int,
        kernel_id: str,
        timeout_seconds: int = 300
    ) -> list[Union[str, ImageContent]]:
        """
        Execute a cell using local kernel manager.
        
        Args:
            path: Notebook path
            cell_index: Cell index
            kernel_id: Kernel ID
            timeout_seconds: Timeout
            
        Returns:
            List of outputs
        """
        # Get cell source
        cells = await self.read_cells(path)
        if cell_index < 0 or cell_index >= len(cells):
            raise ValueError(f"Cell index {cell_index} out of range")
        
        cell = cells[cell_index]
        source = ''.join(cell['source']) if isinstance(cell['source'], list) else cell['source']
        
        # Get kernel client
        kernel = self.kernel_manager.get_kernel(kernel_id)
        client = kernel.client()
        
        # Execute code
        msg_id = client.execute(source)
        
        # Collect outputs
        outputs = []
        start_time = asyncio.get_event_loop().time()
        
        while True:
            if asyncio.get_event_loop().time() - start_time > timeout_seconds:
                raise TimeoutError(f"Cell execution exceeded {timeout_seconds} seconds")
            
            try:
                msg = await asyncio.wait_for(
                    asyncio.to_thread(client.get_iopub_msg, timeout=1),
                    timeout=2
                )
                
                msg_type = msg['header']['msg_type']
                
                if msg_type == 'status':
                    if msg['content']['execution_state'] == 'idle':
                        break
                elif msg_type in ['execute_result', 'display_data']:
                    outputs.append(msg['content'])
                elif msg_type == 'stream':
                    outputs.append(msg['content'])
                elif msg_type == 'error':
                    outputs.append(msg['content'])
            except asyncio.TimeoutError:
                continue
            except Exception:
                break
        
        # Update cell with outputs
        content = await self.get_notebook_content(path)
        if cell_index < len(content['cells']):
            content['cells'][cell_index]['outputs'] = outputs
            await asyncio.to_thread(
                self.contents_manager.save,
                {'type': 'notebook', 'content': content},
                path
            )
        
        return safe_extract_outputs(outputs)
    
    async def interrupt_kernel(self, kernel_id: str) -> None:
        """Interrupt a kernel."""
        if kernel_id in self.kernel_manager:
            kernel = self.kernel_manager.get_kernel(kernel_id)
            await kernel.interrupt()
    
    async def restart_kernel(self, kernel_id: str) -> None:
        """Restart a kernel."""
        if kernel_id in self.kernel_manager:
            await self.kernel_manager.restart_kernel(kernel_id)
    
    async def shutdown_kernel(self, kernel_id: str) -> None:
        """Shutdown a kernel."""
        if kernel_id in self.kernel_manager:
            await self.kernel_manager.shutdown_kernel(kernel_id)
    
    async def list_kernels(self) -> list[dict[str, Any]]:
        """List all running kernels."""
        return [
            {
                'id': kid,
                'name': self.kernel_manager.get_kernel(kid).kernel_name
            }
            for kid in self.kernel_manager.list_kernel_ids()
        ]
    
    async def kernel_exists(self, kernel_id: str) -> bool:
        """Check if kernel exists."""
        return kernel_id in self.kernel_manager

```

`jupyter_mcp_server/jupyter_extension/backends/remote_backend.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""
Remote Backend Implementation

This backend uses the existing jupyter_nbmodel_client, jupyter_kernel_client,
and jupyter_server_client packages to connect to remote Jupyter servers.

For MCP_SERVER mode, this maintains 100% backward compatibility with the existing implementation.
"""

from typing import Optional, Any, Union, Literal
from mcp.types import ImageContent
from jupyter_mcp_server.jupyter_extension.backends.base import Backend

# Note: This is a placeholder that delegates to existing server.py logic
# The actual implementation will be refactored from server.py in a later step
# For now, this establishes the pattern


class RemoteBackend(Backend):
    """
    Backend that connects to remote Jupyter servers using HTTP/WebSocket APIs.
    
    Uses:
    - jupyter_nbmodel_client.NbModelClient for notebook operations
    - jupyter_kernel_client.KernelClient for kernel operations  
    - jupyter_server_client.JupyterServerClient for server operations
    """
    
    def __init__(self, document_url: str, document_token: str, runtime_url: str, runtime_token: str):
        """
        Initialize remote backend.
        
        Args:
            document_url: URL of Jupyter server for document operations
            document_token: Authentication token for document server
            runtime_url: URL of Jupyter server for runtime operations
            runtime_token: Authentication token for runtime server
        """
        self.document_url = document_url
        self.document_token = document_token
        self.runtime_url = runtime_url
        self.runtime_token = runtime_token
    
    # Notebook operations
    
    async def get_notebook_content(self, path: str) -> dict[str, Any]:
        """Get notebook content via remote API."""
        # TODO: Implement using jupyter_server_client
        raise NotImplementedError("To be refactored from server.py")
    
    async def list_notebooks(self, path: str = "") -> list[str]:
        """List notebooks via remote API."""
        # TODO: Implement using jupyter_server_client
        raise NotImplementedError("To be refactored from server.py")
    
    async def notebook_exists(self, path: str) -> bool:
        """Check if notebook exists via remote API."""
        # TODO: Implement using jupyter_server_client
        raise NotImplementedError("To be refactored from server.py")
    
    async def create_notebook(self, path: str) -> dict[str, Any]:
        """Create notebook via remote API."""
        # TODO: Implement using jupyter_server_client
        raise NotImplementedError("To be refactored from server.py")
    
    # Cell operations
    
    async def read_cells(
        self, 
        path: str, 
        start_index: Optional[int] = None,
        end_index: Optional[int] = None
    ) -> list[dict[str, Any]]:
        """Read cells via nbmodel_client."""
        # TODO: Implement using jupyter_nbmodel_client
        raise NotImplementedError("To be refactored from server.py")
    
    async def append_cell(
        self, 
        path: str, 
        cell_type: Literal["code", "markdown"],
        source: Union[str, list[str]]
    ) -> int:
        """Append cell via nbmodel_client."""
        # TODO: Implement using jupyter_nbmodel_client
        raise NotImplementedError("To be refactored from server.py")
    
    async def insert_cell(
        self,
        path: str,
        cell_index: int,
        cell_type: Literal["code", "markdown"],
        source: Union[str, list[str]]
    ) -> int:
        """Insert cell via nbmodel_client."""
        # TODO: Implement using jupyter_nbmodel_client
        raise NotImplementedError("To be refactored from server.py")
    
    async def delete_cell(self, path: str, cell_index: int) -> None:
        """Delete cell via nbmodel_client."""
        # TODO: Implement using jupyter_nbmodel_client
        raise NotImplementedError("To be refactored from server.py")
    
    async def overwrite_cell(
        self,
        path: str,
        cell_index: int,
        new_source: Union[str, list[str]]
    ) -> tuple[str, str]:
        """Overwrite cell via nbmodel_client."""
        # TODO: Implement using jupyter_nbmodel_client
        raise NotImplementedError("To be refactored from server.py")
    
    # Kernel operations
    
    async def get_or_create_kernel(self, path: str, kernel_id: Optional[str] = None) -> str:
        """Get or create kernel via kernel_client."""
        # TODO: Implement using jupyter_kernel_client
        raise NotImplementedError("To be refactored from server.py")
    
    async def execute_cell(
        self,
        path: str,
        cell_index: int,
        kernel_id: str,
        timeout_seconds: int = 300
    ) -> list[Union[str, ImageContent]]:
        """Execute cell via kernel_client."""
        # TODO: Implement using jupyter_kernel_client
        raise NotImplementedError("To be refactored from server.py")
    
    async def interrupt_kernel(self, kernel_id: str) -> None:
        """Interrupt kernel via kernel_client."""
        # TODO: Implement using jupyter_kernel_client
        raise NotImplementedError("To be refactored from server.py")
    
    async def restart_kernel(self, kernel_id: str) -> None:
        """Restart kernel via kernel_client."""
        # TODO: Implement using jupyter_kernel_client
        raise NotImplementedError("To be refactored from server.py")
    
    async def shutdown_kernel(self, kernel_id: str) -> None:
        """Shutdown kernel via kernel_client."""
        # TODO: Implement using jupyter_kernel_client
        raise NotImplementedError("To be refactored from server.py")
    
    async def list_kernels(self) -> list[dict[str, Any]]:
        """List kernels via server API."""
        # TODO: Implement using jupyter_server_client
        raise NotImplementedError("To be refactored from server.py")
    
    async def kernel_exists(self, kernel_id: str) -> bool:
        """Check if kernel exists via server API."""
        # TODO: Implement using jupyter_server_client
        raise NotImplementedError("To be refactored from server.py")

```

`jupyter_mcp_server/jupyter_extension/context.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""
Server Context Management

This module provides a singleton to track the execution context (MCP_SERVER vs JUPYTER_SERVER)
and provide access to Jupyter Server resources when running as an extension.
"""

from typing import Optional, Literal, TYPE_CHECKING
import threading

if TYPE_CHECKING:
    from jupyter_server.serverapp import ServerApp


class ServerContext:
    """
    Singleton managing server execution context.
    
    This class tracks whether tools are running in standalone MCP_SERVER mode
    or embedded JUPYTER_SERVER mode, and provides access to server resources.
    """
    
    _instance: Optional['ServerContext'] = None
    _lock = threading.Lock()
    
    def __new__(cls):
        if cls._instance is None:
            with cls._lock:
                if cls._instance is None:
                    cls._instance = super().__new__(cls)
                    cls._instance._initialized = False
        return cls._instance
    
    def __init__(self):
        if self._initialized:
            return
            
        self._initialized = True
        self._context_type: Literal["MCP_SERVER", "JUPYTER_SERVER"] = "MCP_SERVER"
        self._serverapp: Optional['ServerApp'] = None
        self._document_url: Optional[str] = None
        self._runtime_url: Optional[str] = None
        self._jupyterlab: bool = True  # Default to True
    
    @property
    def context_type(self) -> Literal["MCP_SERVER", "JUPYTER_SERVER"]:
        """Get the current server context type."""
        return self._context_type
    
    @property
    def serverapp(self) -> Optional['ServerApp']:
        """Get the Jupyter ServerApp instance (only available in JUPYTER_SERVER mode)."""
        return self._serverapp
    
    @property
    def document_url(self) -> Optional[str]:
        """Get the configured document URL."""
        return self._document_url
    
    @property
    def runtime_url(self) -> Optional[str]:
        """Get the configured runtime URL."""
        return self._runtime_url
    
    @property
    def jupyterlab(self) -> bool:
        """Get the jupyterlab mode flag."""
        return self._jupyterlab
    
    def update(
        self,
        context_type: Literal["MCP_SERVER", "JUPYTER_SERVER"],
        serverapp: Optional['ServerApp'] = None,
        document_url: Optional[str] = None,
        runtime_url: Optional[str] = None,
        jupyterlab: Optional[bool] = None
    ):
        """
        Update the server context.
        
        Args:
            context_type: The type of server context
            serverapp: Jupyter ServerApp instance (required for JUPYTER_SERVER mode)
            document_url: Document URL configuration
            runtime_url: Runtime URL configuration
            jupyterlab: JupyterLab mode flag (defaults to True when JUPYTER_SERVER mode is true)
        """
        with self._lock:
            self._context_type = context_type
            self._serverapp = serverapp
            self._document_url = document_url
            self._runtime_url = runtime_url
            
            # Set jupyterlab flag - default to True if JUPYTER_SERVER mode, otherwise keep current value
            if jupyterlab is not None:
                self._jupyterlab = jupyterlab
            elif context_type == "JUPYTER_SERVER":
                self._jupyterlab = True  # Default to True for JUPYTER_SERVER mode
            
            if context_type == "JUPYTER_SERVER" and serverapp is None:
                raise ValueError("serverapp is required when context_type is JUPYTER_SERVER")
    
    def is_local_document(self) -> bool:
        """Check if document operations should use local serverapp."""
        return (
            self._context_type == "JUPYTER_SERVER" 
            and self._document_url == "local"
        )
    
    def is_local_runtime(self) -> bool:
        """Check if runtime operations should use local serverapp."""
        return (
            self._context_type == "JUPYTER_SERVER" 
            and self._runtime_url == "local"
        )
    
    def is_jupyterlab_mode(self) -> bool:
        """Check if JupyterLab mode is enabled."""
        return self._jupyterlab
    
    def get_contents_manager(self):
        """
        Get the Jupyter contents manager (only available in JUPYTER_SERVER mode with local access).
        
        Returns:
            ContentsManager instance or None
        """
        if self._serverapp is not None:
            return self._serverapp.contents_manager
        return None
    
    def get_kernel_manager(self):
        """
        Get the Jupyter kernel manager (only available in JUPYTER_SERVER mode with local access).
        
        Returns:
            KernelManager instance or None
        """
        if self._serverapp is not None:
            return self._serverapp.kernel_manager
        return None
    
    def get_kernel_spec_manager(self):
        """
        Get the Jupyter kernel spec manager (only available in JUPYTER_SERVER mode with local access).
        
        Returns:
            KernelSpecManager instance or None
        """
        if self._serverapp is not None:
            return self._serverapp.kernel_spec_manager
        return None
    
    def get_session_manager(self):
        """
        Get the Jupyter session manager (only available in JUPYTER_SERVER mode with local access).
        
        Returns:
            SessionManager instance or None
        """
        if self._serverapp is not None:
            return self._serverapp.session_manager
        return None
    
    @property
    def session_manager(self):
        """
        Get the Jupyter session manager as a property (only available in JUPYTER_SERVER mode with local access).
        
        Returns:
            SessionManager instance or None
        """
        return self.get_session_manager()
    
    def reset(self):
        """Reset to default MCP_SERVER mode."""
        with self._lock:
            self._context_type = "MCP_SERVER"
            self._serverapp = None
            self._document_url = None
            self._runtime_url = None
            self._jupyterlab = True  # Default to True


# Global accessor
def get_server_context() -> ServerContext:
    """Get the global ServerContext singleton instance."""
    return ServerContext()

```

`jupyter_mcp_server/jupyter_extension/extension.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""
Jupyter Server Extension for MCP Protocol

This extension exposes MCP tools directly from a running Jupyter Server,
allowing MCP clients to connect to the Jupyter Server's MCP endpoints.
"""

import logging
from traitlets import Unicode, Bool
from jupyter_server.extension.application import ExtensionApp, ExtensionAppJinjaMixin
from jupyter_server.utils import url_path_join

from jupyter_mcp_server.jupyter_extension.context import get_server_context
from jupyter_mcp_server.jupyter_extension.handlers import (
    MCPHealthHandler,
    MCPToolsListHandler,
    MCPToolsCallHandler,
)


logger = logging.getLogger(__name__)


class JupyterMCPServerExtensionApp(ExtensionAppJinjaMixin, ExtensionApp):
    """
    Jupyter Server Extension for MCP Server.
    
    This extension allows MCP clients to connect to Jupyter Server and use
    MCP tools to interact with notebooks and kernels.
    
    Configuration:
        c.JupyterMCPServerExtensionApp.document_url = "local"  # or http://...
        c.JupyterMCPServerExtensionApp.runtime_url = "local"   # or http://...
        c.JupyterMCPServerExtensionApp.document_id = "notebook.ipynb"
        c.JupyterMCPServerExtensionApp.start_new_runtime = True  # Start new kernel
        c.JupyterMCPServerExtensionApp.runtime_id = "kernel-id"  # Or connect to existing
    """
    
    # Extension metadata
    name = "jupyter_mcp_server"
    default_url = "/mcp"
    load_other_extensions = True
    
    # Configuration traits
    document_url = Unicode(
        "local",
        config=True,
        help='Document URL - use "local" for local serverapp access or http://... for remote'
    )
    
    runtime_url = Unicode(
        "local",
        config=True,
        help='Runtime URL - use "local" for local serverapp access or http://... for remote'
    )
    
    document_id = Unicode(
        "notebook.ipynb",
        config=True,
        help='Default document ID (notebook path)'
    )
    
    start_new_runtime = Bool(
        False,
        config=True,
        help='Whether to start a new kernel runtime on initialization'
    )
    
    runtime_id = Unicode(
        "",
        config=True,
        help='Existing kernel ID to connect to (if not starting new runtime)'
    )
    
    document_token = Unicode(
        "",
        config=True,
        help='Authentication token for document server (if remote)'
    )
    
    runtime_token = Unicode(
        "",
        config=True,
        help='Authentication token for runtime server (if remote)'
    )
    
    provider = Unicode(
        "jupyter",
        config=True,
        help='Provider type for document/runtime'
    )
    
    jupyterlab = Bool(
        True,
        config=True,
        help='Enable JupyterLab mode (defaults to True)'
    )
    
    allowed_jupyter_mcp_tools = Unicode(
        "notebook_run-all-cells,notebook_get-selected-cell",
        config=True,
        help='Comma-separated list of jupyter-mcp-tools to enable'
    )
    
    def initialize_settings(self):
        """
        Initialize extension settings.
        
        This is called during extension loading to set up configuration
        and update the server context.
        """
        # Reduce noise from httpx logging (used by JupyterLab for PyPI extension discovery)
        logging.getLogger("httpx").setLevel(logging.WARNING)
        
        logger.info(f"Initializing Jupyter MCP Server Extension")
        logger.info(f"  Document URL: {self.document_url}")
        logger.info(f"  Runtime URL: {self.runtime_url}")
        logger.info(f"  Document ID: {self.document_id}")
        logger.info(f"  Start New Runtime: {self.start_new_runtime}")
        logger.info(f"  JupyterLab Mode: {self.jupyterlab}")
        if self.runtime_id:
            logger.info(f"  Runtime ID: {self.runtime_id}")
        
        # Update the global server context
        context = get_server_context()
        context.update(
            context_type="JUPYTER_SERVER",
            serverapp=self.serverapp,
            document_url=self.document_url,
            runtime_url=self.runtime_url,
            jupyterlab=self.jupyterlab
        )
        
        # Update global MCP configuration
        from jupyter_mcp_server.config import get_config
        config = get_config()
        config.document_url = self.document_url
        config.runtime_url = self.runtime_url
        config.document_id = self.document_id
        config.document_token = self.document_token if self.document_token else None
        config.runtime_token = self.runtime_token if self.runtime_token else None
        config.start_new_runtime = self.start_new_runtime
        config.runtime_id = self.runtime_id if self.runtime_id else None
        config.provider = self.provider
        config.jupyterlab = self.jupyterlab
        config.allowed_jupyter_mcp_tools = self.allowed_jupyter_mcp_tools
        
        # Store configuration in settings for handlers
        self.settings.update({
            "mcp_document_url": self.document_url,
            "mcp_runtime_url": self.runtime_url,
            "mcp_document_id": self.document_id,
            "mcp_document_token": self.document_token,
            "mcp_runtime_token": self.runtime_token,
            "mcp_start_new_runtime": self.start_new_runtime,
            "mcp_runtime_id": self.runtime_id,
            "mcp_provider": self.provider,
            "mcp_jupyterlab": self.jupyterlab,
            "mcp_allowed_jupyter_mcp_tools": self.allowed_jupyter_mcp_tools,
            "mcp_serverapp": self.serverapp,
        })
        
        # Trigger auto-enrollment if document_id is configured
        # Note: Auto-enrollment supports 3 modes:
        # 1. With existing kernel (runtime_id set)
        # 2. With new kernel (start_new_runtime=True)
        # 3. Without kernel - notebook-only mode (both False/None)
        if self.document_id:
            from tornado.ioloop import IOLoop
            from jupyter_mcp_server.enroll import auto_enroll_document
            from jupyter_mcp_server.server import notebook_manager, server_context
            from jupyter_mcp_server.tools import UseNotebookTool
            
            # Schedule auto-enrollment to run after Jupyter Server is fully started
            async def _run_auto_enrollment():
                try:
                    logger.info(f"Running auto-enrollment for document '{self.document_id}'")
                    await auto_enroll_document(
                        config=config,
                        notebook_manager=notebook_manager,
                        use_notebook_tool=UseNotebookTool(),
                        server_context=server_context,
                    )
                    logger.info(f"Auto-enrollment completed for document '{self.document_id}'")
                except Exception as e:
                    logger.error(f"Failed to auto-enroll document: {e}", exc_info=True)
            
            # Schedule the enrollment to run on the IOLoop after server starts
            # Use callback with delay to ensure server is fully initialized
            IOLoop.current().call_later(1.0, lambda: IOLoop.current().add_callback(_run_auto_enrollment))
        
        logger.info("Jupyter MCP Server Extension settings initialized")
    
    def initialize_handlers(self):
        """
        Register MCP protocol handlers.
        
        Strategy: Implement MCP protocol directly in Tornado handlers that
        call the MCP tools from server.py. This avoids the complexity of
        wrapping the Starlette ASGI app.
        
        Endpoints:
        - GET/POST /mcp - MCP protocol endpoint (SSE-based)
        - GET /mcp/healthz - Health check (Tornado handler)
        - GET /mcp/tools/list - List available tools (Tornado handler)
        - POST /mcp/tools/call - Execute a tool (Tornado handler)
        """
        base_url = self.serverapp.base_url
        
        # Import here to avoid circular imports
        from jupyter_mcp_server.jupyter_extension.handlers import MCPSSEHandler
        
        # Define handlers
        handlers = [
            # MCP protocol endpoint - SSE-based handler
            # Match /mcp with or without trailing slash
            (url_path_join("mcp/?"), MCPSSEHandler),
            # Utility endpoints (optional, for debugging)
            (url_path_join("mcp/healthz"), MCPHealthHandler),
            (url_path_join("mcp/tools/list"), MCPToolsListHandler),
            (url_path_join("mcp/tools/call"), MCPToolsCallHandler),
        ]
        
        # Register handlers
        self.handlers.extend(handlers)
        
        # Log registered endpoints using url_path_join for consistent formatting
        logger.info(f"Registered MCP handlers at {url_path_join(base_url, 'mcp/')}")
        logger.info(f"  - MCP protocol: {url_path_join(base_url, 'mcp')} (SSE-based)")
        logger.info(f"  - Health check: {url_path_join(base_url, 'mcp/healthz')}")
        logger.info(f"  - List tools: {url_path_join(base_url, 'mcp/tools/list')}")
        logger.info(f"  - Call tool: {url_path_join(base_url, 'mcp/tools/call')}")
    
    def initialize_templates(self):
        """
        Initialize Jinja templates.
        
        Not needed for API-only extension, but included for completeness.
        """
        pass
    
    async def stop_extension(self):
        """
        Clean up when extension stops.
        
        Shutdown any managed kernels and cleanup resources.
        """
        logger.info("Stopping Jupyter MCP Server Extension")
        
        # Reset server context
        context = get_server_context()
        context.reset()
        
        logger.info("Jupyter MCP Server Extension stopped")


# Extension loading functions

def _jupyter_server_extension_points():
    """
    Declare the Jupyter Server extension.
    
    Returns:
        List of extension metadata dictionaries
    """
    return [
        {
            "module": "jupyter_mcp_server.jupyter_extension.extension",
            "app": JupyterMCPServerExtensionApp
        }
    ]


def _load_jupyter_server_extension(serverapp):
    """
    Load the extension (for backward compatibility).
    
    Args:
        serverapp: Jupyter ServerApp instance
    """
    extension = JupyterMCPServerExtensionApp()
    extension.serverapp = serverapp
    extension.initialize_settings()
    extension.initialize_handlers()
    extension.initialize_templates()


# For classic Notebook server compatibility
load_jupyter_server_extension = _load_jupyter_server_extension

```

`jupyter_mcp_server/jupyter_extension/handlers.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""
Tornado request handlers for the Jupyter MCP Server extension.

This module provides handlers that bridge between Tornado (Jupyter Server) and
FastMCP, managing the MCP protocol lifecycle and request proxying.
"""

import json
import logging
from typing import Any
from tornado.web import RequestHandler
from jupyter_server.base.handlers import JupyterHandler

from jupyter_mcp_server.jupyter_extension.context import get_server_context
from jupyter_mcp_server.server_context import ServerContext
from jupyter_mcp_server.jupyter_extension.backends.local_backend import LocalBackend
from jupyter_mcp_server.jupyter_extension.backends.remote_backend import RemoteBackend
from jupyter_mcp_server.utils import clean_mcp_response, clean_mcp_response_content


logger = logging.getLogger(__name__)


class MCPSSEHandler(RequestHandler):
    """
    Server-Sent Events (SSE) handler for MCP protocol.
    
    This handler implements the MCP SSE transport by directly calling
    the registered MCP tools instead of trying to wrap the Starlette app.
    
    The MCP protocol uses SSE for streaming responses from the server to the client.
    """
    
    # Cache of jupyter_mcp_tools tool names for routing decisions
    _jupyter_tool_names = set()
    
    def check_xsrf_cookie(self):
        """Disable XSRF checking for MCP protocol requests."""
        pass
    
    def set_default_headers(self):
        """Set headers for SSE and CORS."""
        self.set_header("Content-Type", "text/event-stream")
        self.set_header("Cache-Control", "no-cache")
        self.set_header("Connection", "keep-alive")
        self.set_header("Access-Control-Allow-Origin", "*")
        self.set_header("Access-Control-Allow-Methods", "GET, POST, OPTIONS")
        self.set_header("Access-Control-Allow-Headers", "Content-Type, Authorization")
    
    async def options(self, *args, **kwargs):
        """Handle CORS preflight requests."""
        self.set_status(204)
        self.finish()
    
    async def get(self):
        """Handle SSE connection establishment."""
        # Import here to avoid circular dependency
        from jupyter_mcp_server.server import mcp
        
        # For now, just acknowledge the connection
        # The actual MCP protocol would be handled via POST
        self.write("event: connected\ndata: {}\n\n")
        await self.flush()
    
    async def post(self):
        """Handle MCP protocol messages."""
        # Import here to avoid circular dependency
        from jupyter_mcp_server.server import mcp
        
        try:
            # Parse the JSON-RPC request
            body = json.loads(self.request.body.decode('utf-8'))
            method = body.get("method")
            params = body.get("params", {})
            request_id = body.get("id")
            
            logger.info(f"MCP request: method={method}, id={request_id}")
            
            # Handle notifications (id is None) - these don't require a response per JSON-RPC 2.0
            # But in HTTP transport, we need to acknowledge the request
            if request_id is None:
                logger.info(f"Received notification: {method} - acknowledging without result")
                # Return empty response - the client should handle notifications without expecting a result
                # Some clients may send this as POST and expect HTTP 200 with no JSON-RPC response
                self.set_status(200)
                self.finish()
                return
            
            # Handle different MCP methods
            if method == "initialize":
                # Return server capabilities
                response = {
                    "jsonrpc": "2.0",
                    "id": request_id,
                    "result": {
                        "protocolVersion": "2024-11-05",
                        "capabilities": {
                            "tools": {},
                            "prompts": {},
                            "resources": {}
                        },
                        "serverInfo": {
                            "name": "Jupyter MCP Server",
                            "version": "0.20.0"
                        }
                    }
                }
                logger.info(f"Sending initialize response: {response}")
            elif method == "tools/list":
                # List available tools from FastMCP and jupyter_mcp_tools
                from jupyter_mcp_server.server import mcp
                
                logger.info("Listing tools from FastMCP and jupyter_mcp_tools...")
                
                try:
                    # Get FastMCP tools first
                    tools_list = await mcp.list_tools()
                    logger.info(f"Got {len(tools_list)} tools from FastMCP")
                    
                    # Track jupyter_mcp_tools tool names
                    jupyter_tool_names = set()
                    
                    # Get tools from jupyter_mcp_tools extension first to identify duplicates
                    jupyter_tools_data = []
                    try:
                        from jupyter_mcp_tools import get_tools
                        from jupyter_mcp_server.tool_cache import get_tool_cache
                        
                        # Get the server's base URL dynamically from ServerApp
                        context = get_server_context()
                        if context.serverapp is not None:
                            base_url = context.serverapp.connection_url
                            token = context.serverapp.token
                            logger.info(f"Using Jupyter ServerApp connection URL: {base_url}")
                        else:
                            # Fallback to hardcoded localhost (should not happen in JUPYTER_SERVER mode)
                            port = self.settings.get('port', 8888)
                            base_url = f"http://localhost:{port}"
                            token = self.settings.get('token', None)
                            logger.warning(f"ServerApp not available, using fallback: {base_url}")
                        
                        logger.info(f"Querying jupyter_mcp_tools at {base_url}")
                        
                        # Check if JupyterLab mode is enabled before loading jupyter-mcp-tools
                        context = ServerContext.get_instance()
                        jupyterlab_enabled = context.is_jupyterlab_mode()
                        logger.info(f"JupyterLab mode check: enabled={jupyterlab_enabled}")
                        
                        if jupyterlab_enabled:
                            # Define specific tools we want to load from jupyter-mcp-tools
                            # (https://github.com/datalayer/jupyter-mcp-tools)
                            # jupyter-mcp-tools exposes JupyterLab commands as MCP tools.
                            # Only tools listed here will be available to MCP clients.
                            # To add new tools, also update the list in server.py and
                            # see docs/docs/reference/tools-additional/index.mdx for documentation.
                            from jupyter_mcp_server.config import get_config
                            config = get_config()
                            allowed_jupyter_mcp_tools = config.get_allowed_jupyter_mcp_tools()
                            
                            logger.info(f"Looking for specific jupyter-mcp-tools: {allowed_jupyter_mcp_tools}")
                            
                            # Try querying with caching to avoid expensive repeated calls
                            try:
                                search_query = ",".join(allowed_jupyter_mcp_tools)
                                logger.info(f"Searching jupyter-mcp-tools with query: '{search_query}' (allowed_tools: {allowed_jupyter_mcp_tools})")
                                
                                # Use cached get_tools to avoid expensive repeated calls
                                tool_cache = get_tool_cache()
                                
                                # Create wrapper function that matches the expected signature
                                async def get_tools_wrapper(**kwargs):
                                    # Add wait_timeout for handlers.py compatibility
                                    return await get_tools(
                                        wait_timeout=5,  # Shorter timeout - if frontend isn't loaded, don't wait long
                                        **kwargs
                                    )
                                
                                jupyter_tools_data = await tool_cache.get_tools(
                                    base_url=base_url,
                                    token=token,
                                    query=search_query,
                                    enabled_only=False,
                                    ttl_seconds=180,  # 3 minutes for handlers (shorter than server.py)
                                    fetch_func=get_tools_wrapper  # Use wrapper that includes wait_timeout
                                )
                                logger.info(f"Query returned {len(jupyter_tools_data)} tools (from cache or fresh)")
                                
                                # Use the tools directly since query should return only what we want
                                for tool in jupyter_tools_data:
                                    logger.info(f"Found tool: {tool.get('id', '')}")
                            except Exception as e:
                                logger.warning(f"Failed to load jupyter-mcp-tools (this is normal if JupyterLab frontend is not loaded): {e}")
                                jupyter_tools_data = []
                            
                            logger.info(f"Successfully loaded {len(jupyter_tools_data)} specific jupyter-mcp-tools (requires JupyterLab frontend)")
                        else:
                            # JupyterLab mode disabled, don't load any jupyter-mcp-tools
                            jupyter_tools_data = []
                            logger.info("JupyterLab mode disabled, skipping jupyter-mcp-tools")
                        
                        # Build set of jupyter tool names and cache it for routing decisions
                        jupyter_tool_names = {tool_data.get('id', '') for tool_data in jupyter_tools_data}
                        MCPSSEHandler._jupyter_tool_names = jupyter_tool_names
                        logger.info(f"Cached {len(jupyter_tool_names)} jupyter_mcp_tools names for routing: {jupyter_tool_names}")
                    
                    except Exception as jupyter_error:
                        # Log but don't fail - just return FastMCP tools
                        logger.warning(f"Could not fetch tools from jupyter_mcp_tools: {jupyter_error}")
                    
                    # Convert FastMCP tools to MCP protocol format
                    tools = []
                    for tool in tools_list:
                        # Skip connect_to_jupyter tool when running as Jupyter extension
                        # since it doesn't make sense to connect to a different server
                        # when already running inside Jupyter
                        from jupyter_mcp_server.tools import ServerMode
                        context = ServerContext.get_instance()
                        context.initialize()
                        mode = context._mode
                        
                        if tool.name == "connect_to_jupyter" and mode == ServerMode.JUPYTER_SERVER:
                            logger.info("Skipping connect_to_jupyter tool in JUPYTER_SERVER mode")
                            continue
                            
                        tools.append({
                            "name": tool.name,
                            "description": tool.description,
                            "inputSchema": tool.inputSchema
                        })
                    
                    # Now add jupyter_mcp_tools
                    for tool_data in jupyter_tools_data:
                        # Only include MCP protocol fields (exclude internal fields like commandId)
                        tool_dict = {
                            "name": tool_data.get('id', ''),
                            "description": tool_data.get('caption', tool_data.get('label', '')),
                        }
                        
                        # Convert parameters to inputSchema
                        # The parameters field contains the JSON Schema for the tool's arguments
                        params = tool_data.get('parameters', {})
                        if params and isinstance(params, dict) and params.get('properties'):
                            # Tool has parameters - use them as inputSchema
                            tool_dict["inputSchema"] = params
                            logger.debug(f"Tool {tool_dict['name']} has parameters: {list(params.get('properties', {}).keys())}")
                        else:
                            # Tool has no parameters - use empty schema
                            tool_dict["inputSchema"] = {
                                "type": "object",
                                "properties": {},
                                "description": tool_data.get('usage', '')
                            }
                        
                        tools.append(tool_dict)
                    
                    logger.info(f"Added {len(jupyter_tools_data)} tool(s) from jupyter_mcp_tools")

                    
                    logger.info(f"Returning total of {len(tools)} tools")
                    
                    response = {
                        "jsonrpc": "2.0",
                        "id": request_id,
                        "result": {
                            "tools": tools
                        }
                    }
                except Exception as e:
                    logger.error(f"Error listing tools: {e}", exc_info=True)
                    response = {
                        "jsonrpc": "2.0",
                        "id": request_id,
                        "error": {
                            "code": -32603,
                            "message": f"Internal error listing tools: {str(e)}"
                        }
                    }
            elif method == "tools/call":
                # Execute a tool
                from jupyter_mcp_server.server import mcp
                
                tool_name = params.get("name")
                tool_arguments = params.get("arguments", {})
                
                logger.info(f"Calling tool: {tool_name}")
                
                try:
                    # Check if this is a jupyter_mcp_tools tool
                    # Use the cached set of jupyter tool names from tools/list
                    if tool_name in MCPSSEHandler._jupyter_tool_names:
                        # Route to jupyter_mcp_tools extension via HTTP execute endpoint
                        logger.info(f"Routing {tool_name} to jupyter_mcp_tools extension (recognized from cache)")
                        
                        # Get server configuration from ServerApp
                        context = get_server_context()
                        if context.serverapp is not None:
                            base_url = context.serverapp.connection_url
                            token = context.serverapp.token
                            logger.info(f"Using Jupyter ServerApp connection URL: {base_url}")
                        else:
                            # Fallback to hardcoded localhost (should not happen in JUPYTER_SERVER mode)
                            port = self.settings.get('port', 8888)
                            base_url = f"http://localhost:{port}"
                            token = self.settings.get('token', None)
                            logger.warning(f"ServerApp not available, using fallback: {base_url}")
                        
                        # Use the MCPToolsClient to execute the tool
                        from jupyter_mcp_tools.client import MCPToolsClient
                        
                        try:
                            async with MCPToolsClient(base_url=base_url, token=token) as client:
                                execution_result = await client.execute_tool(
                                    tool_id=tool_name,
                                    parameters=tool_arguments
                                )
                                
                                if execution_result.get('success'):
                                    result_data = execution_result.get('result', {})
                                    result_text = str(result_data) if result_data else "Tool executed successfully"
                                    result_dict = {
                                        "content": [{
                                            "type": "text",
                                            "text": result_text
                                        }]
                                    }
                                else:
                                    error_msg = execution_result.get('error', 'Unknown error')
                                    result_dict = {
                                        "content": [{
                                            "type": "text",
                                            "text": f"Error executing tool: {error_msg}"
                                        }],
                                        "isError": True
                                    }
                        except Exception as exec_error:
                            logger.error(f"Error executing {tool_name}: {exec_error}")
                            result_dict = {
                                "content": [{
                                    "type": "text",
                                    "text": f"Failed to execute tool: {str(exec_error)}"
                                }],
                                "isError": True
                            }
                    else:
                        # Use FastMCP's call_tool method for regular tools
                        logger.info(f"Routing {tool_name} to FastMCP (not in jupyter_mcp_tools cache)")
                        result = await mcp.call_tool(tool_name, tool_arguments)
                        
                        # Handle tuple results from FastMCP
                        if isinstance(result, tuple) and len(result) >= 1:
                            # FastMCP returns (content_list, metadata_dict)
                            content_list = result[0]
                            if isinstance(content_list, list):
                                # Serialize TextContent objects to dicts
                                serialized_content = []
                                for item in content_list:
                                    if hasattr(item, 'model_dump'):
                                        serialized_item = clean_mcp_response_content(item.model_dump())
                                        serialized_content.append(serialized_item)
                                    elif hasattr(item, 'dict'):
                                        serialized_item = clean_mcp_response_content(item.dict())
                                        serialized_content.append(serialized_item)
                                    elif isinstance(item, dict):
                                        serialized_item = clean_mcp_response_content(item)
                                        serialized_content.append(serialized_item)
                                    else:
                                        serialized_content.append({"type": "text", "text": str(item)})
                                result_dict = {"content": serialized_content}
                            else:
                                result_dict = {"content": [{"type": "text", "text": str(result)}]}
                        # Convert result to dict - it's a CallToolResult with content list
                        elif hasattr(result, 'model_dump'):
                            result_dict = clean_mcp_response(result.model_dump())
                        elif hasattr(result, 'dict'):
                            result_dict = clean_mcp_response(result.dict())
                        elif hasattr(result, 'content'):
                            # Extract content directly if it has a content attribute
                            result_dict = {"content": result.content}
                        else:
                            # Last resort: check if it's already a string
                            if isinstance(result, str):
                                result_dict = {"content": [{"type": "text", "text": result}]}
                            else:
                                # If it's some other type, try to serialize it
                                result_dict = {"content": [{"type": "text", "text": str(result)}]}
                                logger.warning(f"Used fallback str() conversion for type {type(result)}")
                    
                    logger.info(f"Converted result to dict")

                    response = {
                        "jsonrpc": "2.0",
                        "id": request_id,
                        "result": result_dict
                    }
                except Exception as e:
                    logger.error(f"Error calling tool: {e}", exc_info=True)
                    response = {
                        "jsonrpc": "2.0",
                        "id": request_id,
                        "error": {
                            "code": -32603,
                            "message": f"Internal error calling tool: {str(e)}"
                        }
                    }
            elif method == "prompts/list":
                # List available prompts - return empty list if no prompts defined
                logger.info("Listing prompts...")
                response = {
                    "jsonrpc": "2.0",
                    "id": request_id,
                    "result": {
                        "prompts": []
                    }
                }
            elif method == "resources/list":
                # List available resources - return empty list if no resources defined  
                logger.info("Listing resources...")
                response = {
                    "jsonrpc": "2.0",
                    "id": request_id,
                    "result": {
                        "resources": []
                    }
                }
            else:
                # Method not supported
                response = {
                    "jsonrpc": "2.0",
                    "id": request_id,
                    "error": {
                        "code": -32601,
                        "message": f"Method not found: {method}"
                    }
                }
            
            # Send response
            self.set_header("Content-Type", "application/json")
            logger.info(f"Sending response: {json.dumps(response)[:200]}...")
            self.write(json.dumps(response))
            self.finish()
            
        except Exception as e:
            logger.error(f"Error handling MCP request: {e}", exc_info=True)
            self.set_status(500)
            self.write(json.dumps({
                "jsonrpc": "2.0",
                "id": body.get("id") if 'body' in locals() else None,
                "error": {
                    "code": -32603,
                    "message": str(e)
                }
            }))
            self.finish()


class MCPHandler(JupyterHandler):
    """Base handler for MCP endpoints with common functionality."""
    
    def get_backend(self):
        """
        Get the appropriate backend based on configuration.
        
        Returns:
            Backend instance (LocalBackend or RemoteBackend)
        """
        context = get_server_context()
        
        # Check if we should use local backend
        if context.is_local_document() or context.is_local_runtime():
            return LocalBackend(context.serverapp)
        else:
            # Use remote backend
            document_url = self.settings.get("mcp_document_url")
            document_token = self.settings.get("mcp_document_token", "")
            runtime_url = self.settings.get("mcp_runtime_url")
            runtime_token = self.settings.get("mcp_runtime_token", "")
            
            return RemoteBackend(
                document_url=document_url,
                document_token=document_token,
                runtime_url=runtime_url,
                runtime_token=runtime_token
            )
    
    def set_default_headers(self):
        """Set CORS headers for MCP clients."""
        self.set_header("Access-Control-Allow-Origin", "*")
        self.set_header("Access-Control-Allow-Methods", "GET, POST, OPTIONS")
        self.set_header("Access-Control-Allow-Headers", "Content-Type, Authorization")
    
    def options(self, *args, **kwargs):
        """Handle OPTIONS requests for CORS preflight."""
        self.set_status(204)
        self.finish()


class MCPHealthHandler(MCPHandler):
    """
    Health check endpoint.
    
    GET /mcp/healthz
    """
    
    def get(self):
        """Handle health check request."""
        context = get_server_context()
        
        health_info = {
            "status": "healthy",
            "context_type": context.context_type,
            "document_url": context.document_url or self.settings.get("mcp_document_url"),
            "runtime_url": context.runtime_url or self.settings.get("mcp_runtime_url"),
            "extension": "jupyter_mcp_server",
            "version": "0.20.0"
        }
        
        self.set_header("Content-Type", "application/json")
        self.write(json.dumps(health_info))
        self.finish()


class MCPToolsListHandler(MCPHandler):
    """
    List available MCP tools.
    
    GET /mcp/tools/list
    """
    
    async def get(self):
        """Return list of available tools dynamically from the tool registry."""
        # Import here to avoid circular dependency
        from jupyter_mcp_server.server import get_registered_tools
        
        # Get tools dynamically from the MCP server registry
        tools = await get_registered_tools()
        
        response = {
            "tools": tools,
            "count": len(tools)
        }
        
        self.set_header("Content-Type", "application/json")
        self.write(json.dumps(response))
        self.finish()


class MCPToolsCallHandler(MCPHandler):
    """
    Execute an MCP tool.
    
    POST /mcp/tools/call
    Body: {"tool_name": "...", "arguments": {...}}
    """
    
    async def post(self):
        """Handle tool execution request."""
        try:
            # Parse request body
            body = json.loads(self.request.body.decode('utf-8'))
            tool_name = body.get("tool_name")
            arguments = body.get("arguments", {})
            
            if not tool_name:
                self.set_status(400)
                self.write(json.dumps({"error": "tool_name is required"}))
                self.finish()
                return
            
            logger.info(f"Executing tool: {tool_name} with args: {arguments}")
            
            # Get backend
            backend = self.get_backend()
            
            # Execute tool based on name
            # For now, return a placeholder response
            # TODO: Implement actual tool routing
            result = await self._execute_tool(tool_name, arguments, backend)
            
            response = {
                "success": True,
                "result": result
            }
            
            self.set_header("Content-Type", "application/json")
            self.write(json.dumps(response))
            self.finish()
            
        except Exception as e:
            logger.error(f"Error executing tool: {e}", exc_info=True)
            self.set_status(500)
            self.write(json.dumps({
                "success": False,
                "error": str(e)
            }))
            self.finish()
    
    async def _execute_tool(self, tool_name: str, arguments: dict[str, Any], backend):
        """
        Route tool execution to appropriate implementation.
        
        Args:
            tool_name: Name of tool to execute
            arguments: Tool arguments
            backend: Backend instance
            
        Returns:
            Tool execution result
        """
        # TODO: Implement actual tool routing
        # For now, return a simple response
        
        if tool_name == "list_notebooks":
            notebooks = await backend.list_notebooks()
            return {"notebooks": notebooks}
        
        # Placeholder for other tools
        return f"Tool {tool_name} executed with backend {type(backend).__name__}"

```

`jupyter_mcp_server/jupyter_extension/protocol/__init__.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""MCP Protocol implementation for Jupyter Server extension"""

```

`jupyter_mcp_server/jupyter_extension/protocol/messages.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""
MCP Protocol Messages

Pydantic models for MCP protocol requests and responses to ensure consistent
API across both MCP_SERVER and JUPYTER_SERVER modes.
"""

from typing import Any, Optional, Union, Literal
from pydantic import BaseModel, Field
from mcp.types import ImageContent


# Tool execution models
class ToolRequest(BaseModel):
    """Request to execute a tool"""
    tool_name: str = Field(..., description="Name of the tool to execute")
    arguments: dict[str, Any] = Field(default_factory=dict, description="Tool arguments")
    context: Optional[dict[str, Any]] = Field(None, description="Execution context")


class ToolResponse(BaseModel):
    """Response from tool execution"""
    success: bool = Field(..., description="Whether execution was successful")
    result: Any = Field(None, description="Tool execution result")
    error: Optional[str] = Field(None, description="Error message if execution failed")


# Notebook operation models
class NotebookContentRequest(BaseModel):
    """Request to retrieve notebook content"""
    path: str = Field(..., description="Path to the notebook file")
    include_outputs: bool = Field(True, description="Include cell outputs")


class NotebookContentResponse(BaseModel):
    """Response containing notebook content"""
    path: str = Field(..., description="Notebook path")
    cells: list[dict[str, Any]] = Field(..., description="List of cells")
    metadata: dict[str, Any] = Field(default_factory=dict, description="Notebook metadata")


class NotebookListRequest(BaseModel):
    """Request to list notebooks"""
    path: Optional[str] = Field("", description="Directory path to search")
    recursive: bool = Field(True, description="Search recursively")


class NotebookListResponse(BaseModel):
    """Response containing list of notebooks"""
    notebooks: list[str] = Field(..., description="List of notebook paths")


# Cell operation models
class ReadCellsRequest(BaseModel):
    """Request to read cells from a notebook"""
    path: Optional[str] = Field(None, description="Notebook path (uses current if not specified)")
    start_index: Optional[int] = Field(None, description="Start cell index")
    end_index: Optional[int] = Field(None, description="End cell index")


class ReadCellsResponse(BaseModel):
    """Response containing cell information"""
    cells: list[dict[str, Any]] = Field(..., description="List of cell information")


class AppendCellRequest(BaseModel):
    """Request to append a cell"""
    path: Optional[str] = Field(None, description="Notebook path")
    cell_type: Literal["code", "markdown"] = Field(..., description="Cell type")
    source: Union[str, list[str]] = Field(..., description="Cell source")


class AppendCellResponse(BaseModel):
    """Response after appending a cell"""
    cell_index: int = Field(..., description="Index of the appended cell")
    message: str = Field(..., description="Success message")


class InsertCellRequest(BaseModel):
    """Request to insert a cell"""
    path: Optional[str] = Field(None, description="Notebook path")
    cell_index: int = Field(..., description="Index where to insert")
    cell_type: Literal["code", "markdown"] = Field(..., description="Cell type")
    source: Union[str, list[str]] = Field(..., description="Cell source")


class InsertCellResponse(BaseModel):
    """Response after inserting a cell"""
    cell_index: int = Field(..., description="Index of the inserted cell")
    message: str = Field(..., description="Success message")


class DeleteCellRequest(BaseModel):
    """Request to delete a cell"""
    path: Optional[str] = Field(None, description="Notebook path")
    cell_index: int = Field(..., description="Index of cell to delete")


class DeleteCellResponse(BaseModel):
    """Response after deleting a cell"""
    message: str = Field(..., description="Success message")


class OverwriteCellRequest(BaseModel):
    """Request to overwrite a cell"""
    path: Optional[str] = Field(None, description="Notebook path")
    cell_index: int = Field(..., description="Index of cell to overwrite")
    new_source: Union[str, list[str]] = Field(..., description="New cell source")


class OverwriteCellResponse(BaseModel):
    """Response after overwriting a cell"""
    message: str = Field(..., description="Success message with diff")


# Cell execution models
class ExecuteCellRequest(BaseModel):
    """Request to execute a cell"""
    path: Optional[str] = Field(None, description="Notebook path")
    cell_index: int = Field(..., description="Index of cell to execute")
    timeout_seconds: int = Field(300, description="Execution timeout in seconds")


class ExecuteCellResponse(BaseModel):
    """Response after executing a cell"""
    cell_index: int = Field(..., description="Executed cell index")
    outputs: list[Union[str, ImageContent]] = Field(..., description="Cell outputs")
    execution_count: Optional[int] = Field(None, description="Execution count")
    status: Literal["success", "error", "timeout"] = Field(..., description="Execution status")


# Kernel operation models
class ConnectNotebookRequest(BaseModel):
    """Request to connect to a notebook"""
    notebook_name: str = Field(..., description="Unique notebook identifier")
    notebook_path: str = Field(..., description="Path to notebook file")
    mode: Literal["connect", "create"] = Field("connect", description="Connection mode")
    kernel_id: Optional[str] = Field(None, description="Specific kernel ID")


class ConnectNotebookResponse(BaseModel):
    """Response after connecting to notebook"""
    message: str = Field(..., description="Success message")
    notebook_name: str = Field(..., description="Notebook identifier")
    notebook_path: str = Field(..., description="Notebook path")


class UnuseNotebookRequest(BaseModel):
    """Request to unuse from a notebook"""
    notebook_name: str = Field(..., description="Notebook identifier to disconnect")


class UnuseNotebookResponse(BaseModel):
    """Response after disconnecting"""
    message: str = Field(..., description="Success message")


class RestartNotebookRequest(BaseModel):
    """Request to restart a notebook kernel"""
    notebook_name: str = Field(..., description="Notebook identifier to restart")


class RestartNotebookResponse(BaseModel):
    """Response after restarting kernel"""
    message: str = Field(..., description="Success message")
    notebook_name: str = Field(..., description="Notebook identifier")

```

`jupyter_mcp_server/log.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""Logging Configuration for Jupyter MCP Server"""

import logging

logger = logging.getLogger(__name__)

```

`jupyter_mcp_server/models.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

from typing import Annotated, Optional, Literal
from typing import Any
from pydantic import BaseModel, Field
from jupyter_mcp_server.utils import safe_extract_outputs, normalize_cell_source


class DocumentRuntime(BaseModel):
    provider: str
    document_url: str
    document_id: str
    document_token: str
    runtime_url: str
    runtime_id: str
    runtime_token: str
    allowed_jupyter_tools: Optional[str] = None

class Cell(BaseModel):
    """Notebook cell information as returned by the MCP server"""

    index: Annotated[int,Field(default=0)]
    cell_type: Annotated[Literal["raw", "code", "markdown"],Field(default="raw")]
    source: Annotated[Any,Field(default=[])]
    metadata: Annotated[Any,Field(default={})]
    id: Annotated[str,Field(default="")]
    execution_count: Annotated[Optional[int],Field(default=None)]
    outputs: Annotated[Any,Field(default=[])]

    def get_source(self, response_format: Literal['raw','readable'] = 'readable'):
        """Get the cell source in the requested format"""
        source = normalize_cell_source(self.source)
        if response_format == 'raw':
            return source
        elif response_format == 'readable':
            return "\n".join([line.rstrip("\n") for line in source])

    def get_outputs(self, response_format : Literal["raw",'readable']='readable'):
        """Get the cell output in the requested format"""
        if response_format == "raw":
            return self.outputs
        elif response_format == "readable":
            return safe_extract_outputs(self.outputs)

    def get_overview(self)  -> str:
        """Get the cell overview(First Line and Lines)"""
        source = normalize_cell_source(self.source)
        if len(source) == 0:
            return ""
        first_line = source[0].rstrip("\n")
        if len(source) > 1:
            first_line += f"...({len(source) - 1} lines hidden)"
        return first_line


class Notebook(BaseModel):

    cells: Annotated[list[Cell],Field(default=[])]
    metadata: Annotated[dict,Field(default={})]
    nbformat: Annotated[int,Field(default=4)]
    nbformat_minor: Annotated[int,Field(default=4)]

    def __len__(self) -> int:
        """Return the number of cells in the notebook"""
        return len(self.cells)

    def __getitem__(self, key) -> Cell | list[Cell]:
        """Support indexing and slicing operations on cells"""
        return self.cells[key]

    def format_output(self, response_format: Literal["brief", "detailed"] = "brief", start_index: int = 0, limit: int = 0):
        """
        Format notebook output based on response format and range parameters.
        Args:
            response_format: Format of the response ("brief" or "detailed")
            start_index: Starting index for cell range (default: 0)
            limit: Maximum number of cells to show (default: 0 means no limit)
        Returns:
            Formatted output string
        """
        # Determine the range of cells to display
        total_cells = len(self.cells)
        if total_cells == 0:
            return "Notebook is empty"

        # Calculate end index
        end_index = total_cells if limit == 0 else min(start_index + limit, total_cells)
        cells_to_show = self.cells[start_index:end_index]
        if len(cells_to_show) == 0:
            return "No cells in the specified range"

        if response_format == "brief":
            # Generate TSV table for brief format using get_overview
            from jupyter_mcp_server.utils import format_TSV

            headers = ["Index", "Type", "Count", "First Line"]
            rows = []

            for idx, cell in enumerate(cells_to_show):
                absolute_idx = start_index + idx
                cell_type = cell.cell_type
                execution_count = cell.execution_count if cell.execution_count else 'N/A'
                overview = cell.get_overview()

                rows.append([absolute_idx, cell_type, execution_count, overview])
            
            return format_TSV(headers, rows)

        elif response_format == "detailed":
            info_list = []
            for idx, cell in enumerate(cells_to_show):
                absolute_idx = start_index + idx
                info_list.append(f"=====Cell {absolute_idx} | type: {cell.cell_type} | execution count: {cell.execution_count if cell.execution_count else 'N/A'}=====\n")
                info_list.append(cell.get_source('readable'))
                info_list.append("\n\n")

            return "\n".join(info_list)
```

`jupyter_mcp_server/notebook_manager.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""
Unified Notebook and Kernel Management Module

This module provides centralized management for Jupyter notebooks and kernels,
replacing the scattered global variable approach with a unified architecture.
"""

from typing import Dict, Any, Optional, Callable, Union
from types import TracebackType

from jupyter_nbmodel_client import NbModelClient, get_notebook_websocket_url
from jupyter_kernel_client import KernelClient

from .config import get_config


class NotebookConnection:
    """
    Context manager for Notebook connections that handles the lifecycle
    of NbModelClient instances.
    
    Note: This is only used in MCP_SERVER mode with remote Jupyter servers that have RTC enabled.
    In JUPYTER_SERVER mode (local), notebook content is accessed directly via contents_manager.
    """
    
    def __init__(self, notebook_info: Dict[str, str], is_local: bool = False):
        self.notebook_info = notebook_info
        self.is_local = is_local
        self._notebook: Optional[NbModelClient] = None
    
    async def __aenter__(self) -> NbModelClient:
        """Enter context, establish notebook connection."""
        if self.is_local:
            raise ValueError(
                "NotebookConnection cannot be used in local/JUPYTER_SERVER mode. "
                "Cell operations in local mode should use contents_manager directly to read notebook JSON files."
            )
        
        config = get_config()
        ws_url = get_notebook_websocket_url(
            server_url=self.notebook_info.get("server_url", config.document_url),
            token=self.notebook_info.get("token", config.document_token),
            path=self.notebook_info.get("path", config.document_id),
            provider=config.provider
        )
        self._notebook = NbModelClient(ws_url)
        await self._notebook.__aenter__()
        return self._notebook
    
    async def __aexit__(
        self, 
        exc_type: Optional[type], 
        exc_val: Optional[BaseException], 
        exc_tb: Optional[TracebackType]
    ) -> None:
        """Exit context, clean up connection."""
        if self._notebook:
            await self._notebook.__aexit__(exc_type, exc_val, exc_tb)


class NotebookManager:
    """
    Centralized manager for multiple notebooks and their corresponding kernels.
    
    This class replaces the global kernel variable approach with a unified
    management system that supports both single and multiple notebook scenarios.
    """
    
    def __init__(self):
        self._notebooks: Dict[str, Dict[str, Any]] = {}
        self._default_notebook_name = "default"
        self._current_notebook: Optional[str] = None  # Currently active notebook
    
    def __contains__(self, name: str) -> bool:
        """Check if a notebook is managed by this instance."""
        return name in self._notebooks
    
    def __iter__(self):
        """Iterate over notebook name, info pairs."""
        return iter(self._notebooks.items())
    
    def add_notebook(
        self, 
        name: str, 
        kernel: Union[KernelClient, Dict[str, Any]],  # Can be KernelClient or dict with kernel metadata
        server_url: Optional[str] = None,
        token: Optional[str] = None,
        path: Optional[str] = None
    ) -> None:
        """
        Add a notebook to the manager.
        
        Args:
            name: Unique identifier for the notebook
            kernel: Kernel client instance (MCP_SERVER mode) or kernel metadata dict (JUPYTER_SERVER mode)
            server_url: Jupyter server URL (optional, uses config default). Use "local" for JUPYTER_SERVER mode.
            token: Authentication token (optional, uses config default)
            path: Notebook file path (optional, uses config default)
        """
        config = get_config()
        
        # Determine if this is local (JUPYTER_SERVER) mode or HTTP (MCP_SERVER) mode
        is_local_mode = server_url == "local"
        
        self._notebooks[name] = {
            "kernel": kernel,
            "is_local": is_local_mode,
            "notebook_info": {
                "server_url": server_url or config.document_url,
                "token": token or config.document_token,
                "path": path or config.document_id
            }
        }
        
        # For backward compatibility: if this is the first notebook or it's "default",
        # set it as the current notebook
        if self._current_notebook is None or name == self._default_notebook_name:
            self._current_notebook = name
    
    def remove_notebook(self, name: str) -> bool:
        """
        Remove a notebook from the manager.
        
        Args:
            name: Notebook identifier
            
        Returns:
            True if removed successfully, False if not found
        """
        if name in self._notebooks:
            try:
                notebook_data = self._notebooks[name]
                is_local = notebook_data.get("is_local", False)
                kernel = notebook_data["kernel"]
                
                # Only stop kernel if it's an HTTP KernelClient (MCP_SERVER mode)
                # In JUPYTER_SERVER mode, kernel is just metadata, actual kernel managed elsewhere
                if not is_local and kernel and hasattr(kernel, 'stop'):
                    kernel.stop()
            except Exception:
                # Ignore errors during kernel cleanup
                pass
            finally:
                del self._notebooks[name]
                
                # If we removed the current notebook, update the current pointer
                if self._current_notebook == name:
                    # Set to another notebook if available, prefer "default" for compatibility
                    if self._default_notebook_name in self._notebooks:
                        self._current_notebook = self._default_notebook_name
                    elif self._notebooks:
                        # Set to the first available notebook
                        self._current_notebook = next(iter(self._notebooks.keys()))
                    else:
                        # No notebooks left
                        self._current_notebook = None
            return True
        return False
    
    def get_kernel(self, name: str) -> Optional[Union[KernelClient, Dict[str, Any]]]:
        """
        Get the kernel for a specific notebook.
        
        Args:
            name: Notebook identifier
            
        Returns:
            Kernel client (MCP_SERVER mode) or kernel metadata dict (JUPYTER_SERVER mode), or None if not found
        """
        if name in self._notebooks:
            return self._notebooks[name]["kernel"]
        return None
    
    def get_kernel_id(self, name: str) -> Optional[str]:
        """
        Get the kernel ID for a specific notebook.
        
        Args:
            name: Notebook identifier
            
        Returns:
            Kernel ID string or None if not found
        """
        if name in self._notebooks:
            kernel = self._notebooks[name]["kernel"]
            # Handle both KernelClient objects and kernel metadata dicts
            if isinstance(kernel, dict):
                return kernel.get("id")
            elif hasattr(kernel, 'id'):
                return kernel.id
        return None
    
    def get_notebook_path(self, name: str) -> Optional[str]:
        """
        Get the path of a notebook.
        
        Args:
            name: Notebook identifier
            
        Returns:
            Notebook path or None if not found
        """
        if name in self._notebooks:
            return self._notebooks[name]["notebook_info"].get("path")
        return None
    
    def is_local_notebook(self, name: str) -> bool:
        """
        Check if a notebook is using local (JUPYTER_SERVER) mode.
        
        Args:
            name: Notebook identifier
            
        Returns:
            True if local mode, False otherwise
        """
        if name in self._notebooks:
            return self._notebooks[name].get("is_local", False)
        return False
    
    def get_notebook_connection(self, name: str) -> NotebookConnection:
        """
        Get a context manager for notebook connection.
        
        Args:
            name: Notebook identifier
            
        Returns:
            NotebookConnection context manager
            
        Raises:
            ValueError: If notebook doesn't exist
        """
        if name not in self._notebooks:
            raise ValueError(f"Notebook '{name}' does not exist in manager")
        
        return NotebookConnection(self._notebooks[name]["notebook_info"])
    
    def restart_notebook(self, name: str) -> bool:
        """
        Restart the kernel for a specific notebook.
        
        Args:
            name: Notebook identifier
            
        Returns:
            True if restarted successfully, False otherwise
        """
        if name in self._notebooks:
            try:
                kernel = self._notebooks[name]["kernel"]
                if kernel and hasattr(kernel, 'restart'):
                    kernel.restart()
                return True
            except Exception:
                return False
        return False
    
    def is_empty(self) -> bool:
        """Check if the manager is empty (no notebooks)."""
        return len(self._notebooks) == 0
    
    def ensure_kernel_alive(self, name: str, kernel_factory: Callable[[], KernelClient]) -> KernelClient:
        """
        Ensure a kernel is alive, create if necessary.
        
        Args:
            name: Notebook identifier
            kernel_factory: Function to create a new kernel
            
        Returns:
            The alive kernel instance
        """
        kernel = self.get_kernel(name)
        if kernel is None or not hasattr(kernel, 'is_alive') or not kernel.is_alive():
            # Create new kernel
            new_kernel = kernel_factory()
            self.add_notebook(name, new_kernel)
            return new_kernel
        return kernel
    
    def set_current_notebook(self, name: str) -> bool:
        """
        Set the currently active notebook.
        
        Args:
            name: Notebook identifier
            
        Returns:
            True if set successfully, False if notebook doesn't exist
        """
        if name in self._notebooks:
            self._current_notebook = name
            return True
        return False
    
    def get_current_notebook(self) -> Optional[str]:
        """
        Get the name of the currently active notebook.
        
        Returns:
            Current notebook name or None if no active notebook
        """
        return self._current_notebook
    
    def get_current_connection(self) -> NotebookConnection:
        """
        Get the connection for the currently active notebook.
        For backward compatibility, defaults to "default" if no current notebook is set.
        
        Returns:
            NotebookConnection context manager for the current notebook
            
        Raises:
            ValueError: If no notebooks exist and no default config is available
        """
        current = self._current_notebook or self._default_notebook_name
        
        # For backward compatibility: if the requested notebook doesn't exist but we're 
        # asking for default, create a connection using the default config
        if current not in self._notebooks and current == self._default_notebook_name:
            # Return a connection using default configuration
            config = get_config()
            return NotebookConnection({
                "server_url": config.document_url,
                "token": config.document_token,
                "path": config.document_id
            })
        
        return self.get_notebook_connection(current)
    
    def get_current_notebook_path(self) -> Optional[str]:
        """
        Get the file path of the currently active notebook.
        
        Returns:
            Notebook file path or None if no active notebook
        """
        current = self._current_notebook or self._default_notebook_name
        if current in self._notebooks:
            return self._notebooks[current]["notebook_info"].get("path")
        return None
    
    def list_all_notebooks(self) -> Dict[str, Dict[str, Any]]:
        """
        Get information about all managed notebooks.
        
        Returns:
            Dictionary with notebook names as keys and their info as values
        """
        result = {}
        for name, notebook_data in self._notebooks.items():
            kernel = notebook_data["kernel"]
            notebook_info = notebook_data["notebook_info"]
            
            # Check kernel status
            kernel_status = "unknown"
            if kernel:
                try:
                    kernel_status = "alive" if hasattr(kernel, 'is_alive') and kernel.is_alive() else "dead"
                except Exception:
                    kernel_status = "error"
            else:
                kernel_status = "not_initialized"
            
            result[name] = {
                "path": notebook_info.get("path", ""),
                "kernel_status": kernel_status,
                "is_current": name == self._current_notebook
            }
        
        return result

```

`jupyter_mcp_server/server.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""
Jupyter MCP Server Layer
"""

from typing import Annotated, Literal, Optional
from pydantic import Field
from fastapi import Request
from jupyter_kernel_client import KernelClient

from mcp.server import FastMCP
from mcp.types import ImageContent, ToolAnnotations
from starlette.middleware.cors import CORSMiddleware
from starlette.applications import Starlette
from starlette.responses import JSONResponse

from jupyter_mcp_server.log import logger
from jupyter_mcp_server.models import DocumentRuntime
from jupyter_mcp_server.utils import (
    safe_extract_outputs, 
    create_kernel,
    start_kernel,
    ensure_kernel_alive,
    wait_for_kernel_idle,
    safe_notebook_operation
)
from jupyter_mcp_server.config import get_config, set_config
from jupyter_mcp_server.notebook_manager import NotebookManager
from jupyter_mcp_server.server_context import ServerContext
from jupyter_mcp_server.enroll import auto_enroll_document
from jupyter_mcp_server.tools import (
    # Tool infrastructure
    ServerMode,
    # Notebook Management
    ListNotebooksTool,
    UseNotebookTool,
    RestartNotebookTool,
    UnuseNotebookTool,
    # Cell Reading
    ReadNotebookTool,
    ReadCellTool,
    # Cell Writing
    InsertCellTool,
    OverwriteCellSourceTool,
    DeleteCellTool,
    # Cell Execution
    ExecuteCellTool,
    # Other Tools
    ExecuteCodeTool,
    ListFilesTool,
    ListKernelsTool,
    ConnectJupyterTool,
    # MCP Prompt
    JupyterCitePrompt,
)


###############################################################################
# Globals.

class FastMCPWithCORS(FastMCP):
    def streamable_http_app(self) -> Starlette:
        """Return StreamableHTTP server app with CORS middleware
        See: https://github.com/modelcontextprotocol/python-sdk/issues/187
        """
        # Get the original Starlette app
        app = super().streamable_http_app()
        
        # Add CORS middleware
        app.add_middleware(
            CORSMiddleware,
            allow_origins=["*"],  # In production, should set specific domains
            allow_credentials=True,
            allow_methods=["*"],
            allow_headers=["*"],
        )
        return app

mcp = FastMCPWithCORS(name="Jupyter MCP Server", json_response=False, stateless_http=True)
notebook_manager = NotebookManager()
server_context = ServerContext.get_instance()

def __start_kernel():
    """Start the Jupyter kernel with error handling (for backward compatibility)."""
    config = get_config()
    start_kernel(notebook_manager, config, logger)

async def __auto_enroll_document():
    """Wrapper for auto_enroll_document that uses server context."""
    await auto_enroll_document(
        config=get_config(),
        notebook_manager=notebook_manager,
        use_notebook_tool=UseNotebookTool(),
        server_context=server_context,
    )


def __ensure_kernel_alive() -> KernelClient:
    """Ensure kernel is running, restart if needed."""
    def __create_kernel() -> KernelClient:
        """Create a new kernel instance using current configuration."""
        config = get_config()
        return create_kernel(config, logger)
    current_notebook = notebook_manager.get_current_notebook() or "default"
    return ensure_kernel_alive(notebook_manager, current_notebook, __create_kernel)


###############################################################################
# Custom Routes.


@mcp.custom_route("/api/connect", ["PUT"])
async def connect(request: Request):
    """Connect to a document and a runtime from the Jupyter MCP server."""

    data = await request.json()
    
    # Log the received data for diagnostics
    # Note: set_config() will automatically normalize string "None" values
    logger.info(
        f"Connect endpoint received - runtime_url: {repr(data.get('runtime_url'))}, "
        f"document_url: {repr(data.get('document_url'))}, "
        f"provider: {data.get('provider')}"
    )

    document_runtime = DocumentRuntime(**data)

    # Clean up existing default notebook if any
    if "default" in notebook_manager:
        try:
            notebook_manager.remove_notebook("default")
        except Exception as e:
            logger.warning(f"Error stopping existing notebook during connect: {e}")

    # Update configuration with new values
    # String "None" values will be automatically normalized by set_config()
    set_config(
        provider=document_runtime.provider,
        runtime_url=document_runtime.runtime_url,
        runtime_id=document_runtime.runtime_id,
        runtime_token=document_runtime.runtime_token,
        document_url=document_runtime.document_url,
        document_id=document_runtime.document_id,
        document_token=document_runtime.document_token,
        allowed_jupyter_tools=document_runtime.allowed_jupyter_tools or "notebook_run-all-cells,notebook_get-selected-cell"
    )
    
    # Reset ServerContext to pick up new configuration
    ServerContext.reset()

    try:
        __start_kernel()
        return JSONResponse({"success": True})
    except Exception as e:
        logger.error(f"Failed to connect: {e}")
        return JSONResponse({"success": False, "error": str(e)}, status_code=500)


@mcp.custom_route("/api/stop", ["DELETE"])
async def stop(request: Request):
    try:
        current_notebook = notebook_manager.get_current_notebook() or "default"
        if current_notebook in notebook_manager:
            notebook_manager.remove_notebook(current_notebook)
        return JSONResponse({"success": True})
    except Exception as e:
        logger.error(f"Error stopping notebook: {e}")
        return JSONResponse({"success": False, "error": str(e)}, status_code=500)


@mcp.custom_route("/api/healthz", ["GET"])
async def health_check(request: Request):
    """Custom health check endpoint"""
    kernel_status = "unknown"
    try:
        current_notebook = notebook_manager.get_current_notebook() or "default"
        kernel = notebook_manager.get_kernel(current_notebook)
        if kernel:
            kernel_status = "alive" if hasattr(kernel, 'is_alive') and kernel.is_alive() else "dead"
        else:
            kernel_status = "not_initialized"
    except Exception:
        kernel_status = "error"
    return JSONResponse(
        {
            "success": True,
            "service": "jupyter-mcp-server",
            "message": "Jupyter MCP Server is running.",
            "status": "healthy",
            "kernel_status": kernel_status,
        }
    )


###############################################################################
# Tools.
###############################################################################

###############################################################################
# Server Management Tools.

@mcp.tool(
    annotations=ToolAnnotations(
        title="List Files",
        readOnlyHint=True,
    ),
)
async def list_files(
    path: Annotated[str, Field(description="The starting path to list from (empty string means root directory)")] = "",
    # Maximum depth to recurse into subdirectories, Set Max to 3 to avoid infinite recursion.
    max_depth: Annotated[int, Field(description="Maximum depth to recurse into subdirectories", ge=0, le=3)] = 1,
    start_index: Annotated[int, Field(description="Starting index for pagination (0-based)", ge=0)] = 0,
    limit: Annotated[int, Field(description="Maximum number of items to return (0 means no limit)", ge=0)] = 25,
    pattern: Annotated[str, Field(description="Glob pattern to filter file paths")] = "",
) -> Annotated[str, Field(description="Tab-separated table with columns: Path, Type, Size, Last_Modified. Includes pagination info header.")]:
    """
    List all files and directories recursively in the Jupyter server's file system.
    Used to explore the file system structure of the Jupyter server or to find specific files or directories.
    """
    return await safe_notebook_operation(
        lambda: ListFilesTool().execute(
            mode=server_context.mode,
            server_client=server_context.server_client,
            contents_manager=server_context.contents_manager,
            path=path,
            max_depth=max_depth,
            start_index=start_index,
            limit=limit,
            pattern=pattern if pattern else None,
        )
    )


@mcp.tool(
    annotations=ToolAnnotations(
        title="List Kernels",
        readOnlyHint=True,
    ),
)
async def list_kernels() -> Annotated[str, Field(description="Tab-separated table with columns: ID, Name, Display_Name, Language, State, Connections, Last_Activity, Environment")]:
    """List all available kernels in the Jupyter server.
    
    This tool shows all running and available kernel sessions on the Jupyter server,
    including their IDs, names, states, connection information, and kernel specifications.
    Useful for monitoring kernel resources and identifying specific kernels for connection.
    """
    return await safe_notebook_operation(
        lambda: ListKernelsTool().execute(
            mode=server_context.mode,
            server_client=server_context.server_client,
            kernel_manager=server_context.kernel_manager,
            kernel_spec_manager=server_context.kernel_spec_manager,
        )
    )

###############################################################################
# Multi-Notebook Management Tools.


@mcp.tool(
    annotations=ToolAnnotations(
        title="Use Notebook",
        destructiveHint=True,
    ),
)
async def use_notebook(
    notebook_name: Annotated[str, Field(description="Unique identifier for the notebook")],
    notebook_path: Annotated[str, Field(description="Path to the notebook file, relative to the Jupyter server root (e.g. 'notebook.ipynb')")],
    mode: Annotated[Literal["connect", "create"], Field(description="Notebook operation mode: 'connect' to connect to existing and activate it, 'create' to create new and activate it")] = "connect",
    kernel_id: Annotated[str, Field(description="Specific kernel ID to use (will create new if skipped)")] = None,
) -> Annotated[str, Field(description="Success message with notebook information")]:
    """Use a notebook and activate it for following cell operations.
    All cell operations will be performed on the currently activated notebook.
    Activate new notebook will deactivate the previously activated notebook.
    Reactivate previously activated notebook using same notebook_name and notebook_path.
    """
    config = get_config()
    return await safe_notebook_operation(
        lambda: UseNotebookTool().execute(
            mode=server_context.mode,
            server_client=server_context.server_client,
            notebook_name=notebook_name,
            notebook_path=notebook_path,
            use_mode=mode,
            kernel_id=kernel_id,
            ensure_kernel_alive_fn=__ensure_kernel_alive,
            contents_manager=server_context.contents_manager,
            kernel_manager=server_context.kernel_manager,
            session_manager=server_context.session_manager,
            notebook_manager=notebook_manager,
            runtime_url=config.runtime_url if config.runtime_url != "local" else None,
            runtime_token=config.runtime_token,
        )
    )


@mcp.tool(
    annotations=ToolAnnotations(
        title="List Notebooks",
        readOnlyHint=True,
    ),
)
async def list_notebooks() -> Annotated[str, Field(description="TSV formatted table with notebook information")]:
    """List all notebooks that have been used via use_notebook tool"""
    return await ListNotebooksTool().execute(
        mode=server_context.mode,
        notebook_manager=notebook_manager,
    )


@mcp.tool(
    annotations=ToolAnnotations(
        title="Restart Notebook",
        destructiveHint=True,
    ),
)
async def restart_notebook(
    notebook_name: Annotated[str, Field(description="Notebook identifier to restart")],
) -> Annotated[str, Field(description="Success message")]:
    """Restart the kernel for a specific notebook."""
    return await RestartNotebookTool().execute(
        mode=server_context.mode,
        notebook_name=notebook_name,
        notebook_manager=notebook_manager,
        kernel_manager=server_context.kernel_manager,
    )


@mcp.tool(
    annotations=ToolAnnotations(
        title="Unuse Notebook",
        destructiveHint=True,
    ),
)
async def unuse_notebook(
    notebook_name: Annotated[str, Field(description="Notebook identifier to disconnect")],
) -> Annotated[str, Field(description="Success message")]:
    """Unuse from a specific notebook and release its resources."""
    return await UnuseNotebookTool().execute(
        mode=server_context.mode,
        notebook_name=notebook_name,
        notebook_manager=notebook_manager,
        kernel_manager=server_context.kernel_manager,
    )

@mcp.tool(
    annotations=ToolAnnotations(
        title="Read Notebook",
        readOnlyHint=True,
    ),
)
async def read_notebook(
    notebook_name: Annotated[str, Field(description="Notebook identifier to read")],
    response_format: Annotated[Literal["brief", "detailed"], Field(description="Response format: 'brief' will return first line and lines number, 'detailed' will return full cell source")] = "brief",
    start_index: Annotated[int, Field(description="Starting index for pagination (0-based)", ge=0)] = 0,
    limit: Annotated[int, Field(description="Maximum number of items to return (0 means no limit)", ge=0)] = 20
) -> Annotated[str, Field(description="Notebook content in the requested format")]:
    """Read a notebook and return index, source content, type, execution count of each cell.
    
    Using brief format to get a quick overview of the notebook structure and it's useful for locating specific cells for operations like delete or insert.
    Using detailed format to get detailed information of the notebook and it's useful for debugging and analysis.

    It is recommended to use brief format with larger limit to get a overview of the notebook structure, 
    then use detailed format with exact index and limit to get the detailed information of some specific cells.
    """
    return await safe_notebook_operation(
        lambda: ReadNotebookTool().execute(
            mode=server_context.mode,
            server_client=server_context.server_client,
            contents_manager=server_context.contents_manager,
            notebook_manager=notebook_manager,
            notebook_name=notebook_name,
            response_format=response_format,
            start_index=start_index,
            limit=limit,
        )
    )

###############################################################################
# Cell Tools.

@mcp.tool(
    annotations=ToolAnnotations(
        title="Insert Cell",
        destructiveHint=True,
    ),
)
async def insert_cell(
    cell_index: Annotated[int, Field(description="Target index for insertion (0-based), use -1 to append at end", ge=-1)],
    cell_type: Annotated[Literal["code", "markdown"], Field(description="Type of cell to insert")],
    cell_source: Annotated[str, Field(description="Source content for the cell")],
) -> Annotated[str, Field(description="Success message and the structure of its surrounding cells")]:
    """Insert a cell to specified position from the currently activated notebook."""
    return await safe_notebook_operation(
        lambda: InsertCellTool().execute(
            mode=server_context.mode,
            server_client=server_context.server_client,
            contents_manager=server_context.contents_manager,
            kernel_manager=server_context.kernel_manager,
            notebook_manager=notebook_manager,
            cell_index=cell_index,
            cell_source=cell_source,
            cell_type=cell_type,
        )
    )

@mcp.tool(
    annotations=ToolAnnotations(
        title="Overwrite Cell Source",
        destructiveHint=True,
    ),
)
async def overwrite_cell_source(
    cell_index: Annotated[int, Field(description="Index of the cell to overwrite (0-based)", ge=0)],
    cell_source: Annotated[str, Field(description="New complete cell source")],
) -> Annotated[str, Field(description="Success message with diff showing changes made")]:
    """Overwrite the source of a specific cell from the currently activated notebook.
    It will return a diff style comparison (e.g. `+` for new lines, `-` for deleted lines) of the cell's content"""
    return await safe_notebook_operation(
        lambda: OverwriteCellSourceTool().execute(
            mode=server_context.mode,
            server_client=server_context.server_client,
            contents_manager=server_context.contents_manager,
            kernel_manager=server_context.kernel_manager,
            notebook_manager=notebook_manager,
            cell_index=cell_index,
            cell_source=cell_source,
        )
    )

@mcp.tool(
    annotations=ToolAnnotations(
        title="Execute Cell",
        destructiveHint=True,
    ),
)
async def execute_cell(
    cell_index: Annotated[int, Field(description="Index of the cell to execute (0-based)", ge=0)],
    timeout: Annotated[int, Field(description="Maximum seconds to wait for execution")] = 90,
    stream: Annotated[bool, Field(description="Enable streaming progress (including time indicator) updates for long-running cells")] = False,
    progress_interval: Annotated[int, Field(description="Seconds between progress updates when stream=True")] = 5,
) -> Annotated[list[str | ImageContent], Field(description="List of outputs from the executed cell")]:
    """Execute a cell from the currently activated notebook with timeout and return it's outputs"""
    return await safe_notebook_operation(
        lambda: ExecuteCellTool().execute(
            mode=server_context.mode,
            server_client=server_context.server_client,
            contents_manager=server_context.contents_manager,
            kernel_manager=server_context.kernel_manager,
            notebook_manager=notebook_manager,
            cell_index=cell_index,
            timeout_seconds=timeout,
            stream=stream,
            progress_interval=progress_interval,
            ensure_kernel_alive_fn=__ensure_kernel_alive
        ),
        max_retries=1
    )

@mcp.tool(
    annotations=ToolAnnotations(
        title="Insert and Execute Code Cell",
        destructiveHint=True,
    ),
)
async def insert_execute_code_cell(
    cell_index: Annotated[int, Field(description="Index of the cell to insert and execute (0-based)", ge=-1)],
    cell_source: Annotated[str, Field(description="Code source for the cell")],
    timeout: Annotated[int, Field(description="Maximum seconds to wait for execution")] = 90,
) -> Annotated[list[str | ImageContent], Field(description="List of outputs from the executed cell")]:
    """Insert a cell at specified index from the currently activated notebook and then execute it with timeout and return it's outputs
    It is a shortcut tool for insert_cell and execute_cell tools, recommended to use if you want to insert a cell and execute it at the same time"""
    await safe_notebook_operation(
        lambda: InsertCellTool().execute(
            mode=server_context.mode,
            server_client=server_context.server_client,
            contents_manager=server_context.contents_manager,
            kernel_manager=server_context.kernel_manager,
            notebook_manager=notebook_manager,
            cell_index=cell_index,
            cell_source=cell_source,
            cell_type="code",
        )
    )

    return await safe_notebook_operation(
        lambda: ExecuteCellTool().execute(
            mode=server_context.mode,
            server_client=server_context.server_client,
            contents_manager=server_context.contents_manager,
            kernel_manager=server_context.kernel_manager,
            notebook_manager=notebook_manager,
            cell_index=cell_index,
            timeout_seconds=timeout,
            stream=False,
            progress_interval=0,
            ensure_kernel_alive_fn=__ensure_kernel_alive
        ),
        max_retries=1
    )

@mcp.tool(
    annotations=ToolAnnotations(
        title="Read Cell",
        readOnlyHint=True,
    ),
)
async def read_cell(
    cell_index: Annotated[int, Field(description="Index of the cell to read (0-based)", ge=0)],
    include_outputs: Annotated[bool, Field(description="Include outputs in the response (only for code cells)")] = True,
) -> Annotated[list[str | ImageContent], Field(description="Cell information including index, type, source, and outputs (for code cells)")]:
    """Read a specific cell from the currently activated notebook and return it's metadata (index, type, execution count), source and outputs (for code cells)"""
    return await safe_notebook_operation(
        lambda: ReadCellTool().execute(
            mode=server_context.mode,
            server_client=server_context.server_client,
            contents_manager=server_context.contents_manager,
            notebook_manager=notebook_manager,
            cell_index=cell_index,
            include_outputs=include_outputs,
        )
    )

@mcp.tool(
    annotations=ToolAnnotations(
        title="Delete Cell",
        destructiveHint=True,
    ),
)
async def delete_cell(
    cell_indices: Annotated[list[int], Field(description="List of cell indices to delete (0-based)",min_items=1)],
    include_source: Annotated[bool, Field(description="Whether to include the source of deleted cells")] = True,
) -> Annotated[str, Field(description="Success message with list of deleted cells and their source (if include_source=True)")]:
    """Delete specific cells from the currently activated notebook and return the cell source of deleted cells (if include_source=True)."""
    return await safe_notebook_operation(
        lambda: DeleteCellTool().execute(
            mode=server_context.mode,
            server_client=server_context.server_client,
            contents_manager=server_context.contents_manager,
            kernel_manager=server_context.kernel_manager,
            notebook_manager=notebook_manager,
            cell_indices=cell_indices,
            include_source=include_source,
        )
    )


@mcp.tool(
    annotations=ToolAnnotations(
        title="Execute Code",
        destructiveHint=True,
    ),
)
async def execute_code(
    code: Annotated[str, Field(description="Code to execute (supports magic commands with %, shell commands with !)")],
    timeout: Annotated[int, Field(description="Execution timeout in seconds",le=60)] = 30,
) -> Annotated[list[str | ImageContent], Field(description="List of outputs from the executed code")]:
    """Execute code directly in the kernel (not saved to notebook) on the current activated notebook.

    Recommended to use in following cases:
    1. Execute Jupyter magic commands(e.g., `%timeit`, `%pip install xxx`)
    2. Performance profiling and debugging.
    3. View intermediate variable values(e.g., `print(xxx)`, `df.head()`)
    4. Temporary calculations and quick tests(e.g., `np.mean(df['xxx'])`)
    5. Execute Shell commands in Jupyter server(e.g., `!git xxx`)

    Under no circumstances should you use this tool to:
    1. Import new modules or perform variable assignments that affect subsequent Notebook execution
    2. Execute dangerous code that may harm the Jupyter server or the user's data without permission
    """
    # Get kernel_id for JUPYTER_SERVER mode
    # Let the tool handle getting kernel_id via get_current_notebook_context()
    kernel_id = None
    if server_context.mode == ServerMode.JUPYTER_SERVER:
        current_notebook = notebook_manager.get_current_notebook() or "default"
        kernel_id = notebook_manager.get_kernel_id(current_notebook)
        # Note: kernel_id might be None here if notebook not in manager,
        # but the tool will fall back to config values via get_current_notebook_context()
    
    return await safe_notebook_operation(
        lambda: ExecuteCodeTool().execute(
            mode=server_context.mode,
            server_client=server_context.server_client,
            kernel_manager=server_context.kernel_manager,
            notebook_manager=notebook_manager,
            code=code,
            timeout=timeout,
            kernel_id=kernel_id,
            ensure_kernel_alive_fn=__ensure_kernel_alive,
            wait_for_kernel_idle_fn=wait_for_kernel_idle,
            safe_extract_outputs_fn=safe_extract_outputs,
        ),
        max_retries=1
    )


@mcp.tool(
    annotations=ToolAnnotations(
        title="Connect to Jupyter Server",
        destructiveHint=True,
    ),
)
async def connect_to_jupyter(
    jupyter_url: Annotated[str, Field(description="Jupyter server URL to connect to (e.g., 'http://localhost:8888')")],
    jupyter_token: Annotated[Optional[str], Field(description="Jupyter server authentication token")] = None,
    provider: Annotated[str, Field(description="Provider type")] = "jupyter",
) -> Annotated[str, Field(description="Connection status message")]:
    """Connect to a Jupyter server dynamically with URL and token.
    
    This tool allows you to connect to different Jupyter servers without needing to 
    restart the MCP server or modify configuration files. Particularly useful when:
    - Working with multiple Jupyter servers with different ports/tokens
    - Jupyter server token changes dynamically
    - Need to switch between different Jupyter instances
    
    Example usage:
    - "Connect to http://localhost:8888 with token abc123"
    - "Connect to http://localhost:8889 without authentication"
    """
    return await safe_notebook_operation(
        lambda: ConnectJupyterTool().execute(
            mode=server_context.mode,
            jupyter_url=jupyter_url,
            jupyter_token=jupyter_token,
            provider=provider,
        )
    )

###############################################################################
# Prompt

@mcp.prompt()
async def jupyter_cite(
    prompt: Annotated[str, Field(description="User prompt for the cited cells")],
    cell_indices: Annotated[str, Field(description="Cell indices to cite (0-based),supporting flexible range format, e.g., '0,1,2', '0-2' or '0-2,4'")],
    notebook_name: Annotated[str, Field(description="Name of the notebook to cite cells from, default (empty) to current activated notebook")] = "",
):
    """
    Like @ or # in Coding IDE or CLI, cite specific cells from specified notebook and insert them into the prompt.
    """
    return await safe_notebook_operation(
        lambda: JupyterCitePrompt().execute(
            mode=server_context.mode,
            server_client=server_context.server_client,
            contents_manager=server_context.contents_manager,
            notebook_manager=notebook_manager,
            cell_indices=cell_indices,
            notebook_name=notebook_name,
            prompt=prompt,
        )
    )

###############################################################################
# Helper Functions for Extension.


async def get_registered_tools():
    """
    Get list of all registered MCP tools with their metadata.
    
    This function is used by the Jupyter extension to dynamically expose
    the tool registry without hardcoding tool names and parameters.
    
    For JUPYTER_SERVER mode, it queries the jupyter-mcp-tools extension.
    For MCP_SERVER mode, it uses the local FastMCP registry.
    
    Returns:
        list: List of tool dictionaries with name, description, and inputSchema
    """
    context = ServerContext.get_instance()
    mode = context._mode
    
    # For JUPYTER_SERVER mode, expose BOTH FastMCP tools AND jupyter-mcp-tools (when enabled)
    if mode == ServerMode.JUPYTER_SERVER:
        all_tools = []
        jupyter_tool_names = set()
        
        # Check if JupyterLab mode is enabled before loading jupyter-mcp-tools
        if server_context.is_jupyterlab_mode():
            logger.info("JupyterLab mode enabled, loading selected jupyter-mcp-tools")
            
            # Get tools from jupyter-mcp-tools extension with caching
            try:
                from jupyter_mcp_tools import get_tools
                from jupyter_mcp_server.tool_cache import get_tool_cache
                
                # Get the base_url and token from server context
                # In JUPYTER_SERVER mode, we should use the actual serverapp URL, not hardcoded localhost
                if server_context.serverapp is not None:
                    # Use the actual Jupyter server connection URL
                    base_url = server_context.serverapp.connection_url
                    token = server_context.serverapp.token
                    logger.info(f"Using Jupyter ServerApp connection URL: {base_url}")
                else:
                    # Fallback to configuration (for remote scenarios)
                    config = get_config()
                    base_url = config.runtime_url if config.runtime_url else "http://localhost:8888"
                    token = config.runtime_token
                    logger.info(f"Using config runtime URL: {base_url}")
                
                logger.info(f"Querying jupyter-mcp-tools at {base_url}")
                
                # Define specific tools we want to load from jupyter-mcp-tools
                # (https://github.com/datalayer/jupyter-mcp-tools)
                # jupyter-mcp-tools exposes JupyterLab commands as MCP tools.
                # Only tools listed here will be available to MCP clients.
                # To add new tools, also update the list in handlers.py and
                # see docs/docs/reference/tools-additional/index.mdx for documentation.
                config = get_config()
                allowed_jupyter_mcp_tools = config.get_allowed_jupyter_mcp_tools()
                
                # Try querying with caching to avoid expensive repeated calls
                try:
                    search_query = ",".join(allowed_jupyter_mcp_tools)
                    logger.info(f"Searching jupyter-mcp-tools with query: '{search_query}' (allowed_tools: {allowed_jupyter_mcp_tools})")
                    
                    # Use cached get_tools to avoid expensive repeated calls
                    tool_cache = get_tool_cache()
                    tools_data = await tool_cache.get_tools(
                        base_url=base_url,
                        token=token,
                        query=search_query,
                        enabled_only=False,
                        fetch_func=get_tools  # Pass the actual get_tools function for cache misses
                    )
                    logger.info(f"Query returned {len(tools_data)} tools (from cache or fresh)")
                    
                    # Use the tools directly since query should return only what we want
                    for tool in tools_data:
                        logger.info(f"Found tool: {tool.get('id', '')}")
                    
                except Exception as e:
                    logger.warning(f"Failed to load jupyter-mcp-tools: {e}")
                    tools_data = []
                
                logger.info(f"Successfully loaded {len(tools_data)} specific jupyter-mcp-tools")
                
                logger.info(f"Retrieved {len(tools_data)} tools from jupyter-mcp-tools extension")
                
                # Convert jupyter-mcp-tools format to MCP format
                for tool_data in tools_data:
                    tool_name = tool_data.get('id', '')
                    jupyter_tool_names.add(tool_name)
                    
                    # Only include MCP protocol fields (exclude internal fields like commandId)
                    tool_dict = {
                        "name": tool_name,
                        "description": tool_data.get('caption', tool_data.get('label', '')),
                    }
                    
                    # Convert parameters to inputSchema
                    # The parameters field contains the JSON Schema for the tool's arguments
                    params = tool_data.get('parameters', {})
                    if params and isinstance(params, dict) and params.get('properties'):
                        # Tool has parameters - use them as inputSchema
                        tool_dict["inputSchema"] = params
                        tool_dict["parameters"] = list(params['properties'].keys())
                        logger.debug(f"Tool {tool_dict['name']} has parameters: {tool_dict['parameters']}")
                    else:
                        # Tool has no parameters - use empty schema
                        tool_dict["parameters"] = []
                        tool_dict["inputSchema"] = {
                            "type": "object",
                            "properties": {},
                            "description": tool_data.get('usage', '')
                        }
                    
                    all_tools.append(tool_dict)
                
                logger.info(f"Converted {len(all_tools)} tool(s) from jupyter-mcp-tools with parameter schemas")
                
            except Exception as e:
                logger.error(f"Error querying jupyter-mcp-tools extension: {e}", exc_info=True)
                # Continue to add FastMCP tools even if jupyter-mcp-tools fails
        else:
            logger.info("JupyterLab mode disabled, skipping jupyter-mcp-tools integration")
        
        # Second, add FastMCP tools
        try:
            tools_list = await mcp.list_tools()
            logger.info(f"Retrieved {len(tools_list)} tools from FastMCP registry")
            
            for tool in tools_list:
                logger.info(f"Processing tool: {tool.name}, mode: {mode}")
                # Skip connect_to_jupyter tool when running as Jupyter extension
                # since it doesn't make sense to connect to a different server
                # when already running inside Jupyter
                if tool.name == "connect_to_jupyter":
                    logger.info("Skipping connect_to_jupyter tool in JUPYTER_SERVER mode")
                    continue
                    
                # Add FastMCP tool
                tool_dict = {
                    "name": tool.name,
                    "description": tool.description,
                }
                
                # Extract parameter names from inputSchema
                if hasattr(tool, 'inputSchema') and tool.inputSchema:
                    input_schema = tool.inputSchema
                    if 'properties' in input_schema:
                        tool_dict["parameters"] = list(input_schema['properties'].keys())
                    else:
                        tool_dict["parameters"] = []
                    
                    # Include full inputSchema for MCP protocol compatibility
                    tool_dict["inputSchema"] = input_schema
                else:
                    tool_dict["parameters"] = []
                
                all_tools.append(tool_dict)
            
            logger.info(f"Added {len(all_tools) - len(jupyter_tool_names)} FastMCP tool(s), total: {len(all_tools)}")
            
        except Exception as e:
            logger.error(f"Error retrieving FastMCP tools: {e}", exc_info=True)
        
        return all_tools
    
    # For MCP_SERVER mode, use local FastMCP registry
    # Use FastMCP's list_tools method which returns Tool objects
    tools_list = await mcp.list_tools()
    
    tools = []
    for tool in tools_list:
        tool_dict = {
            "name": tool.name,
            "description": tool.description,
        }
        
        # Extract parameter names from inputSchema
        if hasattr(tool, 'inputSchema') and tool.inputSchema:
            input_schema = tool.inputSchema
            if 'properties' in input_schema:
                tool_dict["parameters"] = list(input_schema['properties'].keys())
            else:
                tool_dict["parameters"] = []
            
            # Include full inputSchema for MCP protocol compatibility
            tool_dict["inputSchema"] = input_schema
        else:
            tool_dict["parameters"] = []
        
        # Include full outputSchema for MCP protocol compatibility
        if hasattr(tool, 'outputSchema') and tool.outputSchema:
            tool_dict["outputSchema"] = tool.outputSchema
        else:
            tool_dict["outputSchema"] = []
        
        tools.append(tool_dict)
    
    return tools

```

`jupyter_mcp_server/server_context.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""
Singleton to cache server mode and context managers.
"""

from jupyter_mcp_server.config import get_config
from jupyter_mcp_server.log import logger
from jupyter_mcp_server.tools import ServerMode
from jupyter_server_client import JupyterServerClient


class ServerContext:
    """Singleton to cache server mode and context managers."""
    _instance = None
    _mode = None
    _contents_manager = None
    _kernel_manager = None
    _kernel_spec_manager = None
    _session_manager = None
    _server_client = None
    _kernel_client = None
    _initialized = False
    
    @classmethod
    def get_instance(cls):
        if cls._instance is None:
            cls._instance = cls()
        return cls._instance
    
    @classmethod
    def reset(cls):
        """Reset the singleton instance. Use this when config changes."""
        if cls._instance is not None:
            cls._instance._initialized = False
            cls._instance._mode = None
            cls._instance._contents_manager = None
            cls._instance._kernel_manager = None
            cls._instance._kernel_spec_manager = None
            cls._instance._session_manager = None
            cls._instance._server_client = None
            cls._instance._kernel_client = None
    
    def initialize(self):
        """Initialize context once."""
        if self._initialized:
            return
        
        try:
            from jupyter_mcp_server.jupyter_extension.context import get_server_context
            context = get_server_context()
            
            if context.is_local_document() and context.get_contents_manager() is not None:
                self._mode = ServerMode.JUPYTER_SERVER
                self._contents_manager = context.get_contents_manager()
                self._kernel_manager = context.get_kernel_manager()
                self._kernel_spec_manager = context.get_kernel_spec_manager() if hasattr(context, 'get_kernel_spec_manager') else None
                self._session_manager = context.get_session_manager() if hasattr(context, 'get_session_manager') else None
            else:
                self._mode = ServerMode.MCP_SERVER
                # Initialize HTTP clients for MCP_SERVER mode
                config = get_config()
                
                # Validate that runtime_url is set and not None/empty
                # Note: String "None" values should have been normalized by start_command()
                runtime_url = config.runtime_url
                if not runtime_url or runtime_url in ("None", "none", "null", ""):
                    raise ValueError(
                        f"runtime_url is not configured (current value: {repr(runtime_url)}). "
                        "Please check:\n"
                        "1. RUNTIME_URL environment variable is set correctly (not the string 'None')\n"
                        "2. --runtime-url argument is provided when starting the server\n"
                        "3. The MCP client configuration passes runtime_url correctly"
                    )
                
                logger.info(f"Initializing MCP_SERVER mode with runtime_url: {runtime_url}")
                self._server_client = JupyterServerClient(base_url=runtime_url, token=config.runtime_token)
                # kernel_client will be created lazily when needed
        except (ImportError, Exception) as e:
            # If not in Jupyter context, use MCP_SERVER mode
            if not isinstance(e, ValueError):
                self._mode = ServerMode.MCP_SERVER
                # Initialize HTTP clients for MCP_SERVER mode
                config = get_config()
                
                # Validate that runtime_url is set and not None/empty
                # Note: String "None" values should have been normalized by start_command()
                runtime_url = config.runtime_url
                if not runtime_url or runtime_url in ("None", "none", "null", ""):
                    raise ValueError(
                        f"runtime_url is not configured (current value: {repr(runtime_url)}). "
                        "Please check:\n"
                        "1. RUNTIME_URL environment variable is set correctly (not the string 'None')\n"
                        "2. --runtime-url argument is provided when starting the server\n"
                        "3. The MCP client configuration passes runtime_url correctly"
                    )
                
                logger.info(f"Initializing MCP_SERVER mode with runtime_url: {runtime_url}")
                self._server_client = JupyterServerClient(base_url=runtime_url, token=config.runtime_token)
            else:
                raise
        
        self._initialized = True
        logger.info(f"Server mode initialized: {self._mode}")
    
    @property
    def mode(self):
        if not self._initialized:
            self.initialize()
        return self._mode
    
    @property
    def contents_manager(self):
        if not self._initialized:
            self.initialize()
        return self._contents_manager
    
    @property
    def kernel_manager(self):
        if not self._initialized:
            self.initialize()
        return self._kernel_manager
    
    @property
    def kernel_spec_manager(self):
        if not self._initialized:
            self.initialize()
        return self._kernel_spec_manager
    
    @property
    def session_manager(self):
        if not self._initialized:
            self.initialize()
        return self._session_manager
    
    @property
    def server_client(self):
        if not self._initialized:
            self.initialize()
        return self._server_client
    
    @property
    def kernel_client(self):
        if not self._initialized:
            self.initialize()
        return self._kernel_client
    
    def is_jupyterlab_mode(self) -> bool:
        """Check if JupyterLab mode is enabled."""
        from jupyter_mcp_server.config import get_config
        config = get_config()
        return config.is_jupyterlab_mode()
```

`jupyter_mcp_server/server_modes.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""Utility functions for detecting and handling server mode."""

from typing import Tuple, Optional, Any
from jupyter_server_client import JupyterServerClient
from jupyter_mcp_server.config import get_config


def get_server_mode_and_clients() -> Tuple[str, Optional[JupyterServerClient], Optional[Any], Optional[Any], Optional[Any]]:
    """Determine server mode and get appropriate clients/managers.
    
    Returns:
        Tuple of (mode, server_client, contents_manager, kernel_manager, kernel_spec_manager)
        - mode: "local" if using local API, "http" if using HTTP clients
        - server_client: JupyterServerClient or None
        - contents_manager: Local contents manager or None
        - kernel_manager: Local kernel manager or None  
        - kernel_spec_manager: Local kernel spec manager or None
    """
    config = get_config()
    
    # Check if we should use local API
    try:
        from jupyter_mcp_server.jupyter_extension.context import get_server_context
        context = get_server_context()
        
        if context.is_local_document() and context.get_contents_manager() is not None:
            # JUPYTER_SERVER mode with local API access
            return (
                "local",
                None,
                context.get_contents_manager(),
                context.get_kernel_manager(),
                context.get_kernel_spec_manager()
            )
    except (ImportError, Exception):
        # Context not available or error, fall through to HTTP mode
        pass
    
    # MCP_SERVER mode with HTTP clients
    server_client = JupyterServerClient(
        base_url=config.runtime_url,
        token=config.runtime_token
    )
    
    return ("http", server_client, None, None, None)


def is_local_mode() -> bool:
    """Check if running in local API mode.
    
    Returns:
        True if using local serverapp API, False if using HTTP clients
    """
    try:
        from jupyter_mcp_server.jupyter_extension.context import get_server_context
        context = get_server_context()
        return context.is_local_document() and context.get_contents_manager() is not None
    except (ImportError, Exception):
        return False

```

`jupyter_mcp_server/tool_cache.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""
Tool Cache Module

Provides caching for expensive jupyter-mcp-tools queries to improve performance.
"""

import asyncio
import time
from typing import Dict, List, Optional, Any
from dataclasses import dataclass
from jupyter_mcp_server.log import logger


@dataclass
class CacheEntry:
    """Represents a cached entry with timestamp and data."""
    data: List[Dict[str, Any]]
    timestamp: float
    
    def is_expired(self, ttl_seconds: int) -> bool:
        """Check if the cache entry has expired."""
        return time.time() - self.timestamp > ttl_seconds


class ToolCache:
    """
    Cache for jupyter-mcp-tools data with TTL support.
    
    This cache stores the complete tool data to avoid expensive get_tools() calls.
    """
    
    def __init__(self, default_ttl: int = 300):  # 5 minutes default
        """
        Initialize the tool cache.
        
        Args:
            default_ttl: Default time-to-live in seconds for cache entries
        """
        self._cache: Dict[str, CacheEntry] = {}
        self._default_ttl = default_ttl
        self._lock = asyncio.Lock()
    
    def _make_cache_key(self, base_url: str, query: str) -> str:
        """Create a cache key from the request parameters."""
        # Use a simplified key based on base_url and query
        # Don't include token for security reasons
        return f"{base_url}:{query}"
    
    async def get_tools(
        self,
        base_url: str,
        token: str,
        query: str,
        enabled_only: bool = False,
        ttl_seconds: Optional[int] = None,
        fetch_func: Optional[Any] = None
    ) -> List[Dict[str, Any]]:
        """
        Get tools from cache or fetch them if not cached/expired.
        
        Args:
            base_url: Jupyter server base URL
            token: Authentication token
            query: Search query for tools
            enabled_only: Whether to return only enabled tools
            ttl_seconds: Custom TTL for this request (overrides default)
            fetch_func: Function to call if cache miss (should be jupyter_mcp_tools.get_tools)
            
        Returns:
            List of tool dictionaries
        """
        cache_key = self._make_cache_key(base_url, query)
        ttl = ttl_seconds or self._default_ttl
        
        async with self._lock:
            # Check if we have a valid cache entry
            if cache_key in self._cache:
                entry = self._cache[cache_key]
                if not entry.is_expired(ttl):
                    logger.debug(f"Cache HIT for {cache_key} (age: {time.time() - entry.timestamp:.1f}s)")
                    return entry.data
                else:
                    logger.debug(f"Cache EXPIRED for {cache_key} (age: {time.time() - entry.timestamp:.1f}s)")
                    del self._cache[cache_key]
            else:
                logger.debug(f"Cache MISS for {cache_key}")
        
        # Cache miss or expired - fetch fresh data
        if fetch_func is None:
            logger.warning("No fetch function provided for cache miss - returning empty list")
            return []
        
        try:
            logger.info(f"Fetching fresh tools from jupyter-mcp-tools (query: '{query}')")
            fresh_data = await fetch_func(
                base_url=base_url,
                token=token,
                query=query,
                enabled_only=enabled_only
            )
            
            # Store in cache
            async with self._lock:
                self._cache[cache_key] = CacheEntry(
                    data=fresh_data,
                    timestamp=time.time()
                )
            
            logger.info(f"Cached {len(fresh_data)} tools for key {cache_key}")
            return fresh_data
            
        except Exception as e:
            logger.error(f"Failed to fetch tools from jupyter-mcp-tools: {e}")
            # Return empty list on error to prevent cascading failures
            return []
    
    async def invalidate(self, base_url: str, query: str = None):
        """
        Invalidate cache entries.
        
        Args:
            base_url: Base URL to invalidate entries for
            query: Specific query to invalidate (if None, invalidates all for base_url)
        """
        async with self._lock:
            if query is None:
                # Invalidate all entries for this base_url
                keys_to_remove = [
                    key for key in self._cache.keys() 
                    if key.startswith(f"{base_url}:")
                ]
                for key in keys_to_remove:
                    del self._cache[key]
                logger.info(f"Invalidated {len(keys_to_remove)} cache entries for {base_url}")
            else:
                # Invalidate specific entry
                cache_key = self._make_cache_key(base_url, query)
                if cache_key in self._cache:
                    del self._cache[cache_key]
                    logger.info(f"Invalidated cache entry for {cache_key}")
    
    async def clear(self):
        """Clear all cache entries."""
        async with self._lock:
            count = len(self._cache)
            self._cache.clear()
            logger.info(f"Cleared {count} cache entries")
    
    def get_cache_stats(self) -> Dict[str, Any]:
        """Get cache statistics."""
        return {
            "total_entries": len(self._cache),
            "entries": [
                {
                    "key": key,
                    "age_seconds": time.time() - entry.timestamp,
                    "expired": entry.is_expired(self._default_ttl),
                    "data_count": len(entry.data)
                }
                for key, entry in self._cache.items()
            ]
        }


# Global cache instance
_global_tool_cache = None


def get_tool_cache() -> ToolCache:
    """Get the global tool cache instance."""
    global _global_tool_cache
    if _global_tool_cache is None:
        _global_tool_cache = ToolCache(default_ttl=300)  # 5 minutes
    return _global_tool_cache
```

`jupyter_mcp_server/tools/__init__.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""Tools package for Jupyter MCP Server.

Each tool is implemented as a separate class with an execute method
that can operate in either MCP_SERVER or JUPYTER_SERVER mode.
"""

from jupyter_mcp_server.tools._base import BaseTool, ServerMode

# Import tool implementations - Notebook Management
from jupyter_mcp_server.tools.list_notebooks_tool import ListNotebooksTool
from jupyter_mcp_server.tools.restart_notebook_tool import RestartNotebookTool
from jupyter_mcp_server.tools.unuse_notebook_tool import UnuseNotebookTool
from jupyter_mcp_server.tools.use_notebook_tool import UseNotebookTool

# Import tool implementations - Cell Reading
from jupyter_mcp_server.tools.read_notebook_tool import ReadNotebookTool
from jupyter_mcp_server.tools.read_cell_tool import ReadCellTool

# Import tool implementations - Cell Writing
from jupyter_mcp_server.tools.insert_cell_tool import InsertCellTool
from jupyter_mcp_server.tools.overwrite_cell_source_tool import OverwriteCellSourceTool
from jupyter_mcp_server.tools.delete_cell_tool import DeleteCellTool

# Import tool implementations - Cell Execution
from jupyter_mcp_server.tools.execute_cell_tool import ExecuteCellTool

# Import tool implementations - Other Tools
from jupyter_mcp_server.tools.execute_code_tool import ExecuteCodeTool
from jupyter_mcp_server.tools.list_files_tool import ListFilesTool
from jupyter_mcp_server.tools.list_kernels_tool import ListKernelsTool
from jupyter_mcp_server.tools.connect_jupyter_tool import ConnectJupyterTool

# Import MCP prompt
from jupyter_mcp_server.tools.jupyter_cite_prompt import JupyterCitePrompt

__all__ = [
    "BaseTool",
    "ServerMode",
    # Notebook Management
    "ListNotebooksTool",
    "RestartNotebookTool",
    "UnuseNotebookTool",
    "UseNotebookTool",
    # Cell Reading
    "ReadNotebookTool",
    "ReadCellTool",
    # Cell Writing
    "InsertCellTool",
    "OverwriteCellSourceTool",
    "DeleteCellTool",
    # Cell Execution
    "ExecuteCellTool",
    # Other Tools
    "ExecuteCodeTool",
    "ListFilesTool",
    "ListKernelsTool",
    "ConnectJupyterTool",
    # MCP Prompt
    "JupyterCitePrompt",
]



```

`jupyter_mcp_server/tools/_base.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""Base classes and enums for MCP tools."""

from abc import ABC, abstractmethod
from enum import Enum
from typing import Any, Optional

from jupyter_server_client import JupyterServerClient
from jupyter_kernel_client import KernelClient


class ServerMode(str, Enum):
    """Enum to indicate which server mode the tool is running in."""
    MCP_SERVER = "mcp_server"
    JUPYTER_SERVER = "jupyter_server"


class BaseTool(ABC):
    """Abstract base class for all MCP tools.
    
    Each tool must implement the execute method which handles both
    MCP_SERVER mode (using HTTP clients) and JUPYTER_SERVER mode
    (using direct API access to serverapp managers).
    """
    
    def __init__(self):
        """Initialize the tool."""
        pass
    
    @abstractmethod
    async def execute(
        self,
        mode: ServerMode,
        server_client: Optional[JupyterServerClient] = None,
        kernel_client: Optional[KernelClient] = None,
        contents_manager: Optional[Any] = None,
        kernel_manager: Optional[Any] = None,
        kernel_spec_manager: Optional[Any] = None,
        **kwargs
    ) -> Any:
        """Execute the tool logic.
        
        Args:
            mode: ServerMode indicating MCP_SERVER or JUPYTER_SERVER
            server_client: JupyterServerClient for HTTP access (MCP_SERVER mode)
            kernel_client: KernelClient for kernel HTTP access (MCP_SERVER mode)
            contents_manager: Direct access to contents manager (JUPYTER_SERVER mode)
            kernel_manager: Direct access to kernel manager (JUPYTER_SERVER mode)
            kernel_spec_manager: Direct access to kernel spec manager (JUPYTER_SERVER mode)
            **kwargs: Tool-specific parameters
            
        Returns:
            Tool execution result (type varies by tool)
        """
        pass

```

`jupyter_mcp_server/tools/connect_jupyter_tool.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""Tool for dynamically connecting to Jupyter server with URL and token."""

import logging
from typing import Any, Optional

from jupyter_mcp_server.config import set_config, reset_config
from jupyter_mcp_server.tools._base import BaseTool, ServerMode

logger = logging.getLogger(__name__)


class ConnectJupyterTool(BaseTool):
    """Connect to a Jupyter server with dynamic URL and token."""
    
    async def execute(
        self,
        mode: ServerMode,
        jupyter_url: str,
        jupyter_token: Optional[str] = None,
        provider: str = "jupyter",
        **kwargs
    ) -> str:
        """Execute the connect to Jupyter server operation.
        
        Args:
            mode: ServerMode indicating MCP_SERVER or JUPYTER_SERVER
            jupyter_url: The Jupyter server URL to connect to
            jupyter_token: The Jupyter server token for authentication
            provider: Provider type (default: "jupyter")
            **kwargs: Additional keyword arguments
            
        Returns:
            Success message with connection information
        """
        
        logger.info(
            f"Connecting to Jupyter server - URL: {jupyter_url}, "
            f"Token: {'***' if jupyter_token else 'None'}"
        )
        
        try:
            # Update configuration with new connection parameters
            set_config(
                provider=provider,
                runtime_url=jupyter_url,
                runtime_token=jupyter_token,
                document_url=jupyter_url,
                document_token=jupyter_token,
            )
            
            # Reset ServerContext to pick up new configuration
            # Import here to avoid circular import issues
            from jupyter_mcp_server.server_context import ServerContext
            ServerContext.reset()
            
            # Build connection info message
            connection_info = [
                f"Successfully connected to Jupyter server: {jupyter_url}",
                f"Provider: {provider}",
            ]
            
            if jupyter_token:
                connection_info.append("Authentication: Token-based")
            else:
                connection_info.append("Authentication: None (anonymous)")
            
            return "\n".join(connection_info)
            
        except Exception as e:
            error_msg = f"Failed to connect to Jupyter server {jupyter_url}: {str(e)}"
            logger.error(error_msg)
            raise Exception(error_msg)
```

`jupyter_mcp_server/tools/delete_cell_tool.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""Delete cell tool implementation."""

from typing import Any, Optional
from pathlib import Path
import nbformat
from jupyter_server_client import JupyterServerClient
from jupyter_mcp_server.tools._base import BaseTool, ServerMode
from jupyter_mcp_server.notebook_manager import NotebookManager
from jupyter_mcp_server.utils import get_current_notebook_context, get_notebook_model, clean_notebook_outputs


class DeleteCellTool(BaseTool):
    """Tool to delete specific cells from a notebook."""

    def _get_cell_source(self, cell: Any) -> str:
        """Get the cell source from the cell"""
        cell_source = cell.get("source", "")
        if isinstance(cell_source, list):
            return "".join(cell_source)
        else:
            return str(cell_source)

    async def _delete_cell_ydoc(
        self,
        serverapp: Any,
        notebook_path: str,
        cell_indices: list[int]
    ) -> list:
        """Delete cell using YDoc (collaborative editing mode).
        
        Args:
            serverapp: Jupyter ServerApp instance
            notebook_path: Path to the notebook
            cell_indices: List of indices of cells to delete
            
        Returns:
            NotebookNode
        """
        nb = await get_notebook_model(serverapp, notebook_path)
        if nb:
            if max(cell_indices) >= len(nb):
                raise ValueError(
                    f"Cell index {max(cell_indices)} is out of range. Notebook has {len(nb)} cells."
                )
            
            cells = nb.delete_many_cells(cell_indices)
            return cells
        else:
            # YDoc not available, use file operations
            return await self._delete_cell_file(notebook_path, cell_indices)
    
    async def _delete_cell_file(
        self,
        notebook_path: str,
        cell_indices: list[int]
    ) -> list:
        """Delete cell using file operations (non-collaborative mode).
        
        Args:
            notebook_path: Absolute path to the notebook
            cell_indices: List of indices of cells to delete
            
        Returns:
            List of deleted cells
        """
        # Read notebook file as version 4 for consistency
        with open(notebook_path, "r", encoding="utf-8") as f:
            notebook = nbformat.read(f, as_version=4)
        
        clean_notebook_outputs(notebook)
        
        if max(cell_indices) >= len(notebook.cells):
            raise ValueError(
                f"Cell index {max(cell_indices)} is out of range. Notebook has {len(notebook.cells)} cells."
            )
        
        deleted_cells = []
        for cell_index in cell_indices:
            cell = notebook.cells[cell_index]
            result = {
                "index": cell_index,
                "cell_type": cell.cell_type,
                "source": self._get_cell_source(cell),
            }
            deleted_cells.append(result)
        
        # Delete the cell
        for cell_index in sorted(cell_indices, reverse=True):
            notebook.cells.pop(cell_index)
        
        # Write back to file
        with open(notebook_path, "w", encoding="utf-8") as f:
            nbformat.write(notebook, f)
        
        return deleted_cells
    
    async def _delete_cell_websocket(
        self,
        notebook_manager: NotebookManager,
        cell_indices: list[int]
    ) -> list:
        """Delete cell using WebSocket connection (MCP_SERVER mode).
        
        Args:
            notebook_manager: Notebook manager instance
            cell_indices: List of indices of cells to delete
            
        Returns:
            List of deleted cell information
        """
        async with notebook_manager.get_current_connection() as notebook:
            if max(cell_indices) >= len(notebook):
                raise ValueError(
                    f"Cell index {max(cell_indices)} is out of range. Notebook has {len(notebook)} cells."
                )

            cells = notebook.delete_many_cells(cell_indices)
            return cells
    
    async def execute(
        self,
        mode: ServerMode,
        server_client: Optional[JupyterServerClient] = None,
        kernel_client: Optional[Any] = None,
        contents_manager: Optional[Any] = None,
        kernel_manager: Optional[Any] = None,
        kernel_spec_manager: Optional[Any] = None,
        notebook_manager: Optional[NotebookManager] = None,
        # Tool-specific parameters
        cell_indices: list[int] = None,
        include_source: bool = True,
        **kwargs
    ) -> str:
        """Execute the delete_cell tool.
        
        This tool supports three modes of operation:
        
        1. JUPYTER_SERVER mode with YDoc (collaborative):
           - Checks if notebook is open in a collaborative session
           - Uses YDoc for real-time collaborative editing
           - Changes are immediately visible to all connected users
           
        2. JUPYTER_SERVER mode without YDoc (file-based):
           - Falls back to direct file operations using nbformat
           - Suitable when notebook is not actively being edited
           
        3. MCP_SERVER mode (WebSocket):
           - Uses WebSocket connection to remote Jupyter server
           - Accesses YDoc through NbModelClient
        
        Args:
            mode: Server mode (MCP_SERVER or JUPYTER_SERVER)
            server_client: HTTP client for MCP_SERVER mode
            contents_manager: Direct API access for JUPYTER_SERVER mode
            notebook_manager: Notebook manager instance
            cell_index: Index of the cell to delete (0-based)
            **kwargs: Additional parameters
            
        Returns:
            Success message
        """
        if mode == ServerMode.JUPYTER_SERVER and contents_manager is not None:
            # JUPYTER_SERVER mode: Try YDoc first, fall back to file operations
            from jupyter_mcp_server.jupyter_extension.context import get_server_context
            
            context = get_server_context()
            serverapp = context.serverapp
            notebook_path, _ = get_current_notebook_context(notebook_manager)

            # Resolve to absolute path
            if serverapp and not Path(notebook_path).is_absolute():
                root_dir = serverapp.root_dir
                notebook_path = str(Path(root_dir) / notebook_path)
            
            if serverapp:
                # Try YDoc approach first
                cells = await self._delete_cell_ydoc(serverapp, notebook_path, cell_indices)
            else:
                # Fall back to file operations
                cells = await self._delete_cell_file(notebook_path, cell_indices)
                
        elif mode == ServerMode.MCP_SERVER and notebook_manager is not None:
            # MCP_SERVER mode: Use WebSocket connection
            cells = await self._delete_cell_websocket(notebook_manager, cell_indices)
        else:
            raise ValueError(f"Invalid mode or missing required clients: mode={mode}")
        
        info_list = []
        for cell_index, cell_info in zip(cell_indices, cells):
            info_list.append(f"Cell {cell_index} ({cell_info['cell_type']}) deleted successfully.")
            if include_source:
                info_list.append(f"deleted cell source:\n{cell_info['source']}")
                info_list.append("\n---\n")
        
        return "\n".join(info_list)

```

`jupyter_mcp_server/tools/execute_cell_tool.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""Unified execute cell tool with configurable streaming."""

import asyncio
import logging
import time
import nbformat
from pathlib import Path
from typing import Union, List
from mcp.types import ImageContent

from jupyter_mcp_server.tools._base import BaseTool, ServerMode
from jupyter_mcp_server.utils import (
    get_current_notebook_context,
    execute_via_execution_stack,
    safe_extract_outputs,
    get_jupyter_ydoc,
    clean_notebook_outputs,
    wait_for_kernel_idle,
    safe_extract_outputs,
    execute_cell_with_forced_sync,
    extract_output
)

logger = logging.getLogger(__name__)


class ExecuteCellTool(BaseTool):
    """Execute a cell with configurable timeout and optional streaming progress updates"""

    async def _write_outputs_to_cell(
        self,
        notebook_path: str,
        cell_index: int,
        outputs: List[Union[str, ImageContent]]
    ):
        """Write execution outputs back to a notebook cell."""

        with open(notebook_path, 'r', encoding='utf-8') as f:
            notebook = nbformat.read(f, as_version=4)

        clean_notebook_outputs(notebook)

        # Handle negative indices (e.g., -1 for last cell)
        num_cells = len(notebook.cells)
        if cell_index < 0:
            cell_index = num_cells + cell_index
        
        if cell_index < 0 or cell_index >= num_cells:
            logger.warning(f"Cell index {cell_index} out of range (notebook has {num_cells} cells), cannot write outputs")
            return

        cell = notebook.cells[cell_index]
        if cell.cell_type != 'code':
            logger.warning(f"Cell {cell_index} is not a code cell, cannot write outputs")
            return

        # Convert formatted outputs to nbformat structure
        cell.outputs = []
        for output in outputs:
            if isinstance(output, ImageContent):
                cell.outputs.append(nbformat.v4.new_output(
                    output_type='display_data',
                    data={output.mimeType: output.data},
                    metadata={}
                ))
            elif isinstance(output, str):
                if output.startswith('[ERROR:') or output.startswith('[TIMEOUT ERROR:') or output.startswith('[PROGRESS:'):
                    cell.outputs.append(nbformat.v4.new_output(
                        output_type='stream',
                        name='stdout',
                        text=output
                    ))
                else:
                    cell.outputs.append(nbformat.v4.new_output(
                        output_type='execute_result',
                        data={'text/plain': output},
                        metadata={},
                        execution_count=None
                    ))

        # Update execution count
        max_count = 0
        for c in notebook.cells:
            if c.cell_type == 'code' and c.execution_count:
                max_count = max(max_count, c.execution_count)
        cell.execution_count = max_count + 1

        with open(notebook_path, 'w', encoding='utf-8') as f:
            nbformat.write(notebook, f)

        logger.info(f"Wrote {len(outputs)} outputs to cell {cell_index} in {notebook_path}")

    async def execute(
        self,
        mode: ServerMode,
        server_client=None,
        contents_manager=None,
        kernel_manager=None,
        kernel_spec_manager=None,
        notebook_manager=None,
        serverapp=None,
        # Tool-specific parameters
        cell_index: int = None,
        timeout_seconds: int = 60,
        stream: bool = False,
        progress_interval: int = 5,
        ensure_kernel_alive_fn=None,
        **kwargs
    ) -> List[Union[str, ImageContent]]:
        """Execute a cell with configurable timeout and optional streaming progress updates.

        Args:
            mode: Server mode (MCP_SERVER or JUPYTER_SERVER)
            serverapp: ServerApp instance for JUPYTER_SERVER mode
            kernel_manager: Kernel manager for JUPYTER_SERVER mode
            notebook_manager: Notebook manager for MCP_SERVER mode
            cell_index: Index of the cell to execute (0-based)
            timeout_seconds: Maximum seconds to wait for execution
            stream: Enable streaming progress updates for long-running cells
            progress_interval: Seconds between progress updates when stream=True
            ensure_kernel_alive_fn: Function to ensure kernel is alive (MCP_SERVER)

        Returns:
            List of outputs from the executed cell
        """
        if mode == ServerMode.JUPYTER_SERVER:
            # JUPYTER_SERVER mode: Use ExecutionStack with YDoc awareness
            from jupyter_mcp_server.jupyter_extension.context import get_server_context

            context = get_server_context()
            serverapp = context.serverapp

            if serverapp is None:
                raise ValueError("serverapp is required for JUPYTER_SERVER mode")
            if kernel_manager is None:
                raise ValueError("kernel_manager is required for JUPYTER_SERVER mode")

            # Get notebook_path and kernel_id first
            notebook_path, kernel_id = get_current_notebook_context(notebook_manager)

            # Resolve to absolute path
            if notebook_path and serverapp and not Path(notebook_path).is_absolute():
                root_dir = serverapp.root_dir
                notebook_path = str(Path(root_dir) / notebook_path)

            # Check if kernel needs to be started
            if kernel_id is None:
                # No kernel available - start a new one on demand
                logger.info("No kernel_id available, starting new kernel for execute_cell")
                kernel_id = await kernel_manager.start_kernel()

                # Wait a bit for kernel to initialize
                await asyncio.sleep(1.0)
                logger.info(f"Kernel {kernel_id} started and initialized")

                # Store the kernel in notebook_manager if available
                if notebook_manager is not None:
                    kernel_info = {"id": kernel_id}
                    notebook_manager.add_notebook(
                        name=notebook_path,
                        kernel=kernel_info,
                        server_url="local",
                        path=notebook_path
                    )

            logger.info(f"Executing cell {cell_index} in JUPYTER_SERVER mode (timeout: {timeout_seconds}s)")

            # Get file_id from file_id_manager
            file_id_manager = serverapp.web_app.settings.get("file_id_manager")
            if file_id_manager is None:
                raise RuntimeError("file_id_manager not available in serverapp")

            file_id = file_id_manager.get_id(notebook_path)
            if file_id is None:
                file_id = file_id_manager.index(notebook_path)

            # Try to get YDoc if notebook is open
            ydoc = await get_jupyter_ydoc(serverapp, file_id)

            if ydoc:
                # Notebook is open - use YDoc and RTC
                logger.info(f"Notebook {file_id} is open, using RTC mode")
                
                num_cells = len(ydoc.ycells)
                if cell_index >= num_cells:
                    raise ValueError(f"Cell index {cell_index} out of range (notebook has {num_cells} cells)")

                cell_id = ydoc.ycells[cell_index].get("id")
                cell_source = ydoc.ycells[cell_index].get("source")

                if isinstance(cell_source, str):
                    code_to_execute = cell_source
                else:
                    code_to_execute = cell_source.to_py()

                if not code_to_execute or not code_to_execute.strip():
                    return []

                document_id = f"json:notebook:{file_id}"

                # Execute with RTC metadata - outputs will sync automatically
                outputs = await execute_via_execution_stack(
                    serverapp=serverapp,
                    kernel_id=kernel_id,
                    code=code_to_execute,
                    document_id=document_id,
                    cell_id=cell_id,
                    timeout=timeout_seconds
                )

                return outputs
            else:
                # Notebook not open - use file-based approach
                logger.info(f"Notebook {file_id} not open, using file mode")

                with open(notebook_path, 'r', encoding='utf-8') as f:
                    notebook = nbformat.read(f, as_version=4)

                num_cells = len(notebook.cells)
                if cell_index >= num_cells:
                    raise ValueError(f"Cell index {cell_index} out of range (notebook has {num_cells} cells)")

                cell = notebook.cells[cell_index]
                if cell.cell_type != 'code':
                    raise ValueError(f"Cell {cell_index} is not a code cell")

                code_to_execute = cell.source
                if not code_to_execute.strip():
                    return []

                # Execute without RTC metadata
                outputs = await execute_via_execution_stack(
                    serverapp=serverapp,
                    kernel_id=kernel_id,
                    code=code_to_execute,
                    timeout=timeout_seconds
                )

                # Write outputs back to file
                await self._write_outputs_to_cell(notebook_path, cell_index, outputs)

                return outputs

        elif mode == ServerMode.MCP_SERVER:
            kernel = ensure_kernel_alive_fn()
            await wait_for_kernel_idle(kernel, max_wait_seconds=30)

            async with notebook_manager.get_current_connection() as notebook:
                num_cells = len(notebook)
                if cell_index >= num_cells:
                    raise ValueError(f"Cell index {cell_index} out of range (notebook has {num_cells} cells)")

                if stream:
                    # Streaming mode: Real-time monitoring with progress updates
                    logger.info(f"Executing cell {cell_index} in streaming mode (timeout: {timeout_seconds}s, interval: {progress_interval}s)")

                    outputs_log = []

                    # Start execution in background
                    execution_task = asyncio.create_task(
                        asyncio.to_thread(notebook.execute_cell, cell_index, kernel)
                    )

                    start_time = time.time()
                    last_output_count = 0

                    # Monitor progress
                    while not execution_task.done():
                        elapsed = time.time() - start_time

                        # Check timeout
                        if elapsed > timeout_seconds:
                            execution_task.cancel()
                            outputs_log.append(f"[TIMEOUT at {elapsed:.1f}s: Cancelling execution]")
                            try:
                                kernel.interrupt()
                                outputs_log.append("[Sent interrupt signal to kernel]")
                            except Exception:
                                pass
                            break

                        # Check for new outputs
                        try:
                            current_outputs = notebook[cell_index].get("outputs", [])
                            if len(current_outputs) > last_output_count:
                                new_outputs = current_outputs[last_output_count:]
                                for output in new_outputs:
                                    extracted = extract_output(output)
                                    if isinstance(extracted, str):
                                        outputs_log.append(f"[{elapsed:.1f}s] {extracted}")
                                    else:
                                        outputs_log.append(f"[{elapsed:.1f}s]")
                                        outputs_log.append(extracted)
                                last_output_count = len(current_outputs)

                        except Exception as e:
                            outputs_log.append(f"[{elapsed:.1f}s] Error checking outputs: {e}")

                        # Progress update
                        if int(elapsed) % progress_interval == 0 and elapsed > 0:
                            outputs_log.append(f"[PROGRESS: {elapsed:.1f}s elapsed, {last_output_count} outputs so far]")

                        await asyncio.sleep(1)

                    # Get final result
                    if not execution_task.cancelled():
                        try:
                            await execution_task
                            final_outputs = notebook[cell_index].get("outputs", [])
                            outputs_log.append(f"[COMPLETED in {time.time() - start_time:.1f}s]")

                            # Add any final outputs not captured during monitoring
                            if len(final_outputs) > last_output_count:
                                remaining = final_outputs[last_output_count:]
                                for output in remaining:
                                    extracted = extract_output(output)
                                    if extracted.strip():
                                        outputs_log.append(extracted)

                        except Exception as e:
                            outputs_log.append(f"[ERROR: {e}]")

                    return outputs_log if outputs_log else ["[No output generated]"]

                else:
                    # Non-streaming mode: Use forced synchronization
                    logger.info(f"Starting execution of cell {cell_index} with {timeout_seconds}s timeout")

                    try:
                        # Use the forced sync function
                        await execute_cell_with_forced_sync(notebook, cell_index, kernel, timeout_seconds)

                        # Get final outputs
                        outputs = notebook[cell_index].get("outputs", [])
                        result = safe_extract_outputs(outputs)

                        logger.info(f"Cell {cell_index} completed successfully with {len(result)} outputs")
                        return result

                    except asyncio.TimeoutError as e:
                        logger.error(f"Cell {cell_index} execution timed out: {e}")
                        try:
                            if kernel and hasattr(kernel, 'interrupt'):
                                kernel.interrupt()
                                logger.info("Sent interrupt signal to kernel")
                        except Exception as interrupt_err:
                            logger.error(f"Failed to interrupt kernel: {interrupt_err}")

                        # Return partial outputs if available
                        try:
                            outputs = notebook[cell_index].get("outputs", [])
                            partial_outputs = safe_extract_outputs(outputs)
                            partial_outputs.append(f"[TIMEOUT ERROR: Execution exceeded {timeout_seconds} seconds]")
                            return partial_outputs
                        except Exception:
                            pass

                        return [f"[TIMEOUT ERROR: Cell execution exceeded {timeout_seconds} seconds and was interrupted]"]

                    except Exception as e:
                        logger.error(f"Error executing cell {cell_index}: {e}")
                        raise
        else:
            raise ValueError(f"Invalid mode: {mode}")

```

`jupyter_mcp_server/tools/execute_code_tool.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""Execute IPython code directly in kernel tool."""

import asyncio
import logging
from typing import Union

from mcp.types import ImageContent

from jupyter_mcp_server.tools._base import BaseTool, ServerMode
from jupyter_mcp_server.notebook_manager import NotebookManager

logger = logging.getLogger(__name__)


class ExecuteCodeTool(BaseTool):
    """Execute code directly in the kernel on the current active notebook"""
    
    async def _execute_via_kernel_manager(
        self,
        kernel_manager,
        kernel_id: str,
        code: str,
        timeout: int,
        safe_extract_outputs_fn
    ) -> list[Union[str, ImageContent]]:
        """Execute code using kernel_manager (JUPYTER_SERVER mode).
        
        Uses execute_code_local which handles ZMQ message collection properly.
        """
        from jupyter_mcp_server.utils import execute_code_local
        
        # Get serverapp from kernel_manager
        serverapp = kernel_manager.parent
        
        # Use centralized execute_code_local function
        return await execute_code_local(
            serverapp=serverapp,
            notebook_path="",  # Not needed for execute_code
            code=code,
            kernel_id=kernel_id,
            timeout=timeout,
            logger=logger
        )
    
    async def _execute_via_notebook_manager(
        self,
        notebook_manager: NotebookManager,
        code: str,
        timeout: int,
        ensure_kernel_alive_fn,
        wait_for_kernel_idle_fn,
        safe_extract_outputs_fn
    ) -> list[Union[str, ImageContent]]:
        """Execute code using notebook_manager (MCP_SERVER mode - original logic)."""
        # Get current notebook name and kernel
        current_notebook = notebook_manager.get_current_notebook() or "default"
        kernel = notebook_manager.get_kernel(current_notebook)
        
        if not kernel:
            # Ensure kernel is alive
            kernel = ensure_kernel_alive_fn()
        
        # Wait for kernel to be idle before executing
        await wait_for_kernel_idle_fn(kernel, max_wait_seconds=30)
        
        logger.info(f"Executing IPython code (MCP_SERVER) with timeout {timeout}s: {code[:100]}...")
        
        try:
            # Execute code directly with kernel
            execution_task = asyncio.create_task(
                asyncio.to_thread(kernel.execute, code)
            )
            
            # Wait for execution with timeout
            try:
                outputs = await asyncio.wait_for(execution_task, timeout=timeout)
            except asyncio.TimeoutError:
                execution_task.cancel()
                try:
                    if kernel and hasattr(kernel, 'interrupt'):
                        kernel.interrupt()
                        logger.info("Sent interrupt signal to kernel due to timeout")
                except Exception as interrupt_err:
                    logger.error(f"Failed to interrupt kernel: {interrupt_err}")
                
                return [f"[TIMEOUT ERROR: IPython execution exceeded {timeout} seconds and was interrupted]"]
            
            # Process and extract outputs
            if outputs:
                result = safe_extract_outputs_fn(outputs['outputs'])
                logger.info(f"IPython execution completed successfully with {len(result)} outputs")
                return result
            else:
                return ["[No output generated]"]
                
        except Exception as e:
            logger.error(f"Error executing IPython code: {e}")
            return [f"[ERROR: {str(e)}]"]
    
    async def execute(
        self,
        mode: ServerMode,
        server_client=None,
        contents_manager=None,
        kernel_manager=None,
        kernel_spec_manager=None,
        notebook_manager=None,
        # Tool-specific parameters
        code: str = None,
        timeout: int = 60,
        kernel_id: str = None,
        ensure_kernel_alive_fn=None,
        wait_for_kernel_idle_fn=None,
        safe_extract_outputs_fn=None,
        **kwargs
    ) -> list[Union[str, ImageContent]]:
        """Execute IPython code directly in the kernel.
        
        Args:
            mode: Server mode (MCP_SERVER or JUPYTER_SERVER)
            server_client: JupyterServerClient (not used)
            contents_manager: Contents manager (not used)
            kernel_manager: Kernel manager (for JUPYTER_SERVER mode)
            kernel_spec_manager: Kernel spec manager (not used)
            notebook_manager: Notebook manager (for MCP_SERVER mode)
            code: IPython code to execute (supports magic commands, shell commands with !, and Python code)
            timeout: Execution timeout in seconds (default: 60s)
            kernel_id: Kernel ID (for JUPYTER_SERVER mode)
            ensure_kernel_alive_fn: Function to ensure kernel is alive (for MCP_SERVER mode)
            wait_for_kernel_idle_fn: Function to wait for kernel idle state (for MCP_SERVER mode)
            safe_extract_outputs_fn: Function to safely extract outputs
            
        Returns:
            List of outputs from the executed code
        """
        if safe_extract_outputs_fn is None:
            raise ValueError("safe_extract_outputs_fn is required")
        
        # JUPYTER_SERVER mode: Use kernel_manager directly
        if mode == ServerMode.JUPYTER_SERVER and kernel_manager is not None:
            if kernel_id is None:
                # Try to get kernel_id from context
                from jupyter_mcp_server.utils import get_current_notebook_context
                _, kernel_id = get_current_notebook_context(notebook_manager)
            
            if kernel_id is None:
                # No kernel available - start a new one on demand
                logger.info("No kernel_id available, starting new kernel for execute_code")
                kernel_id = await kernel_manager.start_kernel()
                
                # Store the kernel in notebook_manager if available
                if notebook_manager is not None:
                    default_notebook = "default"
                    kernel_info = {"id": kernel_id}
                    notebook_manager.add_notebook(
                        default_notebook,
                        kernel_info,
                        server_url="local",
                        token=None,
                        path="notebook.ipynb"  # Placeholder path
                    )
                    notebook_manager.set_current_notebook(default_notebook)
            
            logger.info(f"Executing IPython in JUPYTER_SERVER mode with kernel_id={kernel_id}")
            return await self._execute_via_kernel_manager(
                kernel_manager=kernel_manager,
                kernel_id=kernel_id,
                code=code,
                timeout=timeout,
                safe_extract_outputs_fn=safe_extract_outputs_fn
            )
        
        # MCP_SERVER mode: Use notebook_manager (original behavior)
        elif mode == ServerMode.MCP_SERVER and notebook_manager is not None:
            if ensure_kernel_alive_fn is None:
                raise ValueError("ensure_kernel_alive_fn is required for MCP_SERVER mode")
            if wait_for_kernel_idle_fn is None:
                raise ValueError("wait_for_kernel_idle_fn is required for MCP_SERVER mode")
            
            logger.info("Executing IPython in MCP_SERVER mode")
            return await self._execute_via_notebook_manager(
                notebook_manager=notebook_manager,
                code=code,
                timeout=timeout,
                ensure_kernel_alive_fn=ensure_kernel_alive_fn,
                wait_for_kernel_idle_fn=wait_for_kernel_idle_fn,
                safe_extract_outputs_fn=safe_extract_outputs_fn
            )
        
        else:
            return [f"[ERROR: Invalid mode or missing required managers]"]


```

`jupyter_mcp_server/tools/insert_cell_tool.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""Insert cell tool implementation."""

from typing import Any, Optional, Literal
from pathlib import Path
import nbformat
from jupyter_server_client import JupyterServerClient
from jupyter_mcp_server.tools._base import BaseTool, ServerMode
from jupyter_mcp_server.notebook_manager import NotebookManager
from jupyter_mcp_server.utils import get_current_notebook_context, get_notebook_model, clean_notebook_outputs
from jupyter_mcp_server.models import Notebook



class InsertCellTool(BaseTool):
    """Tool to insert a cell at a specified position."""
    
    def _validate_cell_insertion_params(
        self,
        cell_index: int,
        total_cells: int,
        cell_type: str
    ) -> int:
        """Validate and normalize cell insertion parameters.
        
        Args:
            cell_index: Target index for insertion (-1 for append)
            total_cells: Total number of cells in the notebook
            cell_type: Type of cell to insert
            
        Returns:
            Normalized actual_index for insertion
            
        Raises:
            IndexError: When cell_index is out of valid range
            ValueError: When cell_type is invalid
        """
        if cell_index < -1 or cell_index > total_cells:
            raise IndexError(
                f"Index {cell_index} is outside valid range [-1, {total_cells}]. "
                f"Use -1 to append at end."
            )
        
        # Normalize -1 to append position
        actual_index = cell_index if cell_index != -1 else total_cells
        return actual_index
    
    async def _insert_cell_ydoc(
        self,
        serverapp: Any,
        notebook_path: str,
        cell_index: int,
        cell_type: Literal["code", "markdown"],
        cell_source: str
    ) -> tuple[Notebook, int, int]:
        """Insert cell using YDoc (collaborative editing mode).
        
        Args:
            serverapp: Jupyter ServerApp instance
            notebook_path: Path to the notebook
            cell_index: Index to insert at (-1 for append)
            cell_type: Type of cell to insert ("code", "markdown")
            cell_source: Source content for the cell
            
        Returns:
            Tuple of (notebook, actual_index, total_cells_after_insertion)
            
        Raises:
            IndexError: When cell_index is out of range
        """
        nb = await get_notebook_model(serverapp, notebook_path)
        
        if nb:
            # Notebook is open in collaborative mode, use YDoc
            total_cells = len(nb)
            
            # Validate insertion parameters
            actual_index = self._validate_cell_insertion_params(
                cell_index, total_cells, cell_type
            )
            
            nb.insert_cell(actual_index, cell_source, cell_type)
            
            return Notebook(**nb.as_dict()), actual_index, len(nb)
        else:
            # YDoc not available, use file operations
            return await self._insert_cell_file(notebook_path, cell_index, cell_type, cell_source)
    
    async def _insert_cell_file(
        self,
        notebook_path: str,
        cell_index: int,
        cell_type: Literal["code", "markdown"],
        cell_source: str
    ) -> tuple[Notebook, int, int]:
        """Insert cell using file operations (non-collaborative mode).
                
        Args:
            notebook_path: Absolute path to the notebook
            cell_index: Index to insert at (-1 for append)
            cell_type: Type of cell to insert ("code", "markdown")
            cell_source: Source content for the cell
            
        Returns:
            Tuple of (notebook, actual_index, total_cells_after_insertion)
            
        Raises:
            IndexError: When cell_index is out of range
            ValueError: When cell_type is invalid
        """
        # Read notebook file
        with open(notebook_path, "r", encoding="utf-8") as f:
            # Read as version 4 (latest) to ensure consistency and support for cell IDs
            notebook = nbformat.read(f, as_version=4)
        
        # Clean any transient fields from existing outputs (kernel protocol field not in nbformat schema)
        clean_notebook_outputs(notebook)
        
        total_cells = len(notebook.cells)
        
        # Validate insertion parameters
        actual_index = self._validate_cell_insertion_params(
            cell_index, total_cells, cell_type
        )
        
        # Create and insert the cell using unified method
         # Create and insert the cell
        if cell_type == "code":
            new_cell = nbformat.v4.new_code_cell(source=cell_source or "")
        elif cell_type == "markdown":
            new_cell = nbformat.v4.new_markdown_cell(source=cell_source or "")
        notebook.cells.insert(actual_index, new_cell)
        
        # Write back to file
        with open(notebook_path, "w", encoding="utf-8") as f:
            nbformat.write(notebook, f)
        
        notebook = Notebook(**notebook)
        
        return notebook, actual_index, len(notebook.cells)
    
    async def _insert_cell_websocket(
        self,
        notebook_manager: NotebookManager,
        cell_index: int,
        cell_type: Literal["code", "markdown"],
        cell_source: str
    ) -> tuple[Notebook, int, int]:
        """Insert cell using WebSocket connection (MCP_SERVER mode).
        
        Args:
            notebook_manager: Notebook manager instance
            cell_index: Index to insert at (-1 for append)
            cell_type: Type of cell to insert ("code", "markdown")
            cell_source: Source content for the cell
            
        Returns:
            Tuple of (notebook, actual_index, total_cells_after_insertion)
            
        Raises:
            IndexError: When cell_index is out of range
            ValueError: When cell_type is invalid
        """
        async with notebook_manager.get_current_connection() as notebook:
            total_cells = len(notebook)
            
            # Validate insertion parameters
            actual_index = self._validate_cell_insertion_params(
                cell_index, total_cells, cell_type
            )
            
            # Use the unified insert_cell method pattern
            # The remote notebook should have: insert_cell(index, source, cell_type)
            notebook.insert_cell(actual_index, cell_source, cell_type)
            
            return Notebook(**notebook.as_dict()), actual_index, len(notebook)

    async def execute(
        self,
        mode: ServerMode,
        server_client: Optional[JupyterServerClient] = None,
        kernel_client: Optional[Any] = None,
        contents_manager: Optional[Any] = None,
        kernel_manager: Optional[Any] = None,
        kernel_spec_manager: Optional[Any] = None,
        notebook_manager: Optional[NotebookManager] = None,
        # Tool-specific parameters
        cell_index: int = None,
        cell_type: Literal["code", "markdown"] = None,
        cell_source: str = None,
        **kwargs
    ) -> str:
        """Execute the insert_cell tool.
        
        This tool supports three modes of operation following a unified insertion pattern:
        
        1. JUPYTER_SERVER mode with YDoc (collaborative):
           - Checks if notebook is open in a collaborative session
           - Uses YDoc for real-time collaborative editing
           - Changes are immediately visible to all connected users
           - Operations protected by thread locks and YDoc transactions
           
        2. JUPYTER_SERVER mode without YDoc (file-based):
           - Falls back to direct file operations using nbformat
           - Suitable when notebook is not actively being edited
           
        3. MCP_SERVER mode (WebSocket):
           - Uses WebSocket connection to remote Jupyter server
           - Delegates to remote notebook's unified insert_cell method
        
        Thread Safety:
        - YDoc mode: Protected by thread lock + YDoc transaction (atomic)
        - File mode: No synchronization needed (single-threaded file I/O)
        - WebSocket mode: Remote server handles synchronization
        
        Args:
            mode: Server mode (MCP_SERVER or JUPYTER_SERVER)
            server_client: HTTP client for MCP_SERVER mode
            contents_manager: Direct API access for JUPYTER_SERVER mode
            notebook_manager: Notebook manager instance
            cell_index: Target index for insertion (0-based, -1 to append)
            cell_type: Type of cell ("code", "markdown")
            cell_source: Source content for the cell
            **kwargs: Additional parameters
            
        Returns:
            Success message with surrounding cells info
            
        Raises:
            ValueError: When mode is invalid or required clients are missing
            IndexError: When cell_index is out of range
            ValueError: When cell_type is invalid
        """
        if mode == ServerMode.JUPYTER_SERVER and contents_manager is not None:
            # JUPYTER_SERVER mode: Try YDoc first, fall back to file operations
            from jupyter_mcp_server.jupyter_extension.context import get_server_context
            
            context = get_server_context()
            serverapp = context.serverapp
            notebook_path, _ = get_current_notebook_context(notebook_manager)
            
            # Resolve to absolute path
            if serverapp and not Path(notebook_path).is_absolute():
                root_dir = serverapp.root_dir
                notebook_path = str(Path(root_dir) / notebook_path)

            if serverapp:
                # Try YDoc approach first (with thread safety and transactions)
                notebook, actual_index, new_total_cells = await self._insert_cell_ydoc(
                    serverapp, notebook_path, cell_index, cell_type, cell_source
                )
            else:
                # Fall back to file operations
                notebook, actual_index, new_total_cells = await self._insert_cell_file(
                    notebook_path, cell_index, cell_type, cell_source
                )
                
        elif mode == ServerMode.MCP_SERVER and notebook_manager is not None:
            # MCP_SERVER mode: Use WebSocket connection with unified insert_cell pattern
            notebook, actual_index, new_total_cells = await self._insert_cell_websocket(
                notebook_manager, cell_index, cell_type, cell_source
            )
        else:
            raise ValueError(f"Invalid mode or missing required clients: mode={mode}")
        
        info_list = [f"Cell inserted successfully at index {actual_index} ({cell_type})!"]
        info_list.append(f"Notebook now has {new_total_cells} cells, showing surrounding cells:")
        # Show context near the insertion
        if new_total_cells - actual_index < 5:
            start_index = max(0, new_total_cells - 10)
        else:
            start_index = max(0, actual_index - 5)
        info_list.append(notebook.format_output(response_format="brief", start_index=start_index, limit=10))
        return "\n".join(info_list)
        


```

`jupyter_mcp_server/tools/jupyter_cite_prompt.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""cite from a notebook."""

from typing import Any, Optional
from mcp.server.fastmcp.prompts.base import UserMessage
from jupyter_server_client import JupyterServerClient
from jupyter_mcp_server.tools._base import BaseTool, ServerMode
from jupyter_mcp_server.notebook_manager import NotebookManager
from jupyter_mcp_server.models import Notebook


class JupyterCitePrompt(BaseTool):
    """Tool to cite specific cells from specified notebook."""
    
    def _parse_cell_indices(self, cell_indices_str: str, max_cells: int) -> list[int]:
        """
        Parse cell indices from a string with flexible format.
        
        Supports formats like:
        - '0,1,2' for individual indices
        - '0-2' for ranges
        - '0-2,4' for mixed format
        - '3-' for from index 3 to end
        
        Args:
            cell_indices_str: String with cell indices
            max_cells: Maximum number of cells in the notebook
            
        Returns:
            List of integer cell indices
            
        Raises:
            ValueError: If indices are invalid or out of range
        """
        if not cell_indices_str or not cell_indices_str.strip():
            raise ValueError("Cell indices cannot be empty")
            
        # Check if notebook is empty
        if max_cells <= 0:
            raise ValueError("Notebook has no cells")
            
        result = set()
        parts = cell_indices_str.split(',')
        
        for part in parts:
            part = part.strip()
            if not part:
                continue
                
            if '-' in part:
                # Handle range format
                range_parts = part.split('-', 1)
                
                if len(range_parts) == 2:
                    start_str, end_str = range_parts
                    
                    if not start_str:
                        raise ValueError(f"Invalid range format: {part}")
                    
                    try:
                        start = int(start_str)
                    except ValueError:
                        raise ValueError(f"Invalid start index: {start_str}")
                    
                    if start < 0:
                        raise ValueError(f"Start index cannot be negative: {start}")
                    
                    if not end_str:
                        # Case: '3-' means from 3 to end
                        end = max_cells - 1
                        # Check if start is within range
                        if start >= max_cells:
                            raise ValueError(f"Cell index {start} is out of range. Notebook has {max_cells} cells.")
                    else:
                        try:
                            end = int(end_str)
                        except ValueError:
                            raise ValueError(f"Invalid end index: {end_str}")
                        
                        if end < start:
                            raise ValueError(f"End index ({end}) must be greater than or equal to start index ({start})")
                else:
                    raise ValueError(f"Invalid range format: {part}")
                    
                # Add all indices in the range
                for i in range(start, end + 1):
                    if i >= max_cells:
                        raise ValueError(f"Cell index {i} is out of range. Notebook has {max_cells} cells.")
                    result.add(i)
            else:
                # Handle single index
                try:
                    index = int(part)
                except ValueError:
                    raise ValueError(f"Invalid cell index: {part}")
                
                if index < 0:
                    raise ValueError(f"Cell index cannot be negative: {index}")
                if index >= max_cells:
                    raise ValueError(f"Cell index {index} is out of range. Notebook has {max_cells} cells.")
                
                result.add(index)
        
        # Convert to sorted list
        return sorted(result)
    
    async def execute(
        self,
        mode: ServerMode,
        server_client: Optional[JupyterServerClient] = None,
        contents_manager: Optional[Any] = None,
        notebook_manager: Optional[NotebookManager] = None,
        cell_indices: Optional[str] = None,
        notebook_name: Optional[str] = None,
        prompt: Optional[str] = None,
        **kwargs
    ) -> str:
        """Execute the read_notebook tool.
        
        Args:
            mode: Server mode (MCP_SERVER or JUPYTER_SERVER)
            contents_manager: Direct API access for JUPYTER_SERVER mode
            notebook_manager: Notebook manager instance
            notebook_name: Notebook identifier to read
            response_format: Response format (brief or detailed)
            start_index: Starting index for pagination (0-based)
            limit: Maximum number of items to return (0 means no limit)
            **kwargs: Additional parameters
            
        Returns:
            Formatted table with cell information
        """
        if notebook_name == "":
            notebook_name = notebook_manager._current_notebook
        if notebook_name not in notebook_manager:
            raise ValueError(f"Notebook '{notebook_name}' is not connected. All currently connected notebooks: {list(notebook_manager.list_all_notebooks().keys())}")
        
        if mode == ServerMode.JUPYTER_SERVER and contents_manager is not None:
            # Local mode: read notebook directly from file system
            notebook_path = notebook_manager.get_notebook_path(notebook_name)
            
            model = await contents_manager.get(notebook_path, content=True, type='notebook')
            if 'content' not in model:
                raise ValueError(f"Could not read notebook content from {notebook_path}")
            notebook = Notebook(**model['content'])
        elif mode == ServerMode.MCP_SERVER and notebook_manager is not None:
            # Remote mode: use WebSocket connection to Y.js document
            async with notebook_manager.get_notebook_connection(notebook_name) as notebook_content:
                notebook = Notebook(**notebook_content.as_dict())
        else:
            raise ValueError(f"Invalid mode or missing required clients: mode={mode}")
        
        # Parse cell indices with flexible format
        parsed_indices = self._parse_cell_indices(cell_indices, len(notebook))

        prompt_list = [f"USER Cite cells {parsed_indices} from notebook {notebook_name}, here are the cells:"]
        for cell_index in parsed_indices:
            cell = notebook.cells[cell_index]
            prompt_list.append(f"=====Cell {cell_index} | type: {cell.cell_type} | execution count: {cell.execution_count if cell.execution_count else 'N/A'}=====")
            prompt_list.append(cell.get_source('readable'))
        
        prompt_list.append("=====End of Cited Cells=====")
        prompt_list.append(f"USER's Instruction are follow: {prompt}")

        return [UserMessage(content="\n".join(prompt_list))]

        


```

`jupyter_mcp_server/tools/list_files_tool.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""List all files and directories tool."""

import fnmatch
from typing import Any, Optional, List, Dict
from jupyter_server_client import JupyterServerClient

from jupyter_mcp_server.tools._base import BaseTool, ServerMode
from jupyter_mcp_server.config import get_config
from jupyter_mcp_server.utils import format_TSV


def format_size(size_bytes: int) -> str:
    """Format file size in human-readable format."""
    if size_bytes < 1024:
        return f"{size_bytes}B"
    elif size_bytes < 1024 * 1024:
        return f"{size_bytes / 1024:.1f}KB"
    else:
        return f"{size_bytes / (1024 * 1024):.1f}MB"


def _list_files_mcp(
    server_client,
    current_path: str = "",
    current_depth: int = 0,
    files: Optional[List[Dict]] = None,
    max_depth: int = 1
) -> List[Dict]:
    """Recursively list all files and directories in the Jupyter server.
    
    Args:
        server_client: JupyterServerClient instance
        current_path: Current directory path
        current_depth: Current recursion depth
        files: Accumulated files list
        max_depth: Maximum recursion depth (0 means list current directory only)
    
    Returns:
        List of file/directory dictionaries with keys: path, type, size, last_modified
    """
    if files is None:
        files = []
    
    try:
        contents = server_client.contents.list_directory(current_path)
        for item in contents:
            full_path = f"{current_path}/{item.name}" if current_path else item.name
            
            # Format size
            size_str = ""
            if hasattr(item, 'size') and item.size is not None:
                size_str = format_size(item.size)
            
            # Format last modified
            last_modified = ""
            if hasattr(item, 'last_modified') and item.last_modified:
                last_modified = item.last_modified.strftime("%Y-%m-%d %H:%M:%S")
            
            # Add file/directory to list
            files.append({
                'path': full_path,
                'type': item.type,
                'size': size_str,
                'last_modified': last_modified
            })
            
            # Recursively explore directories only if we haven't reached max_depth
            # max_depth=0 means no recursion (list current directory only)
            # max_depth=1 means recurse 1 level deep, etc.
            if item.type == "directory" and current_depth < max_depth:
                _list_files_mcp(server_client, full_path, current_depth + 1, files, max_depth)
                
    except Exception as e:
        # If we can't access a directory, add an error entry
        files.append({
            'path': current_path or "root",
            'type': "error",
            'size': "",
            'last_modified': f"Error: {str(e)}"
        })
    
    return files

async def _list_files_local(
    contents_manager: Any,
    path: str = "",
    max_depth: int = 1,
    current_depth: int = 0
) -> List[Dict[str, Any]]:
    """List files using local contents_manager API (JUPYTER_SERVER mode).
    
    Args:
        contents_manager: Jupyter contents manager instance
        path: Starting directory path
        max_depth: Maximum recursion depth (0 means list current directory only)
        current_depth: Current recursion depth
        
    Returns:
        List of file/directory dictionaries
    """
    all_files = []
    
    try:
        # Get directory contents
        model = await contents_manager.get(path, content=True, type='directory')
        
        if 'content' not in model:
            return all_files
        
        for item in model['content']:
            item_path = item['path']
            item_type = item['type']
            item_size = item.get('size', 0) if item_type == 'file' else 0
            
            # Format size
            size_str = format_size(item_size) if item_size else ""
            
            # Format last modified
            last_modified = item.get('last_modified', '')
            if last_modified and hasattr(last_modified, 'strftime'):
                last_modified = last_modified.strftime("%Y-%m-%d %H:%M:%S")
            elif isinstance(last_modified, str) and 'T' in last_modified:
                # Parse ISO format timestamp
                try:
                    from datetime import datetime
                    dt = datetime.fromisoformat(last_modified.replace('Z', '+00:00'))
                    last_modified = dt.strftime("%Y-%m-%d %H:%M:%S")
                except Exception:
                    pass
            
            file_info = {
                'path': item_path,
                'type': item_type,
                'size': size_str,
                'last_modified': str(last_modified)
            }
            all_files.append(file_info)
            
            # Recursively list subdirectories only if we haven't reached max_depth
            # max_depth=0 means no recursion (list current directory only)
            if item_type == 'directory' and current_depth < max_depth:
                subfiles = await _list_files_local(
                    contents_manager,
                    item_path,
                    max_depth,
                    current_depth + 1
                )
                all_files.extend(subfiles)
                
    except Exception:
        # Directory not accessible or doesn't exist
        pass
    
    return all_files

class ListFilesTool(BaseTool):
    """List files and directories in the Jupyter server's file system"""
    
    async def execute(
        self,
        mode: ServerMode,
        server_client: Optional[JupyterServerClient] = None,
        kernel_client: Optional[Any] = None,
        contents_manager: Optional[Any] = None,
        kernel_manager: Optional[Any] = None,
        kernel_spec_manager: Optional[Any] = None,
        notebook_manager: Optional[Any] = None,
        # Tool-specific parameters
        path: str = "",
        max_depth: int = 1,
        start_index: int = 0,
        limit: int = 25,
        pattern: Optional[str] = None,
        **kwargs
    ) -> str:
        """List all files and directories with pagination and filtering.
        
        Args:
            mode: Server mode (MCP_SERVER or JUPYTER_SERVER)
            server_client: JupyterServerClient for MCP_SERVER mode
            contents_manager: Direct API access for JUPYTER_SERVER mode
            path: The starting path to list from (empty string means root directory)
            max_depth: Maximum depth to recurse into subdirectories (0 means list current directory only, default: 1)
            start_index: Starting index for pagination (0-based, default: 0)
            limit: Maximum number of items to return (0 means no limit, default: 25)
            pattern: Glob pattern to filter file paths (e.g., '*.py', '**/*.ipynb', default: "")
            **kwargs: Additional parameters
            
        Returns:
            Tab-separated table with columns: Path, Type, Size, Last_Modified
            Includes pagination info header.
        """
        # Get all files based on mode
        if mode == ServerMode.JUPYTER_SERVER and contents_manager is not None:
            # Local mode: use contents_manager directly
            all_files = await _list_files_local(contents_manager, path, max_depth)
        elif mode == ServerMode.MCP_SERVER:
            # Remote mode: use HTTP client
            config = get_config()
            server_client = JupyterServerClient(base_url=config.runtime_url, token=config.runtime_token)
            all_files = _list_files_mcp(server_client, path, 0, None, max_depth)
        else:
            raise ValueError(f"Invalid mode or missing required clients: mode={mode}")
        
        if not all_files:
            return f"No files found in path '{path or 'root'}'"
        
        result = ""
        
        # Sort files by path for better readability
        all_files.sort(key=lambda x: x['path'])
        
        # Apply glob pattern filter if provided
        if pattern:
            try:
                filtered_files = [f for f in all_files if fnmatch.fnmatch(f['path'], pattern)]
                all_files = filtered_files
            except Exception:
                result += f"[WARNING] Invalid glob pattern '{pattern}', skipping pattern filter. \n"
        
        # Calculate pagination
        total_files = len(all_files)
        
        if total_files == 0:
            if pattern:
                return f"No files matching pattern '{pattern}' found in path '{path or 'root'}'"
            return f"No files found in path '{path or 'root'}'"
        if start_index >= total_files:
            result += f"[WARNING] Start index is greater than the number of files: start_index={start_index}, total_files={total_files}. Reset start_index to 0. \n"
            start_index = 0
        
        # Apply pagination
        end_index = min(start_index + limit, total_files) if limit > 0 else total_files
        paginated_files = all_files[start_index:end_index]
        
        # Prepare pagination info
        result += f"Showing {start_index}-{end_index} of {total_files} files\n\n"
        
        # Create TSV formatted output
        headers = ["Path", "Type", "Size", "Last_Modified"]
        result += format_TSV(headers, [[file['path'], file['type'], file['size'], file['last_modified']] for file in paginated_files])

        return result

```

`jupyter_mcp_server/tools/list_kernels_tool.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""List all available kernels tool."""

from typing import Any, Optional, List, Dict
from jupyter_server_client import JupyterServerClient

from jupyter_mcp_server.tools._base import BaseTool, ServerMode
from jupyter_mcp_server.utils import format_TSV


class ListKernelsTool(BaseTool):
    """List all available kernels in the Jupyter server."""
    
    def _list_kernels_http(self, server_client: JupyterServerClient) -> List[Dict[str, str]]:
        """List kernels using HTTP API (MCP_SERVER mode)."""
        try:
            # Get all kernels from the Jupyter server
            kernels = server_client.kernels.list_kernels()
            
            if not kernels:
                return []
            
            # Get kernel specifications for additional details
            kernels_specs = server_client.kernelspecs.list_kernelspecs()
            
            # Create enhanced kernel information list
            output = []
            for kernel in kernels:
                kernel_info = {
                    "id": kernel.id or "unknown",
                    "name": kernel.name or "unknown",
                    "state": "unknown",
                    "connections": "unknown", 
                    "last_activity": "unknown",
                    "display_name": "unknown",
                    "language": "unknown",
                    "env": "unknown"
                }
                
                # Get kernel state - this might vary depending on the API version
                if hasattr(kernel, 'execution_state'):
                    kernel_info["state"] = kernel.execution_state
                elif hasattr(kernel, 'state'):
                    kernel_info["state"] = kernel.state
                
                # Get connection count
                if hasattr(kernel, 'connections'):
                    kernel_info["connections"] = str(kernel.connections)
                
                # Get last activity
                if hasattr(kernel, 'last_activity') and kernel.last_activity:
                    if hasattr(kernel.last_activity, 'strftime'):
                        kernel_info["last_activity"] = kernel.last_activity.strftime("%Y-%m-%d %H:%M:%S")
                    else:
                        kernel_info["last_activity"] = str(kernel.last_activity)
                
                output.append(kernel_info)
            
            # Enhance kernel info with specifications
            for kernel in output:
                kernel_name = kernel["name"]
                if hasattr(kernels_specs, 'kernelspecs') and kernel_name in kernels_specs.kernelspecs:
                    kernel_spec = kernels_specs.kernelspecs[kernel_name]
                    if hasattr(kernel_spec, 'spec'):
                        if hasattr(kernel_spec.spec, 'display_name'):
                            kernel["display_name"] = kernel_spec.spec.display_name
                        if hasattr(kernel_spec.spec, 'language'):
                            kernel["language"] = kernel_spec.spec.language
                        if hasattr(kernel_spec.spec, 'env'):
                            # Convert env dict to a readable string format
                            env_dict = kernel_spec.spec.env
                            if env_dict:
                                env_str = "; ".join([f"{k}={v}" for k, v in env_dict.items()])
                                kernel["env"] = env_str[:100] + "..." if len(env_str) > 100 else env_str
            
            return output
            
        except Exception as e:
            raise RuntimeError(f"Error listing kernels via HTTP: {str(e)}")
    
    async def _list_kernels_local(
        self, 
        kernel_manager: Any, 
        kernel_spec_manager: Any
    ) -> List[Dict[str, str]]:
        """List kernels using local kernel_manager API (JUPYTER_SERVER mode)."""
        try:
            # Get all running kernels - list_kernels() returns dicts with kernel info
            kernel_infos = list(kernel_manager.list_kernels())
            
            if not kernel_infos:
                return []
            
            # Get kernel specifications
            kernel_specs = kernel_spec_manager.get_all_specs() if kernel_spec_manager else {}
            
            # Create enhanced kernel information list
            output = []
            for kernel_info_dict in kernel_infos:
                # kernel_info_dict is already a dict with kernel information
                kernel_id = kernel_info_dict.get('id', 'unknown')
                kernel_name = kernel_info_dict.get('name', 'unknown')
                
                kernel_info = {
                    "id": kernel_id,
                    "name": kernel_name,
                    "state": kernel_info_dict.get('execution_state', 'unknown'),
                    "connections": str(kernel_info_dict.get('connections', 'unknown')),
                    "last_activity": "unknown",
                    "display_name": "unknown",
                    "language": "unknown",
                    "env": "unknown"
                }
                
                # Format last activity if present
                last_activity = kernel_info_dict.get('last_activity')
                if last_activity:
                    if hasattr(last_activity, 'strftime'):
                        kernel_info["last_activity"] = last_activity.strftime("%Y-%m-%d %H:%M:%S")
                    else:
                        kernel_info["last_activity"] = str(last_activity)
                
                output.append(kernel_info)
            
            # Enhance kernel info with specifications
            for kernel in output:
                kernel_name = kernel["name"]
                if kernel_name in kernel_specs:
                    spec = kernel_specs[kernel_name].get('spec', {})
                    if 'display_name' in spec:
                        kernel["display_name"] = spec['display_name']
                    if 'language' in spec:
                        kernel["language"] = spec['language']
                    if 'env' in spec and spec['env']:
                        env_dict = spec['env']
                        env_str = "; ".join([f"{k}={v}" for k, v in env_dict.items()])
                        kernel["env"] = env_str[:100] + "..." if len(env_str) > 100 else env_str
            
            return output
            
        except Exception as e:
            raise RuntimeError(f"Error listing kernels locally: {str(e)}")
    
    async def execute(
        self,
        mode: ServerMode,
        server_client: Optional[JupyterServerClient] = None,
        kernel_client: Optional[Any] = None,
        contents_manager: Optional[Any] = None,
        kernel_manager: Optional[Any] = None,
        kernel_spec_manager: Optional[Any] = None,
        **kwargs
    ) -> str:
        """List all available kernels.
        
        Args:
            mode: Server mode (MCP_SERVER or JUPYTER_SERVER)
            server_client: HTTP client for MCP_SERVER mode
            kernel_manager: Direct kernel manager access for JUPYTER_SERVER mode
            kernel_spec_manager: Kernel spec manager for JUPYTER_SERVER mode
            **kwargs: Additional parameters (unused)
            
        Returns:
            Tab-separated table with columns: ID, Name, Display_Name, Language, State, Connections, Last_Activity, Environment
        """
        # Get kernel info based on mode
        if mode == ServerMode.JUPYTER_SERVER and kernel_manager is not None:
            kernel_list = await self._list_kernels_local(kernel_manager, kernel_spec_manager)
        elif mode == ServerMode.MCP_SERVER and server_client is not None:
            kernel_list = self._list_kernels_http(server_client)
        else:
            raise ValueError(f"Invalid mode or missing required managers/clients: mode={mode}")
        
        if not kernel_list:
            return "No kernels found on the Jupyter server."
        
        try:
            # Create TSV formatted output
            headers = ["ID", "Name", "Display_Name", "Language", "State", "Connections", "Last_Activity", "Environment"]
            rows = []
            
            for kernel in kernel_list:
                rows.append([kernel['id'], kernel['name'], kernel['display_name'], kernel['language'], kernel['state'], kernel['connections'], kernel['last_activity'], kernel['env']])
            
            return format_TSV(headers, rows)
            
        except Exception as e:
            return f"Error formatting kernel list: {str(e)}"


```

`jupyter_mcp_server/tools/list_notebooks_tool.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""List notebooks tool implementation."""

from typing import Any, Optional
from jupyter_mcp_server.tools._base import BaseTool, ServerMode
from jupyter_mcp_server.notebook_manager import NotebookManager
from jupyter_mcp_server.utils import format_TSV


class ListNotebooksTool(BaseTool):
    """Tool to list all managed notebooks (that have been used via use_notebook)."""
    
    async def execute(
        self,
        mode: ServerMode,
        server_client: Optional[Any] = None,
        contents_manager: Optional[Any] = None,
        kernel_manager: Optional[Any] = None,
        kernel_spec_manager: Optional[Any] = None,
        notebook_manager: Optional[NotebookManager] = None,
        **kwargs
    ) -> str:
        """Execute the list_notebooks tool.
        
        This tool lists all notebooks that have been managed through the use_notebook tool.
        It does NOT perform recursive filesystem scanning.
        
        Args:
            mode: Server mode (MCP_SERVER or JUPYTER_SERVER)
            notebook_manager: Notebook manager instance
            **kwargs: Additional parameters (unused)
            
        Returns:
            TSV formatted table with managed notebook information
        """
        if notebook_manager is None:
            return "No notebook manager available."
        
        # Get all managed notebooks
        managed_notebooks = notebook_manager.list_all_notebooks()
        
        if not managed_notebooks:
            return "No managed notebooks. Use the use_notebook tool to manage notebooks first."
        
        # Create TSV formatted output
        headers = ["Name", "Path", "Kernel_ID", "Kernel_Status", "Activate"]
        rows = []
        
        # Sort by name for consistent output
        for name in sorted(managed_notebooks.keys()):
            info = managed_notebooks[name]
            activate_marker = "âœ“" if info.get("is_current") else ""
            # Get kernel_id from notebook_manager
            kernel_id = notebook_manager.get_kernel_id(name) or "-"
            rows.append([
                name,
                info.get("path", "-"),
                kernel_id,
                info.get("kernel_status", "unknown"),
                activate_marker
            ])
        
        return format_TSV(headers, rows)

```

`jupyter_mcp_server/tools/overwrite_cell_source_tool.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""Overwrite cell source tool implementation."""

import difflib
import nbformat
from pathlib import Path
from typing import Any, Optional
from jupyter_server_client import JupyterServerClient
from jupyter_mcp_server.tools._base import BaseTool, ServerMode
from jupyter_mcp_server.notebook_manager import NotebookManager
from jupyter_mcp_server.utils import get_current_notebook_context, get_notebook_model, clean_notebook_outputs


class OverwriteCellSourceTool(BaseTool):
    """Tool to overwrite the source of an existing cell."""
    
    def _generate_diff(self, old_source: str, new_source: str) -> str:
        """Generate unified diff between old and new source."""
        old_lines = old_source.splitlines(keepends=False)
        new_lines = new_source.splitlines(keepends=False)
        
        diff_lines = list[str](difflib.unified_diff(
            old_lines, 
            new_lines, 
            lineterm='',
            n=3  # Number of context lines
        ))
        
        if len(diff_lines) > 3:
            return '\n'.join(diff_lines)
        return "no changes detected"
    
    async def _overwrite_cell_ydoc(
        self,
        serverapp: Any,
        notebook_path: str,
        cell_index: int,
        cell_source: str
    ) -> str:
        """Overwrite cell source using YDoc (collaborative editing mode).
        
        Args:
            serverapp: Jupyter ServerApp instance
            notebook_path: Path to the notebook
            cell_index: Index of the cell to overwrite
            cell_source: New cell source content
            
        Returns:
            Diff showing changes made
            
        Raises:
            RuntimeError: When file_id_manager is not available
            ValueError: When cell_index is out of range
        """
        # Get notebook model
        nb = await get_notebook_model(serverapp, notebook_path)

        if nb:
            # Notebook is open in collaborative mode, use YDoc
            if cell_index >= len(nb):
                raise ValueError(
                    f"Cell index {cell_index} is out of range. Notebook has {len(nb)} cells."
                )
            
            old_source = nb.get_cell_source(cell_index)
            if isinstance(old_source, list):
                old_source = "".join(old_source)
            else:
                old_source = str(old_source)
            nb.set_cell_source(cell_index, cell_source)
            
            return self._generate_diff(old_source, cell_source)
        else:
            # YDoc not available, use file operations
            return await self._overwrite_cell_file(notebook_path, cell_index, cell_source)
    
    async def _overwrite_cell_file(
        self,
        notebook_path: str,
        cell_index: int,
        cell_source: str
    ) -> str:
        """Overwrite cell using file operations (non-collaborative mode).
        
        Args:
            notebook_path: Path to the notebook file
            cell_index: Index of the cell to overwrite
            cell_source: New cell source content
            
        Returns:
            Diff showing changes made
            
        Raises:
            ValueError: When cell_index is out of range
        """
        # Read notebook file as version 4 for consistency
        with open(notebook_path, "r", encoding="utf-8") as f:
            notebook = nbformat.read(f, as_version=4)
        clean_notebook_outputs(notebook)
        
        if cell_index >= len(notebook.cells):
            raise ValueError(
                f"Cell index {cell_index} is out of range. Notebook has {len(notebook.cells)} cells."
            )
        
        # Get original cell content
        old_source = notebook.cells[cell_index].source
        
        # Set new cell source
        notebook.cells[cell_index].source = cell_source
        
        # Write back to file
        with open(notebook_path, "w", encoding="utf-8") as f:
            nbformat.write(notebook, f)
        
        return self._generate_diff(old_source, cell_source)
    
    async def _overwrite_cell_websocket(
        self,
        notebook_manager: NotebookManager,
        cell_index: int,
        cell_source: str
    ) -> str:
        """Overwrite cell using WebSocket connection (MCP_SERVER mode).
        
        Args:
            notebook_manager: Notebook manager instance
            cell_index: Index of the cell to overwrite
            cell_source: New cell source content
            
        Returns:
            Diff showing changes made
            
        Raises:
            ValueError: When cell_index is out of range
        """
        async with notebook_manager.get_current_connection() as notebook:
            if cell_index >= len(notebook):
                raise ValueError(f"Cell index {cell_index} out of range")
            
            # Get original cell content
            old_source = notebook.get_cell_source(cell_index)
            if isinstance(old_source, list):
                old_source = "".join(old_source)
            else:
                old_source = str(old_source)
            notebook.set_cell_source(cell_index, cell_source)
            return self._generate_diff(old_source, cell_source)
    
    async def execute(
        self,
        mode: ServerMode,
        server_client: Optional[JupyterServerClient] = None,
        kernel_client: Optional[Any] = None,
        contents_manager: Optional[Any] = None,
        kernel_manager: Optional[Any] = None,
        kernel_spec_manager: Optional[Any] = None,
        notebook_manager: Optional[NotebookManager] = None,
        # Tool-specific parameters
        cell_index: int = None,
        cell_source: str = None,
        **kwargs
    ) -> str:
        """Execute the overwrite_cell_source tool.
        
        This tool supports three modes of operation:
        
        1. JUPYTER_SERVER mode with YDoc (collaborative):
           - Checks if notebook is open in a collaborative session
           - Uses YDoc for real-time collaborative editing
           - Changes are immediately visible to all connected users
           - Operations protected by thread locks and YDoc transactions
           
        2. JUPYTER_SERVER mode without YDoc (file-based):
           - Falls back to direct file operations using nbformat
           - Suitable when notebook is not actively being edited
           
        3. MCP_SERVER mode (WebSocket):
           - Uses WebSocket connection to remote Jupyter server
           - Delegates to remote notebook's set_cell_source method
        
        Thread Safety:
        - YDoc mode: Protected by thread lock + YDoc transaction (atomic)
        - File mode: No synchronization needed (single-threaded file I/O)
        - WebSocket mode: Remote server handles synchronization
        
        Args:
            mode: Server mode (MCP_SERVER or JUPYTER_SERVER)
            server_client: HTTP client for MCP_SERVER mode
            contents_manager: Direct API access for JUPYTER_SERVER mode
            notebook_manager: Notebook manager instance
            cell_index: Index of the cell to overwrite (0-based)
            cell_source: New cell source
            **kwargs: Additional parameters
            
        Returns:
            Success message with diff
            
        Raises:
            ValueError: When mode is invalid or required clients are missing
            ValueError: When cell_index is out of range
        """
        if mode == ServerMode.JUPYTER_SERVER and contents_manager is not None:
            # JUPYTER_SERVER mode: Try YDoc first, fall back to file operations
            from jupyter_mcp_server.jupyter_extension.context import get_server_context
            
            context = get_server_context()
            serverapp = context.serverapp
            notebook_path, _ = get_current_notebook_context(notebook_manager)
            
            # Resolve to absolute path
            if serverapp and not Path(notebook_path).is_absolute():
                root_dir = serverapp.root_dir
                notebook_path = str(Path(root_dir) / notebook_path)

            if serverapp:
                # Try YDoc approach first (with thread safety and transactions)
                diff = await self._overwrite_cell_ydoc(serverapp, notebook_path, cell_index, cell_source)
            else:
                # Fall back to file operations
                diff = await self._overwrite_cell_file(notebook_path, cell_index, cell_source)
                
        elif mode == ServerMode.MCP_SERVER and notebook_manager is not None:
            # MCP_SERVER mode: Use WebSocket connection with remote transaction management
            diff = await self._overwrite_cell_websocket(notebook_manager, cell_index, cell_source)
        else:
            raise ValueError(f"Invalid mode or missing required clients: mode={mode}")
        
        if not diff.strip() or diff == "no changes detected":
            return f"Cell {cell_index} overwritten successfully - no changes detected"
        else:
            return f"Cell {cell_index} overwritten successfully!\n\n```diff\n{diff}\n```"

```

`jupyter_mcp_server/tools/read_cell_tool.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""Read cell tool implementation."""

from typing import Any, Optional
from jupyter_server_client import JupyterServerClient
from jupyter_mcp_server.tools._base import BaseTool, ServerMode
from jupyter_mcp_server.notebook_manager import NotebookManager
from jupyter_mcp_server.models import Notebook
from jupyter_mcp_server.config import get_config
from mcp.types import ImageContent


class ReadCellTool(BaseTool):
    """Tool to read a specific cell from a notebook."""
    
    async def execute(
        self,
        mode: ServerMode,
        server_client: Optional[JupyterServerClient] = None,
        kernel_client: Optional[Any] = None,
        contents_manager: Optional[Any] = None,
        kernel_manager: Optional[Any] = None,
        kernel_spec_manager: Optional[Any] = None,
        notebook_manager: Optional[NotebookManager] = None,
        # Tool-specific parameters
        cell_index: int = None,
        include_outputs: bool = True,
        **kwargs
    ) -> list[str | ImageContent]:
        """Execute the read_cell tool.
        
        Args:
            mode: Server mode (MCP_SERVER or JUPYTER_SERVER)
            contents_manager: Direct API access for JUPYTER_SERVER mode
            notebook_manager: Notebook manager instance
            cell_index: Index of the cell to read (0-based)
            include_outputs: Include outputs in the response (only for code cells)
            **kwargs: Additional parameters
            
        Returns:
            Cell information dictionary
        """
        if mode == ServerMode.JUPYTER_SERVER and contents_manager is not None:
            # Local mode: read notebook directly from file system
            notebook_path = notebook_manager.get_current_notebook_path()
            
            model = await contents_manager.get(notebook_path, content=True, type='notebook')
            if 'content' not in model:
                raise ValueError(f"Could not read notebook content from {notebook_path}")
            notebook = Notebook(**model['content'])
        elif mode == ServerMode.MCP_SERVER and notebook_manager is not None:
            # Remote mode: use WebSocket connection to Y.js document
            async with notebook_manager.get_current_connection() as notebook_content:
                notebook = Notebook(**notebook_content.as_dict())
        else:
            raise ValueError(f"Invalid mode or missing required clients: mode={mode}")
        
        if cell_index >= len(notebook):
            return f"Cell index {cell_index} is out of range. Notebook has {len(notebook)} cells."
        cell = notebook[cell_index]
        info_list = []
        # add cell metadata
        info_list.append(f"=====Cell {cell_index} | type: {cell.cell_type} | execution count: {cell.execution_count if cell.execution_count else 'N/A'}=====")
        # add cell source
        info_list.append(cell.get_source('readable'))
        # add cell outputs for code cells
        if cell.cell_type == "code" and include_outputs:
            info_list.extend(cell.get_outputs('readable'))
        
        return info_list

```

`jupyter_mcp_server/tools/read_notebook_tool.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""List cells tool implementation."""

from typing import Any, Optional, Literal
from jupyter_server_client import JupyterServerClient
from jupyter_mcp_server.tools._base import BaseTool, ServerMode
from jupyter_mcp_server.notebook_manager import NotebookManager
from jupyter_mcp_server.models import Notebook


class ReadNotebookTool(BaseTool):
    """Tool to read a notebook and return index, source content, type, execution count of each cell."""
    
    async def execute(
        self,
        mode: ServerMode,
        server_client: Optional[JupyterServerClient] = None,
        contents_manager: Optional[Any] = None,
        notebook_manager: Optional[NotebookManager] = None,
        notebook_name: str = None,
        response_format: Literal["brief", "detailed"] = "brief",
        start_index: int = 0,
        limit: int = 20,
        **kwargs
    ) -> str:
        """Execute the read_notebook tool.
        
        Args:
            mode: Server mode (MCP_SERVER or JUPYTER_SERVER)
            contents_manager: Direct API access for JUPYTER_SERVER mode
            notebook_manager: Notebook manager instance
            notebook_name: Notebook identifier to read
            response_format: Response format (brief or detailed)
            start_index: Starting index for pagination (0-based)
            limit: Maximum number of items to return (0 means no limit)
            **kwargs: Additional parameters
            
        Returns:
            Formatted table with cell information
        """
        if notebook_name not in notebook_manager:
            return f"Notebook '{notebook_name}' is not connected. All currently connected notebooks: {list(notebook_manager.list_all_notebooks().keys())}"
        
        if mode == ServerMode.JUPYTER_SERVER and contents_manager is not None:
            # Local mode: read notebook directly from file system
            notebook_path = notebook_manager.get_notebook_path(notebook_name)
            
            model = await contents_manager.get(notebook_path, content=True, type='notebook')
            if 'content' not in model:
                raise ValueError(f"Could not read notebook content from {notebook_path}")
            notebook = Notebook(**model['content'])
        elif mode == ServerMode.MCP_SERVER and notebook_manager is not None:
            # Remote mode: use WebSocket connection to Y.js document
            async with notebook_manager.get_notebook_connection(notebook_name) as notebook_content:
                notebook = Notebook(**notebook_content.as_dict())
        else:
            raise ValueError(f"Invalid mode or missing required clients: mode={mode}")
        
        if start_index >= len(notebook):
            return f"Start index {start_index} is out of range. Notebook has {len(notebook)} cells."
        
        info_list = [f'Notebook {notebook_name} has {len(notebook)} cells.\n']
        info_list.append(notebook.format_output(response_format=response_format, start_index=start_index, limit=limit))

        return "\n".join(info_list)

```

`jupyter_mcp_server/tools/restart_notebook_tool.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""Restart notebook tool implementation."""

import logging
from typing import Any, Optional
from jupyter_server_client import JupyterServerClient
from jupyter_mcp_server.tools._base import BaseTool, ServerMode
from jupyter_mcp_server.notebook_manager import NotebookManager

logger = logging.getLogger(__name__)


class RestartNotebookTool(BaseTool):
    """Tool to restart the kernel for a specific notebook."""
    
    async def execute(
        self,
        mode: ServerMode,
        server_client: Optional[JupyterServerClient] = None,
        kernel_client: Optional[Any] = None,
        contents_manager: Optional[Any] = None,
        kernel_manager: Optional[Any] = None,
        kernel_spec_manager: Optional[Any] = None,
        notebook_manager: Optional[NotebookManager] = None,
        # Tool-specific parameters
        notebook_name: str = None,
        **kwargs
    ) -> str:
        """Execute the restart_notebook tool.
        
        Args:
            mode: Server mode (MCP_SERVER or JUPYTER_SERVER)
            kernel_manager: Kernel manager for JUPYTER_SERVER mode
            notebook_manager: Notebook manager instance
            notebook_name: Notebook identifier to restart
            **kwargs: Additional parameters
            
        Returns:
            Success message
        """
        if notebook_name not in notebook_manager:
            return f"Notebook '{notebook_name}' is not connected. All currently connected notebooks: {list(notebook_manager.list_all_notebooks().keys())}"
        
        if mode == ServerMode.JUPYTER_SERVER:
            # JUPYTER_SERVER mode: Use kernel_manager to restart the kernel
            if kernel_manager is None:
                return f"Failed to restart notebook '{notebook_name}': kernel_manager is required in JUPYTER_SERVER mode."
            
            # Get kernel ID from notebook_manager
            kernel_id = notebook_manager.get_kernel_id(notebook_name)
            if not kernel_id:
                return f"Failed to restart notebook '{notebook_name}': kernel ID not found."
            
            try:
                logger.info(f"Restarting kernel {kernel_id} for notebook '{notebook_name}' in JUPYTER_SERVER mode")
                await kernel_manager.restart_kernel(kernel_id)
                return f"Notebook '{notebook_name}' kernel restarted successfully. Memory state and imported packages have been cleared."
            except Exception as e:
                logger.error(f"Failed to restart kernel {kernel_id}: {e}")
                return f"Failed to restart notebook '{notebook_name}': {e}"
        
        elif mode == ServerMode.MCP_SERVER:
            # MCP_SERVER mode: Use notebook_manager's restart_notebook method
            success = notebook_manager.restart_notebook(notebook_name)
            
            if success:
                return f"Notebook '{notebook_name}' kernel restarted successfully. Memory state and imported packages have been cleared."
            else:
                return f"Failed to restart notebook '{notebook_name}'. The kernel may not support restart operation."
        else:
            return f"Invalid mode: {mode}"

```

`jupyter_mcp_server/tools/unuse_notebook_tool.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""Unuse notebook tool implementation."""

import logging
from typing import Any, Optional
from jupyter_server_client import JupyterServerClient
from jupyter_mcp_server.tools._base import BaseTool, ServerMode
from jupyter_mcp_server.notebook_manager import NotebookManager

logger = logging.getLogger(__name__)


class UnuseNotebookTool(BaseTool):
    """Tool to unuse from a notebook and release its resources"""
    
    async def execute(
        self,
        mode: ServerMode,
        server_client: Optional[JupyterServerClient] = None,
        kernel_client: Optional[Any] = None,
        contents_manager: Optional[Any] = None,
        kernel_manager: Optional[Any] = None,
        kernel_spec_manager: Optional[Any] = None,
        notebook_manager: Optional[NotebookManager] = None,
        # Tool-specific parameters
        notebook_name: str = None,
        **kwargs
    ) -> str:
        """Execute the unuse_notebook tool.
        
        Args:
            mode: Server mode (MCP_SERVER or JUPYTER_SERVER)
            kernel_manager: Kernel manager for JUPYTER_SERVER mode (optional kernel shutdown)
            notebook_manager: Notebook manager instance
            notebook_name: Notebook identifier to disconnect
            **kwargs: Additional parameters
            
        Returns:
            Success message
        """
        if notebook_name not in notebook_manager:
            return f"Notebook '{notebook_name}' is not connected. All currently connected notebooks: {list(notebook_manager.list_all_notebooks().keys())}"
        
        # Get info about which notebook was current
        current_notebook = notebook_manager.get_current_notebook()
        was_current = current_notebook == notebook_name
        
        if mode == ServerMode.JUPYTER_SERVER:
            # JUPYTER_SERVER mode: Optionally shutdown kernel before removing
            # Note: In JUPYTER_SERVER mode, kernel lifecycle is managed by kernel_manager
            # We only remove the reference in notebook_manager, the actual kernel
            # continues to run unless explicitly shutdown
            
            kernel_id = notebook_manager.get_kernel_id(notebook_name)
            if kernel_id and kernel_manager:
                try:
                    logger.info(f"Notebook '{notebook_name}' is being unused in JUPYTER_SERVER mode. Kernel {kernel_id} remains running.")
                    # Optional: Uncomment to shutdown kernel when unused
                    # await kernel_manager.shutdown_kernel(kernel_id)
                    # logger.info(f"Kernel {kernel_id} shutdown successfully")
                except Exception as e:
                    logger.warning(f"Note: Could not access kernel {kernel_id}: {e}")
            
            success = notebook_manager.remove_notebook(notebook_name)
            
        elif mode == ServerMode.MCP_SERVER:
            # MCP_SERVER mode: Use notebook_manager's remove_notebook method
            # which handles KernelClient cleanup automatically
            success = notebook_manager.remove_notebook(notebook_name)
        else:
            return f"Invalid mode: {mode}"
        
        if success:
            message = f"Notebook '{notebook_name}' unused successfully."
            
            if was_current:
                new_current = notebook_manager.get_current_notebook()
                if new_current:
                    message += f" Current notebook switched to '{new_current}'."
                else:
                    message += " No notebooks remaining."
            
            return message
        else:
            return f"Notebook '{notebook_name}' was not found."

```

`jupyter_mcp_server/tools/use_notebook_tool.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""Use notebook tool implementation."""

import logging
from typing import Any, Optional, Literal
from pathlib import Path
from jupyter_server_client import JupyterServerClient, NotFoundError
from jupyter_kernel_client import KernelClient
from jupyter_mcp_server.tools._base import BaseTool, ServerMode
from jupyter_mcp_server.notebook_manager import NotebookManager
from jupyter_mcp_server.models import Notebook

logger = logging.getLogger(__name__)


class UseNotebookTool(BaseTool):
    """Tool to use (connect to or create) a notebook file."""
    
    async def _start_kernel_local(self, kernel_manager: Any):
        # Start a new kernel using local API
        kernel_id = await kernel_manager.start_kernel()
        logger.info(f"Started kernel '{kernel_id}', waiting for it to be ready...")
        
        # CRITICAL: Wait for the kernel to actually start and be ready
        # The start_kernel() call returns immediately, but kernel takes time to start
        import asyncio
        max_wait_time = 30  # seconds
        wait_interval = 0.5  # seconds
        elapsed = 0
        kernel_ready = False
        
        while elapsed < max_wait_time:
            try:
                # Get kernel model to check its state
                kernel_model = kernel_manager.get_kernel(kernel_id)
                if kernel_model is not None:
                    # Kernel exists, check if it's ready
                    # In Jupyter, we can try to get connection info which indicates readiness
                    try:
                        kernel_manager.get_connection_info(kernel_id)
                        kernel_ready = True
                        logger.info(f"Kernel '{kernel_id}' is ready (took {elapsed:.1f}s)")
                        break
                    except:
                        # Connection info not available yet, kernel still starting
                        pass
            except Exception as e:
                logger.debug(f"Waiting for kernel to start: {e}")
            
            await asyncio.sleep(wait_interval)
            elapsed += wait_interval
        
        if not kernel_ready:
            logger.warning(f"Kernel '{kernel_id}' may not be fully ready after {max_wait_time}s wait")
        
        return {"id": kernel_id}

    async def _check_path_http(
        self, 
        server_client: JupyterServerClient, 
        notebook_path: str, 
        mode: str
    ) -> tuple[bool, Optional[str]]:
        """Check if path exists using HTTP API."""
        path = Path(notebook_path)
        try:
            parent_path = path.parent.as_posix() if path.parent.as_posix() != "." else ""
            
            if parent_path:
                dir_contents = server_client.contents.list_directory(parent_path)
            else:
                dir_contents = server_client.contents.list_directory("")
                
            if mode == "connect":
                file_exists = any(file.name == path.name for file in dir_contents)
                if not file_exists:
                    return False, f"'{notebook_path}' not found in jupyter server, please check the notebook already exists."
            
            return True, None
        except NotFoundError:
            parent_dir = path.parent.as_posix() if path.parent.as_posix() != "." else "root directory"
            return False, f"'{parent_dir}' not found in jupyter server, please check the directory path already exists."
        except Exception as e:
            return False, f"Failed to check the path '{notebook_path}': {e}"
    
    async def _check_path_local(
        self,
        contents_manager: Any,
        notebook_path: str,
        mode: str
    ) -> tuple[bool, Optional[str]]:
        """Check if path exists using local contents_manager API."""
        path = Path(notebook_path)
        try:
            parent_path = str(path.parent) if str(path.parent) != "." else ""
            
            # Get directory contents using local API
            model = await contents_manager.get(parent_path, content=True, type='directory')
            
            if mode == "connect":
                file_exists = any(item['name'] == path.name for item in model.get('content', []))
                if not file_exists:
                    return False, f"'{notebook_path}' not found in jupyter server, please check the notebook already exists."
            
            return True, None
        except Exception as e:
            parent_dir = str(path.parent) if str(path.parent) != "." else "root directory"
            return False, f"'{parent_dir}' not found in jupyter server: {e}"
    
    async def execute(
        self,
        mode: ServerMode,
        server_client: Optional[JupyterServerClient] = None,
        kernel_client: Optional[Any] = None,
        contents_manager: Optional[Any] = None,
        kernel_manager: Optional[Any] = None,
        kernel_spec_manager: Optional[Any] = None,
        session_manager: Optional[Any] = None,
        notebook_manager: Optional[NotebookManager] = None,
        # Tool-specific parameters
        notebook_name: str = None,
        notebook_path: str = None,
        use_mode: Literal["connect", "create"] = "connect",
        kernel_id: Optional[str] = None,
        runtime_url: Optional[str] = None,
        runtime_token: Optional[str] = None,
        **kwargs
    ) -> str:
        """Execute the use_notebook tool.
        
        Args:
            mode: Server mode (MCP_SERVER or JUPYTER_SERVER)
            server_client: HTTP client for MCP_SERVER mode
            contents_manager: Direct API access for JUPYTER_SERVER mode
            kernel_manager: Direct kernel manager for JUPYTER_SERVER mode
            session_manager: Session manager for creating kernel-notebook associations
            notebook_manager: Notebook manager instance
            notebook_name: Unique identifier for the notebook
            notebook_path: Path to the notebook file (optional, if not provided switches to existing notebook)
            use_mode: "connect" or "create"
            kernel_id: Optional specific kernel ID
            runtime_url: Runtime URL for HTTP mode
            runtime_token: Runtime token for HTTP mode
            **kwargs: Additional parameters
            
        Returns:
            Success message with notebook information
        """
         # Check server connectivity (HTTP mode only)
        if mode == ServerMode.MCP_SERVER and server_client is not None:
            try:
                server_client.get_status()
            except Exception as e:
                return f"Failed to connect the Jupyter server: {e}"
        
        # Check the path exists
        if mode == ServerMode.JUPYTER_SERVER and contents_manager is not None:
            path_ok, error_msg = await self._check_path_local(contents_manager, notebook_path, use_mode)
        elif mode == ServerMode.MCP_SERVER and server_client is not None:
            path_ok, error_msg = await self._check_path_http(server_client, notebook_path, use_mode)
        else:
            return f"Invalid mode or missing required clients: mode={mode}"
        
        if not path_ok:
            return error_msg
        
        info_list = []

        # Check if notebook already in notebook_manager (Cober all cases)
        if notebook_name in notebook_manager:
            if use_mode == "create":
                if notebook_manager.get_notebook_path(notebook_name) == notebook_path:
                    return f"Notebook '{notebook_name}'(path: {notebook_path}) is already created. DO NOT CREATE AGAIN."
                else:
                    return f"Notebook '{notebook_name}' is already used. Use different notebook_name to create a new notebook on {notebook_path}."
            else:
                if notebook_manager.get_notebook_path(notebook_name) == notebook_path:
                    if notebook_name == notebook_manager.get_current_notebook():
                        return f"Notebook '{notebook_name}' is already activated now. DO NOT REACTIVATE AGAIN."
                    else:
                        # the only correct case.
                        info_list.append(f"[INFO] Reactivating notebook '{notebook_name}' and deactivating '{notebook_manager.get_current_notebook()}'.")
                        notebook_manager.set_current_notebook(notebook_name)
                else:
                    return f"The path '{notebook_path}' is not the correct path for notebook '{notebook_name}'. Do you mean connect to '{notebook_manager.get_notebook_path(notebook_name)}'?"
        # add new notebook to notebook_manager
        else:
            # # Create/connect to kernel based on mode
            if mode == ServerMode.MCP_SERVER and server_client is not None:
                if kernel_id is not None:
                    kernels = server_client.kernels.list_kernels()
                    kernel_exists = any(kernel.id == kernel_id for kernel in kernels)
                    if not kernel_exists:
                        return f"Kernel '{kernel_id}' not found in jupyter server, please check whether the kernel already exists using 'list_kernels' tool."
                kernel = KernelClient(
                    server_url=runtime_url,
                    token=runtime_token,
                    kernel_id=kernel_id
                )
                # FIXED: Ensure kernel is started with the same path as the notebook
                kernel.start(path=notebook_path)

                info_list.append(f"[INFO] Connected to kernel '{kernel.id}'.")
            elif mode == ServerMode.JUPYTER_SERVER and kernel_manager is not None:
                # JUPYTER_SERVER mode: Use local kernel manager API directly
                if kernel_id:
                    # Connect to existing kernel - verify it exists
                    if kernel_id not in kernel_manager:
                        return f"Kernel '{kernel_id}' not found in local kernel manager."
                    kernel = {"id": kernel_id}
                else:
                    kernel = await self._start_kernel_local(kernel_manager)
                    kernel_id = kernel['id']

                info_list.append(f"[INFO] Connected to kernel '{kernel_id}'.")
                # Create a Jupyter session to associate the kernel with the notebook
                # This is CRITICAL for JupyterLab to recognize the kernel-notebook connection
                if session_manager is not None:
                    try:
                        # create_session is an async method, so we await it directly
                        session_dict = await session_manager.create_session(
                            path=notebook_path,
                            kernel_id=kernel_id,
                            type="notebook",
                            name=notebook_path
                        )
                        logger.info(f"Created Jupyter session '{session_dict.get('id')}' for notebook '{notebook_path}' with kernel '{kernel_id}'")
                    except Exception as e:
                        logger.warning(f"Failed to create Jupyter session: {e}. Notebook may not be properly connected in JupyterLab UI.")
                else:
                    logger.warning("No session_manager available. Notebook may not be properly connected in JupyterLab UI.")

            # Create notebook if needed
            if use_mode == "create":
                content = {
                    "cells": [{
                        "cell_type": "markdown",
                        "metadata": {},
                        "source": [
                            "New Notebook Created by Jupyter MCP Server",
                        ]
                    }],
                    "metadata": {},
                    "nbformat": 4,
                    "nbformat_minor": 4
                }
                if mode == ServerMode.JUPYTER_SERVER and contents_manager is not None:
                    # Use local API to create notebook
                    await contents_manager.new(model={'type': 'notebook'}, path=notebook_path)
                elif mode == ServerMode.MCP_SERVER and server_client is not None:
                    server_client.contents.create_notebook(notebook_path, content=content)
            
            # Add notebook to notebook_manager
            if mode == ServerMode.MCP_SERVER and runtime_url:
                notebook_manager.add_notebook(
                    notebook_name,
                    kernel,
                    server_url=runtime_url,
                    token=runtime_token,
                    path=notebook_path
                )
            elif mode == ServerMode.JUPYTER_SERVER and kernel_manager is not None:
                notebook_manager.add_notebook(
                    notebook_name,
                    kernel,
                    server_url="local",
                    token=None,
                    path=notebook_path
                )
            else:
                return f"Invalid configuration: mode={mode}, runtime_url={runtime_url}, kernel_manager={kernel_manager is not None}"
        
            notebook_manager.set_current_notebook(notebook_name)
            info_list.append(f"[INFO] Successfully activate notebook '{notebook_name}'.")
        
        # Return the quick overview of currently activated notebook
        try:
            if mode == ServerMode.JUPYTER_SERVER and contents_manager is not None:
                # Read notebook to get cell count and first 20 cells
                model = await contents_manager.get(notebook_path, content=True, type='notebook')
                if 'content' in model:
                    notebook = Notebook(**model['content'])
                else:
                    notebook = Notebook()
            
            elif mode == ServerMode.MCP_SERVER and notebook_manager is not None:
                # Use notebook manager to get cell info
                async with notebook_manager.get_current_connection() as notebook_content:
                    notebook = Notebook(**notebook_content.as_dict())

            info_list.append(f"\nNotebook has {len(notebook)} cells.")
            info_list.append(f"Showing first {min(20, len(notebook))} cells:\n")
            info_list.append(notebook.format_output(response_format="brief", start_index=0, limit=20))
        except Exception as e:
            logger.debug(f"Failed to get notebook summary: {e}")
        
        # Check if we should open in JupyterLab UI (when JupyterLab mode is enabled)
        try:
            from jupyter_mcp_server.jupyter_extension.context import get_server_context
            context = get_server_context()
            
            if context.is_jupyterlab_mode():
                logger.info(f"JupyterLab mode enabled, attempting to open notebook '{notebook_path}' in JupyterLab UI")
                
                # Determine base_url and token based on mode
                base_url = None
                token = None
                
                if mode == ServerMode.JUPYTER_SERVER and context.serverapp is not None:
                    # JUPYTER_SERVER mode: Use ServerApp connection details
                    base_url = context.serverapp.connection_url
                    token = context.serverapp.token
                elif mode == ServerMode.MCP_SERVER and runtime_url:
                    # MCP_SERVER mode: Use runtime_url and runtime_token
                    base_url = runtime_url
                    token = runtime_token
                
                if base_url and token:
                    try:
                        from jupyter_mcp_tools.client import MCPToolsClient
                        
                        async with MCPToolsClient(base_url=base_url, token=token) as client:
                            execution_result = await client.execute_tool(
                                tool_id="docmanager_open",  # docmanager:open converted to underscore format
                                parameters={"path": notebook_path}
                            )
                            
                            if execution_result.get('success'):
                                logger.info(f"Successfully opened notebook '{notebook_path}' in JupyterLab UI")
                            else:
                                logger.warning(f"Failed to open notebook in JupyterLab UI: {execution_result}")
                                
                    except ImportError:
                        logger.warning("jupyter_mcp_tools not available, skipping JupyterLab UI opening")
                    except Exception as e:
                        logger.warning(f"Failed to open notebook in JupyterLab UI: {e}")
                else:
                    logger.warning("No valid base_url or token available for opening notebook in JupyterLab UI")
        except Exception as e:
            logger.debug(f"Could not check JupyterLab mode: {e}")
        
        return "\n".join(info_list)

```

`jupyter_mcp_server/utils.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

import re
import asyncio
import time
import json
from typing import Any, Union
from mcp.types import ImageContent
from jupyter_mcp_server.config import ALLOW_IMG_OUTPUT
from jupyter_nbmodel_client import NotebookModel


def get_current_notebook_context(notebook_manager=None):
    """
    Get the current notebook path and kernel ID for JUPYTER_SERVER mode.
    
    Args:
        notebook_manager: NotebookManager instance (optional)
        
    Returns:
        Tuple of (notebook_path, kernel_id)
        Falls back to config values if notebook_manager not provided
    """
    from .config import get_config
    
    notebook_path = None
    kernel_id = None
    
    if notebook_manager:
        # Try to get current notebook info from manager
        notebook_path = notebook_manager.get_current_notebook_path()
        current_notebook = notebook_manager.get_current_notebook() or "default"
        kernel_id = notebook_manager.get_kernel_id(current_notebook)
    
    # Fallback to config if not found in manager
    if not notebook_path or not kernel_id:
        config = get_config()
        if not notebook_path:
            notebook_path = config.document_id
        if not kernel_id:
            kernel_id = config.runtime_id
    
    return notebook_path, kernel_id


def extract_output(output: Union[dict, Any]) -> Union[str, ImageContent]:
    """
    Extracts readable output from a Jupyter cell output dictionary.
    Handles both traditional and CRDT-based Jupyter formats.

    Args:
        output: The output from a Jupyter cell (dict or CRDT object).

    Returns:
        str: A string representation of the output.
    """
    # Handle pycrdt._text.Text objects
    if hasattr(output, 'source'):
        return str(output.source)
    
    # Handle CRDT YText objects
    if hasattr(output, '__str__') and 'Text' in str(type(output)):
        text_content = str(output)
        return strip_ansi_codes(text_content)
    
    # Handle lists (common in error tracebacks)
    if isinstance(output, list):
        return '\n'.join(extract_output(item) for item in output)
    
    # Handle traditional dictionary format
    if not isinstance(output, dict):
        return strip_ansi_codes(str(output))
    
    output_type = output.get("output_type")
    
    if output_type == "stream":
        text = output.get("text", "")
        if isinstance(text, list):
            text = ''.join(text)
        elif hasattr(text, 'source'):
            text = str(text.source)
        return strip_ansi_codes(str(text))
    
    elif output_type in ["display_data", "execute_result"]:
        
        data = output.get("data", {})       
        
        if "image/png" in data:
            if ALLOW_IMG_OUTPUT:
                try:
                    return ImageContent(type="image", data=data["image/png"], mimeType="image/png")
                except Exception:
                    # Fallback to text placeholder on error
                    return "[Image Output (PNG) - Error processing image]"
            else:
                return "[Image Output (PNG) - Image display disabled]"
            

        if "text/plain" in data:
            plain_text = data["text/plain"]
            if hasattr(plain_text, 'source'):
                plain_text = str(plain_text.source)
            return strip_ansi_codes(str(plain_text))
        elif "text/html" in data:
            return "[HTML Output]"
        else:
            return f"[{output_type} Data: keys={list(data.keys())}]"
    
    elif output_type == "error":
        traceback = output.get("traceback", [])
        if isinstance(traceback, list):
            clean_traceback = []
            for line in traceback:
                if hasattr(line, 'source'):
                    line = str(line.source)
                clean_traceback.append(strip_ansi_codes(str(line)))
            return '\n'.join(clean_traceback)
        else:
            if hasattr(traceback, 'source'):
                traceback = str(traceback.source)
            return strip_ansi_codes(str(traceback))
    
    else:
        return f"[Unknown output type: {output_type}]"


def strip_ansi_codes(text: str) -> str:
    """Remove ANSI escape sequences from text."""
    ansi_escape = re.compile(r'\x1b\[[0-9;]*m')
    return ansi_escape.sub('', text)


def clean_notebook_outputs(notebook):
    """Remove transient fields from all cell outputs.
    
    The 'transient' field is part of the Jupyter kernel messaging protocol
    but is NOT part of the nbformat schema. This causes validation errors.
    
    Args:
        notebook: nbformat notebook object to clean (modified in place)
    """
    for cell in notebook.cells:
        if cell.cell_type == 'code' and hasattr(cell, 'outputs'):
            for output in cell.outputs:
                if isinstance(output, dict) and 'transient' in output:
                    del output['transient']


def safe_extract_outputs(outputs: Any) -> list[Union[str, ImageContent]]:
    """
    Safely extract all outputs from a cell, handling CRDT structures.
    
    Args:
        outputs: Cell outputs (could be CRDT YArray or traditional list)
        
    Returns:
        list[Union[str, ImageContent]]: List of outputs (strings or image content)
    """
    if not outputs:
        return []
    
    result = []
    
    # Handle CRDT YArray or list of outputs
    if hasattr(outputs, '__iter__') and not isinstance(outputs, (str, dict)):
        try:
            for output in outputs:
                extracted = extract_output(output)
                if extracted:
                    result.append(extracted)
        except Exception as e:
            result.append(f"[Error extracting output: {str(e)}]")
    else:
        # Handle single output
        extracted = extract_output(outputs)
        if extracted:
            result.append(extracted)
    
    return result

def normalize_cell_source(source: Any) -> list[str]:
    """
    Normalize cell source to a list of strings (lines).
    
    In Jupyter notebooks, source can be either:
    - A string (single or multi-line with \n)  
    - A list of strings (each element is a line)
    - CRDT text objects
    
    Args:
        source: The source from a Jupyter cell
        
    Returns:
        list[str]: List of source lines
    """
    if not source:
        return []
    
    # Handle CRDT text objects
    if hasattr(source, 'source'):
        source = str(source.source)
    elif hasattr(source, '__str__') and 'Text' in str(type(source)):
        source = str(source)
    
    # If it's already a list, return as is
    if isinstance(source, list):
        return [str(line) for line in source]
    
    # If it's a string, split by newlines
    if isinstance(source, str):
        # Split by newlines but preserve the newline characters except for the last line
        lines = source.splitlines(keepends=True)
        # Remove trailing newline from the last line if present
        if lines and lines[-1].endswith('\n'):
            lines[-1] = lines[-1][:-1]
        return lines
    
    # Fallback: convert to string and split
    return str(source).splitlines(keepends=True)

def format_TSV(headers: list[str], rows: list[list[str]]) -> str:
    """
    Format data as TSV (Tab-Separated Values)
    
    Args:
        headers: The list of headers
        rows: The list of data rows, each row is a list of strings
    
    Returns:
        The formatted TSV string
    """
    if not headers or not rows:
        return "No data to display"
    
    result = []
    
    header_row = "\t".join(headers)
    result.append(header_row)
    
    for row in rows:
        data_row = "\t".join(str(cell) for cell in row)
        result.append(data_row)
    
    return "\n".join(result)

###############################################################################
# Kernel and notebook operation helpers
###############################################################################


def create_kernel(config, logger):
    """Create a new kernel instance using current configuration."""
    from jupyter_kernel_client import KernelClient
    kernel = None
    try:
        # Initialize the kernel client with the provided parameters.
        kernel = KernelClient(
            server_url=config.runtime_url, 
            token=config.runtime_token, 
            kernel_id=config.runtime_id
        )
        kernel.start()
        logger.info("Kernel created and started successfully")
        return kernel
    except Exception as e:
        logger.error(f"Failed to create kernel: {e}")
        # Clean up partially initialized kernel to prevent __del__ errors
        if kernel is not None:
            try:
                # Try to clean up the kernel object if it exists
                if hasattr(kernel, 'stop'):
                    kernel.stop()
            except Exception as cleanup_error:
                logger.debug(f"Error during kernel cleanup: {cleanup_error}")
        raise


def start_kernel(notebook_manager, config, logger):
    """Start the Jupyter kernel with error handling (for backward compatibility)."""
    try:
        # Remove existing default notebook if any
        if "default" in notebook_manager:
            notebook_manager.remove_notebook("default")
        
        # Create and set up new kernel
        kernel = create_kernel(config, logger)
        notebook_manager.add_notebook("default", kernel)
        logger.info("Default notebook kernel started successfully")
    except Exception as e:
        logger.error(f"Failed to start kernel: {e}")
        raise


def ensure_kernel_alive(notebook_manager, current_notebook, create_kernel_fn):
    """Ensure kernel is running, restart if needed."""
    return notebook_manager.ensure_kernel_alive(current_notebook, create_kernel_fn)


async def execute_cell_with_forced_sync(notebook, cell_index, kernel, timeout_seconds = 300):
    """Execute cell with forced real-time synchronization."""
    from jupyter_mcp_server.log import logger
    
    start_time = time.time()
    
    # Start execution
    execution_future = asyncio.create_task(
        asyncio.to_thread(notebook.execute_cell, cell_index, kernel)
    )
    
    last_output_count = 0
    
    while not execution_future.done():
        elapsed = time.time() - start_time
        
        if elapsed > timeout_seconds:
            execution_future.cancel()
            try:
                if hasattr(kernel, 'interrupt'):
                    kernel.interrupt()
            except Exception:
                pass
            raise asyncio.TimeoutError(f"Cell execution timed out after {timeout_seconds} seconds")
        
        # Check for new outputs and try to trigger sync
        try:
            ydoc = notebook._doc
            current_outputs = ydoc._ycells[cell_index].get("outputs", [])
            
            if len(current_outputs) > last_output_count:
                last_output_count = len(current_outputs)
                logger.info(f"Cell {cell_index} progress: {len(current_outputs)} outputs after {elapsed:.1f}s")
                
                # Try different sync methods
                try:
                    # Method 1: Force Y-doc update
                    if hasattr(ydoc, 'observe') and hasattr(ydoc, 'unobserve'):
                        # Trigger observers by making a tiny change
                        pass
                        
                    # Method 2: Force websocket message
                    if hasattr(notebook, '_websocket') and notebook._websocket:
                        # The websocket should automatically sync on changes
                        pass
                        
                except Exception as sync_error:
                    logger.debug(f"Sync method failed: {sync_error}")
                    
        except Exception as e:
            logger.debug(f"Output check failed: {e}")
        
        await asyncio.sleep(1)  # Check every second
    
    # Get final result
    try:
        await execution_future
    except asyncio.CancelledError:
        pass
    
    return None


def is_kernel_busy(kernel):
    """Check if kernel is currently executing something."""
    try:
        # This is a simple check - you might need to adapt based on your kernel client
        if hasattr(kernel, '_client') and hasattr(kernel._client, 'is_alive'):
            return kernel._client.is_alive()
        return False
    except Exception:
        return False


async def wait_for_kernel_idle(kernel, max_wait_seconds=60):
    """Wait for kernel to become idle before proceeding."""
    from jupyter_mcp_server.log import logger
    
    start_time = time.time()
    while is_kernel_busy(kernel):
        elapsed = time.time() - start_time
        if elapsed > max_wait_seconds:
            logger.warning(f"Kernel still busy after {max_wait_seconds}s, proceeding anyway")
            break
        logger.info(f"Waiting for kernel to become idle... ({elapsed:.1f}s)")
        await asyncio.sleep(1)


async def safe_notebook_operation(operation_func, max_retries=3):
    """Safely execute notebook operations with connection recovery."""
    from jupyter_mcp_server.log import logger
    
    for attempt in range(max_retries):
        try:
            return await operation_func()
        except Exception as e:
            error_msg = str(e).lower()
            if any(err in error_msg for err in ["websocketclosederror", "connection is already closed", "connection closed"]):
                if attempt < max_retries - 1:
                    logger.warning(f"Connection lost, retrying... (attempt {attempt + 1}/{max_retries})")
                    await asyncio.sleep(1 + attempt)  # Increasing delay
                    continue
                else:
                    logger.error(f"Failed after {max_retries} attempts: {e}")
                    raise Exception(f"Connection failed after {max_retries} retries: {e}")
            else:
                # Non-connection error, don't retry
                raise e
    
    raise Exception("Unexpected error in retry logic")


###############################################################################
# Local code execution helpers (JUPYTER_SERVER mode)
###############################################################################


async def execute_via_execution_stack(
    serverapp: Any,
    kernel_id: str,
    code: str,
    document_id: str = None,
    cell_id: str = None,
    timeout: int = 300,
    poll_interval: float = 0.1,
    logger = None
) -> list[Union[str, ImageContent]]:
    """Execute code using ExecutionStack (JUPYTER_SERVER mode with jupyter-server-nbmodel).
    
    This uses the ExecutionStack from jupyter-server-nbmodel extension directly,
    avoiding the reentrant HTTP call issue. This is the preferred method for code
    execution in JUPYTER_SERVER mode.
    
    Args:
        serverapp: Jupyter server application instance
        kernel_id: Kernel ID to execute in
        code: Code to execute
        document_id: Optional document ID for RTC integration (format: json:notebook:<file_id>)
        cell_id: Optional cell ID for RTC integration
        timeout: Maximum time to wait for execution (seconds)
        poll_interval: Time between polling for results (seconds)
        logger: Logger instance (optional)
        
    Returns:
        List of formatted outputs (strings or ImageContent)
        
    Raises:
        RuntimeError: If jupyter-server-nbmodel extension is not installed
        TimeoutError: If execution exceeds timeout
    """
    import logging as default_logging
    
    if logger is None:
        logger = default_logging.getLogger(__name__)
    
    try:
        # Get the ExecutionStack from the jupyter_server_nbmodel extension
        nbmodel_extensions = serverapp.extension_manager.extension_apps.get("jupyter_server_nbmodel", set())
        if not nbmodel_extensions:
            raise RuntimeError("jupyter_server_nbmodel extension not found. Please install it.")
        
        nbmodel_ext = next(iter(nbmodel_extensions))
        execution_stack = nbmodel_ext._Extension__execution_stack
        
        # Build metadata for RTC integration if available
        metadata = {}
        if document_id and cell_id:
            metadata = {
                "document_id": document_id,
                "cell_id": cell_id
            }
        
        # Submit execution request
        logger.info(f"Submitting execution request to kernel {kernel_id}")
        request_id = execution_stack.put(kernel_id, code, metadata)
        logger.info(f"Execution request {request_id} submitted")
        
        # Poll for results
        start_time = asyncio.get_event_loop().time()
        while True:
            elapsed = asyncio.get_event_loop().time() - start_time
            if elapsed > timeout:
                raise TimeoutError(f"Execution timed out after {timeout} seconds")
            
            # Get result (returns None if pending, result dict if complete)
            result = execution_stack.get(kernel_id, request_id)
            
            if result is not None:
                # Execution complete
                logger.info(f"Execution request {request_id} completed")
                
                # Check for errors
                if "error" in result:
                    error_info = result["error"]
                    logger.error(f"Execution error: {error_info}")
                    return [f"[ERROR: {error_info.get('ename', 'Unknown')}: {error_info.get('evalue', '')}]"]
                
                # Check for pending input (shouldn't happen with allow_stdin=False)
                if "input_request" in result:
                    logger.warning("Unexpected input request during execution")
                    return ["[ERROR: Unexpected input request]"]
                
                # Extract outputs
                outputs = result.get("outputs", [])
                
                # Parse JSON string if needed (ExecutionStack returns JSON string)
                if isinstance(outputs, str):
                    import json
                    try:
                        outputs = json.loads(outputs)
                    except json.JSONDecodeError:
                        logger.error(f"Failed to parse outputs JSON: {outputs}")
                        return [f"[ERROR: Invalid output format]"]
                
                if outputs:
                    formatted = safe_extract_outputs(outputs)
                    logger.info(f"Execution completed with {len(formatted)} formatted outputs: {formatted}")
                    return formatted
                else:
                    logger.info("Execution completed with no outputs")
                    return ["[No output generated]"]
            
            # Still pending, wait before next poll
            await asyncio.sleep(poll_interval)
            
    except Exception as e:
        logger.error(f"Error executing via ExecutionStack: {e}", exc_info=True)
        return [f"[ERROR: {str(e)}]"]


async def execute_code_local(
    serverapp,
    notebook_path: str,
    code: str,
    kernel_id: str,
    timeout: int = 300,
    logger=None
) -> list[Union[str, ImageContent]]:
    """Execute code in a kernel and return outputs (JUPYTER_SERVER mode).
    
    This is a centralized code execution function for JUPYTER_SERVER mode that:
    1. Gets the kernel from kernel_manager
    2. Creates a client and sends execute_request
    3. Polls for response messages with timeout
    4. Collects and formats outputs
    5. Cleans up resources
    
    Args:
        serverapp: Jupyter ServerApp instance
        notebook_path: Path to the notebook (for context)
        code: Code to execute
        kernel_id: ID of the kernel to execute in
        timeout: Timeout in seconds (default: 300)
        logger: Logger instance (optional)
        
    Returns:
        List of formatted outputs (strings or ImageContent)
    """
    import zmq.asyncio
    from inspect import isawaitable
    
    if logger is None:
        import logging
        logger = logging.getLogger(__name__)
    
    try:
        # Get kernel manager
        kernel_manager = serverapp.kernel_manager
        
        # Get the kernel using pinned_superclass pattern (like KernelUsageHandler)
        lkm = kernel_manager.pinned_superclass.get_kernel(kernel_manager, kernel_id)
        session = lkm.session
        client = lkm.client()
        
        # Ensure channels are started (critical for receiving IOPub messages!)
        if not client.channels_running:
            client.start_channels()
            # Wait for channels to be ready
            await asyncio.sleep(0.1)
        
        # Send execute request on shell channel
        shell_channel = client.shell_channel
        msg_id = session.msg("execute_request", {
            "code": code,
            "silent": False,
            "store_history": True,
            "user_expressions": {},
            "allow_stdin": False,
            "stop_on_error": False
        })
        shell_channel.send(msg_id)
        
        # Give a moment for messages to start flowing
        await asyncio.sleep(0.01)
        
        # Prepare to collect outputs
        outputs = []
        execution_done = False
        grace_period_ms = 100  # Wait 100ms after shell reply for remaining IOPub messages
        execution_done_time = None
        
        # Poll for messages with timeout
        poller = zmq.asyncio.Poller()
        iopub_socket = client.iopub_channel.socket
        shell_socket = shell_channel.socket
        poller.register(iopub_socket, zmq.POLLIN)
        poller.register(shell_socket, zmq.POLLIN)
        
        timeout_ms = timeout * 1000
        start_time = asyncio.get_event_loop().time()
        
        while not execution_done or (execution_done_time and (asyncio.get_event_loop().time() - execution_done_time) * 1000 < grace_period_ms):
            elapsed_ms = (asyncio.get_event_loop().time() - start_time) * 1000
            remaining_ms = max(0, timeout_ms - elapsed_ms)
            
            # If execution is done and grace period expired, exit
            if execution_done and execution_done_time and (asyncio.get_event_loop().time() - execution_done_time) * 1000 >= grace_period_ms:
                break
            
            if remaining_ms <= 0:
                client.stop_channels()
                logger.warning(f"Code execution timeout after {timeout}s, collected {len(outputs)} outputs")
                return [f"[TIMEOUT ERROR: Code execution exceeded {timeout} seconds]"]
            
            # Use shorter poll timeout during grace period
            poll_timeout = min(remaining_ms, grace_period_ms / 2) if execution_done else remaining_ms
            events = dict(await poller.poll(poll_timeout))
            
            if not events:
                continue  # No messages, continue polling
            
            # IMPORTANT: Process IOPub messages BEFORE shell to collect outputs before marking done
            # Check for IOPub messages (outputs)
            if iopub_socket in events:
                msg = client.iopub_channel.get_msg(timeout=0)
                # Handle async get_msg (like KernelUsageHandler)
                if isawaitable(msg):
                    msg = await msg
                
                if msg and msg.get('parent_header', {}).get('msg_id') == msg_id['header']['msg_id']:
                    msg_type = msg.get('msg_type')
                    content = msg.get('content', {})
                    
                    logger.debug(f"IOPub message: {msg_type}")
                    
                    # Collect output messages
                    if msg_type == 'stream':
                        outputs.append({
                            'output_type': 'stream',
                            'name': content.get('name', 'stdout'),
                            'text': content.get('text', '')
                        })
                        logger.debug(f"Collected stream output: {len(content.get('text', ''))} chars")
                    elif msg_type == 'execute_result':
                        outputs.append({
                            'output_type': 'execute_result',
                            'data': content.get('data', {}),
                            'metadata': content.get('metadata', {}),
                            'execution_count': content.get('execution_count')
                        })
                        logger.debug(f"Collected execute_result, count: {content.get('execution_count')}")
                    elif msg_type == 'display_data':
                        # Note: 'transient' field from kernel messages is NOT part of nbformat schema
                        # Only include 'output_type', 'data', and 'metadata' fields
                        outputs.append({
                            'output_type': 'display_data',
                            'data': content.get('data', {}),
                            'metadata': content.get('metadata', {})
                        })
                        logger.debug("Collected display_data")
                    elif msg_type == 'error':
                        outputs.append({
                            'output_type': 'error',
                            'ename': content.get('ename', ''),
                            'evalue': content.get('evalue', ''),
                            'traceback': content.get('traceback', [])
                        })
                        logger.debug(f"Collected error: {content.get('ename')}")
            
            # Check for shell reply (execution complete) - AFTER processing IOPub
            if shell_socket in events:
                reply = client.shell_channel.get_msg(timeout=0)
                # Handle async get_msg (like KernelUsageHandler)
                if isawaitable(reply):
                    reply = await reply
                
                if reply and reply.get('parent_header', {}).get('msg_id') == msg_id['header']['msg_id']:
                    logger.debug(f"Execution complete, reply status: {reply.get('content', {}).get('status')}")
                    execution_done = True
                    execution_done_time = asyncio.get_event_loop().time()
        
        # Clean up
        client.stop_channels()
        
        # Extract and format outputs
        if outputs:
            result = safe_extract_outputs(outputs)
            logger.info(f"Code execution completed with {len(result)} outputs")
            return result
        else:
            return ["[No output generated]"]
            
    except Exception as e:
        logger.error(f"Error executing code locally: {e}")
        return [f"[ERROR: {str(e)}]"]


async def execute_cell_local(
    serverapp,
    notebook_path: str,
    cell_index: int,
    kernel_id: str,
    timeout: int = 300,
    logger=None
) -> list[Union[str, ImageContent]]:
    """Execute a cell in a notebook and return outputs (JUPYTER_SERVER mode).
    
    This function:
    1. Reads the cell source from the notebook (YDoc or file)
    2. Executes the code using execute_code_local
    3. Writes the outputs back to the notebook (YDoc or file)
    4. Returns the formatted outputs
    
    Args:
        serverapp: Jupyter ServerApp instance
        notebook_path: Path to the notebook
        cell_index: Index of the cell to execute
        kernel_id: ID of the kernel to execute in
        timeout: Timeout in seconds (default: 300)
        logger: Logger instance (optional)
        
    Returns:
        List of formatted outputs (strings or ImageContent)
    """
    import nbformat
    
    if logger is None:
        import logging
        logger = logging.getLogger(__name__)
    
    try:
        # Try to get YDoc first (for collaborative editing)
        file_id_manager = serverapp.web_app.settings.get("file_id_manager")
        ydoc = None
        
        if file_id_manager:
            file_id = file_id_manager.get_id(notebook_path)
            yroom_manager = serverapp.web_app.settings.get("yroom_manager")
            
            if yroom_manager:
                room_id = f"json:notebook:{file_id}"
                if yroom_manager.has_room(room_id):
                    try:
                        yroom = yroom_manager.get_room(room_id)
                        ydoc = await yroom.get_jupyter_ydoc()
                        logger.info(f"Using YDoc for cell {cell_index} execution")
                    except Exception as e:
                        logger.debug(f"Could not get YDoc: {e}")
        
        # Execute using YDoc or file
        if ydoc:
            # YDoc path - read from collaborative document
            if cell_index < 0 or cell_index >= len(ydoc.ycells):
                raise ValueError(f"Cell index {cell_index} out of range. Notebook has {len(ydoc.ycells)} cells.")
            
            cell = ydoc.ycells[cell_index]
            
            # Only execute code cells
            cell_type = cell.get("cell_type", "")
            if cell_type != "code":
                return [f"[Cell {cell_index} is not a code cell (type: {cell_type})]"]
            
            source_raw = cell.get("source", "")
            if isinstance(source_raw, list):
                source = "".join(source_raw)
            else:
                source = str(source_raw)
            
            if not source:
                return ["[Cell is empty]"]
            
            logger.info(f"Cell {cell_index} source from YDoc: {source[:100]}...")
            
            # Execute the code
            outputs = await execute_code_local(
                serverapp=serverapp,
                notebook_path=notebook_path,
                code=source,
                kernel_id=kernel_id,
                timeout=timeout,
                logger=logger
            )
            
            logger.info(f"Execution completed with {len(outputs)} outputs: {outputs}")
            
            # Update execution count in YDoc
            max_count = 0
            for c in ydoc.ycells:
                if c.get("cell_type") == "code" and c.get("execution_count"):
                    max_count = max(max_count, c["execution_count"])
            
            cell["execution_count"] = max_count + 1
            
            # Update outputs in YDoc (simplified - just store formatted strings)
            # YDoc outputs should match nbformat structure
            cell["outputs"] = []
            for output in outputs:
                if isinstance(output, str):
                    cell["outputs"].append({
                        "output_type": "stream",
                        "name": "stdout",
                        "text": output
                    })
            
            return outputs
        else:
            # File path - original logic
            # Read notebook as version 4 (latest) for consistency
            with open(notebook_path, 'r', encoding='utf-8') as f:
                notebook = nbformat.read(f, as_version=4)
            
            # Clean transient fields from outputs
            clean_notebook_outputs(notebook)
            
            # Validate cell index
            if cell_index < 0 or cell_index >= len(notebook.cells):
                raise ValueError(f"Cell index {cell_index} out of range. Notebook has {len(notebook.cells)} cells.")
        
            cell = notebook.cells[cell_index]
            
            # Only execute code cells
            if cell.cell_type != 'code':
                return [f"[Cell {cell_index} is not a code cell (type: {cell.cell_type})]"]
            
            # Get cell source
            source = cell.source
            if not source:
                return ["[Cell is empty]"]
            
            # Execute the code
            logger.info(f"Executing cell {cell_index} from {notebook_path}")
            outputs = await execute_code_local(
                serverapp=serverapp,
                notebook_path=notebook_path,
                code=source,
                kernel_id=kernel_id,
                timeout=timeout,
                logger=logger
            )
            
            # Write outputs back to notebook (update execution_count and outputs)
            # Get the last execution count
            max_count = 0
            for c in notebook.cells:
                if c.cell_type == 'code' and c.execution_count:
                    max_count = max(max_count, c.execution_count)
            
            cell.execution_count = max_count + 1
            
            # Convert formatted outputs back to nbformat structure
            # Note: outputs is already formatted, so we need to reconstruct
            # For simplicity, we'll store a simple representation
            cell.outputs = []
            for output in outputs:
                if isinstance(output, str):
                    # Create a stream output
                    cell.outputs.append(nbformat.v4.new_output(
                        output_type='stream',
                        name='stdout',
                        text=output
                    ))
                elif isinstance(output, ImageContent):
                    # Create a display_data output with image
                    cell.outputs.append(nbformat.v4.new_output(
                        output_type='display_data',
                        data={'image/png': output.data}
                    ))
            
            # Write notebook back
            with open(notebook_path, 'w', encoding='utf-8') as f:
                nbformat.write(notebook, f)
            
            logger.info(f"Cell {cell_index} executed and notebook updated")
            return outputs
        
    except Exception as e:
        logger.error(f"Error executing cell locally: {e}")
        return [f"[ERROR: {str(e)}]"]


async def get_jupyter_ydoc(serverapp: Any, file_id: str):
    """Get the YNotebook document if it's currently open in a collaborative session.
    
    This follows the jupyter_ai_tools pattern of accessing YDoc through the
    yroom_manager when the notebook is actively being edited.
    
    Args:
        serverapp: The Jupyter ServerApp instance
        file_id: The file ID for the document
        
    Returns:
        YNotebook instance or None if not in a collaborative session
    """
    try:
        # Access ywebsocket_server from YDocExtension via extension_manager
        # jupyter-collaboration doesn't add yroom_manager to web_app.settings
        ywebsocket_server = None

        if hasattr(serverapp, 'extension_manager'):
            extension_points = serverapp.extension_manager.extension_points
            if 'jupyter_server_ydoc' in extension_points:
                ydoc_ext_point = extension_points['jupyter_server_ydoc']
                if hasattr(ydoc_ext_point, 'app') and ydoc_ext_point.app:
                    ydoc_app = ydoc_ext_point.app
                    if hasattr(ydoc_app, 'ywebsocket_server'):
                        ywebsocket_server = ydoc_app.ywebsocket_server

        if ywebsocket_server is None:
            return None

        room_id = f"json:notebook:{file_id}"

        # Get room and access document via room._document
        # DocumentRoom stores the YNotebook as room._document, not via get_jupyter_ydoc()
        try:
            yroom = await ywebsocket_server.get_room(room_id)
            if yroom and hasattr(yroom, '_document'):
                return yroom._document
        except Exception:
            pass

    except Exception:
        # YDoc not available, will fall back to file operations
        pass

    return None

async def get_notebook_model(serverapp: Any, notebook_path: str):
    """Get the NotebookModel instance if it's currently open in a collaborative session."""
    # Get file_id from file_id_manager
    file_id_manager = serverapp.web_app.settings.get("file_id_manager")
    if file_id_manager is None:
        raise RuntimeError("file_id_manager not available in serverapp")
    
    file_id = file_id_manager.get_id(notebook_path)
    ydoc = await get_jupyter_ydoc(serverapp, file_id)
    if ydoc is None:
        return None
    nb = NotebookModel()
    nb._doc = ydoc
    return nb


def clean_mcp_response_content(content_item):
    """
    Clean MCP response content by filtering out null annotations and meta fields.
    
    Args:
        content_item: Dictionary representing content item (e.g., TextContent)
        
    Returns:
        Cleaned dictionary with null annotations and meta fields removed
    """
    if isinstance(content_item, dict):
        cleaned = content_item.copy()
        
        # Remove annotations and meta fields if they are None/null
        if cleaned.get("annotations") is None:
            cleaned.pop("annotations", None)
        if cleaned.get("meta") is None:
            cleaned.pop("meta", None)
            
        return cleaned
    
    return content_item


def clean_mcp_response(response_dict):
    """
    Clean MCP response by filtering out null annotations and meta fields from all content items.
    
    Args:
        response_dict: Dictionary representing MCP response with content list
        
    Returns:
        Cleaned response dictionary
    """
    if not isinstance(response_dict, dict):
        return response_dict
        
    cleaned_response = response_dict.copy()
    
    if "content" in cleaned_response and isinstance(cleaned_response["content"], list):
        cleaned_content = []
        for item in cleaned_response["content"]:
            cleaned_content.append(clean_mcp_response_content(item))
        cleaned_response["content"] = cleaned_content
    
    return cleaned_response

```

`mcpb/.mcpbignore`:

```
# Build artifacts
__pycache__/
*.pyc
*.pyo
*.egg-info/
dist/
build/
.eggs/

# Virtual environments
.venv/
venv/

# IDE files
.idea/
.vscode/
*.swp
*.swo

# OS files
.DS_Store
Thumbs.db

# Test files
tests/
*.test.*

# Documentation
*.md
!README.md

# UV lock file (dependencies resolved at install time)
uv.lock

```

`mcpb/README.md`:

```md
<!--
  ~ Copyright (c) 2024- Datalayer, Inc.
  ~
  ~ BSD 3-Clause License
-->

# Jupyter MCP Server - MCPB Bundle

One-click installer for [Jupyter MCP Server](https://github.com/datalayer/jupyter-mcp-server) in Claude Desktop.

## What is this?

This directory contains the source files for building an MCPB (MCP Bundle) / DXT (Desktop Extension) package. The resulting `.mcpb` file allows users to install the Jupyter MCP Server in Claude Desktop with a single click â€” no terminal or manual configuration needed.

## Prerequisites

- [Node.js](https://nodejs.org/) (for the `mcpb` CLI tool)
- A running Jupyter server (JupyterLab or Jupyter Notebook) for the extension to connect to

## Building the Bundle

1. Install the MCPB CLI tool:

   ```bash
   npm install -g @anthropic-ai/mcpb
   ```

2. Build the `.mcpb` file from this directory:

   ```bash
   cd mcpb
   mcpb pack
   ```

   This creates `jupyter-mcp-server-0.22.1.mcpb` in the current directory.

## Installing in Claude Desktop

1. Double-click the `.mcpb` file, or drag it into Claude Desktop Settings
2. Claude Desktop will prompt you to configure:
   - **Jupyter Server URL**: The URL of your running Jupyter server (default: `http://localhost:8888`)
   - **Jupyter Server Token**: The authentication token for your Jupyter server
3. The extension is ready to use

## How It Works

This bundle uses the **UV runtime** type, which means:

- Claude Desktop automatically manages the Python environment
- Dependencies (`jupyter-mcp-server` and its transitive dependencies) are installed via `uv` into an isolated virtual environment
- No system-wide Python installation changes are made
- The server runs in **stdio** transport mode for direct communication with Claude Desktop

## Bundle Structure

```
mcpb/
â”œâ”€â”€ manifest.json      # Extension metadata, tools, and user configuration
â”œâ”€â”€ pyproject.toml     # Python dependencies for UV runtime
â”œâ”€â”€ .mcpbignore        # Files to exclude from the bundle
â”œâ”€â”€ README.md          # This file
â””â”€â”€ src/
    â””â”€â”€ server.py      # Thin entry point that launches the MCP server
```

## User Configuration

When installed, users provide two settings:

| Setting | Environment Variable | Description |
|---------|---------------------|-------------|
| Jupyter Server URL | `JUPYTER_URL` | URL of the Jupyter server (e.g., `http://localhost:8888`) |
| Jupyter Server Token | `JUPYTER_TOKEN` | Authentication token (stored securely in OS keychain) |

These are passed to the server as environment variables by Claude Desktop.

```

`mcpb/manifest.json`:

```json
{
  "manifest_version": "0.4",
  "name": "jupyter-mcp-server",
  "display_name": "Jupyter MCP Server",
  "version": "0.22.1",
  "description": "Connect AI agents to Jupyter Notebooks - execute code, manage notebooks, and interact with kernels in real-time",
  "long_description": "The Jupyter MCP Server enables AI agents like Claude to connect to and manage Jupyter Notebooks in real-time. It provides 14 tools to execute code, manage notebooks, read and write cells, and interact with Jupyter kernels through the standardized Model Context Protocol.\n\n**Requirements:** You need a running Jupyter server (JupyterLab or Jupyter Notebook) to connect to. Start one with:\n```\npip install jupyterlab\njupyter lab --port 8888 --IdentityProvider.token MY_TOKEN\n```",
  "author": {
    "name": "Datalayer",
    "email": "info@datalayer.io",
    "url": "https://datalayer.io"
  },
  "repository": {
    "type": "git",
    "url": "https://github.com/datalayer/jupyter-mcp-server"
  },
  "homepage": "https://jupyter-mcp-server.datalayer.tech",
  "documentation": "https://jupyter-mcp-server.datalayer.tech",
  "support": "https://github.com/datalayer/jupyter-mcp-server/issues",
  "license": "BSD-3-Clause",
  "server": {
    "type": "uv",
    "entry_point": "src/server.py",
    "mcp_config": {
      "command": "uv",
      "args": ["run", "--project", "${__dirname}", "${__dirname}/src/server.py"],
      "env": {
        "JUPYTER_URL": "${user_config.jupyter_url}",
        "JUPYTER_TOKEN": "${user_config.jupyter_token}"
      }
    }
  },
  "tools": [
    {
      "name": "list_files",
      "description": "List files and directories in the Jupyter server filesystem"
    },
    {
      "name": "list_kernels",
      "description": "List all available and running kernel sessions"
    },
    {
      "name": "use_notebook",
      "description": "Connect to an existing notebook or create a new one"
    },
    {
      "name": "list_notebooks",
      "description": "List all managed notebooks and their status"
    },
    {
      "name": "restart_notebook",
      "description": "Restart the kernel for a managed notebook"
    },
    {
      "name": "unuse_notebook",
      "description": "Disconnect from a notebook and release resources"
    },
    {
      "name": "read_notebook",
      "description": "Read notebook content with brief or detailed format"
    },
    {
      "name": "read_cell",
      "description": "Read full content of a single cell including metadata and outputs"
    },
    {
      "name": "insert_cell",
      "description": "Insert new code or markdown cells into a notebook"
    },
    {
      "name": "delete_cell",
      "description": "Delete cells from a notebook by index"
    },
    {
      "name": "overwrite_cell_source",
      "description": "Modify the source code of a notebook cell"
    },
    {
      "name": "execute_cell",
      "description": "Execute a notebook cell with timeout and multimodal output support"
    },
    {
      "name": "insert_execute_code_cell",
      "description": "Insert and execute a code cell in one step"
    },
    {
      "name": "execute_code",
      "description": "Execute arbitrary code directly in the kernel"
    }
  ],
  "user_config": {
    "jupyter_url": {
      "type": "string",
      "title": "Jupyter Server URL",
      "description": "URL of your running Jupyter server (e.g., http://localhost:8888)",
      "default": "http://localhost:8888",
      "required": true
    },
    "jupyter_token": {
      "type": "string",
      "title": "Jupyter Server Token",
      "description": "Authentication token for your Jupyter server",
      "sensitive": true,
      "required": true
    }
  },
  "compatibility": {
    "platforms": ["darwin", "win32", "linux"],
    "runtimes": {
      "python": ">=3.10"
    }
  },
  "keywords": ["jupyter", "notebook", "python", "kernel", "data-science", "code-execution", "mcp"]
}

```

`mcpb/pyproject.toml`:

```toml
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

[project]
name = "jupyter-mcp-server-mcpb"
version = "0.22.1"
description = "Jupyter MCP Server - MCPB bundle for one-click installation in Claude Desktop"
requires-python = ">=3.10"
dependencies = [
    "jupyter-mcp-server>=0.22.1",
]

```

`mcpb/src/server.py`:

```py
#!/usr/bin/env python3
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""Jupyter MCP Server - MCPB entry point for Claude Desktop.

This is a thin wrapper that launches the Jupyter MCP Server
in stdio transport mode for use with Claude Desktop and other
MCP-compatible applications.

Configuration is provided via environment variables set by
the host application from the manifest's user_config:
  - JUPYTER_URL: URL of the Jupyter server
  - JUPYTER_TOKEN: Authentication token for the Jupyter server
"""

from jupyter_mcp_server.CLI import server

if __name__ == "__main__":
    server()

```

`prompt/README.md`:

```md
<!--
  ~ Copyright (c) 2024- Datalayer, Inc.
  ~
  ~ BSD 3-Clause License
-->

# ğŸ“‹ Jupyter MCP Server Prompt Templates

Welcome to the Jupyter MCP Server Prompt Templates repository! This directory contains curated, community-driven prompt templates designed to help AI agents and users make the most of Jupyter MCP Server across different scenarios and use cases.

## ğŸ’¡ How to Use Prompt Templates

Templates are organized by use case, you can choose any of them. 

> [!TIP]
>
>  Start with the [`general/`](general/) template if you're new to Jupyter MCP Server. It provides foundational guidance applicable to most use cases.

### Example Usage

```
1. Go to prompt/general/
2. Read the README.md to understand the template's purpose
3. Copy the content from AGENT.md
4. Paste it as your system prompt(e.g. `CLAUDE.md` in Claude Code)
5. Start your session with enhanced context!
```

## ğŸ¤ Contributing Your Own Templates

We love community contributions! If you've developed a great prompt template that works well with Jupyter MCP, here's how to share it:

### Step 1: Create a Template Directory

Clone the repository and create a new folder with a clear, concise name representing the use case:

```bash
git clone https://github.com/datalayer/jupyter-mcp-server.git
cd jupyter-mcp-server/prompt
mkdir your-use-case/
```

### Step 2: Create a README.md

create a `README.md` file in the new folder and it should include the brief description of what this template is for.

### Step 3: Create the AGENT.md

Create an `AGENT.md` file containing the actual system prompt for AI agents. 

### Step 4: Add Resources (Optional)

You can include additional files to enhance your template

### Step 5: Submit a Pull Request

Create a pull request to let us know your Awesome Prompt Template!

## ğŸ™ Thank You

Thank you for using and contributing to Jupyter MCP Server Prompt Templates! Your participation helps build a stronger community and makes AI-powered notebook workflows more accessible to everyone.

```

`prompt/general/AGENT.md`:

```md
<!--
  ~ Copyright (c) 2024- Datalayer, Inc.
  ~
  ~ BSD 3-Clause License
-->

# Role

You are a Jupyter Agent, a powerful AI assistant designed to help USER code in Jupyter Notebooks.

You are pair programming with a USER to solve their coding task. Please keep going until the user's query is completely resolved, before ending your turn and yielding back to the user. Autonomously resolve the query to the best of your ability before coming back to the user.

Your main goal is to follow the USER's instructions at each message and deliver a high-quality Notebook with a clear structure.

# Core Philosophy

You are **Explorer, Not Builder**, your primary goal is to **explore, discover, and understand**. Treat your work as a scientific investigation, not a software engineering task. Your process should be iterative and guided by curiosity.

### View the Notebook as an Experimentation Space

Treat the Notebook as more than just a document for Markdown and code cells. It is a complete, interactive experimentation space. This means you should leverage all its capabilities to explore and manipulate the environment, such as:
- **Magic Commands**: Use magic commands to fully leverage the Jupyter's capabilities, such as `%pip install <package>` to manage dependencies.
- **Shell Commands**: Execute shell commands directly in cells with `!`, for example, `!ls -l` to inspect files or `!pwd` to confirm the current directory.

### Embrace the Introspective Exploration Loop

This is your core thinking process for any task. This cycle begins by deconstructing the user's request into a concrete, explorable problem and repeats until the goal is achieved.

- **Observe and Formulate**: Observe the user's request and previous outputs. Analyze this information to formulate a specific, internal question that will guide your next immediate action.
- **Code as the Hypothesis**: Write the minimal amount of code necessary to answer your internal question. This code acts as an experiment to test a hypothesis.
- **Execute for Insight**: Run the code immediately. The outputâ€”whether a result, a plot, or an errorâ€”is the raw data from your experiment.
- **Introspect and Iterate**: Analyze the output. What was learned? Does it answer your question? What new questions arise? Summarize your findings, and repeat the cycle, refining your understanding with each iteration.

## Context

{{Add your custom context here, like your package installation, preferred code style, etc.}}

# Rules

1. **ALWAYS MCP**: All operations on the Notebook, such as creating, editing, and code execution, MUST be performed via tools provided by Jupyter MCP. **NEVER Directly create or modify the Notebook Source File Content**.
2. **Prioritize Safety and Await Approval**: If a proposed step involves high risk (e.g., deleting files, modifying critical configurations) or high cost (e.g., downloading very large datasets, running long-lasting computations), you MUST terminate your work cycle, present the proposed action and its potential consequences to the USER, and await explicit approval before proceeding.

# Notebook Format

## Overall Format

1.  **Readability as a Story**: Your Notebook is not just a record of code execution; it's a narrative of your analytical journey and a powerful tool for sharing insights. Use Markdown cells strategically at key junctures to explain your thought process, justify decisions, interpret results, and guide the reader through your analysis. 
2.  **Maintain Tidiness**: Keep the Notebook clean, focused, and logically organized.
    -   **Eliminate Redundancy**: Actively delete any unused, irrelevant, or redundant cells (both code and markdown) to maintain clarity and conciseness.
    -   **Correct In-Place**: When a Code Cell execution results in an error, **ALWAYS modify the original cell to fix the error** rather than adding new cells below it. This ensures a clean, executable, and logical flow without cluttering the Notebook with failed attempts.

## Markdown Cell

1. Avoid large blocks of text; separate different logical blocks with blank lines. Prioritize the use of hierarchical headings (`##`, `###`) and bullet points (`-`) to organize content. Highlight important information with bold formatting (`**`).
2. Use LaTeX syntax for mathematical symbols and formulas. Enclose inline formulas with `$` (e.g., `$E=mc^2$`) and multi-line formulas with `$$` to ensure standard formatting.

### Example
```
## Data Preprocessing Steps
This preprocessing includes 3 core steps:
- **Missing Value Handling**: Use mean imputation for numerical features and mode imputation for categorical features.
- **Outlier Detection**: Identify outliers outside the range `[-3Ïƒ, +3Ïƒ]` using the 3Ïƒ principle.
- **Feature Scaling**: Perform standardization on continuous features with the formula:
$$
z = \frac{x - \mu}{\sigma}
$$
where $\mu$ is the mean and $\sigma$ is the standard deviation.
```

## Code Cell
1. Focus on a single verifiable function (e.g., "Import the pandas library and load the dataset", "Define a quadratic function solution formula"). Complex tasks must be split into multiple consecutive Cells and progressed step-by-step.
2. Each Code Cell must start with a functional comment that clearly states the core task of the Cell (e.g., `# Load the dataset and view the first 5 rows of data`).

### Example
```
# Load the dataset and view basic information

import pandas as pd

data = pd.read_csv("user_behavior.csv")

# Output the first 5 rows of data and data dimensions
print(f"Dataset shape (rows, columns): {data.shape}")
print("First 5 rows of the dataset:")
data.head()
```
```

`prompt/general/README.md`:

```md
<!--
  ~ Copyright (c) 2024- Datalayer, Inc.
  ~
  ~ BSD 3-Clause License
-->

## ğŸ“ Overview

This is the **general-purpose** prompt template for Jupyter MCP Server. It provides foundational guidance and best practices for using Jupyter MCP Server across a wide variety of use cases. **If you're new to Jupyter MCP, start here!**

## ğŸ’¡ Core Philosophy: Explorer, Not Builder

The agent's core concept is to be an **Explorer, not a Builder**. It treats user requests as scientific inquiries rather than simple engineering tasks.

To achieve this, the agent follows the **Introspective Exploration Loop**:

1.  **Observe and Formulate**: Analyze the user's request and existing outputs to form an internal question that guides the next action.
2.  **Code as Hypothesis**: Write minimal code to answer the internal question, treating the code as an experiment.
3.  **Execute for Insight**: Run the code immediately, treating the output (whether a result or an error) as experimental data.
4.  **Introspect and Iterate**: Analyze the output, summarize insights, and begin a new cycle.

## ğŸš€ User Guide: How to Customize the Agent

You can "fine-tune" the agent for your project's specific needs by modifying the `Custom Context` within `AGENT.md`.

Open `AGENT.md` and find the `# Context` section:

```markdown
# Context

{{Add your custom context here, like your package installation, preferred code style, etc.}}
```

Replace the `{{...}}` placeholder with your project-specific rules.

#### Example:

To make the agent prefer the `Polars` library and adhere to the `black` code style, you would modify it like this:

```markdown
# Context

- **Library Preference**: Prioritize using the `Polars` library for data manipulation instead of `Pandas`.
- **Code Style**: All Python code should be formatted according to the `black` code style.
- **Project Background**: This project aims to analyze user behavior data, and the key data file is `user_behavior.csv`.
```

---

- **Version**: 1.0.0
- **Author**: Jupyter MCP Server Community
- **Last Update**: 2025-11-01
```

`pyproject.toml`:

```toml
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

[build-system]
requires = ["hatchling~=1.21"]
build-backend = "hatchling.build"

[project]
name = "jupyter_mcp_server"
authors = [{ name = "Datalayer", email = "info@datalayer.io" }]
dynamic = ["version"]
readme = "README.md"
requires-python = ">=3.10"
keywords = ["Jupyter"]
classifiers = [
  "Intended Audience :: Developers",
  "Intended Audience :: System Administrators",
  "License :: OSI Approved :: BSD License",
  "Programming Language :: Python",
  "Programming Language :: Python :: 3",
]
dependencies = [
    "jupyter-kernel-client>=0.7.3",
    "jupyter-mcp-tools>=0.1.6",
    "jupyter-nbmodel-client>=0.14.4",
    "jupyter-server-nbmodel>=0.1.1a4",
    "jupyter-server-client",
    "jupyter_server>=1.6,<3",
    "tornado>=6.1",
    "traitlets>=5.0",
    "mcp[cli]>=1.10.1",
    "pydantic",
    "uvicorn",
    "click",
    "fastapi"
]

[project.optional-dependencies]
test = [
    "ipykernel", 
    "jupyter_server>=1.6,<3", 
    "pytest>=7.0", 
    "pytest-asyncio",
    "pytest-timeout>=2.1.0",
    "jupyterlab==4.4.1",
    "jupyter-collaboration==4.0.2",
    "datalayer_pycrdt==0.12.17",
    "pillow>=10.0.0"
]
lint = ["mdformat>0.7", "mdformat-gfm>=0.3.5", "ruff"]
typing = ["mypy>=0.990"]

[project.scripts]
jupyter-mcp-server = "jupyter_mcp_server.CLI:server"

[project.license]
file = "LICENSE"

[project.urls]
Home = "https://github.com/datalayer/jupyter-mcp-server"

[tool.hatch.version]
path = "jupyter_mcp_server/__version__.py"

[tool.hatch.build]
include = [
  "jupyter_mcp_server/**/*.py",
  "jupyter-config/**/*.json"
]

[tool.hatch.build.targets.wheel.shared-data]
"jupyter-config/jupyter_server_config.d" = "etc/jupyter/jupyter_server_config.d"
"jupyter-config/jupyter_notebook_config.d" = "etc/jupyter/jupyter_notebook_config.d"

[tool.pytest.ini_options]
filterwarnings = [
  "error",
  "ignore:There is no current event loop:DeprecationWarning",
  "module:make_current is deprecated:DeprecationWarning",
  "module:clear_current is deprecated:DeprecationWarning",
  "module:Jupyter is migrating its paths to use standard platformdirs:DeprecationWarning",
]

[tool.mypy]
check_untyped_defs = true
disallow_incomplete_defs = true
no_implicit_optional = true
pretty = true
show_error_context = true
show_error_codes = true
strict_equality = true
warn_unused_configs = true
warn_unused_ignores = true
warn_redundant_casts = true

[tool.ruff]
target-version = "py310"
line-length = 100

[tool.ruff.lint]
select = [
  "A",
  "B",
  "C",
  "E",
  "F",
  "FBT",
  "I",
  "N",
  "Q",
  "RUF",
  "S",
  "T",
  "UP",
  "W",
  "YTT",
]
ignore = [
  # FBT001 Boolean positional arg in function definition
  "FBT001",
  "FBT002",
  "FBT003",
]

[tool.ruff.lint.per-file-ignores]
# S101 Use of `assert` detected
"jupyter_mcp_server/tests/*" = ["S101"]

```

`pytest.ini`:

```ini
; Copyright (c) 2024- Datalayer, Inc.
;
; BSD 3-Clause License

[pytest]
addopts = -rqA
log_cli = true
log_level = INFO

```

`smithery.yaml`:

```yaml
# Smithery configuration file: https://smithery.ai/docs/config#smitheryyaml

startCommand:
  type: stdio
  configSchema:
    # JSON Schema defining the configuration options for the MCP.
    type: object
    required:
      - serverUrl
      - token
      - notebookPath
    properties:
      serverUrl:
        type: string
        description: The URL of the JupyterLab server that the MCP will connect to.
      token:
        type: string
        description: The token for authenticating with the JupyterLab server.
      notebookPath:
        type: string
        description: The path to the Jupyter notebook to work with.
  commandFunction:
    # A function that produces the CLI command to start the MCP on stdio.
    |-
    (config) => ({ command: 'docker', args: ['run', '-i', '--rm', '-e', `DOCUMENT_URL=${config.serverUrl}`, '-e', `TOKEN=${config.token}`, '-e', `DOCUMENT_ID=${config.notebookPath}`, 'datalayer/jupyter-mcp-server:latest'] })

```

`tests/__init__.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

```

`tests/conftest.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""
Pytest configuration and shared fixtures for Jupyter MCP Server tests.

This module provides:
- jupyter_server fixture: Session-scoped Jupyter Lab server
- jupyter_server_with_extension fixture: Jupyter Lab with MCP extension
- jupyter_mcp_server fixture: Standalone MCP server instance
- mcp_client fixture: MCP protocol client for testing
- _start_server helper: Generic server startup with health checks
- JUPYTER_TOKEN: Authentication token for Jupyter API
"""

import logging
import os
import socket
import subprocess
import time
from http import HTTPStatus

import pytest
import pytest_asyncio
import requests
from requests.exceptions import ConnectionError


JUPYTER_TOKEN = "MY_TOKEN"

# Test mode configuration - set to False to skip testing specific modes
TEST_MCP_SERVER = os.environ.get("TEST_MCP_SERVER", "true").lower() == "true"
TEST_JUPYTER_SERVER = os.environ.get("TEST_JUPYTER_SERVER", "true").lower() == "true"


def _start_server(
    name: str, host: str, port: int, command: list, readiness_endpoint: str, max_retries: int = 5
):
    """A Helper that starts a web server as a python subprocess and wait until it's ready to accept connections

    This method can be used to start both Jupyter and Jupyter MCP servers
    
    Uses subprocess.DEVNULL to prevent pipe blocking issues with verbose output.
    """
    _log_prefix = name
    url = f"http://{host}:{port}"
    url_readiness = f"{url}{readiness_endpoint}"
    logging.info(f"{_log_prefix}: starting ...")
    logging.debug(f"{_log_prefix}: command: {' '.join(command)}")
    
    # Use DEVNULL to prevent any pipe blocking issues
    p_serv = subprocess.Popen(
        command, 
        stdout=subprocess.DEVNULL, 
        stderr=subprocess.DEVNULL
    )
    _log_prefix = f"{_log_prefix} [{p_serv.pid}]"
    
    while max_retries > 0:
        # Check if process died
        poll_result = p_serv.poll()
        if poll_result is not None:
            logging.error(f"{_log_prefix}: process died with exit code {poll_result}")
            pytest.fail(f"{name} failed to start (exit code {poll_result}). Check if port {port} is available.")
        
        try:
            response = requests.get(url_readiness, timeout=10)
            if response is not None and response.status_code == HTTPStatus.OK:
                logging.info(f"{_log_prefix}: started ({url})!")
                yield url
                break
        except (ConnectionError, requests.exceptions.Timeout):
            logging.debug(
                f"{_log_prefix}: waiting to accept connections [{max_retries}]"
            )
            time.sleep(2)
            max_retries -= 1
            
    if not max_retries:
        logging.error(f"{_log_prefix}: fail to start after retries. Check if port {port} is available.")
        pytest.fail(f"{name} failed to start after max retries. Port {port} may be in use or server crashed.")
    logging.debug(f"{_log_prefix}: stopping ...")
    try:
        p_serv.terminate()
        p_serv.wait(timeout=5)  # Reduced timeout for faster cleanup
        logging.info(f"{_log_prefix}: stopped")
    except subprocess.TimeoutExpired:
        logging.warning(f"{_log_prefix}: terminate timeout, forcing kill")
        p_serv.kill()
        try:
            p_serv.wait(timeout=2)
        except subprocess.TimeoutExpired:
            logging.error(f"{_log_prefix}: kill timeout, process may be stuck")
    except Exception as e:
        logging.error(f"{_log_prefix}: error during shutdown: {e}")


@pytest.fixture(scope="session")
def jupyter_server():
    """Start the Jupyter server and returns its URL
    
    This is a session-scoped fixture that starts a single Jupyter Lab instance
    for all tests. Both MCP_SERVER and JUPYTER_SERVER mode tests can share this.
    
    Only starts if at least one test mode is enabled.
    """
    if not TEST_MCP_SERVER and not TEST_JUPYTER_SERVER:
        pytest.skip("Both TEST_MCP_SERVER and TEST_JUPYTER_SERVER are disabled")
    
    host = "localhost"
    port = 8888
    yield from _start_server(
        name="JupyterLab",
        host=host,
        port=port,
        command=[
            "jupyter",
            "lab",
            "--port",
            str(port),
            "--IdentityProvider.token",
            JUPYTER_TOKEN,
            "--ip",
            host,
            "--ServerApp.root_dir",
            "./dev/content",
            "--no-browser",
        ],
        readiness_endpoint="/api",
        max_retries=10,
    )


@pytest.fixture(scope="session")
def jupyter_server_with_extension():
    """Start Jupyter server with MCP extension loaded (JUPYTER_SERVER mode)
    
    This fixture starts Jupyter Lab with the jupyter_mcp_server extension enabled,
    allowing tests to verify JUPYTER_SERVER mode functionality (YDoc, direct kernel access, etc).
    
    Only starts if TEST_JUPYTER_SERVER=True, otherwise skips.
    """
    if not TEST_JUPYTER_SERVER:
        pytest.skip("TEST_JUPYTER_SERVER is disabled")
    
    host = "localhost"
    port = 8889  # Different port to avoid conflicts
    yield from _start_server(
        name="JupyterLab+MCP",
        host=host,
        port=port,
        command=[
            "jupyter",
            "lab",
            "--port",
            str(port),
            "--IdentityProvider.token",
            JUPYTER_TOKEN,
            "--ip",
            host,
            "--ServerApp.root_dir",
            "./dev/content",
            "--no-browser",
            # Load the MCP extension
            "--ServerApp.jpserver_extensions",
            '{"jupyter_mcp_server": True}',
        ],
        readiness_endpoint="/api",
        max_retries=10,
    )


###############################################################################
# MCP Server Fixtures
###############################################################################

@pytest.fixture(scope="function")
def jupyter_mcp_server(request, jupyter_server):
    """Start the Jupyter MCP server and returns its URL
    
    This fixture starts a standalone MCP server that communicates with Jupyter
    via HTTP (MCP_SERVER mode). It can be parametrized to control runtime startup.
    
    Parameters:
        request.param (bool): Whether to start a new kernel runtime (default: True)
    """
    # Find an available port
    def find_free_port():
        with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
            s.bind(('', 0))
            s.listen(1)
            port = s.getsockname()[1]
        return port
    
    host = "localhost"
    port = find_free_port()
    start_new_runtime = True
    try:
        start_new_runtime = request.param
    except AttributeError:
        # fixture not parametrized
        pass
    
    yield from _start_server(
        name="Jupyter MCP",
        host=host,
        port=port,
        command=[
            "python",
            "-m",
            "jupyter_mcp_server",
            "--transport",
            "streamable-http",
            "--document-url",
            jupyter_server,
            "--document-id",
            "notebook.ipynb",
            "--document-token",
            JUPYTER_TOKEN,
            "--runtime-url",
            jupyter_server,
            "--start-new-runtime",
            str(start_new_runtime),
            "--runtime-token",
            JUPYTER_TOKEN,
            "--port",
            str(port),
        ],
        readiness_endpoint="/api/healthz",
    )


def _get_test_params():
    """Generate test parameters based on TEST_MCP_SERVER and TEST_JUPYTER_SERVER flags"""
    params = []
    if TEST_MCP_SERVER:
        params.append("mcp_server")
    if TEST_JUPYTER_SERVER:
        params.append("jupyter_extension")
    
    if not params:
        pytest.skip("Both TEST_MCP_SERVER and TEST_JUPYTER_SERVER are disabled")
    
    return params


@pytest.fixture(scope="function", params=_get_test_params())
def mcp_server_url(request):
    """Parametrized fixture that provides both MCP_SERVER and JUPYTER_SERVER mode URLs
    
    This fixture enables testing the same functionality against both deployment modes:
    - mcp_server: Standalone MCP server (HTTP transport) - when TEST_MCP_SERVER=True
    - jupyter_extension: Jupyter extension mode (direct API access) - when TEST_JUPYTER_SERVER=True
    
    Both expose MCP protocol endpoints that can be tested with MCPClient.
    
    You can control which modes to test via environment variables:
        TEST_MCP_SERVER=true/false (default: true)
        TEST_JUPYTER_SERVER=true/false (default: true)
    
    Parameters:
        request.param (str): Either "mcp_server" or "jupyter_extension"
    
    Returns:
        str: URL of the MCP endpoint for the selected mode
    """
    if request.param == "mcp_server":
        # Get jupyter_server fixture dynamically
        jupyter_server = request.getfixturevalue("jupyter_server")
        
        # Start standalone MCP server
        import socket
        def find_free_port():
            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as s:
                s.bind(('', 0))
                s.listen(1)
                port = s.getsockname()[1]
            return port
        
        host = "localhost"
        port = find_free_port()
        
        yield from _start_server(
            name="Jupyter MCP",
            host=host,
            port=port,
            command=[
                "python",
                "-m",
                "jupyter_mcp_server",
                "--transport",
                "streamable-http",
                "--document-url",
                jupyter_server,
                "--document-id",
                "notebook.ipynb",
                "--document-token",
                JUPYTER_TOKEN,
                "--runtime-url",
                jupyter_server,
                "--start-new-runtime",
                "True",
                "--runtime-token",
                JUPYTER_TOKEN,
                "--port",
                str(port),
            ],
            readiness_endpoint="/api/healthz",
        )
    else:  # jupyter_extension
        # Get jupyter_server_with_extension fixture dynamically
        jupyter_server_with_extension = request.getfixturevalue("jupyter_server_with_extension")
        # Use the extension's MCP endpoints (note: no /mcp suffix, the extension handles routing)
        yield jupyter_server_with_extension


###############################################################################


@pytest_asyncio.fixture(scope="function")
async def mcp_client(jupyter_mcp_server):
    """An MCP client that can connect to the Jupyter MCP server
    
    This fixture provides an MCPClient instance configured to connect to
    the standalone MCP server. It requires the test_common module.
    
    Returns:
        MCPClient: Configured client for MCP protocol communication
    """
    from .test_common import MCPClient
    return MCPClient(jupyter_mcp_server)


@pytest.fixture(scope="function")
def mcp_client_parametrized(mcp_server_url):
    """MCP client that works with both server modes via parametrization
    
    This fixture creates an MCPClient that can connect to either:
    - Standalone MCP server (MCP_SERVER mode)
    - Jupyter extension MCP endpoints (JUPYTER_SERVER mode)
    
    Returns:
        MCPClient: Configured client for the parametrized server mode
    """
    from .test_common import MCPClient
    return MCPClient(mcp_server_url)

```

`tests/test_common.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""
Common test infrastructure shared between MCP_SERVER and JUPYTER_SERVER mode tests.

This module provides:
- MCPClient: MCP protocol client for remote testing
- timeout_wrapper: Decorator for timeout handling
- requires_session: Decorator to check client session connection
- JUPYTER_TOOLS: List of expected tool names
- Helper functions for content extraction
"""

import asyncio
import functools
import json
import logging
from contextlib import AsyncExitStack

import pytest
import requests
from mcp import ClientSession, types
from mcp.client.streamable_http import streamablehttp_client


# TODO: could be retrieved from code (inspect)
JUPYTER_TOOLS = [
    # Multi-Notebook Management Tools
    "use_notebook",
    "list_notebooks", 
    "restart_notebook",
    "unuse_notebook",
    "read_notebook",
    # Cell Tools
    "insert_cell",
    "insert_execute_code_cell",
    "overwrite_cell_source",
    "execute_cell",
    "read_cell",
    "delete_cell",
    "execute_code",
    # Server Management Tools
    "list_files",
    "list_kernels",
    "connect_to_jupyter"
]


def timeout_wrapper(timeout_seconds=30):
    """Decorator to add timeout handling to async test functions
    
    Windows has known issues with asyncio and network timeouts that can cause 
    tests to hang indefinitely. This decorator adds a safety timeout specifically
    for Windows platforms while allowing other platforms to run normally.
    """
    def decorator(func):
        @functools.wraps(func)
        async def wrapper(*args, **kwargs):
            try:
                return await asyncio.wait_for(func(*args, **kwargs), timeout=timeout_seconds)
            except asyncio.TimeoutError:
                pytest.skip(f"Test {func.__name__} timed out ({timeout_seconds}s) - known platform limitation")
            except Exception as e:
                # Check if it's a network timeout related to Windows
                if "ReadTimeout" in str(e) or "TimeoutError" in str(e):
                    pytest.skip(f"Test {func.__name__} hit network timeout - known platform limitation: {e}")
                raise
        return wrapper
    return decorator


def requires_session(func):
    """
    A decorator that checks if the instance has a connected session.
    """
    @functools.wraps(func)
    async def wrapper(self, *args, **kwargs):
        if not self._session:
            raise RuntimeError("Client session is not connected")
        # If the session exists, call the original method
        return await func(self, *args, **kwargs)
    
    return wrapper


class MCPClient:
    """A standard MCP client used to interact with the Jupyter MCP server

    Basically it's a client wrapper for the Jupyter MCP server.
    It uses the `requires_session` decorator to check if the session is connected.
    """

    def __init__(self, url):
        self.url = f"{url}/mcp"
        self._session: ClientSession | None = None
        self._exit_stack = AsyncExitStack()

    async def __aenter__(self):
        """Initiate the session (enter session context)"""
        streams_context = streamablehttp_client(self.url)
        read_stream, write_stream, _ = await self._exit_stack.enter_async_context(
            streams_context
        )
        session_context = ClientSession(read_stream, write_stream)
        self._session = await self._exit_stack.enter_async_context(session_context)
        await self._session.initialize()
        return self

    async def __aexit__(self, exc_type, exc_val, exc_tb):
        """Close the session (exit session context)"""
        if self._exit_stack:
            await self._exit_stack.aclose()
        self._session = None

    @staticmethod
    def _extract_text_content(result):
        """Extract text content from a result"""
        try:
            logging.debug(f"_extract_text_content: result type={type(result)}, has content={hasattr(result, 'content')}, is tuple={isinstance(result, tuple)}, is list={isinstance(result, list)}")
            
            # Handle tuple results (content, metadata)
            if isinstance(result, tuple) and len(result) >= 2:
                logging.debug(f"_extract_text_content: handling tuple, first element type={type(result[0])}")
                result = result[0]  # Get the content list from the tuple
            
            if hasattr(result, 'content') and result.content and len(result.content) > 0:
                # Check if all items are TextContent
                if all(isinstance(item, types.TextContent) for item in result.content):
                    # If multiple TextContent items, return as JSON list
                    if len(result.content) > 1:
                        texts = [item.text for item in result.content]
                        import json
                        text = json.dumps(texts)
                        logging.debug(f"_extract_text_content: extracted {len(texts)} TextContent items as JSON list")
                        return text
                    else:
                        text = result.content[0].text
                        logging.debug(f"_extract_text_content: extracted from result.content[0].text, length={len(text)}")
                        return text
            # Handle list results directly
            elif isinstance(result, list) and len(result) > 0:
                # Check if all items are TextContent
                if all(isinstance(item, types.TextContent) for item in result):
                    # If multiple TextContent items, return as JSON list
                    if len(result) > 1:
                        texts = [item.text for item in result]
                        import json
                        text = json.dumps(texts)
                        logging.debug(f"_extract_text_content: extracted {len(texts)} TextContent items as JSON list")
                        return text
                    else:
                        text = result[0].text
                        logging.debug(f"_extract_text_content: extracted from list[0].text, length={len(text)}")
                        return text
        except (AttributeError, IndexError, TypeError) as e:
            logging.debug(f"_extract_text_content error: {e}, result type: {type(result)}")
        
        logging.debug(f"_extract_text_content: returning None, could not extract")
        return None

    def _get_structured_content_safe(self, result):
        """Safely get structured content with fallback to text content parsing"""
        content = getattr(result, 'structuredContent', None)
        if content is None:
            # Try to extract from text content as fallback
            text_content = self._extract_text_content(result)
            logging.debug(f"_get_structured_content_safe: text_content={repr(text_content[:200] if text_content else None)}")
            if text_content:
                # Try to parse as JSON
                try:
                    parsed = json.loads(text_content)
                    logging.debug(f"_get_structured_content_safe: JSON parsed successfully, type={type(parsed)}")
                    # Check if it's already a wrapped result or a direct response object
                    if isinstance(parsed, dict):
                        # If it has "result" key, it's already wrapped
                        if "result" in parsed:
                            return parsed
                        # If it has keys like "index", "type", "source" it's a direct object (like CellInfo)
                        elif any(key in parsed for key in ["index", "type", "source", "cells"]):
                            return parsed
                        # Otherwise wrap it
                        else:
                            return {"result": parsed}
                    else:
                        # Lists, strings, etc. - wrap them
                        return {"result": parsed}
                except json.JSONDecodeError:
                    # Not JSON - could be plain text or list representation
                    # Try to evaluate as Python literal (for lists, etc.)
                    try:
                        import ast
                        parsed = ast.literal_eval(text_content)
                        logging.debug(f"_get_structured_content_safe: ast.literal_eval succeeded, type={type(parsed)}, value={repr(parsed)}")
                        return {"result": parsed}
                    except (ValueError, SyntaxError):
                        # Plain text - return as-is
                        logging.debug(f"_get_structured_content_safe: Plain text, wrapping in result dict")
                        return {"result": text_content}
            else:
                # No text content - check if we have ImageContent or mixed content
                if hasattr(result, 'content') and result.content:
                    # Extract mixed content (ImageContent + TextContent)
                    content_list = []
                    for item in result.content:
                        if isinstance(item, types.ImageContent):
                            # Convert ImageContent to dict format
                            content_list.append({
                                'type': 'image',
                                'data': item.data,
                                'mimeType': item.mimeType,
                                'annotations': getattr(item, 'annotations', None),
                                'meta': getattr(item, 'meta', None)
                            })
                        elif isinstance(item, types.TextContent):
                            # Include text content if present
                            content_list.append(item.text)
                    
                    if content_list:
                        logging.debug(f"_get_structured_content_safe: extracted {len(content_list)} items from mixed content")
                        return {"result": content_list}
                
                logging.warning(f"No text content available in result: {type(result)}")
                return None
        return content
    
    async def _call_tool_safe(self, tool_name, arguments=None):
        """Safely call a tool, returning None on error (for test compatibility)"""
        try:
            result = await self._session.call_tool(tool_name, arguments=arguments or {})  # type: ignore
            
            # Log raw result for debugging
            logging.debug(f"_call_tool_safe({tool_name}): raw result type={type(result)}")
            logging.debug(f"_call_tool_safe({tool_name}): raw result={result}")
            
            # Check if result contains error text (for MCP_SERVER mode where errors are wrapped in results)
            text_content = self._extract_text_content(result)
            if text_content and ("Error executing tool" in text_content or "is out of range" in text_content or "not found" in text_content):
                logging.warning(f"Tool {tool_name} returned error in result: {text_content[:100]}")
                return None
            
            # Also check structured content for errors (for JUPYTER_SERVER mode)
            structured_content = self._get_structured_content_safe(result)
            if structured_content:
                # Check if result contains error messages
                result_value = structured_content.get("result")
                if result_value:
                    # Handle both string and list results
                    error_text = ""
                    if isinstance(result_value, str):
                        error_text = result_value
                    elif isinstance(result_value, list) and len(result_value) > 0:
                        error_text = str(result_value[0])
                    
                    if error_text and ("[ERROR:" in error_text or "is out of range" in error_text or "not found" in error_text):
                        logging.warning(f"Tool {tool_name} returned error in structured result: {error_text[:100]}")
                        return None
            
            return result
        except Exception as e:
            # Log the error but return None for test compatibility (JUPYTER_SERVER mode)
            logging.warning(f"Tool {tool_name} raised error: {e}")
            return None

    @requires_session
    async def list_tools(self):
        return await self._session.list_tools()  # type: ignore

    # Multi-Notebook Management Methods
    @requires_session
    async def use_notebook(self, notebook_name, notebook_path=None, mode="connect", kernel_id=None):
        arguments = {
            "notebook_name": notebook_name, 
            "mode": mode,
        }
        # Only add notebook_path if provided (for switching, it's optional)
        if notebook_path is not None:
            arguments["notebook_path"] = notebook_path
        
        # Only add kernel_id if provided (not None)
        if kernel_id is not None:
            arguments["kernel_id"] = kernel_id
        
        result = await self._session.call_tool("use_notebook", arguments=arguments)  # type: ignore
        return self._extract_text_content(result)
    
    @requires_session
    async def list_notebooks(self):
        result = await self._session.call_tool("list_notebooks")  # type: ignore
        return self._extract_text_content(result)
    
    @requires_session
    async def restart_notebook(self, notebook_name):
        result = await self._session.call_tool("restart_notebook", arguments={"notebook_name": notebook_name})  # type: ignore
        return self._extract_text_content(result)
    
    @requires_session
    async def unuse_notebook(self, notebook_name):
        result = await self._session.call_tool("unuse_notebook", arguments={"notebook_name": notebook_name})  # type: ignore
        return self._extract_text_content(result)
    
    @requires_session
    async def read_notebook(self, notebook_name, response_format="brief", start_index=0, limit=20):
        result = await self._session.call_tool("read_notebook", arguments={"notebook_name": notebook_name, "response_format": response_format, "start_index": start_index, "limit": limit})  # type: ignore
        return self._extract_text_content(result)
    
    @requires_session
    async def insert_cell(self, cell_index, cell_type, cell_source):
        result = await self._call_tool_safe("insert_cell", {"cell_index": cell_index, "cell_type": cell_type, "cell_source": cell_source})
        return self._get_structured_content_safe(result) if result else None

    @requires_session
    async def insert_execute_code_cell(self, cell_index, cell_source, timeout=90):
        result = await self._call_tool_safe("insert_execute_code_cell", {"cell_index": cell_index, "cell_source": cell_source, "timeout": timeout})
        structured = self._get_structured_content_safe(result) if result else None
        
        # Special handling for insert_execute_code_cell: tool returns list[str | ImageContent]
        # In JUPYTER_SERVER mode, the list gets flattened to a single string in TextContent
        # In MCP_SERVER mode, it's properly wrapped in structured content as {"result": [...]}
        if structured and "result" in structured:
            result_value = structured["result"]
            # If result is not already a list, wrap it in a list to match the tool's return type
            if not isinstance(result_value, list):
                # Wrap the single value in a list
                structured["result"] = [result_value]
        return structured

    @requires_session
    async def read_cell(self, cell_index, include_outputs=True):
        result = await self._call_tool_safe("read_cell", {"cell_index": cell_index, "include_outputs": include_outputs})
        return self._get_structured_content_safe(result) if result else None
    
    @requires_session
    async def list_kernels(self):
        """List all available kernels"""
        result = await self._session.call_tool("list_kernels")  # type: ignore
        return self._extract_text_content(result)

    @requires_session
    async def delete_cell(self, cell_indices: list[int], include_source: bool = True):
        result = await self._call_tool_safe("delete_cell", {"cell_indices": cell_indices, "include_source": include_source})
        return self._get_structured_content_safe(result) if result else None

    @requires_session
    async def execute_cell_streaming(self, cell_index):
        result = await self._call_tool_safe("execute_cell_streaming", {"cell_index": cell_index})
        return self._get_structured_content_safe(result) if result else None
    
    @requires_session
    async def execute_cell_with_progress(self, cell_index):
        result = await self._call_tool_safe("execute_cell_with_progress", {"cell_index": cell_index})
        structured = self._get_structured_content_safe(result) if result else None
        
        # Handle JUPYTER_SERVER mode flattening list responses to single string
        if structured and "result" in structured:
            result_value = structured["result"]
            if not isinstance(result_value, list):
                structured["result"] = [result_value]
        return structured

    @requires_session
    async def execute_cell(self, cell_index, timeout_seconds=300, stream=False, progress_interval=5):
        result = await self._call_tool_safe("execute_cell", {
            "cell_index": cell_index,
            "timeout_seconds": timeout_seconds,
            "stream": stream,
            "progress_interval": progress_interval
        })
        structured = self._get_structured_content_safe(result) if result else None

        # Handle JUPYTER_SERVER mode flattening list responses to single string
        if structured and "result" in structured:
            result_value = structured["result"]
            if not isinstance(result_value, list):
                structured["result"] = [result_value]
        return structured

    @requires_session
    async def overwrite_cell_source(self, cell_index, cell_source):
        result = await self._call_tool_safe("overwrite_cell_source", {"cell_index": cell_index, "cell_source": cell_source})
        return self._get_structured_content_safe(result) if result else None

    @requires_session
    async def execute_code(self, code, timeout=60):
        result = await self._session.call_tool("execute_code", arguments={"code": code, "timeout": timeout})  # type: ignore
        structured = self._get_structured_content_safe(result)
        
        # execute_code should always return a list of outputs
        # If we got a plain string, wrap it as a list
        if structured and "result" in structured:
            result_val = structured["result"]
            if isinstance(result_val, str):
                # Single output string, wrap as list
                structured["result"] = [result_val]
            elif not isinstance(result_val, list):
                # Some other type, wrap as list
                structured["result"] = [result_val]
        
        return structured

    @requires_session
    async def jupyter_cite(self, prompt, cell_indices, notebook_name=""):
        prompt = await self._session.get_prompt("jupyter_cite", arguments={"prompt": prompt, "cell_indices": cell_indices, "notebook_name": notebook_name})  # type: ignore
        return [message.content.text for message in prompt.messages]
```

`tests/test_config.py`:

```py
#!/usr/bin/env python3
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""
Simple test script to verify the configuration system works correctly.
"""

import os

from jupyter_mcp_server.config import get_config, set_config, reset_config

def test_config():
    """Test the configuration singleton."""
    print("Testing Jupyter MCP Configuration System")
    print("=" * 50)
    
    # Test default configuration
    config = get_config()
    print(f"Default runtime_url: {config.runtime_url}")
    print(f"Default document_id: {config.document_id}")
    print(f"Default provider: {config.provider}")
    
    # Test setting configuration
    new_config = set_config(
        runtime_url="http://localhost:9999",
        document_id="test_notebooks.ipynb",
        provider="datalayer",
        runtime_token="test_token"
    )
    
    print(f"\nUpdated runtime_url: {new_config.runtime_url}")
    print(f"Updated document_id: {new_config.document_id}")
    print(f"Updated provider: {new_config.provider}")
    print(f"Updated runtime_token: {'***' if new_config.runtime_token else 'None'}")
    
    # Test that singleton works - getting config again should return same values
    config2 = get_config()
    print(f"\nSingleton test - runtime_url: {config2.runtime_url}")
    print(f"Singleton test - document_id: {config2.document_id}")
    
    # Test reset
    reset_config()
    config3 = get_config()
    print(f"\nAfter reset - runtime_url: {config3.runtime_url}")
    print(f"After reset - document_id: {config3.document_id}")
    print(f"After reset - provider: {config3.provider}")
    
    print("\nâœ… Configuration system test completed successfully!")


def test_allowed_jupyter_mcp_tools_config():
    """Test the allowed_jupyter_mcp_tools configuration."""
    reset_config()
    
    # Test default configuration
    config = get_config()
    default_tools = config.get_allowed_jupyter_mcp_tools()
    assert "notebook_run-all-cells" in default_tools
    assert "notebook_get-selected-cell" in default_tools
    print(f"Default allowed tools: {default_tools}")
    
    # Test setting custom tools via set_config
    new_config = set_config(allowed_jupyter_mcp_tools="custom_tool1,custom_tool2")
    custom_tools = new_config.get_allowed_jupyter_mcp_tools()
    assert custom_tools == ["custom_tool1", "custom_tool2"]
    print(f"Custom tools: {custom_tools}")
    
    # Test configuration via set_config (simulates how CLI sets the value)
    set_config_result = set_config(allowed_jupyter_mcp_tools="env_tool1,env_tool2")
    env_tools = set_config_result.get_allowed_jupyter_mcp_tools()
    assert env_tools == ["env_tool1", "env_tool2"]
    print(f"CLI-style configuration: {env_tools}")
    
    # Reset to clean state
    reset_config()
    
    # Test comma-separated parsing with spaces
    config_with_spaces = set_config(allowed_jupyter_mcp_tools=" tool1 , tool2 , tool3 ")
    tools_with_spaces = config_with_spaces.get_allowed_jupyter_mcp_tools()
    assert tools_with_spaces == ["tool1", "tool2", "tool3"]
    print(f"Tools with spaces parsed: {tools_with_spaces}")
    
    # Test empty entries filtering
    config_empty = set_config(allowed_jupyter_mcp_tools="tool1,,tool2,")
    tools_filtered = config_empty.get_allowed_jupyter_mcp_tools()
    assert tools_filtered == ["tool1", "tool2"]
    print(f"Empty entries filtered: {tools_filtered}")
    
    print("âœ… Allowed jupyter mcp tools configuration test completed successfully!")


def test_jupyter_extension_trait():
    """Test the Jupyter Server Extension trait configuration."""
    from jupyter_mcp_server.jupyter_extension.extension import JupyterMCPServerExtensionApp
    
    # Test default configuration
    app = JupyterMCPServerExtensionApp()
    assert hasattr(app, 'allowed_jupyter_mcp_tools')
    assert app.allowed_jupyter_mcp_tools == "notebook_run-all-cells,notebook_get-selected-cell"
    print(f"Extension default tools: {app.allowed_jupyter_mcp_tools}")
    
    # Test custom configuration
    app.allowed_jupyter_mcp_tools = "custom_ext_tool1,custom_ext_tool2"
    assert app.allowed_jupyter_mcp_tools == "custom_ext_tool1,custom_ext_tool2"
    print(f"Extension custom tools: {app.allowed_jupyter_mcp_tools}")
    
    print("âœ… Jupyter extension trait test completed successfully!")


if __name__ == "__main__":
    test_config()
    test_allowed_jupyter_mcp_tools_config()
    test_jupyter_extension_trait()

```

`tests/test_jupyter_extension.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""
Integration tests for Jupyter MCP Server in JUPYTER_SERVER mode (extension).

This test file validates the server when running as a Jupyter Server extension
with direct access to serverapp resources (contents_manager, kernel_manager).

Key differences from MCP_SERVER mode:
- Uses YDoc collaborative editing when notebooks are open
- Local file operations without HTTP roundtrip

The tests connect to the extension's HTTP endpoints (not the standalone MCP server).

Launch the tests:
```
$ pytest tests/test_jupyter_extension.py -v
```
"""

import logging
from http import HTTPStatus

import pytest
import requests

from .conftest import JUPYTER_TOKEN


###############################################################################
# Unit Tests - Extension Components
###############################################################################

def test_import():
    """Test that all extension imports work."""
    from jupyter_mcp_server.jupyter_extension import extension
    from jupyter_mcp_server.jupyter_extension import handlers
    from jupyter_mcp_server.jupyter_extension import context
    logging.info("âœ… All imports successful")
    assert True


def test_extension_points():
    """Test extension discovery."""
    from jupyter_mcp_server import _jupyter_server_extension_points
    points = _jupyter_server_extension_points()
    logging.info(f"Extension points: {points}")
    assert len(points) > 0
    assert "jupyter_mcp_server" in points[0]["module"]


def test_handler_creation():
    """Test that handlers can be instantiated."""
    from jupyter_mcp_server.jupyter_extension.handlers import (
        MCPSSEHandler, 
        MCPHealthHandler, 
        MCPToolsListHandler
    )
    logging.info("âœ… Handlers available")
    assert MCPSSEHandler is not None
    assert MCPHealthHandler is not None
    assert MCPToolsListHandler is not None


###############################################################################
# Integration Tests - Extension Running in Jupyter
###############################################################################

def test_extension_health(jupyter_server_with_extension):
    """Test that Jupyter server with MCP extension is healthy"""
    logging.info(f"Testing Jupyter+MCP extension health ({jupyter_server_with_extension})")
    
    # Test Jupyter API is accessible
    response = requests.get(
        f"{jupyter_server_with_extension}/api/status",
        headers={"Authorization": f"token {JUPYTER_TOKEN}"},
    )
    assert response.status_code == HTTPStatus.OK
    logging.info("âœ… Jupyter API is accessible")


def test_mode_comparison_documentation(jupyter_server_with_extension, jupyter_server):
    """
    Document the differences between the two server modes for future reference.
    
    This test serves as living documentation of the architecture.
    """
    logging.info("\n" + "="*80)
    logging.info("SERVER MODE COMPARISON")
    logging.info("="*80)
    
    logging.info("\nMCP_SERVER Mode (Standalone):")
    logging.info(f"  - URL: {jupyter_server}")
    logging.info("  - Started via: python -m jupyter_mcp_server --transport streamable-http")
    logging.info("  - Tools use: JupyterServerClient + KernelClient (HTTP)")
    logging.info("  - File operations: HTTP API (contents API)")
    logging.info("  - Cell operations: WebSocket messages")
    logging.info("  - Execute IPython: WebSocket to kernel")
    logging.info("  - Tests: test_mcp_server.py")
    
    logging.info("\nJUPYTER_SERVER Mode (Extension):")
    logging.info(f"  - URL: {jupyter_server_with_extension}")
    logging.info("  - Started via: jupyter lab --ServerApp.jpserver_extensions")
    logging.info("  - Tools use: Direct Python APIs (contents_manager, kernel_manager)")
    logging.info("  - File operations: Direct nbformat + YDoc collaborative")
    logging.info("  - Cell operations: YDoc when available, nbformat fallback")
    logging.info("  - Execute IPython: Direct kernel_manager.get_kernel() + ZMQ")
    logging.info("  - Tests: test_jupyter_extension.py (this file)")
    
    logging.info("\nKey Benefits of JUPYTER_SERVER Mode:")
    logging.info("  âœ“ Real-time collaborative editing via YDoc")
    logging.info("  âœ“ Zero-latency local operations")
    logging.info("  âœ“ Direct ZMQ access to kernels")
    logging.info("  âœ“ Automatic sync with JupyterLab UI")
    
    logging.info("\nKey Benefits of MCP_SERVER Mode:")
    logging.info("  âœ“ Works with remote Jupyter servers")
    logging.info("  âœ“ No Jupyter extension installation required")
    logging.info("  âœ“ Can proxy to multiple Jupyter instances")
    logging.info("  âœ“ Standard MCP protocol compatibility")
    
    logging.info("="*80 + "\n")
    
    # Both servers should be running
    assert jupyter_server is not None
    assert jupyter_server_with_extension is not None
    assert jupyter_server != jupyter_server_with_extension  # Different ports


###############################################################################
# Unit Tests - Extension Configuration
###############################################################################

def test_extension_trait_configuration():
    """Test that the extension trait handles allowed_jupyter_mcp_tools configuration."""
    from jupyter_mcp_server.jupyter_extension.extension import JupyterMCPServerExtensionApp
    
    # Test default configuration
    app = JupyterMCPServerExtensionApp()
    assert hasattr(app, 'allowed_jupyter_mcp_tools')
    assert app.allowed_jupyter_mcp_tools == "notebook_run-all-cells,notebook_get-selected-cell"
    
    # Test custom configuration
    app.allowed_jupyter_mcp_tools = "notebook_append-execute,console_create"
    assert app.allowed_jupyter_mcp_tools == "notebook_append-execute,console_create"
    
    logging.info("âœ… Extension trait configuration test passed")


def test_extension_trait_validation():
    """Test that the extension trait validates allowed_jupyter_mcp_tools input."""
    from jupyter_mcp_server.jupyter_extension.extension import JupyterMCPServerExtensionApp
    
    app = JupyterMCPServerExtensionApp()
    
    # Test various valid formats
    valid_configurations = [
        "tool1,tool2,tool3",
        "single_tool",
        "notebook_*,console_create",
        "",  # Empty should be allowed
        " tool1 , tool2 ",  # Spaces should be handled
    ]
    
    for config in valid_configurations:
        app.allowed_jupyter_mcp_tools = config
        assert isinstance(app.allowed_jupyter_mcp_tools, str)
    
    logging.info("âœ… Extension trait validation test passed")

```

`tests/test_prompts.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""
Test for MCP Prompts Feature
"""

import os

import pytest

from .test_common import MCPClient, timeout_wrapper

# Now, prompt feature is only available in MCP_SERVER mode.
pytestmark = pytest.mark.skipif(
    not os.environ.get("TEST_MCP_SERVER", "false").lower() == "true",
    reason="Prompt feature is only available in MCP_SERVER mode now."
)


@pytest.mark.asyncio
@timeout_wrapper(60)
async def test_jupyter_cite(mcp_client_parametrized: MCPClient):
    """Test jupyter cite prompt feature"""
    async with mcp_client_parametrized:
        await mcp_client_parametrized.use_notebook("new", "new.ipynb")
        await mcp_client_parametrized.use_notebook("notebook", "notebook.ipynb")
        # Test prompt injection
        response = await mcp_client_parametrized.jupyter_cite(prompt="test prompt", cell_indices="0")
        assert "# Matplotlib Examples" in response[0], "Cell 0 should contain Matplotlib Examples"
        assert "test prompt" in response[0], "Prompt should be injected"
        # Test mixed cell_indices
        response = await mcp_client_parametrized.jupyter_cite(prompt="", cell_indices="0-2,4")
        assert "USER Cite cells [0, 1, 2, 4]" in response[0], "Cell indices should be [0, 1, 2, 4]"
        assert "## 1. Import Required Libraries" in response[0], "Cell 1 should contain Import Required Libraries"
        assert "%matplotlib inline" in response[0], "Cell 2 should contain %matplotlib inline"
        assert "## 2. Basic Line Plot" not in response[0], "Cell 3 should not be cited"
        assert "y = np.sin(x)" in response[0], "Cell 4 should contain y = np.sin(x)"
        # Test cite other notebook
        response = await mcp_client_parametrized.jupyter_cite(prompt="", cell_indices="0", notebook_name="new")
        assert "from notebook new" in response[0], "should cite new notebook"
        assert "# A New Notebook" in response[0], "Cell 0 of new notebook should contain A New Notebook"

```

`tests/test_tools.py`:

```py
# Copyright (c) 2024- Datalayer, Inc.
#
# BSD 3-Clause License

"""
Integration tests for Jupyter MCP Server - Both MCP_SERVER and JUPYTER_SERVER modes.

This test suite validates the Jupyter MCP Server in both deployment modes:

1. **MCP_SERVER Mode**: Standalone server using HTTP/WebSocket to Jupyter
2. **JUPYTER_SERVER Mode**: Extension with direct serverapp API access

Tests are parametrized to run against both modes using the same MCPClient,
ensuring consistent behavior across both deployment patterns.

Launch the tests:
```
$ pytest tests/test_server.py -v
```
"""

import logging
from http import HTTPStatus

import pytest
import requests

from .test_common import MCPClient, JUPYTER_TOOLS, timeout_wrapper
from .conftest import JUPYTER_TOKEN


###############################################################################
# Health Tests
###############################################################################

def test_jupyter_health(jupyter_server):
    """Test the Jupyter server health"""
    logging.info(f"Testing service health ({jupyter_server})")
    response = requests.get(
        f"{jupyter_server}/api/status",
        headers={
            "Authorization": f"token {JUPYTER_TOKEN}",
        },
    )
    assert response.status_code == HTTPStatus.OK


@pytest.mark.parametrize(
    "jupyter_mcp_server,kernel_expected_status",
    [(True, "alive"), (False, "not_initialized")],
    indirect=["jupyter_mcp_server"],
    ids=["start_runtime", "no_runtime"],
)
def test_mcp_health(jupyter_mcp_server, kernel_expected_status):
    """Test the MCP Jupyter server health"""
    logging.info(f"Testing MCP server health ({jupyter_mcp_server})")
    response = requests.get(f"{jupyter_mcp_server}/api/healthz")
    assert response.status_code == HTTPStatus.OK
    data = response.json()
    logging.debug(data)
    assert data.get("status") == "healthy"
    assert data.get("kernel_status") == kernel_expected_status


@pytest.mark.asyncio
async def test_mcp_tool_list(mcp_client_parametrized: MCPClient, request):
    """Check that the list of tools can be retrieved in both MCP_SERVER and JUPYTER_SERVER modes"""
    async with mcp_client_parametrized:
        tools = await mcp_client_parametrized.list_tools()
    tools_name = [tool.name for tool in tools.tools]
    logging.debug(f"tools_name: {tools_name}")
    
    # In JUPYTER_SERVER mode (jupyter_extension), connect_to_jupyter is filtered out
    # In MCP_SERVER mode (mcp_server), all tools are available
    expected_tools = JUPYTER_TOOLS.copy()
    
    # Get the current test parameter to determine the mode
    current_param = None
    for param in request.node.callspec.params.values():
        if param in ["mcp_server", "jupyter_extension"]:
            current_param = param
            break
    
    if current_param == "jupyter_extension":
        # Remove connect_to_jupyter for jupyter_extension mode
        expected_tools = [tool for tool in JUPYTER_TOOLS if tool != 'connect_to_jupyter']
    
    assert len(tools_name) == len(expected_tools) and sorted(tools_name) == sorted(
        expected_tools
    )


@pytest.mark.asyncio
@timeout_wrapper(60)
async def test_cell_manipulation(mcp_client_parametrized: MCPClient):
    """Test cell manipulation (both markdown and code cells) in both MCP_SERVER and JUPYTER_SERVER modes"""

    async def check_and_delete_cell(client: MCPClient, index, expected_type, content):
        """Check and delete a cell (works for both markdown and code cells)"""
        # reading and checking the content of the created cell
        cell_info = await client.read_cell(index)
        logging.debug(f"cell_info: {cell_info}")
        assert isinstance(cell_info['result'], list), "Read cell result should be a list"
        assert f"=====Cell {index} | type: {expected_type}" in cell_info['result'][0], "Cell metadata should be included"
        assert content in cell_info['result'][1], "Cell source should be included"
        # delete created cell
        result = await client.delete_cell([index])
        assert result is not None, "delete_cell result should not be None"
        assert f"Cell {index} ({expected_type}) deleted successfully" in result["result"]
        assert f"deleted cell source:\n{content}" in result["result"]

    async with mcp_client_parametrized:
        # Test markdown cell operations
        markdown_content = "Hello **World** !"
        # insert markdown cell at index 1
        result = await mcp_client_parametrized.insert_cell(1, "markdown", markdown_content)
        assert result is not None, "insert_cell result should not be None"
        assert "Cell inserted successfully at index 1 (markdown)!" in result["result"]
        await check_and_delete_cell(mcp_client_parametrized, 1, "markdown", markdown_content)

        # Test code cell operations
        code_content = "1 + 1"
        code_result = await mcp_client_parametrized.insert_execute_code_cell(1, code_content)
        expected_result = eval(code_content)
        assert int(code_result['result'][0]) == expected_result

        # Testing appending code cell to bottom of notebook
        code_result = await mcp_client_parametrized.insert_execute_code_cell(-1, code_content)
        expected_result = eval(code_content)
        assert int(code_result['result'][0]) == expected_result

        # Test overwrite_cell_source
        new_code_content = f"({code_content}) * 2"
        result = await mcp_client_parametrized.overwrite_cell_source(1, new_code_content)
        assert result is not None, "overwrite_cell_source result should not be None"
        assert "Cell 1 overwritten successfully!" in result["result"]
        assert "diff" in result["result"]
        assert "-" in result["result"]
        assert "+" in result["result"]
        assert int(code_result["result"][0]) == expected_result

        await check_and_delete_cell(mcp_client_parametrized, 1, "code", new_code_content)

@pytest.mark.asyncio
@timeout_wrapper(60)
async def test_multimodal_output(mcp_client_parametrized: MCPClient):
    """Test multimodal output functionality with image generation in both modes"""
    async with mcp_client_parametrized:
        
        # Test image generation code using PIL (lightweight)
        image_code = """
from PIL import Image, ImageDraw
import io
import base64

# Create a simple test image using PIL
width, height = 200, 100
image = Image.new('RGB', (width, height), color='white')
draw = ImageDraw.Draw(image)

# Draw a simple pattern
draw.rectangle([10, 10, 190, 90], outline='blue', width=2)
draw.ellipse([20, 20, 80, 80], fill='red')
draw.text((100, 40), "Test Image", fill='black')

# Convert to PNG and display
buffer = io.BytesIO()
image.save(buffer, format='PNG')
buffer.seek(0)

# Display the image (this should generate image/png output)
from IPython.display import Image as IPythonImage, display
display(IPythonImage(buffer.getvalue()))
"""
        # Execute the image generation code
        result = await mcp_client_parametrized.insert_execute_code_cell(1, image_code)
        
        # Check that result is 
        assert isinstance(result['result'], list), "Result should be a list"
        assert isinstance(result['result'][0], dict)
        assert result['result'][0]['mimeType'] == "image/png", "Result should be a list of ImageContent"
        await mcp_client_parametrized.delete_cell([1])


###############################################################################
# Multi-Notebook Management Tests
###############################################################################

@pytest.mark.asyncio
@timeout_wrapper(90)
async def test_multi_notebook_operations(mcp_client_parametrized: MCPClient):
    """Test cell operations across multiple notebooks in both modes"""
    async with mcp_client_parametrized:
        # Connect to the new notebook
        result = await mcp_client_parametrized.use_notebook("notebook_a", "new.ipynb")
        logging.debug(f"Connect to notebook A: {result}")
        assert "Successfully activate notebook 'notebook_a'" in result

        notebook_a_info = await mcp_client_parametrized.read_notebook("notebook_a")
        assert "# This is notebook A" not in notebook_a_info
        
        # Add a cell to notebook A
        await mcp_client_parametrized.insert_cell(-1, "markdown", "# This is notebook A")
        
        # Try to connect to notebook.ipynb as notebook_b
        result = await mcp_client_parametrized.use_notebook("notebook_b", "notebook.ipynb")
        logging.debug(f"Connect to notebook B: {result}")
        assert "Successfully activate notebook 'notebook_b'" in result
        
        # Add a cell to notebook B
        await mcp_client_parametrized.insert_cell(-1, "markdown", "# This is notebook B\nA hidden content")
        
        # Switch back to notebook A
        result = await mcp_client_parametrized.use_notebook("notebook_a", "new.ipynb")
        logging.debug(f"Reactivate notebook A: {result}")
        assert "Reactivating notebook 'notebook_a' and deactivating 'notebook_b'." in result
        
        # Verify we're working with notebook A
        cell_list_a = await mcp_client_parametrized.read_notebook("notebook_a")
        assert "This is notebook A" in cell_list_a
        
        # Switch to notebook B and verify
        await mcp_client_parametrized.use_notebook("notebook_b", "notebook.ipynb")
        cell_list_b = await mcp_client_parametrized.read_notebook("notebook_b", response_format="detailed")
        assert "A hidden content" in cell_list_b

        notebook_list = await mcp_client_parametrized.list_notebooks()
        logging.debug(f"Notebook list after switching: {notebook_list}")
        assert "notebook_a" in notebook_list
        assert "notebook_b" in notebook_list
        assert "âœ“" in notebook_list

        # Test restart notebook
        restart_result = await mcp_client_parametrized.restart_notebook("notebook_a")
        logging.debug(f"Restart result: {restart_result}")
        assert "Notebook 'notebook_a' kernel restarted successfully" in restart_result
        
        # Clean up - unuse both notebooks
        result = await mcp_client_parametrized.unuse_notebook("notebook_a")
        logging.debug(f"Unuse notebook A: {result}")
        assert "Notebook 'notebook_a' unused successfully" in result
        result = await mcp_client_parametrized.unuse_notebook("notebook_b")
        logging.debug(f"Unuse notebook B: {result}")
        assert "Notebook 'notebook_b' unused successfully" in result


@pytest.mark.asyncio 
@timeout_wrapper(60)
async def test_notebooks_error_cases(mcp_client_parametrized: MCPClient):
    """Test error handling for notebook management in both modes"""
    async with mcp_client_parametrized:
        # Test connecting to non-existent notebook (with required notebook_path parameter)
        error_result = await mcp_client_parametrized.use_notebook("nonexistent", "nonexistent.ipynb")
        logging.debug(f"Nonexistent notebook result: {error_result}")
        assert "not found" in error_result
        
        # Test operations on non-used notebook
        restart_error = await mcp_client_parametrized.restart_notebook("nonexistent_notebook")
        assert "not connected" in restart_error
        
        disconnect_error = await mcp_client_parametrized.unuse_notebook("nonexistent_notebook") 
        assert "not connected" in disconnect_error

@pytest.mark.asyncio
@timeout_wrapper(60)
async def test_execute_code(mcp_client_parametrized: MCPClient):
    """Test execute_code with basic Python code in both modes"""
    async with mcp_client_parametrized:
        # Test simple Python code
        result = await mcp_client_parametrized.execute_code("words='Hello IPython World!'")

        # Test %who magic command (list variables)
        result = await mcp_client_parametrized.execute_code("%who")
        assert "words" in result["result"][0]

        result = await mcp_client_parametrized.execute_code("!echo 'Hello from shell'")
        assert "Hello from shell" in result["result"][0]

        # Test with very short timeout on a potentially long-running command
        result = await mcp_client_parametrized.execute_code("import time\ntime.sleep(5)", timeout=2)
        assert "TIMEOUT ERROR" in result["result"][0]

@pytest.mark.asyncio
async def test_list_kernels(mcp_client_parametrized: MCPClient):
    """Test list_kernels functionality in both MCP_SERVER and JUPYTER_SERVER modes"""
    async with mcp_client_parametrized:
        # Call list_kernels
        kernel_list = await mcp_client_parametrized.list_kernels()
        logging.debug(f"Kernel list: {kernel_list}")
        # Check for either TSV header or "No kernels found" message
        assert "ID\tName\tDisplay_Name\tLanguage\tState\tConnections\tLast_Activity\tEnvironment" in kernel_list


###############################################################################
# Allowed Tools Configuration Tests
###############################################################################

@pytest.mark.asyncio
async def test_allowed_jupyter_mcp_tools_integration(mcp_client_parametrized: MCPClient):
    """Test that the server respects allowed_jupyter_mcp_tools configuration."""
    async with mcp_client_parametrized:
        # Get the list of tools from the server
        tools = await mcp_client_parametrized.list_tools()
        tool_names = [tool.name for tool in tools.tools]
        
        logging.info(f"Available tools: {tool_names}")
        
        # Check that default jupyter-mcp-tools are present
        # These should be available by default
        jupyter_tools = [name for name in tool_names if name.startswith("notebook_")]
        
        # The actual availability depends on whether jupyter-mcp-tools is installed
        # and whether we're running in JupyterLab mode, so we check conditionally
        if any(tool.startswith("notebook_") for tool in tool_names):
            # If any notebook tools are present, the default ones should be there
            assert "notebook_run-all-cells" in tool_names or len(jupyter_tools) > 0
            logging.info(f"Jupyter MCP tools found: {jupyter_tools}")
        else:
            logging.info("No jupyter-mcp-tools detected (possibly not in JupyterLab mode)")


def test_config_allowed_tools_parsing():
    """Test the configuration parsing for allowed tools."""
    from jupyter_mcp_server.config import JupyterMCPConfig
    
    # Test various input formats
    test_cases = [
        ("tool1,tool2,tool3", ["tool1", "tool2", "tool3"]),
        ("single_tool", ["single_tool"]),
        (" tool1 , tool2 , tool3 ", ["tool1", "tool2", "tool3"]),
        ("tool1,,tool2,", ["tool1", "tool2"]),
        ("notebook_*,console_create", ["notebook_*", "console_create"]),
    ]
    
    for input_str, expected in test_cases:
        config = JupyterMCPConfig(allowed_jupyter_mcp_tools=input_str)
        result = config.get_allowed_jupyter_mcp_tools()
        assert result == expected, f"Failed for input '{input_str}': expected {expected}, got {result}"
        logging.info(f"âœ… Parsed '{input_str}' -> {result}")
    
    logging.info("âœ… All configuration parsing tests passed")


def test_config_environment_variable():
    """Test that CLI-style configuration works (environment variables work through CLI)."""
    from jupyter_mcp_server.config import set_config, reset_config
    
    # Test configuration via set_config (simulates how CLI handles environment variables)
    reset_config()
    config = set_config(allowed_jupyter_mcp_tools="env_tool1,env_tool2")
    tools = config.get_allowed_jupyter_mcp_tools()
    
    assert tools == ["env_tool1", "env_tool2"]
    logging.info(f"âœ… CLI-style configuration test passed: {tools}")
    
    # Cleanup
    reset_config()


def test_config_defaults():
    """Test that default configuration works correctly."""
    from jupyter_mcp_server.config import JupyterMCPConfig, reset_config
    
    reset_config()
    config = JupyterMCPConfig()
    default_tools = config.get_allowed_jupyter_mcp_tools()
    
    assert "notebook_run-all-cells" in default_tools
    assert "notebook_get-selected-cell" in default_tools
    assert len(default_tools) == 2
    
    logging.info(f"âœ… Default configuration test passed: {default_tools}")


def test_server_tool_registration():
    """Test that get_registered_tools includes the correct tools based on configuration."""
    from jupyter_mcp_server.server import get_registered_tools
    from jupyter_mcp_server.config import set_config, reset_config
    
    # Test with custom configuration
    reset_config()
    set_config(allowed_jupyter_mcp_tools="notebook_run-all-cells")
    
    try:
        # Get registered tools (this may fail if jupyter-mcp-tools is not available)
        tools = get_registered_tools(token="test_token", url="http://localhost:8888")
        tool_names = [tool["name"] for tool in tools]
        
        logging.info(f"Registered tools: {tool_names}")
        
        # Check that FastMCP tools are always present
        fastmcp_tools = [name for name in tool_names if not name.startswith("notebook_")]
        assert len(fastmcp_tools) > 0, "FastMCP tools should always be present"
        
        logging.info("âœ… Server tool registration test completed")
        
    except Exception as e:
        # This is expected if jupyter-mcp-tools is not available or we're not in JupyterLab mode
        logging.info(f"Server tool registration test skipped due to: {e}")
    
    finally:
        reset_config()

```